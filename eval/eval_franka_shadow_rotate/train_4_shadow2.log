################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 11134 steps/s (collection: 8.406s, learning 0.422s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0022
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 25.5898
                       Mean reward: 0.00
               Mean episode length: 21.94
    Episode_Reward/reaching_object: 0.0005
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0002
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 8.83s
                      Time elapsed: 00:00:08
                               ETA: 03:40:43

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 16269 steps/s (collection: 5.862s, learning 0.180s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 25.7090
                       Mean reward: 0.00
               Mean episode length: 45.00
    Episode_Reward/reaching_object: 0.0014
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0005
          Episode_Reward/joint_vel: -0.0006
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.04s
                      Time elapsed: 00:00:14
                               ETA: 03:05:45

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 17420 steps/s (collection: 5.481s, learning 0.162s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 25.7447
                       Mean reward: 0.00
               Mean episode length: 69.37
    Episode_Reward/reaching_object: 0.0023
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0010
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 5.64s
                      Time elapsed: 00:00:20
                               ETA: 02:50:43

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 16659 steps/s (collection: 5.727s, learning 0.173s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 25.7351
                       Mean reward: 0.00
               Mean episode length: 93.77
    Episode_Reward/reaching_object: 0.0031
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0012
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 5.90s
                      Time elapsed: 00:00:26
                               ETA: 02:44:45

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 17323 steps/s (collection: 5.516s, learning 0.158s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 25.7338
                       Mean reward: 0.01
               Mean episode length: 117.34
    Episode_Reward/reaching_object: 0.0044
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0016
          Episode_Reward/joint_vel: -0.0018
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 5.67s
                      Time elapsed: 00:00:32
                               ETA: 02:40:01

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 17887 steps/s (collection: 5.365s, learning 0.131s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 25.7415
                       Mean reward: 0.01
               Mean episode length: 141.43
    Episode_Reward/reaching_object: 0.0055
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0022
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 5.50s
                      Time elapsed: 00:00:37
                               ETA: 02:36:04

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 19098 steps/s (collection: 5.023s, learning 0.124s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 25.7201
                       Mean reward: 0.01
               Mean episode length: 165.01
    Episode_Reward/reaching_object: 0.0072
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0026
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 5.15s
                      Time elapsed: 00:00:42
                               ETA: 02:32:00

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 19599 steps/s (collection: 4.859s, learning 0.157s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 25.7110
                       Mean reward: 0.02
               Mean episode length: 189.52
    Episode_Reward/reaching_object: 0.0084
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0026
          Episode_Reward/joint_vel: -0.0030
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 5.02s
                      Time elapsed: 00:00:47
                               ETA: 02:28:30

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 19086 steps/s (collection: 5.004s, learning 0.146s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 25.7215
                       Mean reward: 0.03
               Mean episode length: 213.81
    Episode_Reward/reaching_object: 0.0114
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0030
          Episode_Reward/joint_vel: -0.0034
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.15s
                      Time elapsed: 00:00:52
                               ETA: 02:26:09

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 59033 steps/s (collection: 1.553s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 25.7307
                       Mean reward: 0.04
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 0.0134
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0038
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.67s
                      Time elapsed: 00:00:54
                               ETA: 02:15:35

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 61539 steps/s (collection: 1.489s, learning 0.109s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 25.7212
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0159
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.60s
                      Time elapsed: 00:00:56
                               ETA: 02:06:47

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 59851 steps/s (collection: 1.529s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 25.7258
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0195
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.64s
                      Time elapsed: 00:00:57
                               ETA: 01:59:32

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 62350 steps/s (collection: 1.465s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 25.7458
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0257
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.58s
                      Time elapsed: 00:00:59
                               ETA: 01:53:16

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 61992 steps/s (collection: 1.471s, learning 0.115s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 25.7687
                       Mean reward: 0.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0311
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.59s
                      Time elapsed: 00:01:00
                               ETA: 01:47:55

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 55110 steps/s (collection: 1.640s, learning 0.144s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 25.7729
                       Mean reward: 0.19
               Mean episode length: 249.96
    Episode_Reward/reaching_object: 0.0408
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.78s
                      Time elapsed: 00:01:02
                               ETA: 01:43:36

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 57049 steps/s (collection: 1.602s, learning 0.121s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 25.8127
                       Mean reward: 0.27
               Mean episode length: 249.83
    Episode_Reward/reaching_object: 0.0536
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.72s
                      Time elapsed: 00:01:04
                               ETA: 01:39:43

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 58120 steps/s (collection: 1.570s, learning 0.122s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0014
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 25.8337
                       Mean reward: 0.36
               Mean episode length: 249.10
    Episode_Reward/reaching_object: 0.0729
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.69s
                      Time elapsed: 00:01:06
                               ETA: 01:36:15

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 55611 steps/s (collection: 1.661s, learning 0.107s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0888
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 25.8797
                       Mean reward: 0.46
               Mean episode length: 246.67
    Episode_Reward/reaching_object: 0.0933
    Episode_Reward/rotating_object: 0.0004
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.77s
                      Time elapsed: 00:01:07
                               ETA: 01:33:16

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 54269 steps/s (collection: 1.701s, learning 0.110s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0060
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 25.9262
                       Mean reward: 0.53
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.1100
    Episode_Reward/rotating_object: 0.0006
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.81s
                      Time elapsed: 00:01:09
                               ETA: 01:30:39

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 53753 steps/s (collection: 1.713s, learning 0.116s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0017
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 25.9516
                       Mean reward: 0.64
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 0.1299
    Episode_Reward/rotating_object: 0.0014
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.83s
                      Time elapsed: 00:01:11
                               ETA: 01:28:19

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 49332 steps/s (collection: 1.879s, learning 0.114s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0029
               Mean surrogate loss: 0.0053
                 Mean entropy loss: 26.0163
                       Mean reward: 0.76
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 0.1532
    Episode_Reward/rotating_object: 0.0040
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 10.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.99s
                      Time elapsed: 00:01:13
                               ETA: 01:26:24

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 50236 steps/s (collection: 1.845s, learning 0.112s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0021
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 26.0773
                       Mean reward: 0.93
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 0.1752
    Episode_Reward/rotating_object: 0.0056
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 9.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.96s
                      Time elapsed: 00:01:15
                               ETA: 01:24:37

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 52395 steps/s (collection: 1.756s, learning 0.121s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0021
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 26.1436
                       Mean reward: 0.86
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 0.1800
    Episode_Reward/rotating_object: 0.0067
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 7.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.88s
                      Time elapsed: 00:01:17
                               ETA: 01:22:53

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 53370 steps/s (collection: 1.730s, learning 0.112s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0024
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 26.1788
                       Mean reward: 0.93
               Mean episode length: 226.03
    Episode_Reward/reaching_object: 0.1855
    Episode_Reward/rotating_object: 0.0044
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 5.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.84s
                      Time elapsed: 00:01:19
                               ETA: 01:21:16

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 51211 steps/s (collection: 1.808s, learning 0.112s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0021
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 26.2070
                       Mean reward: 0.96
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 0.1973
    Episode_Reward/rotating_object: 0.0078
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 6.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.92s
                      Time elapsed: 00:01:21
                               ETA: 01:19:51

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 52074 steps/s (collection: 1.766s, learning 0.122s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0030
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 26.2539
                       Mean reward: 1.09
               Mean episode length: 224.37
    Episode_Reward/reaching_object: 0.2095
    Episode_Reward/rotating_object: 0.0062
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 5.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.89s
                      Time elapsed: 00:01:23
                               ETA: 01:18:31

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 52018 steps/s (collection: 1.779s, learning 0.111s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0036
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 26.3217
                       Mean reward: 1.05
               Mean episode length: 225.75
    Episode_Reward/reaching_object: 0.2191
    Episode_Reward/rotating_object: 0.0085
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 5.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.89s
                      Time elapsed: 00:01:24
                               ETA: 01:17:16

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 53220 steps/s (collection: 1.720s, learning 0.127s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0041
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 26.3412
                       Mean reward: 1.12
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 0.2269
    Episode_Reward/rotating_object: 0.0120
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 6.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.85s
                      Time elapsed: 00:01:26
                               ETA: 01:16:05

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 48114 steps/s (collection: 1.918s, learning 0.125s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0042
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 26.3889
                       Mean reward: 1.27
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 0.2368
    Episode_Reward/rotating_object: 0.0128
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 7.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.04s
                      Time elapsed: 00:01:28
                               ETA: 01:15:08

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 46830 steps/s (collection: 1.951s, learning 0.149s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0051
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 26.4226
                       Mean reward: 1.26
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 0.2447
    Episode_Reward/rotating_object: 0.0177
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 8.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.10s
                      Time elapsed: 00:01:30
                               ETA: 01:14:18

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 40315 steps/s (collection: 2.262s, learning 0.177s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0069
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 26.4824
                       Mean reward: 1.46
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 0.2633
    Episode_Reward/rotating_object: 0.0204
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 10.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.44s
                      Time elapsed: 00:01:33
                               ETA: 01:13:47

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 44598 steps/s (collection: 2.105s, learning 0.099s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0081
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 26.4898
                       Mean reward: 1.55
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 0.2759
    Episode_Reward/rotating_object: 0.0225
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.20s
                      Time elapsed: 00:01:35
                               ETA: 01:13:07

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 50606 steps/s (collection: 1.826s, learning 0.117s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0094
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 26.5520
                       Mean reward: 1.69
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 0.2924
    Episode_Reward/rotating_object: 0.0330
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.94s
                      Time elapsed: 00:01:37
                               ETA: 01:12:17

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 51278 steps/s (collection: 1.805s, learning 0.112s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0124
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 26.6390
                       Mean reward: 1.82
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 0.3095
    Episode_Reward/rotating_object: 0.0469
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.92s
                      Time elapsed: 00:01:39
                               ETA: 01:11:30

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 52940 steps/s (collection: 1.743s, learning 0.114s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0132
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 26.7036
                       Mean reward: 1.79
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.3201
    Episode_Reward/rotating_object: 0.0564
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.86s
                      Time elapsed: 00:01:41
                               ETA: 01:10:42

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 50887 steps/s (collection: 1.826s, learning 0.106s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0177
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 26.7662
                       Mean reward: 2.15
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 0.3321
    Episode_Reward/rotating_object: 0.0773
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 11.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.93s
                      Time elapsed: 00:01:43
                               ETA: 01:10:00

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 51276 steps/s (collection: 1.794s, learning 0.123s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0320
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 26.8338
                       Mean reward: 2.40
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 0.3545
    Episode_Reward/rotating_object: 0.1105
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.92s
                      Time elapsed: 00:01:45
                               ETA: 01:09:19

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 52525 steps/s (collection: 1.750s, learning 0.121s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0434
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 26.9493
                       Mean reward: 2.90
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 0.3684
    Episode_Reward/rotating_object: 0.1252
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.87s
                      Time elapsed: 00:01:47
                               ETA: 01:08:39

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 50615 steps/s (collection: 1.818s, learning 0.125s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.0393
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 27.0326
                       Mean reward: 2.42
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 0.3632
    Episode_Reward/rotating_object: 0.1351
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.94s
                      Time elapsed: 00:01:48
                               ETA: 01:08:04

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 47454 steps/s (collection: 1.949s, learning 0.123s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.1825
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 27.1078
                       Mean reward: 2.80
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 0.3709
    Episode_Reward/rotating_object: 0.1406
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.07s
                      Time elapsed: 00:01:51
                               ETA: 01:07:34

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 47953 steps/s (collection: 1.923s, learning 0.127s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.2495
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 27.2233
                       Mean reward: 2.64
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 0.3885
    Episode_Reward/rotating_object: 0.1791
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.05s
                      Time elapsed: 00:01:53
                               ETA: 01:07:06

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 52659 steps/s (collection: 1.768s, learning 0.099s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.0968
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 27.4100
                       Mean reward: 2.74
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 0.3902
    Episode_Reward/rotating_object: 0.2120
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.87s
                      Time elapsed: 00:01:54
                               ETA: 01:06:32

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 23627 steps/s (collection: 3.764s, learning 0.397s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.3254
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 27.5225
                       Mean reward: 3.50
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.4343
    Episode_Reward/rotating_object: 0.2712
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 4.16s
                      Time elapsed: 00:01:59
                               ETA: 01:07:18

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 18059 steps/s (collection: 4.986s, learning 0.457s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.3363
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 27.7701
                       Mean reward: 3.84
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.4334
    Episode_Reward/rotating_object: 0.2575
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 5.44s
                      Time elapsed: 00:02:04
                               ETA: 01:08:43

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 19463 steps/s (collection: 4.878s, learning 0.172s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.2480
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 27.8548
                       Mean reward: 3.22
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 0.4330
    Episode_Reward/rotating_object: 0.4376
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 5.05s
                      Time elapsed: 00:02:09
                               ETA: 01:09:52

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 21941 steps/s (collection: 4.079s, learning 0.401s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.2047
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 27.9148
                       Mean reward: 4.02
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 0.4475
    Episode_Reward/rotating_object: 0.4288
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 4.48s
                      Time elapsed: 00:02:14
                               ETA: 01:10:40

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 19659 steps/s (collection: 4.483s, learning 0.517s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.3010
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 28.0429
                       Mean reward: 4.84
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 0.4414
    Episode_Reward/rotating_object: 0.5629
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 5.00s
                      Time elapsed: 00:02:19
                               ETA: 01:11:42

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 21251 steps/s (collection: 4.504s, learning 0.122s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.4242
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 28.1587
                       Mean reward: 4.56
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 0.4479
    Episode_Reward/rotating_object: 0.3839
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 4.63s
                      Time elapsed: 00:02:23
                               ETA: 01:12:29

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 52347 steps/s (collection: 1.762s, learning 0.116s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.7298
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 28.2416
                       Mean reward: 4.99
               Mean episode length: 247.30
    Episode_Reward/reaching_object: 0.4634
    Episode_Reward/rotating_object: 0.6544
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.88s
                      Time elapsed: 00:02:25
                               ETA: 01:11:53

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 54376 steps/s (collection: 1.702s, learning 0.106s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.8203
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 28.3220
                       Mean reward: 6.18
               Mean episode length: 246.86
    Episode_Reward/reaching_object: 0.4762
    Episode_Reward/rotating_object: 0.7279
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.81s
                      Time elapsed: 00:02:27
                               ETA: 01:11:17

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 55044 steps/s (collection: 1.679s, learning 0.107s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.7789
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 28.3838
                       Mean reward: 8.51
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.4889
    Episode_Reward/rotating_object: 0.9175
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.79s
                      Time elapsed: 00:02:29
                               ETA: 01:10:41

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 53733 steps/s (collection: 1.723s, learning 0.107s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.3810
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 28.4881
                       Mean reward: 10.11
               Mean episode length: 246.80
    Episode_Reward/reaching_object: 0.4841
    Episode_Reward/rotating_object: 1.2156
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 1.83s
                      Time elapsed: 00:02:30
                               ETA: 01:10:07

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 54388 steps/s (collection: 1.683s, learning 0.124s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.2746
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 28.6080
                       Mean reward: 8.04
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 0.4934
    Episode_Reward/rotating_object: 1.4923
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.81s
                      Time elapsed: 00:02:32
                               ETA: 01:09:34

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 52208 steps/s (collection: 1.770s, learning 0.113s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.6561
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 28.6917
                       Mean reward: 12.96
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 0.4951
    Episode_Reward/rotating_object: 1.8983
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.88s
                      Time elapsed: 00:02:34
                               ETA: 01:09:05

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 53984 steps/s (collection: 1.707s, learning 0.114s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.4626
               Mean surrogate loss: 0.0053
                 Mean entropy loss: 28.7809
                       Mean reward: 11.53
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.5013
    Episode_Reward/rotating_object: 1.9693
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.82s
                      Time elapsed: 00:02:36
                               ETA: 01:08:34

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 53053 steps/s (collection: 1.743s, learning 0.110s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.7173
               Mean surrogate loss: 0.0057
                 Mean entropy loss: 28.7999
                       Mean reward: 14.75
               Mean episode length: 239.77
    Episode_Reward/reaching_object: 0.5108
    Episode_Reward/rotating_object: 2.2279
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.85s
                      Time elapsed: 00:02:38
                               ETA: 01:08:06

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 54757 steps/s (collection: 1.691s, learning 0.105s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.5917
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 28.8065
                       Mean reward: 12.73
               Mean episode length: 244.70
    Episode_Reward/reaching_object: 0.5169
    Episode_Reward/rotating_object: 2.2372
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.80s
                      Time elapsed: 00:02:40
                               ETA: 01:07:37

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 55453 steps/s (collection: 1.666s, learning 0.107s)
             Mean action noise std: 1.20
          Mean value_function loss: 4.1650
               Mean surrogate loss: 0.0062
                 Mean entropy loss: 28.8382
                       Mean reward: 16.48
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 0.5097
    Episode_Reward/rotating_object: 2.9789
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.77s
                      Time elapsed: 00:02:41
                               ETA: 01:07:08

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 52439 steps/s (collection: 1.760s, learning 0.115s)
             Mean action noise std: 1.20
          Mean value_function loss: 5.0527
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 28.8459
                       Mean reward: 14.42
               Mean episode length: 247.18
    Episode_Reward/reaching_object: 0.5190
    Episode_Reward/rotating_object: 3.1038
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.87s
                      Time elapsed: 00:02:43
                               ETA: 01:06:43

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 55062 steps/s (collection: 1.666s, learning 0.119s)
             Mean action noise std: 1.20
          Mean value_function loss: 5.3520
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 28.8692
                       Mean reward: 20.44
               Mean episode length: 242.75
    Episode_Reward/reaching_object: 0.5051
    Episode_Reward/rotating_object: 3.2968
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.79s
                      Time elapsed: 00:02:45
                               ETA: 01:06:16

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 55393 steps/s (collection: 1.661s, learning 0.114s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.2738
               Mean surrogate loss: 0.0209
                 Mean entropy loss: 28.8861
                       Mean reward: 16.38
               Mean episode length: 243.07
    Episode_Reward/reaching_object: 0.5169
    Episode_Reward/rotating_object: 3.0195
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.77s
                      Time elapsed: 00:02:47
                               ETA: 01:05:50

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 53113 steps/s (collection: 1.720s, learning 0.131s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.6379
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 28.8933
                       Mean reward: 24.61
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 0.5017
    Episode_Reward/rotating_object: 3.5528
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.85s
                      Time elapsed: 00:02:49
                               ETA: 01:05:27

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 51002 steps/s (collection: 1.809s, learning 0.119s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.6499
               Mean surrogate loss: 0.0049
                 Mean entropy loss: 28.9871
                       Mean reward: 19.95
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 0.5015
    Episode_Reward/rotating_object: 3.7060
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.93s
                      Time elapsed: 00:02:51
                               ETA: 01:05:06

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 45704 steps/s (collection: 2.019s, learning 0.132s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.1968
               Mean surrogate loss: 0.0055
                 Mean entropy loss: 29.0048
                       Mean reward: 22.32
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 0.4843
    Episode_Reward/rotating_object: 3.4674
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.15s
                      Time elapsed: 00:02:53
                               ETA: 01:04:50

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 50137 steps/s (collection: 1.840s, learning 0.121s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.4087
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 29.0165
                       Mean reward: 23.00
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 0.5158
    Episode_Reward/rotating_object: 4.0020
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.96s
                      Time elapsed: 00:02:55
                               ETA: 01:04:31

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 51629 steps/s (collection: 1.721s, learning 0.183s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.8421
               Mean surrogate loss: 0.0036
                 Mean entropy loss: 29.0904
                       Mean reward: 24.05
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.5184
    Episode_Reward/rotating_object: 3.5885
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.90s
                      Time elapsed: 00:02:57
                               ETA: 01:04:11

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 41587 steps/s (collection: 2.106s, learning 0.258s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.4036
               Mean surrogate loss: 0.0051
                 Mean entropy loss: 29.1161
                       Mean reward: 20.52
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 0.4864
    Episode_Reward/rotating_object: 3.5728
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.36s
                      Time elapsed: 00:02:59
                               ETA: 01:04:02

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 41399 steps/s (collection: 2.244s, learning 0.131s)
             Mean action noise std: 1.23
          Mean value_function loss: 5.4330
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 29.1515
                       Mean reward: 21.48
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 0.4907
    Episode_Reward/rotating_object: 3.6455
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.37s
                      Time elapsed: 00:03:01
                               ETA: 01:03:53

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 47853 steps/s (collection: 1.842s, learning 0.212s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.5545
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 29.2075
                       Mean reward: 23.18
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.5175
    Episode_Reward/rotating_object: 3.7092
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.05s
                      Time elapsed: 00:03:03
                               ETA: 01:03:37

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 43719 steps/s (collection: 2.023s, learning 0.226s)
             Mean action noise std: 1.23
          Mean value_function loss: 2.0057
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 29.2826
                       Mean reward: 20.31
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.5045
    Episode_Reward/rotating_object: 3.8523
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.25s
                      Time elapsed: 00:03:06
                               ETA: 01:03:26

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 43474 steps/s (collection: 2.086s, learning 0.176s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.5536
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 29.3035
                       Mean reward: 20.54
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.4860
    Episode_Reward/rotating_object: 3.4060
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.26s
                      Time elapsed: 00:03:08
                               ETA: 01:03:15

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 45627 steps/s (collection: 1.983s, learning 0.172s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.3263
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 29.3675
                       Mean reward: 15.07
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.4712
    Episode_Reward/rotating_object: 3.2079
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.15s
                      Time elapsed: 00:03:10
                               ETA: 01:03:03

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 46337 steps/s (collection: 1.969s, learning 0.152s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.5661
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 29.4368
                       Mean reward: 13.25
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 0.4650
    Episode_Reward/rotating_object: 2.4743
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.12s
                      Time elapsed: 00:03:12
                               ETA: 01:02:50

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 47247 steps/s (collection: 1.940s, learning 0.141s)
             Mean action noise std: 1.25
          Mean value_function loss: 2.5938
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 29.4732
                       Mean reward: 16.36
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.4714
    Episode_Reward/rotating_object: 2.2755
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.08s
                      Time elapsed: 00:03:14
                               ETA: 01:02:36

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 49490 steps/s (collection: 1.894s, learning 0.093s)
             Mean action noise std: 1.25
          Mean value_function loss: 4.8004
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 29.5035
                       Mean reward: 12.07
               Mean episode length: 249.43
    Episode_Reward/reaching_object: 0.4641
    Episode_Reward/rotating_object: 1.9697
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.99s
                      Time elapsed: 00:03:16
                               ETA: 01:02:21

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 55085 steps/s (collection: 1.666s, learning 0.118s)
             Mean action noise std: 1.25
          Mean value_function loss: 5.8708
               Mean surrogate loss: 0.0046
                 Mean entropy loss: 29.5364
                       Mean reward: 21.04
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 0.4503
    Episode_Reward/rotating_object: 2.6442
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.78s
                      Time elapsed: 00:03:18
                               ETA: 01:02:03

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 53648 steps/s (collection: 1.700s, learning 0.133s)
             Mean action noise std: 1.25
          Mean value_function loss: 5.7757
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 29.5486
                       Mean reward: 22.89
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 0.4602
    Episode_Reward/rotating_object: 3.2662
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.83s
                      Time elapsed: 00:03:20
                               ETA: 01:01:46

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 52778 steps/s (collection: 1.716s, learning 0.147s)
             Mean action noise std: 1.25
          Mean value_function loss: 6.8740
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 29.5792
                       Mean reward: 21.74
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.4484
    Episode_Reward/rotating_object: 3.6513
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.86s
                      Time elapsed: 00:03:22
                               ETA: 01:01:30

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 55082 steps/s (collection: 1.663s, learning 0.122s)
             Mean action noise std: 1.26
          Mean value_function loss: 8.0050
               Mean surrogate loss: 0.0039
                 Mean entropy loss: 29.6310
                       Mean reward: 16.38
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.4551
    Episode_Reward/rotating_object: 4.0893
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.78s
                      Time elapsed: 00:03:24
                               ETA: 01:01:13

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 55772 steps/s (collection: 1.677s, learning 0.086s)
             Mean action noise std: 1.26
          Mean value_function loss: 9.9978
               Mean surrogate loss: 0.0095
                 Mean entropy loss: 29.6503
                       Mean reward: 26.62
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.4764
    Episode_Reward/rotating_object: 4.2344
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.76s
                      Time elapsed: 00:03:25
                               ETA: 01:00:56

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 53170 steps/s (collection: 1.750s, learning 0.099s)
             Mean action noise std: 1.26
          Mean value_function loss: 9.9961
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 29.6566
                       Mean reward: 27.01
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.4933
    Episode_Reward/rotating_object: 5.9276
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.85s
                      Time elapsed: 00:03:27
                               ETA: 01:00:40

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 53632 steps/s (collection: 1.734s, learning 0.099s)
             Mean action noise std: 1.26
          Mean value_function loss: 10.3660
               Mean surrogate loss: 0.0102
                 Mean entropy loss: 29.6980
                       Mean reward: 25.73
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 0.4718
    Episode_Reward/rotating_object: 5.0784
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.83s
                      Time elapsed: 00:03:29
                               ETA: 01:00:25

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 51131 steps/s (collection: 1.754s, learning 0.169s)
             Mean action noise std: 1.26
          Mean value_function loss: 9.9338
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 29.7085
                       Mean reward: 25.19
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.4812
    Episode_Reward/rotating_object: 5.3379
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.92s
                      Time elapsed: 00:03:31
                               ETA: 01:00:12

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 53555 steps/s (collection: 1.688s, learning 0.148s)
             Mean action noise std: 1.27
          Mean value_function loss: 10.5230
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 29.7552
                       Mean reward: 42.65
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.4929
    Episode_Reward/rotating_object: 6.5366
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.84s
                      Time elapsed: 00:03:33
                               ETA: 00:59:57

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 52057 steps/s (collection: 1.777s, learning 0.111s)
             Mean action noise std: 1.27
          Mean value_function loss: 9.9642
               Mean surrogate loss: 0.0077
                 Mean entropy loss: 29.8013
                       Mean reward: 40.24
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.4656
    Episode_Reward/rotating_object: 6.8095
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.89s
                      Time elapsed: 00:03:35
                               ETA: 00:59:44

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 52792 steps/s (collection: 1.751s, learning 0.111s)
             Mean action noise std: 1.27
          Mean value_function loss: 8.9016
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 29.8052
                       Mean reward: 42.54
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 0.4869
    Episode_Reward/rotating_object: 7.9194
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.86s
                      Time elapsed: 00:03:37
                               ETA: 00:59:30

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 52764 steps/s (collection: 1.771s, learning 0.092s)
             Mean action noise std: 1.27
          Mean value_function loss: 9.4165
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 29.8119
                       Mean reward: 34.38
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 0.4623
    Episode_Reward/rotating_object: 6.4243
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.86s
                      Time elapsed: 00:03:38
                               ETA: 00:59:17

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 53112 steps/s (collection: 1.734s, learning 0.117s)
             Mean action noise std: 1.27
          Mean value_function loss: 10.2085
               Mean surrogate loss: 0.0152
                 Mean entropy loss: 29.8270
                       Mean reward: 49.34
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.4885
    Episode_Reward/rotating_object: 8.4711
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.85s
                      Time elapsed: 00:03:40
                               ETA: 00:59:04

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 55332 steps/s (collection: 1.689s, learning 0.088s)
             Mean action noise std: 1.27
          Mean value_function loss: 8.6987
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 29.8320
                       Mean reward: 34.34
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.4651
    Episode_Reward/rotating_object: 6.7622
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.78s
                      Time elapsed: 00:03:42
                               ETA: 00:58:50

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 55028 steps/s (collection: 1.654s, learning 0.132s)
             Mean action noise std: 1.27
          Mean value_function loss: 9.1936
               Mean surrogate loss: 0.0071
                 Mean entropy loss: 29.8655
                       Mean reward: 41.93
               Mean episode length: 248.58
    Episode_Reward/reaching_object: 0.4738
    Episode_Reward/rotating_object: 7.8613
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.79s
                      Time elapsed: 00:03:44
                               ETA: 00:58:36

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 53244 steps/s (collection: 1.691s, learning 0.156s)
             Mean action noise std: 1.28
          Mean value_function loss: 9.1637
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 29.8822
                       Mean reward: 31.33
               Mean episode length: 249.76
    Episode_Reward/reaching_object: 0.4374
    Episode_Reward/rotating_object: 6.0978
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.85s
                      Time elapsed: 00:03:46
                               ETA: 00:58:23

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 53972 steps/s (collection: 1.730s, learning 0.092s)
             Mean action noise std: 1.28
          Mean value_function loss: 9.5037
               Mean surrogate loss: 0.0065
                 Mean entropy loss: 29.9076
                       Mean reward: 23.10
               Mean episode length: 247.53
    Episode_Reward/reaching_object: 0.4427
    Episode_Reward/rotating_object: 6.5166
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.82s
                      Time elapsed: 00:03:47
                               ETA: 00:58:11

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 49232 steps/s (collection: 1.908s, learning 0.089s)
             Mean action noise std: 1.28
          Mean value_function loss: 8.8846
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 29.9216
                       Mean reward: 39.73
               Mean episode length: 248.92
    Episode_Reward/reaching_object: 0.4298
    Episode_Reward/rotating_object: 6.2907
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.00s
                      Time elapsed: 00:03:49
                               ETA: 00:58:01

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 49930 steps/s (collection: 1.876s, learning 0.093s)
             Mean action noise std: 1.28
          Mean value_function loss: 9.0861
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 29.9662
                       Mean reward: 31.37
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.4414
    Episode_Reward/rotating_object: 7.2464
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.97s
                      Time elapsed: 00:03:51
                               ETA: 00:57:51

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 43202 steps/s (collection: 2.089s, learning 0.186s)
             Mean action noise std: 1.28
          Mean value_function loss: 9.7140
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 30.0011
                       Mean reward: 37.01
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 0.4461
    Episode_Reward/rotating_object: 7.0718
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.28s
                      Time elapsed: 00:03:54
                               ETA: 00:57:46

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 44523 steps/s (collection: 2.003s, learning 0.205s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.0669
               Mean surrogate loss: 0.0074
                 Mean entropy loss: 30.0314
                       Mean reward: 35.36
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.4475
    Episode_Reward/rotating_object: 6.6686
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.21s
                      Time elapsed: 00:03:56
                               ETA: 00:57:40

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 46999 steps/s (collection: 1.871s, learning 0.220s)
             Mean action noise std: 1.29
          Mean value_function loss: 10.1834
               Mean surrogate loss: 0.0089
                 Mean entropy loss: 30.0393
                       Mean reward: 35.90
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 0.4305
    Episode_Reward/rotating_object: 6.8089
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.09s
                      Time elapsed: 00:03:58
                               ETA: 00:57:32

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 49890 steps/s (collection: 1.871s, learning 0.100s)
             Mean action noise std: 1.29
          Mean value_function loss: 10.4677
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 30.0415
                       Mean reward: 46.53
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 0.4040
    Episode_Reward/rotating_object: 6.2358
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.97s
                      Time elapsed: 00:04:00
                               ETA: 00:57:22

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 52213 steps/s (collection: 1.774s, learning 0.109s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.9118
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 30.0595
                       Mean reward: 30.61
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 0.4122
    Episode_Reward/rotating_object: 6.9888
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.88s
                      Time elapsed: 00:04:02
                               ETA: 00:57:12

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 53639 steps/s (collection: 1.725s, learning 0.108s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.1311
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 30.0847
                       Mean reward: 41.02
               Mean episode length: 236.54
    Episode_Reward/reaching_object: 0.4096
    Episode_Reward/rotating_object: 6.4850
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.83s
                      Time elapsed: 00:04:04
                               ETA: 00:57:01

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 50710 steps/s (collection: 1.805s, learning 0.133s)
             Mean action noise std: 1.29
          Mean value_function loss: 8.3890
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 30.1240
                       Mean reward: 30.87
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 0.4185
    Episode_Reward/rotating_object: 6.5042
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.94s
                      Time elapsed: 00:04:06
                               ETA: 00:56:51

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 42577 steps/s (collection: 2.102s, learning 0.207s)
             Mean action noise std: 1.30
          Mean value_function loss: 9.9959
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 30.1646
                       Mean reward: 34.61
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 0.4354
    Episode_Reward/rotating_object: 7.1098
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.31s
                      Time elapsed: 00:04:08
                               ETA: 00:56:47

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 44202 steps/s (collection: 2.101s, learning 0.123s)
             Mean action noise std: 1.30
          Mean value_function loss: 10.3681
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 30.1984
                       Mean reward: 45.45
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 0.4313
    Episode_Reward/rotating_object: 7.1059
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.22s
                      Time elapsed: 00:04:10
                               ETA: 00:56:42

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 44968 steps/s (collection: 1.992s, learning 0.194s)
             Mean action noise std: 1.30
          Mean value_function loss: 10.7051
               Mean surrogate loss: 0.0047
                 Mean entropy loss: 30.2119
                       Mean reward: 19.73
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 0.4099
    Episode_Reward/rotating_object: 5.5901
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.19s
                      Time elapsed: 00:04:12
                               ETA: 00:56:36

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 43937 steps/s (collection: 2.068s, learning 0.169s)
             Mean action noise std: 1.30
          Mean value_function loss: 11.1656
               Mean surrogate loss: 0.0079
                 Mean entropy loss: 30.2148
                       Mean reward: 33.02
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 0.4198
    Episode_Reward/rotating_object: 7.4701
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.24s
                      Time elapsed: 00:04:15
                               ETA: 00:56:31

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 47125 steps/s (collection: 1.962s, learning 0.125s)
             Mean action noise std: 1.30
          Mean value_function loss: 9.7510
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 30.2193
                       Mean reward: 39.43
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 0.4191
    Episode_Reward/rotating_object: 7.7631
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.09s
                      Time elapsed: 00:04:17
                               ETA: 00:56:24

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 47688 steps/s (collection: 1.964s, learning 0.098s)
             Mean action noise std: 1.30
          Mean value_function loss: 9.5998
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 30.2614
                       Mean reward: 37.26
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 0.4151
    Episode_Reward/rotating_object: 6.8332
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.06s
                      Time elapsed: 00:04:19
                               ETA: 00:56:17

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 28951 steps/s (collection: 3.138s, learning 0.258s)
             Mean action noise std: 1.31
          Mean value_function loss: 10.2798
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 30.3154
                       Mean reward: 46.12
               Mean episode length: 247.08
    Episode_Reward/reaching_object: 0.4338
    Episode_Reward/rotating_object: 7.8076
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 3.40s
                      Time elapsed: 00:04:22
                               ETA: 00:56:27

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 44084 steps/s (collection: 2.122s, learning 0.108s)
             Mean action noise std: 1.31
          Mean value_function loss: 10.1375
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 30.3370
                       Mean reward: 35.32
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 0.4227
    Episode_Reward/rotating_object: 7.9280
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.23s
                      Time elapsed: 00:04:24
                               ETA: 00:56:22

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 43937 steps/s (collection: 2.051s, learning 0.186s)
             Mean action noise std: 1.31
          Mean value_function loss: 11.1645
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 30.3636
                       Mean reward: 37.21
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 0.4431
    Episode_Reward/rotating_object: 8.5506
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.24s
                      Time elapsed: 00:04:27
                               ETA: 00:56:17

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 41711 steps/s (collection: 2.224s, learning 0.133s)
             Mean action noise std: 1.32
          Mean value_function loss: 11.9968
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 30.4096
                       Mean reward: 34.00
               Mean episode length: 242.67
    Episode_Reward/reaching_object: 0.4305
    Episode_Reward/rotating_object: 6.0073
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.36s
                      Time elapsed: 00:04:29
                               ETA: 00:56:14

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 46846 steps/s (collection: 1.998s, learning 0.101s)
             Mean action noise std: 1.32
          Mean value_function loss: 14.0155
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 30.4623
                       Mean reward: 45.49
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 0.4423
    Episode_Reward/rotating_object: 7.3298
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.10s
                      Time elapsed: 00:04:31
                               ETA: 00:56:07

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 46165 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 1.32
          Mean value_function loss: 13.8978
               Mean surrogate loss: 0.0041
                 Mean entropy loss: 30.4979
                       Mean reward: 37.91
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 0.4428
    Episode_Reward/rotating_object: 6.0250
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.13s
                      Time elapsed: 00:04:33
                               ETA: 00:56:01

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 48182 steps/s (collection: 1.921s, learning 0.120s)
             Mean action noise std: 1.32
          Mean value_function loss: 11.4790
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 30.5124
                       Mean reward: 40.60
               Mean episode length: 246.62
    Episode_Reward/reaching_object: 0.4559
    Episode_Reward/rotating_object: 8.0199
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.04s
                      Time elapsed: 00:04:35
                               ETA: 00:55:54

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 46762 steps/s (collection: 1.962s, learning 0.140s)
             Mean action noise std: 1.32
          Mean value_function loss: 11.9727
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 30.5402
                       Mean reward: 34.65
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 0.4460
    Episode_Reward/rotating_object: 6.7890
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.10s
                      Time elapsed: 00:04:37
                               ETA: 00:55:48

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 44545 steps/s (collection: 2.066s, learning 0.141s)
             Mean action noise std: 1.33
          Mean value_function loss: 12.2872
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 30.5700
                       Mean reward: 55.27
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.4621
    Episode_Reward/rotating_object: 8.3895
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.21s
                      Time elapsed: 00:04:40
                               ETA: 00:55:43

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 37392 steps/s (collection: 2.479s, learning 0.150s)
             Mean action noise std: 1.33
          Mean value_function loss: 12.4590
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 30.6006
                       Mean reward: 32.55
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 0.4412
    Episode_Reward/rotating_object: 7.0899
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.63s
                      Time elapsed: 00:04:42
                               ETA: 00:55:43

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 38293 steps/s (collection: 2.331s, learning 0.237s)
             Mean action noise std: 1.33
          Mean value_function loss: 13.2188
               Mean surrogate loss: 0.0041
                 Mean entropy loss: 30.6246
                       Mean reward: 39.27
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 0.4522
    Episode_Reward/rotating_object: 7.9070
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.57s
                      Time elapsed: 00:04:45
                               ETA: 00:55:42

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 30928 steps/s (collection: 2.854s, learning 0.325s)
             Mean action noise std: 1.33
          Mean value_function loss: 14.4133
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 30.6446
                       Mean reward: 46.01
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 0.4380
    Episode_Reward/rotating_object: 7.1939
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 3.18s
                      Time elapsed: 00:04:48
                               ETA: 00:55:49

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 36989 steps/s (collection: 2.451s, learning 0.207s)
             Mean action noise std: 1.33
          Mean value_function loss: 15.3393
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 30.6828
                       Mean reward: 54.96
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 0.4685
    Episode_Reward/rotating_object: 9.9095
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.66s
                      Time elapsed: 00:04:51
                               ETA: 00:55:49

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 39658 steps/s (collection: 2.248s, learning 0.231s)
             Mean action noise std: 1.34
          Mean value_function loss: 18.6444
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 30.7200
                       Mean reward: 40.93
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 0.4733
    Episode_Reward/rotating_object: 8.3920
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.48s
                      Time elapsed: 00:04:53
                               ETA: 00:55:47

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 43864 steps/s (collection: 2.098s, learning 0.143s)
             Mean action noise std: 1.34
          Mean value_function loss: 23.5337
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 30.7491
                       Mean reward: 69.93
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 0.4776
    Episode_Reward/rotating_object: 10.5526
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.24s
                      Time elapsed: 00:04:55
                               ETA: 00:55:43

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 38490 steps/s (collection: 2.359s, learning 0.195s)
             Mean action noise std: 1.34
          Mean value_function loss: 31.1825
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 30.7664
                       Mean reward: 43.28
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.4657
    Episode_Reward/rotating_object: 9.4422
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.55s
                      Time elapsed: 00:04:58
                               ETA: 00:55:42

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 43396 steps/s (collection: 2.058s, learning 0.207s)
             Mean action noise std: 1.34
          Mean value_function loss: 24.3003
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 30.7769
                       Mean reward: 48.49
               Mean episode length: 237.80
    Episode_Reward/reaching_object: 0.4600
    Episode_Reward/rotating_object: 9.7347
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.27s
                      Time elapsed: 00:05:00
                               ETA: 00:55:38

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 46478 steps/s (collection: 1.961s, learning 0.155s)
             Mean action noise std: 1.34
          Mean value_function loss: 19.6903
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 30.8007
                       Mean reward: 46.91
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 0.4739
    Episode_Reward/rotating_object: 10.3701
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.12s
                      Time elapsed: 00:05:02
                               ETA: 00:55:32

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 47370 steps/s (collection: 1.984s, learning 0.091s)
             Mean action noise std: 1.35
          Mean value_function loss: 20.3550
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 30.8393
                       Mean reward: 39.26
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 0.4691
    Episode_Reward/rotating_object: 9.5674
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.08s
                      Time elapsed: 00:05:04
                               ETA: 00:55:26

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 46886 steps/s (collection: 1.888s, learning 0.209s)
             Mean action noise std: 1.35
          Mean value_function loss: 19.9978
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 30.8826
                       Mean reward: 58.42
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.4532
    Episode_Reward/rotating_object: 10.0600
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.10s
                      Time elapsed: 00:05:06
                               ETA: 00:55:20

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 43138 steps/s (collection: 2.168s, learning 0.111s)
             Mean action noise std: 1.35
          Mean value_function loss: 20.3997
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 30.9293
                       Mean reward: 42.69
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 0.4656
    Episode_Reward/rotating_object: 10.1478
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.28s
                      Time elapsed: 00:05:09
                               ETA: 00:55:16

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 49265 steps/s (collection: 1.892s, learning 0.103s)
             Mean action noise std: 1.36
          Mean value_function loss: 22.4898
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 30.9631
                       Mean reward: 57.12
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 0.4320
    Episode_Reward/rotating_object: 8.8569
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.00s
                      Time elapsed: 00:05:11
                               ETA: 00:55:09

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 47738 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 1.36
          Mean value_function loss: 21.6279
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 30.9925
                       Mean reward: 71.90
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 0.4590
    Episode_Reward/rotating_object: 12.1269
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.06s
                      Time elapsed: 00:05:13
                               ETA: 00:55:03

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 42120 steps/s (collection: 2.196s, learning 0.138s)
             Mean action noise std: 1.36
          Mean value_function loss: 21.8903
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.0265
                       Mean reward: 57.58
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 0.4171
    Episode_Reward/rotating_object: 10.1644
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.33s
                      Time elapsed: 00:05:15
                               ETA: 00:55:00

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 37279 steps/s (collection: 2.454s, learning 0.183s)
             Mean action noise std: 1.36
          Mean value_function loss: 24.4159
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 31.0452
                       Mean reward: 53.28
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.4326
    Episode_Reward/rotating_object: 10.6703
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.64s
                      Time elapsed: 00:05:18
                               ETA: 00:55:00

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 51680 steps/s (collection: 1.810s, learning 0.092s)
             Mean action noise std: 1.36
          Mean value_function loss: 21.9130
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 31.0557
                       Mean reward: 46.10
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.4316
    Episode_Reward/rotating_object: 10.4767
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.90s
                      Time elapsed: 00:05:20
                               ETA: 00:54:52

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 54049 steps/s (collection: 1.730s, learning 0.088s)
             Mean action noise std: 1.36
          Mean value_function loss: 24.3723
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 31.0847
                       Mean reward: 80.20
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 0.4309
    Episode_Reward/rotating_object: 11.5390
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.82s
                      Time elapsed: 00:05:21
                               ETA: 00:54:43

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 51485 steps/s (collection: 1.822s, learning 0.087s)
             Mean action noise std: 1.37
          Mean value_function loss: 26.6123
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 31.1067
                       Mean reward: 56.74
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 0.4398
    Episode_Reward/rotating_object: 11.0281
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.91s
                      Time elapsed: 00:05:23
                               ETA: 00:54:36

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 50687 steps/s (collection: 1.838s, learning 0.101s)
             Mean action noise std: 1.37
          Mean value_function loss: 24.4811
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 31.1280
                       Mean reward: 38.36
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.4265
    Episode_Reward/rotating_object: 10.3646
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.94s
                      Time elapsed: 00:05:25
                               ETA: 00:54:29

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 52754 steps/s (collection: 1.757s, learning 0.107s)
             Mean action noise std: 1.37
          Mean value_function loss: 26.1212
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 31.1391
                       Mean reward: 63.80
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 0.4221
    Episode_Reward/rotating_object: 10.8751
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.86s
                      Time elapsed: 00:05:27
                               ETA: 00:54:21

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 51794 steps/s (collection: 1.772s, learning 0.126s)
             Mean action noise std: 1.37
          Mean value_function loss: 26.6366
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 31.1642
                       Mean reward: 59.37
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 0.4115
    Episode_Reward/rotating_object: 10.9711
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.90s
                      Time elapsed: 00:05:29
                               ETA: 00:54:14

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 52969 steps/s (collection: 1.738s, learning 0.118s)
             Mean action noise std: 1.37
          Mean value_function loss: 29.9312
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 31.1935
                       Mean reward: 62.61
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 0.4062
    Episode_Reward/rotating_object: 10.1836
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.86s
                      Time elapsed: 00:05:31
                               ETA: 00:54:07

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 50880 steps/s (collection: 1.843s, learning 0.089s)
             Mean action noise std: 1.38
          Mean value_function loss: 32.1997
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 31.2190
                       Mean reward: 69.82
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 0.4100
    Episode_Reward/rotating_object: 11.5171
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.93s
                      Time elapsed: 00:05:33
                               ETA: 00:54:00

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 52920 steps/s (collection: 1.765s, learning 0.092s)
             Mean action noise std: 1.38
          Mean value_function loss: 30.5355
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 31.2381
                       Mean reward: 57.04
               Mean episode length: 234.28
    Episode_Reward/reaching_object: 0.3953
    Episode_Reward/rotating_object: 11.3286
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.86s
                      Time elapsed: 00:05:35
                               ETA: 00:53:52

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 53314 steps/s (collection: 1.752s, learning 0.092s)
             Mean action noise std: 1.38
          Mean value_function loss: 29.3626
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 31.2458
                       Mean reward: 69.96
               Mean episode length: 223.27
    Episode_Reward/reaching_object: 0.4158
    Episode_Reward/rotating_object: 13.5620
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.84s
                      Time elapsed: 00:05:37
                               ETA: 00:53:45

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 54452 steps/s (collection: 1.717s, learning 0.088s)
             Mean action noise std: 1.38
          Mean value_function loss: 28.5662
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 31.2646
                       Mean reward: 55.85
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 0.4009
    Episode_Reward/rotating_object: 11.6314
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.81s
                      Time elapsed: 00:05:38
                               ETA: 00:53:37

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 52697 steps/s (collection: 1.760s, learning 0.105s)
             Mean action noise std: 1.38
          Mean value_function loss: 27.6947
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 31.2793
                       Mean reward: 70.92
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 0.4157
    Episode_Reward/rotating_object: 12.5598
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.87s
                      Time elapsed: 00:05:40
                               ETA: 00:53:30

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 46712 steps/s (collection: 1.977s, learning 0.127s)
             Mean action noise std: 1.38
          Mean value_function loss: 33.1706
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.2918
                       Mean reward: 61.41
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 0.4180
    Episode_Reward/rotating_object: 12.9419
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.10s
                      Time elapsed: 00:05:42
                               ETA: 00:53:25

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 47871 steps/s (collection: 1.924s, learning 0.129s)
             Mean action noise std: 1.38
          Mean value_function loss: 29.9129
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 31.3035
                       Mean reward: 69.89
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 0.4027
    Episode_Reward/rotating_object: 12.3013
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.05s
                      Time elapsed: 00:05:44
                               ETA: 00:53:20

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 52264 steps/s (collection: 1.767s, learning 0.114s)
             Mean action noise std: 1.38
          Mean value_function loss: 29.4171
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.3199
                       Mean reward: 73.94
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 0.4207
    Episode_Reward/rotating_object: 13.4845
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.88s
                      Time elapsed: 00:05:46
                               ETA: 00:53:13

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 47516 steps/s (collection: 1.858s, learning 0.211s)
             Mean action noise std: 1.39
          Mean value_function loss: 32.1501
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 31.3414
                       Mean reward: 68.32
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 0.4019
    Episode_Reward/rotating_object: 12.3092
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.07s
                      Time elapsed: 00:05:48
                               ETA: 00:53:08

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 52444 steps/s (collection: 1.736s, learning 0.138s)
             Mean action noise std: 1.39
          Mean value_function loss: 34.4786
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 31.3710
                       Mean reward: 85.44
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 0.4236
    Episode_Reward/rotating_object: 16.1972
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.87s
                      Time elapsed: 00:05:50
                               ETA: 00:53:01

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 47613 steps/s (collection: 1.848s, learning 0.217s)
             Mean action noise std: 1.39
          Mean value_function loss: 34.1070
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.3911
                       Mean reward: 48.42
               Mean episode length: 234.10
    Episode_Reward/reaching_object: 0.3860
    Episode_Reward/rotating_object: 10.7953
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.06s
                      Time elapsed: 00:05:52
                               ETA: 00:52:56

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 54121 steps/s (collection: 1.724s, learning 0.093s)
             Mean action noise std: 1.39
          Mean value_function loss: 38.5638
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.4132
                       Mean reward: 79.02
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.4311
    Episode_Reward/rotating_object: 15.0166
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.82s
                      Time elapsed: 00:05:54
                               ETA: 00:52:49

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 52333 steps/s (collection: 1.790s, learning 0.089s)
             Mean action noise std: 1.39
          Mean value_function loss: 37.6030
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 31.4360
                       Mean reward: 68.09
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 0.4280
    Episode_Reward/rotating_object: 14.0038
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.88s
                      Time elapsed: 00:05:56
                               ETA: 00:52:43

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 46748 steps/s (collection: 1.985s, learning 0.118s)
             Mean action noise std: 1.39
          Mean value_function loss: 37.4568
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.4550
                       Mean reward: 63.52
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 0.4028
    Episode_Reward/rotating_object: 13.9672
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.10s
                      Time elapsed: 00:05:58
                               ETA: 00:52:38

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 52094 steps/s (collection: 1.789s, learning 0.098s)
             Mean action noise std: 1.39
          Mean value_function loss: 35.8646
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.4653
                       Mean reward: 70.45
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 0.3943
    Episode_Reward/rotating_object: 10.4301
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.89s
                      Time elapsed: 00:06:00
                               ETA: 00:52:32

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 51470 steps/s (collection: 1.765s, learning 0.145s)
             Mean action noise std: 1.40
          Mean value_function loss: 37.3038
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.4775
                       Mean reward: 74.22
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 0.4117
    Episode_Reward/rotating_object: 13.7381
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.91s
                      Time elapsed: 00:06:02
                               ETA: 00:52:26

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 47226 steps/s (collection: 1.898s, learning 0.183s)
             Mean action noise std: 1.40
          Mean value_function loss: 38.2262
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.4930
                       Mean reward: 70.50
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 0.4291
    Episode_Reward/rotating_object: 14.6948
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.08s
                      Time elapsed: 00:06:04
                               ETA: 00:52:21

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 46700 steps/s (collection: 1.976s, learning 0.129s)
             Mean action noise std: 1.40
          Mean value_function loss: 35.4450
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.5110
                       Mean reward: 65.14
               Mean episode length: 240.28
    Episode_Reward/reaching_object: 0.4218
    Episode_Reward/rotating_object: 13.5133
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.10s
                      Time elapsed: 00:06:06
                               ETA: 00:52:17

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 47844 steps/s (collection: 1.933s, learning 0.122s)
             Mean action noise std: 1.40
          Mean value_function loss: 38.2437
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 31.5279
                       Mean reward: 89.85
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 0.4256
    Episode_Reward/rotating_object: 15.6939
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.05s
                      Time elapsed: 00:06:08
                               ETA: 00:52:12

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 49989 steps/s (collection: 1.877s, learning 0.089s)
             Mean action noise std: 1.40
          Mean value_function loss: 36.3688
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 31.5434
                       Mean reward: 63.17
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 0.4254
    Episode_Reward/rotating_object: 13.9504
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.97s
                      Time elapsed: 00:06:10
                               ETA: 00:52:07

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 52770 steps/s (collection: 1.743s, learning 0.120s)
             Mean action noise std: 1.40
          Mean value_function loss: 40.0905
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 31.5679
                       Mean reward: 63.60
               Mean episode length: 221.37
    Episode_Reward/reaching_object: 0.4020
    Episode_Reward/rotating_object: 15.1451
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.86s
                      Time elapsed: 00:06:12
                               ETA: 00:52:01

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 52972 steps/s (collection: 1.742s, learning 0.114s)
             Mean action noise std: 1.40
          Mean value_function loss: 37.2035
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 31.5902
                       Mean reward: 68.68
               Mean episode length: 232.64
    Episode_Reward/reaching_object: 0.4215
    Episode_Reward/rotating_object: 14.1289
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.86s
                      Time elapsed: 00:06:14
                               ETA: 00:51:54

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 53498 steps/s (collection: 1.736s, learning 0.102s)
             Mean action noise std: 1.41
          Mean value_function loss: 42.0418
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 31.5998
                       Mean reward: 68.80
               Mean episode length: 224.45
    Episode_Reward/reaching_object: 0.4337
    Episode_Reward/rotating_object: 15.9630
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.84s
                      Time elapsed: 00:06:16
                               ETA: 00:51:48

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 52492 steps/s (collection: 1.756s, learning 0.117s)
             Mean action noise std: 1.41
          Mean value_function loss: 40.2661
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 31.6066
                       Mean reward: 74.73
               Mean episode length: 222.17
    Episode_Reward/reaching_object: 0.4266
    Episode_Reward/rotating_object: 16.4294
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 10.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.87s
                      Time elapsed: 00:06:17
                               ETA: 00:51:42

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 52330 steps/s (collection: 1.735s, learning 0.144s)
             Mean action noise std: 1.41
          Mean value_function loss: 44.4879
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 31.6229
                       Mean reward: 84.78
               Mean episode length: 226.37
    Episode_Reward/reaching_object: 0.4223
    Episode_Reward/rotating_object: 16.6997
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 1.88s
                      Time elapsed: 00:06:19
                               ETA: 00:51:36

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 51750 steps/s (collection: 1.772s, learning 0.128s)
             Mean action noise std: 1.41
          Mean value_function loss: 40.9242
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 31.6409
                       Mean reward: 89.16
               Mean episode length: 222.85
    Episode_Reward/reaching_object: 0.4320
    Episode_Reward/rotating_object: 17.7461
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.90s
                      Time elapsed: 00:06:21
                               ETA: 00:51:30

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 54290 steps/s (collection: 1.706s, learning 0.105s)
             Mean action noise std: 1.41
          Mean value_function loss: 38.4984
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 31.6619
                       Mean reward: 71.34
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 0.4289
    Episode_Reward/rotating_object: 16.2685
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.81s
                      Time elapsed: 00:06:23
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 51576 steps/s (collection: 1.807s, learning 0.099s)
             Mean action noise std: 1.41
          Mean value_function loss: 45.6393
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 31.6835
                       Mean reward: 81.85
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 0.4145
    Episode_Reward/rotating_object: 15.6874
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.91s
                      Time elapsed: 00:06:25
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 51883 steps/s (collection: 1.773s, learning 0.122s)
             Mean action noise std: 1.41
          Mean value_function loss: 42.5739
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 31.7095
                       Mean reward: 69.98
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 0.4477
    Episode_Reward/rotating_object: 16.0495
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.89s
                      Time elapsed: 00:06:27
                               ETA: 00:51:13

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 50466 steps/s (collection: 1.849s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 47.5310
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 31.7284
                       Mean reward: 90.76
               Mean episode length: 227.51
    Episode_Reward/reaching_object: 0.4498
    Episode_Reward/rotating_object: 18.5333
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.95s
                      Time elapsed: 00:06:29
                               ETA: 00:51:08

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 52823 steps/s (collection: 1.754s, learning 0.107s)
             Mean action noise std: 1.42
          Mean value_function loss: 49.6197
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 31.7469
                       Mean reward: 86.24
               Mean episode length: 222.76
    Episode_Reward/reaching_object: 0.4187
    Episode_Reward/rotating_object: 16.3226
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.86s
                      Time elapsed: 00:06:31
                               ETA: 00:51:02

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 48877 steps/s (collection: 1.843s, learning 0.169s)
             Mean action noise std: 1.42
          Mean value_function loss: 51.9511
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 31.7644
                       Mean reward: 79.04
               Mean episode length: 217.79
    Episode_Reward/reaching_object: 0.4226
    Episode_Reward/rotating_object: 17.0029
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.01s
                      Time elapsed: 00:06:33
                               ETA: 00:50:57

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 52634 steps/s (collection: 1.760s, learning 0.108s)
             Mean action noise std: 1.42
          Mean value_function loss: 57.9544
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 31.7818
                       Mean reward: 109.32
               Mean episode length: 222.04
    Episode_Reward/reaching_object: 0.4419
    Episode_Reward/rotating_object: 19.1571
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.87s
                      Time elapsed: 00:06:35
                               ETA: 00:50:52

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 52184 steps/s (collection: 1.733s, learning 0.151s)
             Mean action noise std: 1.42
          Mean value_function loss: 56.7024
               Mean surrogate loss: 0.0093
                 Mean entropy loss: 31.7932
                       Mean reward: 72.65
               Mean episode length: 215.35
    Episode_Reward/reaching_object: 0.3963
    Episode_Reward/rotating_object: 15.1361
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 10.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.88s
                      Time elapsed: 00:06:36
                               ETA: 00:50:46

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 53748 steps/s (collection: 1.730s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 51.5953
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 31.7947
                       Mean reward: 82.27
               Mean episode length: 223.44
    Episode_Reward/reaching_object: 0.4203
    Episode_Reward/rotating_object: 16.7090
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.83s
                      Time elapsed: 00:06:38
                               ETA: 00:50:41

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 54145 steps/s (collection: 1.716s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 53.5011
               Mean surrogate loss: 0.0110
                 Mean entropy loss: 31.7991
                       Mean reward: 113.16
               Mean episode length: 228.67
    Episode_Reward/reaching_object: 0.4402
    Episode_Reward/rotating_object: 17.5790
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.82s
                      Time elapsed: 00:06:40
                               ETA: 00:50:35

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 53581 steps/s (collection: 1.743s, learning 0.092s)
             Mean action noise std: 1.42
          Mean value_function loss: 57.7404
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 31.8012
                       Mean reward: 95.41
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 0.3945
    Episode_Reward/rotating_object: 15.3066
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.83s
                      Time elapsed: 00:06:42
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 52106 steps/s (collection: 1.796s, learning 0.090s)
             Mean action noise std: 1.42
          Mean value_function loss: 59.1708
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.8113
                       Mean reward: 109.79
               Mean episode length: 220.17
    Episode_Reward/reaching_object: 0.4308
    Episode_Reward/rotating_object: 19.2494
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.89s
                      Time elapsed: 00:06:44
                               ETA: 00:50:24

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 51886 steps/s (collection: 1.806s, learning 0.088s)
             Mean action noise std: 1.42
          Mean value_function loss: 53.8589
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 31.8322
                       Mean reward: 90.49
               Mean episode length: 217.02
    Episode_Reward/reaching_object: 0.4596
    Episode_Reward/rotating_object: 20.2070
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.89s
                      Time elapsed: 00:06:46
                               ETA: 00:50:18

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 51954 steps/s (collection: 1.754s, learning 0.139s)
             Mean action noise std: 1.43
          Mean value_function loss: 56.3087
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.8548
                       Mean reward: 106.83
               Mean episode length: 219.18
    Episode_Reward/reaching_object: 0.4414
    Episode_Reward/rotating_object: 19.7188
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 1.89s
                      Time elapsed: 00:06:48
                               ETA: 00:50:13

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 48791 steps/s (collection: 1.902s, learning 0.113s)
             Mean action noise std: 1.43
          Mean value_function loss: 54.1415
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 31.8780
                       Mean reward: 110.60
               Mean episode length: 223.86
    Episode_Reward/reaching_object: 0.4441
    Episode_Reward/rotating_object: 18.8316
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.01s
                      Time elapsed: 00:06:50
                               ETA: 00:50:09

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 48888 steps/s (collection: 1.902s, learning 0.109s)
             Mean action noise std: 1.43
          Mean value_function loss: 55.9571
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.8960
                       Mean reward: 79.97
               Mean episode length: 213.45
    Episode_Reward/reaching_object: 0.4259
    Episode_Reward/rotating_object: 18.6183
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.01s
                      Time elapsed: 00:06:52
                               ETA: 00:50:05

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 52006 steps/s (collection: 1.749s, learning 0.142s)
             Mean action noise std: 1.43
          Mean value_function loss: 55.8478
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.9125
                       Mean reward: 96.45
               Mean episode length: 223.14
    Episode_Reward/reaching_object: 0.4672
    Episode_Reward/rotating_object: 21.1820
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 1.89s
                      Time elapsed: 00:06:53
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 54164 steps/s (collection: 1.695s, learning 0.120s)
             Mean action noise std: 1.43
          Mean value_function loss: 55.3153
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.9273
                       Mean reward: 130.95
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 0.4612
    Episode_Reward/rotating_object: 22.1566
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 1.81s
                      Time elapsed: 00:06:55
                               ETA: 00:49:54

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 50821 steps/s (collection: 1.841s, learning 0.094s)
             Mean action noise std: 1.43
          Mean value_function loss: 59.8669
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 31.9385
                       Mean reward: 95.36
               Mean episode length: 220.37
    Episode_Reward/reaching_object: 0.4245
    Episode_Reward/rotating_object: 18.5813
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.93s
                      Time elapsed: 00:06:57
                               ETA: 00:49:50

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 50464 steps/s (collection: 1.815s, learning 0.133s)
             Mean action noise std: 1.43
          Mean value_function loss: 58.6170
               Mean surrogate loss: 0.0059
                 Mean entropy loss: 31.9476
                       Mean reward: 110.93
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 0.4534
    Episode_Reward/rotating_object: 20.8841
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.95s
                      Time elapsed: 00:06:59
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 53337 steps/s (collection: 1.744s, learning 0.099s)
             Mean action noise std: 1.43
          Mean value_function loss: 52.4132
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 31.9514
                       Mean reward: 68.45
               Mean episode length: 208.37
    Episode_Reward/reaching_object: 0.4291
    Episode_Reward/rotating_object: 19.7251
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 1.84s
                      Time elapsed: 00:07:01
                               ETA: 00:49:40

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 52736 steps/s (collection: 1.744s, learning 0.120s)
             Mean action noise std: 1.43
          Mean value_function loss: 55.3913
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 31.9588
                       Mean reward: 125.41
               Mean episode length: 222.48
    Episode_Reward/reaching_object: 0.4678
    Episode_Reward/rotating_object: 25.3890
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.86s
                      Time elapsed: 00:07:03
                               ETA: 00:49:35

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 52532 steps/s (collection: 1.768s, learning 0.103s)
             Mean action noise std: 1.44
          Mean value_function loss: 59.5711
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 31.9711
                       Mean reward: 97.06
               Mean episode length: 220.68
    Episode_Reward/reaching_object: 0.4482
    Episode_Reward/rotating_object: 21.4881
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.87s
                      Time elapsed: 00:07:05
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 53140 steps/s (collection: 1.759s, learning 0.091s)
             Mean action noise std: 1.44
          Mean value_function loss: 60.8766
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 31.9877
                       Mean reward: 112.08
               Mean episode length: 225.01
    Episode_Reward/reaching_object: 0.4730
    Episode_Reward/rotating_object: 24.0600
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.85s
                      Time elapsed: 00:07:07
                               ETA: 00:49:24

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 50222 steps/s (collection: 1.758s, learning 0.199s)
             Mean action noise std: 1.44
          Mean value_function loss: 55.9249
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 31.9964
                       Mean reward: 137.17
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 0.4803
    Episode_Reward/rotating_object: 25.4521
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.96s
                      Time elapsed: 00:07:09
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 50392 steps/s (collection: 1.778s, learning 0.173s)
             Mean action noise std: 1.44
          Mean value_function loss: 61.8354
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.0089
                       Mean reward: 126.15
               Mean episode length: 223.09
    Episode_Reward/reaching_object: 0.4736
    Episode_Reward/rotating_object: 24.9113
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.95s
                      Time elapsed: 00:07:11
                               ETA: 00:49:16

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 51795 steps/s (collection: 1.707s, learning 0.191s)
             Mean action noise std: 1.44
          Mean value_function loss: 61.6214
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 32.0181
                       Mean reward: 113.17
               Mean episode length: 223.98
    Episode_Reward/reaching_object: 0.4644
    Episode_Reward/rotating_object: 24.8596
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.90s
                      Time elapsed: 00:07:12
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 53762 steps/s (collection: 1.719s, learning 0.109s)
             Mean action noise std: 1.44
          Mean value_function loss: 59.1893
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.0242
                       Mean reward: 159.95
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 0.4926
    Episode_Reward/rotating_object: 28.1438
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.83s
                      Time elapsed: 00:07:14
                               ETA: 00:49:06

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 53388 steps/s (collection: 1.737s, learning 0.104s)
             Mean action noise std: 1.44
          Mean value_function loss: 67.6866
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.0336
                       Mean reward: 142.55
               Mean episode length: 223.73
    Episode_Reward/reaching_object: 0.4647
    Episode_Reward/rotating_object: 23.7870
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.84s
                      Time elapsed: 00:07:16
                               ETA: 00:49:01

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 54023 steps/s (collection: 1.730s, learning 0.090s)
             Mean action noise std: 1.44
          Mean value_function loss: 68.5884
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 32.0424
                       Mean reward: 148.08
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 0.4941
    Episode_Reward/rotating_object: 27.5549
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.82s
                      Time elapsed: 00:07:18
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 54388 steps/s (collection: 1.720s, learning 0.088s)
             Mean action noise std: 1.44
          Mean value_function loss: 59.0010
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.0590
                       Mean reward: 128.73
               Mean episode length: 227.66
    Episode_Reward/reaching_object: 0.5011
    Episode_Reward/rotating_object: 27.5416
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.81s
                      Time elapsed: 00:07:20
                               ETA: 00:48:51

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 51426 steps/s (collection: 1.765s, learning 0.146s)
             Mean action noise std: 1.44
          Mean value_function loss: 61.6217
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.0715
                       Mean reward: 120.88
               Mean episode length: 220.50
    Episode_Reward/reaching_object: 0.4866
    Episode_Reward/rotating_object: 27.7266
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.91s
                      Time elapsed: 00:07:22
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 51337 steps/s (collection: 1.802s, learning 0.113s)
             Mean action noise std: 1.45
          Mean value_function loss: 65.7950
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.0800
                       Mean reward: 131.09
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 0.5079
    Episode_Reward/rotating_object: 29.5301
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.91s
                      Time elapsed: 00:07:24
                               ETA: 00:48:42

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 50732 steps/s (collection: 1.764s, learning 0.174s)
             Mean action noise std: 1.45
          Mean value_function loss: 67.6924
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.0846
                       Mean reward: 119.66
               Mean episode length: 225.71
    Episode_Reward/reaching_object: 0.5339
    Episode_Reward/rotating_object: 30.6046
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.94s
                      Time elapsed: 00:07:25
                               ETA: 00:48:37

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 51367 steps/s (collection: 1.734s, learning 0.180s)
             Mean action noise std: 1.45
          Mean value_function loss: 74.3085
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.0885
                       Mean reward: 120.90
               Mean episode length: 221.57
    Episode_Reward/reaching_object: 0.4921
    Episode_Reward/rotating_object: 28.0659
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.91s
                      Time elapsed: 00:07:27
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 52504 steps/s (collection: 1.724s, learning 0.149s)
             Mean action noise std: 1.45
          Mean value_function loss: 74.5433
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.0956
                       Mean reward: 146.00
               Mean episode length: 223.21
    Episode_Reward/reaching_object: 0.5133
    Episode_Reward/rotating_object: 27.6027
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.87s
                      Time elapsed: 00:07:29
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 53174 steps/s (collection: 1.748s, learning 0.101s)
             Mean action noise std: 1.45
          Mean value_function loss: 68.7140
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.1052
                       Mean reward: 140.53
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 0.5334
    Episode_Reward/rotating_object: 33.1236
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.85s
                      Time elapsed: 00:07:31
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 52777 steps/s (collection: 1.748s, learning 0.115s)
             Mean action noise std: 1.45
          Mean value_function loss: 62.2156
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 32.1145
                       Mean reward: 188.02
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 0.5277
    Episode_Reward/rotating_object: 32.4469
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.86s
                      Time elapsed: 00:07:33
                               ETA: 00:48:19

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 52711 steps/s (collection: 1.751s, learning 0.114s)
             Mean action noise std: 1.45
          Mean value_function loss: 68.6233
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.1221
                       Mean reward: 174.78
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 0.5235
    Episode_Reward/rotating_object: 31.8188
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.86s
                      Time elapsed: 00:07:35
                               ETA: 00:48:15

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 52798 steps/s (collection: 1.748s, learning 0.114s)
             Mean action noise std: 1.45
          Mean value_function loss: 75.7045
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 32.1299
                       Mean reward: 135.85
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 0.5285
    Episode_Reward/rotating_object: 31.4972
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.86s
                      Time elapsed: 00:07:37
                               ETA: 00:48:10

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 50549 steps/s (collection: 1.830s, learning 0.115s)
             Mean action noise std: 1.45
          Mean value_function loss: 65.7252
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.1374
                       Mean reward: 182.99
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 0.5423
    Episode_Reward/rotating_object: 37.5255
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 1.94s
                      Time elapsed: 00:07:39
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 53859 steps/s (collection: 1.702s, learning 0.123s)
             Mean action noise std: 1.45
          Mean value_function loss: 73.6939
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 32.1460
                       Mean reward: 150.40
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 0.5202
    Episode_Reward/rotating_object: 32.5845
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 1.83s
                      Time elapsed: 00:07:40
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 54920 steps/s (collection: 1.690s, learning 0.100s)
             Mean action noise std: 1.45
          Mean value_function loss: 72.1595
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 32.1558
                       Mean reward: 173.22
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 0.5470
    Episode_Reward/rotating_object: 35.8777
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.79s
                      Time elapsed: 00:07:42
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 54329 steps/s (collection: 1.712s, learning 0.097s)
             Mean action noise std: 1.45
          Mean value_function loss: 75.3303
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 32.1689
                       Mean reward: 152.37
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 0.5356
    Episode_Reward/rotating_object: 35.5588
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.81s
                      Time elapsed: 00:07:44
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 54155 steps/s (collection: 1.702s, learning 0.113s)
             Mean action noise std: 1.45
          Mean value_function loss: 84.1468
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 32.1802
                       Mean reward: 166.65
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 0.5145
    Episode_Reward/rotating_object: 36.5039
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.82s
                      Time elapsed: 00:07:46
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 52154 steps/s (collection: 1.788s, learning 0.097s)
             Mean action noise std: 1.45
          Mean value_function loss: 89.2869
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 32.1882
                       Mean reward: 183.58
               Mean episode length: 236.98
    Episode_Reward/reaching_object: 0.5417
    Episode_Reward/rotating_object: 37.6089
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.88s
                      Time elapsed: 00:07:48
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 51577 steps/s (collection: 1.785s, learning 0.121s)
             Mean action noise std: 1.46
          Mean value_function loss: 89.2233
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 32.1978
                       Mean reward: 182.59
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 0.5339
    Episode_Reward/rotating_object: 35.8473
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.91s
                      Time elapsed: 00:07:50
                               ETA: 00:47:38

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 53112 steps/s (collection: 1.735s, learning 0.116s)
             Mean action noise std: 1.46
          Mean value_function loss: 80.9833
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.2058
                       Mean reward: 190.77
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 0.5238
    Episode_Reward/rotating_object: 37.2087
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 1.85s
                      Time elapsed: 00:07:52
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 52131 steps/s (collection: 1.790s, learning 0.096s)
             Mean action noise std: 1.46
          Mean value_function loss: 78.0019
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.2165
                       Mean reward: 180.64
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 0.5336
    Episode_Reward/rotating_object: 37.8032
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 1.89s
                      Time elapsed: 00:07:53
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 51767 steps/s (collection: 1.805s, learning 0.094s)
             Mean action noise std: 1.46
          Mean value_function loss: 83.6238
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 32.2290
                       Mean reward: 198.35
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 0.5436
    Episode_Reward/rotating_object: 37.0432
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.90s
                      Time elapsed: 00:07:55
                               ETA: 00:47:26

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 52859 steps/s (collection: 1.737s, learning 0.123s)
             Mean action noise std: 1.46
          Mean value_function loss: 72.6864
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.2383
                       Mean reward: 167.80
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 0.5213
    Episode_Reward/rotating_object: 35.1901
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.86s
                      Time elapsed: 00:07:57
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 51436 steps/s (collection: 1.810s, learning 0.102s)
             Mean action noise std: 1.46
          Mean value_function loss: 73.0101
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 32.2483
                       Mean reward: 175.61
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 0.5274
    Episode_Reward/rotating_object: 34.6866
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 1.91s
                      Time elapsed: 00:07:59
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 50460 steps/s (collection: 1.851s, learning 0.098s)
             Mean action noise std: 1.46
          Mean value_function loss: 75.7130
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 32.2543
                       Mean reward: 167.57
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 0.5295
    Episode_Reward/rotating_object: 38.5241
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.95s
                      Time elapsed: 00:08:01
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 48505 steps/s (collection: 1.865s, learning 0.161s)
             Mean action noise std: 1.46
          Mean value_function loss: 83.5968
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 32.2615
                       Mean reward: 204.03
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 0.5295
    Episode_Reward/rotating_object: 38.0921
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.03s
                      Time elapsed: 00:08:03
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 44584 steps/s (collection: 2.046s, learning 0.159s)
             Mean action noise std: 1.46
          Mean value_function loss: 89.6795
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.2691
                       Mean reward: 205.22
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 0.5517
    Episode_Reward/rotating_object: 39.5233
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.20s
                      Time elapsed: 00:08:05
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 40062 steps/s (collection: 2.219s, learning 0.234s)
             Mean action noise std: 1.46
          Mean value_function loss: 90.5015
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.2789
                       Mean reward: 207.21
               Mean episode length: 229.76
    Episode_Reward/reaching_object: 0.5246
    Episode_Reward/rotating_object: 36.7705
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.45s
                      Time elapsed: 00:08:08
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 39322 steps/s (collection: 2.255s, learning 0.245s)
             Mean action noise std: 1.46
          Mean value_function loss: 95.7200
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.2856
                       Mean reward: 197.29
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 0.5165
    Episode_Reward/rotating_object: 37.2374
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.50s
                      Time elapsed: 00:08:10
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 36823 steps/s (collection: 2.475s, learning 0.195s)
             Mean action noise std: 1.46
          Mean value_function loss: 97.8790
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.2921
                       Mean reward: 193.40
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 0.5267
    Episode_Reward/rotating_object: 37.4617
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.67s
                      Time elapsed: 00:08:13
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 39164 steps/s (collection: 2.412s, learning 0.098s)
             Mean action noise std: 1.46
          Mean value_function loss: 90.5261
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.2986
                       Mean reward: 214.17
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 0.5372
    Episode_Reward/rotating_object: 41.7424
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.51s
                      Time elapsed: 00:08:15
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 45561 steps/s (collection: 2.010s, learning 0.148s)
             Mean action noise std: 1.47
          Mean value_function loss: 83.3118
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 32.3055
                       Mean reward: 217.48
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 0.5524
    Episode_Reward/rotating_object: 43.3219
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.16s
                      Time elapsed: 00:08:18
                               ETA: 00:47:04

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 43991 steps/s (collection: 2.112s, learning 0.123s)
             Mean action noise std: 1.47
          Mean value_function loss: 88.2166
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 32.3133
                       Mean reward: 232.42
               Mean episode length: 228.01
    Episode_Reward/reaching_object: 0.5349
    Episode_Reward/rotating_object: 44.6406
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.23s
                      Time elapsed: 00:08:20
                               ETA: 00:47:02

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 49949 steps/s (collection: 1.800s, learning 0.168s)
             Mean action noise std: 1.47
          Mean value_function loss: 90.1132
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.3240
                       Mean reward: 236.38
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 0.5624
    Episode_Reward/rotating_object: 47.3065
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.97s
                      Time elapsed: 00:08:22
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 44852 steps/s (collection: 2.057s, learning 0.135s)
             Mean action noise std: 1.47
          Mean value_function loss: 86.6204
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 32.3366
                       Mean reward: 240.18
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 0.5413
    Episode_Reward/rotating_object: 44.5421
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.19s
                      Time elapsed: 00:08:24
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 48483 steps/s (collection: 1.900s, learning 0.127s)
             Mean action noise std: 1.47
          Mean value_function loss: 85.8020
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 32.3405
                       Mean reward: 228.65
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 0.5331
    Episode_Reward/rotating_object: 42.3316
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.03s
                      Time elapsed: 00:08:26
                               ETA: 00:46:53

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 52150 steps/s (collection: 1.792s, learning 0.093s)
             Mean action noise std: 1.47
          Mean value_function loss: 83.6180
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 32.3418
                       Mean reward: 249.21
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 0.5431
    Episode_Reward/rotating_object: 45.4721
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.88s
                      Time elapsed: 00:08:28
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 49228 steps/s (collection: 1.789s, learning 0.208s)
             Mean action noise std: 1.47
          Mean value_function loss: 83.4747
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.3493
                       Mean reward: 190.20
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 0.5262
    Episode_Reward/rotating_object: 42.2525
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.00s
                      Time elapsed: 00:08:30
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 50981 steps/s (collection: 1.749s, learning 0.179s)
             Mean action noise std: 1.47
          Mean value_function loss: 81.5283
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 32.3597
                       Mean reward: 227.03
               Mean episode length: 225.03
    Episode_Reward/reaching_object: 0.5448
    Episode_Reward/rotating_object: 47.5089
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.93s
                      Time elapsed: 00:08:32
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 46576 steps/s (collection: 2.015s, learning 0.096s)
             Mean action noise std: 1.47
          Mean value_function loss: 84.2785
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.3655
                       Mean reward: 232.77
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 0.5449
    Episode_Reward/rotating_object: 45.0998
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.11s
                      Time elapsed: 00:08:34
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 43617 steps/s (collection: 2.155s, learning 0.099s)
             Mean action noise std: 1.47
          Mean value_function loss: 85.9379
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.3748
                       Mean reward: 221.47
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 0.5269
    Episode_Reward/rotating_object: 43.5971
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.25s
                      Time elapsed: 00:08:36
                               ETA: 00:46:37

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 52024 steps/s (collection: 1.772s, learning 0.118s)
             Mean action noise std: 1.47
          Mean value_function loss: 93.8901
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.3834
                       Mean reward: 232.49
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 0.5528
    Episode_Reward/rotating_object: 48.3526
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.89s
                      Time elapsed: 00:08:38
                               ETA: 00:46:33

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 52687 steps/s (collection: 1.776s, learning 0.090s)
             Mean action noise std: 1.47
          Mean value_function loss: 120.1910
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.3889
                       Mean reward: 264.09
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 0.5330
    Episode_Reward/rotating_object: 46.4209
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.87s
                      Time elapsed: 00:08:40
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 52283 steps/s (collection: 1.788s, learning 0.092s)
             Mean action noise std: 1.47
          Mean value_function loss: 114.4820
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.3974
                       Mean reward: 242.57
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 0.5257
    Episode_Reward/rotating_object: 45.3286
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 1.88s
                      Time elapsed: 00:08:42
                               ETA: 00:46:25

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 50287 steps/s (collection: 1.821s, learning 0.134s)
             Mean action noise std: 1.47
          Mean value_function loss: 100.2806
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 32.4047
                       Mean reward: 236.03
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 0.5249
    Episode_Reward/rotating_object: 44.9043
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 1.95s
                      Time elapsed: 00:08:44
                               ETA: 00:46:22

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 51245 steps/s (collection: 1.788s, learning 0.130s)
             Mean action noise std: 1.47
          Mean value_function loss: 102.5404
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 32.4079
                       Mean reward: 273.08
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 0.5513
    Episode_Reward/rotating_object: 51.1071
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 1.92s
                      Time elapsed: 00:08:46
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 52297 steps/s (collection: 1.758s, learning 0.122s)
             Mean action noise std: 1.48
          Mean value_function loss: 102.3416
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.4149
                       Mean reward: 234.96
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 0.5567
    Episode_Reward/rotating_object: 47.7881
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 1.88s
                      Time elapsed: 00:08:48
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 51525 steps/s (collection: 1.794s, learning 0.114s)
             Mean action noise std: 1.48
          Mean value_function loss: 110.4604
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.4226
                       Mean reward: 228.58
               Mean episode length: 225.90
    Episode_Reward/reaching_object: 0.5203
    Episode_Reward/rotating_object: 46.7557
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 1.91s
                      Time elapsed: 00:08:49
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 52231 steps/s (collection: 1.790s, learning 0.092s)
             Mean action noise std: 1.48
          Mean value_function loss: 103.2191
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 32.4246
                       Mean reward: 232.98
               Mean episode length: 224.84
    Episode_Reward/reaching_object: 0.5385
    Episode_Reward/rotating_object: 46.0685
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 1.88s
                      Time elapsed: 00:08:51
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 45565 steps/s (collection: 1.971s, learning 0.187s)
             Mean action noise std: 1.48
          Mean value_function loss: 96.8061
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.4272
                       Mean reward: 253.89
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 0.5623
    Episode_Reward/rotating_object: 51.1208
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.16s
                      Time elapsed: 00:08:53
                               ETA: 00:46:04

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 41677 steps/s (collection: 2.180s, learning 0.179s)
             Mean action noise std: 1.48
          Mean value_function loss: 92.1337
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.4348
                       Mean reward: 235.56
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 0.5571
    Episode_Reward/rotating_object: 52.4559
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.36s
                      Time elapsed: 00:08:56
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 51928 steps/s (collection: 1.776s, learning 0.117s)
             Mean action noise std: 1.48
          Mean value_function loss: 93.5934
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 32.4426
                       Mean reward: 235.62
               Mean episode length: 229.07
    Episode_Reward/reaching_object: 0.5532
    Episode_Reward/rotating_object: 48.3588
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.89s
                      Time elapsed: 00:08:58
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 47097 steps/s (collection: 1.965s, learning 0.123s)
             Mean action noise std: 1.48
          Mean value_function loss: 99.9864
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.4524
                       Mean reward: 252.62
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 0.5614
    Episode_Reward/rotating_object: 48.5393
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.09s
                      Time elapsed: 00:09:00
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 45680 steps/s (collection: 1.913s, learning 0.239s)
             Mean action noise std: 1.48
          Mean value_function loss: 107.7229
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 32.4588
                       Mean reward: 229.05
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 0.5619
    Episode_Reward/rotating_object: 50.4351
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.15s
                      Time elapsed: 00:09:02
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 42320 steps/s (collection: 2.192s, learning 0.131s)
             Mean action noise std: 1.48
          Mean value_function loss: 108.8643
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 32.4666
                       Mean reward: 253.59
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 0.5599
    Episode_Reward/rotating_object: 52.3312
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.32s
                      Time elapsed: 00:09:04
                               ETA: 00:45:52

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 41374 steps/s (collection: 2.236s, learning 0.140s)
             Mean action noise std: 1.48
          Mean value_function loss: 108.1292
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 32.4725
                       Mean reward: 291.45
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 0.5580
    Episode_Reward/rotating_object: 55.3815
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.38s
                      Time elapsed: 00:09:07
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 42932 steps/s (collection: 2.105s, learning 0.185s)
             Mean action noise std: 1.48
          Mean value_function loss: 107.5169
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 32.4775
                       Mean reward: 239.58
               Mean episode length: 219.84
    Episode_Reward/reaching_object: 0.5416
    Episode_Reward/rotating_object: 51.2956
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.29s
                      Time elapsed: 00:09:09
                               ETA: 00:45:49

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 47292 steps/s (collection: 1.929s, learning 0.150s)
             Mean action noise std: 1.48
          Mean value_function loss: 102.9314
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 32.4829
                       Mean reward: 270.68
               Mean episode length: 226.85
    Episode_Reward/reaching_object: 0.5431
    Episode_Reward/rotating_object: 53.3448
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.08s
                      Time elapsed: 00:09:11
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 41551 steps/s (collection: 2.185s, learning 0.181s)
             Mean action noise std: 1.48
          Mean value_function loss: 95.5249
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.4887
                       Mean reward: 249.40
               Mean episode length: 225.60
    Episode_Reward/reaching_object: 0.5443
    Episode_Reward/rotating_object: 50.6900
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.37s
                      Time elapsed: 00:09:13
                               ETA: 00:45:45

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 49652 steps/s (collection: 1.840s, learning 0.140s)
             Mean action noise std: 1.48
          Mean value_function loss: 102.2624
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.4976
                       Mean reward: 269.81
               Mean episode length: 225.45
    Episode_Reward/reaching_object: 0.5512
    Episode_Reward/rotating_object: 54.8177
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 1.98s
                      Time elapsed: 00:09:15
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 49779 steps/s (collection: 1.855s, learning 0.120s)
             Mean action noise std: 1.48
          Mean value_function loss: 114.3724
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.5065
                       Mean reward: 299.07
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 0.5396
    Episode_Reward/rotating_object: 54.7071
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.97s
                      Time elapsed: 00:09:17
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 50157 steps/s (collection: 1.845s, learning 0.115s)
             Mean action noise std: 1.48
          Mean value_function loss: 116.3146
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 32.5123
                       Mean reward: 235.13
               Mean episode length: 218.91
    Episode_Reward/reaching_object: 0.5316
    Episode_Reward/rotating_object: 51.7186
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 1.96s
                      Time elapsed: 00:09:19
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 47404 steps/s (collection: 1.938s, learning 0.135s)
             Mean action noise std: 1.48
          Mean value_function loss: 113.1167
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.5136
                       Mean reward: 251.96
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 0.5628
    Episode_Reward/rotating_object: 53.8674
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.07s
                      Time elapsed: 00:09:21
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 48560 steps/s (collection: 1.920s, learning 0.104s)
             Mean action noise std: 1.48
          Mean value_function loss: 97.8357
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 32.5167
                       Mean reward: 280.04
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 0.5599
    Episode_Reward/rotating_object: 55.8172
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.02s
                      Time elapsed: 00:09:23
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 49577 steps/s (collection: 1.856s, learning 0.127s)
             Mean action noise std: 1.49
          Mean value_function loss: 102.2021
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.5246
                       Mean reward: 266.56
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 0.5587
    Episode_Reward/rotating_object: 55.3269
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 1.98s
                      Time elapsed: 00:09:25
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 49940 steps/s (collection: 1.838s, learning 0.131s)
             Mean action noise std: 1.49
          Mean value_function loss: 104.2012
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.5375
                       Mean reward: 266.64
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 0.5528
    Episode_Reward/rotating_object: 53.3212
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 1.97s
                      Time elapsed: 00:09:27
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 48153 steps/s (collection: 1.939s, learning 0.102s)
             Mean action noise std: 1.49
          Mean value_function loss: 101.3459
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.5499
                       Mean reward: 271.76
               Mean episode length: 219.80
    Episode_Reward/reaching_object: 0.5447
    Episode_Reward/rotating_object: 53.9080
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.04s
                      Time elapsed: 00:09:29
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 52983 steps/s (collection: 1.747s, learning 0.108s)
             Mean action noise std: 1.49
          Mean value_function loss: 102.3022
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 32.5557
                       Mean reward: 335.08
               Mean episode length: 229.97
    Episode_Reward/reaching_object: 0.5470
    Episode_Reward/rotating_object: 56.3333
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 1.86s
                      Time elapsed: 00:09:31
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 48263 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 1.49
          Mean value_function loss: 95.9612
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 32.5578
                       Mean reward: 282.98
               Mean episode length: 227.76
    Episode_Reward/reaching_object: 0.5545
    Episode_Reward/rotating_object: 54.0185
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.04s
                      Time elapsed: 00:09:33
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 53456 steps/s (collection: 1.719s, learning 0.120s)
             Mean action noise std: 1.49
          Mean value_function loss: 90.9742
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.5624
                       Mean reward: 297.69
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 0.5636
    Episode_Reward/rotating_object: 57.8981
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 1.84s
                      Time elapsed: 00:09:35
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 49148 steps/s (collection: 1.889s, learning 0.111s)
             Mean action noise std: 1.49
          Mean value_function loss: 97.7912
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.5702
                       Mean reward: 288.75
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 0.5635
    Episode_Reward/rotating_object: 57.2853
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.00s
                      Time elapsed: 00:09:37
                               ETA: 00:45:06

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 52617 steps/s (collection: 1.768s, learning 0.100s)
             Mean action noise std: 1.49
          Mean value_function loss: 108.8326
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.5783
                       Mean reward: 316.95
               Mean episode length: 228.90
    Episode_Reward/reaching_object: 0.5746
    Episode_Reward/rotating_object: 59.9859
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 1.87s
                      Time elapsed: 00:09:39
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 53548 steps/s (collection: 1.717s, learning 0.119s)
             Mean action noise std: 1.49
          Mean value_function loss: 101.2877
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.5833
                       Mean reward: 300.31
               Mean episode length: 221.78
    Episode_Reward/reaching_object: 0.5610
    Episode_Reward/rotating_object: 56.4654
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.84s
                      Time elapsed: 00:09:41
                               ETA: 00:44:59

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 54821 steps/s (collection: 1.704s, learning 0.090s)
             Mean action noise std: 1.49
          Mean value_function loss: 104.7095
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.5880
                       Mean reward: 327.43
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 0.5925
    Episode_Reward/rotating_object: 64.3012
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 1.79s
                      Time elapsed: 00:09:43
                               ETA: 00:44:55

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 52645 steps/s (collection: 1.772s, learning 0.095s)
             Mean action noise std: 1.49
          Mean value_function loss: 109.3533
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.5922
                       Mean reward: 343.94
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 0.5956
    Episode_Reward/rotating_object: 67.4797
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 1.87s
                      Time elapsed: 00:09:45
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 53977 steps/s (collection: 1.724s, learning 0.098s)
             Mean action noise std: 1.49
          Mean value_function loss: 98.0358
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 32.5997
                       Mean reward: 343.68
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 0.5897
    Episode_Reward/rotating_object: 66.5604
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 1.82s
                      Time elapsed: 00:09:46
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 52981 steps/s (collection: 1.758s, learning 0.098s)
             Mean action noise std: 1.49
          Mean value_function loss: 103.9488
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.6044
                       Mean reward: 342.76
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 0.5873
    Episode_Reward/rotating_object: 68.6878
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 1.86s
                      Time elapsed: 00:09:48
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 52755 steps/s (collection: 1.751s, learning 0.113s)
             Mean action noise std: 1.49
          Mean value_function loss: 99.2395
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 32.6155
                       Mean reward: 330.25
               Mean episode length: 226.15
    Episode_Reward/reaching_object: 0.5594
    Episode_Reward/rotating_object: 62.4957
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 1.86s
                      Time elapsed: 00:09:50
                               ETA: 00:44:40

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 53296 steps/s (collection: 1.753s, learning 0.092s)
             Mean action noise std: 1.49
          Mean value_function loss: 99.6697
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 32.6235
                       Mean reward: 319.32
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 0.5772
    Episode_Reward/rotating_object: 65.2411
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 1.84s
                      Time elapsed: 00:09:52
                               ETA: 00:44:36

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 53548 steps/s (collection: 1.748s, learning 0.088s)
             Mean action noise std: 1.49
          Mean value_function loss: 103.1654
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 32.6259
                       Mean reward: 335.99
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 0.5762
    Episode_Reward/rotating_object: 66.4690
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 1.84s
                      Time elapsed: 00:09:54
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 53863 steps/s (collection: 1.733s, learning 0.092s)
             Mean action noise std: 1.49
          Mean value_function loss: 125.7004
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 32.6301
                       Mean reward: 334.14
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 0.5861
    Episode_Reward/rotating_object: 63.4645
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 1.83s
                      Time elapsed: 00:09:56
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 52570 steps/s (collection: 1.757s, learning 0.113s)
             Mean action noise std: 1.50
          Mean value_function loss: 133.8753
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 32.6352
                       Mean reward: 350.67
               Mean episode length: 224.42
    Episode_Reward/reaching_object: 0.5767
    Episode_Reward/rotating_object: 65.4438
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 1.87s
                      Time elapsed: 00:09:57
                               ETA: 00:44:25

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 53220 steps/s (collection: 1.741s, learning 0.106s)
             Mean action noise std: 1.50
          Mean value_function loss: 107.9765
               Mean surrogate loss: 0.0059
                 Mean entropy loss: 32.6378
                       Mean reward: 305.68
               Mean episode length: 222.03
    Episode_Reward/reaching_object: 0.5783
    Episode_Reward/rotating_object: 63.9507
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 1.85s
                      Time elapsed: 00:09:59
                               ETA: 00:44:22

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 52532 steps/s (collection: 1.761s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 86.0614
               Mean surrogate loss: 0.0085
                 Mean entropy loss: 32.6391
                       Mean reward: 338.16
               Mean episode length: 221.86
    Episode_Reward/reaching_object: 0.5963
    Episode_Reward/rotating_object: 67.6672
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 1.87s
                      Time elapsed: 00:10:01
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 52301 steps/s (collection: 1.786s, learning 0.094s)
             Mean action noise std: 1.50
          Mean value_function loss: 72.6701
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 32.6402
                       Mean reward: 354.37
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 0.5876
    Episode_Reward/rotating_object: 66.0161
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 1.88s
                      Time elapsed: 00:10:03
                               ETA: 00:44:15

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 54558 steps/s (collection: 1.685s, learning 0.117s)
             Mean action noise std: 1.50
          Mean value_function loss: 73.9399
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 32.6460
                       Mean reward: 333.27
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 0.5680
    Episode_Reward/rotating_object: 64.0976
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 1.80s
                      Time elapsed: 00:10:05
                               ETA: 00:44:11

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 54499 steps/s (collection: 1.714s, learning 0.090s)
             Mean action noise std: 1.50
          Mean value_function loss: 67.5319
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.6519
                       Mean reward: 392.53
               Mean episode length: 236.74
    Episode_Reward/reaching_object: 0.5912
    Episode_Reward/rotating_object: 68.5061
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 1.80s
                      Time elapsed: 00:10:07
                               ETA: 00:44:07

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 51244 steps/s (collection: 1.775s, learning 0.143s)
             Mean action noise std: 1.50
          Mean value_function loss: 76.6967
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.6574
                       Mean reward: 285.67
               Mean episode length: 220.15
    Episode_Reward/reaching_object: 0.5639
    Episode_Reward/rotating_object: 66.0350
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 1.92s
                      Time elapsed: 00:10:09
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 51915 steps/s (collection: 1.789s, learning 0.104s)
             Mean action noise std: 1.50
          Mean value_function loss: 81.7599
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 32.6626
                       Mean reward: 348.85
               Mean episode length: 230.99
    Episode_Reward/reaching_object: 0.5859
    Episode_Reward/rotating_object: 69.0928
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 1.89s
                      Time elapsed: 00:10:10
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 51396 steps/s (collection: 1.803s, learning 0.110s)
             Mean action noise std: 1.50
          Mean value_function loss: 77.8013
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 32.6653
                       Mean reward: 382.64
               Mean episode length: 223.55
    Episode_Reward/reaching_object: 0.5671
    Episode_Reward/rotating_object: 68.3824
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 1.91s
                      Time elapsed: 00:10:12
                               ETA: 00:43:57

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 51325 steps/s (collection: 1.813s, learning 0.102s)
             Mean action noise std: 1.50
          Mean value_function loss: 79.1830
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.6679
                       Mean reward: 333.54
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 0.5695
    Episode_Reward/rotating_object: 68.8144
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 1.92s
                      Time elapsed: 00:10:14
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 52622 steps/s (collection: 1.760s, learning 0.108s)
             Mean action noise std: 1.50
          Mean value_function loss: 76.9314
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 32.6714
                       Mean reward: 275.69
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 0.5789
    Episode_Reward/rotating_object: 67.7970
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 1.87s
                      Time elapsed: 00:10:16
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 53343 steps/s (collection: 1.724s, learning 0.119s)
             Mean action noise std: 1.50
          Mean value_function loss: 91.2721
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.6726
                       Mean reward: 358.63
               Mean episode length: 229.60
    Episode_Reward/reaching_object: 0.5855
    Episode_Reward/rotating_object: 67.9481
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 1.84s
                      Time elapsed: 00:10:18
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 52614 steps/s (collection: 1.769s, learning 0.100s)
             Mean action noise std: 1.50
          Mean value_function loss: 92.6931
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.6781
                       Mean reward: 276.09
               Mean episode length: 210.60
    Episode_Reward/reaching_object: 0.5718
    Episode_Reward/rotating_object: 63.4765
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 1.87s
                      Time elapsed: 00:10:20
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 54102 steps/s (collection: 1.726s, learning 0.091s)
             Mean action noise std: 1.50
          Mean value_function loss: 113.1618
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 32.6863
                       Mean reward: 336.85
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 0.6119
    Episode_Reward/rotating_object: 71.5711
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 1.82s
                      Time elapsed: 00:10:22
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 52662 steps/s (collection: 1.765s, learning 0.102s)
             Mean action noise std: 1.50
          Mean value_function loss: 118.9811
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 32.6899
                       Mean reward: 359.38
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 0.6089
    Episode_Reward/rotating_object: 70.0719
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 1.87s
                      Time elapsed: 00:10:24
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 52805 steps/s (collection: 1.729s, learning 0.133s)
             Mean action noise std: 1.50
          Mean value_function loss: 92.0614
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 32.6920
                       Mean reward: 370.94
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 0.6114
    Episode_Reward/rotating_object: 71.5666
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 1.86s
                      Time elapsed: 00:10:25
                               ETA: 00:43:33

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 52636 steps/s (collection: 1.745s, learning 0.122s)
             Mean action noise std: 1.50
          Mean value_function loss: 89.0350
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 32.6947
                       Mean reward: 392.64
               Mean episode length: 225.96
    Episode_Reward/reaching_object: 0.6029
    Episode_Reward/rotating_object: 72.1788
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 1.87s
                      Time elapsed: 00:10:27
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 52819 steps/s (collection: 1.770s, learning 0.091s)
             Mean action noise std: 1.50
          Mean value_function loss: 79.5530
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.6983
                       Mean reward: 358.16
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 0.6048
    Episode_Reward/rotating_object: 72.3104
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 1.86s
                      Time elapsed: 00:10:29
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 54074 steps/s (collection: 1.725s, learning 0.093s)
             Mean action noise std: 1.50
          Mean value_function loss: 87.8917
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.7017
                       Mean reward: 342.99
               Mean episode length: 223.17
    Episode_Reward/reaching_object: 0.6076
    Episode_Reward/rotating_object: 73.6873
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 1.82s
                      Time elapsed: 00:10:31
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 53877 steps/s (collection: 1.721s, learning 0.103s)
             Mean action noise std: 1.50
          Mean value_function loss: 94.4736
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.7080
                       Mean reward: 409.30
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 0.6108
    Episode_Reward/rotating_object: 77.3995
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 1.82s
                      Time elapsed: 00:10:33
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 52695 steps/s (collection: 1.753s, learning 0.112s)
             Mean action noise std: 1.50
          Mean value_function loss: 108.9808
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.7140
                       Mean reward: 412.85
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 0.6278
    Episode_Reward/rotating_object: 79.4478
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 1.87s
                      Time elapsed: 00:10:35
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 52720 steps/s (collection: 1.762s, learning 0.102s)
             Mean action noise std: 1.50
          Mean value_function loss: 110.6847
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.7215
                       Mean reward: 388.34
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 0.6093
    Episode_Reward/rotating_object: 77.7930
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 1.86s
                      Time elapsed: 00:10:37
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 51995 steps/s (collection: 1.776s, learning 0.115s)
             Mean action noise std: 1.50
          Mean value_function loss: 105.3313
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 32.7271
                       Mean reward: 384.25
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 0.6153
    Episode_Reward/rotating_object: 75.8243
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 1.89s
                      Time elapsed: 00:10:38
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 52713 steps/s (collection: 1.750s, learning 0.115s)
             Mean action noise std: 1.50
          Mean value_function loss: 111.2590
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 32.7341
                       Mean reward: 400.56
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 0.6268
    Episode_Reward/rotating_object: 80.0991
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 1.86s
                      Time elapsed: 00:10:40
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 52524 steps/s (collection: 1.751s, learning 0.121s)
             Mean action noise std: 1.51
          Mean value_function loss: 126.9628
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 32.7422
                       Mean reward: 388.78
               Mean episode length: 226.21
    Episode_Reward/reaching_object: 0.6243
    Episode_Reward/rotating_object: 77.0820
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 1.87s
                      Time elapsed: 00:10:42
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 54273 steps/s (collection: 1.717s, learning 0.094s)
             Mean action noise std: 1.51
          Mean value_function loss: 114.7491
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.7467
                       Mean reward: 457.27
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 0.6345
    Episode_Reward/rotating_object: 83.5631
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 1.81s
                      Time elapsed: 00:10:44
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 53923 steps/s (collection: 1.732s, learning 0.091s)
             Mean action noise std: 1.51
          Mean value_function loss: 106.7127
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.7517
                       Mean reward: 419.45
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 0.6473
    Episode_Reward/rotating_object: 78.6468
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 1.82s
                      Time elapsed: 00:10:46
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 53297 steps/s (collection: 1.737s, learning 0.108s)
             Mean action noise std: 1.51
          Mean value_function loss: 119.5182
               Mean surrogate loss: 0.0055
                 Mean entropy loss: 32.7589
                       Mean reward: 393.17
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 0.6510
    Episode_Reward/rotating_object: 80.7258
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 1.84s
                      Time elapsed: 00:10:48
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 54298 steps/s (collection: 1.714s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 108.3001
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.7629
                       Mean reward: 408.83
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 0.6619
    Episode_Reward/rotating_object: 81.4996
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 1.81s
                      Time elapsed: 00:10:49
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 53940 steps/s (collection: 1.721s, learning 0.101s)
             Mean action noise std: 1.51
          Mean value_function loss: 112.7291
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.7692
                       Mean reward: 409.69
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 0.6424
    Episode_Reward/rotating_object: 78.9081
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 1.82s
                      Time elapsed: 00:10:51
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 52008 steps/s (collection: 1.766s, learning 0.125s)
             Mean action noise std: 1.51
          Mean value_function loss: 110.1738
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.7786
                       Mean reward: 412.68
               Mean episode length: 218.82
    Episode_Reward/reaching_object: 0.6260
    Episode_Reward/rotating_object: 79.8585
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 1.89s
                      Time elapsed: 00:10:53
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 54176 steps/s (collection: 1.708s, learning 0.107s)
             Mean action noise std: 1.51
          Mean value_function loss: 106.6105
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.7834
                       Mean reward: 424.88
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 0.6614
    Episode_Reward/rotating_object: 82.7129
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 1.81s
                      Time elapsed: 00:10:55
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 53725 steps/s (collection: 1.734s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 101.4306
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.7916
                       Mean reward: 430.28
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 0.6542
    Episode_Reward/rotating_object: 84.9396
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 1.83s
                      Time elapsed: 00:10:57
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 53596 steps/s (collection: 1.735s, learning 0.099s)
             Mean action noise std: 1.51
          Mean value_function loss: 106.5919
               Mean surrogate loss: 0.0073
                 Mean entropy loss: 32.7995
                       Mean reward: 386.36
               Mean episode length: 217.36
    Episode_Reward/reaching_object: 0.6348
    Episode_Reward/rotating_object: 80.7073
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 1.83s
                      Time elapsed: 00:10:59
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 52374 steps/s (collection: 1.778s, learning 0.099s)
             Mean action noise std: 1.51
          Mean value_function loss: 98.5852
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 32.8022
                       Mean reward: 476.53
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 0.6598
    Episode_Reward/rotating_object: 89.2063
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 1.88s
                      Time elapsed: 00:11:00
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 52532 steps/s (collection: 1.770s, learning 0.101s)
             Mean action noise std: 1.51
          Mean value_function loss: 92.9442
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 32.8042
                       Mean reward: 479.00
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 0.6636
    Episode_Reward/rotating_object: 90.0571
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 1.87s
                      Time elapsed: 00:11:02
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 52934 steps/s (collection: 1.732s, learning 0.125s)
             Mean action noise std: 1.51
          Mean value_function loss: 97.9729
               Mean surrogate loss: 0.0037
                 Mean entropy loss: 32.8061
                       Mean reward: 468.46
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 0.6541
    Episode_Reward/rotating_object: 89.2887
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 1.86s
                      Time elapsed: 00:11:04
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 54008 steps/s (collection: 1.723s, learning 0.097s)
             Mean action noise std: 1.51
          Mean value_function loss: 100.2852
               Mean surrogate loss: 0.0076
                 Mean entropy loss: 32.8071
                       Mean reward: 424.23
               Mean episode length: 221.76
    Episode_Reward/reaching_object: 0.6303
    Episode_Reward/rotating_object: 86.9134
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.82s
                      Time elapsed: 00:11:06
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 51939 steps/s (collection: 1.782s, learning 0.110s)
             Mean action noise std: 1.51
          Mean value_function loss: 104.6883
               Mean surrogate loss: 0.0091
                 Mean entropy loss: 32.8074
                       Mean reward: 455.00
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 0.6598
    Episode_Reward/rotating_object: 91.2640
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 1.89s
                      Time elapsed: 00:11:08
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 52657 steps/s (collection: 1.772s, learning 0.095s)
             Mean action noise std: 1.51
          Mean value_function loss: 108.3129
               Mean surrogate loss: 0.0065
                 Mean entropy loss: 32.8076
                       Mean reward: 436.46
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 0.6315
    Episode_Reward/rotating_object: 88.5858
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 1.87s
                      Time elapsed: 00:11:10
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 53079 steps/s (collection: 1.757s, learning 0.095s)
             Mean action noise std: 1.51
          Mean value_function loss: 99.8897
               Mean surrogate loss: 0.0061
                 Mean entropy loss: 32.8077
                       Mean reward: 426.81
               Mean episode length: 223.58
    Episode_Reward/reaching_object: 0.6303
    Episode_Reward/rotating_object: 87.3414
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 1.85s
                      Time elapsed: 00:11:12
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 53123 steps/s (collection: 1.743s, learning 0.108s)
             Mean action noise std: 1.51
          Mean value_function loss: 112.6222
               Mean surrogate loss: 0.0068
                 Mean entropy loss: 32.8079
                       Mean reward: 435.92
               Mean episode length: 216.41
    Episode_Reward/reaching_object: 0.6278
    Episode_Reward/rotating_object: 87.1655
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 1.85s
                      Time elapsed: 00:11:13
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 53399 steps/s (collection: 1.745s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 102.0252
               Mean surrogate loss: 0.0059
                 Mean entropy loss: 32.8082
                       Mean reward: 447.39
               Mean episode length: 223.70
    Episode_Reward/reaching_object: 0.6329
    Episode_Reward/rotating_object: 88.9375
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 1.84s
                      Time elapsed: 00:11:15
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 53392 steps/s (collection: 1.753s, learning 0.088s)
             Mean action noise std: 1.51
          Mean value_function loss: 108.7662
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 32.8086
                       Mean reward: 469.11
               Mean episode length: 225.97
    Episode_Reward/reaching_object: 0.6549
    Episode_Reward/rotating_object: 93.9672
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 1.84s
                      Time elapsed: 00:11:17
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 53467 steps/s (collection: 1.742s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 116.2871
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 32.8115
                       Mean reward: 483.03
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 0.6551
    Episode_Reward/rotating_object: 90.9950
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 1.84s
                      Time elapsed: 00:11:19
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 54085 steps/s (collection: 1.726s, learning 0.092s)
             Mean action noise std: 1.51
          Mean value_function loss: 107.9740
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.8198
                       Mean reward: 434.61
               Mean episode length: 220.16
    Episode_Reward/reaching_object: 0.6422
    Episode_Reward/rotating_object: 89.8369
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 1.82s
                      Time elapsed: 00:11:21
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 52593 steps/s (collection: 1.768s, learning 0.101s)
             Mean action noise std: 1.51
          Mean value_function loss: 106.9264
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.8307
                       Mean reward: 405.45
               Mean episode length: 218.31
    Episode_Reward/reaching_object: 0.6519
    Episode_Reward/rotating_object: 88.8487
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 1.87s
                      Time elapsed: 00:11:23
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 52751 steps/s (collection: 1.773s, learning 0.091s)
             Mean action noise std: 1.51
          Mean value_function loss: 112.1231
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 32.8382
                       Mean reward: 511.68
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 92.7397
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 1.86s
                      Time elapsed: 00:11:25
                               ETA: 00:41:48

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 53001 steps/s (collection: 1.761s, learning 0.094s)
             Mean action noise std: 1.51
          Mean value_function loss: 109.7349
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 32.8382
                       Mean reward: 398.71
               Mean episode length: 216.97
    Episode_Reward/reaching_object: 0.6391
    Episode_Reward/rotating_object: 88.3181
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 1.85s
                      Time elapsed: 00:11:26
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 50979 steps/s (collection: 1.781s, learning 0.147s)
             Mean action noise std: 1.52
          Mean value_function loss: 105.4098
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.8409
                       Mean reward: 441.61
               Mean episode length: 220.34
    Episode_Reward/reaching_object: 0.6247
    Episode_Reward/rotating_object: 84.9988
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 1.93s
                      Time elapsed: 00:11:28
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 52347 steps/s (collection: 1.772s, learning 0.106s)
             Mean action noise std: 1.52
          Mean value_function loss: 108.4766
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.8467
                       Mean reward: 473.84
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 0.6377
    Episode_Reward/rotating_object: 87.0111
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 1.88s
                      Time elapsed: 00:11:30
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 50638 steps/s (collection: 1.773s, learning 0.168s)
             Mean action noise std: 1.52
          Mean value_function loss: 114.6277
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 32.8522
                       Mean reward: 453.85
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 0.6481
    Episode_Reward/rotating_object: 91.4391
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 1.94s
                      Time elapsed: 00:11:32
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 50813 steps/s (collection: 1.834s, learning 0.101s)
             Mean action noise std: 1.52
          Mean value_function loss: 103.1288
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.8600
                       Mean reward: 452.25
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 0.6630
    Episode_Reward/rotating_object: 90.1836
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 1.93s
                      Time elapsed: 00:11:34
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 44570 steps/s (collection: 2.067s, learning 0.139s)
             Mean action noise std: 1.52
          Mean value_function loss: 112.8321
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 32.8691
                       Mean reward: 412.75
               Mean episode length: 217.58
    Episode_Reward/reaching_object: 0.6621
    Episode_Reward/rotating_object: 89.2861
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.21s
                      Time elapsed: 00:11:36
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 48597 steps/s (collection: 1.918s, learning 0.105s)
             Mean action noise std: 1.52
          Mean value_function loss: 102.9159
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.8762
                       Mean reward: 448.53
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 0.6697
    Episode_Reward/rotating_object: 92.0029
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.02s
                      Time elapsed: 00:11:38
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 51476 steps/s (collection: 1.804s, learning 0.106s)
             Mean action noise std: 1.52
          Mean value_function loss: 107.4807
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 32.8834
                       Mean reward: 470.35
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 90.1259
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 1.91s
                      Time elapsed: 00:11:40
                               ETA: 00:41:26

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 51700 steps/s (collection: 1.784s, learning 0.117s)
             Mean action noise std: 1.52
          Mean value_function loss: 95.7338
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 32.8891
                       Mean reward: 468.88
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 0.6823
    Episode_Reward/rotating_object: 94.0159
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 1.90s
                      Time elapsed: 00:11:42
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 50354 steps/s (collection: 1.834s, learning 0.119s)
             Mean action noise std: 1.52
          Mean value_function loss: 98.9292
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.8934
                       Mean reward: 409.53
               Mean episode length: 211.69
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 90.3316
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 1.95s
                      Time elapsed: 00:11:44
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 52041 steps/s (collection: 1.788s, learning 0.101s)
             Mean action noise std: 1.52
          Mean value_function loss: 98.0661
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.8984
                       Mean reward: 494.79
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 0.6743
    Episode_Reward/rotating_object: 95.0623
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 1.89s
                      Time elapsed: 00:11:46
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 19622 steps/s (collection: 4.872s, learning 0.138s)
             Mean action noise std: 1.52
          Mean value_function loss: 108.2539
               Mean surrogate loss: 0.0250
                 Mean entropy loss: 32.9068
                       Mean reward: 499.84
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 95.7255
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.01s
                      Time elapsed: 00:11:51
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14500 steps/s (collection: 6.593s, learning 0.186s)
             Mean action noise std: 1.52
          Mean value_function loss: 105.8624
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 32.9091
                       Mean reward: 491.26
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 0.6734
    Episode_Reward/rotating_object: 96.1295
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.78s
                      Time elapsed: 00:11:58
                               ETA: 00:41:40

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14871 steps/s (collection: 6.429s, learning 0.181s)
             Mean action noise std: 1.52
          Mean value_function loss: 108.0885
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.9119
                       Mean reward: 500.07
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 0.6641
    Episode_Reward/rotating_object: 96.3753
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.61s
                      Time elapsed: 00:12:04
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14685 steps/s (collection: 6.545s, learning 0.149s)
             Mean action noise std: 1.52
          Mean value_function loss: 108.0116
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.9149
                       Mean reward: 487.80
               Mean episode length: 223.85
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 94.2896
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.69s
                      Time elapsed: 00:12:11
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 15039 steps/s (collection: 6.367s, learning 0.169s)
             Mean action noise std: 1.52
          Mean value_function loss: 99.2353
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.9166
                       Mean reward: 501.50
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 0.6760
    Episode_Reward/rotating_object: 98.7269
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.54s
                      Time elapsed: 00:12:18
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14580 steps/s (collection: 6.621s, learning 0.121s)
             Mean action noise std: 1.52
          Mean value_function loss: 96.0061
               Mean surrogate loss: 0.0075
                 Mean entropy loss: 32.9190
                       Mean reward: 577.82
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 0.6894
    Episode_Reward/rotating_object: 104.5717
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.74s
                      Time elapsed: 00:12:24
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 14889 steps/s (collection: 6.465s, learning 0.138s)
             Mean action noise std: 1.52
          Mean value_function loss: 99.4626
               Mean surrogate loss: 0.0048
                 Mean entropy loss: 32.9217
                       Mean reward: 520.89
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 0.6751
    Episode_Reward/rotating_object: 99.6538
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.60s
                      Time elapsed: 00:12:31
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14213 steps/s (collection: 6.700s, learning 0.217s)
             Mean action noise std: 1.52
          Mean value_function loss: 93.2200
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.9259
                       Mean reward: 510.63
               Mean episode length: 228.28
    Episode_Reward/reaching_object: 0.6986
    Episode_Reward/rotating_object: 101.9974
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.92s
                      Time elapsed: 00:12:38
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13147 steps/s (collection: 7.367s, learning 0.110s)
             Mean action noise std: 1.52
          Mean value_function loss: 97.0666
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.9315
                       Mean reward: 493.18
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 0.7105
    Episode_Reward/rotating_object: 103.5006
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.48s
                      Time elapsed: 00:12:45
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 50224 steps/s (collection: 1.831s, learning 0.126s)
             Mean action noise std: 1.52
          Mean value_function loss: 102.3414
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.9350
                       Mean reward: 535.29
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 0.7204
    Episode_Reward/rotating_object: 105.3696
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.96s
                      Time elapsed: 00:12:47
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 46170 steps/s (collection: 2.011s, learning 0.119s)
             Mean action noise std: 1.52
          Mean value_function loss: 94.5020
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 32.9365
                       Mean reward: 534.16
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 109.6233
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.13s
                      Time elapsed: 00:12:49
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 44738 steps/s (collection: 2.012s, learning 0.186s)
             Mean action noise std: 1.52
          Mean value_function loss: 97.7901
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.9412
                       Mean reward: 521.72
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 0.6935
    Episode_Reward/rotating_object: 103.4240
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.20s
                      Time elapsed: 00:12:52
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 44503 steps/s (collection: 2.078s, learning 0.131s)
             Mean action noise std: 1.53
          Mean value_function loss: 90.8140
               Mean surrogate loss: 0.0064
                 Mean entropy loss: 32.9449
                       Mean reward: 558.39
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 0.7186
    Episode_Reward/rotating_object: 108.9677
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.21s
                      Time elapsed: 00:12:54
                               ETA: 00:43:04

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 44956 steps/s (collection: 1.984s, learning 0.203s)
             Mean action noise std: 1.53
          Mean value_function loss: 93.5608
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 32.9493
                       Mean reward: 539.61
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 0.7067
    Episode_Reward/rotating_object: 107.1682
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.19s
                      Time elapsed: 00:12:56
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 39349 steps/s (collection: 2.353s, learning 0.145s)
             Mean action noise std: 1.53
          Mean value_function loss: 96.1577
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 32.9547
                       Mean reward: 542.62
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 108.9360
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.50s
                      Time elapsed: 00:12:59
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 44965 steps/s (collection: 2.001s, learning 0.186s)
             Mean action noise std: 1.53
          Mean value_function loss: 105.6557
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 32.9604
                       Mean reward: 551.83
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 0.7097
    Episode_Reward/rotating_object: 108.3339
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.19s
                      Time elapsed: 00:13:01
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 46278 steps/s (collection: 1.938s, learning 0.186s)
             Mean action noise std: 1.53
          Mean value_function loss: 108.7347
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.9693
                       Mean reward: 531.70
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 0.6867
    Episode_Reward/rotating_object: 107.0476
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.12s
                      Time elapsed: 00:13:03
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 44534 steps/s (collection: 2.004s, learning 0.204s)
             Mean action noise std: 1.53
          Mean value_function loss: 108.2706
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 32.9755
                       Mean reward: 503.55
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 0.6987
    Episode_Reward/rotating_object: 105.9155
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.21s
                      Time elapsed: 00:13:05
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 44231 steps/s (collection: 2.058s, learning 0.164s)
             Mean action noise std: 1.53
          Mean value_function loss: 98.3037
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 32.9809
                       Mean reward: 532.02
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 0.6879
    Episode_Reward/rotating_object: 103.0126
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.22s
                      Time elapsed: 00:13:07
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 45331 steps/s (collection: 2.025s, learning 0.143s)
             Mean action noise std: 1.53
          Mean value_function loss: 99.8434
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.9863
                       Mean reward: 445.78
               Mean episode length: 212.58
    Episode_Reward/reaching_object: 0.6722
    Episode_Reward/rotating_object: 103.3026
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.17s
                      Time elapsed: 00:13:09
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 40046 steps/s (collection: 2.231s, learning 0.224s)
             Mean action noise std: 1.53
          Mean value_function loss: 88.0905
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.9930
                       Mean reward: 542.48
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 0.6943
    Episode_Reward/rotating_object: 108.0746
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.45s
                      Time elapsed: 00:13:12
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 43539 steps/s (collection: 2.139s, learning 0.118s)
             Mean action noise std: 1.53
          Mean value_function loss: 95.3770
               Mean surrogate loss: 0.0068
                 Mean entropy loss: 32.9985
                       Mean reward: 558.55
               Mean episode length: 228.83
    Episode_Reward/reaching_object: 0.6817
    Episode_Reward/rotating_object: 109.2754
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.26s
                      Time elapsed: 00:13:14
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 46887 steps/s (collection: 1.979s, learning 0.118s)
             Mean action noise std: 1.53
          Mean value_function loss: 86.2211
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 33.0000
                       Mean reward: 539.25
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 0.7031
    Episode_Reward/rotating_object: 111.8914
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.10s
                      Time elapsed: 00:13:16
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 43368 steps/s (collection: 2.131s, learning 0.136s)
             Mean action noise std: 1.53
          Mean value_function loss: 99.5698
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.0014
                       Mean reward: 533.00
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 0.6874
    Episode_Reward/rotating_object: 105.0804
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.27s
                      Time elapsed: 00:13:19
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 37803 steps/s (collection: 2.416s, learning 0.184s)
             Mean action noise std: 1.53
          Mean value_function loss: 106.9333
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.0057
                       Mean reward: 506.51
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 0.6989
    Episode_Reward/rotating_object: 107.4843
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.60s
                      Time elapsed: 00:13:21
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 41359 steps/s (collection: 2.219s, learning 0.158s)
             Mean action noise std: 1.53
          Mean value_function loss: 108.3722
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 33.0113
                       Mean reward: 523.60
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 0.6914
    Episode_Reward/rotating_object: 106.1188
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.38s
                      Time elapsed: 00:13:23
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 37605 steps/s (collection: 2.386s, learning 0.228s)
             Mean action noise std: 1.53
          Mean value_function loss: 92.1097
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.0148
                       Mean reward: 540.33
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 0.6864
    Episode_Reward/rotating_object: 107.2598
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.61s
                      Time elapsed: 00:13:26
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 37013 steps/s (collection: 2.445s, learning 0.211s)
             Mean action noise std: 1.53
          Mean value_function loss: 101.5174
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.0210
                       Mean reward: 561.78
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 0.7120
    Episode_Reward/rotating_object: 111.9991
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.66s
                      Time elapsed: 00:13:29
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 38579 steps/s (collection: 2.338s, learning 0.210s)
             Mean action noise std: 1.53
          Mean value_function loss: 86.1469
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.0299
                       Mean reward: 568.32
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 0.7127
    Episode_Reward/rotating_object: 113.6930
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.55s
                      Time elapsed: 00:13:31
                               ETA: 00:42:34

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 46016 steps/s (collection: 1.983s, learning 0.153s)
             Mean action noise std: 1.53
          Mean value_function loss: 83.8713
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 33.0407
                       Mean reward: 578.60
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 0.7181
    Episode_Reward/rotating_object: 111.4541
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.14s
                      Time elapsed: 00:13:33
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 43469 steps/s (collection: 2.123s, learning 0.139s)
             Mean action noise std: 1.54
          Mean value_function loss: 82.0619
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.0445
                       Mean reward: 559.67
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 0.7110
    Episode_Reward/rotating_object: 110.1656
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.26s
                      Time elapsed: 00:13:36
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 44131 steps/s (collection: 2.115s, learning 0.112s)
             Mean action noise std: 1.54
          Mean value_function loss: 92.4663
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 33.0510
                       Mean reward: 588.01
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 0.7301
    Episode_Reward/rotating_object: 115.5863
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.23s
                      Time elapsed: 00:13:38
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 43987 steps/s (collection: 2.092s, learning 0.143s)
             Mean action noise std: 1.54
          Mean value_function loss: 82.1644
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 33.0558
                       Mean reward: 604.03
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 112.8175
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.23s
                      Time elapsed: 00:13:40
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 51415 steps/s (collection: 1.782s, learning 0.130s)
             Mean action noise std: 1.54
          Mean value_function loss: 86.4177
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 33.0574
                       Mean reward: 582.36
               Mean episode length: 240.58
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 113.2737
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.91s
                      Time elapsed: 00:13:42
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 48609 steps/s (collection: 1.871s, learning 0.152s)
             Mean action noise std: 1.54
          Mean value_function loss: 88.2148
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.0586
                       Mean reward: 577.38
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 117.0008
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.02s
                      Time elapsed: 00:13:44
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 48701 steps/s (collection: 1.838s, learning 0.181s)
             Mean action noise std: 1.54
          Mean value_function loss: 103.3261
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 33.0610
                       Mean reward: 556.80
               Mean episode length: 231.74
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 111.2386
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.02s
                      Time elapsed: 00:13:46
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 47894 steps/s (collection: 1.923s, learning 0.130s)
             Mean action noise std: 1.54
          Mean value_function loss: 94.7059
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.0615
                       Mean reward: 591.51
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 119.5844
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.05s
                      Time elapsed: 00:13:48
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 52152 steps/s (collection: 1.736s, learning 0.149s)
             Mean action noise std: 1.54
          Mean value_function loss: 89.4630
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.0615
                       Mean reward: 564.88
               Mean episode length: 232.16
    Episode_Reward/reaching_object: 0.7198
    Episode_Reward/rotating_object: 110.8780
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.88s
                      Time elapsed: 00:13:50
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 52341 steps/s (collection: 1.777s, learning 0.101s)
             Mean action noise std: 1.54
          Mean value_function loss: 94.6343
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 33.0653
                       Mean reward: 597.07
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 115.8971
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.88s
                      Time elapsed: 00:13:52
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 52723 steps/s (collection: 1.736s, learning 0.128s)
             Mean action noise std: 1.54
          Mean value_function loss: 90.7728
               Mean surrogate loss: 0.0072
                 Mean entropy loss: 33.0662
                       Mean reward: 599.05
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 118.8807
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.86s
                      Time elapsed: 00:13:54
                               ETA: 00:42:03

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 49272 steps/s (collection: 1.838s, learning 0.158s)
             Mean action noise std: 1.54
          Mean value_function loss: 89.3714
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 33.0664
                       Mean reward: 560.62
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 0.7429
    Episode_Reward/rotating_object: 112.0899
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.00s
                      Time elapsed: 00:13:56
                               ETA: 00:42:00

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 51875 steps/s (collection: 1.801s, learning 0.094s)
             Mean action noise std: 1.54
          Mean value_function loss: 87.2897
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.0683
                       Mean reward: 566.39
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 0.7188
    Episode_Reward/rotating_object: 113.4605
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.89s
                      Time elapsed: 00:13:58
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 52361 steps/s (collection: 1.792s, learning 0.086s)
             Mean action noise std: 1.54
          Mean value_function loss: 84.7595
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.0717
                       Mean reward: 598.42
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 119.5724
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.88s
                      Time elapsed: 00:14:00
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 52358 steps/s (collection: 1.765s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 76.2338
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 33.0735
                       Mean reward: 615.20
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.7456
    Episode_Reward/rotating_object: 120.5484
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.88s
                      Time elapsed: 00:14:01
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 48122 steps/s (collection: 1.954s, learning 0.089s)
             Mean action noise std: 1.54
          Mean value_function loss: 70.5693
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 33.0744
                       Mean reward: 648.01
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.7605
    Episode_Reward/rotating_object: 123.9084
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.04s
                      Time elapsed: 00:14:03
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 51645 steps/s (collection: 1.785s, learning 0.119s)
             Mean action noise std: 1.54
          Mean value_function loss: 81.9173
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.0779
                       Mean reward: 557.68
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 0.7256
    Episode_Reward/rotating_object: 115.6821
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.90s
                      Time elapsed: 00:14:05
                               ETA: 00:41:44

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 50557 steps/s (collection: 1.830s, learning 0.114s)
             Mean action noise std: 1.54
          Mean value_function loss: 80.1398
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.0833
                       Mean reward: 605.53
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 0.7422
    Episode_Reward/rotating_object: 122.9367
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.94s
                      Time elapsed: 00:14:07
                               ETA: 00:41:41

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 51368 steps/s (collection: 1.818s, learning 0.096s)
             Mean action noise std: 1.54
          Mean value_function loss: 80.0203
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.0907
                       Mean reward: 625.89
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.7395
    Episode_Reward/rotating_object: 121.5266
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.91s
                      Time elapsed: 00:14:09
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 52182 steps/s (collection: 1.785s, learning 0.099s)
             Mean action noise std: 1.54
          Mean value_function loss: 87.1859
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.0997
                       Mean reward: 633.36
               Mean episode length: 242.22
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 118.1269
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.88s
                      Time elapsed: 00:14:11
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 52683 steps/s (collection: 1.767s, learning 0.099s)
             Mean action noise std: 1.54
          Mean value_function loss: 88.1036
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 33.1041
                       Mean reward: 613.84
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 0.7204
    Episode_Reward/rotating_object: 122.7411
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.87s
                      Time elapsed: 00:14:13
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 51715 steps/s (collection: 1.786s, learning 0.115s)
             Mean action noise std: 1.54
          Mean value_function loss: 79.7012
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 33.1102
                       Mean reward: 599.96
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 120.9577
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.90s
                      Time elapsed: 00:14:15
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 53543 steps/s (collection: 1.741s, learning 0.095s)
             Mean action noise std: 1.54
          Mean value_function loss: 86.2632
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.1170
                       Mean reward: 596.24
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 0.7260
    Episode_Reward/rotating_object: 120.3650
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.84s
                      Time elapsed: 00:14:17
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 51148 steps/s (collection: 1.830s, learning 0.092s)
             Mean action noise std: 1.54
          Mean value_function loss: 87.5540
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.1239
                       Mean reward: 588.27
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 121.7553
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 1.92s
                      Time elapsed: 00:14:19
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 51594 steps/s (collection: 1.806s, learning 0.099s)
             Mean action noise std: 1.54
          Mean value_function loss: 89.3079
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 33.1315
                       Mean reward: 594.99
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 0.7376
    Episode_Reward/rotating_object: 118.4775
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.91s
                      Time elapsed: 00:14:21
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 49779 steps/s (collection: 1.863s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 91.6283
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 33.1388
                       Mean reward: 627.34
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 123.0611
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.97s
                      Time elapsed: 00:14:23
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 53639 steps/s (collection: 1.736s, learning 0.097s)
             Mean action noise std: 1.55
          Mean value_function loss: 90.4184
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 33.1452
                       Mean reward: 606.28
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 0.7330
    Episode_Reward/rotating_object: 119.8324
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.83s
                      Time elapsed: 00:14:24
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 49315 steps/s (collection: 1.844s, learning 0.149s)
             Mean action noise std: 1.55
          Mean value_function loss: 92.5364
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.1466
                       Mean reward: 613.71
               Mean episode length: 238.42
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 122.7486
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.99s
                      Time elapsed: 00:14:26
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 51514 steps/s (collection: 1.792s, learning 0.116s)
             Mean action noise std: 1.55
          Mean value_function loss: 83.0910
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.1501
                       Mean reward: 635.49
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 0.7268
    Episode_Reward/rotating_object: 122.8690
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.91s
                      Time elapsed: 00:14:28
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 51755 steps/s (collection: 1.787s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 78.0843
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.1524
                       Mean reward: 613.78
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 0.7227
    Episode_Reward/rotating_object: 123.4716
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.90s
                      Time elapsed: 00:14:30
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 47240 steps/s (collection: 1.970s, learning 0.111s)
             Mean action noise std: 1.55
          Mean value_function loss: 88.5710
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 33.1553
                       Mean reward: 593.78
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 0.7088
    Episode_Reward/rotating_object: 121.9748
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.08s
                      Time elapsed: 00:14:32
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 44182 steps/s (collection: 2.129s, learning 0.096s)
             Mean action noise std: 1.55
          Mean value_function loss: 84.5032
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 33.1601
                       Mean reward: 578.05
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 0.7081
    Episode_Reward/rotating_object: 120.3732
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.22s
                      Time elapsed: 00:14:34
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 41782 steps/s (collection: 2.163s, learning 0.190s)
             Mean action noise std: 1.55
          Mean value_function loss: 83.0431
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 33.1624
                       Mean reward: 647.07
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 0.7289
    Episode_Reward/rotating_object: 127.5048
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.35s
                      Time elapsed: 00:14:37
                               ETA: 00:40:56

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 50056 steps/s (collection: 1.852s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 87.3313
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.1654
                       Mean reward: 626.88
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 0.7087
    Episode_Reward/rotating_object: 125.3885
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.96s
                      Time elapsed: 00:14:39
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 49555 steps/s (collection: 1.862s, learning 0.122s)
             Mean action noise std: 1.55
          Mean value_function loss: 77.0848
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 33.1698
                       Mean reward: 632.23
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.7034
    Episode_Reward/rotating_object: 122.5191
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.98s
                      Time elapsed: 00:14:41
                               ETA: 00:40:50

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 45622 steps/s (collection: 2.030s, learning 0.125s)
             Mean action noise std: 1.55
          Mean value_function loss: 78.1183
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 33.1749
                       Mean reward: 576.43
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 0.7149
    Episode_Reward/rotating_object: 121.9780
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.15s
                      Time elapsed: 00:14:43
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 49438 steps/s (collection: 1.856s, learning 0.133s)
             Mean action noise std: 1.55
          Mean value_function loss: 78.6381
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 33.1803
                       Mean reward: 652.55
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.7361
    Episode_Reward/rotating_object: 127.4754
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.99s
                      Time elapsed: 00:14:45
                               ETA: 00:40:45

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 51047 steps/s (collection: 1.816s, learning 0.110s)
             Mean action noise std: 1.55
          Mean value_function loss: 80.2826
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.1840
                       Mean reward: 618.17
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 122.7891
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.93s
                      Time elapsed: 00:14:47
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 51360 steps/s (collection: 1.806s, learning 0.108s)
             Mean action noise std: 1.55
          Mean value_function loss: 88.6746
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 33.1858
                       Mean reward: 668.33
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.7452
    Episode_Reward/rotating_object: 127.3213
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.91s
                      Time elapsed: 00:14:49
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 51023 steps/s (collection: 1.815s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 79.1617
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.1899
                       Mean reward: 637.09
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 128.7319
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.93s
                      Time elapsed: 00:14:51
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 47959 steps/s (collection: 1.962s, learning 0.088s)
             Mean action noise std: 1.55
          Mean value_function loss: 81.8200
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 33.2028
                       Mean reward: 651.10
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 127.2321
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.05s
                      Time elapsed: 00:14:53
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 52146 steps/s (collection: 1.775s, learning 0.111s)
             Mean action noise std: 1.55
          Mean value_function loss: 82.0020
               Mean surrogate loss: 0.0040
                 Mean entropy loss: 33.2110
                       Mean reward: 586.83
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 0.7418
    Episode_Reward/rotating_object: 120.7587
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.89s
                      Time elapsed: 00:14:55
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 50018 steps/s (collection: 1.866s, learning 0.100s)
             Mean action noise std: 1.55
          Mean value_function loss: 91.2882
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.2118
                       Mean reward: 608.28
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 0.7603
    Episode_Reward/rotating_object: 129.8949
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.97s
                      Time elapsed: 00:14:57
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 52639 steps/s (collection: 1.767s, learning 0.100s)
             Mean action noise std: 1.55
          Mean value_function loss: 78.5665
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.2139
                       Mean reward: 643.63
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 126.8721
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.87s
                      Time elapsed: 00:14:58
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 51167 steps/s (collection: 1.800s, learning 0.122s)
             Mean action noise std: 1.55
          Mean value_function loss: 79.4373
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 33.2188
                       Mean reward: 638.00
               Mean episode length: 238.33
    Episode_Reward/reaching_object: 0.7572
    Episode_Reward/rotating_object: 128.0636
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.92s
                      Time elapsed: 00:15:00
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 50126 steps/s (collection: 1.851s, learning 0.110s)
             Mean action noise std: 1.55
          Mean value_function loss: 78.1245
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.2243
                       Mean reward: 603.17
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 123.0770
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.96s
                      Time elapsed: 00:15:02
                               ETA: 00:40:18

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 49754 steps/s (collection: 1.852s, learning 0.124s)
             Mean action noise std: 1.56
          Mean value_function loss: 79.6574
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 33.2308
                       Mean reward: 669.17
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.7686
    Episode_Reward/rotating_object: 130.8667
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.98s
                      Time elapsed: 00:15:04
                               ETA: 00:40:15

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 51436 steps/s (collection: 1.797s, learning 0.115s)
             Mean action noise std: 1.56
          Mean value_function loss: 82.2305
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.2329
                       Mean reward: 605.10
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 126.0682
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.91s
                      Time elapsed: 00:15:06
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 51313 steps/s (collection: 1.795s, learning 0.121s)
             Mean action noise std: 1.56
          Mean value_function loss: 83.6904
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.2394
                       Mean reward: 616.80
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 126.1616
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.92s
                      Time elapsed: 00:15:08
                               ETA: 00:40:09

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 52575 steps/s (collection: 1.753s, learning 0.117s)
             Mean action noise std: 1.56
          Mean value_function loss: 77.8516
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 33.2510
                       Mean reward: 640.06
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 130.6860
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.87s
                      Time elapsed: 00:15:10
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 52188 steps/s (collection: 1.778s, learning 0.106s)
             Mean action noise std: 1.56
          Mean value_function loss: 69.1177
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.2550
                       Mean reward: 630.83
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 0.7383
    Episode_Reward/rotating_object: 126.6294
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.88s
                      Time elapsed: 00:15:12
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 54300 steps/s (collection: 1.699s, learning 0.112s)
             Mean action noise std: 1.56
          Mean value_function loss: 78.7729
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.2556
                       Mean reward: 628.23
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 127.9692
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.81s
                      Time elapsed: 00:15:14
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 53571 steps/s (collection: 1.722s, learning 0.113s)
             Mean action noise std: 1.56
          Mean value_function loss: 70.9098
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 33.2682
                       Mean reward: 635.83
               Mean episode length: 242.67
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 127.3249
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.83s
                      Time elapsed: 00:15:16
                               ETA: 00:39:57

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 53015 steps/s (collection: 1.741s, learning 0.113s)
             Mean action noise std: 1.56
          Mean value_function loss: 78.3505
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 33.2821
                       Mean reward: 623.07
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 128.1402
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.85s
                      Time elapsed: 00:15:17
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 51874 steps/s (collection: 1.773s, learning 0.122s)
             Mean action noise std: 1.56
          Mean value_function loss: 79.5153
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 33.2881
                       Mean reward: 644.29
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 127.8297
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.90s
                      Time elapsed: 00:15:19
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 52817 steps/s (collection: 1.758s, learning 0.104s)
             Mean action noise std: 1.56
          Mean value_function loss: 69.2559
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 33.2907
                       Mean reward: 667.09
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 126.4782
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.86s
                      Time elapsed: 00:15:21
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 51827 steps/s (collection: 1.778s, learning 0.119s)
             Mean action noise std: 1.56
          Mean value_function loss: 72.2507
               Mean surrogate loss: 0.0041
                 Mean entropy loss: 33.2929
                       Mean reward: 660.88
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.7571
    Episode_Reward/rotating_object: 130.1991
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.90s
                      Time elapsed: 00:15:23
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 53194 steps/s (collection: 1.757s, learning 0.091s)
             Mean action noise std: 1.56
          Mean value_function loss: 75.4694
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.2952
                       Mean reward: 669.50
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 0.7562
    Episode_Reward/rotating_object: 132.3850
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.85s
                      Time elapsed: 00:15:25
                               ETA: 00:39:41

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 50760 steps/s (collection: 1.820s, learning 0.117s)
             Mean action noise std: 1.56
          Mean value_function loss: 81.4402
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.3011
                       Mean reward: 655.50
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 0.7548
    Episode_Reward/rotating_object: 129.9321
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.94s
                      Time elapsed: 00:15:27
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 51395 steps/s (collection: 1.796s, learning 0.117s)
             Mean action noise std: 1.56
          Mean value_function loss: 69.9186
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.3052
                       Mean reward: 644.73
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 0.7679
    Episode_Reward/rotating_object: 133.3151
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.91s
                      Time elapsed: 00:15:29
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 52985 steps/s (collection: 1.740s, learning 0.115s)
             Mean action noise std: 1.56
          Mean value_function loss: 73.6059
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.3078
                       Mean reward: 667.28
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 0.7494
    Episode_Reward/rotating_object: 130.7396
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.86s
                      Time elapsed: 00:15:31
                               ETA: 00:39:32

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 52547 steps/s (collection: 1.773s, learning 0.098s)
             Mean action noise std: 1.56
          Mean value_function loss: 68.3355
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 33.3103
                       Mean reward: 650.45
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 131.0356
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.87s
                      Time elapsed: 00:15:32
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 52377 steps/s (collection: 1.745s, learning 0.132s)
             Mean action noise std: 1.56
          Mean value_function loss: 66.3668
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.3152
                       Mean reward: 654.93
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 0.7549
    Episode_Reward/rotating_object: 129.6621
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.88s
                      Time elapsed: 00:15:34
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 53714 steps/s (collection: 1.716s, learning 0.114s)
             Mean action noise std: 1.57
          Mean value_function loss: 64.6926
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.3246
                       Mean reward: 668.47
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 0.7638
    Episode_Reward/rotating_object: 133.9598
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.83s
                      Time elapsed: 00:15:36
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 53159 steps/s (collection: 1.747s, learning 0.103s)
             Mean action noise std: 1.57
          Mean value_function loss: 68.1804
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 33.3325
                       Mean reward: 655.44
               Mean episode length: 234.20
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 133.6798
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.85s
                      Time elapsed: 00:15:38
                               ETA: 00:39:20

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 52291 steps/s (collection: 1.765s, learning 0.115s)
             Mean action noise std: 1.57
          Mean value_function loss: 61.6305
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 33.3384
                       Mean reward: 684.51
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 134.2977
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.88s
                      Time elapsed: 00:15:40
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 51172 steps/s (collection: 1.805s, learning 0.116s)
             Mean action noise std: 1.57
          Mean value_function loss: 58.3681
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.3424
                       Mean reward: 670.12
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 0.7610
    Episode_Reward/rotating_object: 131.5028
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.92s
                      Time elapsed: 00:15:42
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 52459 steps/s (collection: 1.773s, learning 0.101s)
             Mean action noise std: 1.57
          Mean value_function loss: 63.6313
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 33.3479
                       Mean reward: 686.68
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 133.1306
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.87s
                      Time elapsed: 00:15:44
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 51886 steps/s (collection: 1.777s, learning 0.118s)
             Mean action noise std: 1.57
          Mean value_function loss: 67.1079
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 33.3496
                       Mean reward: 686.32
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7491
    Episode_Reward/rotating_object: 134.5848
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.89s
                      Time elapsed: 00:15:46
                               ETA: 00:39:08

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 52142 steps/s (collection: 1.769s, learning 0.116s)
             Mean action noise std: 1.57
          Mean value_function loss: 72.9569
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.3514
                       Mean reward: 646.59
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 133.5447
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.89s
                      Time elapsed: 00:15:47
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 51433 steps/s (collection: 1.800s, learning 0.112s)
             Mean action noise std: 1.57
          Mean value_function loss: 67.5464
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.3560
                       Mean reward: 663.39
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 132.8368
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.91s
                      Time elapsed: 00:15:49
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 51323 steps/s (collection: 1.805s, learning 0.110s)
             Mean action noise std: 1.57
          Mean value_function loss: 63.1395
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.3654
                       Mean reward: 643.53
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 131.5747
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.92s
                      Time elapsed: 00:15:51
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 50728 steps/s (collection: 1.813s, learning 0.125s)
             Mean action noise std: 1.57
          Mean value_function loss: 85.0262
               Mean surrogate loss: 0.0054
                 Mean entropy loss: 33.3733
                       Mean reward: 662.15
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 0.7422
    Episode_Reward/rotating_object: 131.5450
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.94s
                      Time elapsed: 00:15:53
                               ETA: 00:38:57

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 49832 steps/s (collection: 1.848s, learning 0.125s)
             Mean action noise std: 1.57
          Mean value_function loss: 79.0711
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 33.3764
                       Mean reward: 641.71
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 0.7330
    Episode_Reward/rotating_object: 129.7739
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.97s
                      Time elapsed: 00:15:55
                               ETA: 00:38:54

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 49924 steps/s (collection: 1.856s, learning 0.113s)
             Mean action noise std: 1.57
          Mean value_function loss: 69.2506
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.3784
                       Mean reward: 676.99
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 0.7377
    Episode_Reward/rotating_object: 132.2986
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.97s
                      Time elapsed: 00:15:57
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 50484 steps/s (collection: 1.837s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 67.1264
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.3863
                       Mean reward: 626.96
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 0.7260
    Episode_Reward/rotating_object: 127.8948
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.95s
                      Time elapsed: 00:15:59
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 50860 steps/s (collection: 1.839s, learning 0.094s)
             Mean action noise std: 1.57
          Mean value_function loss: 68.9559
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.3949
                       Mean reward: 677.64
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 133.7532
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.93s
                      Time elapsed: 00:16:01
                               ETA: 00:38:46

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 50817 steps/s (collection: 1.812s, learning 0.123s)
             Mean action noise std: 1.57
          Mean value_function loss: 61.8448
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 33.4052
                       Mean reward: 705.11
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7438
    Episode_Reward/rotating_object: 133.3775
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.93s
                      Time elapsed: 00:16:03
                               ETA: 00:38:43

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 47622 steps/s (collection: 1.944s, learning 0.120s)
             Mean action noise std: 1.58
          Mean value_function loss: 66.9225
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 33.4129
                       Mean reward: 639.02
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 0.7484
    Episode_Reward/rotating_object: 132.2588
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.06s
                      Time elapsed: 00:16:05
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 50553 steps/s (collection: 1.850s, learning 0.095s)
             Mean action noise std: 1.58
          Mean value_function loss: 78.0507
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.4174
                       Mean reward: 628.70
               Mean episode length: 227.92
    Episode_Reward/reaching_object: 0.7141
    Episode_Reward/rotating_object: 129.0073
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.94s
                      Time elapsed: 00:16:07
                               ETA: 00:38:38

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 48661 steps/s (collection: 1.922s, learning 0.098s)
             Mean action noise std: 1.58
          Mean value_function loss: 60.3609
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.4218
                       Mean reward: 639.82
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 0.7194
    Episode_Reward/rotating_object: 132.3918
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.02s
                      Time elapsed: 00:16:09
                               ETA: 00:38:35

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 47735 steps/s (collection: 1.970s, learning 0.090s)
             Mean action noise std: 1.58
          Mean value_function loss: 63.7212
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 33.4294
                       Mean reward: 651.13
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 0.7082
    Episode_Reward/rotating_object: 128.0719
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.06s
                      Time elapsed: 00:16:11
                               ETA: 00:38:33

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 51803 steps/s (collection: 1.790s, learning 0.108s)
             Mean action noise std: 1.58
          Mean value_function loss: 66.0923
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 33.4369
                       Mean reward: 666.44
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 0.7219
    Episode_Reward/rotating_object: 131.9669
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.90s
                      Time elapsed: 00:16:13
                               ETA: 00:38:30

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 49251 steps/s (collection: 1.891s, learning 0.105s)
             Mean action noise std: 1.58
          Mean value_function loss: 66.4512
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.4471
                       Mean reward: 717.61
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 0.7321
    Episode_Reward/rotating_object: 137.4244
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.00s
                      Time elapsed: 00:16:15
                               ETA: 00:38:27

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 51170 steps/s (collection: 1.812s, learning 0.109s)
             Mean action noise std: 1.58
          Mean value_function loss: 64.9956
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.4532
                       Mean reward: 657.73
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 0.7237
    Episode_Reward/rotating_object: 132.7531
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.92s
                      Time elapsed: 00:16:17
                               ETA: 00:38:24

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 49651 steps/s (collection: 1.867s, learning 0.113s)
             Mean action noise std: 1.58
          Mean value_function loss: 60.2059
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.4642
                       Mean reward: 688.87
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.7147
    Episode_Reward/rotating_object: 133.0712
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.98s
                      Time elapsed: 00:16:19
                               ETA: 00:38:21

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 50683 steps/s (collection: 1.846s, learning 0.093s)
             Mean action noise std: 1.58
          Mean value_function loss: 62.8998
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.4697
                       Mean reward: 651.20
               Mean episode length: 240.53
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 131.5036
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.94s
                      Time elapsed: 00:16:21
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 52172 steps/s (collection: 1.798s, learning 0.086s)
             Mean action noise std: 1.58
          Mean value_function loss: 53.2107
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.4752
                       Mean reward: 628.71
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 0.7160
    Episode_Reward/rotating_object: 130.0300
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.88s
                      Time elapsed: 00:16:23
                               ETA: 00:38:16

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 51991 steps/s (collection: 1.794s, learning 0.097s)
             Mean action noise std: 1.58
          Mean value_function loss: 60.4320
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.4787
                       Mean reward: 671.29
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 134.8325
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.89s
                      Time elapsed: 00:16:25
                               ETA: 00:38:13

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 50701 steps/s (collection: 1.833s, learning 0.106s)
             Mean action noise std: 1.58
          Mean value_function loss: 55.9466
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.4857
                       Mean reward: 693.14
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 0.7211
    Episode_Reward/rotating_object: 137.6295
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.94s
                      Time elapsed: 00:16:27
                               ETA: 00:38:10

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 51112 steps/s (collection: 1.809s, learning 0.115s)
             Mean action noise std: 1.58
          Mean value_function loss: 53.6735
               Mean surrogate loss: 0.0051
                 Mean entropy loss: 33.4948
                       Mean reward: 664.80
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 0.7255
    Episode_Reward/rotating_object: 132.4766
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.92s
                      Time elapsed: 00:16:28
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 52376 steps/s (collection: 1.784s, learning 0.093s)
             Mean action noise std: 1.59
          Mean value_function loss: 65.8936
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.4994
                       Mean reward: 654.73
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 0.7040
    Episode_Reward/rotating_object: 134.0430
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.88s
                      Time elapsed: 00:16:30
                               ETA: 00:38:05

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 52277 steps/s (collection: 1.786s, learning 0.094s)
             Mean action noise std: 1.59
          Mean value_function loss: 62.7852
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.5038
                       Mean reward: 683.24
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 0.7172
    Episode_Reward/rotating_object: 135.4363
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.88s
                      Time elapsed: 00:16:32
                               ETA: 00:38:02

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 52010 steps/s (collection: 1.788s, learning 0.103s)
             Mean action noise std: 1.59
          Mean value_function loss: 54.6169
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.5132
                       Mean reward: 654.00
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 0.7162
    Episode_Reward/rotating_object: 136.7167
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.89s
                      Time elapsed: 00:16:34
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 51766 steps/s (collection: 1.814s, learning 0.085s)
             Mean action noise std: 1.59
          Mean value_function loss: 58.3073
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.5206
                       Mean reward: 679.94
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 0.6840
    Episode_Reward/rotating_object: 132.6103
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.90s
                      Time elapsed: 00:16:36
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 52108 steps/s (collection: 1.795s, learning 0.091s)
             Mean action noise std: 1.59
          Mean value_function loss: 60.9004
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.5289
                       Mean reward: 688.76
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 0.6963
    Episode_Reward/rotating_object: 136.3693
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.89s
                      Time elapsed: 00:16:38
                               ETA: 00:37:53

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 52281 steps/s (collection: 1.786s, learning 0.095s)
             Mean action noise std: 1.59
          Mean value_function loss: 59.9668
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.5373
                       Mean reward: 665.03
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 134.1200
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.88s
                      Time elapsed: 00:16:40
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 51695 steps/s (collection: 1.777s, learning 0.125s)
             Mean action noise std: 1.59
          Mean value_function loss: 59.9158
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 33.5441
                       Mean reward: 736.20
               Mean episode length: 246.66
    Episode_Reward/reaching_object: 0.7045
    Episode_Reward/rotating_object: 138.6763
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.90s
                      Time elapsed: 00:16:42
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 52523 steps/s (collection: 1.762s, learning 0.110s)
             Mean action noise std: 1.59
          Mean value_function loss: 50.8935
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 33.5505
                       Mean reward: 716.19
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 138.9387
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.87s
                      Time elapsed: 00:16:44
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 51917 steps/s (collection: 1.778s, learning 0.116s)
             Mean action noise std: 1.59
          Mean value_function loss: 63.9900
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.5596
                       Mean reward: 665.73
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 0.7039
    Episode_Reward/rotating_object: 135.7222
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.89s
                      Time elapsed: 00:16:45
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 52097 steps/s (collection: 1.779s, learning 0.108s)
             Mean action noise std: 1.59
          Mean value_function loss: 59.4322
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.5689
                       Mean reward: 688.28
               Mean episode length: 244.53
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 139.3381
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.89s
                      Time elapsed: 00:16:47
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 50883 steps/s (collection: 1.802s, learning 0.130s)
             Mean action noise std: 1.59
          Mean value_function loss: 61.0447
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.5801
                       Mean reward: 696.40
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 0.7055
    Episode_Reward/rotating_object: 136.1928
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.93s
                      Time elapsed: 00:16:49
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 51438 steps/s (collection: 1.795s, learning 0.117s)
             Mean action noise std: 1.60
          Mean value_function loss: 53.6101
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 33.5913
                       Mean reward: 686.57
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 0.7089
    Episode_Reward/rotating_object: 135.6679
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.91s
                      Time elapsed: 00:16:51
                               ETA: 00:37:33

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 51995 steps/s (collection: 1.792s, learning 0.098s)
             Mean action noise std: 1.60
          Mean value_function loss: 65.8673
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 33.5935
                       Mean reward: 662.42
               Mean episode length: 234.89
    Episode_Reward/reaching_object: 0.7143
    Episode_Reward/rotating_object: 137.2955
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.89s
                      Time elapsed: 00:16:53
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 50610 steps/s (collection: 1.810s, learning 0.133s)
             Mean action noise std: 1.60
          Mean value_function loss: 64.5263
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.5991
                       Mean reward: 640.51
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 136.0502
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.94s
                      Time elapsed: 00:16:55
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 49778 steps/s (collection: 1.862s, learning 0.113s)
             Mean action noise std: 1.60
          Mean value_function loss: 57.0408
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.6110
                       Mean reward: 671.86
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 0.7064
    Episode_Reward/rotating_object: 138.0080
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.97s
                      Time elapsed: 00:16:57
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 50126 steps/s (collection: 1.842s, learning 0.120s)
             Mean action noise std: 1.60
          Mean value_function loss: 61.6159
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 33.6204
                       Mean reward: 679.63
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 0.6991
    Episode_Reward/rotating_object: 135.5738
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.96s
                      Time elapsed: 00:16:59
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 48449 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 1.60
          Mean value_function loss: 51.9160
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 33.6220
                       Mean reward: 701.21
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 0.7069
    Episode_Reward/rotating_object: 138.8308
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.03s
                      Time elapsed: 00:17:01
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 49420 steps/s (collection: 1.879s, learning 0.110s)
             Mean action noise std: 1.60
          Mean value_function loss: 55.9626
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 33.6233
                       Mean reward: 678.08
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.7129
    Episode_Reward/rotating_object: 138.5180
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.99s
                      Time elapsed: 00:17:03
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 50333 steps/s (collection: 1.841s, learning 0.112s)
             Mean action noise std: 1.60
          Mean value_function loss: 69.4880
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.6246
                       Mean reward: 666.71
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 0.6977
    Episode_Reward/rotating_object: 135.6639
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.95s
                      Time elapsed: 00:17:05
                               ETA: 00:37:15

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 49450 steps/s (collection: 1.881s, learning 0.107s)
             Mean action noise std: 1.60
          Mean value_function loss: 59.3721
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.6294
                       Mean reward: 698.06
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 0.6942
    Episode_Reward/rotating_object: 138.0665
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.99s
                      Time elapsed: 00:17:07
                               ETA: 00:37:12

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 50643 steps/s (collection: 1.812s, learning 0.130s)
             Mean action noise std: 1.60
          Mean value_function loss: 62.8881
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.6394
                       Mean reward: 642.21
               Mean episode length: 226.59
    Episode_Reward/reaching_object: 0.6791
    Episode_Reward/rotating_object: 130.3987
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.94s
                      Time elapsed: 00:17:09
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 49956 steps/s (collection: 1.843s, learning 0.125s)
             Mean action noise std: 1.60
          Mean value_function loss: 70.6405
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.6522
                       Mean reward: 669.20
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 136.1408
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.97s
                      Time elapsed: 00:17:11
                               ETA: 00:37:07

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 51557 steps/s (collection: 1.787s, learning 0.120s)
             Mean action noise std: 1.60
          Mean value_function loss: 56.3229
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.6659
                       Mean reward: 652.03
               Mean episode length: 231.28
    Episode_Reward/reaching_object: 0.6962
    Episode_Reward/rotating_object: 138.1211
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.91s
                      Time elapsed: 00:17:13
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 50167 steps/s (collection: 1.843s, learning 0.117s)
             Mean action noise std: 1.61
          Mean value_function loss: 59.6949
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.6765
                       Mean reward: 684.56
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 0.7034
    Episode_Reward/rotating_object: 138.6819
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.96s
                      Time elapsed: 00:17:15
                               ETA: 00:37:02

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 50787 steps/s (collection: 1.820s, learning 0.116s)
             Mean action noise std: 1.61
          Mean value_function loss: 62.2235
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.6847
                       Mean reward: 703.09
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 0.6914
    Episode_Reward/rotating_object: 136.3644
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.94s
                      Time elapsed: 00:17:17
                               ETA: 00:36:59

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 50764 steps/s (collection: 1.824s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 58.8897
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 33.6955
                       Mean reward: 709.07
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 0.7015
    Episode_Reward/rotating_object: 140.7388
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.94s
                      Time elapsed: 00:17:19
                               ETA: 00:36:56

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 48786 steps/s (collection: 1.897s, learning 0.118s)
             Mean action noise std: 1.61
          Mean value_function loss: 68.0695
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.7055
                       Mean reward: 656.10
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 0.6878
    Episode_Reward/rotating_object: 135.7363
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.01s
                      Time elapsed: 00:17:21
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 49664 steps/s (collection: 1.874s, learning 0.105s)
             Mean action noise std: 1.61
          Mean value_function loss: 62.5972
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 33.7126
                       Mean reward: 651.10
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 0.6937
    Episode_Reward/rotating_object: 134.2923
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.98s
                      Time elapsed: 00:17:23
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 50881 steps/s (collection: 1.827s, learning 0.105s)
             Mean action noise std: 1.61
          Mean value_function loss: 48.5072
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.7254
                       Mean reward: 713.39
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.6914
    Episode_Reward/rotating_object: 139.3842
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.93s
                      Time elapsed: 00:17:24
                               ETA: 00:36:49

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 49500 steps/s (collection: 1.879s, learning 0.107s)
             Mean action noise std: 1.61
          Mean value_function loss: 52.1847
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.7497
                       Mean reward: 680.51
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 0.6970
    Episode_Reward/rotating_object: 140.5363
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.99s
                      Time elapsed: 00:17:26
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 49868 steps/s (collection: 1.848s, learning 0.123s)
             Mean action noise std: 1.62
          Mean value_function loss: 54.0538
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.7632
                       Mean reward: 669.90
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 0.7018
    Episode_Reward/rotating_object: 139.8808
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.97s
                      Time elapsed: 00:17:28
                               ETA: 00:36:44

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 50226 steps/s (collection: 1.838s, learning 0.119s)
             Mean action noise std: 1.62
          Mean value_function loss: 52.8493
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.7912
                       Mean reward: 717.94
               Mean episode length: 246.23
    Episode_Reward/reaching_object: 0.7037
    Episode_Reward/rotating_object: 139.4878
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.96s
                      Time elapsed: 00:17:30
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 50889 steps/s (collection: 1.825s, learning 0.107s)
             Mean action noise std: 1.62
          Mean value_function loss: 43.7868
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.8179
                       Mean reward: 700.32
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7021
    Episode_Reward/rotating_object: 141.0173
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.93s
                      Time elapsed: 00:17:32
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 50300 steps/s (collection: 1.859s, learning 0.096s)
             Mean action noise std: 1.62
          Mean value_function loss: 53.4001
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.8351
                       Mean reward: 723.14
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.7028
    Episode_Reward/rotating_object: 140.8857
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.95s
                      Time elapsed: 00:17:34
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 50151 steps/s (collection: 1.844s, learning 0.116s)
             Mean action noise std: 1.62
          Mean value_function loss: 51.0273
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.8509
                       Mean reward: 724.80
               Mean episode length: 247.66
    Episode_Reward/reaching_object: 0.7133
    Episode_Reward/rotating_object: 142.4462
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.96s
                      Time elapsed: 00:17:36
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 49944 steps/s (collection: 1.853s, learning 0.115s)
             Mean action noise std: 1.62
          Mean value_function loss: 50.7554
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 33.8604
                       Mean reward: 689.37
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 140.9506
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.97s
                      Time elapsed: 00:17:38
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 49712 steps/s (collection: 1.859s, learning 0.119s)
             Mean action noise std: 1.63
          Mean value_function loss: 52.7385
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.8676
                       Mean reward: 707.77
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.7131
    Episode_Reward/rotating_object: 141.9193
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.98s
                      Time elapsed: 00:17:40
                               ETA: 00:36:28

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 51444 steps/s (collection: 1.796s, learning 0.115s)
             Mean action noise std: 1.63
          Mean value_function loss: 49.4712
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.8741
                       Mean reward: 727.37
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 0.7093
    Episode_Reward/rotating_object: 139.9385
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.91s
                      Time elapsed: 00:17:42
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 52577 steps/s (collection: 1.771s, learning 0.099s)
             Mean action noise std: 1.63
          Mean value_function loss: 52.4157
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.8837
                       Mean reward: 726.28
               Mean episode length: 248.63
    Episode_Reward/reaching_object: 0.7120
    Episode_Reward/rotating_object: 142.7882
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.87s
                      Time elapsed: 00:17:44
                               ETA: 00:36:23

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 51137 steps/s (collection: 1.797s, learning 0.125s)
             Mean action noise std: 1.63
          Mean value_function loss: 55.0819
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.8989
                       Mean reward: 704.36
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 0.6993
    Episode_Reward/rotating_object: 137.9300
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.92s
                      Time elapsed: 00:17:46
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 51815 steps/s (collection: 1.788s, learning 0.110s)
             Mean action noise std: 1.63
          Mean value_function loss: 48.5810
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.9130
                       Mean reward: 712.99
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.7191
    Episode_Reward/rotating_object: 143.1382
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.90s
                      Time elapsed: 00:17:48
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 51258 steps/s (collection: 1.801s, learning 0.117s)
             Mean action noise std: 1.63
          Mean value_function loss: 53.2975
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.9267
                       Mean reward: 719.99
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 140.5770
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 1.92s
                      Time elapsed: 00:17:50
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 52255 steps/s (collection: 1.772s, learning 0.110s)
             Mean action noise std: 1.63
          Mean value_function loss: 43.3224
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.9388
                       Mean reward: 719.31
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 142.2883
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.88s
                      Time elapsed: 00:17:52
                               ETA: 00:36:12

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 52388 steps/s (collection: 1.768s, learning 0.109s)
             Mean action noise std: 1.63
          Mean value_function loss: 54.7379
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.9454
                       Mean reward: 722.54
               Mean episode length: 244.19
    Episode_Reward/reaching_object: 0.7112
    Episode_Reward/rotating_object: 140.9305
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.88s
                      Time elapsed: 00:17:53
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 52026 steps/s (collection: 1.782s, learning 0.107s)
             Mean action noise std: 1.64
          Mean value_function loss: 44.0813
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.9692
                       Mean reward: 710.97
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 0.7089
    Episode_Reward/rotating_object: 139.9058
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.89s
                      Time elapsed: 00:17:55
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 52365 steps/s (collection: 1.778s, learning 0.100s)
             Mean action noise std: 1.64
          Mean value_function loss: 49.0316
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 33.9925
                       Mean reward: 736.73
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7175
    Episode_Reward/rotating_object: 142.3871
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.88s
                      Time elapsed: 00:17:57
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 52003 steps/s (collection: 1.774s, learning 0.116s)
             Mean action noise std: 1.64
          Mean value_function loss: 51.2858
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.0043
                       Mean reward: 715.98
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 0.7136
    Episode_Reward/rotating_object: 143.7077
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.89s
                      Time elapsed: 00:17:59
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 52400 steps/s (collection: 1.757s, learning 0.119s)
             Mean action noise std: 1.64
          Mean value_function loss: 42.4836
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.0198
                       Mean reward: 714.23
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 0.7155
    Episode_Reward/rotating_object: 143.5677
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.88s
                      Time elapsed: 00:18:01
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 49999 steps/s (collection: 1.842s, learning 0.124s)
             Mean action noise std: 1.64
          Mean value_function loss: 44.0875
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.0377
                       Mean reward: 712.43
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 0.7133
    Episode_Reward/rotating_object: 143.3456
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.97s
                      Time elapsed: 00:18:03
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 51595 steps/s (collection: 1.791s, learning 0.115s)
             Mean action noise std: 1.65
          Mean value_function loss: 54.7677
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.0578
                       Mean reward: 713.53
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 0.6936
    Episode_Reward/rotating_object: 138.7174
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.91s
                      Time elapsed: 00:18:05
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 51390 steps/s (collection: 1.801s, learning 0.112s)
             Mean action noise std: 1.65
          Mean value_function loss: 48.2940
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.0742
                       Mean reward: 712.58
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 0.7099
    Episode_Reward/rotating_object: 145.0769
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.91s
                      Time elapsed: 00:18:07
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 53215 steps/s (collection: 1.756s, learning 0.092s)
             Mean action noise std: 1.65
          Mean value_function loss: 55.8534
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 34.0843
                       Mean reward: 703.61
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.6968
    Episode_Reward/rotating_object: 142.5929
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.85s
                      Time elapsed: 00:18:09
                               ETA: 00:35:48

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 50451 steps/s (collection: 1.830s, learning 0.118s)
             Mean action noise std: 1.65
          Mean value_function loss: 43.2576
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.1046
                       Mean reward: 728.96
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.7088
    Episode_Reward/rotating_object: 143.1090
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.95s
                      Time elapsed: 00:18:11
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 52181 steps/s (collection: 1.772s, learning 0.112s)
             Mean action noise std: 1.66
          Mean value_function loss: 42.4759
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.1391
                       Mean reward: 712.47
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 0.7053
    Episode_Reward/rotating_object: 142.5823
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.88s
                      Time elapsed: 00:18:12
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 51512 steps/s (collection: 1.788s, learning 0.120s)
             Mean action noise std: 1.66
          Mean value_function loss: 51.8481
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.1555
                       Mean reward: 694.12
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 0.7034
    Episode_Reward/rotating_object: 142.7599
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.91s
                      Time elapsed: 00:18:14
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 51467 steps/s (collection: 1.802s, learning 0.108s)
             Mean action noise std: 1.66
          Mean value_function loss: 43.0657
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.1652
                       Mean reward: 706.19
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 0.7018
    Episode_Reward/rotating_object: 142.4909
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.91s
                      Time elapsed: 00:18:16
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 51558 steps/s (collection: 1.796s, learning 0.110s)
             Mean action noise std: 1.66
          Mean value_function loss: 57.8870
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.1742
                       Mean reward: 719.60
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 0.7056
    Episode_Reward/rotating_object: 142.6503
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.91s
                      Time elapsed: 00:18:18
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 51474 steps/s (collection: 1.813s, learning 0.097s)
             Mean action noise std: 1.66
          Mean value_function loss: 45.3556
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.1797
                       Mean reward: 703.25
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 0.7111
    Episode_Reward/rotating_object: 145.1323
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.91s
                      Time elapsed: 00:18:20
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 51540 steps/s (collection: 1.800s, learning 0.107s)
             Mean action noise std: 1.66
          Mean value_function loss: 48.8068
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.1896
                       Mean reward: 711.98
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 0.6990
    Episode_Reward/rotating_object: 139.2390
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.91s
                      Time elapsed: 00:18:22
                               ETA: 00:35:29

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 52029 steps/s (collection: 1.772s, learning 0.118s)
             Mean action noise std: 1.66
          Mean value_function loss: 57.7289
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.2055
                       Mean reward: 736.24
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.6989
    Episode_Reward/rotating_object: 142.7558
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.89s
                      Time elapsed: 00:18:24
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 52047 steps/s (collection: 1.780s, learning 0.109s)
             Mean action noise std: 1.67
          Mean value_function loss: 47.8146
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 34.2286
                       Mean reward: 753.59
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7036
    Episode_Reward/rotating_object: 141.6348
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.89s
                      Time elapsed: 00:18:26
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 51331 steps/s (collection: 1.803s, learning 0.112s)
             Mean action noise std: 1.67
          Mean value_function loss: 51.2254
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.2421
                       Mean reward: 712.11
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 0.7018
    Episode_Reward/rotating_object: 141.4188
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.92s
                      Time elapsed: 00:18:28
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 50926 steps/s (collection: 1.815s, learning 0.116s)
             Mean action noise std: 1.67
          Mean value_function loss: 47.9335
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 34.2598
                       Mean reward: 670.82
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 0.7009
    Episode_Reward/rotating_object: 141.2619
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.93s
                      Time elapsed: 00:18:30
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 49425 steps/s (collection: 1.880s, learning 0.109s)
             Mean action noise std: 1.67
          Mean value_function loss: 49.9045
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 34.2765
                       Mean reward: 728.58
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 0.7030
    Episode_Reward/rotating_object: 142.7798
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.99s
                      Time elapsed: 00:18:32
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 52877 steps/s (collection: 1.747s, learning 0.112s)
             Mean action noise std: 1.67
          Mean value_function loss: 46.7875
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.3037
                       Mean reward: 726.10
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.7049
    Episode_Reward/rotating_object: 143.1661
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.86s
                      Time elapsed: 00:18:33
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 52071 steps/s (collection: 1.794s, learning 0.093s)
             Mean action noise std: 1.68
          Mean value_function loss: 47.2766
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.3295
                       Mean reward: 743.36
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7097
    Episode_Reward/rotating_object: 145.7444
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.89s
                      Time elapsed: 00:18:35
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 41872 steps/s (collection: 2.192s, learning 0.156s)
             Mean action noise std: 1.68
          Mean value_function loss: 42.9805
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 34.3529
                       Mean reward: 737.82
               Mean episode length: 243.23
    Episode_Reward/reaching_object: 0.7077
    Episode_Reward/rotating_object: 146.2906
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.35s
                      Time elapsed: 00:18:38
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 41545 steps/s (collection: 2.167s, learning 0.200s)
             Mean action noise std: 1.68
          Mean value_function loss: 54.7912
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 34.3644
                       Mean reward: 687.70
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 0.6959
    Episode_Reward/rotating_object: 142.6146
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.37s
                      Time elapsed: 00:18:40
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 46391 steps/s (collection: 1.988s, learning 0.131s)
             Mean action noise std: 1.68
          Mean value_function loss: 54.6567
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.3702
                       Mean reward: 712.28
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 0.7047
    Episode_Reward/rotating_object: 143.9032
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.12s
                      Time elapsed: 00:18:42
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 48824 steps/s (collection: 1.910s, learning 0.103s)
             Mean action noise std: 1.68
          Mean value_function loss: 46.3094
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.3883
                       Mean reward: 742.24
               Mean episode length: 242.67
    Episode_Reward/reaching_object: 0.7002
    Episode_Reward/rotating_object: 143.6536
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.01s
                      Time elapsed: 00:18:44
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 46557 steps/s (collection: 1.983s, learning 0.128s)
             Mean action noise std: 1.68
          Mean value_function loss: 57.7546
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.4044
                       Mean reward: 699.28
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 0.6956
    Episode_Reward/rotating_object: 140.5953
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.11s
                      Time elapsed: 00:18:46
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 48381 steps/s (collection: 1.909s, learning 0.123s)
             Mean action noise std: 1.69
          Mean value_function loss: 53.9419
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.4215
                       Mean reward: 700.56
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 0.6990
    Episode_Reward/rotating_object: 141.4859
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.03s
                      Time elapsed: 00:18:48
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 47279 steps/s (collection: 1.935s, learning 0.145s)
             Mean action noise std: 1.69
          Mean value_function loss: 48.3617
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.4400
                       Mean reward: 735.95
               Mean episode length: 246.35
    Episode_Reward/reaching_object: 0.7104
    Episode_Reward/rotating_object: 145.0746
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.08s
                      Time elapsed: 00:18:50
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 51903 steps/s (collection: 1.807s, learning 0.087s)
             Mean action noise std: 1.69
          Mean value_function loss: 40.6582
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 34.4491
                       Mean reward: 738.47
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7147
    Episode_Reward/rotating_object: 145.4430
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.89s
                      Time elapsed: 00:18:52
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 51896 steps/s (collection: 1.781s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 47.4165
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.4544
                       Mean reward: 732.31
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 0.7094
    Episode_Reward/rotating_object: 143.6417
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.89s
                      Time elapsed: 00:18:54
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 52564 steps/s (collection: 1.776s, learning 0.094s)
             Mean action noise std: 1.69
          Mean value_function loss: 50.2899
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.4672
                       Mean reward: 741.67
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 145.8409
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.87s
                      Time elapsed: 00:18:56
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 50119 steps/s (collection: 1.781s, learning 0.181s)
             Mean action noise std: 1.69
          Mean value_function loss: 46.0336
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.4839
                       Mean reward: 714.27
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.7013
    Episode_Reward/rotating_object: 142.7171
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.96s
                      Time elapsed: 00:18:58
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 49294 steps/s (collection: 1.830s, learning 0.165s)
             Mean action noise std: 1.69
          Mean value_function loss: 44.5037
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.5017
                       Mean reward: 709.88
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 0.7137
    Episode_Reward/rotating_object: 145.6004
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.99s
                      Time elapsed: 00:19:00
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 48915 steps/s (collection: 1.874s, learning 0.136s)
             Mean action noise std: 1.70
          Mean value_function loss: 55.3554
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.5228
                       Mean reward: 725.91
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.7031
    Episode_Reward/rotating_object: 144.0154
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.01s
                      Time elapsed: 00:19:02
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 52102 steps/s (collection: 1.776s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 39.0052
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.5525
                       Mean reward: 739.31
               Mean episode length: 244.34
    Episode_Reward/reaching_object: 0.7134
    Episode_Reward/rotating_object: 147.5016
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.89s
                      Time elapsed: 00:19:04
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 50632 steps/s (collection: 1.810s, learning 0.131s)
             Mean action noise std: 1.70
          Mean value_function loss: 47.0141
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.5722
                       Mean reward: 721.03
               Mean episode length: 236.09
    Episode_Reward/reaching_object: 0.7108
    Episode_Reward/rotating_object: 147.1447
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.94s
                      Time elapsed: 00:19:06
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 48748 steps/s (collection: 1.889s, learning 0.128s)
             Mean action noise std: 1.70
          Mean value_function loss: 45.8730
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 34.5969
                       Mean reward: 716.63
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 0.7087
    Episode_Reward/rotating_object: 145.4350
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.02s
                      Time elapsed: 00:19:08
                               ETA: 00:34:33

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 43838 steps/s (collection: 2.056s, learning 0.187s)
             Mean action noise std: 1.71
          Mean value_function loss: 46.9117
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.6185
                       Mean reward: 744.11
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 0.7039
    Episode_Reward/rotating_object: 144.6223
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.24s
                      Time elapsed: 00:19:10
                               ETA: 00:34:31

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 48367 steps/s (collection: 1.933s, learning 0.100s)
             Mean action noise std: 1.71
          Mean value_function loss: 49.9262
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.6428
                       Mean reward: 748.27
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7030
    Episode_Reward/rotating_object: 144.5776
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.03s
                      Time elapsed: 00:19:12
                               ETA: 00:34:29

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 49282 steps/s (collection: 1.868s, learning 0.126s)
             Mean action noise std: 1.71
          Mean value_function loss: 51.8594
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.6660
                       Mean reward: 704.20
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 0.6975
    Episode_Reward/rotating_object: 141.2591
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.99s
                      Time elapsed: 00:19:14
                               ETA: 00:34:26

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 50071 steps/s (collection: 1.849s, learning 0.114s)
             Mean action noise std: 1.72
          Mean value_function loss: 51.9023
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.6984
                       Mean reward: 731.88
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.6944
    Episode_Reward/rotating_object: 145.7609
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.96s
                      Time elapsed: 00:19:16
                               ETA: 00:34:24

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 48031 steps/s (collection: 1.882s, learning 0.165s)
             Mean action noise std: 1.72
          Mean value_function loss: 50.7138
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.7441
                       Mean reward: 731.78
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 0.6872
    Episode_Reward/rotating_object: 143.4097
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.05s
                      Time elapsed: 00:19:18
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 45162 steps/s (collection: 2.028s, learning 0.149s)
             Mean action noise std: 1.72
          Mean value_function loss: 40.4297
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.7807
                       Mean reward: 728.24
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 0.6969
    Episode_Reward/rotating_object: 145.0887
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.18s
                      Time elapsed: 00:19:20
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 44091 steps/s (collection: 2.090s, learning 0.139s)
             Mean action noise std: 1.73
          Mean value_function loss: 50.1442
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.7974
                       Mean reward: 754.68
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 0.6987
    Episode_Reward/rotating_object: 147.1806
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.23s
                      Time elapsed: 00:19:23
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 47664 steps/s (collection: 1.960s, learning 0.103s)
             Mean action noise std: 1.73
          Mean value_function loss: 37.6247
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.8206
                       Mean reward: 733.57
               Mean episode length: 246.86
    Episode_Reward/reaching_object: 0.6964
    Episode_Reward/rotating_object: 146.0193
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.06s
                      Time elapsed: 00:19:25
                               ETA: 00:34:15

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 46542 steps/s (collection: 1.958s, learning 0.154s)
             Mean action noise std: 1.73
          Mean value_function loss: 46.7055
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.8432
                       Mean reward: 715.30
               Mean episode length: 242.44
    Episode_Reward/reaching_object: 0.6951
    Episode_Reward/rotating_object: 146.8832
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.11s
                      Time elapsed: 00:19:27
                               ETA: 00:34:13

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 48686 steps/s (collection: 1.914s, learning 0.106s)
             Mean action noise std: 1.73
          Mean value_function loss: 41.4915
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.8671
                       Mean reward: 755.05
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6907
    Episode_Reward/rotating_object: 146.8273
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.02s
                      Time elapsed: 00:19:29
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 44581 steps/s (collection: 2.082s, learning 0.123s)
             Mean action noise std: 1.74
          Mean value_function loss: 49.2761
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.8936
                       Mean reward: 706.61
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 146.7422
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.21s
                      Time elapsed: 00:19:31
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 47263 steps/s (collection: 1.952s, learning 0.128s)
             Mean action noise std: 1.74
          Mean value_function loss: 43.8478
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.9401
                       Mean reward: 717.94
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 0.6778
    Episode_Reward/rotating_object: 144.3412
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.08s
                      Time elapsed: 00:19:33
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 49353 steps/s (collection: 1.888s, learning 0.104s)
             Mean action noise std: 1.74
          Mean value_function loss: 54.2101
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.9657
                       Mean reward: 745.42
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6836
    Episode_Reward/rotating_object: 144.8919
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.99s
                      Time elapsed: 00:19:35
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 45609 steps/s (collection: 1.978s, learning 0.178s)
             Mean action noise std: 1.75
          Mean value_function loss: 46.5337
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.9868
                       Mean reward: 723.07
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 0.6939
    Episode_Reward/rotating_object: 145.1909
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.16s
                      Time elapsed: 00:19:37
                               ETA: 00:34:02

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 45419 steps/s (collection: 2.044s, learning 0.120s)
             Mean action noise std: 1.75
          Mean value_function loss: 45.2777
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.0101
                       Mean reward: 725.22
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.6811
    Episode_Reward/rotating_object: 144.0473
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.16s
                      Time elapsed: 00:19:39
                               ETA: 00:34:00

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 48682 steps/s (collection: 1.911s, learning 0.108s)
             Mean action noise std: 1.75
          Mean value_function loss: 49.5125
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.0284
                       Mean reward: 667.77
               Mean episode length: 228.90
    Episode_Reward/reaching_object: 0.6686
    Episode_Reward/rotating_object: 140.0792
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.02s
                      Time elapsed: 00:19:41
                               ETA: 00:33:57

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 42071 steps/s (collection: 2.187s, learning 0.149s)
             Mean action noise std: 1.75
          Mean value_function loss: 58.4052
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.0509
                       Mean reward: 718.93
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 0.6760
    Episode_Reward/rotating_object: 144.6123
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.34s
                      Time elapsed: 00:19:44
                               ETA: 00:33:55

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 38853 steps/s (collection: 2.365s, learning 0.166s)
             Mean action noise std: 1.75
          Mean value_function loss: 54.7026
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.0700
                       Mean reward: 696.38
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 0.6762
    Episode_Reward/rotating_object: 142.5800
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.53s
                      Time elapsed: 00:19:46
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 39270 steps/s (collection: 2.374s, learning 0.130s)
             Mean action noise std: 1.76
          Mean value_function loss: 53.4471
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.0960
                       Mean reward: 733.63
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 144.5065
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.50s
                      Time elapsed: 00:19:49
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 43949 steps/s (collection: 2.137s, learning 0.100s)
             Mean action noise std: 1.76
          Mean value_function loss: 43.0447
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.1239
                       Mean reward: 734.47
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 0.6922
    Episode_Reward/rotating_object: 142.4484
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.24s
                      Time elapsed: 00:19:51
                               ETA: 00:33:50

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 44505 steps/s (collection: 2.043s, learning 0.166s)
             Mean action noise std: 1.76
          Mean value_function loss: 45.4165
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.1384
                       Mean reward: 725.30
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 0.6923
    Episode_Reward/rotating_object: 146.7801
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.21s
                      Time elapsed: 00:19:53
                               ETA: 00:33:48

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 46587 steps/s (collection: 2.002s, learning 0.108s)
             Mean action noise std: 1.76
          Mean value_function loss: 39.3651
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.1548
                       Mean reward: 678.79
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 0.6825
    Episode_Reward/rotating_object: 140.2370
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.11s
                      Time elapsed: 00:19:55
                               ETA: 00:33:46

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 47840 steps/s (collection: 1.925s, learning 0.130s)
             Mean action noise std: 1.77
          Mean value_function loss: 41.0854
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 35.1806
                       Mean reward: 716.50
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 0.7039
    Episode_Reward/rotating_object: 144.2703
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.05s
                      Time elapsed: 00:19:57
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 45343 steps/s (collection: 2.038s, learning 0.130s)
             Mean action noise std: 1.77
          Mean value_function loss: 41.0172
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.1909
                       Mean reward: 718.47
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 0.6952
    Episode_Reward/rotating_object: 146.4815
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.17s
                      Time elapsed: 00:20:00
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 47939 steps/s (collection: 1.952s, learning 0.099s)
             Mean action noise std: 1.77
          Mean value_function loss: 52.9038
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.2098
                       Mean reward: 751.67
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.7009
    Episode_Reward/rotating_object: 149.2434
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.05s
                      Time elapsed: 00:20:02
                               ETA: 00:33:39

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 49294 steps/s (collection: 1.894s, learning 0.101s)
             Mean action noise std: 1.77
          Mean value_function loss: 46.2131
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.2361
                       Mean reward: 717.12
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 145.8404
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.99s
                      Time elapsed: 00:20:04
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 46081 steps/s (collection: 1.966s, learning 0.168s)
             Mean action noise std: 1.77
          Mean value_function loss: 58.6132
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.2599
                       Mean reward: 744.49
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.7049
    Episode_Reward/rotating_object: 146.8170
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.13s
                      Time elapsed: 00:20:06
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 48410 steps/s (collection: 1.901s, learning 0.130s)
             Mean action noise std: 1.78
          Mean value_function loss: 45.9698
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.2794
                       Mean reward: 702.35
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 0.6931
    Episode_Reward/rotating_object: 142.9734
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.03s
                      Time elapsed: 00:20:08
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 47025 steps/s (collection: 1.987s, learning 0.103s)
             Mean action noise std: 1.78
          Mean value_function loss: 48.3998
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.2976
                       Mean reward: 758.07
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 0.6984
    Episode_Reward/rotating_object: 146.4770
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.09s
                      Time elapsed: 00:20:10
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 48897 steps/s (collection: 1.871s, learning 0.139s)
             Mean action noise std: 1.78
          Mean value_function loss: 41.0915
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.3135
                       Mean reward: 705.94
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 0.6962
    Episode_Reward/rotating_object: 143.9276
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.01s
                      Time elapsed: 00:20:12
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 44895 steps/s (collection: 1.988s, learning 0.201s)
             Mean action noise std: 1.78
          Mean value_function loss: 50.6048
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.3328
                       Mean reward: 691.25
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 0.6935
    Episode_Reward/rotating_object: 142.3141
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.19s
                      Time elapsed: 00:20:14
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 49962 steps/s (collection: 1.843s, learning 0.124s)
             Mean action noise std: 1.78
          Mean value_function loss: 46.5208
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.3502
                       Mean reward: 709.40
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 0.6916
    Episode_Reward/rotating_object: 142.6043
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.97s
                      Time elapsed: 00:20:16
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 45913 steps/s (collection: 1.943s, learning 0.198s)
             Mean action noise std: 1.79
          Mean value_function loss: 51.9892
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.3729
                       Mean reward: 727.68
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 0.6997
    Episode_Reward/rotating_object: 145.1102
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.14s
                      Time elapsed: 00:20:18
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 51486 steps/s (collection: 1.817s, learning 0.093s)
             Mean action noise std: 1.79
          Mean value_function loss: 36.0968
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.3932
                       Mean reward: 731.27
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 0.7014
    Episode_Reward/rotating_object: 146.9505
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.91s
                      Time elapsed: 00:20:20
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 51866 steps/s (collection: 1.797s, learning 0.099s)
             Mean action noise std: 1.79
          Mean value_function loss: 47.5252
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.4184
                       Mean reward: 724.54
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 0.6961
    Episode_Reward/rotating_object: 146.5119
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.90s
                      Time elapsed: 00:20:22
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 49317 steps/s (collection: 1.819s, learning 0.174s)
             Mean action noise std: 1.79
          Mean value_function loss: 45.0310
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.4415
                       Mean reward: 751.89
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.6963
    Episode_Reward/rotating_object: 147.4085
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.99s
                      Time elapsed: 00:20:24
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 48280 steps/s (collection: 1.933s, learning 0.104s)
             Mean action noise std: 1.80
          Mean value_function loss: 39.8178
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.4672
                       Mean reward: 752.08
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 0.6922
    Episode_Reward/rotating_object: 146.5234
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.04s
                      Time elapsed: 00:20:26
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 47857 steps/s (collection: 1.896s, learning 0.159s)
             Mean action noise std: 1.80
          Mean value_function loss: 40.2098
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.4746
                       Mean reward: 741.36
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 0.6948
    Episode_Reward/rotating_object: 146.1610
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.05s
                      Time elapsed: 00:20:28
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 50233 steps/s (collection: 1.843s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 47.0396
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.4937
                       Mean reward: 726.56
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 0.6861
    Episode_Reward/rotating_object: 147.9929
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 1.96s
                      Time elapsed: 00:20:30
                               ETA: 00:33:07

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 50202 steps/s (collection: 1.849s, learning 0.110s)
             Mean action noise std: 1.80
          Mean value_function loss: 39.2939
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.5133
                       Mean reward: 744.69
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 146.3558
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 1.96s
                      Time elapsed: 00:20:32
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 49824 steps/s (collection: 1.868s, learning 0.105s)
             Mean action noise std: 1.80
          Mean value_function loss: 42.0065
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.5273
                       Mean reward: 734.40
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 148.3779
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 1.97s
                      Time elapsed: 00:20:34
                               ETA: 00:33:02

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 50289 steps/s (collection: 1.862s, learning 0.093s)
             Mean action noise std: 1.81
          Mean value_function loss: 41.7648
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.5450
                       Mean reward: 726.02
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 0.6959
    Episode_Reward/rotating_object: 146.1743
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.95s
                      Time elapsed: 00:20:36
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 49705 steps/s (collection: 1.866s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 48.7071
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.5639
                       Mean reward: 749.10
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 146.4180
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.98s
                      Time elapsed: 00:20:38
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 48365 steps/s (collection: 1.917s, learning 0.116s)
             Mean action noise std: 1.81
          Mean value_function loss: 31.5109
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.5937
                       Mean reward: 777.18
               Mean episode length: 248.74
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 149.3852
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.03s
                      Time elapsed: 00:20:40
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 52036 steps/s (collection: 1.798s, learning 0.092s)
             Mean action noise std: 1.81
          Mean value_function loss: 36.2988
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.6214
                       Mean reward: 766.49
               Mean episode length: 246.95
    Episode_Reward/reaching_object: 0.7069
    Episode_Reward/rotating_object: 148.3293
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 1.89s
                      Time elapsed: 00:20:42
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 48406 steps/s (collection: 1.892s, learning 0.139s)
             Mean action noise std: 1.82
          Mean value_function loss: 41.8929
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.6433
                       Mean reward: 726.62
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.7007
    Episode_Reward/rotating_object: 145.8383
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.03s
                      Time elapsed: 00:20:44
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 52016 steps/s (collection: 1.801s, learning 0.089s)
             Mean action noise std: 1.82
          Mean value_function loss: 43.9055
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.6591
                       Mean reward: 692.72
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 0.6914
    Episode_Reward/rotating_object: 146.0646
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.89s
                      Time elapsed: 00:20:46
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 51552 steps/s (collection: 1.803s, learning 0.104s)
             Mean action noise std: 1.82
          Mean value_function loss: 40.5503
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.6782
                       Mean reward: 706.60
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 0.6983
    Episode_Reward/rotating_object: 146.4579
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.91s
                      Time elapsed: 00:20:48
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 51641 steps/s (collection: 1.769s, learning 0.134s)
             Mean action noise std: 1.82
          Mean value_function loss: 33.5149
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.6974
                       Mean reward: 741.97
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.7100
    Episode_Reward/rotating_object: 151.0078
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.90s
                      Time elapsed: 00:20:50
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 52556 steps/s (collection: 1.779s, learning 0.091s)
             Mean action noise std: 1.82
          Mean value_function loss: 44.8506
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.7115
                       Mean reward: 722.47
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 0.6941
    Episode_Reward/rotating_object: 145.4504
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.87s
                      Time elapsed: 00:20:51
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 51666 steps/s (collection: 1.808s, learning 0.095s)
             Mean action noise std: 1.83
          Mean value_function loss: 35.5214
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.7395
                       Mean reward: 757.30
               Mean episode length: 246.88
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 148.9532
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.90s
                      Time elapsed: 00:20:53
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 49672 steps/s (collection: 1.876s, learning 0.103s)
             Mean action noise std: 1.83
          Mean value_function loss: 33.6637
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.7676
                       Mean reward: 741.71
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.7058
    Episode_Reward/rotating_object: 146.5736
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.98s
                      Time elapsed: 00:20:55
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 50360 steps/s (collection: 1.852s, learning 0.100s)
             Mean action noise std: 1.83
          Mean value_function loss: 39.9439
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.7853
                       Mean reward: 756.16
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 147.4545
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.95s
                      Time elapsed: 00:20:57
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 49807 steps/s (collection: 1.881s, learning 0.093s)
             Mean action noise std: 1.83
          Mean value_function loss: 49.1291
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.8036
                       Mean reward: 762.68
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 0.7112
    Episode_Reward/rotating_object: 150.0588
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.97s
                      Time elapsed: 00:20:59
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 50497 steps/s (collection: 1.830s, learning 0.117s)
             Mean action noise std: 1.84
          Mean value_function loss: 40.5915
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.8248
                       Mean reward: 731.45
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 0.7033
    Episode_Reward/rotating_object: 149.3493
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.95s
                      Time elapsed: 00:21:01
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 51832 steps/s (collection: 1.808s, learning 0.089s)
             Mean action noise std: 1.84
          Mean value_function loss: 40.2875
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.8455
                       Mean reward: 749.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7091
    Episode_Reward/rotating_object: 145.7889
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.90s
                      Time elapsed: 00:21:03
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 47793 steps/s (collection: 1.862s, learning 0.195s)
             Mean action noise std: 1.84
          Mean value_function loss: 38.6263
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.8639
                       Mean reward: 769.34
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 150.7905
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.06s
                      Time elapsed: 00:21:05
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 48519 steps/s (collection: 1.911s, learning 0.115s)
             Mean action noise std: 1.84
          Mean value_function loss: 49.3004
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.9000
                       Mean reward: 729.66
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 0.6994
    Episode_Reward/rotating_object: 146.7520
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.03s
                      Time elapsed: 00:21:07
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 49102 steps/s (collection: 1.844s, learning 0.158s)
             Mean action noise std: 1.85
          Mean value_function loss: 46.9181
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.9258
                       Mean reward: 769.96
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7036
    Episode_Reward/rotating_object: 148.1796
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.00s
                      Time elapsed: 00:21:09
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 51556 steps/s (collection: 1.769s, learning 0.138s)
             Mean action noise std: 1.85
          Mean value_function loss: 34.3425
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.9339
                       Mean reward: 754.30
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.7159
    Episode_Reward/rotating_object: 149.6063
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 1.91s
                      Time elapsed: 00:21:11
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 51665 steps/s (collection: 1.806s, learning 0.096s)
             Mean action noise std: 1.85
          Mean value_function loss: 40.3203
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.9563
                       Mean reward: 723.00
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 0.7005
    Episode_Reward/rotating_object: 149.1729
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.90s
                      Time elapsed: 00:21:13
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 48340 steps/s (collection: 1.914s, learning 0.119s)
             Mean action noise std: 1.85
          Mean value_function loss: 38.4717
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 35.9837
                       Mean reward: 737.11
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.6951
    Episode_Reward/rotating_object: 145.1221
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.03s
                      Time elapsed: 00:21:15
                               ETA: 00:32:11

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 50645 steps/s (collection: 1.849s, learning 0.092s)
             Mean action noise std: 1.86
          Mean value_function loss: 34.2248
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 36.0054
                       Mean reward: 717.54
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 0.7064
    Episode_Reward/rotating_object: 149.1345
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 1.94s
                      Time elapsed: 00:21:17
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 48046 steps/s (collection: 1.881s, learning 0.165s)
             Mean action noise std: 1.86
          Mean value_function loss: 37.5822
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 36.0282
                       Mean reward: 751.80
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 0.7032
    Episode_Reward/rotating_object: 149.5288
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.05s
                      Time elapsed: 00:21:19
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 51096 steps/s (collection: 1.823s, learning 0.101s)
             Mean action noise std: 1.86
          Mean value_function loss: 38.2941
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.0626
                       Mean reward: 729.33
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 0.7023
    Episode_Reward/rotating_object: 149.8221
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.92s
                      Time elapsed: 00:21:21
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 51132 steps/s (collection: 1.822s, learning 0.101s)
             Mean action noise std: 1.87
          Mean value_function loss: 49.9281
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.1005
                       Mean reward: 731.45
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 0.6838
    Episode_Reward/rotating_object: 145.3255
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 1.92s
                      Time elapsed: 00:21:23
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 49849 steps/s (collection: 1.865s, learning 0.107s)
             Mean action noise std: 1.87
          Mean value_function loss: 39.3759
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.1244
                       Mean reward: 743.58
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 149.3074
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 1.97s
                      Time elapsed: 00:21:25
                               ETA: 00:31:59

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 51345 steps/s (collection: 1.818s, learning 0.097s)
             Mean action noise std: 1.87
          Mean value_function loss: 37.8654
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.1354
                       Mean reward: 739.30
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.6988
    Episode_Reward/rotating_object: 149.1782
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.91s
                      Time elapsed: 00:21:27
                               ETA: 00:31:56

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 52223 steps/s (collection: 1.791s, learning 0.092s)
             Mean action noise std: 1.87
          Mean value_function loss: 39.1787
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.1556
                       Mean reward: 743.07
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 0.6869
    Episode_Reward/rotating_object: 147.4516
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 1.88s
                      Time elapsed: 00:21:29
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 51040 steps/s (collection: 1.779s, learning 0.147s)
             Mean action noise std: 1.87
          Mean value_function loss: 45.0928
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.1759
                       Mean reward: 746.26
               Mean episode length: 242.65
    Episode_Reward/reaching_object: 0.6996
    Episode_Reward/rotating_object: 150.1029
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.93s
                      Time elapsed: 00:21:30
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 51849 steps/s (collection: 1.801s, learning 0.095s)
             Mean action noise std: 1.88
          Mean value_function loss: 42.3775
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.1916
                       Mean reward: 741.80
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 0.6938
    Episode_Reward/rotating_object: 151.1674
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 1.90s
                      Time elapsed: 00:21:32
                               ETA: 00:31:49

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 52031 steps/s (collection: 1.794s, learning 0.096s)
             Mean action noise std: 1.88
          Mean value_function loss: 44.5288
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.2121
                       Mean reward: 753.03
               Mean episode length: 247.50
    Episode_Reward/reaching_object: 0.6966
    Episode_Reward/rotating_object: 149.1203
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 1.89s
                      Time elapsed: 00:21:34
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 52224 steps/s (collection: 1.766s, learning 0.116s)
             Mean action noise std: 1.88
          Mean value_function loss: 42.2772
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.2445
                       Mean reward: 739.35
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 147.0725
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.88s
                      Time elapsed: 00:21:36
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 52472 steps/s (collection: 1.760s, learning 0.113s)
             Mean action noise std: 1.89
          Mean value_function loss: 45.2313
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.2791
                       Mean reward: 715.77
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 0.6844
    Episode_Reward/rotating_object: 146.4070
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.87s
                      Time elapsed: 00:21:38
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 50606 steps/s (collection: 1.853s, learning 0.089s)
             Mean action noise std: 1.89
          Mean value_function loss: 40.4610
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.3030
                       Mean reward: 726.23
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 0.6958
    Episode_Reward/rotating_object: 147.8024
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 1.94s
                      Time elapsed: 00:21:40
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 52278 steps/s (collection: 1.762s, learning 0.118s)
             Mean action noise std: 1.89
          Mean value_function loss: 46.7813
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 36.3227
                       Mean reward: 754.56
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 0.6785
    Episode_Reward/rotating_object: 145.9651
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.88s
                      Time elapsed: 00:21:42
                               ETA: 00:31:37

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 50956 steps/s (collection: 1.775s, learning 0.154s)
             Mean action noise std: 1.89
          Mean value_function loss: 38.6006
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.3447
                       Mean reward: 764.44
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7072
    Episode_Reward/rotating_object: 150.1802
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.93s
                      Time elapsed: 00:21:44
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 50810 steps/s (collection: 1.822s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 39.6974
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.3643
                       Mean reward: 724.91
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 147.9680
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 1.93s
                      Time elapsed: 00:21:46
                               ETA: 00:31:32

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 52374 steps/s (collection: 1.778s, learning 0.098s)
             Mean action noise std: 1.90
          Mean value_function loss: 43.1212
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.3850
                       Mean reward: 710.57
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 0.6877
    Episode_Reward/rotating_object: 145.7341
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 18.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 1.88s
                      Time elapsed: 00:21:48
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 53445 steps/s (collection: 1.744s, learning 0.096s)
             Mean action noise std: 1.90
          Mean value_function loss: 48.4214
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.4015
                       Mean reward: 738.32
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 0.6876
    Episode_Reward/rotating_object: 147.9757
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.84s
                      Time elapsed: 00:21:49
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 52543 steps/s (collection: 1.757s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 47.4861
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.4230
                       Mean reward: 734.76
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 148.5057
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.87s
                      Time elapsed: 00:21:51
                               ETA: 00:31:24

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 51955 steps/s (collection: 1.783s, learning 0.109s)
             Mean action noise std: 1.91
          Mean value_function loss: 40.2918
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.4451
                       Mean reward: 734.93
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 0.6848
    Episode_Reward/rotating_object: 145.2312
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.89s
                      Time elapsed: 00:21:53
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 50205 steps/s (collection: 1.836s, learning 0.122s)
             Mean action noise std: 1.91
          Mean value_function loss: 36.4351
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 36.4708
                       Mean reward: 761.26
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 0.6968
    Episode_Reward/rotating_object: 153.0007
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.96s
                      Time elapsed: 00:21:55
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 51189 steps/s (collection: 1.811s, learning 0.109s)
             Mean action noise std: 1.91
          Mean value_function loss: 43.1268
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.4929
                       Mean reward: 774.58
               Mean episode length: 246.22
    Episode_Reward/reaching_object: 0.6896
    Episode_Reward/rotating_object: 149.6545
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 1.92s
                      Time elapsed: 00:21:57
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 52730 steps/s (collection: 1.757s, learning 0.108s)
             Mean action noise std: 1.91
          Mean value_function loss: 46.3967
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.5110
                       Mean reward: 727.90
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 0.6887
    Episode_Reward/rotating_object: 149.2295
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 1.86s
                      Time elapsed: 00:21:59
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 52348 steps/s (collection: 1.773s, learning 0.104s)
             Mean action noise std: 1.92
          Mean value_function loss: 37.2814
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.5268
                       Mean reward: 765.00
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.6834
    Episode_Reward/rotating_object: 148.2437
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.88s
                      Time elapsed: 00:22:01
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 50438 steps/s (collection: 1.789s, learning 0.160s)
             Mean action noise std: 1.92
          Mean value_function loss: 42.5147
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 36.5417
                       Mean reward: 721.44
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 0.6774
    Episode_Reward/rotating_object: 145.8017
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 1.95s
                      Time elapsed: 00:22:03
                               ETA: 00:31:10

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 49919 steps/s (collection: 1.808s, learning 0.162s)
             Mean action noise std: 1.92
          Mean value_function loss: 38.5601
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.5552
                       Mean reward: 749.74
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 0.6827
    Episode_Reward/rotating_object: 149.3791
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 1.97s
                      Time elapsed: 00:22:05
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 50108 steps/s (collection: 1.800s, learning 0.162s)
             Mean action noise std: 1.92
          Mean value_function loss: 43.9603
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.5736
                       Mean reward: 743.82
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 0.6959
    Episode_Reward/rotating_object: 150.6426
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 1.96s
                      Time elapsed: 00:22:07
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 51839 steps/s (collection: 1.768s, learning 0.129s)
             Mean action noise std: 1.92
          Mean value_function loss: 43.2974
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.5960
                       Mean reward: 711.87
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 0.6817
    Episode_Reward/rotating_object: 145.4528
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.90s
                      Time elapsed: 00:22:09
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 52126 steps/s (collection: 1.797s, learning 0.089s)
             Mean action noise std: 1.93
          Mean value_function loss: 41.2881
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.6110
                       Mean reward: 752.03
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 0.6922
    Episode_Reward/rotating_object: 150.3701
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 1.89s
                      Time elapsed: 00:22:10
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 51486 steps/s (collection: 1.799s, learning 0.110s)
             Mean action noise std: 1.93
          Mean value_function loss: 45.4014
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.6263
                       Mean reward: 779.46
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6960
    Episode_Reward/rotating_object: 151.9495
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.91s
                      Time elapsed: 00:22:12
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 51066 steps/s (collection: 1.832s, learning 0.093s)
             Mean action noise std: 1.93
          Mean value_function loss: 42.4494
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.6445
                       Mean reward: 752.52
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 148.6646
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.93s
                      Time elapsed: 00:22:14
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 50949 steps/s (collection: 1.820s, learning 0.110s)
             Mean action noise std: 1.93
          Mean value_function loss: 44.6822
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.6695
                       Mean reward: 754.24
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.6888
    Episode_Reward/rotating_object: 147.5566
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.93s
                      Time elapsed: 00:22:16
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 52276 steps/s (collection: 1.766s, learning 0.115s)
             Mean action noise std: 1.93
          Mean value_function loss: 49.5131
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.6883
                       Mean reward: 760.89
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.6947
    Episode_Reward/rotating_object: 150.0393
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.88s
                      Time elapsed: 00:22:18
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 49576 steps/s (collection: 1.860s, learning 0.123s)
             Mean action noise std: 1.94
          Mean value_function loss: 50.7055
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 36.7047
                       Mean reward: 757.46
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 0.6909
    Episode_Reward/rotating_object: 149.2160
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.98s
                      Time elapsed: 00:22:20
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 52141 steps/s (collection: 1.776s, learning 0.110s)
             Mean action noise std: 1.94
          Mean value_function loss: 42.9952
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.7127
                       Mean reward: 735.59
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 0.6864
    Episode_Reward/rotating_object: 147.3835
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.89s
                      Time elapsed: 00:22:22
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 52811 steps/s (collection: 1.769s, learning 0.092s)
             Mean action noise std: 1.94
          Mean value_function loss: 49.1358
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.7323
                       Mean reward: 745.77
               Mean episode length: 244.34
    Episode_Reward/reaching_object: 0.6911
    Episode_Reward/rotating_object: 149.1961
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.86s
                      Time elapsed: 00:22:24
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 49389 steps/s (collection: 1.882s, learning 0.108s)
             Mean action noise std: 1.94
          Mean value_function loss: 45.8221
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.7499
                       Mean reward: 759.81
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.6996
    Episode_Reward/rotating_object: 150.5743
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.99s
                      Time elapsed: 00:22:26
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 50954 steps/s (collection: 1.840s, learning 0.089s)
             Mean action noise std: 1.94
          Mean value_function loss: 49.0100
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 36.7592
                       Mean reward: 757.94
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 0.6879
    Episode_Reward/rotating_object: 151.4898
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.93s
                      Time elapsed: 00:22:28
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 49411 steps/s (collection: 1.868s, learning 0.121s)
             Mean action noise std: 1.94
          Mean value_function loss: 43.0276
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.7716
                       Mean reward: 747.51
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.6889
    Episode_Reward/rotating_object: 148.9756
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.99s
                      Time elapsed: 00:22:30
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 48432 steps/s (collection: 1.914s, learning 0.116s)
             Mean action noise std: 1.95
          Mean value_function loss: 43.3300
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.7840
                       Mean reward: 760.45
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.6847
    Episode_Reward/rotating_object: 148.9502
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.03s
                      Time elapsed: 00:22:32
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 48938 steps/s (collection: 1.882s, learning 0.127s)
             Mean action noise std: 1.95
          Mean value_function loss: 50.2663
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.8078
                       Mean reward: 757.80
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.6749
    Episode_Reward/rotating_object: 147.2486
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.01s
                      Time elapsed: 00:22:34
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 48813 steps/s (collection: 1.862s, learning 0.152s)
             Mean action noise std: 1.95
          Mean value_function loss: 42.7020
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.8466
                       Mean reward: 732.16
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.6798
    Episode_Reward/rotating_object: 152.4921
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.01s
                      Time elapsed: 00:22:36
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 51612 steps/s (collection: 1.815s, learning 0.090s)
             Mean action noise std: 1.96
          Mean value_function loss: 35.8625
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 36.8728
                       Mean reward: 762.10
               Mean episode length: 248.39
    Episode_Reward/reaching_object: 0.6880
    Episode_Reward/rotating_object: 151.4392
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.90s
                      Time elapsed: 00:22:38
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 48764 steps/s (collection: 1.858s, learning 0.158s)
             Mean action noise std: 1.96
          Mean value_function loss: 47.0537
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.8836
                       Mean reward: 761.62
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.6723
    Episode_Reward/rotating_object: 148.3084
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.02s
                      Time elapsed: 00:22:40
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 50795 steps/s (collection: 1.795s, learning 0.141s)
             Mean action noise std: 1.96
          Mean value_function loss: 46.7099
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.8916
                       Mean reward: 736.48
               Mean episode length: 242.07
    Episode_Reward/reaching_object: 0.6733
    Episode_Reward/rotating_object: 149.0024
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.94s
                      Time elapsed: 00:22:42
                               ETA: 00:30:22

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 52252 steps/s (collection: 1.783s, learning 0.099s)
             Mean action noise std: 1.96
          Mean value_function loss: 39.1818
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.9055
                       Mean reward: 750.29
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 0.6699
    Episode_Reward/rotating_object: 148.2065
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.88s
                      Time elapsed: 00:22:44
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 49177 steps/s (collection: 1.827s, learning 0.172s)
             Mean action noise std: 1.96
          Mean value_function loss: 45.1345
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 36.9260
                       Mean reward: 736.44
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 0.6596
    Episode_Reward/rotating_object: 146.8000
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.00s
                      Time elapsed: 00:22:46
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 49566 steps/s (collection: 1.887s, learning 0.096s)
             Mean action noise std: 1.97
          Mean value_function loss: 49.4666
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.9425
                       Mean reward: 736.22
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 0.6638
    Episode_Reward/rotating_object: 147.2538
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 1.98s
                      Time elapsed: 00:22:48
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 51802 steps/s (collection: 1.807s, learning 0.091s)
             Mean action noise std: 1.97
          Mean value_function loss: 56.7383
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.9615
                       Mean reward: 739.40
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 0.6454
    Episode_Reward/rotating_object: 145.6866
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 1.90s
                      Time elapsed: 00:22:49
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 50271 steps/s (collection: 1.856s, learning 0.099s)
             Mean action noise std: 1.97
          Mean value_function loss: 48.6370
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.9834
                       Mean reward: 711.07
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 0.6718
    Episode_Reward/rotating_object: 146.9269
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.96s
                      Time elapsed: 00:22:51
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 51018 steps/s (collection: 1.829s, learning 0.098s)
             Mean action noise std: 1.97
          Mean value_function loss: 63.0625
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.9961
                       Mean reward: 735.14
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 0.6680
    Episode_Reward/rotating_object: 147.1525
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 1.93s
                      Time elapsed: 00:22:53
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 51452 steps/s (collection: 1.810s, learning 0.101s)
             Mean action noise std: 1.97
          Mean value_function loss: 64.5903
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 37.0109
                       Mean reward: 763.86
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 149.9662
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 1.91s
                      Time elapsed: 00:22:55
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 51117 steps/s (collection: 1.819s, learning 0.105s)
             Mean action noise std: 1.97
          Mean value_function loss: 42.8139
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.0197
                       Mean reward: 759.60
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.6748
    Episode_Reward/rotating_object: 146.9132
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 1.92s
                      Time elapsed: 00:22:57
                               ETA: 00:30:03

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 49370 steps/s (collection: 1.894s, learning 0.098s)
             Mean action noise std: 1.98
          Mean value_function loss: 43.9085
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.0357
                       Mean reward: 775.70
               Mean episode length: 249.45
    Episode_Reward/reaching_object: 0.6812
    Episode_Reward/rotating_object: 147.2403
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 1.99s
                      Time elapsed: 00:22:59
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 46836 steps/s (collection: 1.866s, learning 0.233s)
             Mean action noise std: 1.98
          Mean value_function loss: 47.3324
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.0484
                       Mean reward: 734.43
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 0.6644
    Episode_Reward/rotating_object: 147.4770
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.10s
                      Time elapsed: 00:23:01
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 52742 steps/s (collection: 1.757s, learning 0.107s)
             Mean action noise std: 1.98
          Mean value_function loss: 43.4289
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.0615
                       Mean reward: 735.30
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.6867
    Episode_Reward/rotating_object: 149.1277
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.86s
                      Time elapsed: 00:23:03
                               ETA: 00:29:56

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 50583 steps/s (collection: 1.813s, learning 0.130s)
             Mean action noise std: 1.98
          Mean value_function loss: 53.9464
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.0823
                       Mean reward: 700.11
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.6809
    Episode_Reward/rotating_object: 148.3995
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.94s
                      Time elapsed: 00:23:05
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 52498 steps/s (collection: 1.765s, learning 0.107s)
             Mean action noise std: 1.98
          Mean value_function loss: 45.7395
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.0948
                       Mean reward: 755.91
               Mean episode length: 243.02
    Episode_Reward/reaching_object: 0.6798
    Episode_Reward/rotating_object: 149.4011
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.87s
                      Time elapsed: 00:23:07
                               ETA: 00:29:51

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 51038 steps/s (collection: 1.811s, learning 0.115s)
             Mean action noise std: 1.99
          Mean value_function loss: 42.4138
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.1216
                       Mean reward: 737.45
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 0.6865
    Episode_Reward/rotating_object: 151.0439
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.93s
                      Time elapsed: 00:23:09
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 52125 steps/s (collection: 1.790s, learning 0.096s)
             Mean action noise std: 1.99
          Mean value_function loss: 48.5753
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.1550
                       Mean reward: 719.88
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 0.6775
    Episode_Reward/rotating_object: 145.8729
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.89s
                      Time elapsed: 00:23:11
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 51003 steps/s (collection: 1.829s, learning 0.099s)
             Mean action noise std: 1.99
          Mean value_function loss: 36.7578
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.1846
                       Mean reward: 770.70
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 0.6960
    Episode_Reward/rotating_object: 149.4753
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.93s
                      Time elapsed: 00:23:13
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 51891 steps/s (collection: 1.800s, learning 0.095s)
             Mean action noise std: 2.00
          Mean value_function loss: 40.3644
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.2109
                       Mean reward: 766.87
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 0.6760
    Episode_Reward/rotating_object: 149.3785
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.89s
                      Time elapsed: 00:23:15
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 51768 steps/s (collection: 1.785s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 45.1830
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.2325
                       Mean reward: 770.32
               Mean episode length: 247.64
    Episode_Reward/reaching_object: 0.6922
    Episode_Reward/rotating_object: 151.2985
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.90s
                      Time elapsed: 00:23:16
                               ETA: 00:29:40

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 51232 steps/s (collection: 1.800s, learning 0.119s)
             Mean action noise std: 2.00
          Mean value_function loss: 45.1714
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.2533
                       Mean reward: 754.52
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 0.6743
    Episode_Reward/rotating_object: 147.6110
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.92s
                      Time elapsed: 00:23:18
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 51070 steps/s (collection: 1.811s, learning 0.114s)
             Mean action noise std: 2.01
          Mean value_function loss: 40.4418
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.2746
                       Mean reward: 763.80
               Mean episode length: 246.12
    Episode_Reward/reaching_object: 0.6857
    Episode_Reward/rotating_object: 150.1563
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.92s
                      Time elapsed: 00:23:20
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 49571 steps/s (collection: 1.890s, learning 0.094s)
             Mean action noise std: 2.01
          Mean value_function loss: 42.9016
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.2968
                       Mean reward: 734.58
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 0.6858
    Episode_Reward/rotating_object: 149.5482
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.98s
                      Time elapsed: 00:23:22
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 51971 steps/s (collection: 1.798s, learning 0.094s)
             Mean action noise std: 2.01
          Mean value_function loss: 36.7487
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 37.3135
                       Mean reward: 761.78
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 0.6845
    Episode_Reward/rotating_object: 150.8473
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.89s
                      Time elapsed: 00:23:24
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 51998 steps/s (collection: 1.799s, learning 0.091s)
             Mean action noise std: 2.01
          Mean value_function loss: 33.9076
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.3272
                       Mean reward: 751.83
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 0.6850
    Episode_Reward/rotating_object: 151.1273
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.89s
                      Time elapsed: 00:23:26
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 52264 steps/s (collection: 1.757s, learning 0.124s)
             Mean action noise std: 2.01
          Mean value_function loss: 48.4426
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.3491
                       Mean reward: 747.53
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 0.6831
    Episode_Reward/rotating_object: 148.8714
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.88s
                      Time elapsed: 00:23:28
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 29492 steps/s (collection: 3.229s, learning 0.105s)
             Mean action noise std: 2.02
          Mean value_function loss: 46.3466
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.3714
                       Mean reward: 766.15
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.6807
    Episode_Reward/rotating_object: 151.0564
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.33s
                      Time elapsed: 00:23:31
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14588 steps/s (collection: 6.566s, learning 0.173s)
             Mean action noise std: 2.02
          Mean value_function loss: 37.6451
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 37.3971
                       Mean reward: 777.69
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.6838
    Episode_Reward/rotating_object: 151.2209
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.74s
                      Time elapsed: 00:23:38
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14838 steps/s (collection: 6.488s, learning 0.137s)
             Mean action noise std: 2.02
          Mean value_function loss: 43.0644
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 37.4244
                       Mean reward: 760.67
               Mean episode length: 247.29
    Episode_Reward/reaching_object: 0.6824
    Episode_Reward/rotating_object: 150.7984
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.62s
                      Time elapsed: 00:23:45
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14711 steps/s (collection: 6.564s, learning 0.118s)
             Mean action noise std: 2.03
          Mean value_function loss: 43.7196
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.4390
                       Mean reward: 740.03
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 0.6767
    Episode_Reward/rotating_object: 147.8506
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.68s
                      Time elapsed: 00:23:51
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14997 steps/s (collection: 6.413s, learning 0.141s)
             Mean action noise std: 2.03
          Mean value_function loss: 57.2203
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.4660
                       Mean reward: 708.46
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 0.6670
    Episode_Reward/rotating_object: 144.6314
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.55s
                      Time elapsed: 00:23:58
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14852 steps/s (collection: 6.486s, learning 0.133s)
             Mean action noise std: 2.03
          Mean value_function loss: 37.4453
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.4857
                       Mean reward: 753.24
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 0.6764
    Episode_Reward/rotating_object: 148.9459
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.62s
                      Time elapsed: 00:24:04
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14515 steps/s (collection: 6.631s, learning 0.141s)
             Mean action noise std: 2.03
          Mean value_function loss: 32.1881
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.5039
                       Mean reward: 760.80
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 150.5439
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.77s
                      Time elapsed: 00:24:11
                               ETA: 00:29:46

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 15163 steps/s (collection: 6.342s, learning 0.141s)
             Mean action noise std: 2.03
          Mean value_function loss: 33.3134
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.5184
                       Mean reward: 756.33
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 0.6877
    Episode_Reward/rotating_object: 151.8454
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.48s
                      Time elapsed: 00:24:18
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14550 steps/s (collection: 6.589s, learning 0.167s)
             Mean action noise std: 2.04
          Mean value_function loss: 42.0009
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.5371
                       Mean reward: 750.37
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.6814
    Episode_Reward/rotating_object: 150.2443
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.76s
                      Time elapsed: 00:24:24
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 23415 steps/s (collection: 4.109s, learning 0.090s)
             Mean action noise std: 2.04
          Mean value_function loss: 32.3217
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.5625
                       Mean reward: 761.39
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.6830
    Episode_Reward/rotating_object: 151.8797
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.20s
                      Time elapsed: 00:24:29
                               ETA: 00:29:53

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 53029 steps/s (collection: 1.764s, learning 0.090s)
             Mean action noise std: 2.04
          Mean value_function loss: 42.2005
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.5904
                       Mean reward: 747.71
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 0.6762
    Episode_Reward/rotating_object: 149.4542
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.85s
                      Time elapsed: 00:24:31
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 51004 steps/s (collection: 1.809s, learning 0.119s)
             Mean action noise std: 2.05
          Mean value_function loss: 44.9092
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.6154
                       Mean reward: 700.49
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 0.6753
    Episode_Reward/rotating_object: 148.8438
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.93s
                      Time elapsed: 00:24:32
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 47156 steps/s (collection: 1.972s, learning 0.113s)
             Mean action noise std: 2.05
          Mean value_function loss: 39.0747
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.6357
                       Mean reward: 781.99
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.6835
    Episode_Reward/rotating_object: 155.0365
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.08s
                      Time elapsed: 00:24:35
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 51207 steps/s (collection: 1.759s, learning 0.161s)
             Mean action noise std: 2.05
          Mean value_function loss: 38.1882
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.6609
                       Mean reward: 740.91
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 0.6706
    Episode_Reward/rotating_object: 148.7238
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.92s
                      Time elapsed: 00:24:36
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 53248 steps/s (collection: 1.740s, learning 0.107s)
             Mean action noise std: 2.05
          Mean value_function loss: 41.5762
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.6769
                       Mean reward: 766.46
               Mean episode length: 248.53
    Episode_Reward/reaching_object: 0.6793
    Episode_Reward/rotating_object: 151.3934
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.85s
                      Time elapsed: 00:24:38
                               ETA: 00:29:40

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 53043 steps/s (collection: 1.733s, learning 0.121s)
             Mean action noise std: 2.06
          Mean value_function loss: 38.5316
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.6917
                       Mean reward: 764.30
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.6667
    Episode_Reward/rotating_object: 151.9189
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.85s
                      Time elapsed: 00:24:40
                               ETA: 00:29:38

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 52966 steps/s (collection: 1.745s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 46.3454
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.7180
                       Mean reward: 733.64
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 0.6616
    Episode_Reward/rotating_object: 147.5504
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.86s
                      Time elapsed: 00:24:42
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 52299 steps/s (collection: 1.768s, learning 0.112s)
             Mean action noise std: 2.06
          Mean value_function loss: 40.5898
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.7494
                       Mean reward: 745.90
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 0.6610
    Episode_Reward/rotating_object: 146.6784
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.88s
                      Time elapsed: 00:24:44
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 52406 steps/s (collection: 1.763s, learning 0.113s)
             Mean action noise std: 2.07
          Mean value_function loss: 38.4313
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.7735
                       Mean reward: 741.64
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.6730
    Episode_Reward/rotating_object: 148.1455
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.88s
                      Time elapsed: 00:24:46
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 53514 steps/s (collection: 1.731s, learning 0.106s)
             Mean action noise std: 2.07
          Mean value_function loss: 40.9009
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 37.7898
                       Mean reward: 767.77
               Mean episode length: 246.50
    Episode_Reward/reaching_object: 0.6623
    Episode_Reward/rotating_object: 149.1590
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.84s
                      Time elapsed: 00:24:48
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 50173 steps/s (collection: 1.840s, learning 0.120s)
             Mean action noise std: 2.07
          Mean value_function loss: 52.0060
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 37.8007
                       Mean reward: 754.49
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 0.6706
    Episode_Reward/rotating_object: 149.7659
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.96s
                      Time elapsed: 00:24:50
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 52473 steps/s (collection: 1.750s, learning 0.123s)
             Mean action noise std: 2.07
          Mean value_function loss: 43.3786
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.8271
                       Mean reward: 749.87
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 0.6762
    Episode_Reward/rotating_object: 148.9409
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.87s
                      Time elapsed: 00:24:51
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 51911 steps/s (collection: 1.725s, learning 0.169s)
             Mean action noise std: 2.08
          Mean value_function loss: 53.6584
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 37.8538
                       Mean reward: 739.04
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 0.6626
    Episode_Reward/rotating_object: 146.8099
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.89s
                      Time elapsed: 00:24:53
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 53197 steps/s (collection: 1.728s, learning 0.120s)
             Mean action noise std: 2.08
          Mean value_function loss: 54.7173
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.8637
                       Mean reward: 742.44
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 0.6729
    Episode_Reward/rotating_object: 148.6862
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.85s
                      Time elapsed: 00:24:55
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 52752 steps/s (collection: 1.748s, learning 0.116s)
             Mean action noise std: 2.08
          Mean value_function loss: 50.4622
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.8826
                       Mean reward: 764.29
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.6681
    Episode_Reward/rotating_object: 147.5026
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.86s
                      Time elapsed: 00:24:57
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 52337 steps/s (collection: 1.770s, learning 0.108s)
             Mean action noise std: 2.08
          Mean value_function loss: 52.5261
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.9139
                       Mean reward: 774.93
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.6643
    Episode_Reward/rotating_object: 147.8487
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.88s
                      Time elapsed: 00:24:59
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 53599 steps/s (collection: 1.747s, learning 0.088s)
             Mean action noise std: 2.09
          Mean value_function loss: 49.4389
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.9483
                       Mean reward: 732.17
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 0.6685
    Episode_Reward/rotating_object: 149.5690
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.83s
                      Time elapsed: 00:25:01
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 52278 steps/s (collection: 1.754s, learning 0.127s)
             Mean action noise std: 2.09
          Mean value_function loss: 50.9586
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.9645
                       Mean reward: 745.80
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 0.6753
    Episode_Reward/rotating_object: 150.1866
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.88s
                      Time elapsed: 00:25:03
                               ETA: 00:29:07

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 52191 steps/s (collection: 1.726s, learning 0.157s)
             Mean action noise std: 2.09
          Mean value_function loss: 49.4577
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.9804
                       Mean reward: 749.74
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 146.8770
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.88s
                      Time elapsed: 00:25:05
                               ETA: 00:29:05

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 52075 steps/s (collection: 1.761s, learning 0.127s)
             Mean action noise std: 2.09
          Mean value_function loss: 41.6710
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.9961
                       Mean reward: 761.49
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 0.6653
    Episode_Reward/rotating_object: 145.6130
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.89s
                      Time elapsed: 00:25:06
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 53091 steps/s (collection: 1.759s, learning 0.093s)
             Mean action noise std: 2.10
          Mean value_function loss: 53.4601
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.0066
                       Mean reward: 733.79
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 148.0848
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.85s
                      Time elapsed: 00:25:08
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 53064 steps/s (collection: 1.744s, learning 0.109s)
             Mean action noise std: 2.10
          Mean value_function loss: 56.7314
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.0225
                       Mean reward: 737.45
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 0.6418
    Episode_Reward/rotating_object: 144.2820
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.85s
                      Time elapsed: 00:25:10
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 54155 steps/s (collection: 1.729s, learning 0.087s)
             Mean action noise std: 2.10
          Mean value_function loss: 41.0056
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.0375
                       Mean reward: 743.34
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.6596
    Episode_Reward/rotating_object: 147.4914
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.82s
                      Time elapsed: 00:25:12
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 51085 steps/s (collection: 1.824s, learning 0.100s)
             Mean action noise std: 2.10
          Mean value_function loss: 43.2509
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 38.0586
                       Mean reward: 754.10
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 150.9792
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.92s
                      Time elapsed: 00:25:14
                               ETA: 00:28:52

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 52090 steps/s (collection: 1.750s, learning 0.138s)
             Mean action noise std: 2.10
          Mean value_function loss: 34.5730
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.0832
                       Mean reward: 729.90
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 147.4109
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.89s
                      Time elapsed: 00:25:16
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 52607 steps/s (collection: 1.746s, learning 0.123s)
             Mean action noise std: 2.11
          Mean value_function loss: 36.7967
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.0944
                       Mean reward: 745.71
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.6613
    Episode_Reward/rotating_object: 150.4423
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.87s
                      Time elapsed: 00:25:18
                               ETA: 00:28:47

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 52324 steps/s (collection: 1.747s, learning 0.132s)
             Mean action noise std: 2.11
          Mean value_function loss: 40.0964
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.1140
                       Mean reward: 739.63
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 147.7615
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.88s
                      Time elapsed: 00:25:20
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 52894 steps/s (collection: 1.749s, learning 0.110s)
             Mean action noise std: 2.11
          Mean value_function loss: 32.9607
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.1406
                       Mean reward: 769.44
               Mean episode length: 248.23
    Episode_Reward/reaching_object: 0.6673
    Episode_Reward/rotating_object: 152.0334
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.86s
                      Time elapsed: 00:25:21
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 51815 steps/s (collection: 1.784s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 44.8366
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.1616
                       Mean reward: 749.04
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 0.6497
    Episode_Reward/rotating_object: 147.5679
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.90s
                      Time elapsed: 00:25:23
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 52496 steps/s (collection: 1.765s, learning 0.108s)
             Mean action noise std: 2.12
          Mean value_function loss: 47.5789
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.1843
                       Mean reward: 730.35
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 0.6586
    Episode_Reward/rotating_object: 148.6828
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.87s
                      Time elapsed: 00:25:25
                               ETA: 00:28:37

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 51878 steps/s (collection: 1.778s, learning 0.117s)
             Mean action noise std: 2.12
          Mean value_function loss: 42.5288
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.2000
                       Mean reward: 761.34
               Mean episode length: 247.47
    Episode_Reward/reaching_object: 0.6635
    Episode_Reward/rotating_object: 150.8895
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.89s
                      Time elapsed: 00:25:27
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 53853 steps/s (collection: 1.721s, learning 0.105s)
             Mean action noise std: 2.12
          Mean value_function loss: 30.6000
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.2105
                       Mean reward: 764.64
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 0.6629
    Episode_Reward/rotating_object: 151.4334
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.83s
                      Time elapsed: 00:25:29
                               ETA: 00:28:32

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 52648 steps/s (collection: 1.756s, learning 0.111s)
             Mean action noise std: 2.12
          Mean value_function loss: 36.8934
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.2214
                       Mean reward: 774.34
               Mean episode length: 245.29
    Episode_Reward/reaching_object: 0.6585
    Episode_Reward/rotating_object: 149.9456
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.87s
                      Time elapsed: 00:25:31
                               ETA: 00:28:30

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 51972 steps/s (collection: 1.732s, learning 0.159s)
             Mean action noise std: 2.12
          Mean value_function loss: 45.9767
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.2297
                       Mean reward: 762.29
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 0.6612
    Episode_Reward/rotating_object: 151.7897
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.89s
                      Time elapsed: 00:25:33
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 48484 steps/s (collection: 1.895s, learning 0.132s)
             Mean action noise std: 2.13
          Mean value_function loss: 44.3100
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.2423
                       Mean reward: 772.09
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.6641
    Episode_Reward/rotating_object: 150.5398
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.03s
                      Time elapsed: 00:25:35
                               ETA: 00:28:25

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 51278 steps/s (collection: 1.767s, learning 0.150s)
             Mean action noise std: 2.13
          Mean value_function loss: 46.4983
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.2639
                       Mean reward: 730.26
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 0.6704
    Episode_Reward/rotating_object: 153.1086
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.92s
                      Time elapsed: 00:25:37
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 52254 steps/s (collection: 1.782s, learning 0.100s)
             Mean action noise std: 2.13
          Mean value_function loss: 48.6328
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.2918
                       Mean reward: 734.32
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 0.6539
    Episode_Reward/rotating_object: 150.2728
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.88s
                      Time elapsed: 00:25:38
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 52504 steps/s (collection: 1.769s, learning 0.103s)
             Mean action noise std: 2.14
          Mean value_function loss: 37.6933
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.3210
                       Mean reward: 761.80
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 0.6699
    Episode_Reward/rotating_object: 151.2276
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.87s
                      Time elapsed: 00:25:40
                               ETA: 00:28:18

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 52185 steps/s (collection: 1.761s, learning 0.123s)
             Mean action noise std: 2.14
          Mean value_function loss: 42.1693
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 38.3417
                       Mean reward: 736.96
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 0.6627
    Episode_Reward/rotating_object: 152.2585
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.88s
                      Time elapsed: 00:25:42
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 53351 steps/s (collection: 1.720s, learning 0.123s)
             Mean action noise std: 2.14
          Mean value_function loss: 47.9208
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.3580
                       Mean reward: 719.37
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 0.6550
    Episode_Reward/rotating_object: 147.6742
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.84s
                      Time elapsed: 00:25:44
                               ETA: 00:28:13

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 54343 steps/s (collection: 1.716s, learning 0.093s)
             Mean action noise std: 2.14
          Mean value_function loss: 51.2053
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 38.3747
                       Mean reward: 752.49
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 0.6509
    Episode_Reward/rotating_object: 148.1680
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.81s
                      Time elapsed: 00:25:46
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 52299 steps/s (collection: 1.763s, learning 0.117s)
             Mean action noise std: 2.14
          Mean value_function loss: 35.8704
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.3800
                       Mean reward: 781.74
               Mean episode length: 249.23
    Episode_Reward/reaching_object: 0.6616
    Episode_Reward/rotating_object: 152.4072
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.88s
                      Time elapsed: 00:25:48
                               ETA: 00:28:08

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 52310 steps/s (collection: 1.745s, learning 0.134s)
             Mean action noise std: 2.15
          Mean value_function loss: 57.1233
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.3960
                       Mean reward: 718.46
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 149.4862
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.88s
                      Time elapsed: 00:25:50
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 53246 steps/s (collection: 1.757s, learning 0.089s)
             Mean action noise std: 2.15
          Mean value_function loss: 44.8066
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.4224
                       Mean reward: 723.63
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 149.0292
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.85s
                      Time elapsed: 00:25:51
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 53623 steps/s (collection: 1.730s, learning 0.104s)
             Mean action noise std: 2.15
          Mean value_function loss: 37.8192
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.4469
                       Mean reward: 781.69
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 151.2669
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.83s
                      Time elapsed: 00:25:53
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 50329 steps/s (collection: 1.840s, learning 0.113s)
             Mean action noise std: 2.15
          Mean value_function loss: 39.4435
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.4627
                       Mean reward: 755.02
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 149.0988
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.95s
                      Time elapsed: 00:25:55
                               ETA: 00:27:58

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 51912 steps/s (collection: 1.782s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 31.6948
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.4801
                       Mean reward: 766.03
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 152.1064
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.89s
                      Time elapsed: 00:25:57
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 51888 steps/s (collection: 1.782s, learning 0.112s)
             Mean action noise std: 2.16
          Mean value_function loss: 48.7755
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.4849
                       Mean reward: 753.43
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 147.5647
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.89s
                      Time elapsed: 00:25:59
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 51170 steps/s (collection: 1.822s, learning 0.100s)
             Mean action noise std: 2.16
          Mean value_function loss: 51.1134
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.4978
                       Mean reward: 727.59
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 0.6487
    Episode_Reward/rotating_object: 146.2055
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.92s
                      Time elapsed: 00:26:01
                               ETA: 00:27:51

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 52593 steps/s (collection: 1.736s, learning 0.133s)
             Mean action noise std: 2.16
          Mean value_function loss: 36.7780
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 38.5135
                       Mean reward: 722.48
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 0.6554
    Episode_Reward/rotating_object: 147.4883
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.87s
                      Time elapsed: 00:26:03
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 51270 steps/s (collection: 1.805s, learning 0.112s)
             Mean action noise std: 2.16
          Mean value_function loss: 42.6433
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.5200
                       Mean reward: 737.01
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.6542
    Episode_Reward/rotating_object: 149.0245
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.92s
                      Time elapsed: 00:26:05
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 53858 steps/s (collection: 1.723s, learning 0.103s)
             Mean action noise std: 2.16
          Mean value_function loss: 54.3305
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.5355
                       Mean reward: 731.67
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 0.6557
    Episode_Reward/rotating_object: 148.5753
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.83s
                      Time elapsed: 00:26:07
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 52615 steps/s (collection: 1.758s, learning 0.110s)
             Mean action noise std: 2.17
          Mean value_function loss: 37.1953
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.5562
                       Mean reward: 716.40
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.6642
    Episode_Reward/rotating_object: 147.8080
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.87s
                      Time elapsed: 00:26:08
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 52011 steps/s (collection: 1.791s, learning 0.099s)
             Mean action noise std: 2.17
          Mean value_function loss: 50.2686
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.5805
                       Mean reward: 767.39
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.6595
    Episode_Reward/rotating_object: 149.9809
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.89s
                      Time elapsed: 00:26:10
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 53264 steps/s (collection: 1.750s, learning 0.096s)
             Mean action noise std: 2.17
          Mean value_function loss: 43.5189
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.5965
                       Mean reward: 759.05
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 0.6631
    Episode_Reward/rotating_object: 150.2427
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.85s
                      Time elapsed: 00:26:12
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 51130 steps/s (collection: 1.823s, learning 0.100s)
             Mean action noise std: 2.17
          Mean value_function loss: 41.4281
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.6063
                       Mean reward: 782.93
               Mean episode length: 249.05
    Episode_Reward/reaching_object: 0.6676
    Episode_Reward/rotating_object: 150.4179
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.92s
                      Time elapsed: 00:26:14
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 52792 steps/s (collection: 1.743s, learning 0.119s)
             Mean action noise std: 2.17
          Mean value_function loss: 42.9155
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.6176
                       Mean reward: 761.19
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.6595
    Episode_Reward/rotating_object: 145.8290
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.86s
                      Time elapsed: 00:26:16
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 51578 steps/s (collection: 1.789s, learning 0.117s)
             Mean action noise std: 2.18
          Mean value_function loss: 47.5979
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.6277
                       Mean reward: 768.57
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 0.6773
    Episode_Reward/rotating_object: 152.9549
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.91s
                      Time elapsed: 00:26:18
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 51778 steps/s (collection: 1.762s, learning 0.137s)
             Mean action noise std: 2.18
          Mean value_function loss: 45.3134
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.6388
                       Mean reward: 753.81
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 0.6647
    Episode_Reward/rotating_object: 149.6310
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.90s
                      Time elapsed: 00:26:20
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 53630 steps/s (collection: 1.743s, learning 0.090s)
             Mean action noise std: 2.18
          Mean value_function loss: 50.0197
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.6532
                       Mean reward: 728.14
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 0.6581
    Episode_Reward/rotating_object: 145.9839
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.83s
                      Time elapsed: 00:26:22
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 52485 steps/s (collection: 1.777s, learning 0.096s)
             Mean action noise std: 2.18
          Mean value_function loss: 33.3578
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.6697
                       Mean reward: 773.52
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.6779
    Episode_Reward/rotating_object: 151.3989
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.87s
                      Time elapsed: 00:26:23
                               ETA: 00:27:21

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 52038 steps/s (collection: 1.784s, learning 0.105s)
             Mean action noise std: 2.18
          Mean value_function loss: 38.3493
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.6830
                       Mean reward: 743.62
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 149.9875
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.89s
                      Time elapsed: 00:26:25
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 52357 steps/s (collection: 1.764s, learning 0.114s)
             Mean action noise std: 2.19
          Mean value_function loss: 41.0235
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.7012
                       Mean reward: 768.86
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.6693
    Episode_Reward/rotating_object: 151.3384
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.88s
                      Time elapsed: 00:26:27
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 53459 steps/s (collection: 1.740s, learning 0.099s)
             Mean action noise std: 2.19
          Mean value_function loss: 47.0062
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.7275
                       Mean reward: 759.09
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 0.6607
    Episode_Reward/rotating_object: 150.4053
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.84s
                      Time elapsed: 00:26:29
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 52752 steps/s (collection: 1.768s, learning 0.095s)
             Mean action noise std: 2.19
          Mean value_function loss: 35.6312
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.7498
                       Mean reward: 767.42
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.6712
    Episode_Reward/rotating_object: 151.9263
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.86s
                      Time elapsed: 00:26:31
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 51929 steps/s (collection: 1.787s, learning 0.106s)
             Mean action noise std: 2.19
          Mean value_function loss: 40.6610
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.7680
                       Mean reward: 730.69
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 0.6618
    Episode_Reward/rotating_object: 149.4916
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.89s
                      Time elapsed: 00:26:33
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 52754 steps/s (collection: 1.766s, learning 0.097s)
             Mean action noise std: 2.20
          Mean value_function loss: 44.0243
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.7903
                       Mean reward: 728.77
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 0.6675
    Episode_Reward/rotating_object: 149.5771
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.86s
                      Time elapsed: 00:26:35
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 52955 steps/s (collection: 1.747s, learning 0.110s)
             Mean action noise std: 2.20
          Mean value_function loss: 40.3513
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.8046
                       Mean reward: 752.54
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 151.8243
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.86s
                      Time elapsed: 00:26:37
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 53056 steps/s (collection: 1.757s, learning 0.096s)
             Mean action noise std: 2.20
          Mean value_function loss: 34.8239
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 38.8218
                       Mean reward: 776.37
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.6709
    Episode_Reward/rotating_object: 153.1826
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.85s
                      Time elapsed: 00:26:38
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 54338 steps/s (collection: 1.712s, learning 0.097s)
             Mean action noise std: 2.20
          Mean value_function loss: 30.3504
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.8356
                       Mean reward: 780.12
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 152.0510
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.81s
                      Time elapsed: 00:26:40
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 52665 steps/s (collection: 1.758s, learning 0.108s)
             Mean action noise std: 2.21
          Mean value_function loss: 38.2849
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.8497
                       Mean reward: 777.52
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 151.5873
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.87s
                      Time elapsed: 00:26:42
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 51763 steps/s (collection: 1.796s, learning 0.103s)
             Mean action noise std: 2.21
          Mean value_function loss: 42.1492
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.8687
                       Mean reward: 766.55
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 0.6677
    Episode_Reward/rotating_object: 153.1909
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.90s
                      Time elapsed: 00:26:44
                               ETA: 00:26:55

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 50624 steps/s (collection: 1.845s, learning 0.097s)
             Mean action noise std: 2.21
          Mean value_function loss: 37.4801
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.8803
                       Mean reward: 770.07
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 0.6646
    Episode_Reward/rotating_object: 151.0589
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.94s
                      Time elapsed: 00:26:46
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 52396 steps/s (collection: 1.763s, learning 0.114s)
             Mean action noise std: 2.21
          Mean value_function loss: 39.9337
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 38.8959
                       Mean reward: 761.46
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.6713
    Episode_Reward/rotating_object: 154.0867
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.88s
                      Time elapsed: 00:26:48
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 51440 steps/s (collection: 1.785s, learning 0.126s)
             Mean action noise std: 2.21
          Mean value_function loss: 46.9343
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.9091
                       Mean reward: 751.42
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.6670
    Episode_Reward/rotating_object: 150.4552
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.91s
                      Time elapsed: 00:26:50
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 50782 steps/s (collection: 1.821s, learning 0.115s)
             Mean action noise std: 2.22
          Mean value_function loss: 50.8897
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.9303
                       Mean reward: 762.58
               Mean episode length: 245.25
    Episode_Reward/reaching_object: 0.6555
    Episode_Reward/rotating_object: 150.1848
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.94s
                      Time elapsed: 00:26:52
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 50287 steps/s (collection: 1.851s, learning 0.104s)
             Mean action noise std: 2.22
          Mean value_function loss: 44.1216
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.9555
                       Mean reward: 742.87
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 0.6598
    Episode_Reward/rotating_object: 147.8635
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.95s
                      Time elapsed: 00:26:54
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 51693 steps/s (collection: 1.812s, learning 0.090s)
             Mean action noise std: 2.22
          Mean value_function loss: 32.5523
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.9849
                       Mean reward: 761.90
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 0.6675
    Episode_Reward/rotating_object: 155.1225
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.90s
                      Time elapsed: 00:26:55
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 49844 steps/s (collection: 1.833s, learning 0.139s)
             Mean action noise std: 2.23
          Mean value_function loss: 31.7135
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.0145
                       Mean reward: 793.28
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 154.3618
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.97s
                      Time elapsed: 00:26:57
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 51697 steps/s (collection: 1.811s, learning 0.090s)
             Mean action noise std: 2.23
          Mean value_function loss: 49.4333
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.0389
                       Mean reward: 769.14
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 0.6679
    Episode_Reward/rotating_object: 151.6891
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.90s
                      Time elapsed: 00:26:59
                               ETA: 00:26:36

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 51243 steps/s (collection: 1.802s, learning 0.117s)
             Mean action noise std: 2.23
          Mean value_function loss: 37.7408
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.0610
                       Mean reward: 778.34
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.6649
    Episode_Reward/rotating_object: 152.8962
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.92s
                      Time elapsed: 00:27:01
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 52843 steps/s (collection: 1.759s, learning 0.101s)
             Mean action noise std: 2.24
          Mean value_function loss: 45.6103
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.0851
                       Mean reward: 760.34
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.6639
    Episode_Reward/rotating_object: 149.9034
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.86s
                      Time elapsed: 00:27:03
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 52431 steps/s (collection: 1.778s, learning 0.096s)
             Mean action noise std: 2.24
          Mean value_function loss: 43.0781
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.1122
                       Mean reward: 778.21
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 0.6599
    Episode_Reward/rotating_object: 152.3184
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.87s
                      Time elapsed: 00:27:05
                               ETA: 00:26:29

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 52689 steps/s (collection: 1.738s, learning 0.128s)
             Mean action noise std: 2.24
          Mean value_function loss: 44.1591
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.1390
                       Mean reward: 762.27
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 0.6659
    Episode_Reward/rotating_object: 151.9738
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.87s
                      Time elapsed: 00:27:07
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 52263 steps/s (collection: 1.762s, learning 0.119s)
             Mean action noise std: 2.25
          Mean value_function loss: 47.0470
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.1540
                       Mean reward: 767.39
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 0.6625
    Episode_Reward/rotating_object: 149.0287
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.88s
                      Time elapsed: 00:27:09
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 52884 steps/s (collection: 1.747s, learning 0.112s)
             Mean action noise std: 2.25
          Mean value_function loss: 37.4582
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.1669
                       Mean reward: 773.06
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 0.6652
    Episode_Reward/rotating_object: 152.2793
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.86s
                      Time elapsed: 00:27:11
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 50880 steps/s (collection: 1.812s, learning 0.120s)
             Mean action noise std: 2.25
          Mean value_function loss: 58.0674
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.1870
                       Mean reward: 749.27
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 0.6679
    Episode_Reward/rotating_object: 150.5601
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.93s
                      Time elapsed: 00:27:13
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 52818 steps/s (collection: 1.765s, learning 0.096s)
             Mean action noise std: 2.25
          Mean value_function loss: 37.8641
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.2121
                       Mean reward: 752.89
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 0.6651
    Episode_Reward/rotating_object: 152.8396
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.86s
                      Time elapsed: 00:27:14
                               ETA: 00:26:17

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 51552 steps/s (collection: 1.781s, learning 0.126s)
             Mean action noise std: 2.26
          Mean value_function loss: 47.7004
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.2451
                       Mean reward: 745.02
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.6691
    Episode_Reward/rotating_object: 150.3840
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.91s
                      Time elapsed: 00:27:16
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 53174 steps/s (collection: 1.762s, learning 0.087s)
             Mean action noise std: 2.26
          Mean value_function loss: 34.0696
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.2638
                       Mean reward: 777.03
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.6672
    Episode_Reward/rotating_object: 152.9468
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.85s
                      Time elapsed: 00:27:18
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 52427 steps/s (collection: 1.744s, learning 0.131s)
             Mean action noise std: 2.26
          Mean value_function loss: 48.1920
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.2824
                       Mean reward: 747.31
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 0.6651
    Episode_Reward/rotating_object: 148.9875
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.88s
                      Time elapsed: 00:27:20
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 49527 steps/s (collection: 1.860s, learning 0.125s)
             Mean action noise std: 2.27
          Mean value_function loss: 49.5025
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.3016
                       Mean reward: 764.77
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 0.6690
    Episode_Reward/rotating_object: 150.3873
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.98s
                      Time elapsed: 00:27:22
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 53785 steps/s (collection: 1.720s, learning 0.108s)
             Mean action noise std: 2.27
          Mean value_function loss: 44.9360
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 39.3168
                       Mean reward: 758.06
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 0.6582
    Episode_Reward/rotating_object: 148.1817
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.83s
                      Time elapsed: 00:27:24
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 52043 steps/s (collection: 1.752s, learning 0.137s)
             Mean action noise std: 2.27
          Mean value_function loss: 41.1695
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.3294
                       Mean reward: 775.39
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.6619
    Episode_Reward/rotating_object: 150.9815
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.89s
                      Time elapsed: 00:27:26
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 49273 steps/s (collection: 1.903s, learning 0.092s)
             Mean action noise std: 2.27
          Mean value_function loss: 33.8470
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.3534
                       Mean reward: 792.37
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 153.3176
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.00s
                      Time elapsed: 00:27:28
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 51690 steps/s (collection: 1.792s, learning 0.110s)
             Mean action noise std: 2.28
          Mean value_function loss: 51.3033
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.3754
                       Mean reward: 751.48
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 0.6515
    Episode_Reward/rotating_object: 149.3587
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.90s
                      Time elapsed: 00:27:30
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 51273 steps/s (collection: 1.806s, learning 0.111s)
             Mean action noise std: 2.28
          Mean value_function loss: 40.9558
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.3964
                       Mean reward: 740.79
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 0.6441
    Episode_Reward/rotating_object: 148.4126
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.92s
                      Time elapsed: 00:27:32
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 51967 steps/s (collection: 1.780s, learning 0.112s)
             Mean action noise std: 2.28
          Mean value_function loss: 48.1882
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.4110
                       Mean reward: 759.39
               Mean episode length: 241.25
    Episode_Reward/reaching_object: 0.6517
    Episode_Reward/rotating_object: 150.9679
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.89s
                      Time elapsed: 00:27:33
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 51575 steps/s (collection: 1.796s, learning 0.110s)
             Mean action noise std: 2.29
          Mean value_function loss: 44.9294
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.4356
                       Mean reward: 735.45
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 0.6423
    Episode_Reward/rotating_object: 146.7283
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.91s
                      Time elapsed: 00:27:35
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 51384 steps/s (collection: 1.802s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 59.4208
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.4548
                       Mean reward: 779.67
               Mean episode length: 244.20
    Episode_Reward/reaching_object: 0.6435
    Episode_Reward/rotating_object: 151.3332
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.91s
                      Time elapsed: 00:27:37
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 51046 steps/s (collection: 1.807s, learning 0.119s)
             Mean action noise std: 2.29
          Mean value_function loss: 40.0085
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.4645
                       Mean reward: 776.34
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 0.6468
    Episode_Reward/rotating_object: 151.6083
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.93s
                      Time elapsed: 00:27:39
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 51246 steps/s (collection: 1.775s, learning 0.144s)
             Mean action noise std: 2.29
          Mean value_function loss: 37.3085
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.4795
                       Mean reward: 753.75
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 0.6522
    Episode_Reward/rotating_object: 153.8107
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.92s
                      Time elapsed: 00:27:41
                               ETA: 00:25:44

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 49660 steps/s (collection: 1.862s, learning 0.118s)
             Mean action noise std: 2.29
          Mean value_function loss: 39.5021
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.4991
                       Mean reward: 730.66
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 0.6515
    Episode_Reward/rotating_object: 147.0885
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.98s
                      Time elapsed: 00:27:43
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 52345 steps/s (collection: 1.767s, learning 0.111s)
             Mean action noise std: 2.30
          Mean value_function loss: 35.5611
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.5215
                       Mean reward: 757.17
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.6536
    Episode_Reward/rotating_object: 154.0035
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.88s
                      Time elapsed: 00:27:45
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 50118 steps/s (collection: 1.863s, learning 0.099s)
             Mean action noise std: 2.30
          Mean value_function loss: 46.7801
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.5460
                       Mean reward: 770.48
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.6535
    Episode_Reward/rotating_object: 153.6866
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 1.96s
                      Time elapsed: 00:27:47
                               ETA: 00:25:37

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 50275 steps/s (collection: 1.843s, learning 0.112s)
             Mean action noise std: 2.30
          Mean value_function loss: 47.7996
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.5704
                       Mean reward: 769.54
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.6504
    Episode_Reward/rotating_object: 151.0641
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.96s
                      Time elapsed: 00:27:49
                               ETA: 00:25:34

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 50972 steps/s (collection: 1.813s, learning 0.116s)
             Mean action noise std: 2.31
          Mean value_function loss: 63.5527
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.5943
                       Mean reward: 750.75
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.6394
    Episode_Reward/rotating_object: 149.0414
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.93s
                      Time elapsed: 00:27:51
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 52786 steps/s (collection: 1.771s, learning 0.091s)
             Mean action noise std: 2.31
          Mean value_function loss: 57.4813
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.6108
                       Mean reward: 764.13
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 0.6377
    Episode_Reward/rotating_object: 148.9538
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.86s
                      Time elapsed: 00:27:53
                               ETA: 00:25:30

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 51964 steps/s (collection: 1.802s, learning 0.090s)
             Mean action noise std: 2.31
          Mean value_function loss: 56.7803
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.6171
                       Mean reward: 716.92
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 0.6272
    Episode_Reward/rotating_object: 146.6050
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.89s
                      Time elapsed: 00:27:55
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 52251 steps/s (collection: 1.776s, learning 0.106s)
             Mean action noise std: 2.31
          Mean value_function loss: 36.6218
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.6295
                       Mean reward: 763.39
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.6371
    Episode_Reward/rotating_object: 148.2173
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.88s
                      Time elapsed: 00:27:56
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 49156 steps/s (collection: 1.909s, learning 0.091s)
             Mean action noise std: 2.32
          Mean value_function loss: 44.8626
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.6595
                       Mean reward: 759.93
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 0.6443
    Episode_Reward/rotating_object: 148.7500
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.00s
                      Time elapsed: 00:27:58
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 52482 steps/s (collection: 1.767s, learning 0.106s)
             Mean action noise std: 2.32
          Mean value_function loss: 37.8416
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.6963
                       Mean reward: 769.91
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.6509
    Episode_Reward/rotating_object: 152.5273
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.87s
                      Time elapsed: 00:28:00
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 52127 steps/s (collection: 1.791s, learning 0.095s)
             Mean action noise std: 2.32
          Mean value_function loss: 44.4686
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.7269
                       Mean reward: 734.58
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 0.6459
    Episode_Reward/rotating_object: 148.0964
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.89s
                      Time elapsed: 00:28:02
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 49428 steps/s (collection: 1.863s, learning 0.126s)
             Mean action noise std: 2.33
          Mean value_function loss: 47.9253
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.7372
                       Mean reward: 738.85
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 151.2382
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 1.99s
                      Time elapsed: 00:28:04
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 49555 steps/s (collection: 1.849s, learning 0.134s)
             Mean action noise std: 2.33
          Mean value_function loss: 48.5004
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.7471
                       Mean reward: 760.22
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.6498
    Episode_Reward/rotating_object: 151.5372
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 1.98s
                      Time elapsed: 00:28:06
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 48203 steps/s (collection: 1.894s, learning 0.145s)
             Mean action noise std: 2.33
          Mean value_function loss: 31.9393
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.7593
                       Mean reward: 764.81
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.6558
    Episode_Reward/rotating_object: 153.2187
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.04s
                      Time elapsed: 00:28:08
                               ETA: 00:25:11

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 50309 steps/s (collection: 1.800s, learning 0.154s)
             Mean action noise std: 2.33
          Mean value_function loss: 48.3233
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.7774
                       Mean reward: 763.10
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 0.6440
    Episode_Reward/rotating_object: 151.7451
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.95s
                      Time elapsed: 00:28:10
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 50265 steps/s (collection: 1.789s, learning 0.167s)
             Mean action noise std: 2.34
          Mean value_function loss: 57.1524
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.7927
                       Mean reward: 723.89
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 0.6460
    Episode_Reward/rotating_object: 149.3135
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.96s
                      Time elapsed: 00:28:12
                               ETA: 00:25:07

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 51097 steps/s (collection: 1.812s, learning 0.112s)
             Mean action noise std: 2.34
          Mean value_function loss: 44.5751
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.8134
                       Mean reward: 785.62
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.6396
    Episode_Reward/rotating_object: 148.1396
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.92s
                      Time elapsed: 00:28:14
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 49259 steps/s (collection: 1.843s, learning 0.153s)
             Mean action noise std: 2.34
          Mean value_function loss: 55.6151
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.8418
                       Mean reward: 767.00
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 150.5051
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.00s
                      Time elapsed: 00:28:16
                               ETA: 00:25:02

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 48997 steps/s (collection: 1.849s, learning 0.158s)
             Mean action noise std: 2.35
          Mean value_function loss: 42.6272
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.8709
                       Mean reward: 748.82
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 0.6304
    Episode_Reward/rotating_object: 148.4054
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.01s
                      Time elapsed: 00:28:18
                               ETA: 00:25:00

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 48537 steps/s (collection: 1.896s, learning 0.129s)
             Mean action noise std: 2.35
          Mean value_function loss: 45.7923
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 39.8931
                       Mean reward: 727.15
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 0.6493
    Episode_Reward/rotating_object: 150.0960
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.03s
                      Time elapsed: 00:28:20
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 50877 steps/s (collection: 1.809s, learning 0.123s)
             Mean action noise std: 2.35
          Mean value_function loss: 52.1157
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.9097
                       Mean reward: 761.37
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.6450
    Episode_Reward/rotating_object: 150.1595
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.93s
                      Time elapsed: 00:28:22
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 47343 steps/s (collection: 1.936s, learning 0.140s)
             Mean action noise std: 2.35
          Mean value_function loss: 46.0138
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.9360
                       Mean reward: 766.99
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.6486
    Episode_Reward/rotating_object: 150.6513
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.08s
                      Time elapsed: 00:28:24
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 48119 steps/s (collection: 1.929s, learning 0.113s)
             Mean action noise std: 2.36
          Mean value_function loss: 45.8446
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.9609
                       Mean reward: 781.59
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 0.6447
    Episode_Reward/rotating_object: 150.4709
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.04s
                      Time elapsed: 00:28:26
                               ETA: 00:24:51

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 46972 steps/s (collection: 1.935s, learning 0.158s)
             Mean action noise std: 2.36
          Mean value_function loss: 41.5208
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.9738
                       Mean reward: 747.15
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 0.6430
    Episode_Reward/rotating_object: 149.7100
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.09s
                      Time elapsed: 00:28:28
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 50482 steps/s (collection: 1.803s, learning 0.145s)
             Mean action noise std: 2.36
          Mean value_function loss: 44.3528
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.9879
                       Mean reward: 758.00
               Mean episode length: 244.68
    Episode_Reward/reaching_object: 0.6480
    Episode_Reward/rotating_object: 152.2910
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.95s
                      Time elapsed: 00:28:30
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 50093 steps/s (collection: 1.846s, learning 0.116s)
             Mean action noise std: 2.36
          Mean value_function loss: 37.3907
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.0039
                       Mean reward: 778.50
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 153.4348
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.96s
                      Time elapsed: 00:28:32
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 48501 steps/s (collection: 1.832s, learning 0.195s)
             Mean action noise std: 2.36
          Mean value_function loss: 53.0719
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.0127
                       Mean reward: 735.99
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 149.4419
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.03s
                      Time elapsed: 00:28:34
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 48504 steps/s (collection: 1.919s, learning 0.108s)
             Mean action noise std: 2.37
          Mean value_function loss: 39.8804
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.0185
                       Mean reward: 741.10
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 0.6359
    Episode_Reward/rotating_object: 150.1596
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.03s
                      Time elapsed: 00:28:36
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 51436 steps/s (collection: 1.787s, learning 0.125s)
             Mean action noise std: 2.37
          Mean value_function loss: 45.8928
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.0256
                       Mean reward: 746.12
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 0.6497
    Episode_Reward/rotating_object: 153.8100
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.91s
                      Time elapsed: 00:28:38
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 48597 steps/s (collection: 1.903s, learning 0.120s)
             Mean action noise std: 2.37
          Mean value_function loss: 51.5804
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.0459
                       Mean reward: 778.30
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 0.6461
    Episode_Reward/rotating_object: 152.2077
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.02s
                      Time elapsed: 00:28:40
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 45455 steps/s (collection: 1.998s, learning 0.165s)
             Mean action noise std: 2.38
          Mean value_function loss: 44.1183
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.0690
                       Mean reward: 753.58
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 0.6509
    Episode_Reward/rotating_object: 150.7319
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.16s
                      Time elapsed: 00:28:42
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 48814 steps/s (collection: 1.910s, learning 0.104s)
             Mean action noise std: 2.38
          Mean value_function loss: 41.4186
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.0988
                       Mean reward: 775.26
               Mean episode length: 247.30
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 153.1573
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.01s
                      Time elapsed: 00:28:44
                               ETA: 00:24:31

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 49839 steps/s (collection: 1.813s, learning 0.160s)
             Mean action noise std: 2.38
          Mean value_function loss: 40.9331
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.1186
                       Mean reward: 758.75
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 151.4504
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.97s
                      Time elapsed: 00:28:46
                               ETA: 00:24:29

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 51217 steps/s (collection: 1.824s, learning 0.095s)
             Mean action noise std: 2.38
          Mean value_function loss: 46.8674
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.1356
                       Mean reward: 728.22
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.6599
    Episode_Reward/rotating_object: 150.3107
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.92s
                      Time elapsed: 00:28:48
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 48502 steps/s (collection: 1.886s, learning 0.141s)
             Mean action noise std: 2.39
          Mean value_function loss: 53.2981
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.1579
                       Mean reward: 762.21
               Mean episode length: 239.80
    Episode_Reward/reaching_object: 0.6439
    Episode_Reward/rotating_object: 150.8662
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.03s
                      Time elapsed: 00:28:50
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 47709 steps/s (collection: 1.966s, learning 0.095s)
             Mean action noise std: 2.39
          Mean value_function loss: 52.6731
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.1854
                       Mean reward: 742.85
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 0.6493
    Episode_Reward/rotating_object: 151.4214
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.06s
                      Time elapsed: 00:28:52
                               ETA: 00:24:22

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 51094 steps/s (collection: 1.794s, learning 0.130s)
             Mean action noise std: 2.40
          Mean value_function loss: 41.0219
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.2182
                       Mean reward: 765.78
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 0.6655
    Episode_Reward/rotating_object: 154.0510
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.92s
                      Time elapsed: 00:28:54
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 51812 steps/s (collection: 1.782s, learning 0.115s)
             Mean action noise std: 2.40
          Mean value_function loss: 53.8082
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.2452
                       Mean reward: 780.72
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 0.6549
    Episode_Reward/rotating_object: 150.1171
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.90s
                      Time elapsed: 00:28:56
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 52044 steps/s (collection: 1.791s, learning 0.098s)
             Mean action noise std: 2.40
          Mean value_function loss: 47.5725
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.2615
                       Mean reward: 766.07
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 148.4595
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.89s
                      Time elapsed: 00:28:58
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 50707 steps/s (collection: 1.826s, learning 0.113s)
             Mean action noise std: 2.40
          Mean value_function loss: 47.9206
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.2799
                       Mean reward: 770.20
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 0.6588
    Episode_Reward/rotating_object: 147.5206
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.94s
                      Time elapsed: 00:29:00
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 51965 steps/s (collection: 1.794s, learning 0.098s)
             Mean action noise std: 2.41
          Mean value_function loss: 51.3227
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.3057
                       Mean reward: 723.91
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 151.0062
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.89s
                      Time elapsed: 00:29:02
                               ETA: 00:24:10

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 48702 steps/s (collection: 1.848s, learning 0.171s)
             Mean action noise std: 2.41
          Mean value_function loss: 51.6165
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.3271
                       Mean reward: 774.42
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 0.6567
    Episode_Reward/rotating_object: 150.4272
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.02s
                      Time elapsed: 00:29:04
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 51053 steps/s (collection: 1.827s, learning 0.098s)
             Mean action noise std: 2.41
          Mean value_function loss: 48.9028
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.3463
                       Mean reward: 785.52
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.6553
    Episode_Reward/rotating_object: 151.5798
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.93s
                      Time elapsed: 00:29:06
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 49716 steps/s (collection: 1.868s, learning 0.110s)
             Mean action noise std: 2.42
          Mean value_function loss: 72.6137
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.3672
                       Mean reward: 730.59
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 146.4906
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.98s
                      Time elapsed: 00:29:08
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 50249 steps/s (collection: 1.824s, learning 0.133s)
             Mean action noise std: 2.42
          Mean value_function loss: 47.4708
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.3872
                       Mean reward: 762.28
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 148.2590
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.96s
                      Time elapsed: 00:29:10
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 51972 steps/s (collection: 1.778s, learning 0.113s)
             Mean action noise std: 2.42
          Mean value_function loss: 42.2461
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.4075
                       Mean reward: 765.17
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 153.9718
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.89s
                      Time elapsed: 00:29:12
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 50468 steps/s (collection: 1.843s, learning 0.105s)
             Mean action noise std: 2.42
          Mean value_function loss: 54.0683
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.4235
                       Mean reward: 759.59
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 150.7538
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.95s
                      Time elapsed: 00:29:14
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 51506 steps/s (collection: 1.769s, learning 0.140s)
             Mean action noise std: 2.43
          Mean value_function loss: 52.5853
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.4448
                       Mean reward: 763.80
               Mean episode length: 246.92
    Episode_Reward/reaching_object: 0.6474
    Episode_Reward/rotating_object: 146.2963
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.91s
                      Time elapsed: 00:29:15
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 50820 steps/s (collection: 1.782s, learning 0.153s)
             Mean action noise std: 2.43
          Mean value_function loss: 45.2715
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.4761
                       Mean reward: 763.99
               Mean episode length: 244.73
    Episode_Reward/reaching_object: 0.6580
    Episode_Reward/rotating_object: 151.6856
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.93s
                      Time elapsed: 00:29:17
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 50070 steps/s (collection: 1.810s, learning 0.153s)
             Mean action noise std: 2.43
          Mean value_function loss: 41.6981
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.5041
                       Mean reward: 755.36
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 0.6627
    Episode_Reward/rotating_object: 149.2925
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.96s
                      Time elapsed: 00:29:19
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 49753 steps/s (collection: 1.841s, learning 0.135s)
             Mean action noise std: 2.44
          Mean value_function loss: 50.7828
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.5234
                       Mean reward: 767.01
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 0.6347
    Episode_Reward/rotating_object: 148.0099
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.98s
                      Time elapsed: 00:29:21
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 50257 steps/s (collection: 1.824s, learning 0.132s)
             Mean action noise std: 2.44
          Mean value_function loss: 33.5603
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 40.5418
                       Mean reward: 749.31
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 147.6246
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.96s
                      Time elapsed: 00:29:23
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 52369 steps/s (collection: 1.782s, learning 0.095s)
             Mean action noise std: 2.44
          Mean value_function loss: 64.9742
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.5590
                       Mean reward: 720.91
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 0.6364
    Episode_Reward/rotating_object: 144.3239
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.88s
                      Time elapsed: 00:29:25
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 51334 steps/s (collection: 1.808s, learning 0.107s)
             Mean action noise std: 2.45
          Mean value_function loss: 46.6574
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.5813
                       Mean reward: 760.11
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 0.6464
    Episode_Reward/rotating_object: 152.4249
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.91s
                      Time elapsed: 00:29:27
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 52549 steps/s (collection: 1.771s, learning 0.100s)
             Mean action noise std: 2.45
          Mean value_function loss: 45.6451
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.6119
                       Mean reward: 750.17
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 0.6449
    Episode_Reward/rotating_object: 149.8282
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.87s
                      Time elapsed: 00:29:29
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 51925 steps/s (collection: 1.806s, learning 0.087s)
             Mean action noise std: 2.45
          Mean value_function loss: 44.0810
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.6278
                       Mean reward: 760.10
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.6562
    Episode_Reward/rotating_object: 150.1823
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.89s
                      Time elapsed: 00:29:31
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 49697 steps/s (collection: 1.868s, learning 0.110s)
             Mean action noise std: 2.45
          Mean value_function loss: 46.7681
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.6406
                       Mean reward: 741.82
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 0.6453
    Episode_Reward/rotating_object: 148.5685
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.98s
                      Time elapsed: 00:29:33
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 51116 steps/s (collection: 1.799s, learning 0.124s)
             Mean action noise std: 2.46
          Mean value_function loss: 32.7577
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.6569
                       Mean reward: 738.69
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 0.6495
    Episode_Reward/rotating_object: 150.1481
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.92s
                      Time elapsed: 00:29:35
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 51310 steps/s (collection: 1.775s, learning 0.141s)
             Mean action noise std: 2.46
          Mean value_function loss: 45.8903
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.6692
                       Mean reward: 768.46
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 150.7233
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.92s
                      Time elapsed: 00:29:37
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 50725 steps/s (collection: 1.794s, learning 0.144s)
             Mean action noise std: 2.46
          Mean value_function loss: 42.3545
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.6830
                       Mean reward: 734.67
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 0.6513
    Episode_Reward/rotating_object: 151.4214
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.94s
                      Time elapsed: 00:29:39
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 50158 steps/s (collection: 1.843s, learning 0.117s)
             Mean action noise std: 2.46
          Mean value_function loss: 45.9880
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.7003
                       Mean reward: 762.13
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 0.6563
    Episode_Reward/rotating_object: 152.0392
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.96s
                      Time elapsed: 00:29:41
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 51056 steps/s (collection: 1.838s, learning 0.088s)
             Mean action noise std: 2.47
          Mean value_function loss: 46.0027
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 40.7133
                       Mean reward: 736.66
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 0.6530
    Episode_Reward/rotating_object: 148.8839
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.93s
                      Time elapsed: 00:29:42
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 52122 steps/s (collection: 1.786s, learning 0.100s)
             Mean action noise std: 2.47
          Mean value_function loss: 53.1916
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.7332
                       Mean reward: 758.59
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 0.6687
    Episode_Reward/rotating_object: 151.2077
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.89s
                      Time elapsed: 00:29:44
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 52078 steps/s (collection: 1.765s, learning 0.123s)
             Mean action noise std: 2.47
          Mean value_function loss: 53.6108
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.7499
                       Mean reward: 763.63
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.6733
    Episode_Reward/rotating_object: 152.5523
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.89s
                      Time elapsed: 00:29:46
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 52588 steps/s (collection: 1.768s, learning 0.101s)
             Mean action noise std: 2.47
          Mean value_function loss: 52.1572
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.7630
                       Mean reward: 754.92
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 0.6583
    Episode_Reward/rotating_object: 148.2610
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.87s
                      Time elapsed: 00:29:48
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 52882 steps/s (collection: 1.762s, learning 0.097s)
             Mean action noise std: 2.48
          Mean value_function loss: 39.8733
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.7807
                       Mean reward: 762.04
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.6770
    Episode_Reward/rotating_object: 152.3326
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.86s
                      Time elapsed: 00:29:50
                               ETA: 00:23:13

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 53291 steps/s (collection: 1.752s, learning 0.093s)
             Mean action noise std: 2.48
          Mean value_function loss: 38.5115
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.8035
                       Mean reward: 760.65
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 0.6660
    Episode_Reward/rotating_object: 150.3531
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.84s
                      Time elapsed: 00:29:52
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 52187 steps/s (collection: 1.774s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 47.3025
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.8234
                       Mean reward: 749.54
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 149.4652
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.88s
                      Time elapsed: 00:29:54
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 52953 steps/s (collection: 1.738s, learning 0.118s)
             Mean action noise std: 2.48
          Mean value_function loss: 67.9782
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.8381
                       Mean reward: 740.89
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 0.6580
    Episode_Reward/rotating_object: 149.6435
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.86s
                      Time elapsed: 00:29:56
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 51591 steps/s (collection: 1.769s, learning 0.137s)
             Mean action noise std: 2.49
          Mean value_function loss: 52.6181
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.8610
                       Mean reward: 729.01
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 0.6576
    Episode_Reward/rotating_object: 146.1554
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.91s
                      Time elapsed: 00:29:57
                               ETA: 00:23:04

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 52349 steps/s (collection: 1.744s, learning 0.134s)
             Mean action noise std: 2.49
          Mean value_function loss: 44.5519
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.8745
                       Mean reward: 722.87
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 0.6590
    Episode_Reward/rotating_object: 148.4962
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.88s
                      Time elapsed: 00:29:59
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 52324 steps/s (collection: 1.778s, learning 0.101s)
             Mean action noise std: 2.49
          Mean value_function loss: 39.8158
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 40.8869
                       Mean reward: 773.38
               Mean episode length: 247.36
    Episode_Reward/reaching_object: 0.6659
    Episode_Reward/rotating_object: 152.6463
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.88s
                      Time elapsed: 00:30:01
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 50805 steps/s (collection: 1.790s, learning 0.145s)
             Mean action noise std: 2.49
          Mean value_function loss: 49.0811
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 40.8890
                       Mean reward: 758.75
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 0.6600
    Episode_Reward/rotating_object: 151.0334
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.93s
                      Time elapsed: 00:30:03
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 47292 steps/s (collection: 1.961s, learning 0.118s)
             Mean action noise std: 2.49
          Mean value_function loss: 55.0777
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.8937
                       Mean reward: 743.54
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 0.6540
    Episode_Reward/rotating_object: 149.1621
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.08s
                      Time elapsed: 00:30:05
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 47516 steps/s (collection: 1.921s, learning 0.148s)
             Mean action noise std: 2.49
          Mean value_function loss: 55.2843
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 40.9069
                       Mean reward: 763.61
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.6592
    Episode_Reward/rotating_object: 150.1950
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.07s
                      Time elapsed: 00:30:07
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 49077 steps/s (collection: 1.877s, learning 0.126s)
             Mean action noise std: 2.50
          Mean value_function loss: 59.6250
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.9263
                       Mean reward: 745.33
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 150.2558
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.00s
                      Time elapsed: 00:30:09
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 47834 steps/s (collection: 1.877s, learning 0.178s)
             Mean action noise std: 2.50
          Mean value_function loss: 59.6452
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.9527
                       Mean reward: 779.64
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 149.0589
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.06s
                      Time elapsed: 00:30:11
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 48696 steps/s (collection: 1.889s, learning 0.130s)
             Mean action noise std: 2.51
          Mean value_function loss: 41.2414
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.9796
                       Mean reward: 768.32
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 150.9350
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.02s
                      Time elapsed: 00:30:13
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 48036 steps/s (collection: 1.881s, learning 0.166s)
             Mean action noise std: 2.51
          Mean value_function loss: 43.7644
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 40.9990
                       Mean reward: 762.43
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 0.6492
    Episode_Reward/rotating_object: 147.9301
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.05s
                      Time elapsed: 00:30:15
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 52520 steps/s (collection: 1.772s, learning 0.100s)
             Mean action noise std: 2.51
          Mean value_function loss: 44.8185
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.0137
                       Mean reward: 765.38
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 0.6589
    Episode_Reward/rotating_object: 152.8972
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.87s
                      Time elapsed: 00:30:17
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 52923 steps/s (collection: 1.769s, learning 0.088s)
             Mean action noise std: 2.51
          Mean value_function loss: 43.5489
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.0324
                       Mean reward: 760.62
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.6531
    Episode_Reward/rotating_object: 150.6254
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 1.86s
                      Time elapsed: 00:30:19
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 52254 steps/s (collection: 1.775s, learning 0.107s)
             Mean action noise std: 2.52
          Mean value_function loss: 41.6048
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.0473
                       Mean reward: 744.19
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 151.9511
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.88s
                      Time elapsed: 00:30:21
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 52816 steps/s (collection: 1.765s, learning 0.097s)
             Mean action noise std: 2.52
          Mean value_function loss: 33.0121
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.0736
                       Mean reward: 782.66
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 151.5898
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 1.86s
                      Time elapsed: 00:30:23
                               ETA: 00:22:35

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 52928 steps/s (collection: 1.766s, learning 0.091s)
             Mean action noise std: 2.52
          Mean value_function loss: 38.3262
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.1007
                       Mean reward: 763.46
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.6609
    Episode_Reward/rotating_object: 151.2693
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 1.86s
                      Time elapsed: 00:30:25
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 52939 steps/s (collection: 1.761s, learning 0.096s)
             Mean action noise std: 2.52
          Mean value_function loss: 47.4249
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.1137
                       Mean reward: 734.14
               Mean episode length: 236.25
    Episode_Reward/reaching_object: 0.6457
    Episode_Reward/rotating_object: 147.1486
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.86s
                      Time elapsed: 00:30:27
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 51887 steps/s (collection: 1.775s, learning 0.119s)
             Mean action noise std: 2.53
          Mean value_function loss: 41.0272
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.1247
                       Mean reward: 743.90
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 0.6443
    Episode_Reward/rotating_object: 150.1535
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.89s
                      Time elapsed: 00:30:29
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 52598 steps/s (collection: 1.773s, learning 0.096s)
             Mean action noise std: 2.53
          Mean value_function loss: 40.4226
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.1374
                       Mean reward: 759.83
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 0.6484
    Episode_Reward/rotating_object: 150.4443
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.87s
                      Time elapsed: 00:30:30
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 53397 steps/s (collection: 1.751s, learning 0.090s)
             Mean action noise std: 2.53
          Mean value_function loss: 43.8974
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.1529
                       Mean reward: 770.82
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 0.6657
    Episode_Reward/rotating_object: 152.7944
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.84s
                      Time elapsed: 00:30:32
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 51822 steps/s (collection: 1.779s, learning 0.118s)
             Mean action noise std: 2.53
          Mean value_function loss: 52.7897
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 41.1748
                       Mean reward: 755.94
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 0.6583
    Episode_Reward/rotating_object: 152.0321
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.90s
                      Time elapsed: 00:30:34
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 52486 steps/s (collection: 1.774s, learning 0.098s)
             Mean action noise std: 2.54
          Mean value_function loss: 53.2375
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.1954
                       Mean reward: 760.37
               Mean episode length: 240.96
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 151.5601
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.87s
                      Time elapsed: 00:30:36
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 50943 steps/s (collection: 1.819s, learning 0.111s)
             Mean action noise std: 2.54
          Mean value_function loss: 55.1519
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.2064
                       Mean reward: 746.31
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 0.6508
    Episode_Reward/rotating_object: 148.0105
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.93s
                      Time elapsed: 00:30:38
                               ETA: 00:22:17

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 52616 steps/s (collection: 1.777s, learning 0.091s)
             Mean action noise std: 2.54
          Mean value_function loss: 49.9187
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.2202
                       Mean reward: 735.70
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 0.6587
    Episode_Reward/rotating_object: 151.1168
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.87s
                      Time elapsed: 00:30:40
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 51352 steps/s (collection: 1.798s, learning 0.116s)
             Mean action noise std: 2.54
          Mean value_function loss: 46.5068
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.2327
                       Mean reward: 751.86
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 0.6644
    Episode_Reward/rotating_object: 152.3612
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.91s
                      Time elapsed: 00:30:42
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 50916 steps/s (collection: 1.779s, learning 0.152s)
             Mean action noise std: 2.54
          Mean value_function loss: 50.9788
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.2421
                       Mean reward: 719.38
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 0.6557
    Episode_Reward/rotating_object: 147.7356
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.93s
                      Time elapsed: 00:30:44
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 51463 steps/s (collection: 1.769s, learning 0.141s)
             Mean action noise std: 2.55
          Mean value_function loss: 47.1035
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.2602
                       Mean reward: 749.90
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 0.6703
    Episode_Reward/rotating_object: 153.1694
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.91s
                      Time elapsed: 00:30:46
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 51430 steps/s (collection: 1.802s, learning 0.109s)
             Mean action noise std: 2.55
          Mean value_function loss: 53.9947
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.2830
                       Mean reward: 730.56
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 0.6557
    Episode_Reward/rotating_object: 149.3799
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.91s
                      Time elapsed: 00:30:47
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 53283 steps/s (collection: 1.756s, learning 0.089s)
             Mean action noise std: 2.55
          Mean value_function loss: 56.8230
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.3002
                       Mean reward: 733.02
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 0.6712
    Episode_Reward/rotating_object: 151.5824
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.84s
                      Time elapsed: 00:30:49
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 52515 steps/s (collection: 1.774s, learning 0.098s)
             Mean action noise std: 2.55
          Mean value_function loss: 48.4418
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.3119
                       Mean reward: 757.11
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 0.6550
    Episode_Reward/rotating_object: 150.5690
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.87s
                      Time elapsed: 00:30:51
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 51944 steps/s (collection: 1.792s, learning 0.100s)
             Mean action noise std: 2.56
          Mean value_function loss: 59.6320
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.3252
                       Mean reward: 744.40
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 0.6558
    Episode_Reward/rotating_object: 149.2569
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.89s
                      Time elapsed: 00:30:53
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 51795 steps/s (collection: 1.802s, learning 0.096s)
             Mean action noise std: 2.56
          Mean value_function loss: 53.8225
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.3369
                       Mean reward: 719.65
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 0.6576
    Episode_Reward/rotating_object: 148.0519
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.90s
                      Time elapsed: 00:30:55
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 52141 steps/s (collection: 1.773s, learning 0.113s)
             Mean action noise std: 2.56
          Mean value_function loss: 50.9003
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.3509
                       Mean reward: 767.65
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.6652
    Episode_Reward/rotating_object: 150.5794
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.89s
                      Time elapsed: 00:30:57
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 52289 steps/s (collection: 1.766s, learning 0.114s)
             Mean action noise std: 2.56
          Mean value_function loss: 41.3708
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.3629
                       Mean reward: 732.46
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 0.6607
    Episode_Reward/rotating_object: 152.8269
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.88s
                      Time elapsed: 00:30:59
                               ETA: 00:21:52

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 51143 steps/s (collection: 1.763s, learning 0.159s)
             Mean action noise std: 2.56
          Mean value_function loss: 47.4347
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.3740
                       Mean reward: 745.31
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 0.6598
    Episode_Reward/rotating_object: 148.7944
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.92s
                      Time elapsed: 00:31:01
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 49073 steps/s (collection: 1.787s, learning 0.216s)
             Mean action noise std: 2.57
          Mean value_function loss: 44.3139
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.3828
                       Mean reward: 768.34
               Mean episode length: 246.14
    Episode_Reward/reaching_object: 0.6578
    Episode_Reward/rotating_object: 150.2125
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.00s
                      Time elapsed: 00:31:03
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 49776 steps/s (collection: 1.829s, learning 0.146s)
             Mean action noise std: 2.57
          Mean value_function loss: 49.3715
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.3988
                       Mean reward: 767.58
               Mean episode length: 242.29
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 152.0349
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.97s
                      Time elapsed: 00:31:05
                               ETA: 00:21:45

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 50533 steps/s (collection: 1.803s, learning 0.142s)
             Mean action noise std: 2.57
          Mean value_function loss: 61.9164
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.4150
                       Mean reward: 757.56
               Mean episode length: 240.87
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 146.1038
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.95s
                      Time elapsed: 00:31:07
                               ETA: 00:21:43

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 51591 steps/s (collection: 1.802s, learning 0.103s)
             Mean action noise std: 2.57
          Mean value_function loss: 52.4974
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.4337
                       Mean reward: 757.36
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.6537
    Episode_Reward/rotating_object: 148.3429
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.91s
                      Time elapsed: 00:31:08
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 52130 steps/s (collection: 1.792s, learning 0.094s)
             Mean action noise std: 2.58
          Mean value_function loss: 46.8031
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.4552
                       Mean reward: 751.22
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 0.6629
    Episode_Reward/rotating_object: 152.1398
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.89s
                      Time elapsed: 00:31:10
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 50390 steps/s (collection: 1.839s, learning 0.112s)
             Mean action noise std: 2.58
          Mean value_function loss: 33.0487
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.4697
                       Mean reward: 771.66
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 0.6665
    Episode_Reward/rotating_object: 151.2934
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.95s
                      Time elapsed: 00:31:12
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 51778 steps/s (collection: 1.810s, learning 0.088s)
             Mean action noise std: 2.58
          Mean value_function loss: 34.3143
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.4805
                       Mean reward: 734.84
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 151.7797
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.90s
                      Time elapsed: 00:31:14
                               ETA: 00:21:34

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 52019 steps/s (collection: 1.785s, learning 0.105s)
             Mean action noise std: 2.58
          Mean value_function loss: 53.1694
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.4869
                       Mean reward: 750.32
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 0.6685
    Episode_Reward/rotating_object: 151.4390
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.89s
                      Time elapsed: 00:31:16
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 50892 steps/s (collection: 1.811s, learning 0.121s)
             Mean action noise std: 2.59
          Mean value_function loss: 42.6801
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.5014
                       Mean reward: 763.63
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 0.6723
    Episode_Reward/rotating_object: 150.5009
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.93s
                      Time elapsed: 00:31:18
                               ETA: 00:21:29

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 51975 steps/s (collection: 1.802s, learning 0.089s)
             Mean action noise std: 2.59
          Mean value_function loss: 48.9540
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.5164
                       Mean reward: 722.73
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 148.0969
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.89s
                      Time elapsed: 00:31:20
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 50448 steps/s (collection: 1.832s, learning 0.117s)
             Mean action noise std: 2.59
          Mean value_function loss: 56.3772
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.5351
                       Mean reward: 749.04
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 0.6674
    Episode_Reward/rotating_object: 153.4549
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.95s
                      Time elapsed: 00:31:22
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 51959 steps/s (collection: 1.764s, learning 0.128s)
             Mean action noise std: 2.59
          Mean value_function loss: 41.1159
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 41.5453
                       Mean reward: 760.44
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 0.6661
    Episode_Reward/rotating_object: 151.2692
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.89s
                      Time elapsed: 00:31:24
                               ETA: 00:21:22

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 52021 steps/s (collection: 1.787s, learning 0.103s)
             Mean action noise std: 2.59
          Mean value_function loss: 54.8011
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.5595
                       Mean reward: 762.98
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.6578
    Episode_Reward/rotating_object: 147.9839
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 1.89s
                      Time elapsed: 00:31:26
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 50965 steps/s (collection: 1.802s, learning 0.127s)
             Mean action noise std: 2.60
          Mean value_function loss: 44.3692
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.5729
                       Mean reward: 758.58
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 0.6749
    Episode_Reward/rotating_object: 153.0827
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 1.93s
                      Time elapsed: 00:31:28
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 52081 steps/s (collection: 1.775s, learning 0.113s)
             Mean action noise std: 2.60
          Mean value_function loss: 51.7218
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.5899
                       Mean reward: 753.03
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.6599
    Episode_Reward/rotating_object: 151.3306
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 1.89s
                      Time elapsed: 00:31:29
                               ETA: 00:21:16

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 51467 steps/s (collection: 1.802s, learning 0.108s)
             Mean action noise std: 2.60
          Mean value_function loss: 46.8097
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.6135
                       Mean reward: 750.23
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 149.2652
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 1.91s
                      Time elapsed: 00:31:31
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 50098 steps/s (collection: 1.857s, learning 0.106s)
             Mean action noise std: 2.61
          Mean value_function loss: 54.3610
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.6396
                       Mean reward: 744.79
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.6580
    Episode_Reward/rotating_object: 148.8220
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 1.96s
                      Time elapsed: 00:31:33
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 51760 steps/s (collection: 1.809s, learning 0.090s)
             Mean action noise std: 2.61
          Mean value_function loss: 62.5776
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.6618
                       Mean reward: 764.57
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 0.6574
    Episode_Reward/rotating_object: 150.3556
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 1.90s
                      Time elapsed: 00:31:35
                               ETA: 00:21:09

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 50938 steps/s (collection: 1.840s, learning 0.090s)
             Mean action noise std: 2.61
          Mean value_function loss: 46.3740
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.6797
                       Mean reward: 716.30
               Mean episode length: 227.61
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 148.2336
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 1.93s
                      Time elapsed: 00:31:37
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 50592 steps/s (collection: 1.826s, learning 0.117s)
             Mean action noise std: 2.62
          Mean value_function loss: 69.5030
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.7033
                       Mean reward: 707.16
               Mean episode length: 231.64
    Episode_Reward/reaching_object: 0.6382
    Episode_Reward/rotating_object: 143.4499
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 1.94s
                      Time elapsed: 00:31:39
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 50854 steps/s (collection: 1.821s, learning 0.112s)
             Mean action noise std: 2.62
          Mean value_function loss: 52.8450
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.7273
                       Mean reward: 766.41
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 0.6532
    Episode_Reward/rotating_object: 149.4749
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 1.93s
                      Time elapsed: 00:31:41
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 51812 steps/s (collection: 1.800s, learning 0.098s)
             Mean action noise std: 2.63
          Mean value_function loss: 44.1901
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.7590
                       Mean reward: 759.32
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 151.4404
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 1.90s
                      Time elapsed: 00:31:43
                               ETA: 00:21:00

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 50142 steps/s (collection: 1.832s, learning 0.129s)
             Mean action noise std: 2.63
          Mean value_function loss: 52.7601
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 41.7847
                       Mean reward: 752.87
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 150.4835
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 1.96s
                      Time elapsed: 00:31:45
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 50491 steps/s (collection: 1.794s, learning 0.153s)
             Mean action noise std: 2.63
          Mean value_function loss: 52.6351
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.7940
                       Mean reward: 738.34
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 0.6518
    Episode_Reward/rotating_object: 149.3319
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.95s
                      Time elapsed: 00:31:47
                               ETA: 00:20:56

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 50350 steps/s (collection: 1.788s, learning 0.164s)
             Mean action noise std: 2.63
          Mean value_function loss: 49.8571
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.8093
                       Mean reward: 742.32
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.6549
    Episode_Reward/rotating_object: 150.3690
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.95s
                      Time elapsed: 00:31:49
                               ETA: 00:20:53

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 50073 steps/s (collection: 1.795s, learning 0.169s)
             Mean action noise std: 2.63
          Mean value_function loss: 43.3266
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.8299
                       Mean reward: 784.59
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 152.0311
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 1.96s
                      Time elapsed: 00:31:51
                               ETA: 00:20:51

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 51596 steps/s (collection: 1.773s, learning 0.132s)
             Mean action noise std: 2.64
          Mean value_function loss: 52.4654
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.8456
                       Mean reward: 770.14
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 0.6516
    Episode_Reward/rotating_object: 149.1232
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.91s
                      Time elapsed: 00:31:53
                               ETA: 00:20:49

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 51718 steps/s (collection: 1.810s, learning 0.091s)
             Mean action noise std: 2.64
          Mean value_function loss: 50.7692
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.8595
                       Mean reward: 764.29
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 0.6448
    Episode_Reward/rotating_object: 148.8492
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 1.90s
                      Time elapsed: 00:31:55
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 51496 steps/s (collection: 1.794s, learning 0.115s)
             Mean action noise std: 2.64
          Mean value_function loss: 48.8600
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.8754
                       Mean reward: 754.13
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 0.6534
    Episode_Reward/rotating_object: 150.6179
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 1.91s
                      Time elapsed: 00:31:56
                               ETA: 00:20:44

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 52394 steps/s (collection: 1.784s, learning 0.092s)
             Mean action noise std: 2.64
          Mean value_function loss: 47.9997
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.8844
                       Mean reward: 793.01
               Mean episode length: 246.68
    Episode_Reward/reaching_object: 0.6587
    Episode_Reward/rotating_object: 150.7377
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.88s
                      Time elapsed: 00:31:58
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 51991 steps/s (collection: 1.777s, learning 0.114s)
             Mean action noise std: 2.64
          Mean value_function loss: 51.1280
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.8942
                       Mean reward: 720.15
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 0.6473
    Episode_Reward/rotating_object: 150.5427
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.89s
                      Time elapsed: 00:32:00
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 48842 steps/s (collection: 1.848s, learning 0.165s)
             Mean action noise std: 2.65
          Mean value_function loss: 50.7037
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.9186
                       Mean reward: 772.37
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 0.6455
    Episode_Reward/rotating_object: 146.8875
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.01s
                      Time elapsed: 00:32:02
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 49586 steps/s (collection: 1.885s, learning 0.098s)
             Mean action noise std: 2.65
          Mean value_function loss: 59.3794
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.9418
                       Mean reward: 756.28
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 150.2557
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.98s
                      Time elapsed: 00:32:04
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 51083 steps/s (collection: 1.808s, learning 0.116s)
             Mean action noise std: 2.65
          Mean value_function loss: 50.7417
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.9575
                       Mean reward: 786.00
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 0.6520
    Episode_Reward/rotating_object: 150.6724
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.92s
                      Time elapsed: 00:32:06
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 51249 steps/s (collection: 1.803s, learning 0.116s)
             Mean action noise std: 2.66
          Mean value_function loss: 49.2324
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.9791
                       Mean reward: 728.48
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 0.6569
    Episode_Reward/rotating_object: 149.2808
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.92s
                      Time elapsed: 00:32:08
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 50016 steps/s (collection: 1.849s, learning 0.116s)
             Mean action noise std: 2.66
          Mean value_function loss: 60.3294
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.0008
                       Mean reward: 730.96
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 0.6445
    Episode_Reward/rotating_object: 148.1108
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.97s
                      Time elapsed: 00:32:10
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 51369 steps/s (collection: 1.817s, learning 0.097s)
             Mean action noise std: 2.66
          Mean value_function loss: 54.7747
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.0154
                       Mean reward: 732.98
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 148.5218
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.91s
                      Time elapsed: 00:32:12
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 49642 steps/s (collection: 1.887s, learning 0.094s)
             Mean action noise std: 2.66
          Mean value_function loss: 53.2032
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.0340
                       Mean reward: 767.05
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.6544
    Episode_Reward/rotating_object: 151.4897
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 1.98s
                      Time elapsed: 00:32:14
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 49364 steps/s (collection: 1.853s, learning 0.139s)
             Mean action noise std: 2.67
          Mean value_function loss: 50.7193
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.0555
                       Mean reward: 754.90
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 0.6530
    Episode_Reward/rotating_object: 149.5442
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 1.99s
                      Time elapsed: 00:32:16
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 51106 steps/s (collection: 1.806s, learning 0.118s)
             Mean action noise std: 2.67
          Mean value_function loss: 64.1497
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.0784
                       Mean reward: 742.25
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 0.6412
    Episode_Reward/rotating_object: 149.6709
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.92s
                      Time elapsed: 00:32:18
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 50658 steps/s (collection: 1.847s, learning 0.093s)
             Mean action noise std: 2.68
          Mean value_function loss: 47.5021
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.1022
                       Mean reward: 752.39
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 0.6555
    Episode_Reward/rotating_object: 151.2954
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.94s
                      Time elapsed: 00:32:20
                               ETA: 00:20:18

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 51016 steps/s (collection: 1.805s, learning 0.122s)
             Mean action noise std: 2.68
          Mean value_function loss: 48.7019
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.1170
                       Mean reward: 764.26
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 0.6437
    Episode_Reward/rotating_object: 147.6196
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 1.93s
                      Time elapsed: 00:32:22
                               ETA: 00:20:16

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 49308 steps/s (collection: 1.892s, learning 0.102s)
             Mean action noise std: 2.68
          Mean value_function loss: 52.4366
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.1248
                       Mean reward: 761.86
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 0.6578
    Episode_Reward/rotating_object: 150.1906
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.99s
                      Time elapsed: 00:32:24
                               ETA: 00:20:14

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 49965 steps/s (collection: 1.844s, learning 0.124s)
             Mean action noise std: 2.68
          Mean value_function loss: 59.1972
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.1391
                       Mean reward: 745.25
               Mean episode length: 235.90
    Episode_Reward/reaching_object: 0.6395
    Episode_Reward/rotating_object: 147.4164
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.97s
                      Time elapsed: 00:32:26
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 49502 steps/s (collection: 1.886s, learning 0.100s)
             Mean action noise std: 2.68
          Mean value_function loss: 46.1772
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.1544
                       Mean reward: 735.49
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 0.6477
    Episode_Reward/rotating_object: 150.0766
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.99s
                      Time elapsed: 00:32:28
                               ETA: 00:20:09

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 49848 steps/s (collection: 1.859s, learning 0.113s)
             Mean action noise std: 2.69
          Mean value_function loss: 49.2887
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.1655
                       Mean reward: 704.81
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 0.6456
    Episode_Reward/rotating_object: 147.0149
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.97s
                      Time elapsed: 00:32:30
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 50711 steps/s (collection: 1.830s, learning 0.108s)
             Mean action noise std: 2.69
          Mean value_function loss: 47.3943
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.1889
                       Mean reward: 775.00
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 0.6456
    Episode_Reward/rotating_object: 150.9583
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.94s
                      Time elapsed: 00:32:32
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 50649 steps/s (collection: 1.825s, learning 0.116s)
             Mean action noise std: 2.69
          Mean value_function loss: 42.2063
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.2054
                       Mean reward: 767.72
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 0.6465
    Episode_Reward/rotating_object: 148.2910
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.94s
                      Time elapsed: 00:32:34
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 51860 steps/s (collection: 1.807s, learning 0.088s)
             Mean action noise std: 2.69
          Mean value_function loss: 44.6547
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.2124
                       Mean reward: 751.10
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 0.6569
    Episode_Reward/rotating_object: 151.0126
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.90s
                      Time elapsed: 00:32:35
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 49169 steps/s (collection: 1.859s, learning 0.140s)
             Mean action noise std: 2.70
          Mean value_function loss: 45.9233
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.2274
                       Mean reward: 729.28
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 0.6435
    Episode_Reward/rotating_object: 150.2637
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.00s
                      Time elapsed: 00:32:37
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 50393 steps/s (collection: 1.845s, learning 0.106s)
             Mean action noise std: 2.70
          Mean value_function loss: 55.1709
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.2436
                       Mean reward: 737.75
               Mean episode length: 238.88
    Episode_Reward/reaching_object: 0.6557
    Episode_Reward/rotating_object: 152.3823
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.95s
                      Time elapsed: 00:32:39
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 50358 steps/s (collection: 1.826s, learning 0.126s)
             Mean action noise std: 2.70
          Mean value_function loss: 38.3856
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.2530
                       Mean reward: 761.42
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.6566
    Episode_Reward/rotating_object: 149.4411
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.95s
                      Time elapsed: 00:32:41
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 51720 steps/s (collection: 1.811s, learning 0.090s)
             Mean action noise std: 2.70
          Mean value_function loss: 39.4709
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.2710
                       Mean reward: 772.87
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.6569
    Episode_Reward/rotating_object: 151.3548
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.90s
                      Time elapsed: 00:32:43
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 49500 steps/s (collection: 1.864s, learning 0.122s)
             Mean action noise std: 2.70
          Mean value_function loss: 49.3639
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.2871
                       Mean reward: 768.13
               Mean episode length: 244.73
    Episode_Reward/reaching_object: 0.6473
    Episode_Reward/rotating_object: 150.6948
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.99s
                      Time elapsed: 00:32:45
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 51270 steps/s (collection: 1.802s, learning 0.116s)
             Mean action noise std: 2.71
          Mean value_function loss: 35.4687
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.2977
                       Mean reward: 759.21
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 0.6529
    Episode_Reward/rotating_object: 150.1562
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.92s
                      Time elapsed: 00:32:47
                               ETA: 00:19:47

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 50116 steps/s (collection: 1.817s, learning 0.145s)
             Mean action noise std: 2.71
          Mean value_function loss: 41.0396
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.3048
                       Mean reward: 783.44
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 156.0253
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.96s
                      Time elapsed: 00:32:49
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 50154 steps/s (collection: 1.843s, learning 0.118s)
             Mean action noise std: 2.71
          Mean value_function loss: 51.4781
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.3119
                       Mean reward: 742.33
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 0.6463
    Episode_Reward/rotating_object: 148.3904
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.96s
                      Time elapsed: 00:32:51
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 50075 steps/s (collection: 1.831s, learning 0.132s)
             Mean action noise std: 2.71
          Mean value_function loss: 44.8815
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.3297
                       Mean reward: 790.64
               Mean episode length: 247.40
    Episode_Reward/reaching_object: 0.6696
    Episode_Reward/rotating_object: 155.3697
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 1.96s
                      Time elapsed: 00:32:53
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 50967 steps/s (collection: 1.833s, learning 0.096s)
             Mean action noise std: 2.71
          Mean value_function loss: 42.9873
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.3398
                       Mean reward: 751.95
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 0.6519
    Episode_Reward/rotating_object: 151.2569
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.93s
                      Time elapsed: 00:32:55
                               ETA: 00:19:38

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 52189 steps/s (collection: 1.780s, learning 0.103s)
             Mean action noise std: 2.72
          Mean value_function loss: 44.1253
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.3515
                       Mean reward: 758.01
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 0.6465
    Episode_Reward/rotating_object: 151.2761
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.88s
                      Time elapsed: 00:32:57
                               ETA: 00:19:36

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 51577 steps/s (collection: 1.816s, learning 0.090s)
             Mean action noise std: 2.72
          Mean value_function loss: 60.6264
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.3624
                       Mean reward: 760.19
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 0.6525
    Episode_Reward/rotating_object: 150.3340
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.91s
                      Time elapsed: 00:32:59
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 50860 steps/s (collection: 1.835s, learning 0.098s)
             Mean action noise std: 2.72
          Mean value_function loss: 33.7845
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.3778
                       Mean reward: 731.83
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 0.6530
    Episode_Reward/rotating_object: 149.6881
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.93s
                      Time elapsed: 00:33:01
                               ETA: 00:19:32

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 49632 steps/s (collection: 1.859s, learning 0.122s)
             Mean action noise std: 2.72
          Mean value_function loss: 49.2315
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.3907
                       Mean reward: 783.31
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 0.6517
    Episode_Reward/rotating_object: 151.5635
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.98s
                      Time elapsed: 00:33:03
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 50222 steps/s (collection: 1.864s, learning 0.094s)
             Mean action noise std: 2.73
          Mean value_function loss: 58.3260
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.4086
                       Mean reward: 761.51
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 0.6400
    Episode_Reward/rotating_object: 147.7957
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.96s
                      Time elapsed: 00:33:05
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 51386 steps/s (collection: 1.826s, learning 0.088s)
             Mean action noise std: 2.73
          Mean value_function loss: 54.1018
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.4318
                       Mean reward: 756.78
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 0.6411
    Episode_Reward/rotating_object: 149.2329
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.91s
                      Time elapsed: 00:33:07
                               ETA: 00:19:25

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 50290 steps/s (collection: 1.830s, learning 0.125s)
             Mean action noise std: 2.73
          Mean value_function loss: 42.0965
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.4497
                       Mean reward: 766.73
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 0.6534
    Episode_Reward/rotating_object: 152.9980
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.95s
                      Time elapsed: 00:33:08
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 51251 steps/s (collection: 1.816s, learning 0.102s)
             Mean action noise std: 2.74
          Mean value_function loss: 50.7614
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.4717
                       Mean reward: 755.87
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 0.6434
    Episode_Reward/rotating_object: 148.0547
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.92s
                      Time elapsed: 00:33:10
                               ETA: 00:19:21

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 50697 steps/s (collection: 1.841s, learning 0.098s)
             Mean action noise std: 2.74
          Mean value_function loss: 41.0503
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.4909
                       Mean reward: 782.10
               Mean episode length: 244.98
    Episode_Reward/reaching_object: 0.6604
    Episode_Reward/rotating_object: 154.2685
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.94s
                      Time elapsed: 00:33:12
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 50697 steps/s (collection: 1.813s, learning 0.126s)
             Mean action noise std: 2.74
          Mean value_function loss: 44.7791
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.5068
                       Mean reward: 741.24
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 0.6529
    Episode_Reward/rotating_object: 151.9829
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.94s
                      Time elapsed: 00:33:14
                               ETA: 00:19:16

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 51132 steps/s (collection: 1.785s, learning 0.138s)
             Mean action noise std: 2.75
          Mean value_function loss: 37.0019
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.5193
                       Mean reward: 754.89
               Mean episode length: 240.52
    Episode_Reward/reaching_object: 0.6547
    Episode_Reward/rotating_object: 152.3958
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.92s
                      Time elapsed: 00:33:16
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 49288 steps/s (collection: 1.845s, learning 0.149s)
             Mean action noise std: 2.75
          Mean value_function loss: 44.7928
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.5383
                       Mean reward: 780.49
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6574
    Episode_Reward/rotating_object: 151.6477
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 1.99s
                      Time elapsed: 00:33:18
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 50198 steps/s (collection: 1.849s, learning 0.110s)
             Mean action noise std: 2.75
          Mean value_function loss: 50.6385
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.5522
                       Mean reward: 761.36
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 0.6399
    Episode_Reward/rotating_object: 147.8867
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.96s
                      Time elapsed: 00:33:20
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 50809 steps/s (collection: 1.794s, learning 0.141s)
             Mean action noise std: 2.75
          Mean value_function loss: 58.1933
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.5693
                       Mean reward: 729.90
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 0.6447
    Episode_Reward/rotating_object: 149.6914
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.93s
                      Time elapsed: 00:33:22
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 51363 steps/s (collection: 1.805s, learning 0.109s)
             Mean action noise std: 2.76
          Mean value_function loss: 38.9433
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.5878
                       Mean reward: 784.93
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6450
    Episode_Reward/rotating_object: 149.2172
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.91s
                      Time elapsed: 00:33:24
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 52319 steps/s (collection: 1.787s, learning 0.092s)
             Mean action noise std: 2.76
          Mean value_function loss: 52.7187
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.6058
                       Mean reward: 781.62
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.6439
    Episode_Reward/rotating_object: 148.0778
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.88s
                      Time elapsed: 00:33:26
                               ETA: 00:19:03

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 50246 steps/s (collection: 1.841s, learning 0.116s)
             Mean action noise std: 2.76
          Mean value_function loss: 55.8236
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6302
                       Mean reward: 777.46
               Mean episode length: 244.51
    Episode_Reward/reaching_object: 0.6499
    Episode_Reward/rotating_object: 151.3306
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.96s
                      Time elapsed: 00:33:28
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 51137 steps/s (collection: 1.829s, learning 0.093s)
             Mean action noise std: 2.77
          Mean value_function loss: 46.3857
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.6538
                       Mean reward: 761.41
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 149.6341
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.92s
                      Time elapsed: 00:33:30
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 52578 steps/s (collection: 1.774s, learning 0.096s)
             Mean action noise std: 2.77
          Mean value_function loss: 57.3799
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.6711
                       Mean reward: 751.56
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 0.6462
    Episode_Reward/rotating_object: 148.5496
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 1.87s
                      Time elapsed: 00:33:32
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 52375 steps/s (collection: 1.780s, learning 0.096s)
             Mean action noise std: 2.77
          Mean value_function loss: 53.2196
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.6929
                       Mean reward: 779.74
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.6469
    Episode_Reward/rotating_object: 152.1301
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.88s
                      Time elapsed: 00:33:33
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 50737 steps/s (collection: 1.814s, learning 0.124s)
             Mean action noise std: 2.78
          Mean value_function loss: 57.2270
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.7107
                       Mean reward: 753.50
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 0.6541
    Episode_Reward/rotating_object: 150.6521
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.94s
                      Time elapsed: 00:33:35
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 50809 steps/s (collection: 1.826s, learning 0.109s)
             Mean action noise std: 2.78
          Mean value_function loss: 47.7348
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.7230
                       Mean reward: 736.62
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 0.6419
    Episode_Reward/rotating_object: 148.6481
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.93s
                      Time elapsed: 00:33:37
                               ETA: 00:18:50

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 50142 steps/s (collection: 1.845s, learning 0.116s)
             Mean action noise std: 2.78
          Mean value_function loss: 54.4517
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.7395
                       Mean reward: 780.18
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 0.6479
    Episode_Reward/rotating_object: 152.8886
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 1.96s
                      Time elapsed: 00:33:39
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 51229 steps/s (collection: 1.805s, learning 0.114s)
             Mean action noise std: 2.78
          Mean value_function loss: 53.0785
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.7506
                       Mean reward: 745.66
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 0.6423
    Episode_Reward/rotating_object: 149.9515
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.92s
                      Time elapsed: 00:33:41
                               ETA: 00:18:46

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 51777 steps/s (collection: 1.795s, learning 0.104s)
             Mean action noise std: 2.78
          Mean value_function loss: 57.4636
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.7614
                       Mean reward: 748.59
               Mean episode length: 239.50
    Episode_Reward/reaching_object: 0.6433
    Episode_Reward/rotating_object: 148.4887
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.90s
                      Time elapsed: 00:33:43
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 52014 steps/s (collection: 1.780s, learning 0.110s)
             Mean action noise std: 2.79
          Mean value_function loss: 52.0342
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.7710
                       Mean reward: 753.00
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 0.6430
    Episode_Reward/rotating_object: 150.5234
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.89s
                      Time elapsed: 00:33:45
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 51963 steps/s (collection: 1.798s, learning 0.094s)
             Mean action noise std: 2.79
          Mean value_function loss: 51.6813
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.7839
                       Mean reward: 768.99
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 0.6387
    Episode_Reward/rotating_object: 148.3483
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.89s
                      Time elapsed: 00:33:47
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 50927 steps/s (collection: 1.808s, learning 0.123s)
             Mean action noise std: 2.79
          Mean value_function loss: 42.2965
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.8025
                       Mean reward: 770.61
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 0.6562
    Episode_Reward/rotating_object: 153.1422
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.93s
                      Time elapsed: 00:33:49
                               ETA: 00:18:37

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 51139 steps/s (collection: 1.813s, learning 0.109s)
             Mean action noise std: 2.79
          Mean value_function loss: 54.7811
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.8232
                       Mean reward: 728.56
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 0.6335
    Episode_Reward/rotating_object: 148.4548
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.92s
                      Time elapsed: 00:33:51
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 51294 steps/s (collection: 1.815s, learning 0.102s)
             Mean action noise std: 2.80
          Mean value_function loss: 46.1620
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.8376
                       Mean reward: 751.13
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 0.6349
    Episode_Reward/rotating_object: 148.1131
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.92s
                      Time elapsed: 00:33:53
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 51605 steps/s (collection: 1.806s, learning 0.099s)
             Mean action noise std: 2.80
          Mean value_function loss: 52.0603
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.8522
                       Mean reward: 761.09
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 0.6432
    Episode_Reward/rotating_object: 149.5437
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.90s
                      Time elapsed: 00:33:55
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 51587 steps/s (collection: 1.790s, learning 0.116s)
             Mean action noise std: 2.80
          Mean value_function loss: 43.7844
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.8628
                       Mean reward: 769.14
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 0.6498
    Episode_Reward/rotating_object: 153.6797
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.91s
                      Time elapsed: 00:33:57
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 51953 steps/s (collection: 1.786s, learning 0.106s)
             Mean action noise std: 2.80
          Mean value_function loss: 43.1335
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.8682
                       Mean reward: 774.96
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.6478
    Episode_Reward/rotating_object: 151.9949
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 1.89s
                      Time elapsed: 00:33:58
                               ETA: 00:18:26

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 48987 steps/s (collection: 1.862s, learning 0.145s)
             Mean action noise std: 2.80
          Mean value_function loss: 48.6162
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.8727
                       Mean reward: 763.63
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.6432
    Episode_Reward/rotating_object: 150.2534
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.01s
                      Time elapsed: 00:34:00
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 48388 steps/s (collection: 1.887s, learning 0.144s)
             Mean action noise std: 2.80
          Mean value_function loss: 43.9138
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.8809
                       Mean reward: 775.59
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.6548
    Episode_Reward/rotating_object: 151.0586
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.03s
                      Time elapsed: 00:34:02
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 45386 steps/s (collection: 2.038s, learning 0.128s)
             Mean action noise std: 2.81
          Mean value_function loss: 43.1290
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.8943
                       Mean reward: 769.98
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 0.6436
    Episode_Reward/rotating_object: 152.1664
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.17s
                      Time elapsed: 00:34:05
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 47177 steps/s (collection: 1.964s, learning 0.120s)
             Mean action noise std: 2.81
          Mean value_function loss: 60.8752
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.9076
                       Mean reward: 731.61
               Mean episode length: 234.19
    Episode_Reward/reaching_object: 0.6446
    Episode_Reward/rotating_object: 150.3004
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.08s
                      Time elapsed: 00:34:07
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 47994 steps/s (collection: 1.928s, learning 0.121s)
             Mean action noise std: 2.81
          Mean value_function loss: 44.4385
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.9168
                       Mean reward: 768.76
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 0.6554
    Episode_Reward/rotating_object: 153.0262
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.05s
                      Time elapsed: 00:34:09
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 47411 steps/s (collection: 1.897s, learning 0.176s)
             Mean action noise std: 2.81
          Mean value_function loss: 45.9983
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.9329
                       Mean reward: 800.84
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.6517
    Episode_Reward/rotating_object: 155.5159
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.07s
                      Time elapsed: 00:34:11
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 47289 steps/s (collection: 1.918s, learning 0.161s)
             Mean action noise std: 2.82
          Mean value_function loss: 43.9544
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.9451
                       Mean reward: 745.30
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 0.6404
    Episode_Reward/rotating_object: 148.2137
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.08s
                      Time elapsed: 00:34:13
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 47675 steps/s (collection: 1.941s, learning 0.121s)
             Mean action noise std: 2.82
          Mean value_function loss: 51.0196
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.9630
                       Mean reward: 788.19
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.6430
    Episode_Reward/rotating_object: 152.0968
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.06s
                      Time elapsed: 00:34:15
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 49958 steps/s (collection: 1.869s, learning 0.099s)
             Mean action noise std: 2.82
          Mean value_function loss: 49.6820
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.9807
                       Mean reward: 743.08
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 0.6484
    Episode_Reward/rotating_object: 152.6138
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 1.97s
                      Time elapsed: 00:34:17
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 50432 steps/s (collection: 1.837s, learning 0.112s)
             Mean action noise std: 2.82
          Mean value_function loss: 56.1730
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.9903
                       Mean reward: 753.38
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 0.6366
    Episode_Reward/rotating_object: 149.1508
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 1.95s
                      Time elapsed: 00:34:19
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 50080 steps/s (collection: 1.839s, learning 0.124s)
             Mean action noise std: 2.83
          Mean value_function loss: 57.9226
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.0001
                       Mean reward: 752.31
               Mean episode length: 236.09
    Episode_Reward/reaching_object: 0.6398
    Episode_Reward/rotating_object: 150.3847
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.96s
                      Time elapsed: 00:34:21
                               ETA: 00:18:03

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 51352 steps/s (collection: 1.819s, learning 0.095s)
             Mean action noise std: 2.83
          Mean value_function loss: 53.4174
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.0144
                       Mean reward: 745.27
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 0.6386
    Episode_Reward/rotating_object: 151.6828
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.91s
                      Time elapsed: 00:34:23
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 51952 steps/s (collection: 1.787s, learning 0.105s)
             Mean action noise std: 2.83
          Mean value_function loss: 54.3600
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.0343
                       Mean reward: 732.72
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 0.6364
    Episode_Reward/rotating_object: 149.8031
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.89s
                      Time elapsed: 00:34:25
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 51074 steps/s (collection: 1.809s, learning 0.115s)
             Mean action noise std: 2.83
          Mean value_function loss: 46.2847
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.0519
                       Mean reward: 750.63
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 152.0906
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.92s
                      Time elapsed: 00:34:27
                               ETA: 00:17:56

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 50985 steps/s (collection: 1.826s, learning 0.102s)
             Mean action noise std: 2.84
          Mean value_function loss: 31.5604
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.0612
                       Mean reward: 749.95
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 153.4525
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.93s
                      Time elapsed: 00:34:28
                               ETA: 00:17:54

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 50281 steps/s (collection: 1.812s, learning 0.144s)
             Mean action noise std: 2.84
          Mean value_function loss: 46.3163
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.0704
                       Mean reward: 752.55
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 0.6370
    Episode_Reward/rotating_object: 152.2258
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 1.96s
                      Time elapsed: 00:34:30
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 48932 steps/s (collection: 1.872s, learning 0.137s)
             Mean action noise std: 2.84
          Mean value_function loss: 41.6038
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.0871
                       Mean reward: 750.60
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 0.6499
    Episode_Reward/rotating_object: 153.1207
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.01s
                      Time elapsed: 00:34:32
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 49980 steps/s (collection: 1.844s, learning 0.123s)
             Mean action noise std: 2.84
          Mean value_function loss: 40.4833
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.1085
                       Mean reward: 764.93
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 0.6420
    Episode_Reward/rotating_object: 150.6364
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 1.97s
                      Time elapsed: 00:34:34
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 49475 steps/s (collection: 1.822s, learning 0.165s)
             Mean action noise std: 2.85
          Mean value_function loss: 33.6843
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.1283
                       Mean reward: 756.38
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.6546
    Episode_Reward/rotating_object: 153.3504
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.99s
                      Time elapsed: 00:34:36
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 50505 steps/s (collection: 1.783s, learning 0.164s)
             Mean action noise std: 2.85
          Mean value_function loss: 41.2729
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.1477
                       Mean reward: 778.07
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 0.6463
    Episode_Reward/rotating_object: 153.6862
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 1.95s
                      Time elapsed: 00:34:38
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 52075 steps/s (collection: 1.779s, learning 0.109s)
             Mean action noise std: 2.86
          Mean value_function loss: 59.6119
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.1739
                       Mean reward: 724.04
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 0.6392
    Episode_Reward/rotating_object: 150.4777
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 1.89s
                      Time elapsed: 00:34:40
                               ETA: 00:17:41

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 51757 steps/s (collection: 1.808s, learning 0.091s)
             Mean action noise std: 2.86
          Mean value_function loss: 45.7186
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.1916
                       Mean reward: 754.82
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 0.6453
    Episode_Reward/rotating_object: 152.5071
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 1.90s
                      Time elapsed: 00:34:42
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 49141 steps/s (collection: 1.848s, learning 0.152s)
             Mean action noise std: 2.86
          Mean value_function loss: 57.1523
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.1987
                       Mean reward: 745.51
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.6408
    Episode_Reward/rotating_object: 146.6658
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.00s
                      Time elapsed: 00:34:44
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 49917 steps/s (collection: 1.866s, learning 0.103s)
             Mean action noise std: 2.86
          Mean value_function loss: 55.9992
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.2065
                       Mean reward: 724.96
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 0.6343
    Episode_Reward/rotating_object: 149.9056
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 1.97s
                      Time elapsed: 00:34:46
                               ETA: 00:17:34

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 48667 steps/s (collection: 1.899s, learning 0.121s)
             Mean action noise std: 2.86
          Mean value_function loss: 47.9501
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.2246
                       Mean reward: 764.39
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 0.6408
    Episode_Reward/rotating_object: 152.1588
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.02s
                      Time elapsed: 00:34:48
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 48322 steps/s (collection: 1.893s, learning 0.141s)
             Mean action noise std: 2.87
          Mean value_function loss: 56.5036
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.2547
                       Mean reward: 740.30
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 0.6433
    Episode_Reward/rotating_object: 150.0619
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.03s
                      Time elapsed: 00:34:50
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 48791 steps/s (collection: 1.866s, learning 0.149s)
             Mean action noise std: 2.87
          Mean value_function loss: 47.6537
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.2806
                       Mean reward: 759.07
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.6377
    Episode_Reward/rotating_object: 149.0899
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.01s
                      Time elapsed: 00:34:52
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 16378 steps/s (collection: 5.876s, learning 0.126s)
             Mean action noise std: 2.87
          Mean value_function loss: 45.5022
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.3010
                       Mean reward: 782.74
               Mean episode length: 245.28
    Episode_Reward/reaching_object: 0.6476
    Episode_Reward/rotating_object: 150.9570
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.00s
                      Time elapsed: 00:34:58
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 15833 steps/s (collection: 6.054s, learning 0.155s)
             Mean action noise std: 2.88
          Mean value_function loss: 47.7483
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.3173
                       Mean reward: 765.07
               Mean episode length: 239.79
    Episode_Reward/reaching_object: 0.6414
    Episode_Reward/rotating_object: 150.4433
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.21s
                      Time elapsed: 00:35:04
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 15761 steps/s (collection: 6.076s, learning 0.161s)
             Mean action noise std: 2.88
          Mean value_function loss: 59.5862
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.3404
                       Mean reward: 776.40
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 0.6427
    Episode_Reward/rotating_object: 150.7469
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.24s
                      Time elapsed: 00:35:11
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 15986 steps/s (collection: 5.984s, learning 0.166s)
             Mean action noise std: 2.88
          Mean value_function loss: 56.5597
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.3570
                       Mean reward: 776.48
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 0.6330
    Episode_Reward/rotating_object: 150.6539
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.15s
                      Time elapsed: 00:35:17
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 15973 steps/s (collection: 6.015s, learning 0.140s)
             Mean action noise std: 2.89
          Mean value_function loss: 47.3754
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.3779
                       Mean reward: 753.45
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 0.6388
    Episode_Reward/rotating_object: 150.3298
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.15s
                      Time elapsed: 00:35:23
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 15883 steps/s (collection: 6.055s, learning 0.134s)
             Mean action noise std: 2.89
          Mean value_function loss: 52.6168
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.3909
                       Mean reward: 769.49
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.6436
    Episode_Reward/rotating_object: 150.1716
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.19s
                      Time elapsed: 00:35:29
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 16337 steps/s (collection: 5.878s, learning 0.140s)
             Mean action noise std: 2.89
          Mean value_function loss: 49.3418
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.4023
                       Mean reward: 780.75
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 0.6450
    Episode_Reward/rotating_object: 153.1041
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.02s
                      Time elapsed: 00:35:35
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 15821 steps/s (collection: 6.064s, learning 0.150s)
             Mean action noise std: 2.89
          Mean value_function loss: 45.3310
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.4199
                       Mean reward: 747.71
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 0.6455
    Episode_Reward/rotating_object: 150.0951
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.21s
                      Time elapsed: 00:35:41
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 17578 steps/s (collection: 5.502s, learning 0.090s)
             Mean action noise std: 2.90
          Mean value_function loss: 43.3108
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.4299
                       Mean reward: 762.83
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.6475
    Episode_Reward/rotating_object: 149.8764
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 5.59s
                      Time elapsed: 00:35:47
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 52396 steps/s (collection: 1.730s, learning 0.146s)
             Mean action noise std: 2.90
          Mean value_function loss: 41.4915
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.4440
                       Mean reward: 767.93
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 0.6423
    Episode_Reward/rotating_object: 151.5764
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.88s
                      Time elapsed: 00:35:49
                               ETA: 00:17:24

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 52803 steps/s (collection: 1.763s, learning 0.099s)
             Mean action noise std: 2.90
          Mean value_function loss: 48.2822
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.4614
                       Mean reward: 759.83
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 0.6495
    Episode_Reward/rotating_object: 154.9948
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.86s
                      Time elapsed: 00:35:51
                               ETA: 00:17:22

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 53286 steps/s (collection: 1.744s, learning 0.101s)
             Mean action noise std: 2.91
          Mean value_function loss: 52.2587
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.4805
                       Mean reward: 723.63
               Mean episode length: 234.83
    Episode_Reward/reaching_object: 0.6438
    Episode_Reward/rotating_object: 148.9362
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.84s
                      Time elapsed: 00:35:53
                               ETA: 00:17:20

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 53410 steps/s (collection: 1.750s, learning 0.091s)
             Mean action noise std: 2.91
          Mean value_function loss: 34.9566
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.4986
                       Mean reward: 780.86
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.6587
    Episode_Reward/rotating_object: 151.8890
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.84s
                      Time elapsed: 00:35:54
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 53291 steps/s (collection: 1.728s, learning 0.117s)
             Mean action noise std: 2.91
          Mean value_function loss: 39.6950
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.5074
                       Mean reward: 776.96
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.6601
    Episode_Reward/rotating_object: 156.0340
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.84s
                      Time elapsed: 00:35:56
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 54897 steps/s (collection: 1.702s, learning 0.089s)
             Mean action noise std: 2.91
          Mean value_function loss: 54.1861
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.5121
                       Mean reward: 756.04
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 0.6366
    Episode_Reward/rotating_object: 150.6344
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.79s
                      Time elapsed: 00:35:58
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 53531 steps/s (collection: 1.732s, learning 0.105s)
             Mean action noise std: 2.91
          Mean value_function loss: 40.2923
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.5165
                       Mean reward: 784.70
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 0.6522
    Episode_Reward/rotating_object: 150.3641
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.84s
                      Time elapsed: 00:36:00
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 52401 steps/s (collection: 1.733s, learning 0.143s)
             Mean action noise std: 2.91
          Mean value_function loss: 54.1758
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.5243
                       Mean reward: 744.41
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 0.6542
    Episode_Reward/rotating_object: 152.5390
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.88s
                      Time elapsed: 00:36:02
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 52315 steps/s (collection: 1.767s, learning 0.113s)
             Mean action noise std: 2.92
          Mean value_function loss: 51.6420
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.5436
                       Mean reward: 761.03
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 0.6440
    Episode_Reward/rotating_object: 148.8220
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.88s
                      Time elapsed: 00:36:04
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 52901 steps/s (collection: 1.758s, learning 0.101s)
             Mean action noise std: 2.92
          Mean value_function loss: 47.6866
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.5610
                       Mean reward: 766.52
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 0.6494
    Episode_Reward/rotating_object: 151.1550
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.86s
                      Time elapsed: 00:36:05
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 52863 steps/s (collection: 1.748s, learning 0.112s)
             Mean action noise std: 2.92
          Mean value_function loss: 59.7866
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.5690
                       Mean reward: 728.99
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 0.6421
    Episode_Reward/rotating_object: 151.2762
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.86s
                      Time elapsed: 00:36:07
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 53951 steps/s (collection: 1.730s, learning 0.092s)
             Mean action noise std: 2.93
          Mean value_function loss: 50.8243
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.5838
                       Mean reward: 792.77
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6492
    Episode_Reward/rotating_object: 151.3081
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.82s
                      Time elapsed: 00:36:09
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 53773 steps/s (collection: 1.714s, learning 0.114s)
             Mean action noise std: 2.93
          Mean value_function loss: 46.3891
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.5944
                       Mean reward: 760.98
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.6545
    Episode_Reward/rotating_object: 155.1271
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.83s
                      Time elapsed: 00:36:11
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 52510 steps/s (collection: 1.770s, learning 0.102s)
             Mean action noise std: 2.93
          Mean value_function loss: 44.8277
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.5993
                       Mean reward: 790.77
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6551
    Episode_Reward/rotating_object: 153.2876
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.87s
                      Time elapsed: 00:36:13
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 51882 steps/s (collection: 1.792s, learning 0.103s)
             Mean action noise std: 2.93
          Mean value_function loss: 42.7706
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.6088
                       Mean reward: 777.27
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 0.6439
    Episode_Reward/rotating_object: 152.5874
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.89s
                      Time elapsed: 00:36:15
                               ETA: 00:16:53

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 53092 steps/s (collection: 1.743s, learning 0.109s)
             Mean action noise std: 2.93
          Mean value_function loss: 45.1458
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.6213
                       Mean reward: 792.00
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.6591
    Episode_Reward/rotating_object: 153.6034
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.85s
                      Time elapsed: 00:36:17
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 52690 steps/s (collection: 1.747s, learning 0.119s)
             Mean action noise std: 2.93
          Mean value_function loss: 47.7996
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.6342
                       Mean reward: 751.57
               Mean episode length: 239.75
    Episode_Reward/reaching_object: 0.6611
    Episode_Reward/rotating_object: 152.9221
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.87s
                      Time elapsed: 00:36:18
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 53177 steps/s (collection: 1.762s, learning 0.087s)
             Mean action noise std: 2.93
          Mean value_function loss: 52.1626
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.6443
                       Mean reward: 754.77
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 0.6554
    Episode_Reward/rotating_object: 150.4940
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.85s
                      Time elapsed: 00:36:20
                               ETA: 00:16:46

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 53837 steps/s (collection: 1.732s, learning 0.094s)
             Mean action noise std: 2.94
          Mean value_function loss: 64.3311
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.6541
                       Mean reward: 705.42
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 0.6441
    Episode_Reward/rotating_object: 148.6517
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.83s
                      Time elapsed: 00:36:22
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 53466 steps/s (collection: 1.740s, learning 0.099s)
             Mean action noise std: 2.94
          Mean value_function loss: 36.0789
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.6680
                       Mean reward: 793.44
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.6604
    Episode_Reward/rotating_object: 153.8158
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.84s
                      Time elapsed: 00:36:24
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 53261 steps/s (collection: 1.731s, learning 0.115s)
             Mean action noise std: 2.94
          Mean value_function loss: 36.1959
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.6832
                       Mean reward: 782.33
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 0.6638
    Episode_Reward/rotating_object: 154.9718
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.85s
                      Time elapsed: 00:36:26
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 53273 steps/s (collection: 1.738s, learning 0.108s)
             Mean action noise std: 2.95
          Mean value_function loss: 47.2546
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.6960
                       Mean reward: 756.80
               Mean episode length: 241.01
    Episode_Reward/reaching_object: 0.6480
    Episode_Reward/rotating_object: 148.5440
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.85s
                      Time elapsed: 00:36:28
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 52912 steps/s (collection: 1.749s, learning 0.109s)
             Mean action noise std: 2.95
          Mean value_function loss: 59.4039
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.7083
                       Mean reward: 747.26
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 0.6459
    Episode_Reward/rotating_object: 149.9401
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.86s
                      Time elapsed: 00:36:30
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 53782 steps/s (collection: 1.724s, learning 0.104s)
             Mean action noise std: 2.95
          Mean value_function loss: 36.4366
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.7196
                       Mean reward: 790.56
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 155.2825
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.83s
                      Time elapsed: 00:36:31
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 53709 steps/s (collection: 1.738s, learning 0.092s)
             Mean action noise std: 2.95
          Mean value_function loss: 47.3754
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.7297
                       Mean reward: 784.60
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 0.6606
    Episode_Reward/rotating_object: 154.7567
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.83s
                      Time elapsed: 00:36:33
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 52899 steps/s (collection: 1.724s, learning 0.135s)
             Mean action noise std: 2.95
          Mean value_function loss: 41.5169
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.7370
                       Mean reward: 775.01
               Mean episode length: 243.94
    Episode_Reward/reaching_object: 0.6710
    Episode_Reward/rotating_object: 155.4545
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.86s
                      Time elapsed: 00:36:35
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 53385 steps/s (collection: 1.707s, learning 0.134s)
             Mean action noise std: 2.96
          Mean value_function loss: 49.8000
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.7500
                       Mean reward: 771.51
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 0.6525
    Episode_Reward/rotating_object: 151.6144
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.84s
                      Time elapsed: 00:36:37
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 52502 steps/s (collection: 1.764s, learning 0.108s)
             Mean action noise std: 2.96
          Mean value_function loss: 40.5988
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.7616
                       Mean reward: 762.60
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 0.6623
    Episode_Reward/rotating_object: 152.9697
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.87s
                      Time elapsed: 00:36:39
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 53170 steps/s (collection: 1.736s, learning 0.113s)
             Mean action noise std: 2.96
          Mean value_function loss: 46.1761
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.7795
                       Mean reward: 788.01
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.6559
    Episode_Reward/rotating_object: 151.6557
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.85s
                      Time elapsed: 00:36:41
                               ETA: 00:16:21

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 52692 steps/s (collection: 1.780s, learning 0.086s)
             Mean action noise std: 2.96
          Mean value_function loss: 41.5803
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.7858
                       Mean reward: 788.97
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.6641
    Episode_Reward/rotating_object: 156.3562
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.87s
                      Time elapsed: 00:36:42
                               ETA: 00:16:19

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 53436 steps/s (collection: 1.743s, learning 0.097s)
             Mean action noise std: 2.96
          Mean value_function loss: 43.4504
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.7917
                       Mean reward: 747.73
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 0.6574
    Episode_Reward/rotating_object: 151.3091
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.84s
                      Time elapsed: 00:36:44
                               ETA: 00:16:17

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 53158 steps/s (collection: 1.742s, learning 0.107s)
             Mean action noise std: 2.97
          Mean value_function loss: 50.6754
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.8017
                       Mean reward: 774.00
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.6515
    Episode_Reward/rotating_object: 150.7509
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.85s
                      Time elapsed: 00:36:46
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 53065 steps/s (collection: 1.743s, learning 0.109s)
             Mean action noise std: 2.97
          Mean value_function loss: 65.1616
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.8196
                       Mean reward: 746.69
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 0.6611
    Episode_Reward/rotating_object: 150.5284
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.85s
                      Time elapsed: 00:36:48
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 53683 steps/s (collection: 1.715s, learning 0.117s)
             Mean action noise std: 2.97
          Mean value_function loss: 49.0132
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.8388
                       Mean reward: 778.83
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.6571
    Episode_Reward/rotating_object: 153.8429
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.83s
                      Time elapsed: 00:36:50
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 54178 steps/s (collection: 1.719s, learning 0.095s)
             Mean action noise std: 2.97
          Mean value_function loss: 52.2899
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.8517
                       Mean reward: 793.70
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.6590
    Episode_Reward/rotating_object: 150.9775
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.81s
                      Time elapsed: 00:36:52
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 52244 steps/s (collection: 1.762s, learning 0.120s)
             Mean action noise std: 2.98
          Mean value_function loss: 55.6964
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.8614
                       Mean reward: 734.49
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 0.6568
    Episode_Reward/rotating_object: 150.7439
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.88s
                      Time elapsed: 00:36:54
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 53459 steps/s (collection: 1.748s, learning 0.091s)
             Mean action noise std: 2.98
          Mean value_function loss: 49.7589
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.8742
                       Mean reward: 744.81
               Mean episode length: 236.83
    Episode_Reward/reaching_object: 0.6547
    Episode_Reward/rotating_object: 152.4893
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.84s
                      Time elapsed: 00:36:55
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 54063 steps/s (collection: 1.733s, learning 0.086s)
             Mean action noise std: 2.98
          Mean value_function loss: 45.8037
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.8899
                       Mean reward: 774.62
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 0.6575
    Episode_Reward/rotating_object: 151.7673
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 1.82s
                      Time elapsed: 00:36:57
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 51623 steps/s (collection: 1.760s, learning 0.145s)
             Mean action noise std: 2.98
          Mean value_function loss: 55.1368
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.9005
                       Mean reward: 719.21
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 0.6483
    Episode_Reward/rotating_object: 148.7359
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.90s
                      Time elapsed: 00:36:59
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 53241 steps/s (collection: 1.726s, learning 0.121s)
             Mean action noise std: 2.98
          Mean value_function loss: 45.8193
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.9110
                       Mean reward: 755.66
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 150.2644
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.85s
                      Time elapsed: 00:37:01
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 52643 steps/s (collection: 1.775s, learning 0.093s)
             Mean action noise std: 2.99
          Mean value_function loss: 38.8166
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.9196
                       Mean reward: 779.05
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.6582
    Episode_Reward/rotating_object: 152.9567
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.87s
                      Time elapsed: 00:37:03
                               ETA: 00:15:54

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 52833 steps/s (collection: 1.749s, learning 0.111s)
             Mean action noise std: 2.99
          Mean value_function loss: 38.5188
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.9281
                       Mean reward: 718.27
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 0.6604
    Episode_Reward/rotating_object: 150.7984
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.86s
                      Time elapsed: 00:37:05
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 52092 steps/s (collection: 1.791s, learning 0.096s)
             Mean action noise std: 2.99
          Mean value_function loss: 41.2263
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.9391
                       Mean reward: 778.47
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 0.6529
    Episode_Reward/rotating_object: 151.3468
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 1.89s
                      Time elapsed: 00:37:07
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 52732 steps/s (collection: 1.749s, learning 0.116s)
             Mean action noise std: 2.99
          Mean value_function loss: 54.2582
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.9511
                       Mean reward: 758.61
               Mean episode length: 236.98
    Episode_Reward/reaching_object: 0.6474
    Episode_Reward/rotating_object: 149.5888
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.86s
                      Time elapsed: 00:37:08
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 53994 steps/s (collection: 1.732s, learning 0.088s)
             Mean action noise std: 3.00
          Mean value_function loss: 41.5802
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.9654
                       Mean reward: 770.73
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.6544
    Episode_Reward/rotating_object: 152.5749
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.82s
                      Time elapsed: 00:37:10
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 49096 steps/s (collection: 1.902s, learning 0.100s)
             Mean action noise std: 3.00
          Mean value_function loss: 42.4825
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.9792
                       Mean reward: 773.19
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 0.6669
    Episode_Reward/rotating_object: 155.1384
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.00s
                      Time elapsed: 00:37:12
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 49753 steps/s (collection: 1.876s, learning 0.100s)
             Mean action noise std: 3.00
          Mean value_function loss: 49.1984
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.9920
                       Mean reward: 794.21
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 0.6560
    Episode_Reward/rotating_object: 153.9321
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.98s
                      Time elapsed: 00:37:14
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 50658 steps/s (collection: 1.810s, learning 0.130s)
             Mean action noise std: 3.00
          Mean value_function loss: 43.2059
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.0023
                       Mean reward: 764.99
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.6611
    Episode_Reward/rotating_object: 153.3682
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.94s
                      Time elapsed: 00:37:16
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 52230 steps/s (collection: 1.740s, learning 0.142s)
             Mean action noise std: 3.00
          Mean value_function loss: 40.4712
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.0104
                       Mean reward: 767.67
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 0.6546
    Episode_Reward/rotating_object: 151.5423
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.88s
                      Time elapsed: 00:37:18
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 51899 steps/s (collection: 1.729s, learning 0.165s)
             Mean action noise std: 3.01
          Mean value_function loss: 42.9965
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.0185
                       Mean reward: 786.16
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.6619
    Episode_Reward/rotating_object: 154.7179
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.89s
                      Time elapsed: 00:37:20
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 50775 steps/s (collection: 1.846s, learning 0.091s)
             Mean action noise std: 3.01
          Mean value_function loss: 45.6625
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.0293
                       Mean reward: 752.83
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.6649
    Episode_Reward/rotating_object: 154.6484
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.94s
                      Time elapsed: 00:37:22
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 53377 steps/s (collection: 1.752s, learning 0.090s)
             Mean action noise std: 3.01
          Mean value_function loss: 59.5196
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.0394
                       Mean reward: 753.03
               Mean episode length: 236.74
    Episode_Reward/reaching_object: 0.6593
    Episode_Reward/rotating_object: 150.3656
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.84s
                      Time elapsed: 00:37:24
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 51364 steps/s (collection: 1.789s, learning 0.125s)
             Mean action noise std: 3.01
          Mean value_function loss: 43.1779
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.0501
                       Mean reward: 790.25
               Mean episode length: 247.34
    Episode_Reward/reaching_object: 0.6626
    Episode_Reward/rotating_object: 152.7787
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.91s
                      Time elapsed: 00:37:26
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 53286 steps/s (collection: 1.751s, learning 0.094s)
             Mean action noise std: 3.02
          Mean value_function loss: 38.2938
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.0667
                       Mean reward: 741.85
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 0.6638
    Episode_Reward/rotating_object: 149.4455
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.84s
                      Time elapsed: 00:37:27
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 53739 steps/s (collection: 1.729s, learning 0.100s)
             Mean action noise std: 3.02
          Mean value_function loss: 36.0068
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.0791
                       Mean reward: 770.71
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 0.6700
    Episode_Reward/rotating_object: 156.2906
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.83s
                      Time elapsed: 00:37:29
                               ETA: 00:15:24

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 52870 steps/s (collection: 1.746s, learning 0.113s)
             Mean action noise std: 3.02
          Mean value_function loss: 62.3222
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.0882
                       Mean reward: 760.29
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 151.5983
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.86s
                      Time elapsed: 00:37:31
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 51172 steps/s (collection: 1.787s, learning 0.134s)
             Mean action noise std: 3.02
          Mean value_function loss: 50.0709
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.0950
                       Mean reward: 781.95
               Mean episode length: 247.47
    Episode_Reward/reaching_object: 0.6657
    Episode_Reward/rotating_object: 151.7386
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.92s
                      Time elapsed: 00:37:33
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 49826 steps/s (collection: 1.835s, learning 0.138s)
             Mean action noise std: 3.02
          Mean value_function loss: 46.7149
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.1125
                       Mean reward: 773.85
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 0.6551
    Episode_Reward/rotating_object: 150.2712
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.97s
                      Time elapsed: 00:37:35
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 54274 steps/s (collection: 1.721s, learning 0.091s)
             Mean action noise std: 3.03
          Mean value_function loss: 43.3015
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.1316
                       Mean reward: 764.53
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 0.6631
    Episode_Reward/rotating_object: 151.6338
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.81s
                      Time elapsed: 00:37:37
                               ETA: 00:15:15

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 53073 steps/s (collection: 1.762s, learning 0.091s)
             Mean action noise std: 3.03
          Mean value_function loss: 33.7502
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.1441
                       Mean reward: 806.28
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.6684
    Episode_Reward/rotating_object: 154.3455
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.85s
                      Time elapsed: 00:37:39
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 53092 steps/s (collection: 1.752s, learning 0.100s)
             Mean action noise std: 3.03
          Mean value_function loss: 44.8431
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.1592
                       Mean reward: 748.17
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 0.6642
    Episode_Reward/rotating_object: 151.3021
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.85s
                      Time elapsed: 00:37:41
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 53511 steps/s (collection: 1.750s, learning 0.087s)
             Mean action noise std: 3.03
          Mean value_function loss: 57.6701
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.1681
                       Mean reward: 771.55
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.6544
    Episode_Reward/rotating_object: 152.4950
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.84s
                      Time elapsed: 00:37:42
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 50004 steps/s (collection: 1.793s, learning 0.173s)
             Mean action noise std: 3.04
          Mean value_function loss: 60.0725
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.1822
                       Mean reward: 765.34
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 0.6437
    Episode_Reward/rotating_object: 151.4319
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.97s
                      Time elapsed: 00:37:44
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 52589 steps/s (collection: 1.777s, learning 0.092s)
             Mean action noise std: 3.04
          Mean value_function loss: 50.0450
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.1932
                       Mean reward: 760.87
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 0.6465
    Episode_Reward/rotating_object: 149.2814
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.87s
                      Time elapsed: 00:37:46
                               ETA: 00:15:04

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 52167 steps/s (collection: 1.756s, learning 0.128s)
             Mean action noise std: 3.04
          Mean value_function loss: 42.6799
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.2045
                       Mean reward: 764.76
               Mean episode length: 244.29
    Episode_Reward/reaching_object: 0.6607
    Episode_Reward/rotating_object: 151.9964
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.88s
                      Time elapsed: 00:37:48
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 51611 steps/s (collection: 1.799s, learning 0.106s)
             Mean action noise std: 3.04
          Mean value_function loss: 42.2659
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.2128
                       Mean reward: 759.83
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 0.6669
    Episode_Reward/rotating_object: 154.5950
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.90s
                      Time elapsed: 00:37:50
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 52440 steps/s (collection: 1.758s, learning 0.117s)
             Mean action noise std: 3.04
          Mean value_function loss: 44.2905
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 44.2215
                       Mean reward: 772.04
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 0.6588
    Episode_Reward/rotating_object: 154.5870
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.87s
                      Time elapsed: 00:37:52
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 51482 steps/s (collection: 1.812s, learning 0.098s)
             Mean action noise std: 3.05
          Mean value_function loss: 51.9198
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.2355
                       Mean reward: 738.60
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 0.6525
    Episode_Reward/rotating_object: 152.6709
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.91s
                      Time elapsed: 00:37:54
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 50225 steps/s (collection: 1.843s, learning 0.114s)
             Mean action noise std: 3.05
          Mean value_function loss: 55.8509
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.2519
                       Mean reward: 729.14
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 151.0577
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.96s
                      Time elapsed: 00:37:56
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 51700 steps/s (collection: 1.792s, learning 0.110s)
             Mean action noise std: 3.05
          Mean value_function loss: 46.0727
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 44.2691
                       Mean reward: 782.46
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.6479
    Episode_Reward/rotating_object: 154.6226
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.90s
                      Time elapsed: 00:37:58
                               ETA: 00:14:50

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 50728 steps/s (collection: 1.832s, learning 0.106s)
             Mean action noise std: 3.05
          Mean value_function loss: 34.8937
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.2777
                       Mean reward: 762.84
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 152.7384
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.94s
                      Time elapsed: 00:38:00
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 50668 steps/s (collection: 1.796s, learning 0.144s)
             Mean action noise std: 3.05
          Mean value_function loss: 35.5887
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.2864
                       Mean reward: 766.75
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 0.6617
    Episode_Reward/rotating_object: 152.9856
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.94s
                      Time elapsed: 00:38:02
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 53012 steps/s (collection: 1.740s, learning 0.114s)
             Mean action noise std: 3.06
          Mean value_function loss: 41.6850
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.2943
                       Mean reward: 760.96
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 0.6607
    Episode_Reward/rotating_object: 154.4095
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.85s
                      Time elapsed: 00:38:03
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 51760 steps/s (collection: 1.780s, learning 0.119s)
             Mean action noise std: 3.06
          Mean value_function loss: 45.8604
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.3035
                       Mean reward: 748.00
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 0.6492
    Episode_Reward/rotating_object: 150.1794
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.90s
                      Time elapsed: 00:38:05
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 50792 steps/s (collection: 1.767s, learning 0.168s)
             Mean action noise std: 3.06
          Mean value_function loss: 38.8929
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.3140
                       Mean reward: 793.55
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 0.6704
    Episode_Reward/rotating_object: 155.4336
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.94s
                      Time elapsed: 00:38:07
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 51422 steps/s (collection: 1.767s, learning 0.145s)
             Mean action noise std: 3.06
          Mean value_function loss: 39.8532
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.3352
                       Mean reward: 760.46
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.6696
    Episode_Reward/rotating_object: 153.9294
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.91s
                      Time elapsed: 00:38:09
                               ETA: 00:14:37

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 52335 steps/s (collection: 1.775s, learning 0.103s)
             Mean action noise std: 3.07
          Mean value_function loss: 55.0226
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 44.3601
                       Mean reward: 758.20
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 0.6621
    Episode_Reward/rotating_object: 149.9450
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.88s
                      Time elapsed: 00:38:11
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 51475 steps/s (collection: 1.797s, learning 0.113s)
             Mean action noise std: 3.07
          Mean value_function loss: 58.1451
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.3802
                       Mean reward: 743.25
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 0.6497
    Episode_Reward/rotating_object: 149.9105
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.91s
                      Time elapsed: 00:38:13
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 52421 steps/s (collection: 1.772s, learning 0.103s)
             Mean action noise std: 3.07
          Mean value_function loss: 50.1652
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.3940
                       Mean reward: 755.48
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 152.2112
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.88s
                      Time elapsed: 00:38:15
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 50168 steps/s (collection: 1.844s, learning 0.116s)
             Mean action noise std: 3.08
          Mean value_function loss: 47.8149
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.4057
                       Mean reward: 762.88
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 0.6613
    Episode_Reward/rotating_object: 154.0444
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.96s
                      Time elapsed: 00:38:17
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 52913 steps/s (collection: 1.758s, learning 0.100s)
             Mean action noise std: 3.08
          Mean value_function loss: 50.0942
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.4191
                       Mean reward: 757.02
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.6586
    Episode_Reward/rotating_object: 150.3252
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.86s
                      Time elapsed: 00:38:19
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 52087 steps/s (collection: 1.766s, learning 0.121s)
             Mean action noise std: 3.08
          Mean value_function loss: 43.0047
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.4291
                       Mean reward: 775.46
               Mean episode length: 245.00
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 154.2961
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 1.89s
                      Time elapsed: 00:38:21
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 52963 steps/s (collection: 1.728s, learning 0.128s)
             Mean action noise std: 3.08
          Mean value_function loss: 43.2456
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.4398
                       Mean reward: 766.94
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 0.6624
    Episode_Reward/rotating_object: 151.3508
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.86s
                      Time elapsed: 00:38:22
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 52279 steps/s (collection: 1.778s, learning 0.102s)
             Mean action noise std: 3.08
          Mean value_function loss: 49.2263
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.4491
                       Mean reward: 790.01
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 151.9879
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.88s
                      Time elapsed: 00:38:24
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 52731 steps/s (collection: 1.754s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 48.5906
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.4658
                       Mean reward: 759.12
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 0.6637
    Episode_Reward/rotating_object: 152.8416
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.86s
                      Time elapsed: 00:38:26
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 52290 steps/s (collection: 1.791s, learning 0.089s)
             Mean action noise std: 3.09
          Mean value_function loss: 34.7576
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.4807
                       Mean reward: 753.56
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 0.6801
    Episode_Reward/rotating_object: 153.3568
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.88s
                      Time elapsed: 00:38:28
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 53420 steps/s (collection: 1.751s, learning 0.089s)
             Mean action noise std: 3.09
          Mean value_function loss: 44.8717
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.4958
                       Mean reward: 787.58
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 0.6674
    Episode_Reward/rotating_object: 152.7238
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.84s
                      Time elapsed: 00:38:30
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 52013 steps/s (collection: 1.765s, learning 0.125s)
             Mean action noise std: 3.09
          Mean value_function loss: 48.4704
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.5019
                       Mean reward: 752.94
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.6679
    Episode_Reward/rotating_object: 151.0864
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.89s
                      Time elapsed: 00:38:32
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 51699 steps/s (collection: 1.764s, learning 0.137s)
             Mean action noise std: 3.09
          Mean value_function loss: 46.2204
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.5092
                       Mean reward: 761.69
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 152.7979
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.90s
                      Time elapsed: 00:38:34
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 50842 steps/s (collection: 1.820s, learning 0.113s)
             Mean action noise std: 3.10
          Mean value_function loss: 44.3714
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.5182
                       Mean reward: 760.05
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 0.6745
    Episode_Reward/rotating_object: 154.0541
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.93s
                      Time elapsed: 00:38:36
                               ETA: 00:14:07

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 53485 steps/s (collection: 1.726s, learning 0.112s)
             Mean action noise std: 3.10
          Mean value_function loss: 64.3409
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.5271
                       Mean reward: 726.64
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 151.6263
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.84s
                      Time elapsed: 00:38:37
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 51645 steps/s (collection: 1.808s, learning 0.095s)
             Mean action noise std: 3.10
          Mean value_function loss: 42.7747
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.5380
                       Mean reward: 761.12
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 0.6745
    Episode_Reward/rotating_object: 152.4258
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.90s
                      Time elapsed: 00:38:39
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 48551 steps/s (collection: 1.931s, learning 0.094s)
             Mean action noise std: 3.10
          Mean value_function loss: 40.8555
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.5484
                       Mean reward: 764.61
               Mean episode length: 241.69
    Episode_Reward/reaching_object: 0.6794
    Episode_Reward/rotating_object: 156.0373
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.02s
                      Time elapsed: 00:38:41
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 53775 steps/s (collection: 1.740s, learning 0.089s)
             Mean action noise std: 3.10
          Mean value_function loss: 30.1853
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.5611
                       Mean reward: 788.09
               Mean episode length: 247.62
    Episode_Reward/reaching_object: 0.6719
    Episode_Reward/rotating_object: 153.9009
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.83s
                      Time elapsed: 00:38:43
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 48734 steps/s (collection: 1.839s, learning 0.178s)
             Mean action noise std: 3.11
          Mean value_function loss: 48.0295
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.5685
                       Mean reward: 760.49
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 0.6747
    Episode_Reward/rotating_object: 154.3526
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.02s
                      Time elapsed: 00:38:45
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 51730 steps/s (collection: 1.815s, learning 0.085s)
             Mean action noise std: 3.11
          Mean value_function loss: 44.0124
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.5843
                       Mean reward: 794.71
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.6729
    Episode_Reward/rotating_object: 154.3561
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.90s
                      Time elapsed: 00:38:47
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 52140 steps/s (collection: 1.790s, learning 0.095s)
             Mean action noise std: 3.11
          Mean value_function loss: 47.7340
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.5994
                       Mean reward: 764.73
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 0.6700
    Episode_Reward/rotating_object: 153.1839
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.89s
                      Time elapsed: 00:38:49
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 53548 steps/s (collection: 1.744s, learning 0.092s)
             Mean action noise std: 3.11
          Mean value_function loss: 51.7262
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.6085
                       Mean reward: 779.27
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 153.0328
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 1.84s
                      Time elapsed: 00:38:51
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 52448 steps/s (collection: 1.788s, learning 0.086s)
             Mean action noise std: 3.12
          Mean value_function loss: 57.9763
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.6174
                       Mean reward: 738.94
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 0.6665
    Episode_Reward/rotating_object: 153.0093
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.87s
                      Time elapsed: 00:38:53
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 50306 steps/s (collection: 1.819s, learning 0.135s)
             Mean action noise std: 3.12
          Mean value_function loss: 38.0518
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.6273
                       Mean reward: 775.29
               Mean episode length: 242.07
    Episode_Reward/reaching_object: 0.6690
    Episode_Reward/rotating_object: 152.5253
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.95s
                      Time elapsed: 00:38:55
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 51946 steps/s (collection: 1.795s, learning 0.097s)
             Mean action noise std: 3.12
          Mean value_function loss: 41.7993
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.6426
                       Mean reward: 769.32
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 0.6710
    Episode_Reward/rotating_object: 153.3404
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.89s
                      Time elapsed: 00:38:57
                               ETA: 00:13:43

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 51909 steps/s (collection: 1.793s, learning 0.101s)
             Mean action noise std: 3.12
          Mean value_function loss: 49.7490
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.6637
                       Mean reward: 761.08
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 0.6633
    Episode_Reward/rotating_object: 151.9752
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.89s
                      Time elapsed: 00:38:58
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 49004 steps/s (collection: 1.864s, learning 0.142s)
             Mean action noise std: 3.13
          Mean value_function loss: 42.9101
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.6735
                       Mean reward: 790.32
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 0.6639
    Episode_Reward/rotating_object: 155.3824
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.01s
                      Time elapsed: 00:39:00
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 50018 steps/s (collection: 1.856s, learning 0.109s)
             Mean action noise std: 3.13
          Mean value_function loss: 51.9028
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.6818
                       Mean reward: 759.68
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 0.6657
    Episode_Reward/rotating_object: 152.1245
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.97s
                      Time elapsed: 00:39:02
                               ETA: 00:13:36

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 51967 steps/s (collection: 1.780s, learning 0.112s)
             Mean action noise std: 3.13
          Mean value_function loss: 50.2304
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.6929
                       Mean reward: 759.40
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 0.6753
    Episode_Reward/rotating_object: 153.8665
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.89s
                      Time elapsed: 00:39:04
                               ETA: 00:13:34

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 49754 steps/s (collection: 1.868s, learning 0.108s)
             Mean action noise std: 3.13
          Mean value_function loss: 47.6323
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.7068
                       Mean reward: 786.42
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.6734
    Episode_Reward/rotating_object: 154.1899
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.98s
                      Time elapsed: 00:39:06
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 51684 steps/s (collection: 1.795s, learning 0.107s)
             Mean action noise std: 3.13
          Mean value_function loss: 53.5091
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.7147
                       Mean reward: 779.44
               Mean episode length: 240.66
    Episode_Reward/reaching_object: 0.6616
    Episode_Reward/rotating_object: 151.3933
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.90s
                      Time elapsed: 00:39:08
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 49284 steps/s (collection: 1.867s, learning 0.128s)
             Mean action noise std: 3.14
          Mean value_function loss: 37.6697
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.7251
                       Mean reward: 783.71
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.6650
    Episode_Reward/rotating_object: 151.5084
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.99s
                      Time elapsed: 00:39:10
                               ETA: 00:13:28

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 52416 steps/s (collection: 1.778s, learning 0.097s)
             Mean action noise std: 3.14
          Mean value_function loss: 50.0820
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.7408
                       Mean reward: 774.76
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.6727
    Episode_Reward/rotating_object: 153.9567
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.88s
                      Time elapsed: 00:39:12
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 49915 steps/s (collection: 1.790s, learning 0.180s)
             Mean action noise std: 3.14
          Mean value_function loss: 45.6235
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.7607
                       Mean reward: 750.79
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 153.1105
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.97s
                      Time elapsed: 00:39:14
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 47059 steps/s (collection: 1.986s, learning 0.103s)
             Mean action noise std: 3.15
          Mean value_function loss: 59.1394
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.7794
                       Mean reward: 753.69
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.6585
    Episode_Reward/rotating_object: 149.8620
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.09s
                      Time elapsed: 00:39:16
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 50539 steps/s (collection: 1.819s, learning 0.126s)
             Mean action noise std: 3.15
          Mean value_function loss: 55.7898
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.7931
                       Mean reward: 783.69
               Mean episode length: 241.13
    Episode_Reward/reaching_object: 0.6604
    Episode_Reward/rotating_object: 153.1643
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.95s
                      Time elapsed: 00:39:18
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 48056 steps/s (collection: 1.868s, learning 0.177s)
             Mean action noise std: 3.15
          Mean value_function loss: 49.8731
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.7990
                       Mean reward: 742.34
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 0.6509
    Episode_Reward/rotating_object: 149.4665
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.05s
                      Time elapsed: 00:39:20
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 51862 steps/s (collection: 1.805s, learning 0.090s)
             Mean action noise std: 3.15
          Mean value_function loss: 48.1220
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.8159
                       Mean reward: 760.16
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.6611
    Episode_Reward/rotating_object: 152.1146
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.90s
                      Time elapsed: 00:39:22
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 50217 steps/s (collection: 1.802s, learning 0.156s)
             Mean action noise std: 3.15
          Mean value_function loss: 52.7216
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.8322
                       Mean reward: 765.57
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.6668
    Episode_Reward/rotating_object: 153.3972
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.96s
                      Time elapsed: 00:39:24
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 48861 steps/s (collection: 1.897s, learning 0.115s)
             Mean action noise std: 3.15
          Mean value_function loss: 48.4823
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.8375
                       Mean reward: 764.13
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 0.6630
    Episode_Reward/rotating_object: 151.6361
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.01s
                      Time elapsed: 00:39:26
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 52448 steps/s (collection: 1.772s, learning 0.102s)
             Mean action noise std: 3.16
          Mean value_function loss: 57.4393
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.8502
                       Mean reward: 760.78
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 0.6596
    Episode_Reward/rotating_object: 150.0860
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.87s
                      Time elapsed: 00:39:28
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 50617 steps/s (collection: 1.793s, learning 0.150s)
             Mean action noise std: 3.16
          Mean value_function loss: 40.3186
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 44.8642
                       Mean reward: 775.99
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 0.6777
    Episode_Reward/rotating_object: 155.1943
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.94s
                      Time elapsed: 00:39:30
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 51530 steps/s (collection: 1.781s, learning 0.127s)
             Mean action noise std: 3.16
          Mean value_function loss: 41.2580
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.8744
                       Mean reward: 780.35
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 0.6725
    Episode_Reward/rotating_object: 152.3855
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.91s
                      Time elapsed: 00:39:32
                               ETA: 00:13:04

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 53194 steps/s (collection: 1.756s, learning 0.092s)
             Mean action noise std: 3.17
          Mean value_function loss: 38.0895
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.8869
                       Mean reward: 775.23
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 0.6799
    Episode_Reward/rotating_object: 155.8821
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.85s
                      Time elapsed: 00:39:33
                               ETA: 00:13:02

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 51421 steps/s (collection: 1.815s, learning 0.097s)
             Mean action noise std: 3.17
          Mean value_function loss: 50.9582
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.8991
                       Mean reward: 707.10
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 0.6667
    Episode_Reward/rotating_object: 150.3551
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.91s
                      Time elapsed: 00:39:35
                               ETA: 00:13:00

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 51117 steps/s (collection: 1.838s, learning 0.085s)
             Mean action noise std: 3.17
          Mean value_function loss: 52.3451
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.9122
                       Mean reward: 744.61
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 0.6725
    Episode_Reward/rotating_object: 153.1646
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.92s
                      Time elapsed: 00:39:37
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 51902 steps/s (collection: 1.806s, learning 0.089s)
             Mean action noise std: 3.17
          Mean value_function loss: 49.6095
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.9327
                       Mean reward: 763.81
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 149.9654
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.89s
                      Time elapsed: 00:39:39
                               ETA: 00:12:55

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 51886 steps/s (collection: 1.796s, learning 0.099s)
             Mean action noise std: 3.18
          Mean value_function loss: 42.1437
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.9405
                       Mean reward: 785.82
               Mean episode length: 246.81
    Episode_Reward/reaching_object: 0.6815
    Episode_Reward/rotating_object: 154.4607
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.89s
                      Time elapsed: 00:39:41
                               ETA: 00:12:53

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 51783 steps/s (collection: 1.793s, learning 0.105s)
             Mean action noise std: 3.18
          Mean value_function loss: 58.1832
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.9498
                       Mean reward: 766.22
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 0.6706
    Episode_Reward/rotating_object: 151.8058
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.90s
                      Time elapsed: 00:39:43
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 52205 steps/s (collection: 1.781s, learning 0.102s)
             Mean action noise std: 3.18
          Mean value_function loss: 51.7224
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.9689
                       Mean reward: 768.10
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 0.6867
    Episode_Reward/rotating_object: 154.7649
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.88s
                      Time elapsed: 00:39:45
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 52861 steps/s (collection: 1.767s, learning 0.093s)
             Mean action noise std: 3.18
          Mean value_function loss: 56.0187
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.9918
                       Mean reward: 746.68
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 0.6715
    Episode_Reward/rotating_object: 153.5653
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.86s
                      Time elapsed: 00:39:47
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 51700 steps/s (collection: 1.785s, learning 0.116s)
             Mean action noise std: 3.18
          Mean value_function loss: 44.1867
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.9976
                       Mean reward: 797.30
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 0.6735
    Episode_Reward/rotating_object: 152.4999
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.90s
                      Time elapsed: 00:39:49
                               ETA: 00:12:44

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 49551 steps/s (collection: 1.842s, learning 0.142s)
             Mean action noise std: 3.19
          Mean value_function loss: 42.5816
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.9989
                       Mean reward: 785.48
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 0.6751
    Episode_Reward/rotating_object: 154.3357
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.98s
                      Time elapsed: 00:39:51
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 53060 steps/s (collection: 1.761s, learning 0.092s)
             Mean action noise std: 3.19
          Mean value_function loss: 55.9324
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.0081
                       Mean reward: 732.17
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 153.1060
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.85s
                      Time elapsed: 00:39:53
                               ETA: 00:12:40

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 48978 steps/s (collection: 1.875s, learning 0.133s)
             Mean action noise std: 3.19
          Mean value_function loss: 39.9543
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.0195
                       Mean reward: 792.15
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 0.6774
    Episode_Reward/rotating_object: 153.7259
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.01s
                      Time elapsed: 00:39:55
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 50831 steps/s (collection: 1.842s, learning 0.092s)
             Mean action noise std: 3.19
          Mean value_function loss: 54.1032
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.0323
                       Mean reward: 785.62
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 0.6675
    Episode_Reward/rotating_object: 153.0218
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.93s
                      Time elapsed: 00:39:56
                               ETA: 00:12:36

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 51445 steps/s (collection: 1.808s, learning 0.103s)
             Mean action noise std: 3.20
          Mean value_function loss: 57.0598
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.0483
                       Mean reward: 767.08
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 0.6677
    Episode_Reward/rotating_object: 152.0738
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.91s
                      Time elapsed: 00:39:58
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 53354 steps/s (collection: 1.754s, learning 0.089s)
             Mean action noise std: 3.20
          Mean value_function loss: 64.0710
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.0644
                       Mean reward: 756.72
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 0.6753
    Episode_Reward/rotating_object: 151.0933
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.84s
                      Time elapsed: 00:40:00
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 51030 steps/s (collection: 1.816s, learning 0.110s)
             Mean action noise std: 3.20
          Mean value_function loss: 35.4223
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.0798
                       Mean reward: 798.55
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.6742
    Episode_Reward/rotating_object: 154.2070
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.93s
                      Time elapsed: 00:40:02
                               ETA: 00:12:29

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 49738 steps/s (collection: 1.844s, learning 0.133s)
             Mean action noise std: 3.20
          Mean value_function loss: 35.2672
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.0904
                       Mean reward: 789.38
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.6753
    Episode_Reward/rotating_object: 154.6452
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.98s
                      Time elapsed: 00:40:04
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 50821 steps/s (collection: 1.783s, learning 0.152s)
             Mean action noise std: 3.20
          Mean value_function loss: 56.5368
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.0958
                       Mean reward: 753.03
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 0.6720
    Episode_Reward/rotating_object: 149.9752
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.93s
                      Time elapsed: 00:40:06
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 50481 steps/s (collection: 1.810s, learning 0.138s)
             Mean action noise std: 3.21
          Mean value_function loss: 46.6481
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.1075
                       Mean reward: 736.65
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 150.4858
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.95s
                      Time elapsed: 00:40:08
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 51044 steps/s (collection: 1.818s, learning 0.108s)
             Mean action noise std: 3.21
          Mean value_function loss: 40.4875
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.1195
                       Mean reward: 767.44
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 0.6653
    Episode_Reward/rotating_object: 153.2677
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.93s
                      Time elapsed: 00:40:10
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 52854 steps/s (collection: 1.775s, learning 0.085s)
             Mean action noise std: 3.21
          Mean value_function loss: 44.7631
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.1316
                       Mean reward: 775.20
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 0.6747
    Episode_Reward/rotating_object: 153.0514
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.86s
                      Time elapsed: 00:40:12
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 52493 steps/s (collection: 1.785s, learning 0.087s)
             Mean action noise std: 3.21
          Mean value_function loss: 47.9547
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.1472
                       Mean reward: 778.24
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.6761
    Episode_Reward/rotating_object: 154.7410
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.87s
                      Time elapsed: 00:40:14
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 51341 steps/s (collection: 1.823s, learning 0.092s)
             Mean action noise std: 3.21
          Mean value_function loss: 55.0990
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.1582
                       Mean reward: 783.87
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 153.2320
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.91s
                      Time elapsed: 00:40:16
                               ETA: 00:12:14

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 50150 steps/s (collection: 1.874s, learning 0.086s)
             Mean action noise std: 3.22
          Mean value_function loss: 50.1114
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 45.1695
                       Mean reward: 761.06
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 153.2392
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.96s
                      Time elapsed: 00:40:18
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 53352 steps/s (collection: 1.752s, learning 0.091s)
             Mean action noise std: 3.22
          Mean value_function loss: 49.1135
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.1814
                       Mean reward: 761.73
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.6600
    Episode_Reward/rotating_object: 151.1443
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.84s
                      Time elapsed: 00:40:19
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 50816 steps/s (collection: 1.820s, learning 0.115s)
             Mean action noise std: 3.22
          Mean value_function loss: 37.9483
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.1932
                       Mean reward: 747.43
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 153.1585
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.93s
                      Time elapsed: 00:40:21
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 49862 steps/s (collection: 1.857s, learning 0.114s)
             Mean action noise std: 3.22
          Mean value_function loss: 41.0618
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.2066
                       Mean reward: 766.05
               Mean episode length: 242.90
    Episode_Reward/reaching_object: 0.6676
    Episode_Reward/rotating_object: 153.4852
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.97s
                      Time elapsed: 00:40:23
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 50272 steps/s (collection: 1.807s, learning 0.148s)
             Mean action noise std: 3.23
          Mean value_function loss: 45.6579
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.2301
                       Mean reward: 738.84
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 151.9125
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.96s
                      Time elapsed: 00:40:25
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 50311 steps/s (collection: 1.824s, learning 0.130s)
             Mean action noise std: 3.23
          Mean value_function loss: 42.2579
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.2511
                       Mean reward: 786.46
               Mean episode length: 248.80
    Episode_Reward/reaching_object: 0.6680
    Episode_Reward/rotating_object: 151.8392
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.95s
                      Time elapsed: 00:40:27
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 51249 steps/s (collection: 1.799s, learning 0.119s)
             Mean action noise std: 3.23
          Mean value_function loss: 45.9756
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.2606
                       Mean reward: 796.56
               Mean episode length: 249.56
    Episode_Reward/reaching_object: 0.6668
    Episode_Reward/rotating_object: 155.2171
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.92s
                      Time elapsed: 00:40:29
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 51883 steps/s (collection: 1.785s, learning 0.110s)
             Mean action noise std: 3.24
          Mean value_function loss: 41.5848
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.2747
                       Mean reward: 745.64
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 151.7567
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.89s
                      Time elapsed: 00:40:31
                               ETA: 00:11:57

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 51995 steps/s (collection: 1.790s, learning 0.101s)
             Mean action noise std: 3.24
          Mean value_function loss: 45.9240
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.2910
                       Mean reward: 769.69
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 0.6719
    Episode_Reward/rotating_object: 154.5556
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.89s
                      Time elapsed: 00:40:33
                               ETA: 00:11:55

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 52549 steps/s (collection: 1.774s, learning 0.097s)
             Mean action noise std: 3.24
          Mean value_function loss: 45.3755
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.3012
                       Mean reward: 772.60
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.6631
    Episode_Reward/rotating_object: 153.6697
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.87s
                      Time elapsed: 00:40:35
                               ETA: 00:11:53

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 51936 steps/s (collection: 1.795s, learning 0.098s)
             Mean action noise std: 3.24
          Mean value_function loss: 46.3816
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.3120
                       Mean reward: 783.79
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 151.2680
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 1.89s
                      Time elapsed: 00:40:37
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 51690 steps/s (collection: 1.784s, learning 0.118s)
             Mean action noise std: 3.25
          Mean value_function loss: 53.5978
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.3225
                       Mean reward: 757.80
               Mean episode length: 242.15
    Episode_Reward/reaching_object: 0.6543
    Episode_Reward/rotating_object: 151.5812
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.90s
                      Time elapsed: 00:40:39
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 53519 steps/s (collection: 1.748s, learning 0.089s)
             Mean action noise std: 3.25
          Mean value_function loss: 57.7292
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.3404
                       Mean reward: 737.44
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 0.6534
    Episode_Reward/rotating_object: 148.4219
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 1.84s
                      Time elapsed: 00:40:40
                               ETA: 00:11:46

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 51005 steps/s (collection: 1.810s, learning 0.118s)
             Mean action noise std: 3.25
          Mean value_function loss: 49.5315
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.3543
                       Mean reward: 738.85
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 0.6578
    Episode_Reward/rotating_object: 153.1285
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 1.93s
                      Time elapsed: 00:40:42
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 51507 steps/s (collection: 1.753s, learning 0.155s)
             Mean action noise std: 3.25
          Mean value_function loss: 50.1956
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.3622
                       Mean reward: 755.62
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 0.6502
    Episode_Reward/rotating_object: 150.2938
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.91s
                      Time elapsed: 00:40:44
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 52973 steps/s (collection: 1.759s, learning 0.097s)
             Mean action noise std: 3.26
          Mean value_function loss: 36.6903
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.3726
                       Mean reward: 768.01
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 152.1654
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 1.86s
                      Time elapsed: 00:40:46
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 52240 steps/s (collection: 1.776s, learning 0.106s)
             Mean action noise std: 3.26
          Mean value_function loss: 65.2189
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.3883
                       Mean reward: 754.01
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 0.6519
    Episode_Reward/rotating_object: 150.7894
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 1.88s
                      Time elapsed: 00:40:48
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 49091 steps/s (collection: 1.895s, learning 0.107s)
             Mean action noise std: 3.26
          Mean value_function loss: 45.3462
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.4020
                       Mean reward: 780.28
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 151.7840
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.00s
                      Time elapsed: 00:40:50
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 51473 steps/s (collection: 1.795s, learning 0.114s)
             Mean action noise std: 3.26
          Mean value_function loss: 53.3375
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.4095
                       Mean reward: 771.18
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.6599
    Episode_Reward/rotating_object: 148.8826
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 1.91s
                      Time elapsed: 00:40:52
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 52611 steps/s (collection: 1.754s, learning 0.115s)
             Mean action noise std: 3.26
          Mean value_function loss: 39.5201
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.4162
                       Mean reward: 814.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6655
    Episode_Reward/rotating_object: 155.1775
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.87s
                      Time elapsed: 00:40:54
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 51071 steps/s (collection: 1.838s, learning 0.087s)
             Mean action noise std: 3.27
          Mean value_function loss: 46.8588
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 45.4334
                       Mean reward: 748.23
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 0.6613
    Episode_Reward/rotating_object: 149.7388
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 1.92s
                      Time elapsed: 00:40:56
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 51842 steps/s (collection: 1.804s, learning 0.092s)
             Mean action noise std: 3.27
          Mean value_function loss: 51.4270
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.4435
                       Mean reward: 754.95
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 0.6527
    Episode_Reward/rotating_object: 150.1909
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.90s
                      Time elapsed: 00:40:58
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 49143 steps/s (collection: 1.894s, learning 0.106s)
             Mean action noise std: 3.27
          Mean value_function loss: 48.1155
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.4494
                       Mean reward: 802.30
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.6643
    Episode_Reward/rotating_object: 152.9386
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.00s
                      Time elapsed: 00:41:00
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 49205 steps/s (collection: 1.907s, learning 0.091s)
             Mean action noise std: 3.27
          Mean value_function loss: 54.0546
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.4586
                       Mean reward: 797.65
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.6476
    Episode_Reward/rotating_object: 151.1114
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.00s
                      Time elapsed: 00:41:02
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 51151 steps/s (collection: 1.811s, learning 0.111s)
             Mean action noise std: 3.27
          Mean value_function loss: 43.0759
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.4727
                       Mean reward: 781.06
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 0.6669
    Episode_Reward/rotating_object: 156.6342
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.92s
                      Time elapsed: 00:41:03
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 51377 steps/s (collection: 1.815s, learning 0.099s)
             Mean action noise std: 3.28
          Mean value_function loss: 38.0155
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.4892
                       Mean reward: 764.48
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 0.6519
    Episode_Reward/rotating_object: 151.0786
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.91s
                      Time elapsed: 00:41:05
                               ETA: 00:11:18

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 51109 steps/s (collection: 1.812s, learning 0.112s)
             Mean action noise std: 3.28
          Mean value_function loss: 45.6563
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.5023
                       Mean reward: 807.10
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 153.5212
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.92s
                      Time elapsed: 00:41:07
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 51034 steps/s (collection: 1.794s, learning 0.132s)
             Mean action noise std: 3.28
          Mean value_function loss: 49.5848
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.5144
                       Mean reward: 749.27
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 0.6583
    Episode_Reward/rotating_object: 152.5616
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.93s
                      Time elapsed: 00:41:09
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 49904 steps/s (collection: 1.835s, learning 0.135s)
             Mean action noise std: 3.29
          Mean value_function loss: 60.1351
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.5315
                       Mean reward: 756.32
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 0.6485
    Episode_Reward/rotating_object: 149.9826
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.97s
                      Time elapsed: 00:41:11
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 50620 steps/s (collection: 1.842s, learning 0.100s)
             Mean action noise std: 3.29
          Mean value_function loss: 47.7796
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.5441
                       Mean reward: 790.90
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 153.9449
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.94s
                      Time elapsed: 00:41:13
                               ETA: 00:11:10

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 51001 steps/s (collection: 1.829s, learning 0.098s)
             Mean action noise std: 3.29
          Mean value_function loss: 39.1343
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.5590
                       Mean reward: 810.44
               Mean episode length: 248.31
    Episode_Reward/reaching_object: 0.6671
    Episode_Reward/rotating_object: 154.7521
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.93s
                      Time elapsed: 00:41:15
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 51613 steps/s (collection: 1.809s, learning 0.095s)
             Mean action noise std: 3.29
          Mean value_function loss: 61.0099
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.5710
                       Mean reward: 753.89
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 0.6536
    Episode_Reward/rotating_object: 150.5235
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.90s
                      Time elapsed: 00:41:17
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 49916 steps/s (collection: 1.863s, learning 0.106s)
             Mean action noise std: 3.30
          Mean value_function loss: 48.7584
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.5805
                       Mean reward: 748.87
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 0.6611
    Episode_Reward/rotating_object: 151.1722
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.97s
                      Time elapsed: 00:41:19
                               ETA: 00:11:03

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 51614 steps/s (collection: 1.800s, learning 0.105s)
             Mean action noise std: 3.30
          Mean value_function loss: 46.2773
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.5896
                       Mean reward: 746.58
               Mean episode length: 238.74
    Episode_Reward/reaching_object: 0.6623
    Episode_Reward/rotating_object: 151.0816
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.90s
                      Time elapsed: 00:41:21
                               ETA: 00:11:01

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 51765 steps/s (collection: 1.810s, learning 0.089s)
             Mean action noise std: 3.30
          Mean value_function loss: 40.8251
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.6013
                       Mean reward: 799.46
               Mean episode length: 249.86
    Episode_Reward/reaching_object: 0.6723
    Episode_Reward/rotating_object: 155.2345
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.90s
                      Time elapsed: 00:41:23
                               ETA: 00:10:59

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 51238 steps/s (collection: 1.809s, learning 0.109s)
             Mean action noise std: 3.30
          Mean value_function loss: 47.5104
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.6070
                       Mean reward: 780.50
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.6619
    Episode_Reward/rotating_object: 154.1739
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.92s
                      Time elapsed: 00:41:25
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 51748 steps/s (collection: 1.784s, learning 0.116s)
             Mean action noise std: 3.30
          Mean value_function loss: 74.8050
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.6140
                       Mean reward: 741.73
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 0.6425
    Episode_Reward/rotating_object: 147.9040
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.90s
                      Time elapsed: 00:41:27
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 50405 steps/s (collection: 1.828s, learning 0.122s)
             Mean action noise std: 3.30
          Mean value_function loss: 51.9149
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.6259
                       Mean reward: 735.28
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 0.6515
    Episode_Reward/rotating_object: 148.6435
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.95s
                      Time elapsed: 00:41:29
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 51428 steps/s (collection: 1.809s, learning 0.103s)
             Mean action noise std: 3.31
          Mean value_function loss: 41.7696
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.6376
                       Mean reward: 771.77
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 0.6532
    Episode_Reward/rotating_object: 150.8949
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.91s
                      Time elapsed: 00:41:30
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 51677 steps/s (collection: 1.786s, learning 0.116s)
             Mean action noise std: 3.31
          Mean value_function loss: 44.9579
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.6489
                       Mean reward: 771.66
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 0.6670
    Episode_Reward/rotating_object: 154.2135
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.90s
                      Time elapsed: 00:41:32
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 50376 steps/s (collection: 1.849s, learning 0.102s)
             Mean action noise std: 3.31
          Mean value_function loss: 48.1550
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.6577
                       Mean reward: 783.44
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.6519
    Episode_Reward/rotating_object: 150.5583
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.95s
                      Time elapsed: 00:41:34
                               ETA: 00:10:46

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 51662 steps/s (collection: 1.790s, learning 0.113s)
             Mean action noise std: 3.31
          Mean value_function loss: 49.6957
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.6732
                       Mean reward: 763.17
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 154.4621
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.90s
                      Time elapsed: 00:41:36
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 51131 steps/s (collection: 1.824s, learning 0.098s)
             Mean action noise std: 3.32
          Mean value_function loss: 38.2552
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.6886
                       Mean reward: 790.03
               Mean episode length: 247.40
    Episode_Reward/reaching_object: 0.6679
    Episode_Reward/rotating_object: 155.8835
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.92s
                      Time elapsed: 00:41:38
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 52762 steps/s (collection: 1.777s, learning 0.086s)
             Mean action noise std: 3.32
          Mean value_function loss: 59.5535
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.7046
                       Mean reward: 748.41
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 0.6567
    Episode_Reward/rotating_object: 151.0805
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.86s
                      Time elapsed: 00:41:40
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 51426 steps/s (collection: 1.795s, learning 0.116s)
             Mean action noise std: 3.32
          Mean value_function loss: 55.8005
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.7135
                       Mean reward: 728.70
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 0.6568
    Episode_Reward/rotating_object: 147.2362
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.91s
                      Time elapsed: 00:41:42
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 51545 steps/s (collection: 1.794s, learning 0.113s)
             Mean action noise std: 3.32
          Mean value_function loss: 44.5720
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.7210
                       Mean reward: 750.39
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 0.6545
    Episode_Reward/rotating_object: 152.0817
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.91s
                      Time elapsed: 00:41:44
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 52006 steps/s (collection: 1.763s, learning 0.127s)
             Mean action noise std: 3.33
          Mean value_function loss: 43.3553
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 45.7315
                       Mean reward: 792.22
               Mean episode length: 246.58
    Episode_Reward/reaching_object: 0.6646
    Episode_Reward/rotating_object: 153.2077
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.89s
                      Time elapsed: 00:41:46
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 52373 steps/s (collection: 1.787s, learning 0.090s)
             Mean action noise std: 3.33
          Mean value_function loss: 51.8924
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.7482
                       Mean reward: 757.30
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 0.6545
    Episode_Reward/rotating_object: 150.6684
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.88s
                      Time elapsed: 00:41:48
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 49549 steps/s (collection: 1.882s, learning 0.102s)
             Mean action noise std: 3.33
          Mean value_function loss: 48.2218
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.7590
                       Mean reward: 783.99
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 155.2247
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.98s
                      Time elapsed: 00:41:50
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 53201 steps/s (collection: 1.758s, learning 0.090s)
             Mean action noise std: 3.33
          Mean value_function loss: 56.6261
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.7661
                       Mean reward: 782.96
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 151.6863
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.85s
                      Time elapsed: 00:41:51
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 50992 steps/s (collection: 1.795s, learning 0.133s)
             Mean action noise std: 3.34
          Mean value_function loss: 39.4691
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.7772
                       Mean reward: 756.89
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 0.6642
    Episode_Reward/rotating_object: 151.8440
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.93s
                      Time elapsed: 00:41:53
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 51985 steps/s (collection: 1.799s, learning 0.092s)
             Mean action noise std: 3.34
          Mean value_function loss: 46.4118
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.7937
                       Mean reward: 786.33
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 151.0490
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.89s
                      Time elapsed: 00:41:55
                               ETA: 00:10:23

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 52310 steps/s (collection: 1.767s, learning 0.112s)
             Mean action noise std: 3.34
          Mean value_function loss: 55.4837
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.8117
                       Mean reward: 737.58
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 0.6535
    Episode_Reward/rotating_object: 150.2231
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.88s
                      Time elapsed: 00:41:57
                               ETA: 00:10:21

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 51592 steps/s (collection: 1.790s, learning 0.115s)
             Mean action noise std: 3.34
          Mean value_function loss: 43.8646
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.8260
                       Mean reward: 779.01
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 0.6629
    Episode_Reward/rotating_object: 154.2245
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.91s
                      Time elapsed: 00:41:59
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 50215 steps/s (collection: 1.831s, learning 0.126s)
             Mean action noise std: 3.35
          Mean value_function loss: 43.9691
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.8329
                       Mean reward: 711.66
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 0.6671
    Episode_Reward/rotating_object: 152.4526
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.96s
                      Time elapsed: 00:42:01
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 51710 steps/s (collection: 1.798s, learning 0.104s)
             Mean action noise std: 3.35
          Mean value_function loss: 56.9614
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.8439
                       Mean reward: 749.85
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 0.6578
    Episode_Reward/rotating_object: 149.7168
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.90s
                      Time elapsed: 00:42:03
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 53216 steps/s (collection: 1.757s, learning 0.090s)
             Mean action noise std: 3.35
          Mean value_function loss: 48.8617
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.8545
                       Mean reward: 772.04
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 0.6725
    Episode_Reward/rotating_object: 154.3963
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.85s
                      Time elapsed: 00:42:05
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 52538 steps/s (collection: 1.766s, learning 0.105s)
             Mean action noise std: 3.35
          Mean value_function loss: 55.6649
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.8623
                       Mean reward: 761.04
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 0.6588
    Episode_Reward/rotating_object: 151.8947
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.87s
                      Time elapsed: 00:42:07
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 52298 steps/s (collection: 1.762s, learning 0.118s)
             Mean action noise std: 3.35
          Mean value_function loss: 40.7606
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.8734
                       Mean reward: 788.32
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 151.2716
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.88s
                      Time elapsed: 00:42:08
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 53400 steps/s (collection: 1.745s, learning 0.095s)
             Mean action noise std: 3.36
          Mean value_function loss: 42.2231
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.8860
                       Mean reward: 775.44
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 154.9439
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.84s
                      Time elapsed: 00:42:10
                               ETA: 00:10:06

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 51795 steps/s (collection: 1.790s, learning 0.108s)
             Mean action noise std: 3.36
          Mean value_function loss: 56.0319
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.8935
                       Mean reward: 731.64
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 0.6567
    Episode_Reward/rotating_object: 150.8157
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.90s
                      Time elapsed: 00:42:12
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 52227 steps/s (collection: 1.769s, learning 0.114s)
             Mean action noise std: 3.36
          Mean value_function loss: 54.2736
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.8990
                       Mean reward: 787.15
               Mean episode length: 244.91
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 152.2181
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.88s
                      Time elapsed: 00:42:14
                               ETA: 00:10:01

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 51806 steps/s (collection: 1.786s, learning 0.112s)
             Mean action noise std: 3.36
          Mean value_function loss: 48.1122
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.9083
                       Mean reward: 809.27
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.6622
    Episode_Reward/rotating_object: 150.8654
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.90s
                      Time elapsed: 00:42:16
                               ETA: 00:09:59

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 52174 steps/s (collection: 1.782s, learning 0.102s)
             Mean action noise std: 3.36
          Mean value_function loss: 47.2811
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.9196
                       Mean reward: 747.07
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 0.6614
    Episode_Reward/rotating_object: 154.2377
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.88s
                      Time elapsed: 00:42:18
                               ETA: 00:09:57

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 49018 steps/s (collection: 1.892s, learning 0.114s)
             Mean action noise std: 3.37
          Mean value_function loss: 49.5156
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.9311
                       Mean reward: 729.16
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 0.6576
    Episode_Reward/rotating_object: 151.3841
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.01s
                      Time elapsed: 00:42:20
                               ETA: 00:09:55

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 52188 steps/s (collection: 1.786s, learning 0.098s)
             Mean action noise std: 3.37
          Mean value_function loss: 53.0710
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.9441
                       Mean reward: 753.57
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 0.6617
    Episode_Reward/rotating_object: 152.6560
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.88s
                      Time elapsed: 00:42:22
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 49497 steps/s (collection: 1.801s, learning 0.185s)
             Mean action noise std: 3.37
          Mean value_function loss: 39.5509
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.9540
                       Mean reward: 758.03
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 0.6627
    Episode_Reward/rotating_object: 151.8865
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.99s
                      Time elapsed: 00:42:24
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 53058 steps/s (collection: 1.743s, learning 0.110s)
             Mean action noise std: 3.37
          Mean value_function loss: 52.0436
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.9626
                       Mean reward: 761.61
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 154.1296
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.85s
                      Time elapsed: 00:42:26
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 52187 steps/s (collection: 1.792s, learning 0.092s)
             Mean action noise std: 3.38
          Mean value_function loss: 39.5856
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.9733
                       Mean reward: 759.28
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 154.3295
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.88s
                      Time elapsed: 00:42:27
                               ETA: 00:09:46

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 53552 steps/s (collection: 1.735s, learning 0.101s)
             Mean action noise std: 3.38
          Mean value_function loss: 50.2324
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.9790
                       Mean reward: 750.90
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 0.6623
    Episode_Reward/rotating_object: 151.9845
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.84s
                      Time elapsed: 00:42:29
                               ETA: 00:09:44

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 52711 steps/s (collection: 1.777s, learning 0.087s)
             Mean action noise std: 3.38
          Mean value_function loss: 46.9053
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.9870
                       Mean reward: 759.55
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 0.6718
    Episode_Reward/rotating_object: 152.9194
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.86s
                      Time elapsed: 00:42:31
                               ETA: 00:09:42

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 52200 steps/s (collection: 1.769s, learning 0.115s)
             Mean action noise std: 3.38
          Mean value_function loss: 40.8891
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.9996
                       Mean reward: 761.01
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 0.6679
    Episode_Reward/rotating_object: 152.8313
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.88s
                      Time elapsed: 00:42:33
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 51948 steps/s (collection: 1.778s, learning 0.114s)
             Mean action noise std: 3.38
          Mean value_function loss: 43.7036
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.0052
                       Mean reward: 733.66
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.6614
    Episode_Reward/rotating_object: 149.0970
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.89s
                      Time elapsed: 00:42:35
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 52109 steps/s (collection: 1.792s, learning 0.095s)
             Mean action noise std: 3.39
          Mean value_function loss: 55.6764
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.0126
                       Mean reward: 770.04
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 0.6549
    Episode_Reward/rotating_object: 149.5812
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.89s
                      Time elapsed: 00:42:37
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 52951 steps/s (collection: 1.741s, learning 0.115s)
             Mean action noise std: 3.39
          Mean value_function loss: 44.6224
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.0237
                       Mean reward: 781.62
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.6759
    Episode_Reward/rotating_object: 153.8870
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.86s
                      Time elapsed: 00:42:39
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 51617 steps/s (collection: 1.804s, learning 0.100s)
             Mean action noise std: 3.39
          Mean value_function loss: 41.8498
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.0380
                       Mean reward: 763.03
               Mean episode length: 235.66
    Episode_Reward/reaching_object: 0.6634
    Episode_Reward/rotating_object: 152.4924
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.90s
                      Time elapsed: 00:42:41
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 52276 steps/s (collection: 1.785s, learning 0.095s)
             Mean action noise std: 3.39
          Mean value_function loss: 59.1393
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 46.0479
                       Mean reward: 744.26
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 0.6723
    Episode_Reward/rotating_object: 151.5501
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.88s
                      Time elapsed: 00:42:42
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 52088 steps/s (collection: 1.765s, learning 0.122s)
             Mean action noise std: 3.39
          Mean value_function loss: 54.2206
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 46.0557
                       Mean reward: 779.53
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.6660
    Episode_Reward/rotating_object: 153.3658
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.89s
                      Time elapsed: 00:42:44
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 51336 steps/s (collection: 1.815s, learning 0.099s)
             Mean action noise std: 3.40
          Mean value_function loss: 43.7509
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.0703
                       Mean reward: 788.07
               Mean episode length: 245.40
    Episode_Reward/reaching_object: 0.6791
    Episode_Reward/rotating_object: 153.7113
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.91s
                      Time elapsed: 00:42:46
                               ETA: 00:09:25

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 51845 steps/s (collection: 1.802s, learning 0.094s)
             Mean action noise std: 3.40
          Mean value_function loss: 36.6332
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.0818
                       Mean reward: 812.09
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6869
    Episode_Reward/rotating_object: 157.3745
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.90s
                      Time elapsed: 00:42:48
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 52206 steps/s (collection: 1.771s, learning 0.112s)
             Mean action noise std: 3.40
          Mean value_function loss: 44.7129
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.0958
                       Mean reward: 766.67
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 0.6695
    Episode_Reward/rotating_object: 153.3994
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 1.88s
                      Time elapsed: 00:42:50
                               ETA: 00:09:21

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 51199 steps/s (collection: 1.821s, learning 0.099s)
             Mean action noise std: 3.41
          Mean value_function loss: 48.6210
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 46.1104
                       Mean reward: 785.82
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 0.6831
    Episode_Reward/rotating_object: 155.7854
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 1.92s
                      Time elapsed: 00:42:52
                               ETA: 00:09:19

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 51784 steps/s (collection: 1.713s, learning 0.185s)
             Mean action noise std: 3.41
          Mean value_function loss: 49.6709
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.1269
                       Mean reward: 770.16
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 0.6733
    Episode_Reward/rotating_object: 152.1947
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 1.90s
                      Time elapsed: 00:42:54
                               ETA: 00:09:17

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 52813 steps/s (collection: 1.726s, learning 0.135s)
             Mean action noise std: 3.41
          Mean value_function loss: 40.8985
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.1413
                       Mean reward: 796.64
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.6841
    Episode_Reward/rotating_object: 156.2165
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.86s
                      Time elapsed: 00:42:56
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 52625 steps/s (collection: 1.770s, learning 0.098s)
             Mean action noise std: 3.41
          Mean value_function loss: 40.9038
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.1523
                       Mean reward: 794.37
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.6730
    Episode_Reward/rotating_object: 155.0537
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 1.87s
                      Time elapsed: 00:42:58
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 52099 steps/s (collection: 1.785s, learning 0.102s)
             Mean action noise std: 3.42
          Mean value_function loss: 51.1193
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.1610
                       Mean reward: 766.45
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 0.6662
    Episode_Reward/rotating_object: 152.8319
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 1.89s
                      Time elapsed: 00:42:59
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 51040 steps/s (collection: 1.825s, learning 0.101s)
             Mean action noise std: 3.42
          Mean value_function loss: 33.3377
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 46.1719
                       Mean reward: 784.73
               Mean episode length: 246.97
    Episode_Reward/reaching_object: 0.6775
    Episode_Reward/rotating_object: 154.9072
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 1.93s
                      Time elapsed: 00:43:01
                               ETA: 00:09:08

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 51855 steps/s (collection: 1.788s, learning 0.108s)
             Mean action noise std: 3.42
          Mean value_function loss: 51.6436
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.1815
                       Mean reward: 755.85
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.6739
    Episode_Reward/rotating_object: 151.5833
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 1.90s
                      Time elapsed: 00:43:03
                               ETA: 00:09:06

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 51023 steps/s (collection: 1.830s, learning 0.097s)
             Mean action noise std: 3.42
          Mean value_function loss: 41.4794
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.1891
                       Mean reward: 780.02
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 0.6732
    Episode_Reward/rotating_object: 155.1522
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 1.93s
                      Time elapsed: 00:43:05
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 52898 steps/s (collection: 1.762s, learning 0.096s)
             Mean action noise std: 3.42
          Mean value_function loss: 56.7303
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.1973
                       Mean reward: 804.97
               Mean episode length: 246.66
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 153.1113
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 1.86s
                      Time elapsed: 00:43:07
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 52729 steps/s (collection: 1.738s, learning 0.126s)
             Mean action noise std: 3.43
          Mean value_function loss: 47.3269
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.2064
                       Mean reward: 777.38
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 0.6637
    Episode_Reward/rotating_object: 153.1115
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.86s
                      Time elapsed: 00:43:09
                               ETA: 00:08:59

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 49346 steps/s (collection: 1.833s, learning 0.160s)
             Mean action noise std: 3.43
          Mean value_function loss: 36.9266
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.2219
                       Mean reward: 771.47
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 0.6712
    Episode_Reward/rotating_object: 152.9192
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 1.99s
                      Time elapsed: 00:43:11
                               ETA: 00:08:57

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 50469 steps/s (collection: 1.801s, learning 0.147s)
             Mean action noise std: 3.43
          Mean value_function loss: 36.8714
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.2360
                       Mean reward: 760.49
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.6808
    Episode_Reward/rotating_object: 153.8186
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 1.95s
                      Time elapsed: 00:43:13
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 50098 steps/s (collection: 1.820s, learning 0.143s)
             Mean action noise std: 3.43
          Mean value_function loss: 49.6566
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.2451
                       Mean reward: 781.08
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 0.6733
    Episode_Reward/rotating_object: 154.5328
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 1.96s
                      Time elapsed: 00:43:15
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 49971 steps/s (collection: 1.819s, learning 0.148s)
             Mean action noise std: 3.44
          Mean value_function loss: 49.5052
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 46.2579
                       Mean reward: 774.20
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 0.6662
    Episode_Reward/rotating_object: 153.0289
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 1.97s
                      Time elapsed: 00:43:17
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 50704 steps/s (collection: 1.815s, learning 0.124s)
             Mean action noise std: 3.44
          Mean value_function loss: 43.3352
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 46.2668
                       Mean reward: 758.20
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.6739
    Episode_Reward/rotating_object: 155.5781
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 1.94s
                      Time elapsed: 00:43:19
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 51773 steps/s (collection: 1.780s, learning 0.119s)
             Mean action noise std: 3.44
          Mean value_function loss: 35.9918
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.2767
                       Mean reward: 780.37
               Mean episode length: 246.41
    Episode_Reward/reaching_object: 0.6833
    Episode_Reward/rotating_object: 154.0389
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 1.90s
                      Time elapsed: 00:43:21
                               ETA: 00:08:47

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 51494 steps/s (collection: 1.789s, learning 0.120s)
             Mean action noise std: 3.44
          Mean value_function loss: 32.4746
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.2927
                       Mean reward: 798.70
               Mean episode length: 244.53
    Episode_Reward/reaching_object: 0.6788
    Episode_Reward/rotating_object: 154.3159
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.91s
                      Time elapsed: 00:43:23
                               ETA: 00:08:45

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 50988 steps/s (collection: 1.772s, learning 0.156s)
             Mean action noise std: 3.45
          Mean value_function loss: 49.6613
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.3044
                       Mean reward: 769.91
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.6846
    Episode_Reward/rotating_object: 155.3818
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 1.93s
                      Time elapsed: 00:43:24
                               ETA: 00:08:43

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 51194 steps/s (collection: 1.830s, learning 0.090s)
             Mean action noise std: 3.45
          Mean value_function loss: 35.1593
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.3166
                       Mean reward: 760.41
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 0.6816
    Episode_Reward/rotating_object: 154.0455
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 1.92s
                      Time elapsed: 00:43:26
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 53004 steps/s (collection: 1.759s, learning 0.096s)
             Mean action noise std: 3.45
          Mean value_function loss: 42.0837
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.3284
                       Mean reward: 777.44
               Mean episode length: 242.88
    Episode_Reward/reaching_object: 0.6859
    Episode_Reward/rotating_object: 155.1314
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 1.85s
                      Time elapsed: 00:43:28
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 52437 steps/s (collection: 1.787s, learning 0.088s)
             Mean action noise std: 3.45
          Mean value_function loss: 43.9366
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.3399
                       Mean reward: 748.46
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 0.6799
    Episode_Reward/rotating_object: 152.9573
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 1.87s
                      Time elapsed: 00:43:30
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 51555 steps/s (collection: 1.786s, learning 0.121s)
             Mean action noise std: 3.45
          Mean value_function loss: 50.9630
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.3467
                       Mean reward: 771.89
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 0.6792
    Episode_Reward/rotating_object: 152.4803
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 1.91s
                      Time elapsed: 00:43:32
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 50624 steps/s (collection: 1.820s, learning 0.122s)
             Mean action noise std: 3.46
          Mean value_function loss: 42.0456
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.3537
                       Mean reward: 761.32
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.6863
    Episode_Reward/rotating_object: 154.3799
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 1.94s
                      Time elapsed: 00:43:34
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 46519 steps/s (collection: 1.999s, learning 0.115s)
             Mean action noise std: 3.46
          Mean value_function loss: 46.8622
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 46.3623
                       Mean reward: 766.30
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 0.6874
    Episode_Reward/rotating_object: 154.5882
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.11s
                      Time elapsed: 00:43:36
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 47963 steps/s (collection: 1.928s, learning 0.122s)
             Mean action noise std: 3.46
          Mean value_function loss: 42.4519
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.3697
                       Mean reward: 769.70
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 0.6806
    Episode_Reward/rotating_object: 154.8892
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.05s
                      Time elapsed: 00:43:38
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 43994 steps/s (collection: 2.017s, learning 0.218s)
             Mean action noise std: 3.46
          Mean value_function loss: 42.1311
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.3778
                       Mean reward: 777.42
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 0.6812
    Episode_Reward/rotating_object: 155.1005
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.23s
                      Time elapsed: 00:43:40
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 46401 steps/s (collection: 2.026s, learning 0.093s)
             Mean action noise std: 3.46
          Mean value_function loss: 32.5227
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 46.3870
                       Mean reward: 801.54
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.6927
    Episode_Reward/rotating_object: 154.9286
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.12s
                      Time elapsed: 00:43:43
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 52200 steps/s (collection: 1.790s, learning 0.094s)
             Mean action noise std: 3.47
          Mean value_function loss: 42.2376
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.3946
                       Mean reward: 800.41
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.6812
    Episode_Reward/rotating_object: 154.1317
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 1.88s
                      Time elapsed: 00:43:44
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 39720 steps/s (collection: 2.214s, learning 0.261s)
             Mean action noise std: 3.47
          Mean value_function loss: 55.7086
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.4042
                       Mean reward: 750.62
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 0.6799
    Episode_Reward/rotating_object: 152.6339
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.47s
                      Time elapsed: 00:43:47
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 35187 steps/s (collection: 2.662s, learning 0.132s)
             Mean action noise std: 3.47
          Mean value_function loss: 46.8962
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 46.4122
                       Mean reward: 779.25
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 0.6693
    Episode_Reward/rotating_object: 151.5900
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.79s
                      Time elapsed: 00:43:50
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 26898 steps/s (collection: 3.375s, learning 0.280s)
             Mean action noise std: 3.47
          Mean value_function loss: 44.9553
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.4172
                       Mean reward: 759.58
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.6835
    Episode_Reward/rotating_object: 152.7310
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 3.65s
                      Time elapsed: 00:43:53
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 40076 steps/s (collection: 2.287s, learning 0.166s)
             Mean action noise std: 3.47
          Mean value_function loss: 38.8146
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.4277
                       Mean reward: 762.18
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 0.6894
    Episode_Reward/rotating_object: 153.1374
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.45s
                      Time elapsed: 00:43:56
                               ETA: 00:08:14

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 36467 steps/s (collection: 2.513s, learning 0.183s)
             Mean action noise std: 3.48
          Mean value_function loss: 33.7657
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.4399
                       Mean reward: 817.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6832
    Episode_Reward/rotating_object: 152.9519
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.70s
                      Time elapsed: 00:43:58
                               ETA: 00:08:12

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 40050 steps/s (collection: 2.310s, learning 0.144s)
             Mean action noise std: 3.48
          Mean value_function loss: 38.3740
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.4517
                       Mean reward: 809.90
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6848
    Episode_Reward/rotating_object: 155.6166
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.45s
                      Time elapsed: 00:44:01
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 44274 steps/s (collection: 2.120s, learning 0.100s)
             Mean action noise std: 3.48
          Mean value_function loss: 43.2257
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 46.4616
                       Mean reward: 757.16
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 0.6804
    Episode_Reward/rotating_object: 153.9222
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.22s
                      Time elapsed: 00:44:03
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 42800 steps/s (collection: 2.154s, learning 0.142s)
             Mean action noise std: 3.48
          Mean value_function loss: 28.7502
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.4693
                       Mean reward: 791.21
               Mean episode length: 246.67
    Episode_Reward/reaching_object: 0.6906
    Episode_Reward/rotating_object: 156.1351
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.30s
                      Time elapsed: 00:44:05
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 40521 steps/s (collection: 2.299s, learning 0.127s)
             Mean action noise std: 3.48
          Mean value_function loss: 44.0699
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 46.4757
                       Mean reward: 801.17
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.6968
    Episode_Reward/rotating_object: 157.0748
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.43s
                      Time elapsed: 00:44:08
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 42263 steps/s (collection: 2.145s, learning 0.181s)
             Mean action noise std: 3.49
          Mean value_function loss: 30.8826
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.4822
                       Mean reward: 802.78
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.6917
    Episode_Reward/rotating_object: 154.3462
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.33s
                      Time elapsed: 00:44:10
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 37057 steps/s (collection: 2.470s, learning 0.183s)
             Mean action noise std: 3.49
          Mean value_function loss: 41.5715
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 46.4940
                       Mean reward: 776.24
               Mean episode length: 243.04
    Episode_Reward/reaching_object: 0.6873
    Episode_Reward/rotating_object: 154.7055
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.65s
                      Time elapsed: 00:44:13
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 40585 steps/s (collection: 2.228s, learning 0.194s)
             Mean action noise std: 3.49
          Mean value_function loss: 35.4459
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.4998
                       Mean reward: 779.87
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.6937
    Episode_Reward/rotating_object: 155.4538
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.42s
                      Time elapsed: 00:44:15
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 42040 steps/s (collection: 2.210s, learning 0.128s)
             Mean action noise std: 3.49
          Mean value_function loss: 46.0996
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.5059
                       Mean reward: 756.60
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 0.6866
    Episode_Reward/rotating_object: 153.9144
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.34s
                      Time elapsed: 00:44:18
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 43884 steps/s (collection: 2.113s, learning 0.127s)
             Mean action noise std: 3.49
          Mean value_function loss: 38.9314
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 46.5139
                       Mean reward: 764.91
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 0.6909
    Episode_Reward/rotating_object: 156.5495
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.24s
                      Time elapsed: 00:44:20
                               ETA: 00:07:54

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 41263 steps/s (collection: 2.247s, learning 0.135s)
             Mean action noise std: 3.49
          Mean value_function loss: 44.0043
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 46.5209
                       Mean reward: 762.16
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 0.6879
    Episode_Reward/rotating_object: 153.4722
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.38s
                      Time elapsed: 00:44:22
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 43225 steps/s (collection: 2.134s, learning 0.140s)
             Mean action noise std: 3.49
          Mean value_function loss: 43.4730
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.5243
                       Mean reward: 765.71
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 154.3323
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.27s
                      Time elapsed: 00:44:25
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 41235 steps/s (collection: 2.258s, learning 0.126s)
             Mean action noise std: 3.50
          Mean value_function loss: 46.7039
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.5309
                       Mean reward: 793.84
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.6974
    Episode_Reward/rotating_object: 156.7481
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.38s
                      Time elapsed: 00:44:27
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 35354 steps/s (collection: 2.526s, learning 0.255s)
             Mean action noise std: 3.50
          Mean value_function loss: 37.2511
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.5404
                       Mean reward: 764.35
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 0.6980
    Episode_Reward/rotating_object: 154.6519
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.78s
                      Time elapsed: 00:44:30
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 40450 steps/s (collection: 2.282s, learning 0.149s)
             Mean action noise std: 3.50
          Mean value_function loss: 62.7718
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 46.5511
                       Mean reward: 788.74
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 0.6947
    Episode_Reward/rotating_object: 155.4104
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.43s
                      Time elapsed: 00:44:32
                               ETA: 00:07:43

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 41835 steps/s (collection: 2.214s, learning 0.136s)
             Mean action noise std: 3.50
          Mean value_function loss: 56.1465
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.5613
                       Mean reward: 754.69
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 0.6859
    Episode_Reward/rotating_object: 152.1386
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.35s
                      Time elapsed: 00:44:34
                               ETA: 00:07:41

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 38070 steps/s (collection: 2.374s, learning 0.209s)
             Mean action noise std: 3.51
          Mean value_function loss: 45.1864
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.5716
                       Mean reward: 767.31
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 0.6915
    Episode_Reward/rotating_object: 154.4517
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.58s
                      Time elapsed: 00:44:37
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 38721 steps/s (collection: 2.395s, learning 0.143s)
             Mean action noise std: 3.51
          Mean value_function loss: 34.5621
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 46.5841
                       Mean reward: 805.06
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7011
    Episode_Reward/rotating_object: 155.2984
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.54s
                      Time elapsed: 00:44:40
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 38940 steps/s (collection: 2.366s, learning 0.158s)
             Mean action noise std: 3.51
          Mean value_function loss: 45.8934
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 46.5930
                       Mean reward: 762.18
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.6898
    Episode_Reward/rotating_object: 152.7159
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.52s
                      Time elapsed: 00:44:42
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 42960 steps/s (collection: 2.166s, learning 0.122s)
             Mean action noise std: 3.51
          Mean value_function loss: 50.5304
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.5953
                       Mean reward: 802.27
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 0.6911
    Episode_Reward/rotating_object: 155.4870
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.29s
                      Time elapsed: 00:44:44
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 40527 steps/s (collection: 2.301s, learning 0.124s)
             Mean action noise std: 3.51
          Mean value_function loss: 50.7035
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.6020
                       Mean reward: 783.74
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 0.6957
    Episode_Reward/rotating_object: 154.7349
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.43s
                      Time elapsed: 00:44:47
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 43240 steps/s (collection: 2.141s, learning 0.132s)
             Mean action noise std: 3.51
          Mean value_function loss: 42.9650
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.6116
                       Mean reward: 739.04
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 0.6994
    Episode_Reward/rotating_object: 153.0335
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.27s
                      Time elapsed: 00:44:49
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 42199 steps/s (collection: 2.187s, learning 0.143s)
             Mean action noise std: 3.52
          Mean value_function loss: 28.6944
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.6243
                       Mean reward: 783.94
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 0.7028
    Episode_Reward/rotating_object: 156.2772
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.33s
                      Time elapsed: 00:44:51
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 41432 steps/s (collection: 2.231s, learning 0.142s)
             Mean action noise std: 3.52
          Mean value_function loss: 44.5413
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.6284
                       Mean reward: 773.97
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.6952
    Episode_Reward/rotating_object: 155.8207
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.37s
                      Time elapsed: 00:44:54
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 41069 steps/s (collection: 2.194s, learning 0.200s)
             Mean action noise std: 3.52
          Mean value_function loss: 46.9561
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 46.6319
                       Mean reward: 783.42
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 0.6893
    Episode_Reward/rotating_object: 153.6212
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.39s
                      Time elapsed: 00:44:56
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 40738 steps/s (collection: 2.285s, learning 0.128s)
             Mean action noise std: 3.52
          Mean value_function loss: 46.3018
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.6357
                       Mean reward: 740.76
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 154.2587
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.41s
                      Time elapsed: 00:44:59
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 35529 steps/s (collection: 2.469s, learning 0.297s)
             Mean action noise std: 3.52
          Mean value_function loss: 43.3029
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 46.6422
                       Mean reward: 781.91
               Mean episode length: 244.34
    Episode_Reward/reaching_object: 0.6851
    Episode_Reward/rotating_object: 153.0266
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.77s
                      Time elapsed: 00:45:01
                               ETA: 00:07:19

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 39936 steps/s (collection: 2.331s, learning 0.130s)
             Mean action noise std: 3.52
          Mean value_function loss: 48.0597
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.6485
                       Mean reward: 702.16
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 0.6880
    Episode_Reward/rotating_object: 153.1698
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.46s
                      Time elapsed: 00:45:04
                               ETA: 00:07:17

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 39507 steps/s (collection: 2.279s, learning 0.209s)
             Mean action noise std: 3.52
          Mean value_function loss: 40.4183
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.6523
                       Mean reward: 776.78
               Mean episode length: 245.21
    Episode_Reward/reaching_object: 0.6937
    Episode_Reward/rotating_object: 155.4457
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.49s
                      Time elapsed: 00:45:06
                               ETA: 00:07:15

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 37135 steps/s (collection: 2.450s, learning 0.197s)
             Mean action noise std: 3.53
          Mean value_function loss: 54.1046
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.6612
                       Mean reward: 738.92
               Mean episode length: 233.26
    Episode_Reward/reaching_object: 0.6731
    Episode_Reward/rotating_object: 150.6215
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.65s
                      Time elapsed: 00:45:09
                               ETA: 00:07:13

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 38747 steps/s (collection: 2.281s, learning 0.256s)
             Mean action noise std: 3.53
          Mean value_function loss: 37.3618
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 46.6770
                       Mean reward: 773.78
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.6856
    Episode_Reward/rotating_object: 155.5320
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.54s
                      Time elapsed: 00:45:11
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 39473 steps/s (collection: 2.377s, learning 0.113s)
             Mean action noise std: 3.53
          Mean value_function loss: 48.6021
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.6920
                       Mean reward: 765.79
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 0.6774
    Episode_Reward/rotating_object: 153.1364
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.49s
                      Time elapsed: 00:45:14
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 41710 steps/s (collection: 2.183s, learning 0.174s)
             Mean action noise std: 3.54
          Mean value_function loss: 40.7287
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.7081
                       Mean reward: 795.66
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.6845
    Episode_Reward/rotating_object: 154.3489
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.36s
                      Time elapsed: 00:45:16
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 43398 steps/s (collection: 2.159s, learning 0.107s)
             Mean action noise std: 3.54
          Mean value_function loss: 41.2200
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.7201
                       Mean reward: 745.37
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 0.6833
    Episode_Reward/rotating_object: 154.9866
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.27s
                      Time elapsed: 00:45:19
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 44988 steps/s (collection: 2.073s, learning 0.112s)
             Mean action noise std: 3.54
          Mean value_function loss: 46.0022
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.7302
                       Mean reward: 807.78
               Mean episode length: 247.05
    Episode_Reward/reaching_object: 0.6752
    Episode_Reward/rotating_object: 155.0972
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.19s
                      Time elapsed: 00:45:21
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 43128 steps/s (collection: 2.173s, learning 0.106s)
             Mean action noise std: 3.54
          Mean value_function loss: 50.6080
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.7398
                       Mean reward: 773.97
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 0.6732
    Episode_Reward/rotating_object: 155.0349
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.28s
                      Time elapsed: 00:45:23
                               ETA: 00:07:01

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 38880 steps/s (collection: 2.363s, learning 0.166s)
             Mean action noise std: 3.54
          Mean value_function loss: 35.1818
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 46.7510
                       Mean reward: 790.97
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 0.6806
    Episode_Reward/rotating_object: 156.3022
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.53s
                      Time elapsed: 00:45:26
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 43265 steps/s (collection: 2.161s, learning 0.111s)
             Mean action noise std: 3.55
          Mean value_function loss: 29.3259
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.7581
                       Mean reward: 814.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6874
    Episode_Reward/rotating_object: 155.9842
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.27s
                      Time elapsed: 00:45:28
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 41406 steps/s (collection: 2.262s, learning 0.112s)
             Mean action noise std: 3.55
          Mean value_function loss: 42.4543
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.7649
                       Mean reward: 786.81
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 153.0215
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.37s
                      Time elapsed: 00:45:30
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 35996 steps/s (collection: 2.506s, learning 0.225s)
             Mean action noise std: 3.55
          Mean value_function loss: 58.5021
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.7733
                       Mean reward: 758.31
               Mean episode length: 237.80
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 152.7734
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.73s
                      Time elapsed: 00:45:33
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 41469 steps/s (collection: 2.222s, learning 0.149s)
             Mean action noise std: 3.55
          Mean value_function loss: 43.8299
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.7808
                       Mean reward: 757.50
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 152.1554
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.37s
                      Time elapsed: 00:45:35
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 41185 steps/s (collection: 2.288s, learning 0.099s)
             Mean action noise std: 3.55
          Mean value_function loss: 46.8228
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.7899
                       Mean reward: 772.70
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 0.6782
    Episode_Reward/rotating_object: 154.3589
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.39s
                      Time elapsed: 00:45:38
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 40850 steps/s (collection: 2.261s, learning 0.146s)
             Mean action noise std: 3.56
          Mean value_function loss: 47.7661
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.7987
                       Mean reward: 763.76
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 0.6870
    Episode_Reward/rotating_object: 155.0426
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.41s
                      Time elapsed: 00:45:40
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 39166 steps/s (collection: 2.384s, learning 0.126s)
             Mean action noise std: 3.56
          Mean value_function loss: 41.4663
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.8034
                       Mean reward: 751.93
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 0.6709
    Episode_Reward/rotating_object: 152.7043
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.51s
                      Time elapsed: 00:45:43
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 39669 steps/s (collection: 2.308s, learning 0.171s)
             Mean action noise std: 3.56
          Mean value_function loss: 41.7876
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.8101
                       Mean reward: 787.70
               Mean episode length: 246.12
    Episode_Reward/reaching_object: 0.6814
    Episode_Reward/rotating_object: 153.4268
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.48s
                      Time elapsed: 00:45:45
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 42344 steps/s (collection: 2.189s, learning 0.132s)
             Mean action noise std: 3.56
          Mean value_function loss: 36.3397
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.8186
                       Mean reward: 797.26
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.6875
    Episode_Reward/rotating_object: 154.7157
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.32s
                      Time elapsed: 00:45:47
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 37643 steps/s (collection: 2.465s, learning 0.146s)
             Mean action noise std: 3.56
          Mean value_function loss: 36.1001
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.8267
                       Mean reward: 807.72
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6941
    Episode_Reward/rotating_object: 158.6628
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.61s
                      Time elapsed: 00:45:50
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 38532 steps/s (collection: 2.330s, learning 0.221s)
             Mean action noise std: 3.56
          Mean value_function loss: 41.0133
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 46.8399
                       Mean reward: 805.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6796
    Episode_Reward/rotating_object: 154.7743
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.55s
                      Time elapsed: 00:45:53
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 42947 steps/s (collection: 2.178s, learning 0.111s)
             Mean action noise std: 3.57
          Mean value_function loss: 39.5900
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.8477
                       Mean reward: 810.08
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6859
    Episode_Reward/rotating_object: 156.8170
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.29s
                      Time elapsed: 00:45:55
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 38485 steps/s (collection: 2.368s, learning 0.187s)
             Mean action noise std: 3.57
          Mean value_function loss: 45.7942
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.8579
                       Mean reward: 799.83
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 0.6886
    Episode_Reward/rotating_object: 157.0944
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.55s
                      Time elapsed: 00:45:57
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 37175 steps/s (collection: 2.531s, learning 0.113s)
             Mean action noise std: 3.57
          Mean value_function loss: 42.3806
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.8636
                       Mean reward: 766.65
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.6880
    Episode_Reward/rotating_object: 153.6384
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.64s
                      Time elapsed: 00:46:00
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 37526 steps/s (collection: 2.418s, learning 0.201s)
             Mean action noise std: 3.57
          Mean value_function loss: 36.4199
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.8691
                       Mean reward: 779.31
               Mean episode length: 248.48
    Episode_Reward/reaching_object: 0.6956
    Episode_Reward/rotating_object: 155.1363
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.62s
                      Time elapsed: 00:46:03
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 36886 steps/s (collection: 2.561s, learning 0.104s)
             Mean action noise std: 3.57
          Mean value_function loss: 36.1812
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.8772
                       Mean reward: 779.03
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.6747
    Episode_Reward/rotating_object: 152.1875
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.67s
                      Time elapsed: 00:46:05
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 42471 steps/s (collection: 2.208s, learning 0.106s)
             Mean action noise std: 3.57
          Mean value_function loss: 44.5054
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.8817
                       Mean reward: 792.40
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 0.6785
    Episode_Reward/rotating_object: 153.7397
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.31s
                      Time elapsed: 00:46:08
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 41340 steps/s (collection: 2.199s, learning 0.179s)
             Mean action noise std: 3.58
          Mean value_function loss: 42.9088
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.8926
                       Mean reward: 772.45
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 0.6948
    Episode_Reward/rotating_object: 156.7135
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.38s
                      Time elapsed: 00:46:10
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 34853 steps/s (collection: 2.570s, learning 0.250s)
             Mean action noise std: 3.58
          Mean value_function loss: 41.2258
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.9063
                       Mean reward: 800.89
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.6891
    Episode_Reward/rotating_object: 155.1683
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.82s
                      Time elapsed: 00:46:13
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 38102 steps/s (collection: 2.454s, learning 0.125s)
             Mean action noise std: 3.58
          Mean value_function loss: 49.2866
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.9165
                       Mean reward: 780.40
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 152.5576
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.58s
                      Time elapsed: 00:46:15
                               ETA: 00:06:18

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 38861 steps/s (collection: 2.406s, learning 0.124s)
             Mean action noise std: 3.58
          Mean value_function loss: 36.5568
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.9248
                       Mean reward: 763.25
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 0.6922
    Episode_Reward/rotating_object: 154.1757
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.53s
                      Time elapsed: 00:46:18
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 41491 steps/s (collection: 2.231s, learning 0.138s)
             Mean action noise std: 3.58
          Mean value_function loss: 43.8634
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.9319
                       Mean reward: 784.12
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.6956
    Episode_Reward/rotating_object: 155.7636
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.37s
                      Time elapsed: 00:46:20
                               ETA: 00:06:14

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 38115 steps/s (collection: 2.471s, learning 0.108s)
             Mean action noise std: 3.59
          Mean value_function loss: 40.5926
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.9434
                       Mean reward: 784.22
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 0.6985
    Episode_Reward/rotating_object: 156.0322
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.58s
                      Time elapsed: 00:46:23
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 37527 steps/s (collection: 2.397s, learning 0.222s)
             Mean action noise std: 3.59
          Mean value_function loss: 24.7997
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 46.9526
                       Mean reward: 793.34
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7002
    Episode_Reward/rotating_object: 157.5518
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.62s
                      Time elapsed: 00:46:26
                               ETA: 00:06:10

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 41611 steps/s (collection: 2.228s, learning 0.135s)
             Mean action noise std: 3.59
          Mean value_function loss: 37.5740
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 46.9594
                       Mean reward: 810.14
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.6983
    Episode_Reward/rotating_object: 157.9460
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.36s
                      Time elapsed: 00:46:28
                               ETA: 00:06:08

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 42161 steps/s (collection: 2.207s, learning 0.125s)
             Mean action noise std: 3.59
          Mean value_function loss: 55.6671
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 46.9629
                       Mean reward: 780.82
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 155.1657
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.33s
                      Time elapsed: 00:46:30
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 42735 steps/s (collection: 2.163s, learning 0.137s)
             Mean action noise std: 3.59
          Mean value_function loss: 41.0254
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.9675
                       Mean reward: 800.89
               Mean episode length: 245.13
    Episode_Reward/reaching_object: 0.6918
    Episode_Reward/rotating_object: 154.8759
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.30s
                      Time elapsed: 00:46:33
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 40111 steps/s (collection: 2.311s, learning 0.139s)
             Mean action noise std: 3.60
          Mean value_function loss: 35.7045
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 46.9807
                       Mean reward: 781.98
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 0.6952
    Episode_Reward/rotating_object: 156.2854
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.45s
                      Time elapsed: 00:46:35
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 42196 steps/s (collection: 2.218s, learning 0.112s)
             Mean action noise std: 3.60
          Mean value_function loss: 58.8405
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 46.9916
                       Mean reward: 783.64
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 0.6909
    Episode_Reward/rotating_object: 154.5139
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.33s
                      Time elapsed: 00:46:37
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 35448 steps/s (collection: 2.661s, learning 0.112s)
             Mean action noise std: 3.60
          Mean value_function loss: 57.4309
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.0030
                       Mean reward: 764.73
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 0.6947
    Episode_Reward/rotating_object: 155.5831
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.77s
                      Time elapsed: 00:46:40
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 39658 steps/s (collection: 2.352s, learning 0.126s)
             Mean action noise std: 3.60
          Mean value_function loss: 46.8147
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.0108
                       Mean reward: 758.00
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 0.6944
    Episode_Reward/rotating_object: 152.3232
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.48s
                      Time elapsed: 00:46:43
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 34970 steps/s (collection: 2.587s, learning 0.224s)
             Mean action noise std: 3.60
          Mean value_function loss: 29.1207
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.0172
                       Mean reward: 784.18
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 0.7056
    Episode_Reward/rotating_object: 156.6915
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.81s
                      Time elapsed: 00:46:45
                               ETA: 00:05:53

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 8251 steps/s (collection: 11.469s, learning 0.445s)
             Mean action noise std: 3.61
          Mean value_function loss: 36.3402
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.0228
                       Mean reward: 789.16
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 154.4140
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 11.91s
                      Time elapsed: 00:46:57
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 5346 steps/s (collection: 17.946s, learning 0.442s)
             Mean action noise std: 3.61
          Mean value_function loss: 46.5977
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 47.0316
                       Mean reward: 783.54
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 0.6969
    Episode_Reward/rotating_object: 156.6945
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 18.39s
                      Time elapsed: 00:47:16
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 4976 steps/s (collection: 19.446s, learning 0.309s)
             Mean action noise std: 3.61
          Mean value_function loss: 43.2469
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.0428
                       Mean reward: 781.48
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 0.7051
    Episode_Reward/rotating_object: 157.6740
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 19.76s
                      Time elapsed: 00:47:35
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 5101 steps/s (collection: 18.729s, learning 0.539s)
             Mean action noise std: 3.61
          Mean value_function loss: 51.5780
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 47.0549
                       Mean reward: 782.33
               Mean episode length: 240.52
    Episode_Reward/reaching_object: 0.6912
    Episode_Reward/rotating_object: 155.3717
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 19.27s
                      Time elapsed: 00:47:55
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 5186 steps/s (collection: 18.410s, learning 0.545s)
             Mean action noise std: 3.61
          Mean value_function loss: 45.8625
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.0563
                       Mean reward: 774.09
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.6992
    Episode_Reward/rotating_object: 157.5397
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 18.96s
                      Time elapsed: 00:48:14
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 4977 steps/s (collection: 19.198s, learning 0.553s)
             Mean action noise std: 3.61
          Mean value_function loss: 38.5434
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.0605
                       Mean reward: 763.61
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 0.6952
    Episode_Reward/rotating_object: 152.7682
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 19.75s
                      Time elapsed: 00:48:33
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 5023 steps/s (collection: 18.946s, learning 0.624s)
             Mean action noise std: 3.62
          Mean value_function loss: 36.0457
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.0689
                       Mean reward: 773.95
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 0.6972
    Episode_Reward/rotating_object: 156.3781
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 19.57s
                      Time elapsed: 00:48:53
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 4995 steps/s (collection: 19.199s, learning 0.480s)
             Mean action noise std: 3.62
          Mean value_function loss: 31.7979
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.0790
                       Mean reward: 777.26
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 0.6925
    Episode_Reward/rotating_object: 153.7594
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 19.68s
                      Time elapsed: 00:49:13
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 3976 steps/s (collection: 24.196s, learning 0.527s)
             Mean action noise std: 3.62
          Mean value_function loss: 44.0918
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 47.0869
                       Mean reward: 787.69
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.6898
    Episode_Reward/rotating_object: 154.3871
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 24.72s
                      Time elapsed: 00:49:37
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 18014 steps/s (collection: 5.008s, learning 0.449s)
             Mean action noise std: 3.62
          Mean value_function loss: 44.1081
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 47.0932
                       Mean reward: 785.51
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 0.6884
    Episode_Reward/rotating_object: 156.7282
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 5.46s
                      Time elapsed: 00:49:43
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 16001 steps/s (collection: 5.533s, learning 0.611s)
             Mean action noise std: 3.62
          Mean value_function loss: 42.2455
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.0980
                       Mean reward: 743.32
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 0.6918
    Episode_Reward/rotating_object: 154.4099
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 6.14s
                      Time elapsed: 00:49:49
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 15735 steps/s (collection: 5.768s, learning 0.480s)
             Mean action noise std: 3.62
          Mean value_function loss: 42.6203
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.1074
                       Mean reward: 773.70
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 0.6929
    Episode_Reward/rotating_object: 152.0508
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 6.25s
                      Time elapsed: 00:49:55
                               ETA: 00:05:47

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 15394 steps/s (collection: 5.950s, learning 0.436s)
             Mean action noise std: 3.63
          Mean value_function loss: 35.5375
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 47.1187
                       Mean reward: 781.98
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.6982
    Episode_Reward/rotating_object: 156.0178
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 6.39s
                      Time elapsed: 00:50:02
                               ETA: 00:05:45

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 15549 steps/s (collection: 5.853s, learning 0.469s)
             Mean action noise std: 3.63
          Mean value_function loss: 54.8985
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.1243
                       Mean reward: 758.41
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 153.1488
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 6.32s
                      Time elapsed: 00:50:08
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 14813 steps/s (collection: 6.052s, learning 0.584s)
             Mean action noise std: 3.63
          Mean value_function loss: 33.0117
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.1333
                       Mean reward: 745.88
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 0.6980
    Episode_Reward/rotating_object: 156.0388
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 6.64s
                      Time elapsed: 00:50:15
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 16726 steps/s (collection: 5.297s, learning 0.580s)
             Mean action noise std: 3.63
          Mean value_function loss: 40.0238
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 47.1407
                       Mean reward: 780.92
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.7005
    Episode_Reward/rotating_object: 157.1477
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 5.88s
                      Time elapsed: 00:50:20
                               ETA: 00:05:40

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 15377 steps/s (collection: 5.789s, learning 0.604s)
             Mean action noise std: 3.63
          Mean value_function loss: 34.8514
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.1440
                       Mean reward: 797.08
               Mean episode length: 246.33
    Episode_Reward/reaching_object: 0.6995
    Episode_Reward/rotating_object: 156.5782
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 6.39s
                      Time elapsed: 00:50:27
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 15403 steps/s (collection: 5.915s, learning 0.467s)
             Mean action noise std: 3.63
          Mean value_function loss: 48.7048
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.1516
                       Mean reward: 793.32
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 0.6933
    Episode_Reward/rotating_object: 155.5670
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 6.38s
                      Time elapsed: 00:50:33
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 16440 steps/s (collection: 5.486s, learning 0.493s)
             Mean action noise std: 3.63
          Mean value_function loss: 45.3651
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 47.1572
                       Mean reward: 777.89
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 0.6924
    Episode_Reward/rotating_object: 152.1898
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 5.98s
                      Time elapsed: 00:50:39
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 15131 steps/s (collection: 6.087s, learning 0.409s)
             Mean action noise std: 3.64
          Mean value_function loss: 42.9252
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.1657
                       Mean reward: 788.15
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 0.7008
    Episode_Reward/rotating_object: 156.0069
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 6.50s
                      Time elapsed: 00:50:46
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 16622 steps/s (collection: 5.477s, learning 0.437s)
             Mean action noise std: 3.64
          Mean value_function loss: 45.8447
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 47.1742
                       Mean reward: 727.44
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 0.6995
    Episode_Reward/rotating_object: 152.6946
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 5.91s
                      Time elapsed: 00:50:52
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 15900 steps/s (collection: 5.870s, learning 0.312s)
             Mean action noise std: 3.64
          Mean value_function loss: 21.5562
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.1812
                       Mean reward: 787.16
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 0.7041
    Episode_Reward/rotating_object: 157.7743
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 6.18s
                      Time elapsed: 00:50:58
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 15238 steps/s (collection: 5.921s, learning 0.531s)
             Mean action noise std: 3.64
          Mean value_function loss: 50.4357
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.1868
                       Mean reward: 747.37
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.7036
    Episode_Reward/rotating_object: 155.1977
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 6.45s
                      Time elapsed: 00:51:04
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 15038 steps/s (collection: 6.087s, learning 0.450s)
             Mean action noise std: 3.64
          Mean value_function loss: 32.7578
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 47.1986
                       Mean reward: 781.65
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.7017
    Episode_Reward/rotating_object: 156.0596
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 6.54s
                      Time elapsed: 00:51:11
                               ETA: 00:05:25

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 15483 steps/s (collection: 5.866s, learning 0.483s)
             Mean action noise std: 3.65
          Mean value_function loss: 50.7549
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.2072
                       Mean reward: 771.26
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 0.6962
    Episode_Reward/rotating_object: 154.4839
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 6.35s
                      Time elapsed: 00:51:17
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 14458 steps/s (collection: 6.314s, learning 0.485s)
             Mean action noise std: 3.65
          Mean value_function loss: 44.4263
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.2159
                       Mean reward: 775.10
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 0.6959
    Episode_Reward/rotating_object: 153.9141
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 6.80s
                      Time elapsed: 00:51:24
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 17236 steps/s (collection: 5.215s, learning 0.489s)
             Mean action noise std: 3.65
          Mean value_function loss: 35.6535
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 47.2245
                       Mean reward: 793.13
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 0.6955
    Episode_Reward/rotating_object: 154.3758
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 5.70s
                      Time elapsed: 00:51:30
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 16644 steps/s (collection: 5.591s, learning 0.315s)
             Mean action noise std: 3.65
          Mean value_function loss: 45.2622
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.2312
                       Mean reward: 762.42
               Mean episode length: 238.31
    Episode_Reward/reaching_object: 0.6994
    Episode_Reward/rotating_object: 154.7239
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 5.91s
                      Time elapsed: 00:51:36
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 15558 steps/s (collection: 5.750s, learning 0.568s)
             Mean action noise std: 3.65
          Mean value_function loss: 42.8537
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.2370
                       Mean reward: 792.96
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 0.7015
    Episode_Reward/rotating_object: 158.2214
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 6.32s
                      Time elapsed: 00:51:42
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 16831 steps/s (collection: 5.433s, learning 0.408s)
             Mean action noise std: 3.65
          Mean value_function loss: 59.9746
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 47.2438
                       Mean reward: 772.38
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.6916
    Episode_Reward/rotating_object: 153.6215
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 5.84s
                      Time elapsed: 00:51:48
                               ETA: 00:05:14

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 15283 steps/s (collection: 5.968s, learning 0.464s)
             Mean action noise std: 3.66
          Mean value_function loss: 51.3625
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.2507
                       Mean reward: 790.93
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.6964
    Episode_Reward/rotating_object: 155.2936
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 6.43s
                      Time elapsed: 00:51:54
                               ETA: 00:05:12

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 18306 steps/s (collection: 4.976s, learning 0.394s)
             Mean action noise std: 3.66
          Mean value_function loss: 40.2242
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 47.2599
                       Mean reward: 791.64
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.6992
    Episode_Reward/rotating_object: 155.2133
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 5.37s
                      Time elapsed: 00:52:00
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 19148 steps/s (collection: 4.715s, learning 0.419s)
             Mean action noise std: 3.66
          Mean value_function loss: 56.1404
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.2663
                       Mean reward: 742.95
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 0.6814
    Episode_Reward/rotating_object: 152.1944
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 5.13s
                      Time elapsed: 00:52:05
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 16775 steps/s (collection: 5.411s, learning 0.449s)
             Mean action noise std: 3.66
          Mean value_function loss: 44.2259
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.2731
                       Mean reward: 757.35
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 0.7005
    Episode_Reward/rotating_object: 155.8469
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 5.86s
                      Time elapsed: 00:52:11
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 16395 steps/s (collection: 5.489s, learning 0.506s)
             Mean action noise std: 3.66
          Mean value_function loss: 52.6305
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.2838
                       Mean reward: 800.46
               Mean episode length: 244.93
    Episode_Reward/reaching_object: 0.6969
    Episode_Reward/rotating_object: 155.6028
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 6.00s
                      Time elapsed: 00:52:17
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 16590 steps/s (collection: 5.519s, learning 0.406s)
             Mean action noise std: 3.66
          Mean value_function loss: 47.2663
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 47.2904
                       Mean reward: 808.57
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 0.6847
    Episode_Reward/rotating_object: 152.0866
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 5.93s
                      Time elapsed: 00:52:22
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 17621 steps/s (collection: 5.196s, learning 0.383s)
             Mean action noise std: 3.66
          Mean value_function loss: 50.9545
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 47.2962
                       Mean reward: 771.08
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 0.6931
    Episode_Reward/rotating_object: 154.9942
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 5.58s
                      Time elapsed: 00:52:28
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 15804 steps/s (collection: 5.822s, learning 0.398s)
             Mean action noise std: 3.67
          Mean value_function loss: 51.0328
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 47.3035
                       Mean reward: 749.39
               Mean episode length: 237.96
    Episode_Reward/reaching_object: 0.6800
    Episode_Reward/rotating_object: 150.6902
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 6.22s
                      Time elapsed: 00:52:34
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 16310 steps/s (collection: 5.528s, learning 0.498s)
             Mean action noise std: 3.67
          Mean value_function loss: 59.5395
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.3139
                       Mean reward: 728.96
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 0.6845
    Episode_Reward/rotating_object: 151.6254
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 6.03s
                      Time elapsed: 00:52:40
                               ETA: 00:04:57

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 16163 steps/s (collection: 5.567s, learning 0.515s)
             Mean action noise std: 3.67
          Mean value_function loss: 37.7711
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 47.3210
                       Mean reward: 781.31
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 0.7014
    Episode_Reward/rotating_object: 156.3445
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 6.08s
                      Time elapsed: 00:52:46
                               ETA: 00:04:55

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 15220 steps/s (collection: 6.063s, learning 0.395s)
             Mean action noise std: 3.67
          Mean value_function loss: 39.4351
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 47.3257
                       Mean reward: 785.63
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7019
    Episode_Reward/rotating_object: 155.8380
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 6.46s
                      Time elapsed: 00:52:53
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 15809 steps/s (collection: 5.775s, learning 0.443s)
             Mean action noise std: 3.67
          Mean value_function loss: 49.8987
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.3308
                       Mean reward: 767.75
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 0.6925
    Episode_Reward/rotating_object: 154.7725
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 6.22s
                      Time elapsed: 00:52:59
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 18721 steps/s (collection: 4.760s, learning 0.491s)
             Mean action noise std: 3.67
          Mean value_function loss: 38.9408
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.3398
                       Mean reward: 795.22
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7026
    Episode_Reward/rotating_object: 157.9404
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 5.25s
                      Time elapsed: 00:53:04
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 15501 steps/s (collection: 6.053s, learning 0.288s)
             Mean action noise std: 3.68
          Mean value_function loss: 43.6720
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 47.3509
                       Mean reward: 789.75
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 153.7228
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 6.34s
                      Time elapsed: 00:53:11
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 16307 steps/s (collection: 5.539s, learning 0.489s)
             Mean action noise std: 3.68
          Mean value_function loss: 51.8617
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 47.3618
                       Mean reward: 771.76
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 0.6864
    Episode_Reward/rotating_object: 150.2017
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 6.03s
                      Time elapsed: 00:53:17
                               ETA: 00:04:45

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 17228 steps/s (collection: 5.291s, learning 0.415s)
             Mean action noise std: 3.68
          Mean value_function loss: 37.1638
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 47.3678
                       Mean reward: 778.71
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 0.6833
    Episode_Reward/rotating_object: 151.5327
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 5.71s
                      Time elapsed: 00:53:22
                               ETA: 00:04:43

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 16179 steps/s (collection: 5.573s, learning 0.503s)
             Mean action noise std: 3.68
          Mean value_function loss: 44.0501
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 47.3750
                       Mean reward: 784.21
               Mean episode length: 242.83
    Episode_Reward/reaching_object: 0.6891
    Episode_Reward/rotating_object: 154.2315
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 6.08s
                      Time elapsed: 00:53:28
                               ETA: 00:04:41

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 15998 steps/s (collection: 5.637s, learning 0.508s)
             Mean action noise std: 3.68
          Mean value_function loss: 48.6613
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.3852
                       Mean reward: 743.04
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 0.6796
    Episode_Reward/rotating_object: 152.0557
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 6.14s
                      Time elapsed: 00:53:35
                               ETA: 00:04:39

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 15119 steps/s (collection: 5.955s, learning 0.547s)
             Mean action noise std: 3.69
          Mean value_function loss: 48.3843
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.3982
                       Mean reward: 755.56
               Mean episode length: 234.18
    Episode_Reward/reaching_object: 0.6789
    Episode_Reward/rotating_object: 151.8170
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 6.50s
                      Time elapsed: 00:53:41
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 15377 steps/s (collection: 5.852s, learning 0.540s)
             Mean action noise std: 3.69
          Mean value_function loss: 30.9127
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 47.4094
                       Mean reward: 798.92
               Mean episode length: 245.04
    Episode_Reward/reaching_object: 0.7024
    Episode_Reward/rotating_object: 157.6219
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 6.39s
                      Time elapsed: 00:53:47
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 15879 steps/s (collection: 5.795s, learning 0.396s)
             Mean action noise std: 3.69
          Mean value_function loss: 42.5553
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.4190
                       Mean reward: 804.83
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6954
    Episode_Reward/rotating_object: 157.7050
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 6.19s
                      Time elapsed: 00:53:54
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 16720 steps/s (collection: 5.348s, learning 0.531s)
             Mean action noise std: 3.69
          Mean value_function loss: 46.6615
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 47.4284
                       Mean reward: 777.31
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 0.6894
    Episode_Reward/rotating_object: 153.5312
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 5.88s
                      Time elapsed: 00:54:00
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 16729 steps/s (collection: 5.357s, learning 0.519s)
             Mean action noise std: 3.69
          Mean value_function loss: 32.3654
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.4372
                       Mean reward: 777.27
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 0.6824
    Episode_Reward/rotating_object: 152.5430
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 5.88s
                      Time elapsed: 00:54:05
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 15587 steps/s (collection: 5.869s, learning 0.438s)
             Mean action noise std: 3.69
          Mean value_function loss: 41.8250
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.4438
                       Mean reward: 762.74
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.7003
    Episode_Reward/rotating_object: 157.3941
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 6.31s
                      Time elapsed: 00:54:12
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 15466 steps/s (collection: 5.948s, learning 0.408s)
             Mean action noise std: 3.70
          Mean value_function loss: 43.0026
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.4544
                       Mean reward: 820.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6926
    Episode_Reward/rotating_object: 156.6981
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 6.36s
                      Time elapsed: 00:54:18
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 15312 steps/s (collection: 5.928s, learning 0.492s)
             Mean action noise std: 3.70
          Mean value_function loss: 48.1518
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.4730
                       Mean reward: 797.86
               Mean episode length: 246.29
    Episode_Reward/reaching_object: 0.6931
    Episode_Reward/rotating_object: 155.7814
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 6.42s
                      Time elapsed: 00:54:25
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 17988 steps/s (collection: 5.155s, learning 0.310s)
             Mean action noise std: 3.70
          Mean value_function loss: 41.4568
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 47.4865
                       Mean reward: 807.64
               Mean episode length: 248.35
    Episode_Reward/reaching_object: 0.6864
    Episode_Reward/rotating_object: 155.4152
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 5.46s
                      Time elapsed: 00:54:30
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 21755 steps/s (collection: 4.084s, learning 0.435s)
             Mean action noise std: 3.71
          Mean value_function loss: 44.7126
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.4962
                       Mean reward: 758.41
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 0.6793
    Episode_Reward/rotating_object: 152.3371
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 4.52s
                      Time elapsed: 00:54:34
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 17887 steps/s (collection: 5.196s, learning 0.300s)
             Mean action noise std: 3.71
          Mean value_function loss: 44.3037
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 47.5092
                       Mean reward: 779.43
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 0.6925
    Episode_Reward/rotating_object: 156.6524
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 5.50s
                      Time elapsed: 00:54:40
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 15647 steps/s (collection: 5.883s, learning 0.399s)
             Mean action noise std: 3.71
          Mean value_function loss: 45.9902
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.5184
                       Mean reward: 770.24
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 0.6914
    Episode_Reward/rotating_object: 155.0033
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 6.28s
                      Time elapsed: 00:54:46
                               ETA: 00:04:14

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 15057 steps/s (collection: 5.967s, learning 0.561s)
             Mean action noise std: 3.71
          Mean value_function loss: 34.1386
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.5314
                       Mean reward: 778.09
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 0.6937
    Episode_Reward/rotating_object: 158.6877
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 6.53s
                      Time elapsed: 00:54:53
                               ETA: 00:04:12

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 16934 steps/s (collection: 5.476s, learning 0.329s)
             Mean action noise std: 3.71
          Mean value_function loss: 61.1285
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 47.5426
                       Mean reward: 759.56
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 0.6821
    Episode_Reward/rotating_object: 153.5246
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 5.80s
                      Time elapsed: 00:54:59
                               ETA: 00:04:10

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 16858 steps/s (collection: 5.333s, learning 0.498s)
             Mean action noise std: 3.72
          Mean value_function loss: 51.8367
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.5497
                       Mean reward: 773.42
               Mean episode length: 239.19
    Episode_Reward/reaching_object: 0.6855
    Episode_Reward/rotating_object: 154.1675
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 5.83s
                      Time elapsed: 00:55:04
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 17906 steps/s (collection: 5.016s, learning 0.473s)
             Mean action noise std: 3.72
          Mean value_function loss: 48.9486
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 47.5576
                       Mean reward: 751.79
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 0.6826
    Episode_Reward/rotating_object: 154.1241
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 5.49s
                      Time elapsed: 00:55:10
                               ETA: 00:04:06

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 15203 steps/s (collection: 5.994s, learning 0.472s)
             Mean action noise std: 3.72
          Mean value_function loss: 35.5486
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.5637
                       Mean reward: 787.01
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.6885
    Episode_Reward/rotating_object: 154.7851
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 6.47s
                      Time elapsed: 00:55:16
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 15762 steps/s (collection: 5.744s, learning 0.493s)
             Mean action noise std: 3.72
          Mean value_function loss: 33.2075
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 47.5720
                       Mean reward: 814.87
               Mean episode length: 247.17
    Episode_Reward/reaching_object: 0.6893
    Episode_Reward/rotating_object: 158.1510
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 6.24s
                      Time elapsed: 00:55:23
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 16144 steps/s (collection: 5.623s, learning 0.466s)
             Mean action noise std: 3.72
          Mean value_function loss: 39.3301
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 47.5787
                       Mean reward: 799.70
               Mean episode length: 248.80
    Episode_Reward/reaching_object: 0.6889
    Episode_Reward/rotating_object: 154.6287
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 6.09s
                      Time elapsed: 00:55:29
                               ETA: 00:04:00

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 15673 steps/s (collection: 5.846s, learning 0.426s)
             Mean action noise std: 3.72
          Mean value_function loss: 44.2533
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.5826
                       Mean reward: 811.19
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 0.6733
    Episode_Reward/rotating_object: 151.5898
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 6.27s
                      Time elapsed: 00:55:35
                               ETA: 00:03:58

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 16445 steps/s (collection: 5.696s, learning 0.282s)
             Mean action noise std: 3.73
          Mean value_function loss: 48.1076
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.5879
                       Mean reward: 766.04
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 0.6877
    Episode_Reward/rotating_object: 153.5853
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 5.98s
                      Time elapsed: 00:55:41
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 19597 steps/s (collection: 4.739s, learning 0.278s)
             Mean action noise std: 3.73
          Mean value_function loss: 40.4558
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 47.5988
                       Mean reward: 803.54
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6884
    Episode_Reward/rotating_object: 156.6525
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 5.02s
                      Time elapsed: 00:55:46
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 15946 steps/s (collection: 5.700s, learning 0.465s)
             Mean action noise std: 3.73
          Mean value_function loss: 45.7832
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.6073
                       Mean reward: 755.03
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 0.6817
    Episode_Reward/rotating_object: 152.9361
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 6.16s
                      Time elapsed: 00:55:52
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 19801 steps/s (collection: 4.687s, learning 0.277s)
             Mean action noise std: 3.73
          Mean value_function loss: 33.0742
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.6208
                       Mean reward: 773.99
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 0.6839
    Episode_Reward/rotating_object: 155.7431
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 4.96s
                      Time elapsed: 00:55:57
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 18513 steps/s (collection: 4.904s, learning 0.406s)
             Mean action noise std: 3.74
          Mean value_function loss: 52.4561
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.6376
                       Mean reward: 790.99
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.6811
    Episode_Reward/rotating_object: 153.0902
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 5.31s
                      Time elapsed: 00:56:02
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 14089 steps/s (collection: 6.402s, learning 0.575s)
             Mean action noise std: 3.74
          Mean value_function loss: 51.0449
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.6544
                       Mean reward: 754.06
               Mean episode length: 237.11
    Episode_Reward/reaching_object: 0.6750
    Episode_Reward/rotating_object: 152.1476
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 6.98s
                      Time elapsed: 00:56:09
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 15785 steps/s (collection: 5.803s, learning 0.424s)
             Mean action noise std: 3.74
          Mean value_function loss: 44.8562
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 47.6635
                       Mean reward: 766.99
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 0.6775
    Episode_Reward/rotating_object: 153.7758
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 6.23s
                      Time elapsed: 00:56:16
                               ETA: 00:03:42

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 19013 steps/s (collection: 4.801s, learning 0.369s)
             Mean action noise std: 3.74
          Mean value_function loss: 44.5471
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 47.6792
                       Mean reward: 779.56
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.6846
    Episode_Reward/rotating_object: 154.8716
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 5.17s
                      Time elapsed: 00:56:21
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 15362 steps/s (collection: 5.999s, learning 0.400s)
             Mean action noise std: 3.74
          Mean value_function loss: 54.0280
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 47.6858
                       Mean reward: 767.39
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.6757
    Episode_Reward/rotating_object: 153.3606
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 6.40s
                      Time elapsed: 00:56:27
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 15808 steps/s (collection: 5.707s, learning 0.511s)
             Mean action noise std: 3.75
          Mean value_function loss: 38.3494
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.6895
                       Mean reward: 786.99
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 0.6946
    Episode_Reward/rotating_object: 160.0877
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 6.22s
                      Time elapsed: 00:56:33
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 14751 steps/s (collection: 6.185s, learning 0.479s)
             Mean action noise std: 3.75
          Mean value_function loss: 41.3451
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.6983
                       Mean reward: 768.46
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 0.6743
    Episode_Reward/rotating_object: 154.0368
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 6.66s
                      Time elapsed: 00:56:40
                               ETA: 00:03:34

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 16049 steps/s (collection: 5.548s, learning 0.578s)
             Mean action noise std: 3.75
          Mean value_function loss: 37.0673
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 47.7092
                       Mean reward: 810.59
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.6888
    Episode_Reward/rotating_object: 155.7762
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 6.13s
                      Time elapsed: 00:56:46
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 14307 steps/s (collection: 6.324s, learning 0.546s)
             Mean action noise std: 3.75
          Mean value_function loss: 46.0286
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.7158
                       Mean reward: 759.48
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 0.6801
    Episode_Reward/rotating_object: 155.5244
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 6.87s
                      Time elapsed: 00:56:53
                               ETA: 00:03:30

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 17831 steps/s (collection: 5.100s, learning 0.413s)
             Mean action noise std: 3.75
          Mean value_function loss: 61.6334
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.7228
                       Mean reward: 734.60
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 0.6669
    Episode_Reward/rotating_object: 151.0300
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 5.51s
                      Time elapsed: 00:56:59
                               ETA: 00:03:27

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 14738 steps/s (collection: 6.108s, learning 0.562s)
             Mean action noise std: 3.75
          Mean value_function loss: 50.8933
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.7319
                       Mean reward: 763.23
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 0.6747
    Episode_Reward/rotating_object: 152.5891
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 6.67s
                      Time elapsed: 00:57:05
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 16735 steps/s (collection: 5.448s, learning 0.425s)
             Mean action noise std: 3.76
          Mean value_function loss: 53.9973
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.7434
                       Mean reward: 773.32
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.6803
    Episode_Reward/rotating_object: 153.9003
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 5.87s
                      Time elapsed: 00:57:11
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 17164 steps/s (collection: 5.173s, learning 0.554s)
             Mean action noise std: 3.76
          Mean value_function loss: 42.4120
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 47.7544
                       Mean reward: 768.24
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 0.6693
    Episode_Reward/rotating_object: 153.2854
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 5.73s
                      Time elapsed: 00:57:17
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 17506 steps/s (collection: 5.246s, learning 0.369s)
             Mean action noise std: 3.76
          Mean value_function loss: 56.9655
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 47.7612
                       Mean reward: 769.44
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 0.6668
    Episode_Reward/rotating_object: 150.2884
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 5.62s
                      Time elapsed: 00:57:22
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 15853 steps/s (collection: 5.608s, learning 0.593s)
             Mean action noise std: 3.76
          Mean value_function loss: 53.9745
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.7705
                       Mean reward: 756.61
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 0.6703
    Episode_Reward/rotating_object: 154.4582
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 6.20s
                      Time elapsed: 00:57:29
                               ETA: 00:03:16

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 15040 steps/s (collection: 5.964s, learning 0.572s)
             Mean action noise std: 3.76
          Mean value_function loss: 40.0019
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.7780
                       Mean reward: 796.41
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.6798
    Episode_Reward/rotating_object: 155.5837
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 6.54s
                      Time elapsed: 00:57:35
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 15154 steps/s (collection: 5.953s, learning 0.533s)
             Mean action noise std: 3.77
          Mean value_function loss: 53.5415
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 47.7846
                       Mean reward: 799.99
               Mean episode length: 242.58
    Episode_Reward/reaching_object: 0.6668
    Episode_Reward/rotating_object: 153.2013
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 6.49s
                      Time elapsed: 00:57:42
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 15960 steps/s (collection: 5.714s, learning 0.445s)
             Mean action noise std: 3.77
          Mean value_function loss: 45.5214
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 47.7903
                       Mean reward: 772.70
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6824
    Episode_Reward/rotating_object: 153.6408
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 6.16s
                      Time elapsed: 00:57:48
                               ETA: 00:03:10

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 14702 steps/s (collection: 6.247s, learning 0.439s)
             Mean action noise std: 3.77
          Mean value_function loss: 40.3966
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 47.7951
                       Mean reward: 780.80
               Mean episode length: 246.89
    Episode_Reward/reaching_object: 0.6798
    Episode_Reward/rotating_object: 155.0746
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 6.69s
                      Time elapsed: 00:57:55
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 16511 steps/s (collection: 5.398s, learning 0.555s)
             Mean action noise std: 3.77
          Mean value_function loss: 50.3322
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.7981
                       Mean reward: 787.97
               Mean episode length: 247.29
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 154.2059
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 5.95s
                      Time elapsed: 00:58:00
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 16232 steps/s (collection: 5.626s, learning 0.430s)
             Mean action noise std: 3.77
          Mean value_function loss: 51.9071
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.8027
                       Mean reward: 785.51
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 0.6756
    Episode_Reward/rotating_object: 155.3147
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 6.06s
                      Time elapsed: 00:58:07
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 17226 steps/s (collection: 5.275s, learning 0.431s)
             Mean action noise std: 3.77
          Mean value_function loss: 40.5118
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.8120
                       Mean reward: 802.29
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.6876
    Episode_Reward/rotating_object: 158.4058
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 5.71s
                      Time elapsed: 00:58:12
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 15796 steps/s (collection: 5.925s, learning 0.298s)
             Mean action noise std: 3.78
          Mean value_function loss: 39.3801
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.8205
                       Mean reward: 749.53
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 154.3452
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 6.22s
                      Time elapsed: 00:58:18
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 15264 steps/s (collection: 6.039s, learning 0.401s)
             Mean action noise std: 3.78
          Mean value_function loss: 42.9524
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.8240
                       Mean reward: 772.92
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 0.6796
    Episode_Reward/rotating_object: 151.3902
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 6.44s
                      Time elapsed: 00:58:25
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 17818 steps/s (collection: 4.995s, learning 0.521s)
             Mean action noise std: 3.78
          Mean value_function loss: 43.0792
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 47.8297
                       Mean reward: 785.41
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 0.6867
    Episode_Reward/rotating_object: 155.4841
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 5.52s
                      Time elapsed: 00:58:30
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 17806 steps/s (collection: 5.244s, learning 0.277s)
             Mean action noise std: 3.78
          Mean value_function loss: 53.4851
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.8352
                       Mean reward: 762.37
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 0.6655
    Episode_Reward/rotating_object: 149.9106
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 5.52s
                      Time elapsed: 00:58:36
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 22029 steps/s (collection: 4.090s, learning 0.373s)
             Mean action noise std: 3.78
          Mean value_function loss: 38.2826
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.8392
                       Mean reward: 760.73
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 155.4847
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 4.46s
                      Time elapsed: 00:58:40
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 20933 steps/s (collection: 4.332s, learning 0.364s)
             Mean action noise std: 3.78
          Mean value_function loss: 45.7548
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.8470
                       Mean reward: 775.10
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 0.6847
    Episode_Reward/rotating_object: 155.6109
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 4.70s
                      Time elapsed: 00:58:45
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 20525 steps/s (collection: 4.494s, learning 0.295s)
             Mean action noise std: 3.79
          Mean value_function loss: 37.9422
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 47.8575
                       Mean reward: 777.82
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 0.6862
    Episode_Reward/rotating_object: 155.1230
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 4.79s
                      Time elapsed: 00:58:50
                               ETA: 00:02:44

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 20145 steps/s (collection: 4.598s, learning 0.282s)
             Mean action noise std: 3.79
          Mean value_function loss: 47.3810
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 47.8639
                       Mean reward: 760.65
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 0.6869
    Episode_Reward/rotating_object: 153.1629
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 4.88s
                      Time elapsed: 00:58:55
                               ETA: 00:02:42

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 24495 steps/s (collection: 3.729s, learning 0.284s)
             Mean action noise std: 3.79
          Mean value_function loss: 43.9373
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.8731
                       Mean reward: 778.75
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 0.6887
    Episode_Reward/rotating_object: 155.0247
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 4.01s
                      Time elapsed: 00:58:59
                               ETA: 00:02:40

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 23015 steps/s (collection: 3.973s, learning 0.298s)
             Mean action noise std: 3.79
          Mean value_function loss: 38.0361
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.8799
                       Mean reward: 805.68
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6998
    Episode_Reward/rotating_object: 158.6972
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 4.27s
                      Time elapsed: 00:59:03
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 21831 steps/s (collection: 4.215s, learning 0.288s)
             Mean action noise std: 3.79
          Mean value_function loss: 51.6297
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 47.8872
                       Mean reward: 747.52
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 0.6805
    Episode_Reward/rotating_object: 150.9469
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 4.50s
                      Time elapsed: 00:59:08
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 19794 steps/s (collection: 4.626s, learning 0.340s)
             Mean action noise std: 3.79
          Mean value_function loss: 47.1175
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 47.8975
                       Mean reward: 779.74
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 156.9783
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 4.97s
                      Time elapsed: 00:59:13
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 23665 steps/s (collection: 3.857s, learning 0.297s)
             Mean action noise std: 3.80
          Mean value_function loss: 37.8112
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.9100
                       Mean reward: 805.11
               Mean episode length: 246.22
    Episode_Reward/reaching_object: 0.6843
    Episode_Reward/rotating_object: 155.0052
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 4.15s
                      Time elapsed: 00:59:17
                               ETA: 00:02:30

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 20937 steps/s (collection: 4.389s, learning 0.306s)
             Mean action noise std: 3.80
          Mean value_function loss: 51.1082
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.9184
                       Mean reward: 764.87
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 0.6874
    Episode_Reward/rotating_object: 154.6464
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 4.70s
                      Time elapsed: 00:59:21
                               ETA: 00:02:28

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 22769 steps/s (collection: 3.989s, learning 0.329s)
             Mean action noise std: 3.80
          Mean value_function loss: 41.7419
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.9251
                       Mean reward: 780.03
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 0.6885
    Episode_Reward/rotating_object: 156.5667
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 4.32s
                      Time elapsed: 00:59:26
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 19425 steps/s (collection: 4.649s, learning 0.412s)
             Mean action noise std: 3.80
          Mean value_function loss: 36.2231
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.9352
                       Mean reward: 775.67
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 0.6989
    Episode_Reward/rotating_object: 158.4435
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 5.06s
                      Time elapsed: 00:59:31
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 21322 steps/s (collection: 4.247s, learning 0.363s)
             Mean action noise std: 3.80
          Mean value_function loss: 44.5749
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 47.9418
                       Mean reward: 763.81
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.6907
    Episode_Reward/rotating_object: 155.0201
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 4.61s
                      Time elapsed: 00:59:35
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 18639 steps/s (collection: 4.909s, learning 0.365s)
             Mean action noise std: 3.81
          Mean value_function loss: 38.5394
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.9457
                       Mean reward: 799.56
               Mean episode length: 247.57
    Episode_Reward/reaching_object: 0.6939
    Episode_Reward/rotating_object: 156.4203
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 5.27s
                      Time elapsed: 00:59:41
                               ETA: 00:02:18

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 21785 steps/s (collection: 4.256s, learning 0.256s)
             Mean action noise std: 3.81
          Mean value_function loss: 40.0729
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 47.9590
                       Mean reward: 780.51
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 0.6950
    Episode_Reward/rotating_object: 157.4036
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 4.51s
                      Time elapsed: 00:59:45
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 20949 steps/s (collection: 4.232s, learning 0.460s)
             Mean action noise std: 3.81
          Mean value_function loss: 41.5903
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.9726
                       Mean reward: 762.87
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 0.6874
    Episode_Reward/rotating_object: 155.8932
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 4.69s
                      Time elapsed: 00:59:50
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 18810 steps/s (collection: 4.959s, learning 0.267s)
             Mean action noise std: 3.81
          Mean value_function loss: 50.6484
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 47.9821
                       Mean reward: 743.95
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 0.6887
    Episode_Reward/rotating_object: 153.9799
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 5.23s
                      Time elapsed: 00:59:55
                               ETA: 00:02:11

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 21389 steps/s (collection: 4.154s, learning 0.442s)
             Mean action noise std: 3.82
          Mean value_function loss: 36.8633
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 47.9935
                       Mean reward: 752.92
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 0.6896
    Episode_Reward/rotating_object: 153.6342
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 4.60s
                      Time elapsed: 01:00:00
                               ETA: 00:02:09

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 15177 steps/s (collection: 6.022s, learning 0.455s)
             Mean action noise std: 3.82
          Mean value_function loss: 30.1540
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.9992
                       Mean reward: 784.97
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.6943
    Episode_Reward/rotating_object: 157.2944
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 6.48s
                      Time elapsed: 01:00:06
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 17217 steps/s (collection: 5.124s, learning 0.586s)
             Mean action noise std: 3.82
          Mean value_function loss: 49.1295
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.0040
                       Mean reward: 771.72
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 0.6944
    Episode_Reward/rotating_object: 157.6827
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 5.71s
                      Time elapsed: 01:00:12
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 15561 steps/s (collection: 5.916s, learning 0.401s)
             Mean action noise std: 3.82
          Mean value_function loss: 53.7258
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 48.0148
                       Mean reward: 779.48
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 0.6863
    Episode_Reward/rotating_object: 154.4990
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 6.32s
                      Time elapsed: 01:00:18
                               ETA: 00:02:02

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 14847 steps/s (collection: 6.236s, learning 0.385s)
             Mean action noise std: 3.82
          Mean value_function loss: 47.5581
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 48.0264
                       Mean reward: 782.83
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 0.6866
    Episode_Reward/rotating_object: 153.5744
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 6.62s
                      Time elapsed: 01:00:25
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 15907 steps/s (collection: 5.661s, learning 0.519s)
             Mean action noise std: 3.82
          Mean value_function loss: 39.9498
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 48.0344
                       Mean reward: 786.78
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 0.6962
    Episode_Reward/rotating_object: 158.6581
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 6.18s
                      Time elapsed: 01:00:31
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 15992 steps/s (collection: 5.647s, learning 0.500s)
             Mean action noise std: 3.83
          Mean value_function loss: 41.1914
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 48.0431
                       Mean reward: 768.16
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 0.6847
    Episode_Reward/rotating_object: 155.4071
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 6.15s
                      Time elapsed: 01:00:37
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 14986 steps/s (collection: 6.015s, learning 0.544s)
             Mean action noise std: 3.83
          Mean value_function loss: 52.7352
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 48.0518
                       Mean reward: 774.53
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.6866
    Episode_Reward/rotating_object: 155.5364
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 6.56s
                      Time elapsed: 01:00:44
                               ETA: 00:01:52

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 16142 steps/s (collection: 5.640s, learning 0.450s)
             Mean action noise std: 3.83
          Mean value_function loss: 44.8425
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 48.0576
                       Mean reward: 765.87
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 0.6996
    Episode_Reward/rotating_object: 156.7292
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 6.09s
                      Time elapsed: 01:00:50
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 15978 steps/s (collection: 5.690s, learning 0.462s)
             Mean action noise std: 3.83
          Mean value_function loss: 53.9147
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 48.0640
                       Mean reward: 765.48
               Mean episode length: 234.28
    Episode_Reward/reaching_object: 0.6816
    Episode_Reward/rotating_object: 153.5076
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 6.15s
                      Time elapsed: 01:00:56
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 15259 steps/s (collection: 5.936s, learning 0.506s)
             Mean action noise std: 3.83
          Mean value_function loss: 49.1642
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 48.0680
                       Mean reward: 789.84
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 156.6350
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 6.44s
                      Time elapsed: 01:01:02
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 15648 steps/s (collection: 5.848s, learning 0.434s)
             Mean action noise std: 3.83
          Mean value_function loss: 47.5683
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 48.0742
                       Mean reward: 747.09
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 0.6845
    Episode_Reward/rotating_object: 152.9111
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 6.28s
                      Time elapsed: 01:01:09
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 16251 steps/s (collection: 5.628s, learning 0.421s)
             Mean action noise std: 3.83
          Mean value_function loss: 53.5925
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 48.0795
                       Mean reward: 775.16
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 0.6907
    Episode_Reward/rotating_object: 154.1084
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 6.05s
                      Time elapsed: 01:01:15
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 17961 steps/s (collection: 5.073s, learning 0.400s)
             Mean action noise std: 3.84
          Mean value_function loss: 44.6768
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 48.0852
                       Mean reward: 798.75
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 0.7000
    Episode_Reward/rotating_object: 156.7538
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 5.47s
                      Time elapsed: 01:01:20
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 17227 steps/s (collection: 5.258s, learning 0.448s)
             Mean action noise std: 3.84
          Mean value_function loss: 51.2575
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 48.0932
                       Mean reward: 789.60
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.6896
    Episode_Reward/rotating_object: 154.7758
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 5.71s
                      Time elapsed: 01:01:26
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 17926 steps/s (collection: 5.015s, learning 0.468s)
             Mean action noise std: 3.84
          Mean value_function loss: 49.0504
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 48.0977
                       Mean reward: 800.65
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 0.6810
    Episode_Reward/rotating_object: 151.5788
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 5.48s
                      Time elapsed: 01:01:31
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 14764 steps/s (collection: 6.206s, learning 0.452s)
             Mean action noise std: 3.84
          Mean value_function loss: 39.1123
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 48.1051
                       Mean reward: 779.98
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 0.6853
    Episode_Reward/rotating_object: 153.1907
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 6.66s
                      Time elapsed: 01:01:38
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 14935 steps/s (collection: 5.999s, learning 0.583s)
             Mean action noise std: 3.84
          Mean value_function loss: 25.3281
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 48.1134
                       Mean reward: 798.80
               Mean episode length: 248.83
    Episode_Reward/reaching_object: 0.7037
    Episode_Reward/rotating_object: 157.4180
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 6.58s
                      Time elapsed: 01:01:45
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 14567 steps/s (collection: 6.211s, learning 0.537s)
             Mean action noise std: 3.84
          Mean value_function loss: 38.5777
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 48.1168
                       Mean reward: 783.36
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 0.7067
    Episode_Reward/rotating_object: 159.3694
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 6.75s
                      Time elapsed: 01:01:51
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 16087 steps/s (collection: 5.603s, learning 0.508s)
             Mean action noise std: 3.85
          Mean value_function loss: 60.1707
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 48.1233
                       Mean reward: 746.99
               Mean episode length: 233.23
    Episode_Reward/reaching_object: 0.6818
    Episode_Reward/rotating_object: 153.1476
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 6.11s
                      Time elapsed: 01:01:57
                               ETA: 00:01:23

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 14668 steps/s (collection: 6.138s, learning 0.564s)
             Mean action noise std: 3.85
          Mean value_function loss: 34.6121
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 48.1300
                       Mean reward: 813.30
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 0.6955
    Episode_Reward/rotating_object: 156.0011
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 6.70s
                      Time elapsed: 01:02:04
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 14705 steps/s (collection: 6.200s, learning 0.484s)
             Mean action noise std: 3.85
          Mean value_function loss: 34.0975
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 48.1344
                       Mean reward: 801.89
               Mean episode length: 243.94
    Episode_Reward/reaching_object: 0.6994
    Episode_Reward/rotating_object: 158.3807
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 6.68s
                      Time elapsed: 01:02:11
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 14767 steps/s (collection: 6.084s, learning 0.572s)
             Mean action noise std: 3.85
          Mean value_function loss: 42.4232
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 48.1406
                       Mean reward: 819.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7027
    Episode_Reward/rotating_object: 156.8269
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 6.66s
                      Time elapsed: 01:02:18
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 15073 steps/s (collection: 5.948s, learning 0.574s)
             Mean action noise std: 3.85
          Mean value_function loss: 45.6475
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 48.1514
                       Mean reward: 781.52
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 0.6835
    Episode_Reward/rotating_object: 154.2228
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 6.52s
                      Time elapsed: 01:02:24
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 14644 steps/s (collection: 6.199s, learning 0.513s)
             Mean action noise std: 3.85
          Mean value_function loss: 44.9925
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 48.1644
                       Mean reward: 763.64
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 0.6892
    Episode_Reward/rotating_object: 155.4845
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 6.71s
                      Time elapsed: 01:02:31
                               ETA: 00:01:11

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 15853 steps/s (collection: 5.716s, learning 0.485s)
             Mean action noise std: 3.86
          Mean value_function loss: 42.9331
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 48.1770
                       Mean reward: 804.13
               Mean episode length: 248.61
    Episode_Reward/reaching_object: 0.6938
    Episode_Reward/rotating_object: 156.9818
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 6.20s
                      Time elapsed: 01:02:37
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 14044 steps/s (collection: 6.501s, learning 0.498s)
             Mean action noise std: 3.86
          Mean value_function loss: 43.8157
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 48.1884
                       Mean reward: 799.40
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 156.2361
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 7.00s
                      Time elapsed: 01:02:44
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 15568 steps/s (collection: 5.824s, learning 0.490s)
             Mean action noise std: 3.86
          Mean value_function loss: 47.9081
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 48.2016
                       Mean reward: 758.94
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 0.6778
    Episode_Reward/rotating_object: 152.4533
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 6.31s
                      Time elapsed: 01:02:50
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 24325 steps/s (collection: 3.797s, learning 0.244s)
             Mean action noise std: 3.86
          Mean value_function loss: 41.7792
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 48.2106
                       Mean reward: 796.54
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 0.6917
    Episode_Reward/rotating_object: 156.4581
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 4.04s
                      Time elapsed: 01:02:54
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 32098 steps/s (collection: 2.930s, learning 0.132s)
             Mean action noise std: 3.86
          Mean value_function loss: 26.7945
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 48.2120
                       Mean reward: 795.00
               Mean episode length: 245.05
    Episode_Reward/reaching_object: 0.7116
    Episode_Reward/rotating_object: 160.3025
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 3.06s
                      Time elapsed: 01:02:57
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 50377 steps/s (collection: 1.836s, learning 0.116s)
             Mean action noise std: 3.87
          Mean value_function loss: 41.3691
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 48.2124
                       Mean reward: 783.29
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.6911
    Episode_Reward/rotating_object: 154.0938
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.95s
                      Time elapsed: 01:02:59
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 50580 steps/s (collection: 1.827s, learning 0.117s)
             Mean action noise std: 3.87
          Mean value_function loss: 42.2330
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 48.2215
                       Mean reward: 786.14
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7018
    Episode_Reward/rotating_object: 157.3050
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.94s
                      Time elapsed: 01:03:01
                               ETA: 00:00:53

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 20472 steps/s (collection: 4.456s, learning 0.346s)
             Mean action noise std: 3.87
          Mean value_function loss: 59.1875
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 48.2346
                       Mean reward: 751.02
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 0.6848
    Episode_Reward/rotating_object: 150.8569
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 4.80s
                      Time elapsed: 01:03:06
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 15930 steps/s (collection: 5.752s, learning 0.418s)
             Mean action noise std: 3.87
          Mean value_function loss: 39.0835
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 48.2446
                       Mean reward: 759.96
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 0.6948
    Episode_Reward/rotating_object: 155.5208
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 6.17s
                      Time elapsed: 01:03:12
                               ETA: 00:00:48

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 16633 steps/s (collection: 5.497s, learning 0.413s)
             Mean action noise std: 3.88
          Mean value_function loss: 47.1428
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 48.2554
                       Mean reward: 788.14
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 0.6998
    Episode_Reward/rotating_object: 157.6020
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 5.91s
                      Time elapsed: 01:03:18
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 15258 steps/s (collection: 6.076s, learning 0.366s)
             Mean action noise std: 3.88
          Mean value_function loss: 50.2463
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 48.2674
                       Mean reward: 795.93
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 0.6816
    Episode_Reward/rotating_object: 154.2321
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 6.44s
                      Time elapsed: 01:03:25
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 15863 steps/s (collection: 5.733s, learning 0.464s)
             Mean action noise std: 3.88
          Mean value_function loss: 43.0297
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 48.2766
                       Mean reward: 772.81
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 0.6919
    Episode_Reward/rotating_object: 156.9160
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 6.20s
                      Time elapsed: 01:03:31
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 16081 steps/s (collection: 5.690s, learning 0.423s)
             Mean action noise std: 3.88
          Mean value_function loss: 43.2261
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 48.2879
                       Mean reward: 754.25
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 0.6817
    Episode_Reward/rotating_object: 154.1628
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 6.11s
                      Time elapsed: 01:03:37
                               ETA: 00:00:38

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 17785 steps/s (collection: 5.007s, learning 0.520s)
             Mean action noise std: 3.89
          Mean value_function loss: 48.9800
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 48.2993
                       Mean reward: 782.48
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 0.6858
    Episode_Reward/rotating_object: 153.9847
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 5.53s
                      Time elapsed: 01:03:42
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 20125 steps/s (collection: 4.458s, learning 0.427s)
             Mean action noise std: 3.89
          Mean value_function loss: 43.7814
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 48.3077
                       Mean reward: 795.28
               Mean episode length: 245.00
    Episode_Reward/reaching_object: 0.6804
    Episode_Reward/rotating_object: 153.3511
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 4.88s
                      Time elapsed: 01:03:47
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 45001 steps/s (collection: 2.076s, learning 0.108s)
             Mean action noise std: 3.89
          Mean value_function loss: 47.9770
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 48.3137
                       Mean reward: 781.21
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 0.6871
    Episode_Reward/rotating_object: 156.1022
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.18s
                      Time elapsed: 01:03:49
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 52513 steps/s (collection: 1.750s, learning 0.122s)
             Mean action noise std: 3.89
          Mean value_function loss: 53.9880
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 48.3204
                       Mean reward: 783.22
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 0.6783
    Episode_Reward/rotating_object: 153.6335
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.87s
                      Time elapsed: 01:03:51
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 53252 steps/s (collection: 1.724s, learning 0.122s)
             Mean action noise std: 3.89
          Mean value_function loss: 45.3685
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 48.3273
                       Mean reward: 803.46
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 0.6874
    Episode_Reward/rotating_object: 156.9929
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.85s
                      Time elapsed: 01:03:53
                               ETA: 00:00:25

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 53592 steps/s (collection: 1.741s, learning 0.094s)
             Mean action noise std: 3.90
          Mean value_function loss: 35.0964
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 48.3393
                       Mean reward: 806.55
               Mean episode length: 249.82
    Episode_Reward/reaching_object: 0.6916
    Episode_Reward/rotating_object: 157.3218
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.83s
                      Time elapsed: 01:03:55
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 52441 steps/s (collection: 1.769s, learning 0.106s)
             Mean action noise std: 3.90
          Mean value_function loss: 31.0518
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 48.3445
                       Mean reward: 775.32
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.6976
    Episode_Reward/rotating_object: 159.0565
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.87s
                      Time elapsed: 01:03:57
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 52729 steps/s (collection: 1.763s, learning 0.101s)
             Mean action noise std: 3.90
          Mean value_function loss: 46.5383
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 48.3494
                       Mean reward: 770.96
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 0.6912
    Episode_Reward/rotating_object: 155.4852
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.86s
                      Time elapsed: 01:03:59
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 51415 steps/s (collection: 1.803s, learning 0.109s)
             Mean action noise std: 3.90
          Mean value_function loss: 48.9018
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 48.3553
                       Mean reward: 776.34
               Mean episode length: 240.87
    Episode_Reward/reaching_object: 0.6871
    Episode_Reward/rotating_object: 155.8928
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.91s
                      Time elapsed: 01:04:01
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 53034 steps/s (collection: 1.764s, learning 0.090s)
             Mean action noise std: 3.90
          Mean value_function loss: 44.9154
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 48.3626
                       Mean reward: 764.09
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 0.6843
    Episode_Reward/rotating_object: 155.2472
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.85s
                      Time elapsed: 01:04:03
                               ETA: 00:00:12

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 51402 steps/s (collection: 1.819s, learning 0.094s)
             Mean action noise std: 3.90
          Mean value_function loss: 35.2049
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 48.3693
                       Mean reward: 791.91
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 0.6961
    Episode_Reward/rotating_object: 158.8272
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.91s
                      Time elapsed: 01:04:04
                               ETA: 00:00:10

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 53093 steps/s (collection: 1.754s, learning 0.098s)
             Mean action noise std: 3.91
          Mean value_function loss: 51.4687
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 48.3788
                       Mean reward: 749.85
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 0.6847
    Episode_Reward/rotating_object: 154.3485
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.85s
                      Time elapsed: 01:04:06
                               ETA: 00:00:07

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 53146 steps/s (collection: 1.751s, learning 0.098s)
             Mean action noise std: 3.91
          Mean value_function loss: 36.2104
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 48.3880
                       Mean reward: 758.65
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 0.6954
    Episode_Reward/rotating_object: 156.8556
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.85s
                      Time elapsed: 01:04:08
                               ETA: 00:00:05

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 52269 steps/s (collection: 1.760s, learning 0.120s)
             Mean action noise std: 3.91
          Mean value_function loss: 37.4185
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 48.3936
                       Mean reward: 802.65
               Mean episode length: 248.63
    Episode_Reward/reaching_object: 0.6928
    Episode_Reward/rotating_object: 154.7143
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.88s
                      Time elapsed: 01:04:10
                               ETA: 00:00:02

