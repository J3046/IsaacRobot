################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10236 steps/s (collection: 9.276s, learning 0.327s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0021
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 25.5804
                       Mean reward: 0.00
               Mean episode length: 21.31
    Episode_Reward/reaching_object: 0.0004
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0002
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.60s
                      Time elapsed: 00:00:09
                               ETA: 04:00:04

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 14472 steps/s (collection: 6.619s, learning 0.173s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 25.6984
                       Mean reward: 0.00
               Mean episode length: 45.35
    Episode_Reward/reaching_object: 0.0013
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0005
          Episode_Reward/joint_vel: -0.0006
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.79s
                      Time elapsed: 00:00:16
                               ETA: 03:24:48

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14428 steps/s (collection: 6.656s, learning 0.157s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 25.7072
                       Mean reward: 0.00
               Mean episode length: 69.71
    Episode_Reward/reaching_object: 0.0023
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0010
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.81s
                      Time elapsed: 00:00:23
                               ETA: 03:13:08

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 15093 steps/s (collection: 6.363s, learning 0.150s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 25.7224
                       Mean reward: 0.00
               Mean episode length: 93.33
    Episode_Reward/reaching_object: 0.0032
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0012
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.51s
                      Time elapsed: 00:00:29
                               ETA: 03:05:23

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14350 steps/s (collection: 6.679s, learning 0.171s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 25.7381
                       Mean reward: 0.01
               Mean episode length: 117.98
    Episode_Reward/reaching_object: 0.0044
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0016
          Episode_Reward/joint_vel: -0.0018
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.85s
                      Time elapsed: 00:00:36
                               ETA: 03:02:22

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 14764 steps/s (collection: 6.494s, learning 0.164s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 25.7516
                       Mean reward: 0.01
               Mean episode length: 141.18
    Episode_Reward/reaching_object: 0.0058
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0022
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.66s
                      Time elapsed: 00:00:43
                               ETA: 02:59:31

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 14351 steps/s (collection: 6.687s, learning 0.163s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 25.7640
                       Mean reward: 0.01
               Mean episode length: 165.30
    Episode_Reward/reaching_object: 0.0073
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0026
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.85s
                      Time elapsed: 00:00:50
                               ETA: 02:58:08

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14584 steps/s (collection: 6.593s, learning 0.147s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 25.7597
                       Mean reward: 0.02
               Mean episode length: 189.28
    Episode_Reward/reaching_object: 0.0083
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0026
          Episode_Reward/joint_vel: -0.0030
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.74s
                      Time elapsed: 00:00:56
                               ETA: 02:56:44

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 17756 steps/s (collection: 5.424s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 25.7597
                       Mean reward: 0.02
               Mean episode length: 213.34
    Episode_Reward/reaching_object: 0.0103
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0030
          Episode_Reward/joint_vel: -0.0034
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.54s
                      Time elapsed: 00:01:02
                               ETA: 02:52:17

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 61278 steps/s (collection: 1.462s, learning 0.142s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 25.7550
                       Mean reward: 0.04
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.0141
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0038
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.60s
                      Time elapsed: 00:01:03
                               ETA: 02:38:56

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 64454 steps/s (collection: 1.427s, learning 0.098s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 25.7618
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0164
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.53s
                      Time elapsed: 00:01:05
                               ETA: 02:27:50

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 58672 steps/s (collection: 1.541s, learning 0.134s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 25.7516
                       Mean reward: 0.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0187
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.68s
                      Time elapsed: 00:01:07
                               ETA: 02:18:53

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 61681 steps/s (collection: 1.495s, learning 0.098s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 25.7825
                       Mean reward: 0.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0241
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.59s
                      Time elapsed: 00:01:08
                               ETA: 02:11:09

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 63714 steps/s (collection: 1.450s, learning 0.093s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 25.8177
                       Mean reward: 0.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0290
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.54s
                      Time elapsed: 00:01:10
                               ETA: 02:04:26

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 61646 steps/s (collection: 1.446s, learning 0.149s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 25.8263
                       Mean reward: 0.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0356
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.59s
                      Time elapsed: 00:01:11
                               ETA: 01:58:42

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 63103 steps/s (collection: 1.459s, learning 0.099s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 25.8544
                       Mean reward: 0.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0421
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.56s
                      Time elapsed: 00:01:13
                               ETA: 01:53:37

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 59177 steps/s (collection: 1.557s, learning 0.105s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0019
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 25.8761
                       Mean reward: 0.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0575
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.66s
                      Time elapsed: 00:01:15
                               ETA: 01:49:16

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 57570 steps/s (collection: 1.611s, learning 0.097s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0293
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 25.9165
                       Mean reward: 0.33
               Mean episode length: 249.49
    Episode_Reward/reaching_object: 0.0729
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.71s
                      Time elapsed: 00:01:16
                               ETA: 01:45:29

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 54936 steps/s (collection: 1.683s, learning 0.106s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0146
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 25.9050
                       Mean reward: 0.56
               Mean episode length: 247.47
    Episode_Reward/reaching_object: 0.1042
    Episode_Reward/rotating_object: 0.0010
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.79s
                      Time elapsed: 00:01:18
                               ETA: 01:42:11

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 50662 steps/s (collection: 1.826s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0022
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 25.9389
                       Mean reward: 0.58
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 0.1155
    Episode_Reward/rotating_object: 0.0024
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.94s
                      Time elapsed: 00:01:20
                               ETA: 01:39:24

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 54299 steps/s (collection: 1.710s, learning 0.100s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0017
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 25.9729
                       Mean reward: 0.79
               Mean episode length: 241.49
    Episode_Reward/reaching_object: 0.1483
    Episode_Reward/rotating_object: 0.0038
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.81s
                      Time elapsed: 00:01:22
                               ETA: 01:36:44

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 51822 steps/s (collection: 1.712s, learning 0.185s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0018
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 25.9927
                       Mean reward: 0.84
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 0.1559
    Episode_Reward/rotating_object: 0.0035
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.90s
                      Time elapsed: 00:01:24
                               ETA: 01:34:24

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 49686 steps/s (collection: 1.852s, learning 0.126s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0020
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 26.0334
                       Mean reward: 0.88
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 0.1683
    Episode_Reward/rotating_object: 0.0040
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 10.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.98s
                      Time elapsed: 00:01:26
                               ETA: 01:32:21

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 51232 steps/s (collection: 1.806s, learning 0.113s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0030
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 26.0926
                       Mean reward: 1.03
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 0.1892
    Episode_Reward/rotating_object: 0.0073
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 8.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.92s
                      Time elapsed: 00:01:28
                               ETA: 01:30:25

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 52579 steps/s (collection: 1.750s, learning 0.120s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0043
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 26.1242
                       Mean reward: 1.03
               Mean episode length: 230.00
    Episode_Reward/reaching_object: 0.1930
    Episode_Reward/rotating_object: 0.0105
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 8.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.87s
                      Time elapsed: 00:01:30
                               ETA: 01:28:34

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 50658 steps/s (collection: 1.786s, learning 0.155s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0058
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 26.2606
                       Mean reward: 1.11
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 0.2118
    Episode_Reward/rotating_object: 0.0143
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 8.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.94s
                      Time elapsed: 00:01:31
                               ETA: 01:26:57

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 52489 steps/s (collection: 1.759s, learning 0.114s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0101
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 26.2730
                       Mean reward: 1.42
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 0.2228
    Episode_Reward/rotating_object: 0.0219
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 6.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.87s
                      Time elapsed: 00:01:33
                               ETA: 01:25:22

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 52880 steps/s (collection: 1.760s, learning 0.099s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0100
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 26.3816
                       Mean reward: 1.39
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 0.2331
    Episode_Reward/rotating_object: 0.0311
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 9.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.86s
                      Time elapsed: 00:01:35
                               ETA: 01:23:54

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 53546 steps/s (collection: 1.742s, learning 0.094s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0179
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 26.4583
                       Mean reward: 1.46
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 0.2434
    Episode_Reward/rotating_object: 0.0343
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 8.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.84s
                      Time elapsed: 00:01:37
                               ETA: 01:22:30

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 51740 steps/s (collection: 1.772s, learning 0.127s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.1621
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 26.5469
                       Mean reward: 1.54
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 0.2565
    Episode_Reward/rotating_object: 0.0503
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 9.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.90s
                      Time elapsed: 00:01:39
                               ETA: 01:21:15

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 45290 steps/s (collection: 2.004s, learning 0.166s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1915
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 26.6259
                       Mean reward: 1.73
               Mean episode length: 225.84
    Episode_Reward/reaching_object: 0.2755
    Episode_Reward/rotating_object: 0.0539
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 9.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.17s
                      Time elapsed: 00:01:41
                               ETA: 01:20:17

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 45706 steps/s (collection: 1.967s, learning 0.184s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3866
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 26.7537
                       Mean reward: 3.37
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 0.2857
    Episode_Reward/rotating_object: 0.1081
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 10.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.15s
                      Time elapsed: 00:01:43
                               ETA: 01:19:22

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 48985 steps/s (collection: 1.892s, learning 0.115s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.2189
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 26.9810
                       Mean reward: 1.84
               Mean episode length: 224.97
    Episode_Reward/reaching_object: 0.3085
    Episode_Reward/rotating_object: 0.2081
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 10.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.01s
                      Time elapsed: 00:01:45
                               ETA: 01:18:24

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 51410 steps/s (collection: 1.805s, learning 0.107s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.3649
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 27.1216
                       Mean reward: 2.63
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 0.3288
    Episode_Reward/rotating_object: 0.2568
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 10.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.91s
                      Time elapsed: 00:01:47
                               ETA: 01:17:25

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 51759 steps/s (collection: 1.793s, learning 0.106s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.1047
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 27.2787
                       Mean reward: 2.08
               Mean episode length: 220.97
    Episode_Reward/reaching_object: 0.3303
    Episode_Reward/rotating_object: 0.2086
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 9.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.90s
                      Time elapsed: 00:01:49
                               ETA: 01:16:29

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 48756 steps/s (collection: 1.924s, learning 0.093s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.2267
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 27.3851
                       Mean reward: 2.34
               Mean episode length: 217.79
    Episode_Reward/reaching_object: 0.3434
    Episode_Reward/rotating_object: 0.1614
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 9.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.02s
                      Time elapsed: 00:01:51
                               ETA: 01:15:40

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 49594 steps/s (collection: 1.888s, learning 0.095s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.5594
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 27.5136
                       Mean reward: 4.00
               Mean episode length: 211.05
    Episode_Reward/reaching_object: 0.3476
    Episode_Reward/rotating_object: 0.3108
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 9.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.98s
                      Time elapsed: 00:01:53
                               ETA: 01:14:53

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 49632 steps/s (collection: 1.883s, learning 0.098s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.4127
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 27.6421
                       Mean reward: 2.49
               Mean episode length: 219.41
    Episode_Reward/reaching_object: 0.3648
    Episode_Reward/rotating_object: 0.3052
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 10.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.98s
                      Time elapsed: 00:01:55
                               ETA: 01:14:08

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 50490 steps/s (collection: 1.854s, learning 0.093s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.5666
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 27.7122
                       Mean reward: 4.09
               Mean episode length: 218.40
    Episode_Reward/reaching_object: 0.3773
    Episode_Reward/rotating_object: 0.3631
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 10.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.95s
                      Time elapsed: 00:01:57
                               ETA: 01:13:24

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 51014 steps/s (collection: 1.832s, learning 0.095s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.2518
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 27.8092
                       Mean reward: 4.10
               Mean episode length: 215.88
    Episode_Reward/reaching_object: 0.3690
    Episode_Reward/rotating_object: 0.3683
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 9.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.93s
                      Time elapsed: 00:01:59
                               ETA: 01:12:41

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 50826 steps/s (collection: 1.833s, learning 0.101s)
             Mean action noise std: 1.14
          Mean value_function loss: 2.0361
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 27.8634
                       Mean reward: 4.78
               Mean episode length: 221.23
    Episode_Reward/reaching_object: 0.3848
    Episode_Reward/rotating_object: 0.5868
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.93s
                      Time elapsed: 00:02:01
                               ETA: 01:12:01

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 50879 steps/s (collection: 1.826s, learning 0.107s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.4148
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 27.9479
                       Mean reward: 7.10
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 0.4173
    Episode_Reward/rotating_object: 0.8035
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.93s
                      Time elapsed: 00:02:03
                               ETA: 01:11:22

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 48989 steps/s (collection: 1.857s, learning 0.150s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.9381
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 28.0116
                       Mean reward: 8.48
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 0.4486
    Episode_Reward/rotating_object: 1.4495
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.01s
                      Time elapsed: 00:02:05
                               ETA: 01:10:48

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 49846 steps/s (collection: 1.877s, learning 0.095s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.4643
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 28.0643
                       Mean reward: 5.79
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 0.4406
    Episode_Reward/rotating_object: 1.2800
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.97s
                      Time elapsed: 00:02:07
                               ETA: 01:10:14

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 50775 steps/s (collection: 1.821s, learning 0.115s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.5071
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 28.1326
                       Mean reward: 7.30
               Mean episode length: 218.83
    Episode_Reward/reaching_object: 0.4311
    Episode_Reward/rotating_object: 1.6398
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.94s
                      Time elapsed: 00:02:09
                               ETA: 01:09:40

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 51281 steps/s (collection: 1.824s, learning 0.093s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.8886
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 28.2252
                       Mean reward: 8.75
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 0.4194
    Episode_Reward/rotating_object: 1.3365
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.92s
                      Time elapsed: 00:02:11
                               ETA: 01:09:07

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 50263 steps/s (collection: 1.802s, learning 0.154s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.5157
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 28.3044
                       Mean reward: 7.08
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 0.4261
    Episode_Reward/rotating_object: 1.2438
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.96s
                      Time elapsed: 00:02:13
                               ETA: 01:08:36

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 50020 steps/s (collection: 1.785s, learning 0.181s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.8197
               Mean surrogate loss: 0.0081
                 Mean entropy loss: 28.3388
                       Mean reward: 8.05
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 0.4338
    Episode_Reward/rotating_object: 1.3429
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.97s
                      Time elapsed: 00:02:15
                               ETA: 01:08:07

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 52123 steps/s (collection: 1.776s, learning 0.110s)
             Mean action noise std: 1.17
          Mean value_function loss: 4.9695
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 28.3452
                       Mean reward: 13.83
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 0.4360
    Episode_Reward/rotating_object: 2.0729
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.89s
                      Time elapsed: 00:02:16
                               ETA: 01:07:37

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 51224 steps/s (collection: 1.811s, learning 0.108s)
             Mean action noise std: 1.17
          Mean value_function loss: 6.3558
               Mean surrogate loss: 0.0082
                 Mean entropy loss: 28.3567
                       Mean reward: 12.69
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 0.4276
    Episode_Reward/rotating_object: 2.4689
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.92s
                      Time elapsed: 00:02:18
                               ETA: 01:07:09

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 47612 steps/s (collection: 1.886s, learning 0.179s)
             Mean action noise std: 1.17
          Mean value_function loss: 7.0189
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 28.3634
                       Mean reward: 17.96
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 0.4345
    Episode_Reward/rotating_object: 3.1478
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.06s
                      Time elapsed: 00:02:20
                               ETA: 01:06:46

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 50827 steps/s (collection: 1.840s, learning 0.094s)
             Mean action noise std: 1.17
          Mean value_function loss: 5.7666
               Mean surrogate loss: 0.0121
                 Mean entropy loss: 28.4023
                       Mean reward: 13.06
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 0.4514
    Episode_Reward/rotating_object: 2.7977
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 1.93s
                      Time elapsed: 00:02:22
                               ETA: 01:06:20

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 53344 steps/s (collection: 1.746s, learning 0.096s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.9273
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 28.4120
                       Mean reward: 16.77
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 0.4545
    Episode_Reward/rotating_object: 3.8519
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.84s
                      Time elapsed: 00:02:24
                               ETA: 01:05:53

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 52525 steps/s (collection: 1.765s, learning 0.107s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.6767
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 28.4275
                       Mean reward: 16.08
               Mean episode length: 241.96
    Episode_Reward/reaching_object: 0.4444
    Episode_Reward/rotating_object: 3.9056
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.87s
                      Time elapsed: 00:02:26
                               ETA: 01:05:27

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 52918 steps/s (collection: 1.745s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.5298
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 28.4610
                       Mean reward: 12.94
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 0.4369
    Episode_Reward/rotating_object: 2.3664
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.86s
                      Time elapsed: 00:02:28
                               ETA: 01:05:02

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 49947 steps/s (collection: 1.833s, learning 0.136s)
             Mean action noise std: 1.18
          Mean value_function loss: 5.2374
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 28.5152
                       Mean reward: 11.94
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 0.4198
    Episode_Reward/rotating_object: 2.1474
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.97s
                      Time elapsed: 00:02:30
                               ETA: 01:04:40

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 51463 steps/s (collection: 1.814s, learning 0.096s)
             Mean action noise std: 1.18
          Mean value_function loss: 6.8324
               Mean surrogate loss: 0.0237
                 Mean entropy loss: 28.5448
                       Mean reward: 13.04
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 0.4348
    Episode_Reward/rotating_object: 2.6028
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.91s
                      Time elapsed: 00:02:32
                               ETA: 01:04:18

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 50118 steps/s (collection: 1.853s, learning 0.108s)
             Mean action noise std: 1.18
          Mean value_function loss: 6.9458
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 28.5575
                       Mean reward: 16.56
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 0.4242
    Episode_Reward/rotating_object: 2.8437
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.96s
                      Time elapsed: 00:02:34
                               ETA: 01:03:57

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 46746 steps/s (collection: 1.898s, learning 0.205s)
             Mean action noise std: 1.19
          Mean value_function loss: 6.7065
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 28.6186
                       Mean reward: 20.82
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 0.4042
    Episode_Reward/rotating_object: 3.3863
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.10s
                      Time elapsed: 00:02:36
                               ETA: 01:03:41

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 47596 steps/s (collection: 1.967s, learning 0.098s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.5523
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 28.6560
                       Mean reward: 14.68
               Mean episode length: 218.47
    Episode_Reward/reaching_object: 0.3940
    Episode_Reward/rotating_object: 3.5952
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 9.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.07s
                      Time elapsed: 00:02:38
                               ETA: 01:03:24

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 50474 steps/s (collection: 1.851s, learning 0.097s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.2458
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 28.6943
                       Mean reward: 16.28
               Mean episode length: 218.61
    Episode_Reward/reaching_object: 0.3818
    Episode_Reward/rotating_object: 3.0673
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.95s
                      Time elapsed: 00:02:40
                               ETA: 01:03:05

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 47992 steps/s (collection: 1.905s, learning 0.144s)
             Mean action noise std: 1.20
          Mean value_function loss: 4.8302
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 28.7411
                       Mean reward: 22.72
               Mean episode length: 218.34
    Episode_Reward/reaching_object: 0.3796
    Episode_Reward/rotating_object: 3.8899
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 10.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.05s
                      Time elapsed: 00:02:42
                               ETA: 01:02:49

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 49489 steps/s (collection: 1.889s, learning 0.097s)
             Mean action noise std: 1.20
          Mean value_function loss: 5.5043
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 28.8074
                       Mean reward: 21.55
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 0.3773
    Episode_Reward/rotating_object: 3.4516
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 9.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.99s
                      Time elapsed: 00:02:44
                               ETA: 01:02:32

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 49574 steps/s (collection: 1.891s, learning 0.092s)
             Mean action noise std: 1.21
          Mean value_function loss: 6.7945
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 28.8630
                       Mean reward: 10.62
               Mean episode length: 212.95
    Episode_Reward/reaching_object: 0.3895
    Episode_Reward/rotating_object: 2.1416
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 8.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.98s
                      Time elapsed: 00:02:46
                               ETA: 01:02:16

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 50432 steps/s (collection: 1.857s, learning 0.093s)
             Mean action noise std: 1.21
          Mean value_function loss: 7.2785
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 28.9057
                       Mean reward: 20.71
               Mean episode length: 216.42
    Episode_Reward/reaching_object: 0.3904
    Episode_Reward/rotating_object: 2.8143
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 8.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.95s
                      Time elapsed: 00:02:48
                               ETA: 01:01:59

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 50116 steps/s (collection: 1.831s, learning 0.131s)
             Mean action noise std: 1.21
          Mean value_function loss: 8.2663
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 28.9535
                       Mean reward: 12.27
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 0.4158
    Episode_Reward/rotating_object: 2.3961
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 9.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.96s
                      Time elapsed: 00:02:50
                               ETA: 01:01:42

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 46619 steps/s (collection: 1.957s, learning 0.152s)
             Mean action noise std: 1.22
          Mean value_function loss: 8.6588
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 29.0040
                       Mean reward: 13.05
               Mean episode length: 231.78
    Episode_Reward/reaching_object: 0.4277
    Episode_Reward/rotating_object: 2.9547
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.11s
                      Time elapsed: 00:02:52
                               ETA: 01:01:30

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 50374 steps/s (collection: 1.853s, learning 0.099s)
             Mean action noise std: 1.22
          Mean value_function loss: 8.9315
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 29.0601
                       Mean reward: 17.99
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 0.4307
    Episode_Reward/rotating_object: 3.2371
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.95s
                      Time elapsed: 00:02:54
                               ETA: 01:01:14

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 51242 steps/s (collection: 1.780s, learning 0.138s)
             Mean action noise std: 1.22
          Mean value_function loss: 11.1879
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 29.1026
                       Mean reward: 20.39
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.4283
    Episode_Reward/rotating_object: 3.3392
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.92s
                      Time elapsed: 00:02:56
                               ETA: 01:00:58

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 50756 steps/s (collection: 1.815s, learning 0.122s)
             Mean action noise std: 1.23
          Mean value_function loss: 12.8290
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 29.1610
                       Mean reward: 22.38
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 0.4575
    Episode_Reward/rotating_object: 4.4645
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.94s
                      Time elapsed: 00:02:58
                               ETA: 01:00:43

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 51599 steps/s (collection: 1.787s, learning 0.118s)
             Mean action noise std: 1.23
          Mean value_function loss: 15.9993
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 29.2040
                       Mean reward: 19.12
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.4309
    Episode_Reward/rotating_object: 4.5153
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 18.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.91s
                      Time elapsed: 00:03:00
                               ETA: 01:00:27

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 46879 steps/s (collection: 1.949s, learning 0.148s)
             Mean action noise std: 1.23
          Mean value_function loss: 13.7651
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 29.2322
                       Mean reward: 33.16
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 0.4179
    Episode_Reward/rotating_object: 5.1733
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.10s
                      Time elapsed: 00:03:02
                               ETA: 01:00:16

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 51221 steps/s (collection: 1.815s, learning 0.105s)
             Mean action noise std: 1.23
          Mean value_function loss: 11.7829
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 29.2464
                       Mean reward: 23.24
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 0.4270
    Episode_Reward/rotating_object: 5.3498
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.92s
                      Time elapsed: 00:03:04
                               ETA: 01:00:02

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 50289 steps/s (collection: 1.807s, learning 0.148s)
             Mean action noise std: 1.23
          Mean value_function loss: 11.0402
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 29.2593
                       Mean reward: 30.28
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 0.4049
    Episode_Reward/rotating_object: 4.4819
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.95s
                      Time elapsed: 00:03:06
                               ETA: 00:59:48

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 50662 steps/s (collection: 1.834s, learning 0.106s)
             Mean action noise std: 1.24
          Mean value_function loss: 11.7705
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 29.2931
                       Mean reward: 24.86
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 0.3889
    Episode_Reward/rotating_object: 4.2159
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.94s
                      Time elapsed: 00:03:08
                               ETA: 00:59:35

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 51669 steps/s (collection: 1.804s, learning 0.099s)
             Mean action noise std: 1.24
          Mean value_function loss: 13.3485
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 29.3486
                       Mean reward: 25.52
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 0.3959
    Episode_Reward/rotating_object: 5.3771
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.90s
                      Time elapsed: 00:03:09
                               ETA: 00:59:21

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 52008 steps/s (collection: 1.800s, learning 0.090s)
             Mean action noise std: 1.24
          Mean value_function loss: 15.5987
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 29.3776
                       Mean reward: 33.25
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 0.3948
    Episode_Reward/rotating_object: 5.4600
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.89s
                      Time elapsed: 00:03:11
                               ETA: 00:59:07

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 51252 steps/s (collection: 1.823s, learning 0.095s)
             Mean action noise std: 1.24
          Mean value_function loss: 13.6111
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 29.4139
                       Mean reward: 25.04
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.3856
    Episode_Reward/rotating_object: 4.8298
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.92s
                      Time elapsed: 00:03:13
                               ETA: 00:58:54

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 51517 steps/s (collection: 1.801s, learning 0.107s)
             Mean action noise std: 1.25
          Mean value_function loss: 13.4965
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 29.4627
                       Mean reward: 31.25
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.3735
    Episode_Reward/rotating_object: 4.9131
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.91s
                      Time elapsed: 00:03:15
                               ETA: 00:58:41

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 51241 steps/s (collection: 1.818s, learning 0.100s)
             Mean action noise std: 1.25
          Mean value_function loss: 13.9626
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 29.4955
                       Mean reward: 35.45
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 0.3876
    Episode_Reward/rotating_object: 4.8030
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.92s
                      Time elapsed: 00:03:17
                               ETA: 00:58:29

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 52221 steps/s (collection: 1.785s, learning 0.097s)
             Mean action noise std: 1.25
          Mean value_function loss: 12.7020
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 29.5280
                       Mean reward: 42.61
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 0.3905
    Episode_Reward/rotating_object: 5.7422
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.88s
                      Time elapsed: 00:03:19
                               ETA: 00:58:16

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 51348 steps/s (collection: 1.814s, learning 0.101s)
             Mean action noise std: 1.25
          Mean value_function loss: 11.5500
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 29.5486
                       Mean reward: 32.73
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 0.3885
    Episode_Reward/rotating_object: 5.1549
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.91s
                      Time elapsed: 00:03:21
                               ETA: 00:58:04

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 50007 steps/s (collection: 1.844s, learning 0.122s)
             Mean action noise std: 1.25
          Mean value_function loss: 13.0427
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 29.5793
                       Mean reward: 27.45
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.3740
    Episode_Reward/rotating_object: 5.4695
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.97s
                      Time elapsed: 00:03:23
                               ETA: 00:57:53

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 51726 steps/s (collection: 1.788s, learning 0.113s)
             Mean action noise std: 1.26
          Mean value_function loss: 13.5928
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 29.6067
                       Mean reward: 38.44
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.3718
    Episode_Reward/rotating_object: 5.4597
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.90s
                      Time elapsed: 00:03:25
                               ETA: 00:57:42

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 47292 steps/s (collection: 1.920s, learning 0.159s)
             Mean action noise std: 1.26
          Mean value_function loss: 12.7558
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 29.6499
                       Mean reward: 28.98
               Mean episode length: 232.04
    Episode_Reward/reaching_object: 0.3743
    Episode_Reward/rotating_object: 5.9075
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.08s
                      Time elapsed: 00:03:27
                               ETA: 00:57:33

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 49265 steps/s (collection: 1.904s, learning 0.091s)
             Mean action noise std: 1.26
          Mean value_function loss: 11.0777
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 29.6961
                       Mean reward: 21.63
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 0.3542
    Episode_Reward/rotating_object: 4.1556
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 11.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.00s
                      Time elapsed: 00:03:29
                               ETA: 00:57:23

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 49542 steps/s (collection: 1.845s, learning 0.139s)
             Mean action noise std: 1.26
          Mean value_function loss: 11.5618
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 29.7327
                       Mean reward: 29.21
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 0.3705
    Episode_Reward/rotating_object: 5.6617
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 11.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.98s
                      Time elapsed: 00:03:31
                               ETA: 00:57:14

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 50295 steps/s (collection: 1.823s, learning 0.132s)
             Mean action noise std: 1.27
          Mean value_function loss: 10.2549
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 29.7687
                       Mean reward: 31.65
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 0.3607
    Episode_Reward/rotating_object: 5.4985
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.95s
                      Time elapsed: 00:03:33
                               ETA: 00:57:04

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 49632 steps/s (collection: 1.835s, learning 0.146s)
             Mean action noise std: 1.27
          Mean value_function loss: 10.4282
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 29.8020
                       Mean reward: 23.23
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 0.3672
    Episode_Reward/rotating_object: 5.2158
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.98s
                      Time elapsed: 00:03:35
                               ETA: 00:56:54

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 48286 steps/s (collection: 1.911s, learning 0.125s)
             Mean action noise std: 1.27
          Mean value_function loss: 10.8532
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 29.8308
                       Mean reward: 23.57
               Mean episode length: 220.76
    Episode_Reward/reaching_object: 0.3634
    Episode_Reward/rotating_object: 5.0225
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.04s
                      Time elapsed: 00:03:37
                               ETA: 00:56:46

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 49344 steps/s (collection: 1.876s, learning 0.117s)
             Mean action noise std: 1.27
          Mean value_function loss: 12.1140
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 29.8587
                       Mean reward: 33.44
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 0.3736
    Episode_Reward/rotating_object: 5.6574
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.99s
                      Time elapsed: 00:03:39
                               ETA: 00:56:37

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 50740 steps/s (collection: 1.821s, learning 0.116s)
             Mean action noise std: 1.28
          Mean value_function loss: 10.9637
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 29.8850
                       Mean reward: 22.69
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 0.3628
    Episode_Reward/rotating_object: 4.7767
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.94s
                      Time elapsed: 00:03:41
                               ETA: 00:56:27

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 45132 steps/s (collection: 2.011s, learning 0.168s)
             Mean action noise std: 1.28
          Mean value_function loss: 13.1860
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 29.9177
                       Mean reward: 35.95
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 0.3755
    Episode_Reward/rotating_object: 6.2307
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.18s
                      Time elapsed: 00:03:43
                               ETA: 00:56:21

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 49895 steps/s (collection: 1.872s, learning 0.099s)
             Mean action noise std: 1.28
          Mean value_function loss: 13.9708
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 29.9617
                       Mean reward: 29.86
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 0.3776
    Episode_Reward/rotating_object: 6.1290
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.97s
                      Time elapsed: 00:03:45
                               ETA: 00:56:12

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 49353 steps/s (collection: 1.824s, learning 0.168s)
             Mean action noise std: 1.28
          Mean value_function loss: 13.7866
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 29.9929
                       Mean reward: 31.68
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 0.3489
    Episode_Reward/rotating_object: 5.4695
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.99s
                      Time elapsed: 00:03:47
                               ETA: 00:56:04

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 48683 steps/s (collection: 1.822s, learning 0.198s)
             Mean action noise std: 1.29
          Mean value_function loss: 13.6031
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 30.0385
                       Mean reward: 32.58
               Mean episode length: 222.22
    Episode_Reward/reaching_object: 0.3501
    Episode_Reward/rotating_object: 5.0426
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.02s
                      Time elapsed: 00:03:49
                               ETA: 00:55:56

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 48299 steps/s (collection: 1.862s, learning 0.174s)
             Mean action noise std: 1.29
          Mean value_function loss: 14.8753
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 30.0631
                       Mean reward: 26.32
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 0.3623
    Episode_Reward/rotating_object: 5.7506
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 10.3750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.04s
                      Time elapsed: 00:03:51
                               ETA: 00:55:49

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 47594 steps/s (collection: 1.932s, learning 0.134s)
             Mean action noise std: 1.29
          Mean value_function loss: 14.9087
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 30.1024
                       Mean reward: 26.06
               Mean episode length: 215.99
    Episode_Reward/reaching_object: 0.3447
    Episode_Reward/rotating_object: 5.7458
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.07s
                      Time elapsed: 00:03:53
                               ETA: 00:55:42

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 50212 steps/s (collection: 1.823s, learning 0.135s)
             Mean action noise std: 1.30
          Mean value_function loss: 15.7594
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 30.1490
                       Mean reward: 28.05
               Mean episode length: 220.16
    Episode_Reward/reaching_object: 0.3558
    Episode_Reward/rotating_object: 5.4814
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.96s
                      Time elapsed: 00:03:55
                               ETA: 00:55:33

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 49606 steps/s (collection: 1.839s, learning 0.143s)
             Mean action noise std: 1.30
          Mean value_function loss: 14.0340
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.1964
                       Mean reward: 34.42
               Mean episode length: 226.37
    Episode_Reward/reaching_object: 0.3504
    Episode_Reward/rotating_object: 7.2883
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.98s
                      Time elapsed: 00:03:57
                               ETA: 00:55:25

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 50047 steps/s (collection: 1.836s, learning 0.128s)
             Mean action noise std: 1.30
          Mean value_function loss: 14.6886
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 30.2382
                       Mean reward: 46.65
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 0.3804
    Episode_Reward/rotating_object: 7.9836
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.96s
                      Time elapsed: 00:03:59
                               ETA: 00:55:17

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 47375 steps/s (collection: 1.961s, learning 0.114s)
             Mean action noise std: 1.30
          Mean value_function loss: 14.3447
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 30.2718
                       Mean reward: 36.61
               Mean episode length: 220.75
    Episode_Reward/reaching_object: 0.3591
    Episode_Reward/rotating_object: 5.5975
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.08s
                      Time elapsed: 00:04:01
                               ETA: 00:55:11

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 46674 steps/s (collection: 1.967s, learning 0.139s)
             Mean action noise std: 1.30
          Mean value_function loss: 14.5318
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 30.2837
                       Mean reward: 28.95
               Mean episode length: 227.37
    Episode_Reward/reaching_object: 0.3777
    Episode_Reward/rotating_object: 6.6609
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.11s
                      Time elapsed: 00:04:03
                               ETA: 00:55:05

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 48202 steps/s (collection: 1.918s, learning 0.121s)
             Mean action noise std: 1.31
          Mean value_function loss: 16.3461
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 30.3000
                       Mean reward: 40.34
               Mean episode length: 220.06
    Episode_Reward/reaching_object: 0.3679
    Episode_Reward/rotating_object: 7.7043
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.04s
                      Time elapsed: 00:04:05
                               ETA: 00:54:58

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 49698 steps/s (collection: 1.871s, learning 0.107s)
             Mean action noise std: 1.31
          Mean value_function loss: 18.3807
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 30.3249
                       Mean reward: 43.48
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 0.3829
    Episode_Reward/rotating_object: 7.4113
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.98s
                      Time elapsed: 00:04:07
                               ETA: 00:54:51

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 48857 steps/s (collection: 1.920s, learning 0.092s)
             Mean action noise std: 1.31
          Mean value_function loss: 18.9301
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 30.3525
                       Mean reward: 58.86
               Mean episode length: 226.22
    Episode_Reward/reaching_object: 0.3934
    Episode_Reward/rotating_object: 8.4329
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 1.4167
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.01s
                      Time elapsed: 00:04:09
                               ETA: 00:54:44

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 49681 steps/s (collection: 1.867s, learning 0.112s)
             Mean action noise std: 1.31
          Mean value_function loss: 17.0648
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 30.3674
                       Mean reward: 32.20
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 0.3790
    Episode_Reward/rotating_object: 6.3803
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 10.6250
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.98s
                      Time elapsed: 00:04:11
                               ETA: 00:54:37

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 49478 steps/s (collection: 1.839s, learning 0.148s)
             Mean action noise std: 1.31
          Mean value_function loss: 18.2218
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 30.3969
                       Mean reward: 46.19
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 0.4102
    Episode_Reward/rotating_object: 7.6692
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 10.7500
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.99s
                      Time elapsed: 00:04:13
                               ETA: 00:54:30

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 49690 steps/s (collection: 1.847s, learning 0.131s)
             Mean action noise std: 1.32
          Mean value_function loss: 18.6037
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 30.4345
                       Mean reward: 46.56
               Mean episode length: 228.33
    Episode_Reward/reaching_object: 0.3906
    Episode_Reward/rotating_object: 8.4515
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 11.9167
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.98s
                      Time elapsed: 00:04:15
                               ETA: 00:54:23

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 50118 steps/s (collection: 1.857s, learning 0.105s)
             Mean action noise std: 1.32
          Mean value_function loss: 20.3059
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.4685
                       Mean reward: 52.41
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 0.4139
    Episode_Reward/rotating_object: 8.0879
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.96s
                      Time elapsed: 00:04:17
                               ETA: 00:54:15

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 48279 steps/s (collection: 1.877s, learning 0.160s)
             Mean action noise std: 1.32
          Mean value_function loss: 21.3553
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 30.4959
                       Mean reward: 33.68
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 0.3913
    Episode_Reward/rotating_object: 7.5541
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.04s
                      Time elapsed: 00:04:19
                               ETA: 00:54:09

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 49567 steps/s (collection: 1.870s, learning 0.114s)
             Mean action noise std: 1.32
          Mean value_function loss: 21.0072
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 30.5305
                       Mean reward: 62.42
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 0.4153
    Episode_Reward/rotating_object: 9.7316
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.98s
                      Time elapsed: 00:04:21
                               ETA: 00:54:02

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 49520 steps/s (collection: 1.840s, learning 0.145s)
             Mean action noise std: 1.32
          Mean value_function loss: 21.0934
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 30.5471
                       Mean reward: 39.92
               Mean episode length: 223.95
    Episode_Reward/reaching_object: 0.3990
    Episode_Reward/rotating_object: 8.9519
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.99s
                      Time elapsed: 00:04:23
                               ETA: 00:53:56

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 49678 steps/s (collection: 1.850s, learning 0.129s)
             Mean action noise std: 1.33
          Mean value_function loss: 20.0497
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 30.5637
                       Mean reward: 30.65
               Mean episode length: 224.96
    Episode_Reward/reaching_object: 0.4015
    Episode_Reward/rotating_object: 7.9448
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.98s
                      Time elapsed: 00:04:25
                               ETA: 00:53:49

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 50878 steps/s (collection: 1.831s, learning 0.101s)
             Mean action noise std: 1.33
          Mean value_function loss: 24.3836
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 30.5870
                       Mean reward: 39.25
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 0.3893
    Episode_Reward/rotating_object: 8.8845
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 10.8333
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.93s
                      Time elapsed: 00:04:27
                               ETA: 00:53:42

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 49945 steps/s (collection: 1.835s, learning 0.133s)
             Mean action noise std: 1.33
          Mean value_function loss: 23.1092
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 30.6047
                       Mean reward: 58.45
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 0.3940
    Episode_Reward/rotating_object: 8.9832
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.97s
                      Time elapsed: 00:04:29
                               ETA: 00:53:36

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 49961 steps/s (collection: 1.832s, learning 0.136s)
             Mean action noise std: 1.33
          Mean value_function loss: 26.7389
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 30.6266
                       Mean reward: 34.45
               Mean episode length: 222.82
    Episode_Reward/reaching_object: 0.3891
    Episode_Reward/rotating_object: 8.8454
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.97s
                      Time elapsed: 00:04:31
                               ETA: 00:53:29

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 49668 steps/s (collection: 1.834s, learning 0.146s)
             Mean action noise std: 1.33
          Mean value_function loss: 30.3166
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 30.6394
                       Mean reward: 49.39
               Mean episode length: 225.80
    Episode_Reward/reaching_object: 0.3879
    Episode_Reward/rotating_object: 9.1968
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 10.4583
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.98s
                      Time elapsed: 00:04:33
                               ETA: 00:53:23

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 50828 steps/s (collection: 1.832s, learning 0.102s)
             Mean action noise std: 1.33
          Mean value_function loss: 28.7137
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 30.6552
                       Mean reward: 61.52
               Mean episode length: 219.88
    Episode_Reward/reaching_object: 0.4041
    Episode_Reward/rotating_object: 9.4365
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.93s
                      Time elapsed: 00:04:35
                               ETA: 00:53:16

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 49412 steps/s (collection: 1.882s, learning 0.107s)
             Mean action noise std: 1.33
          Mean value_function loss: 29.4917
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 30.6849
                       Mean reward: 69.84
               Mean episode length: 222.11
    Episode_Reward/reaching_object: 0.4032
    Episode_Reward/rotating_object: 11.4772
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.99s
                      Time elapsed: 00:04:37
                               ETA: 00:53:10

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 50419 steps/s (collection: 1.855s, learning 0.095s)
             Mean action noise std: 1.34
          Mean value_function loss: 27.1648
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 30.7163
                       Mean reward: 60.82
               Mean episode length: 228.39
    Episode_Reward/reaching_object: 0.3932
    Episode_Reward/rotating_object: 9.9046
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 10.6250
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.95s
                      Time elapsed: 00:04:39
                               ETA: 00:53:04

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 48594 steps/s (collection: 1.865s, learning 0.158s)
             Mean action noise std: 1.34
          Mean value_function loss: 26.5442
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 30.7368
                       Mean reward: 43.19
               Mean episode length: 219.48
    Episode_Reward/reaching_object: 0.3873
    Episode_Reward/rotating_object: 8.4187
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.02s
                      Time elapsed: 00:04:41
                               ETA: 00:52:58

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 49390 steps/s (collection: 1.893s, learning 0.098s)
             Mean action noise std: 1.34
          Mean value_function loss: 23.4854
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.7508
                       Mean reward: 46.53
               Mean episode length: 225.93
    Episode_Reward/reaching_object: 0.3837
    Episode_Reward/rotating_object: 9.5901
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.99s
                      Time elapsed: 00:04:43
                               ETA: 00:52:52

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 48901 steps/s (collection: 1.909s, learning 0.102s)
             Mean action noise std: 1.34
          Mean value_function loss: 25.7970
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 30.7767
                       Mean reward: 50.19
               Mean episode length: 219.13
    Episode_Reward/reaching_object: 0.3844
    Episode_Reward/rotating_object: 10.5740
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.01s
                      Time elapsed: 00:04:45
                               ETA: 00:52:47

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 49649 steps/s (collection: 1.879s, learning 0.101s)
             Mean action noise std: 1.34
          Mean value_function loss: 26.2107
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 30.8080
                       Mean reward: 42.05
               Mean episode length: 209.77
    Episode_Reward/reaching_object: 0.3906
    Episode_Reward/rotating_object: 10.2837
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.98s
                      Time elapsed: 00:04:47
                               ETA: 00:52:41

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 48511 steps/s (collection: 1.920s, learning 0.106s)
             Mean action noise std: 1.35
          Mean value_function loss: 28.2505
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.8297
                       Mean reward: 54.07
               Mean episode length: 225.12
    Episode_Reward/reaching_object: 0.3781
    Episode_Reward/rotating_object: 9.4192
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.03s
                      Time elapsed: 00:04:49
                               ETA: 00:52:36

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 49038 steps/s (collection: 1.898s, learning 0.107s)
             Mean action noise std: 1.35
          Mean value_function loss: 25.7633
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 30.8602
                       Mean reward: 40.01
               Mean episode length: 211.56
    Episode_Reward/reaching_object: 0.3690
    Episode_Reward/rotating_object: 9.6864
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.00s
                      Time elapsed: 00:04:51
                               ETA: 00:52:30

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 47713 steps/s (collection: 1.903s, learning 0.157s)
             Mean action noise std: 1.35
          Mean value_function loss: 27.5479
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 30.8868
                       Mean reward: 49.51
               Mean episode length: 213.85
    Episode_Reward/reaching_object: 0.3692
    Episode_Reward/rotating_object: 9.0220
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 10.5833
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.06s
                      Time elapsed: 00:04:53
                               ETA: 00:52:25

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 46773 steps/s (collection: 1.965s, learning 0.137s)
             Mean action noise std: 1.35
          Mean value_function loss: 26.5118
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 30.9193
                       Mean reward: 52.28
               Mean episode length: 211.72
    Episode_Reward/reaching_object: 0.3812
    Episode_Reward/rotating_object: 10.9170
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 11.2083
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.10s
                      Time elapsed: 00:04:55
                               ETA: 00:52:21

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 47923 steps/s (collection: 1.898s, learning 0.153s)
             Mean action noise std: 1.36
          Mean value_function loss: 25.0071
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.9567
                       Mean reward: 47.22
               Mean episode length: 214.11
    Episode_Reward/reaching_object: 0.3623
    Episode_Reward/rotating_object: 8.0365
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 10.2500
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.05s
                      Time elapsed: 00:04:57
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 45582 steps/s (collection: 2.055s, learning 0.102s)
             Mean action noise std: 1.36
          Mean value_function loss: 26.9600
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 30.9960
                       Mean reward: 51.55
               Mean episode length: 213.96
    Episode_Reward/reaching_object: 0.3621
    Episode_Reward/rotating_object: 9.7747
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 8.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.16s
                      Time elapsed: 00:04:59
                               ETA: 00:52:13

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 46668 steps/s (collection: 1.948s, learning 0.159s)
             Mean action noise std: 1.36
          Mean value_function loss: 26.1083
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 31.0302
                       Mean reward: 44.31
               Mean episode length: 196.32
    Episode_Reward/reaching_object: 0.3653
    Episode_Reward/rotating_object: 9.7530
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 9.7500
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.11s
                      Time elapsed: 00:05:01
                               ETA: 00:52:08

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 48632 steps/s (collection: 1.906s, learning 0.115s)
             Mean action noise std: 1.36
          Mean value_function loss: 27.9414
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 31.0599
                       Mean reward: 53.37
               Mean episode length: 208.43
    Episode_Reward/reaching_object: 0.3700
    Episode_Reward/rotating_object: 8.6733
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 10.5417
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 10.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.02s
                      Time elapsed: 00:05:03
                               ETA: 00:52:03

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 48474 steps/s (collection: 1.904s, learning 0.124s)
             Mean action noise std: 1.36
          Mean value_function loss: 26.7724
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 31.0859
                       Mean reward: 50.52
               Mean episode length: 205.41
    Episode_Reward/reaching_object: 0.3775
    Episode_Reward/rotating_object: 10.0055
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 10.2500
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.03s
                      Time elapsed: 00:05:05
                               ETA: 00:51:58

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 49992 steps/s (collection: 1.874s, learning 0.093s)
             Mean action noise std: 1.37
          Mean value_function loss: 28.9301
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 31.1039
                       Mean reward: 48.02
               Mean episode length: 203.84
    Episode_Reward/reaching_object: 0.3704
    Episode_Reward/rotating_object: 8.5620
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 9.5833
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.97s
                      Time elapsed: 00:05:07
                               ETA: 00:51:53

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 48956 steps/s (collection: 1.905s, learning 0.103s)
             Mean action noise std: 1.37
          Mean value_function loss: 27.8596
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 31.1200
                       Mean reward: 56.01
               Mean episode length: 216.28
    Episode_Reward/reaching_object: 0.3820
    Episode_Reward/rotating_object: 9.2608
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 9.7500
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.01s
                      Time elapsed: 00:05:09
                               ETA: 00:51:48

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 49179 steps/s (collection: 1.907s, learning 0.092s)
             Mean action noise std: 1.37
          Mean value_function loss: 35.7641
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 31.1412
                       Mean reward: 71.81
               Mean episode length: 220.35
    Episode_Reward/reaching_object: 0.3885
    Episode_Reward/rotating_object: 12.2558
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 10.3333
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.00s
                      Time elapsed: 00:05:11
                               ETA: 00:51:43

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 49034 steps/s (collection: 1.908s, learning 0.097s)
             Mean action noise std: 1.37
          Mean value_function loss: 42.9027
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 31.1652
                       Mean reward: 49.32
               Mean episode length: 209.19
    Episode_Reward/reaching_object: 0.3763
    Episode_Reward/rotating_object: 11.0697
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 9.7917
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.00s
                      Time elapsed: 00:05:13
                               ETA: 00:51:38

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 49699 steps/s (collection: 1.876s, learning 0.102s)
             Mean action noise std: 1.37
          Mean value_function loss: 42.6613
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 31.1822
                       Mean reward: 53.60
               Mean episode length: 213.30
    Episode_Reward/reaching_object: 0.3779
    Episode_Reward/rotating_object: 10.2708
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 9.9167
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.98s
                      Time elapsed: 00:05:15
                               ETA: 00:51:33

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 49690 steps/s (collection: 1.875s, learning 0.104s)
             Mean action noise std: 1.37
          Mean value_function loss: 35.8051
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 31.1987
                       Mean reward: 42.53
               Mean episode length: 214.80
    Episode_Reward/reaching_object: 0.3540
    Episode_Reward/rotating_object: 8.5511
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 9.2917
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.98s
                      Time elapsed: 00:05:17
                               ETA: 00:51:28

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 49059 steps/s (collection: 1.868s, learning 0.136s)
             Mean action noise std: 1.38
          Mean value_function loss: 35.4261
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 31.2278
                       Mean reward: 38.70
               Mean episode length: 208.47
    Episode_Reward/reaching_object: 0.3770
    Episode_Reward/rotating_object: 10.4475
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 10.4583
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 9.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.00s
                      Time elapsed: 00:05:19
                               ETA: 00:51:23

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 49123 steps/s (collection: 1.907s, learning 0.095s)
             Mean action noise std: 1.38
          Mean value_function loss: 35.3229
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 31.2603
                       Mean reward: 51.76
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 0.3949
    Episode_Reward/rotating_object: 10.2971
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.00s
                      Time elapsed: 00:05:21
                               ETA: 00:51:18

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 47848 steps/s (collection: 1.928s, learning 0.127s)
             Mean action noise std: 1.38
          Mean value_function loss: 38.1470
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 31.2914
                       Mean reward: 67.77
               Mean episode length: 221.73
    Episode_Reward/reaching_object: 0.3782
    Episode_Reward/rotating_object: 10.3724
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 7.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.05s
                      Time elapsed: 00:05:23
                               ETA: 00:51:14

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 47266 steps/s (collection: 1.968s, learning 0.112s)
             Mean action noise std: 1.38
          Mean value_function loss: 34.0343
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 31.3005
                       Mean reward: 67.71
               Mean episode length: 216.32
    Episode_Reward/reaching_object: 0.4009
    Episode_Reward/rotating_object: 12.8381
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 11.1667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.08s
                      Time elapsed: 00:05:25
                               ETA: 00:51:10

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 49291 steps/s (collection: 1.888s, learning 0.107s)
             Mean action noise std: 1.38
          Mean value_function loss: 36.7939
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 31.3130
                       Mean reward: 46.49
               Mean episode length: 215.18
    Episode_Reward/reaching_object: 0.3916
    Episode_Reward/rotating_object: 11.2703
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.99s
                      Time elapsed: 00:05:27
                               ETA: 00:51:05

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 45510 steps/s (collection: 1.997s, learning 0.163s)
             Mean action noise std: 1.38
          Mean value_function loss: 36.8267
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 31.3311
                       Mean reward: 63.49
               Mean episode length: 218.82
    Episode_Reward/reaching_object: 0.3840
    Episode_Reward/rotating_object: 10.8425
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 10.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.16s
                      Time elapsed: 00:05:29
                               ETA: 00:51:02

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 49254 steps/s (collection: 1.901s, learning 0.095s)
             Mean action noise std: 1.38
          Mean value_function loss: 34.2497
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 31.3466
                       Mean reward: 83.33
               Mean episode length: 225.49
    Episode_Reward/reaching_object: 0.4279
    Episode_Reward/rotating_object: 14.7978
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 10.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.00s
                      Time elapsed: 00:05:31
                               ETA: 00:50:57

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 48805 steps/s (collection: 1.902s, learning 0.112s)
             Mean action noise std: 1.39
          Mean value_function loss: 38.2203
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 31.3640
                       Mean reward: 72.23
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 0.3947
    Episode_Reward/rotating_object: 13.9485
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 11.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.01s
                      Time elapsed: 00:05:33
                               ETA: 00:50:53

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 48929 steps/s (collection: 1.877s, learning 0.132s)
             Mean action noise std: 1.39
          Mean value_function loss: 40.2478
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 31.3847
                       Mean reward: 65.38
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 0.4105
    Episode_Reward/rotating_object: 13.8300
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 10.4583
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.01s
                      Time elapsed: 00:05:35
                               ETA: 00:50:48

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 49259 steps/s (collection: 1.905s, learning 0.091s)
             Mean action noise std: 1.39
          Mean value_function loss: 36.1392
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 31.4086
                       Mean reward: 63.17
               Mean episode length: 208.50
    Episode_Reward/reaching_object: 0.4066
    Episode_Reward/rotating_object: 13.2694
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 10.8333
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.00s
                      Time elapsed: 00:05:37
                               ETA: 00:50:44

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 46257 steps/s (collection: 1.959s, learning 0.167s)
             Mean action noise std: 1.39
          Mean value_function loss: 37.6690
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.4274
                       Mean reward: 99.11
               Mean episode length: 226.30
    Episode_Reward/reaching_object: 0.3981
    Episode_Reward/rotating_object: 13.6845
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.13s
                      Time elapsed: 00:05:40
                               ETA: 00:50:40

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 46617 steps/s (collection: 2.007s, learning 0.102s)
             Mean action noise std: 1.39
          Mean value_function loss: 43.2426
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 31.4428
                       Mean reward: 78.67
               Mean episode length: 224.65
    Episode_Reward/reaching_object: 0.4204
    Episode_Reward/rotating_object: 14.3709
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.11s
                      Time elapsed: 00:05:42
                               ETA: 00:50:37

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 48733 steps/s (collection: 1.848s, learning 0.170s)
             Mean action noise std: 1.39
          Mean value_function loss: 34.3143
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 31.4455
                       Mean reward: 88.07
               Mean episode length: 224.52
    Episode_Reward/reaching_object: 0.4241
    Episode_Reward/rotating_object: 15.2165
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.02s
                      Time elapsed: 00:05:44
                               ETA: 00:50:32

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 45837 steps/s (collection: 2.019s, learning 0.126s)
             Mean action noise std: 1.39
          Mean value_function loss: 31.7984
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 31.4611
                       Mean reward: 79.60
               Mean episode length: 227.04
    Episode_Reward/reaching_object: 0.4105
    Episode_Reward/rotating_object: 13.9932
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.14s
                      Time elapsed: 00:05:46
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 49101 steps/s (collection: 1.901s, learning 0.101s)
             Mean action noise std: 1.40
          Mean value_function loss: 36.4387
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 31.4853
                       Mean reward: 74.53
               Mean episode length: 220.37
    Episode_Reward/reaching_object: 0.4084
    Episode_Reward/rotating_object: 14.6865
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 10.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.00s
                      Time elapsed: 00:05:48
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 42947 steps/s (collection: 2.177s, learning 0.112s)
             Mean action noise std: 1.40
          Mean value_function loss: 38.9426
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 31.4941
                       Mean reward: 74.65
               Mean episode length: 220.37
    Episode_Reward/reaching_object: 0.4000
    Episode_Reward/rotating_object: 12.8897
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.29s
                      Time elapsed: 00:05:50
                               ETA: 00:50:23

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 48848 steps/s (collection: 1.890s, learning 0.122s)
             Mean action noise std: 1.40
          Mean value_function loss: 42.9636
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.5021
                       Mean reward: 88.24
               Mean episode length: 229.93
    Episode_Reward/reaching_object: 0.4219
    Episode_Reward/rotating_object: 16.4652
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.01s
                      Time elapsed: 00:05:52
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 47655 steps/s (collection: 1.897s, learning 0.166s)
             Mean action noise std: 1.40
          Mean value_function loss: 44.0498
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 31.5210
                       Mean reward: 87.91
               Mean episode length: 217.61
    Episode_Reward/reaching_object: 0.4236
    Episode_Reward/rotating_object: 16.0000
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.06s
                      Time elapsed: 00:05:54
                               ETA: 00:50:15

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 47567 steps/s (collection: 1.910s, learning 0.157s)
             Mean action noise std: 1.40
          Mean value_function loss: 39.1636
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 31.5408
                       Mean reward: 65.62
               Mean episode length: 225.85
    Episode_Reward/reaching_object: 0.4153
    Episode_Reward/rotating_object: 14.7709
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.07s
                      Time elapsed: 00:05:56
                               ETA: 00:50:11

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 48975 steps/s (collection: 1.885s, learning 0.122s)
             Mean action noise std: 1.40
          Mean value_function loss: 39.4943
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.5567
                       Mean reward: 85.01
               Mean episode length: 227.75
    Episode_Reward/reaching_object: 0.4225
    Episode_Reward/rotating_object: 16.2443
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.01s
                      Time elapsed: 00:05:58
                               ETA: 00:50:07

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 46262 steps/s (collection: 2.004s, learning 0.121s)
             Mean action noise std: 1.40
          Mean value_function loss: 47.5600
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 31.5732
                       Mean reward: 74.37
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 0.4386
    Episode_Reward/rotating_object: 16.9508
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.12s
                      Time elapsed: 00:06:00
                               ETA: 00:50:04

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 48677 steps/s (collection: 1.923s, learning 0.096s)
             Mean action noise std: 1.40
          Mean value_function loss: 38.1456
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 31.5811
                       Mean reward: 92.00
               Mean episode length: 226.21
    Episode_Reward/reaching_object: 0.4419
    Episode_Reward/rotating_object: 17.4233
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.02s
                      Time elapsed: 00:06:02
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 48299 steps/s (collection: 1.922s, learning 0.113s)
             Mean action noise std: 1.40
          Mean value_function loss: 46.3760
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 31.5913
                       Mean reward: 102.91
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 0.4483
    Episode_Reward/rotating_object: 18.0710
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.04s
                      Time elapsed: 00:06:04
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 48725 steps/s (collection: 1.897s, learning 0.121s)
             Mean action noise std: 1.40
          Mean value_function loss: 38.1720
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 31.6019
                       Mean reward: 75.32
               Mean episode length: 219.43
    Episode_Reward/reaching_object: 0.4279
    Episode_Reward/rotating_object: 16.0094
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.02s
                      Time elapsed: 00:06:07
                               ETA: 00:49:52

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 47157 steps/s (collection: 1.953s, learning 0.132s)
             Mean action noise std: 1.41
          Mean value_function loss: 41.2822
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.6161
                       Mean reward: 104.49
               Mean episode length: 221.98
    Episode_Reward/reaching_object: 0.4422
    Episode_Reward/rotating_object: 18.7146
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.08s
                      Time elapsed: 00:06:09
                               ETA: 00:49:48

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 49503 steps/s (collection: 1.874s, learning 0.112s)
             Mean action noise std: 1.41
          Mean value_function loss: 49.0706
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 31.6269
                       Mean reward: 82.71
               Mean episode length: 217.94
    Episode_Reward/reaching_object: 0.4286
    Episode_Reward/rotating_object: 16.3405
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.99s
                      Time elapsed: 00:06:11
                               ETA: 00:49:44

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 49974 steps/s (collection: 1.873s, learning 0.095s)
             Mean action noise std: 1.41
          Mean value_function loss: 57.0124
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 31.6378
                       Mean reward: 80.70
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 0.4460
    Episode_Reward/rotating_object: 17.1055
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.97s
                      Time elapsed: 00:06:13
                               ETA: 00:49:39

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 46131 steps/s (collection: 1.945s, learning 0.186s)
             Mean action noise std: 1.41
          Mean value_function loss: 47.4148
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 31.6437
                       Mean reward: 83.44
               Mean episode length: 216.43
    Episode_Reward/reaching_object: 0.4373
    Episode_Reward/rotating_object: 17.7780
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.13s
                      Time elapsed: 00:06:15
                               ETA: 00:49:36

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 45787 steps/s (collection: 2.037s, learning 0.110s)
             Mean action noise std: 1.41
          Mean value_function loss: 46.2771
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 31.6615
                       Mean reward: 74.12
               Mean episode length: 219.92
    Episode_Reward/reaching_object: 0.4416
    Episode_Reward/rotating_object: 16.8832
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.15s
                      Time elapsed: 00:06:17
                               ETA: 00:49:33

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 48536 steps/s (collection: 1.918s, learning 0.107s)
             Mean action noise std: 1.41
          Mean value_function loss: 45.3936
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 31.6843
                       Mean reward: 81.31
               Mean episode length: 218.73
    Episode_Reward/reaching_object: 0.4477
    Episode_Reward/rotating_object: 20.2519
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.03s
                      Time elapsed: 00:06:19
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 49343 steps/s (collection: 1.901s, learning 0.092s)
             Mean action noise std: 1.41
          Mean value_function loss: 55.8652
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.7086
                       Mean reward: 69.19
               Mean episode length: 215.20
    Episode_Reward/reaching_object: 0.4260
    Episode_Reward/rotating_object: 17.3647
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 11.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.99s
                      Time elapsed: 00:06:21
                               ETA: 00:49:26

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 48313 steps/s (collection: 1.936s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 60.0016
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 31.7338
                       Mean reward: 80.97
               Mean episode length: 218.61
    Episode_Reward/reaching_object: 0.4416
    Episode_Reward/rotating_object: 19.4398
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.03s
                      Time elapsed: 00:06:23
                               ETA: 00:49:22

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 46388 steps/s (collection: 1.999s, learning 0.121s)
             Mean action noise std: 1.42
          Mean value_function loss: 59.8386
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.7554
                       Mean reward: 95.59
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 0.4481
    Episode_Reward/rotating_object: 18.7028
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.12s
                      Time elapsed: 00:06:25
                               ETA: 00:49:19

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 48364 steps/s (collection: 1.930s, learning 0.103s)
             Mean action noise std: 1.42
          Mean value_function loss: 53.0416
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.7742
                       Mean reward: 109.83
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 0.4565
    Episode_Reward/rotating_object: 20.9456
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.03s
                      Time elapsed: 00:06:27
                               ETA: 00:49:15

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 46834 steps/s (collection: 1.971s, learning 0.128s)
             Mean action noise std: 1.42
          Mean value_function loss: 66.1929
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.7962
                       Mean reward: 114.58
               Mean episode length: 218.27
    Episode_Reward/reaching_object: 0.4575
    Episode_Reward/rotating_object: 20.8498
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.10s
                      Time elapsed: 00:06:29
                               ETA: 00:49:12

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 46891 steps/s (collection: 1.938s, learning 0.159s)
             Mean action noise std: 1.42
          Mean value_function loss: 60.9273
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.8105
                       Mean reward: 76.48
               Mean episode length: 214.21
    Episode_Reward/reaching_object: 0.4372
    Episode_Reward/rotating_object: 18.3015
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.10s
                      Time elapsed: 00:06:31
                               ETA: 00:49:09

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 48463 steps/s (collection: 1.928s, learning 0.100s)
             Mean action noise std: 1.42
          Mean value_function loss: 55.1503
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.8256
                       Mean reward: 77.72
               Mean episode length: 209.33
    Episode_Reward/reaching_object: 0.4237
    Episode_Reward/rotating_object: 17.8732
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.03s
                      Time elapsed: 00:06:33
                               ETA: 00:49:05

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 47072 steps/s (collection: 1.943s, learning 0.145s)
             Mean action noise std: 1.42
          Mean value_function loss: 58.0285
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.8420
                       Mean reward: 106.99
               Mean episode length: 222.42
    Episode_Reward/reaching_object: 0.4582
    Episode_Reward/rotating_object: 22.0034
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 11.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.09s
                      Time elapsed: 00:06:35
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 47502 steps/s (collection: 1.907s, learning 0.162s)
             Mean action noise std: 1.43
          Mean value_function loss: 60.5180
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.8614
                       Mean reward: 106.02
               Mean episode length: 228.01
    Episode_Reward/reaching_object: 0.4333
    Episode_Reward/rotating_object: 20.8312
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.07s
                      Time elapsed: 00:06:37
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 45462 steps/s (collection: 1.987s, learning 0.176s)
             Mean action noise std: 1.43
          Mean value_function loss: 60.0583
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.8816
                       Mean reward: 94.50
               Mean episode length: 219.31
    Episode_Reward/reaching_object: 0.4428
    Episode_Reward/rotating_object: 21.8059
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.16s
                      Time elapsed: 00:06:40
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 47564 steps/s (collection: 1.957s, learning 0.110s)
             Mean action noise std: 1.43
          Mean value_function loss: 57.9614
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.8953
                       Mean reward: 126.32
               Mean episode length: 224.34
    Episode_Reward/reaching_object: 0.4215
    Episode_Reward/rotating_object: 20.6597
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.07s
                      Time elapsed: 00:06:42
                               ETA: 00:48:52

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 49099 steps/s (collection: 1.889s, learning 0.114s)
             Mean action noise std: 1.43
          Mean value_function loss: 55.4845
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.9091
                       Mean reward: 128.08
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 0.4430
    Episode_Reward/rotating_object: 24.8193
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.00s
                      Time elapsed: 00:06:44
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 44811 steps/s (collection: 2.079s, learning 0.115s)
             Mean action noise std: 1.43
          Mean value_function loss: 58.7966
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 31.9174
                       Mean reward: 127.85
               Mean episode length: 225.21
    Episode_Reward/reaching_object: 0.4539
    Episode_Reward/rotating_object: 23.4947
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.19s
                      Time elapsed: 00:06:46
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 47960 steps/s (collection: 1.930s, learning 0.120s)
             Mean action noise std: 1.43
          Mean value_function loss: 61.0635
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 31.9210
                       Mean reward: 104.99
               Mean episode length: 216.16
    Episode_Reward/reaching_object: 0.4337
    Episode_Reward/rotating_object: 21.6159
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.05s
                      Time elapsed: 00:06:48
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 48478 steps/s (collection: 1.916s, learning 0.112s)
             Mean action noise std: 1.43
          Mean value_function loss: 55.9256
               Mean surrogate loss: 0.0037
                 Mean entropy loss: 31.9241
                       Mean reward: 128.61
               Mean episode length: 222.66
    Episode_Reward/reaching_object: 0.4653
    Episode_Reward/rotating_object: 24.7423
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.03s
                      Time elapsed: 00:06:50
                               ETA: 00:48:39

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 48823 steps/s (collection: 1.920s, learning 0.093s)
             Mean action noise std: 1.43
          Mean value_function loss: 58.1483
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 31.9285
                       Mean reward: 116.72
               Mean episode length: 223.81
    Episode_Reward/reaching_object: 0.4420
    Episode_Reward/rotating_object: 21.6769
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.01s
                      Time elapsed: 00:06:52
                               ETA: 00:48:35

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 49547 steps/s (collection: 1.884s, learning 0.100s)
             Mean action noise std: 1.43
          Mean value_function loss: 56.4334
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.9467
                       Mean reward: 133.27
               Mean episode length: 227.99
    Episode_Reward/reaching_object: 0.4691
    Episode_Reward/rotating_object: 25.8232
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.98s
                      Time elapsed: 00:06:54
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 48889 steps/s (collection: 1.915s, learning 0.096s)
             Mean action noise std: 1.44
          Mean value_function loss: 63.5229
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 31.9746
                       Mean reward: 129.06
               Mean episode length: 216.96
    Episode_Reward/reaching_object: 0.4481
    Episode_Reward/rotating_object: 24.6807
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.01s
                      Time elapsed: 00:06:56
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 49609 steps/s (collection: 1.880s, learning 0.102s)
             Mean action noise std: 1.44
          Mean value_function loss: 64.5376
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 31.9894
                       Mean reward: 126.18
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 0.4442
    Episode_Reward/rotating_object: 24.1978
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.98s
                      Time elapsed: 00:06:58
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 49326 steps/s (collection: 1.884s, learning 0.109s)
             Mean action noise std: 1.44
          Mean value_function loss: 62.3116
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.0064
                       Mean reward: 111.43
               Mean episode length: 217.37
    Episode_Reward/reaching_object: 0.4540
    Episode_Reward/rotating_object: 23.0381
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.99s
                      Time elapsed: 00:07:00
                               ETA: 00:48:20

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 47491 steps/s (collection: 1.954s, learning 0.116s)
             Mean action noise std: 1.44
          Mean value_function loss: 75.5418
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.0191
                       Mean reward: 142.56
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 0.4640
    Episode_Reward/rotating_object: 26.5607
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.07s
                      Time elapsed: 00:07:02
                               ETA: 00:48:17

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 49468 steps/s (collection: 1.870s, learning 0.117s)
             Mean action noise std: 1.44
          Mean value_function loss: 72.4821
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.0297
                       Mean reward: 130.47
               Mean episode length: 225.63
    Episode_Reward/reaching_object: 0.4422
    Episode_Reward/rotating_object: 24.8138
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.99s
                      Time elapsed: 00:07:04
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 44785 steps/s (collection: 2.086s, learning 0.109s)
             Mean action noise std: 1.44
          Mean value_function loss: 63.9732
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.0421
                       Mean reward: 110.96
               Mean episode length: 222.32
    Episode_Reward/reaching_object: 0.4451
    Episode_Reward/rotating_object: 23.1483
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.19s
                      Time elapsed: 00:07:06
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 49461 steps/s (collection: 1.892s, learning 0.095s)
             Mean action noise std: 1.44
          Mean value_function loss: 64.7907
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 32.0569
                       Mean reward: 131.45
               Mean episode length: 223.86
    Episode_Reward/reaching_object: 0.4520
    Episode_Reward/rotating_object: 23.8024
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.99s
                      Time elapsed: 00:07:08
                               ETA: 00:48:07

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 49604 steps/s (collection: 1.877s, learning 0.105s)
             Mean action noise std: 1.44
          Mean value_function loss: 78.7901
               Mean surrogate loss: 0.0071
                 Mean entropy loss: 32.0725
                       Mean reward: 150.28
               Mean episode length: 223.84
    Episode_Reward/reaching_object: 0.4692
    Episode_Reward/rotating_object: 27.8223
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.98s
                      Time elapsed: 00:07:10
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 49594 steps/s (collection: 1.873s, learning 0.110s)
             Mean action noise std: 1.44
          Mean value_function loss: 59.7445
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 32.0800
                       Mean reward: 125.25
               Mean episode length: 225.13
    Episode_Reward/reaching_object: 0.4633
    Episode_Reward/rotating_object: 25.4571
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.98s
                      Time elapsed: 00:07:12
                               ETA: 00:48:00

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 48432 steps/s (collection: 1.918s, learning 0.112s)
             Mean action noise std: 1.44
          Mean value_function loss: 65.4690
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.0925
                       Mean reward: 144.50
               Mean episode length: 232.48
    Episode_Reward/reaching_object: 0.4617
    Episode_Reward/rotating_object: 26.4453
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.03s
                      Time elapsed: 00:07:14
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 47874 steps/s (collection: 1.944s, learning 0.110s)
             Mean action noise std: 1.45
          Mean value_function loss: 68.0538
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.1032
                       Mean reward: 155.65
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 0.4643
    Episode_Reward/rotating_object: 25.7310
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.05s
                      Time elapsed: 00:07:16
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 49087 steps/s (collection: 1.909s, learning 0.094s)
             Mean action noise std: 1.45
          Mean value_function loss: 80.5231
               Mean surrogate loss: 0.0042
                 Mean entropy loss: 32.1138
                       Mean reward: 112.37
               Mean episode length: 213.57
    Episode_Reward/reaching_object: 0.4600
    Episode_Reward/rotating_object: 28.4791
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.00s
                      Time elapsed: 00:07:18
                               ETA: 00:47:50

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 48195 steps/s (collection: 1.933s, learning 0.107s)
             Mean action noise std: 1.45
          Mean value_function loss: 82.2741
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.1192
                       Mean reward: 115.18
               Mean episode length: 220.21
    Episode_Reward/reaching_object: 0.4575
    Episode_Reward/rotating_object: 26.6153
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.04s
                      Time elapsed: 00:07:20
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 50040 steps/s (collection: 1.872s, learning 0.093s)
             Mean action noise std: 1.45
          Mean value_function loss: 72.2551
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 32.1327
                       Mean reward: 138.49
               Mean episode length: 219.91
    Episode_Reward/reaching_object: 0.4551
    Episode_Reward/rotating_object: 28.0793
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.96s
                      Time elapsed: 00:07:22
                               ETA: 00:47:43

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 46471 steps/s (collection: 1.997s, learning 0.119s)
             Mean action noise std: 1.45
          Mean value_function loss: 80.5131
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.1468
                       Mean reward: 116.27
               Mean episode length: 223.85
    Episode_Reward/reaching_object: 0.4582
    Episode_Reward/rotating_object: 27.3410
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.12s
                      Time elapsed: 00:07:24
                               ETA: 00:47:40

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 48314 steps/s (collection: 1.935s, learning 0.100s)
             Mean action noise std: 1.45
          Mean value_function loss: 77.9872
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 32.1645
                       Mean reward: 102.34
               Mean episode length: 219.79
    Episode_Reward/reaching_object: 0.4755
    Episode_Reward/rotating_object: 29.4832
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.03s
                      Time elapsed: 00:07:26
                               ETA: 00:47:37

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 47756 steps/s (collection: 1.943s, learning 0.116s)
             Mean action noise std: 1.45
          Mean value_function loss: 78.6425
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 32.1849
                       Mean reward: 151.56
               Mean episode length: 227.19
    Episode_Reward/reaching_object: 0.4738
    Episode_Reward/rotating_object: 29.1549
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.06s
                      Time elapsed: 00:07:28
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 47567 steps/s (collection: 1.911s, learning 0.156s)
             Mean action noise std: 1.45
          Mean value_function loss: 85.3599
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 32.2081
                       Mean reward: 120.38
               Mean episode length: 208.99
    Episode_Reward/reaching_object: 0.4420
    Episode_Reward/rotating_object: 27.3390
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.07s
                      Time elapsed: 00:07:30
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 47636 steps/s (collection: 1.965s, learning 0.099s)
             Mean action noise std: 1.46
          Mean value_function loss: 79.9270
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 32.2209
                       Mean reward: 142.27
               Mean episode length: 214.65
    Episode_Reward/reaching_object: 0.4578
    Episode_Reward/rotating_object: 28.0967
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.06s
                      Time elapsed: 00:07:33
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 48255 steps/s (collection: 1.923s, learning 0.114s)
             Mean action noise std: 1.46
          Mean value_function loss: 75.9435
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 32.2311
                       Mean reward: 113.15
               Mean episode length: 208.71
    Episode_Reward/reaching_object: 0.4554
    Episode_Reward/rotating_object: 25.8766
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.04s
                      Time elapsed: 00:07:35
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 49411 steps/s (collection: 1.887s, learning 0.103s)
             Mean action noise std: 1.46
          Mean value_function loss: 71.2500
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.2453
                       Mean reward: 130.91
               Mean episode length: 223.15
    Episode_Reward/reaching_object: 0.4505
    Episode_Reward/rotating_object: 27.0257
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.99s
                      Time elapsed: 00:07:37
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 49637 steps/s (collection: 1.880s, learning 0.101s)
             Mean action noise std: 1.46
          Mean value_function loss: 73.4483
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.2704
                       Mean reward: 140.87
               Mean episode length: 215.37
    Episode_Reward/reaching_object: 0.4541
    Episode_Reward/rotating_object: 24.5156
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 10.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.98s
                      Time elapsed: 00:07:39
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 46665 steps/s (collection: 1.970s, learning 0.137s)
             Mean action noise std: 1.46
          Mean value_function loss: 80.8137
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 32.2918
                       Mean reward: 123.57
               Mean episode length: 204.80
    Episode_Reward/reaching_object: 0.4492
    Episode_Reward/rotating_object: 29.9358
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.11s
                      Time elapsed: 00:07:41
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 45230 steps/s (collection: 2.026s, learning 0.147s)
             Mean action noise std: 1.46
          Mean value_function loss: 88.8711
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 32.3032
                       Mean reward: 154.34
               Mean episode length: 218.68
    Episode_Reward/reaching_object: 0.4645
    Episode_Reward/rotating_object: 29.4311
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.17s
                      Time elapsed: 00:07:43
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 47724 steps/s (collection: 1.952s, learning 0.108s)
             Mean action noise std: 1.46
          Mean value_function loss: 84.2388
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 32.3204
                       Mean reward: 146.86
               Mean episode length: 216.27
    Episode_Reward/reaching_object: 0.4590
    Episode_Reward/rotating_object: 29.6292
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.06s
                      Time elapsed: 00:07:45
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 47546 steps/s (collection: 1.950s, learning 0.117s)
             Mean action noise std: 1.47
          Mean value_function loss: 76.7452
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 32.3363
                       Mean reward: 195.22
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 0.4445
    Episode_Reward/rotating_object: 28.5930
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.07s
                      Time elapsed: 00:07:47
                               ETA: 00:47:06

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 48052 steps/s (collection: 1.911s, learning 0.135s)
             Mean action noise std: 1.47
          Mean value_function loss: 77.4171
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 32.3554
                       Mean reward: 154.44
               Mean episode length: 213.93
    Episode_Reward/reaching_object: 0.4632
    Episode_Reward/rotating_object: 32.4256
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 11.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.05s
                      Time elapsed: 00:07:49
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 47164 steps/s (collection: 1.940s, learning 0.144s)
             Mean action noise std: 1.47
          Mean value_function loss: 77.5531
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 32.3686
                       Mean reward: 157.84
               Mean episode length: 214.91
    Episode_Reward/reaching_object: 0.4553
    Episode_Reward/rotating_object: 28.4648
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.08s
                      Time elapsed: 00:07:51
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 46744 steps/s (collection: 2.009s, learning 0.094s)
             Mean action noise std: 1.47
          Mean value_function loss: 78.4504
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 32.3802
                       Mean reward: 149.77
               Mean episode length: 223.03
    Episode_Reward/reaching_object: 0.4713
    Episode_Reward/rotating_object: 33.2686
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.10s
                      Time elapsed: 00:07:53
                               ETA: 00:46:57

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 48439 steps/s (collection: 1.923s, learning 0.106s)
             Mean action noise std: 1.47
          Mean value_function loss: 69.4502
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 32.3916
                       Mean reward: 140.05
               Mean episode length: 216.22
    Episode_Reward/reaching_object: 0.4597
    Episode_Reward/rotating_object: 31.0472
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 11.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.03s
                      Time elapsed: 00:07:55
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 46950 steps/s (collection: 1.994s, learning 0.100s)
             Mean action noise std: 1.47
          Mean value_function loss: 71.8151
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 32.4047
                       Mean reward: 146.65
               Mean episode length: 211.23
    Episode_Reward/reaching_object: 0.4506
    Episode_Reward/rotating_object: 31.8375
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.09s
                      Time elapsed: 00:07:57
                               ETA: 00:46:52

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 48456 steps/s (collection: 1.911s, learning 0.118s)
             Mean action noise std: 1.47
          Mean value_function loss: 74.9156
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 32.4201
                       Mean reward: 144.47
               Mean episode length: 213.29
    Episode_Reward/reaching_object: 0.4543
    Episode_Reward/rotating_object: 30.2332
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.03s
                      Time elapsed: 00:07:59
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 48085 steps/s (collection: 1.941s, learning 0.103s)
             Mean action noise std: 1.47
          Mean value_function loss: 82.6224
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 32.4290
                       Mean reward: 161.33
               Mean episode length: 216.17
    Episode_Reward/reaching_object: 0.4598
    Episode_Reward/rotating_object: 31.4263
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.04s
                      Time elapsed: 00:08:01
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 49375 steps/s (collection: 1.879s, learning 0.112s)
             Mean action noise std: 1.47
          Mean value_function loss: 79.9154
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 32.4425
                       Mean reward: 120.02
               Mean episode length: 217.31
    Episode_Reward/reaching_object: 0.4459
    Episode_Reward/rotating_object: 30.2927
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 1.99s
                      Time elapsed: 00:08:03
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 47930 steps/s (collection: 1.950s, learning 0.101s)
             Mean action noise std: 1.48
          Mean value_function loss: 77.6157
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 32.4517
                       Mean reward: 169.33
               Mean episode length: 219.63
    Episode_Reward/reaching_object: 0.4544
    Episode_Reward/rotating_object: 30.9400
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.05s
                      Time elapsed: 00:08:05
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 49144 steps/s (collection: 1.879s, learning 0.121s)
             Mean action noise std: 1.48
          Mean value_function loss: 74.9891
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.4634
                       Mean reward: 154.71
               Mean episode length: 215.96
    Episode_Reward/reaching_object: 0.4634
    Episode_Reward/rotating_object: 31.9471
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.00s
                      Time elapsed: 00:08:07
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 49388 steps/s (collection: 1.900s, learning 0.090s)
             Mean action noise std: 1.48
          Mean value_function loss: 76.2664
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.4799
                       Mean reward: 176.50
               Mean episode length: 220.27
    Episode_Reward/reaching_object: 0.4651
    Episode_Reward/rotating_object: 35.6349
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 1.99s
                      Time elapsed: 00:08:09
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 48287 steps/s (collection: 1.925s, learning 0.111s)
             Mean action noise std: 1.48
          Mean value_function loss: 77.0464
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 32.4963
                       Mean reward: 152.00
               Mean episode length: 211.86
    Episode_Reward/reaching_object: 0.4383
    Episode_Reward/rotating_object: 30.0095
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.04s
                      Time elapsed: 00:08:11
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 49466 steps/s (collection: 1.891s, learning 0.096s)
             Mean action noise std: 1.48
          Mean value_function loss: 75.9676
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.5102
                       Mean reward: 158.06
               Mean episode length: 211.88
    Episode_Reward/reaching_object: 0.4732
    Episode_Reward/rotating_object: 33.9902
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.99s
                      Time elapsed: 00:08:13
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 48827 steps/s (collection: 1.903s, learning 0.111s)
             Mean action noise std: 1.48
          Mean value_function loss: 90.4579
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 32.5267
                       Mean reward: 199.45
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 0.4695
    Episode_Reward/rotating_object: 37.5267
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.01s
                      Time elapsed: 00:08:15
                               ETA: 00:46:23

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 49468 steps/s (collection: 1.886s, learning 0.101s)
             Mean action noise std: 1.48
          Mean value_function loss: 82.3994
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.5372
                       Mean reward: 182.71
               Mean episode length: 214.71
    Episode_Reward/reaching_object: 0.4515
    Episode_Reward/rotating_object: 36.0131
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.99s
                      Time elapsed: 00:08:17
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 49288 steps/s (collection: 1.902s, learning 0.092s)
             Mean action noise std: 1.48
          Mean value_function loss: 86.7048
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 32.5550
                       Mean reward: 201.18
               Mean episode length: 210.17
    Episode_Reward/reaching_object: 0.4568
    Episode_Reward/rotating_object: 36.5443
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.99s
                      Time elapsed: 00:08:19
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 47925 steps/s (collection: 1.957s, learning 0.094s)
             Mean action noise std: 1.49
          Mean value_function loss: 81.7430
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 32.5716
                       Mean reward: 184.15
               Mean episode length: 212.10
    Episode_Reward/reaching_object: 0.4527
    Episode_Reward/rotating_object: 36.8852
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 10.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.05s
                      Time elapsed: 00:08:21
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 46308 steps/s (collection: 2.014s, learning 0.109s)
             Mean action noise std: 1.49
          Mean value_function loss: 67.0198
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 32.5883
                       Mean reward: 168.86
               Mean episode length: 218.46
    Episode_Reward/reaching_object: 0.4544
    Episode_Reward/rotating_object: 33.7924
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.12s
                      Time elapsed: 00:08:24
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 48066 steps/s (collection: 1.940s, learning 0.105s)
             Mean action noise std: 1.49
          Mean value_function loss: 61.0416
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 32.5956
                       Mean reward: 180.52
               Mean episode length: 211.58
    Episode_Reward/reaching_object: 0.4497
    Episode_Reward/rotating_object: 36.5480
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.05s
                      Time elapsed: 00:08:26
                               ETA: 00:46:08

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 48046 steps/s (collection: 1.947s, learning 0.099s)
             Mean action noise std: 1.49
          Mean value_function loss: 62.7069
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 32.6027
                       Mean reward: 210.92
               Mean episode length: 223.97
    Episode_Reward/reaching_object: 0.4569
    Episode_Reward/rotating_object: 36.7075
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.05s
                      Time elapsed: 00:08:28
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 49814 steps/s (collection: 1.868s, learning 0.106s)
             Mean action noise std: 1.49
          Mean value_function loss: 55.3552
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.6174
                       Mean reward: 196.20
               Mean episode length: 215.20
    Episode_Reward/reaching_object: 0.4269
    Episode_Reward/rotating_object: 37.0351
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.97s
                      Time elapsed: 00:08:30
                               ETA: 00:46:02

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 50029 steps/s (collection: 1.871s, learning 0.094s)
             Mean action noise std: 1.49
          Mean value_function loss: 62.9174
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.6383
                       Mean reward: 166.84
               Mean episode length: 206.66
    Episode_Reward/reaching_object: 0.4436
    Episode_Reward/rotating_object: 35.5349
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.96s
                      Time elapsed: 00:08:32
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 46047 steps/s (collection: 2.014s, learning 0.121s)
             Mean action noise std: 1.49
          Mean value_function loss: 68.8963
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 32.6552
                       Mean reward: 233.88
               Mean episode length: 219.76
    Episode_Reward/reaching_object: 0.4606
    Episode_Reward/rotating_object: 40.0000
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.13s
                      Time elapsed: 00:08:34
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 49134 steps/s (collection: 1.891s, learning 0.110s)
             Mean action noise std: 1.49
          Mean value_function loss: 65.6807
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 32.6666
                       Mean reward: 168.98
               Mean episode length: 216.33
    Episode_Reward/reaching_object: 0.4520
    Episode_Reward/rotating_object: 37.8954
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.00s
                      Time elapsed: 00:08:36
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 47756 steps/s (collection: 1.923s, learning 0.136s)
             Mean action noise std: 1.50
          Mean value_function loss: 73.4217
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 32.6807
                       Mean reward: 208.08
               Mean episode length: 220.26
    Episode_Reward/reaching_object: 0.4453
    Episode_Reward/rotating_object: 37.5201
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.06s
                      Time elapsed: 00:08:38
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 47722 steps/s (collection: 1.940s, learning 0.120s)
             Mean action noise std: 1.50
          Mean value_function loss: 75.5443
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 32.6954
                       Mean reward: 209.85
               Mean episode length: 217.80
    Episode_Reward/reaching_object: 0.4563
    Episode_Reward/rotating_object: 38.9367
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.06s
                      Time elapsed: 00:08:40
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 45954 steps/s (collection: 1.963s, learning 0.177s)
             Mean action noise std: 1.50
          Mean value_function loss: 76.9110
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 32.7002
                       Mean reward: 210.97
               Mean episode length: 213.85
    Episode_Reward/reaching_object: 0.4609
    Episode_Reward/rotating_object: 39.0431
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.14s
                      Time elapsed: 00:08:42
                               ETA: 00:45:45

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 47514 steps/s (collection: 1.884s, learning 0.185s)
             Mean action noise std: 1.50
          Mean value_function loss: 83.2045
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.7060
                       Mean reward: 208.78
               Mean episode length: 206.16
    Episode_Reward/reaching_object: 0.4445
    Episode_Reward/rotating_object: 39.4845
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.07s
                      Time elapsed: 00:08:44
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 48192 steps/s (collection: 1.896s, learning 0.144s)
             Mean action noise std: 1.50
          Mean value_function loss: 82.4094
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.7187
                       Mean reward: 204.95
               Mean episode length: 218.11
    Episode_Reward/reaching_object: 0.4597
    Episode_Reward/rotating_object: 37.1419
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.04s
                      Time elapsed: 00:08:46
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 48111 steps/s (collection: 1.917s, learning 0.127s)
             Mean action noise std: 1.50
          Mean value_function loss: 98.2146
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 32.7288
                       Mean reward: 234.92
               Mean episode length: 218.40
    Episode_Reward/reaching_object: 0.4863
    Episode_Reward/rotating_object: 40.9385
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.04s
                      Time elapsed: 00:08:48
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 48545 steps/s (collection: 1.918s, learning 0.107s)
             Mean action noise std: 1.50
          Mean value_function loss: 98.7421
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 32.7433
                       Mean reward: 232.67
               Mean episode length: 218.33
    Episode_Reward/reaching_object: 0.4717
    Episode_Reward/rotating_object: 39.5078
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.03s
                      Time elapsed: 00:08:50
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 47402 steps/s (collection: 1.904s, learning 0.170s)
             Mean action noise std: 1.50
          Mean value_function loss: 94.2649
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 32.7595
                       Mean reward: 214.03
               Mean episode length: 216.22
    Episode_Reward/reaching_object: 0.5014
    Episode_Reward/rotating_object: 43.3853
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.07s
                      Time elapsed: 00:08:52
                               ETA: 00:45:31

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 45220 steps/s (collection: 2.035s, learning 0.139s)
             Mean action noise std: 1.50
          Mean value_function loss: 100.3737
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 32.7716
                       Mean reward: 223.76
               Mean episode length: 214.63
    Episode_Reward/reaching_object: 0.4560
    Episode_Reward/rotating_object: 38.0829
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.17s
                      Time elapsed: 00:08:54
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 46638 steps/s (collection: 1.991s, learning 0.117s)
             Mean action noise std: 1.50
          Mean value_function loss: 106.8995
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 32.7810
                       Mean reward: 204.82
               Mean episode length: 205.79
    Episode_Reward/reaching_object: 0.4924
    Episode_Reward/rotating_object: 44.4828
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.11s
                      Time elapsed: 00:08:57
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 47106 steps/s (collection: 1.996s, learning 0.091s)
             Mean action noise std: 1.51
          Mean value_function loss: 115.0556
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.7903
                       Mean reward: 221.57
               Mean episode length: 206.47
    Episode_Reward/reaching_object: 0.4876
    Episode_Reward/rotating_object: 43.3121
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.09s
                      Time elapsed: 00:08:59
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 46043 steps/s (collection: 2.039s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 120.0019
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 32.7984
                       Mean reward: 254.55
               Mean episode length: 218.00
    Episode_Reward/reaching_object: 0.4729
    Episode_Reward/rotating_object: 41.7366
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.14s
                      Time elapsed: 00:09:01
                               ETA: 00:45:21

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 44723 steps/s (collection: 2.013s, learning 0.185s)
             Mean action noise std: 1.51
          Mean value_function loss: 136.4009
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.8016
                       Mean reward: 258.78
               Mean episode length: 215.60
    Episode_Reward/reaching_object: 0.5161
    Episode_Reward/rotating_object: 47.3778
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.20s
                      Time elapsed: 00:09:03
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 47541 steps/s (collection: 1.969s, learning 0.099s)
             Mean action noise std: 1.51
          Mean value_function loss: 117.7906
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.8078
                       Mean reward: 220.37
               Mean episode length: 208.29
    Episode_Reward/reaching_object: 0.4910
    Episode_Reward/rotating_object: 42.6071
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.07s
                      Time elapsed: 00:09:05
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 47187 steps/s (collection: 1.956s, learning 0.128s)
             Mean action noise std: 1.51
          Mean value_function loss: 103.7377
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 32.8139
                       Mean reward: 238.64
               Mean episode length: 220.60
    Episode_Reward/reaching_object: 0.5201
    Episode_Reward/rotating_object: 49.3501
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.08s
                      Time elapsed: 00:09:07
                               ETA: 00:45:14

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 48074 steps/s (collection: 1.954s, learning 0.091s)
             Mean action noise std: 1.51
          Mean value_function loss: 88.5209
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.8180
                       Mean reward: 254.56
               Mean episode length: 214.64
    Episode_Reward/reaching_object: 0.5087
    Episode_Reward/rotating_object: 45.3544
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.04s
                      Time elapsed: 00:09:09
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 49278 steps/s (collection: 1.893s, learning 0.102s)
             Mean action noise std: 1.51
          Mean value_function loss: 92.6565
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.8265
                       Mean reward: 242.33
               Mean episode length: 206.49
    Episode_Reward/reaching_object: 0.5044
    Episode_Reward/rotating_object: 47.6706
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.99s
                      Time elapsed: 00:09:11
                               ETA: 00:45:08

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 48426 steps/s (collection: 1.898s, learning 0.132s)
             Mean action noise std: 1.51
          Mean value_function loss: 94.0030
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 32.8410
                       Mean reward: 249.38
               Mean episode length: 218.46
    Episode_Reward/reaching_object: 0.5082
    Episode_Reward/rotating_object: 49.1826
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.03s
                      Time elapsed: 00:09:13
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 47452 steps/s (collection: 1.952s, learning 0.120s)
             Mean action noise std: 1.51
          Mean value_function loss: 99.4541
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.8483
                       Mean reward: 297.03
               Mean episode length: 221.45
    Episode_Reward/reaching_object: 0.5051
    Episode_Reward/rotating_object: 52.7922
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.07s
                      Time elapsed: 00:09:15
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 48023 steps/s (collection: 1.926s, learning 0.121s)
             Mean action noise std: 1.51
          Mean value_function loss: 103.5430
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.8590
                       Mean reward: 239.98
               Mean episode length: 212.77
    Episode_Reward/reaching_object: 0.4876
    Episode_Reward/rotating_object: 49.9202
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.05s
                      Time elapsed: 00:09:17
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 48775 steps/s (collection: 1.919s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 80.0522
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 32.8717
                       Mean reward: 282.94
               Mean episode length: 221.92
    Episode_Reward/reaching_object: 0.5031
    Episode_Reward/rotating_object: 51.6262
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.02s
                      Time elapsed: 00:09:19
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 49009 steps/s (collection: 1.902s, learning 0.103s)
             Mean action noise std: 1.51
          Mean value_function loss: 88.4914
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.8777
                       Mean reward: 264.74
               Mean episode length: 205.13
    Episode_Reward/reaching_object: 0.4889
    Episode_Reward/rotating_object: 51.8381
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.01s
                      Time elapsed: 00:09:21
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 46817 steps/s (collection: 1.982s, learning 0.118s)
             Mean action noise std: 1.51
          Mean value_function loss: 84.9833
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.8895
                       Mean reward: 259.81
               Mean episode length: 214.11
    Episode_Reward/reaching_object: 0.5029
    Episode_Reward/rotating_object: 51.9825
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.10s
                      Time elapsed: 00:09:23
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 47139 steps/s (collection: 1.954s, learning 0.131s)
             Mean action noise std: 1.52
          Mean value_function loss: 87.8998
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 32.9047
                       Mean reward: 262.74
               Mean episode length: 212.37
    Episode_Reward/reaching_object: 0.4874
    Episode_Reward/rotating_object: 51.1589
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.09s
                      Time elapsed: 00:09:26
                               ETA: 00:44:49

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 46867 steps/s (collection: 1.983s, learning 0.114s)
             Mean action noise std: 1.52
          Mean value_function loss: 96.2923
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.9149
                       Mean reward: 282.59
               Mean episode length: 208.05
    Episode_Reward/reaching_object: 0.4874
    Episode_Reward/rotating_object: 56.6087
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.10s
                      Time elapsed: 00:09:28
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 48728 steps/s (collection: 1.906s, learning 0.112s)
             Mean action noise std: 1.52
          Mean value_function loss: 94.5803
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.9281
                       Mean reward: 268.39
               Mean episode length: 209.50
    Episode_Reward/reaching_object: 0.4864
    Episode_Reward/rotating_object: 55.1676
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.02s
                      Time elapsed: 00:09:30
                               ETA: 00:44:43

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 47289 steps/s (collection: 1.956s, learning 0.123s)
             Mean action noise std: 1.52
          Mean value_function loss: 105.7170
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 32.9407
                       Mean reward: 274.49
               Mean episode length: 207.60
    Episode_Reward/reaching_object: 0.4900
    Episode_Reward/rotating_object: 55.6482
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.08s
                      Time elapsed: 00:09:32
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 48435 steps/s (collection: 1.917s, learning 0.113s)
             Mean action noise std: 1.52
          Mean value_function loss: 91.3321
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 32.9524
                       Mean reward: 289.11
               Mean episode length: 220.80
    Episode_Reward/reaching_object: 0.4973
    Episode_Reward/rotating_object: 54.7874
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.03s
                      Time elapsed: 00:09:34
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 49603 steps/s (collection: 1.885s, learning 0.097s)
             Mean action noise std: 1.52
          Mean value_function loss: 89.7709
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.9624
                       Mean reward: 269.56
               Mean episode length: 218.45
    Episode_Reward/reaching_object: 0.4902
    Episode_Reward/rotating_object: 52.6765
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.98s
                      Time elapsed: 00:09:36
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 48568 steps/s (collection: 1.915s, learning 0.109s)
             Mean action noise std: 1.52
          Mean value_function loss: 98.2632
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.9729
                       Mean reward: 304.84
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 0.5019
    Episode_Reward/rotating_object: 56.9930
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.02s
                      Time elapsed: 00:09:38
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 47640 steps/s (collection: 1.915s, learning 0.149s)
             Mean action noise std: 1.52
          Mean value_function loss: 97.8312
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.9789
                       Mean reward: 279.36
               Mean episode length: 210.67
    Episode_Reward/reaching_object: 0.4794
    Episode_Reward/rotating_object: 54.5758
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.06s
                      Time elapsed: 00:09:40
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 47407 steps/s (collection: 1.961s, learning 0.113s)
             Mean action noise std: 1.52
          Mean value_function loss: 105.8911
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 32.9900
                       Mean reward: 264.31
               Mean episode length: 215.24
    Episode_Reward/reaching_object: 0.4915
    Episode_Reward/rotating_object: 57.6677
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.07s
                      Time elapsed: 00:09:42
                               ETA: 00:44:27

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 46538 steps/s (collection: 1.960s, learning 0.152s)
             Mean action noise std: 1.52
          Mean value_function loss: 95.7733
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 32.9991
                       Mean reward: 288.98
               Mean episode length: 210.04
    Episode_Reward/reaching_object: 0.4796
    Episode_Reward/rotating_object: 55.3753
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.11s
                      Time elapsed: 00:09:44
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 47896 steps/s (collection: 1.931s, learning 0.122s)
             Mean action noise std: 1.53
          Mean value_function loss: 106.6193
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.0158
                       Mean reward: 291.25
               Mean episode length: 214.63
    Episode_Reward/reaching_object: 0.4896
    Episode_Reward/rotating_object: 55.0052
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.05s
                      Time elapsed: 00:09:46
                               ETA: 00:44:22

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 47395 steps/s (collection: 1.939s, learning 0.136s)
             Mean action noise std: 1.53
          Mean value_function loss: 99.2515
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 33.0352
                       Mean reward: 273.87
               Mean episode length: 211.87
    Episode_Reward/reaching_object: 0.5026
    Episode_Reward/rotating_object: 55.7005
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.07s
                      Time elapsed: 00:09:48
                               ETA: 00:44:19

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 44774 steps/s (collection: 2.054s, learning 0.142s)
             Mean action noise std: 1.53
          Mean value_function loss: 110.7965
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 33.0497
                       Mean reward: 337.03
               Mean episode length: 218.76
    Episode_Reward/reaching_object: 0.5088
    Episode_Reward/rotating_object: 59.2850
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.20s
                      Time elapsed: 00:09:50
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 46150 steps/s (collection: 2.002s, learning 0.128s)
             Mean action noise std: 1.53
          Mean value_function loss: 106.7878
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 33.0640
                       Mean reward: 328.82
               Mean episode length: 222.77
    Episode_Reward/reaching_object: 0.5181
    Episode_Reward/rotating_object: 58.3225
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.13s
                      Time elapsed: 00:09:52
                               ETA: 00:44:15

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 45760 steps/s (collection: 2.044s, learning 0.104s)
             Mean action noise std: 1.53
          Mean value_function loss: 105.6311
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.0779
                       Mean reward: 284.51
               Mean episode length: 212.40
    Episode_Reward/reaching_object: 0.5140
    Episode_Reward/rotating_object: 56.7752
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.15s
                      Time elapsed: 00:09:55
                               ETA: 00:44:13

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 49047 steps/s (collection: 1.903s, learning 0.102s)
             Mean action noise std: 1.53
          Mean value_function loss: 108.9592
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.0860
                       Mean reward: 325.46
               Mean episode length: 218.46
    Episode_Reward/reaching_object: 0.4873
    Episode_Reward/rotating_object: 56.4192
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.00s
                      Time elapsed: 00:09:57
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 46467 steps/s (collection: 1.979s, learning 0.137s)
             Mean action noise std: 1.53
          Mean value_function loss: 111.8775
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.0976
                       Mean reward: 305.62
               Mean episode length: 213.07
    Episode_Reward/reaching_object: 0.5000
    Episode_Reward/rotating_object: 60.0247
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.12s
                      Time elapsed: 00:09:59
                               ETA: 00:44:07

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 47642 steps/s (collection: 1.959s, learning 0.105s)
             Mean action noise std: 1.53
          Mean value_function loss: 107.0393
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 33.1081
                       Mean reward: 320.83
               Mean episode length: 215.68
    Episode_Reward/reaching_object: 0.5165
    Episode_Reward/rotating_object: 62.9765
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.06s
                      Time elapsed: 00:10:01
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 48070 steps/s (collection: 1.934s, learning 0.111s)
             Mean action noise std: 1.53
          Mean value_function loss: 100.1590
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.1120
                       Mean reward: 301.99
               Mean episode length: 207.12
    Episode_Reward/reaching_object: 0.5142
    Episode_Reward/rotating_object: 63.5090
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.05s
                      Time elapsed: 00:10:03
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 48134 steps/s (collection: 1.944s, learning 0.098s)
             Mean action noise std: 1.53
          Mean value_function loss: 93.0229
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.1159
                       Mean reward: 331.43
               Mean episode length: 213.79
    Episode_Reward/reaching_object: 0.4886
    Episode_Reward/rotating_object: 59.5686
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.04s
                      Time elapsed: 00:10:05
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 47278 steps/s (collection: 1.979s, learning 0.101s)
             Mean action noise std: 1.54
          Mean value_function loss: 104.2773
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.1227
                       Mean reward: 330.89
               Mean episode length: 217.34
    Episode_Reward/reaching_object: 0.5074
    Episode_Reward/rotating_object: 61.5938
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.08s
                      Time elapsed: 00:10:07
                               ETA: 00:43:57

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 46807 steps/s (collection: 1.973s, learning 0.128s)
             Mean action noise std: 1.54
          Mean value_function loss: 112.9890
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.1305
                       Mean reward: 335.21
               Mean episode length: 209.17
    Episode_Reward/reaching_object: 0.5197
    Episode_Reward/rotating_object: 67.8525
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.10s
                      Time elapsed: 00:10:09
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 47949 steps/s (collection: 1.940s, learning 0.110s)
             Mean action noise std: 1.54
          Mean value_function loss: 111.1982
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 33.1418
                       Mean reward: 330.07
               Mean episode length: 205.48
    Episode_Reward/reaching_object: 0.5131
    Episode_Reward/rotating_object: 66.2590
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.05s
                      Time elapsed: 00:10:11
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 49137 steps/s (collection: 1.901s, learning 0.100s)
             Mean action noise std: 1.54
          Mean value_function loss: 111.0894
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.1552
                       Mean reward: 321.55
               Mean episode length: 215.51
    Episode_Reward/reaching_object: 0.5137
    Episode_Reward/rotating_object: 63.0107
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.00s
                      Time elapsed: 00:10:13
                               ETA: 00:43:49

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 48262 steps/s (collection: 1.933s, learning 0.104s)
             Mean action noise std: 1.54
          Mean value_function loss: 103.1279
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 33.1629
                       Mean reward: 332.31
               Mean episode length: 211.98
    Episode_Reward/reaching_object: 0.5152
    Episode_Reward/rotating_object: 63.9544
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.04s
                      Time elapsed: 00:10:15
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 47678 steps/s (collection: 1.945s, learning 0.117s)
             Mean action noise std: 1.54
          Mean value_function loss: 98.4936
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 33.1702
                       Mean reward: 366.23
               Mean episode length: 212.82
    Episode_Reward/reaching_object: 0.5215
    Episode_Reward/rotating_object: 70.6099
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.06s
                      Time elapsed: 00:10:17
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 46217 steps/s (collection: 1.926s, learning 0.201s)
             Mean action noise std: 1.54
          Mean value_function loss: 103.8790
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.1832
                       Mean reward: 298.92
               Mean episode length: 200.95
    Episode_Reward/reaching_object: 0.5039
    Episode_Reward/rotating_object: 65.8011
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.13s
                      Time elapsed: 00:10:19
                               ETA: 00:43:41

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 47534 steps/s (collection: 1.897s, learning 0.171s)
             Mean action noise std: 1.54
          Mean value_function loss: 108.6930
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 33.1986
                       Mean reward: 380.03
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 0.5241
    Episode_Reward/rotating_object: 69.1867
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.07s
                      Time elapsed: 00:10:21
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 47082 steps/s (collection: 1.964s, learning 0.124s)
             Mean action noise std: 1.54
          Mean value_function loss: 106.8737
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.2104
                       Mean reward: 376.61
               Mean episode length: 219.44
    Episode_Reward/reaching_object: 0.5033
    Episode_Reward/rotating_object: 67.2355
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.09s
                      Time elapsed: 00:10:23
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 44845 steps/s (collection: 2.071s, learning 0.122s)
             Mean action noise std: 1.55
          Mean value_function loss: 111.1047
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 33.2229
                       Mean reward: 329.55
               Mean episode length: 212.69
    Episode_Reward/reaching_object: 0.5138
    Episode_Reward/rotating_object: 70.5972
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.19s
                      Time elapsed: 00:10:26
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 46334 steps/s (collection: 2.009s, learning 0.113s)
             Mean action noise std: 1.55
          Mean value_function loss: 109.9245
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.2312
                       Mean reward: 321.98
               Mean episode length: 209.98
    Episode_Reward/reaching_object: 0.5312
    Episode_Reward/rotating_object: 68.8772
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.12s
                      Time elapsed: 00:10:28
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 45038 steps/s (collection: 2.062s, learning 0.121s)
             Mean action noise std: 1.55
          Mean value_function loss: 110.9314
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.2362
                       Mean reward: 383.21
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 0.5351
    Episode_Reward/rotating_object: 73.5522
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.18s
                      Time elapsed: 00:10:30
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 47462 steps/s (collection: 1.953s, learning 0.119s)
             Mean action noise std: 1.55
          Mean value_function loss: 116.3747
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.2434
                       Mean reward: 349.48
               Mean episode length: 221.70
    Episode_Reward/reaching_object: 0.5377
    Episode_Reward/rotating_object: 71.8872
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.07s
                      Time elapsed: 00:10:32
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 47880 steps/s (collection: 1.952s, learning 0.102s)
             Mean action noise std: 1.55
          Mean value_function loss: 115.0312
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.2530
                       Mean reward: 339.62
               Mean episode length: 211.69
    Episode_Reward/reaching_object: 0.5404
    Episode_Reward/rotating_object: 70.5158
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.05s
                      Time elapsed: 00:10:34
                               ETA: 00:43:25

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 47921 steps/s (collection: 1.929s, learning 0.123s)
             Mean action noise std: 1.55
          Mean value_function loss: 124.4765
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 33.2614
                       Mean reward: 327.51
               Mean episode length: 209.97
    Episode_Reward/reaching_object: 0.5295
    Episode_Reward/rotating_object: 70.4806
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.05s
                      Time elapsed: 00:10:36
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 47490 steps/s (collection: 1.944s, learning 0.126s)
             Mean action noise std: 1.55
          Mean value_function loss: 120.6917
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.2667
                       Mean reward: 379.66
               Mean episode length: 217.15
    Episode_Reward/reaching_object: 0.5480
    Episode_Reward/rotating_object: 76.3229
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.07s
                      Time elapsed: 00:10:38
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 44945 steps/s (collection: 2.048s, learning 0.139s)
             Mean action noise std: 1.55
          Mean value_function loss: 117.7201
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.2766
                       Mean reward: 412.68
               Mean episode length: 217.85
    Episode_Reward/reaching_object: 0.5384
    Episode_Reward/rotating_object: 71.9363
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.19s
                      Time elapsed: 00:10:40
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 47637 steps/s (collection: 1.921s, learning 0.143s)
             Mean action noise std: 1.55
          Mean value_function loss: 120.5080
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.2886
                       Mean reward: 430.12
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 0.5571
    Episode_Reward/rotating_object: 77.5795
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.06s
                      Time elapsed: 00:10:42
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 46426 steps/s (collection: 1.985s, learning 0.132s)
             Mean action noise std: 1.55
          Mean value_function loss: 119.8415
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.3001
                       Mean reward: 417.53
               Mean episode length: 226.51
    Episode_Reward/reaching_object: 0.5679
    Episode_Reward/rotating_object: 75.8781
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.12s
                      Time elapsed: 00:10:45
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 46778 steps/s (collection: 1.952s, learning 0.149s)
             Mean action noise std: 1.55
          Mean value_function loss: 101.4523
               Mean surrogate loss: 0.0040
                 Mean entropy loss: 33.3073
                       Mean reward: 355.14
               Mean episode length: 220.24
    Episode_Reward/reaching_object: 0.5756
    Episode_Reward/rotating_object: 79.6912
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.10s
                      Time elapsed: 00:10:47
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 48029 steps/s (collection: 1.937s, learning 0.110s)
             Mean action noise std: 1.55
          Mean value_function loss: 91.7659
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 33.3095
                       Mean reward: 445.39
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.5869
    Episode_Reward/rotating_object: 87.6561
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.05s
                      Time elapsed: 00:10:49
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 46135 steps/s (collection: 2.027s, learning 0.104s)
             Mean action noise std: 1.55
          Mean value_function loss: 95.6012
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.3128
                       Mean reward: 402.69
               Mean episode length: 217.84
    Episode_Reward/reaching_object: 0.5566
    Episode_Reward/rotating_object: 80.6648
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.13s
                      Time elapsed: 00:10:51
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 47377 steps/s (collection: 1.966s, learning 0.109s)
             Mean action noise std: 1.55
          Mean value_function loss: 97.5201
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.3164
                       Mean reward: 428.55
               Mean episode length: 219.17
    Episode_Reward/reaching_object: 0.5564
    Episode_Reward/rotating_object: 85.3852
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.07s
                      Time elapsed: 00:10:53
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 45708 steps/s (collection: 2.052s, learning 0.099s)
             Mean action noise std: 1.55
          Mean value_function loss: 88.3443
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 33.3153
                       Mean reward: 398.13
               Mean episode length: 224.19
    Episode_Reward/reaching_object: 0.5493
    Episode_Reward/rotating_object: 81.8020
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.15s
                      Time elapsed: 00:10:55
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 47946 steps/s (collection: 1.952s, learning 0.098s)
             Mean action noise std: 1.55
          Mean value_function loss: 101.5562
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.3171
                       Mean reward: 375.50
               Mean episode length: 221.02
    Episode_Reward/reaching_object: 0.5229
    Episode_Reward/rotating_object: 74.9919
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.05s
                      Time elapsed: 00:10:57
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 46646 steps/s (collection: 1.994s, learning 0.113s)
             Mean action noise std: 1.56
          Mean value_function loss: 93.6876
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.3193
                       Mean reward: 464.90
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 0.5284
    Episode_Reward/rotating_object: 81.6463
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.11s
                      Time elapsed: 00:10:59
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 47427 steps/s (collection: 1.975s, learning 0.098s)
             Mean action noise std: 1.56
          Mean value_function loss: 98.6324
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 33.3245
                       Mean reward: 407.68
               Mean episode length: 224.02
    Episode_Reward/reaching_object: 0.5376
    Episode_Reward/rotating_object: 82.1710
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.07s
                      Time elapsed: 00:11:01
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 46453 steps/s (collection: 1.970s, learning 0.147s)
             Mean action noise std: 1.56
          Mean value_function loss: 110.0584
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.3296
                       Mean reward: 415.21
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 0.5437
    Episode_Reward/rotating_object: 84.2495
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.12s
                      Time elapsed: 00:11:03
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 47578 steps/s (collection: 1.922s, learning 0.144s)
             Mean action noise std: 1.56
          Mean value_function loss: 123.8345
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.3342
                       Mean reward: 394.41
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 0.5504
    Episode_Reward/rotating_object: 84.8108
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.07s
                      Time elapsed: 00:11:06
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 48679 steps/s (collection: 1.919s, learning 0.101s)
             Mean action noise std: 1.56
          Mean value_function loss: 123.5656
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.3436
                       Mean reward: 400.58
               Mean episode length: 215.44
    Episode_Reward/reaching_object: 0.5604
    Episode_Reward/rotating_object: 83.1962
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.02s
                      Time elapsed: 00:11:08
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 46989 steps/s (collection: 1.939s, learning 0.153s)
             Mean action noise std: 1.56
          Mean value_function loss: 112.7235
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.3541
                       Mean reward: 448.99
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 0.5713
    Episode_Reward/rotating_object: 82.9268
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.09s
                      Time elapsed: 00:11:10
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 49463 steps/s (collection: 1.876s, learning 0.111s)
             Mean action noise std: 1.56
          Mean value_function loss: 105.0765
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.3598
                       Mean reward: 423.13
               Mean episode length: 225.31
    Episode_Reward/reaching_object: 0.5706
    Episode_Reward/rotating_object: 84.5242
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.99s
                      Time elapsed: 00:11:12
                               ETA: 00:42:41

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 48145 steps/s (collection: 1.886s, learning 0.156s)
             Mean action noise std: 1.56
          Mean value_function loss: 116.0921
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 33.3672
                       Mean reward: 427.37
               Mean episode length: 227.75
    Episode_Reward/reaching_object: 0.5867
    Episode_Reward/rotating_object: 87.6017
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.04s
                      Time elapsed: 00:11:14
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 48278 steps/s (collection: 1.903s, learning 0.134s)
             Mean action noise std: 1.56
          Mean value_function loss: 103.9195
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.3713
                       Mean reward: 424.31
               Mean episode length: 220.63
    Episode_Reward/reaching_object: 0.5850
    Episode_Reward/rotating_object: 87.7435
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.04s
                      Time elapsed: 00:11:16
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 48277 steps/s (collection: 1.923s, learning 0.113s)
             Mean action noise std: 1.56
          Mean value_function loss: 102.0506
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.3779
                       Mean reward: 420.24
               Mean episode length: 219.21
    Episode_Reward/reaching_object: 0.5880
    Episode_Reward/rotating_object: 85.5712
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.04s
                      Time elapsed: 00:11:18
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 47646 steps/s (collection: 1.942s, learning 0.121s)
             Mean action noise std: 1.56
          Mean value_function loss: 101.2776
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 33.3852
                       Mean reward: 472.65
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 0.5883
    Episode_Reward/rotating_object: 88.9967
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.06s
                      Time elapsed: 00:11:20
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 48990 steps/s (collection: 1.892s, learning 0.115s)
             Mean action noise std: 1.56
          Mean value_function loss: 97.8870
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.3944
                       Mean reward: 460.78
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 0.5820
    Episode_Reward/rotating_object: 92.2342
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.01s
                      Time elapsed: 00:11:22
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 47829 steps/s (collection: 1.923s, learning 0.133s)
             Mean action noise std: 1.56
          Mean value_function loss: 96.5047
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.4047
                       Mean reward: 488.68
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 0.5992
    Episode_Reward/rotating_object: 95.6795
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.06s
                      Time elapsed: 00:11:24
                               ETA: 00:42:25

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 47945 steps/s (collection: 1.945s, learning 0.106s)
             Mean action noise std: 1.56
          Mean value_function loss: 115.7632
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.4066
                       Mean reward: 477.12
               Mean episode length: 228.34
    Episode_Reward/reaching_object: 0.5824
    Episode_Reward/rotating_object: 93.3384
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.05s
                      Time elapsed: 00:11:26
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 47052 steps/s (collection: 1.966s, learning 0.124s)
             Mean action noise std: 1.56
          Mean value_function loss: 116.3644
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.4081
                       Mean reward: 479.83
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 0.5816
    Episode_Reward/rotating_object: 95.9686
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.09s
                      Time elapsed: 00:11:28
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 47674 steps/s (collection: 1.930s, learning 0.132s)
             Mean action noise std: 1.56
          Mean value_function loss: 114.9736
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.4151
                       Mean reward: 452.04
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 0.5831
    Episode_Reward/rotating_object: 91.7233
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.06s
                      Time elapsed: 00:11:30
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 46900 steps/s (collection: 1.959s, learning 0.137s)
             Mean action noise std: 1.57
          Mean value_function loss: 103.4785
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.4208
                       Mean reward: 497.42
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 0.5741
    Episode_Reward/rotating_object: 99.2748
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.10s
                      Time elapsed: 00:11:32
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 47482 steps/s (collection: 1.960s, learning 0.110s)
             Mean action noise std: 1.57
          Mean value_function loss: 100.2697
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.4253
                       Mean reward: 470.28
               Mean episode length: 224.64
    Episode_Reward/reaching_object: 0.5853
    Episode_Reward/rotating_object: 99.7677
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.07s
                      Time elapsed: 00:11:34
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 47931 steps/s (collection: 1.947s, learning 0.104s)
             Mean action noise std: 1.57
          Mean value_function loss: 112.5570
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 33.4305
                       Mean reward: 414.65
               Mean episode length: 214.98
    Episode_Reward/reaching_object: 0.5520
    Episode_Reward/rotating_object: 90.7075
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.05s
                      Time elapsed: 00:11:36
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 48151 steps/s (collection: 1.940s, learning 0.102s)
             Mean action noise std: 1.57
          Mean value_function loss: 103.1956
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.4383
                       Mean reward: 452.00
               Mean episode length: 221.32
    Episode_Reward/reaching_object: 0.5652
    Episode_Reward/rotating_object: 95.1254
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.04s
                      Time elapsed: 00:11:38
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 47025 steps/s (collection: 1.962s, learning 0.128s)
             Mean action noise std: 1.57
          Mean value_function loss: 107.9540
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 33.4483
                       Mean reward: 509.03
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 0.5742
    Episode_Reward/rotating_object: 95.6597
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.09s
                      Time elapsed: 00:11:40
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 43543 steps/s (collection: 2.126s, learning 0.132s)
             Mean action noise std: 1.57
          Mean value_function loss: 104.4942
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.4547
                       Mean reward: 508.19
               Mean episode length: 230.45
    Episode_Reward/reaching_object: 0.5628
    Episode_Reward/rotating_object: 95.0950
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.26s
                      Time elapsed: 00:11:43
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 45670 steps/s (collection: 2.004s, learning 0.148s)
             Mean action noise std: 1.57
          Mean value_function loss: 102.1307
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.4630
                       Mean reward: 498.14
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 0.5959
    Episode_Reward/rotating_object: 101.8022
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.15s
                      Time elapsed: 00:11:45
                               ETA: 00:42:02

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 47606 steps/s (collection: 1.957s, learning 0.108s)
             Mean action noise std: 1.57
          Mean value_function loss: 106.4506
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.4656
                       Mean reward: 502.18
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.5781
    Episode_Reward/rotating_object: 96.9815
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.06s
                      Time elapsed: 00:11:47
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 45486 steps/s (collection: 2.026s, learning 0.135s)
             Mean action noise std: 1.57
          Mean value_function loss: 101.3687
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.4673
                       Mean reward: 513.72
               Mean episode length: 230.62
    Episode_Reward/reaching_object: 0.5831
    Episode_Reward/rotating_object: 100.4202
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.16s
                      Time elapsed: 00:11:49
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 48254 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 102.8780
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 33.4700
                       Mean reward: 494.81
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 0.5744
    Episode_Reward/rotating_object: 97.8042
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.04s
                      Time elapsed: 00:11:51
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 47259 steps/s (collection: 1.943s, learning 0.137s)
             Mean action noise std: 1.57
          Mean value_function loss: 98.6577
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 33.4712
                       Mean reward: 524.73
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 0.5789
    Episode_Reward/rotating_object: 102.0778
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.08s
                      Time elapsed: 00:11:53
                               ETA: 00:41:52

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 47997 steps/s (collection: 1.925s, learning 0.123s)
             Mean action noise std: 1.57
          Mean value_function loss: 101.6769
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.4703
                       Mean reward: 513.77
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 0.5694
    Episode_Reward/rotating_object: 99.0576
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.05s
                      Time elapsed: 00:11:55
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 19175 steps/s (collection: 4.969s, learning 0.157s)
             Mean action noise std: 1.57
          Mean value_function loss: 105.6796
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.4730
                       Mean reward: 493.28
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 0.5779
    Episode_Reward/rotating_object: 102.9133
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.13s
                      Time elapsed: 00:12:00
                               ETA: 00:41:58

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14542 steps/s (collection: 6.624s, learning 0.136s)
             Mean action noise std: 1.57
          Mean value_function loss: 114.5130
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.4788
                       Mean reward: 496.38
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 0.5726
    Episode_Reward/rotating_object: 98.7129
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.76s
                      Time elapsed: 00:12:07
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14473 steps/s (collection: 6.656s, learning 0.136s)
             Mean action noise std: 1.57
          Mean value_function loss: 118.5121
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.4824
                       Mean reward: 520.64
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 0.5655
    Episode_Reward/rotating_object: 100.0961
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.79s
                      Time elapsed: 00:12:14
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14669 steps/s (collection: 6.584s, learning 0.118s)
             Mean action noise std: 1.57
          Mean value_function loss: 101.6212
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.4870
                       Mean reward: 528.82
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 0.5692
    Episode_Reward/rotating_object: 106.5126
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.70s
                      Time elapsed: 00:12:21
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14648 steps/s (collection: 6.570s, learning 0.141s)
             Mean action noise std: 1.57
          Mean value_function loss: 115.8881
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.4931
                       Mean reward: 514.47
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 0.5894
    Episode_Reward/rotating_object: 107.3754
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.71s
                      Time elapsed: 00:12:27
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14324 steps/s (collection: 6.719s, learning 0.144s)
             Mean action noise std: 1.57
          Mean value_function loss: 108.7584
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.4981
                       Mean reward: 521.89
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 0.5807
    Episode_Reward/rotating_object: 109.0528
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.86s
                      Time elapsed: 00:12:34
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 15299 steps/s (collection: 6.292s, learning 0.134s)
             Mean action noise std: 1.57
          Mean value_function loss: 99.0996
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 33.5027
                       Mean reward: 533.84
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 0.5762
    Episode_Reward/rotating_object: 103.2400
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.43s
                      Time elapsed: 00:12:41
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14748 steps/s (collection: 6.531s, learning 0.135s)
             Mean action noise std: 1.58
          Mean value_function loss: 90.8553
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.5068
                       Mean reward: 555.11
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 0.5990
    Episode_Reward/rotating_object: 103.9752
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.67s
                      Time elapsed: 00:12:47
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13034 steps/s (collection: 7.436s, learning 0.106s)
             Mean action noise std: 1.58
          Mean value_function loss: 87.8071
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.5137
                       Mean reward: 516.42
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 0.5937
    Episode_Reward/rotating_object: 106.3492
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.54s
                      Time elapsed: 00:12:55
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 49779 steps/s (collection: 1.876s, learning 0.099s)
             Mean action noise std: 1.58
          Mean value_function loss: 94.2819
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.5231
                       Mean reward: 525.43
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 0.5880
    Episode_Reward/rotating_object: 109.9823
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.97s
                      Time elapsed: 00:12:57
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 48867 steps/s (collection: 1.910s, learning 0.102s)
             Mean action noise std: 1.58
          Mean value_function loss: 95.0659
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.5296
                       Mean reward: 519.21
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 0.5926
    Episode_Reward/rotating_object: 108.4590
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.01s
                      Time elapsed: 00:12:59
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 52485 steps/s (collection: 1.777s, learning 0.096s)
             Mean action noise std: 1.58
          Mean value_function loss: 96.7113
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.5343
                       Mean reward: 530.25
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 0.6026
    Episode_Reward/rotating_object: 112.1627
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.87s
                      Time elapsed: 00:13:01
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 51752 steps/s (collection: 1.786s, learning 0.113s)
             Mean action noise std: 1.58
          Mean value_function loss: 91.4894
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 33.5454
                       Mean reward: 553.94
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 0.5961
    Episode_Reward/rotating_object: 109.2625
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.90s
                      Time elapsed: 00:13:03
                               ETA: 00:43:33

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 51619 steps/s (collection: 1.808s, learning 0.096s)
             Mean action noise std: 1.58
          Mean value_function loss: 90.8221
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.5492
                       Mean reward: 608.20
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 0.5926
    Episode_Reward/rotating_object: 111.8782
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.90s
                      Time elapsed: 00:13:04
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 51417 steps/s (collection: 1.782s, learning 0.130s)
             Mean action noise std: 1.58
          Mean value_function loss: 77.4748
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 33.5530
                       Mean reward: 547.14
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 0.5934
    Episode_Reward/rotating_object: 112.3106
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.91s
                      Time elapsed: 00:13:06
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 50553 steps/s (collection: 1.850s, learning 0.095s)
             Mean action noise std: 1.58
          Mean value_function loss: 90.1262
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.5563
                       Mean reward: 544.25
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 0.5926
    Episode_Reward/rotating_object: 115.9611
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.94s
                      Time elapsed: 00:13:08
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 49832 steps/s (collection: 1.831s, learning 0.142s)
             Mean action noise std: 1.58
          Mean value_function loss: 91.9402
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.5578
                       Mean reward: 566.62
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 0.5976
    Episode_Reward/rotating_object: 113.2720
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.97s
                      Time elapsed: 00:13:10
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 51305 steps/s (collection: 1.817s, learning 0.100s)
             Mean action noise std: 1.58
          Mean value_function loss: 100.3171
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 33.5612
                       Mean reward: 542.42
               Mean episode length: 231.81
    Episode_Reward/reaching_object: 0.5918
    Episode_Reward/rotating_object: 106.5706
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.92s
                      Time elapsed: 00:13:12
                               ETA: 00:43:17

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 49727 steps/s (collection: 1.833s, learning 0.144s)
             Mean action noise std: 1.58
          Mean value_function loss: 104.2736
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.5654
                       Mean reward: 555.87
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 0.5827
    Episode_Reward/rotating_object: 109.2477
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.98s
                      Time elapsed: 00:13:14
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 50135 steps/s (collection: 1.865s, learning 0.096s)
             Mean action noise std: 1.58
          Mean value_function loss: 89.0109
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.5668
                       Mean reward: 556.64
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.5854
    Episode_Reward/rotating_object: 110.1479
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.96s
                      Time elapsed: 00:13:16
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 50715 steps/s (collection: 1.823s, learning 0.115s)
             Mean action noise std: 1.58
          Mean value_function loss: 91.5789
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.5656
                       Mean reward: 588.60
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 0.5947
    Episode_Reward/rotating_object: 112.9472
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.94s
                      Time elapsed: 00:13:18
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 51029 steps/s (collection: 1.833s, learning 0.094s)
             Mean action noise std: 1.58
          Mean value_function loss: 89.6832
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.5651
                       Mean reward: 612.01
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 0.5987
    Episode_Reward/rotating_object: 114.6518
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.93s
                      Time elapsed: 00:13:20
                               ETA: 00:43:04

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 51529 steps/s (collection: 1.813s, learning 0.095s)
             Mean action noise std: 1.58
          Mean value_function loss: 95.7821
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 33.5705
                       Mean reward: 589.13
               Mean episode length: 238.31
    Episode_Reward/reaching_object: 0.5907
    Episode_Reward/rotating_object: 111.1982
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.91s
                      Time elapsed: 00:13:22
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 49794 steps/s (collection: 1.879s, learning 0.096s)
             Mean action noise std: 1.58
          Mean value_function loss: 93.7565
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.5839
                       Mean reward: 587.06
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 0.6004
    Episode_Reward/rotating_object: 115.3083
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.97s
                      Time elapsed: 00:13:24
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 50900 steps/s (collection: 1.822s, learning 0.109s)
             Mean action noise std: 1.58
          Mean value_function loss: 92.1193
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 33.5880
                       Mean reward: 577.74
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 0.6077
    Episode_Reward/rotating_object: 112.3494
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.93s
                      Time elapsed: 00:13:26
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 49566 steps/s (collection: 1.843s, learning 0.141s)
             Mean action noise std: 1.58
          Mean value_function loss: 86.1787
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.5893
                       Mean reward: 627.07
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.6084
    Episode_Reward/rotating_object: 119.2450
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.98s
                      Time elapsed: 00:13:28
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 50113 steps/s (collection: 1.866s, learning 0.095s)
             Mean action noise std: 1.58
          Mean value_function loss: 86.1583
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.5920
                       Mean reward: 567.57
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 0.6063
    Episode_Reward/rotating_object: 119.8601
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.96s
                      Time elapsed: 00:13:30
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 50980 steps/s (collection: 1.822s, learning 0.107s)
             Mean action noise std: 1.58
          Mean value_function loss: 89.5171
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 33.5930
                       Mean reward: 603.26
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 0.6068
    Episode_Reward/rotating_object: 119.6475
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.93s
                      Time elapsed: 00:13:32
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 50680 steps/s (collection: 1.829s, learning 0.111s)
             Mean action noise std: 1.58
          Mean value_function loss: 90.5980
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.5951
                       Mean reward: 573.23
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 0.6125
    Episode_Reward/rotating_object: 120.6542
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.94s
                      Time elapsed: 00:13:34
                               ETA: 00:42:41

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 50479 steps/s (collection: 1.838s, learning 0.110s)
             Mean action noise std: 1.59
          Mean value_function loss: 94.7308
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.6002
                       Mean reward: 538.53
               Mean episode length: 221.77
    Episode_Reward/reaching_object: 0.5960
    Episode_Reward/rotating_object: 114.8064
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.95s
                      Time elapsed: 00:13:36
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 50913 steps/s (collection: 1.840s, learning 0.091s)
             Mean action noise std: 1.59
          Mean value_function loss: 91.8371
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.6051
                       Mean reward: 567.79
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 0.6052
    Episode_Reward/rotating_object: 116.8799
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.93s
                      Time elapsed: 00:13:37
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 49543 steps/s (collection: 1.891s, learning 0.093s)
             Mean action noise std: 1.59
          Mean value_function loss: 87.6251
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.6081
                       Mean reward: 621.84
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 0.6040
    Episode_Reward/rotating_object: 119.5999
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.98s
                      Time elapsed: 00:13:39
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 50889 steps/s (collection: 1.836s, learning 0.096s)
             Mean action noise std: 1.59
          Mean value_function loss: 88.4917
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.6128
                       Mean reward: 590.87
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 0.6055
    Episode_Reward/rotating_object: 118.4580
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.93s
                      Time elapsed: 00:13:41
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 47859 steps/s (collection: 1.895s, learning 0.159s)
             Mean action noise std: 1.59
          Mean value_function loss: 90.6331
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.6206
                       Mean reward: 616.98
               Mean episode length: 240.28
    Episode_Reward/reaching_object: 0.5945
    Episode_Reward/rotating_object: 116.8661
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.05s
                      Time elapsed: 00:13:43
                               ETA: 00:42:25

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 49926 steps/s (collection: 1.847s, learning 0.122s)
             Mean action noise std: 1.59
          Mean value_function loss: 87.2763
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.6270
                       Mean reward: 572.56
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 0.5939
    Episode_Reward/rotating_object: 116.1486
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.97s
                      Time elapsed: 00:13:45
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 49461 steps/s (collection: 1.834s, learning 0.154s)
             Mean action noise std: 1.59
          Mean value_function loss: 80.9442
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.6301
                       Mean reward: 587.43
               Mean episode length: 234.72
    Episode_Reward/reaching_object: 0.6087
    Episode_Reward/rotating_object: 116.9008
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.99s
                      Time elapsed: 00:13:47
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 47387 steps/s (collection: 1.967s, learning 0.108s)
             Mean action noise std: 1.59
          Mean value_function loss: 82.1518
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.6348
                       Mean reward: 596.33
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 0.6080
    Episode_Reward/rotating_object: 118.6275
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.07s
                      Time elapsed: 00:13:50
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 50320 steps/s (collection: 1.834s, learning 0.120s)
             Mean action noise std: 1.59
          Mean value_function loss: 81.2357
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.6393
                       Mean reward: 641.59
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 0.6154
    Episode_Reward/rotating_object: 121.6433
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.95s
                      Time elapsed: 00:13:51
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 51020 steps/s (collection: 1.831s, learning 0.096s)
             Mean action noise std: 1.59
          Mean value_function loss: 82.7632
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 33.6443
                       Mean reward: 617.33
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 0.6174
    Episode_Reward/rotating_object: 122.1937
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.93s
                      Time elapsed: 00:13:53
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 52028 steps/s (collection: 1.796s, learning 0.093s)
             Mean action noise std: 1.59
          Mean value_function loss: 84.5424
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.6507
                       Mean reward: 618.24
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 0.6189
    Episode_Reward/rotating_object: 123.2606
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.89s
                      Time elapsed: 00:13:55
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 50672 steps/s (collection: 1.846s, learning 0.094s)
             Mean action noise std: 1.59
          Mean value_function loss: 81.9490
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.6555
                       Mean reward: 625.91
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 0.6163
    Episode_Reward/rotating_object: 120.7660
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.94s
                      Time elapsed: 00:13:57
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 51490 steps/s (collection: 1.808s, learning 0.101s)
             Mean action noise std: 1.59
          Mean value_function loss: 85.0789
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.6583
                       Mean reward: 605.66
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 0.6149
    Episode_Reward/rotating_object: 122.7866
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.91s
                      Time elapsed: 00:13:59
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 50865 steps/s (collection: 1.831s, learning 0.102s)
             Mean action noise std: 1.59
          Mean value_function loss: 79.5039
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.6616
                       Mean reward: 630.77
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 0.6229
    Episode_Reward/rotating_object: 123.2325
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.93s
                      Time elapsed: 00:14:01
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 50572 steps/s (collection: 1.834s, learning 0.110s)
             Mean action noise std: 1.59
          Mean value_function loss: 88.3596
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.6623
                       Mean reward: 642.15
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 0.6205
    Episode_Reward/rotating_object: 125.2187
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.94s
                      Time elapsed: 00:14:03
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 51619 steps/s (collection: 1.810s, learning 0.095s)
             Mean action noise std: 1.59
          Mean value_function loss: 81.5909
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.6655
                       Mean reward: 624.58
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 0.6273
    Episode_Reward/rotating_object: 122.0878
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.90s
                      Time elapsed: 00:14:05
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 51703 steps/s (collection: 1.793s, learning 0.108s)
             Mean action noise std: 1.59
          Mean value_function loss: 81.3883
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.6719
                       Mean reward: 617.69
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 0.6343
    Episode_Reward/rotating_object: 124.8525
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.90s
                      Time elapsed: 00:14:07
                               ETA: 00:41:48

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 51872 steps/s (collection: 1.794s, learning 0.102s)
             Mean action noise std: 1.59
          Mean value_function loss: 77.3845
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.6782
                       Mean reward: 602.27
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 0.6303
    Episode_Reward/rotating_object: 125.3614
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.90s
                      Time elapsed: 00:14:09
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 50693 steps/s (collection: 1.840s, learning 0.099s)
             Mean action noise std: 1.59
          Mean value_function loss: 87.2648
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.6805
                       Mean reward: 655.75
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.6314
    Episode_Reward/rotating_object: 122.1242
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.94s
                      Time elapsed: 00:14:11
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 50528 steps/s (collection: 1.845s, learning 0.100s)
             Mean action noise std: 1.60
          Mean value_function loss: 81.6234
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.6810
                       Mean reward: 593.17
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 0.6301
    Episode_Reward/rotating_object: 122.0177
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.95s
                      Time elapsed: 00:14:13
                               ETA: 00:41:38

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 48495 steps/s (collection: 1.927s, learning 0.100s)
             Mean action noise std: 1.60
          Mean value_function loss: 77.3855
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.6831
                       Mean reward: 637.58
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 0.6322
    Episode_Reward/rotating_object: 124.3515
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.03s
                      Time elapsed: 00:14:15
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 50718 steps/s (collection: 1.824s, learning 0.115s)
             Mean action noise std: 1.60
          Mean value_function loss: 78.2799
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.6909
                       Mean reward: 669.55
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.6445
    Episode_Reward/rotating_object: 124.2776
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.94s
                      Time elapsed: 00:14:17
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 52567 steps/s (collection: 1.776s, learning 0.094s)
             Mean action noise std: 1.60
          Mean value_function loss: 87.2305
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.6943
                       Mean reward: 612.15
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 0.6365
    Episode_Reward/rotating_object: 124.5000
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.87s
                      Time elapsed: 00:14:18
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 48921 steps/s (collection: 1.915s, learning 0.094s)
             Mean action noise std: 1.60
          Mean value_function loss: 73.0416
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.7026
                       Mean reward: 631.49
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 0.6325
    Episode_Reward/rotating_object: 125.4227
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.01s
                      Time elapsed: 00:14:20
                               ETA: 00:41:26

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 49883 steps/s (collection: 1.795s, learning 0.176s)
             Mean action noise std: 1.60
          Mean value_function loss: 76.1932
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.7086
                       Mean reward: 583.77
               Mean episode length: 229.09
    Episode_Reward/reaching_object: 0.6237
    Episode_Reward/rotating_object: 124.1373
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.97s
                      Time elapsed: 00:14:22
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 51560 steps/s (collection: 1.803s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 76.9833
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.7124
                       Mean reward: 641.86
               Mean episode length: 238.97
    Episode_Reward/reaching_object: 0.6321
    Episode_Reward/rotating_object: 126.3443
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.91s
                      Time elapsed: 00:14:24
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 52083 steps/s (collection: 1.799s, learning 0.089s)
             Mean action noise std: 1.60
          Mean value_function loss: 66.4471
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.7177
                       Mean reward: 618.58
               Mean episode length: 245.28
    Episode_Reward/reaching_object: 0.6329
    Episode_Reward/rotating_object: 125.6030
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.89s
                      Time elapsed: 00:14:26
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 52535 steps/s (collection: 1.781s, learning 0.091s)
             Mean action noise std: 1.60
          Mean value_function loss: 70.1621
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 33.7192
                       Mean reward: 623.61
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 0.6319
    Episode_Reward/rotating_object: 128.2465
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.87s
                      Time elapsed: 00:14:28
                               ETA: 00:41:14

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 51357 steps/s (collection: 1.814s, learning 0.100s)
             Mean action noise std: 1.60
          Mean value_function loss: 65.1576
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.7200
                       Mean reward: 661.53
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 0.6285
    Episode_Reward/rotating_object: 130.7695
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.91s
                      Time elapsed: 00:14:30
                               ETA: 00:41:11

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 53495 steps/s (collection: 1.742s, learning 0.096s)
             Mean action noise std: 1.60
          Mean value_function loss: 72.7995
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 33.7254
                       Mean reward: 619.06
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 0.6219
    Episode_Reward/rotating_object: 127.9205
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.84s
                      Time elapsed: 00:14:32
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 52082 steps/s (collection: 1.794s, learning 0.094s)
             Mean action noise std: 1.60
          Mean value_function loss: 65.0618
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.7354
                       Mean reward: 628.66
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 0.6136
    Episode_Reward/rotating_object: 126.7816
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 1.89s
                      Time elapsed: 00:14:34
                               ETA: 00:41:04

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 51592 steps/s (collection: 1.793s, learning 0.112s)
             Mean action noise std: 1.60
          Mean value_function loss: 68.0139
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.7388
                       Mean reward: 662.13
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 0.6163
    Episode_Reward/rotating_object: 127.9994
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 1.91s
                      Time elapsed: 00:14:36
                               ETA: 00:41:01

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 50784 steps/s (collection: 1.779s, learning 0.157s)
             Mean action noise std: 1.60
          Mean value_function loss: 61.9984
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.7436
                       Mean reward: 607.57
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.6104
    Episode_Reward/rotating_object: 127.5889
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.94s
                      Time elapsed: 00:14:38
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 50465 steps/s (collection: 1.793s, learning 0.155s)
             Mean action noise std: 1.60
          Mean value_function loss: 70.2646
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.7503
                       Mean reward: 635.25
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 0.6083
    Episode_Reward/rotating_object: 130.7920
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.95s
                      Time elapsed: 00:14:39
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 52724 steps/s (collection: 1.730s, learning 0.135s)
             Mean action noise std: 1.60
          Mean value_function loss: 73.5059
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.7581
                       Mean reward: 667.00
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 0.6108
    Episode_Reward/rotating_object: 130.5357
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.86s
                      Time elapsed: 00:14:41
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 52438 steps/s (collection: 1.767s, learning 0.108s)
             Mean action noise std: 1.60
          Mean value_function loss: 63.0180
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.7642
                       Mean reward: 626.82
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 0.6078
    Episode_Reward/rotating_object: 133.0309
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.87s
                      Time elapsed: 00:14:43
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 52572 steps/s (collection: 1.769s, learning 0.101s)
             Mean action noise std: 1.61
          Mean value_function loss: 67.6333
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.7713
                       Mean reward: 672.71
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 0.6117
    Episode_Reward/rotating_object: 133.3695
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.87s
                      Time elapsed: 00:14:45
                               ETA: 00:40:45

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 51540 steps/s (collection: 1.814s, learning 0.093s)
             Mean action noise std: 1.61
          Mean value_function loss: 74.8016
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.7848
                       Mean reward: 634.73
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 0.6109
    Episode_Reward/rotating_object: 129.6549
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.91s
                      Time elapsed: 00:14:47
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 52370 steps/s (collection: 1.779s, learning 0.098s)
             Mean action noise std: 1.61
          Mean value_function loss: 66.6387
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.7967
                       Mean reward: 621.82
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 0.6110
    Episode_Reward/rotating_object: 127.7651
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.88s
                      Time elapsed: 00:14:49
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 50948 steps/s (collection: 1.836s, learning 0.094s)
             Mean action noise std: 1.61
          Mean value_function loss: 70.7464
               Mean surrogate loss: 0.0030
                 Mean entropy loss: 33.8090
                       Mean reward: 637.42
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 0.6099
    Episode_Reward/rotating_object: 127.0779
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.93s
                      Time elapsed: 00:14:51
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 52389 steps/s (collection: 1.765s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 73.0419
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.8138
                       Mean reward: 661.15
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 0.6101
    Episode_Reward/rotating_object: 126.1603
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.88s
                      Time elapsed: 00:14:53
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 49077 steps/s (collection: 1.845s, learning 0.158s)
             Mean action noise std: 1.61
          Mean value_function loss: 72.0221
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.8235
                       Mean reward: 632.58
               Mean episode length: 238.06
    Episode_Reward/reaching_object: 0.6249
    Episode_Reward/rotating_object: 131.4181
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.00s
                      Time elapsed: 00:14:55
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 50738 steps/s (collection: 1.783s, learning 0.154s)
             Mean action noise std: 1.61
          Mean value_function loss: 72.4170
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.8402
                       Mean reward: 642.55
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 0.6302
    Episode_Reward/rotating_object: 129.3372
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.94s
                      Time elapsed: 00:14:57
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 49437 steps/s (collection: 1.838s, learning 0.150s)
             Mean action noise std: 1.61
          Mean value_function loss: 70.5079
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.8457
                       Mean reward: 692.28
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 0.6249
    Episode_Reward/rotating_object: 131.9743
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.99s
                      Time elapsed: 00:14:59
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 50847 steps/s (collection: 1.793s, learning 0.141s)
             Mean action noise std: 1.61
          Mean value_function loss: 69.1395
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.8529
                       Mean reward: 652.55
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 0.6266
    Episode_Reward/rotating_object: 131.9265
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.93s
                      Time elapsed: 00:15:01
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 51256 steps/s (collection: 1.825s, learning 0.093s)
             Mean action noise std: 1.62
          Mean value_function loss: 75.4639
               Mean surrogate loss: 0.0032
                 Mean entropy loss: 33.8676
                       Mean reward: 607.54
               Mean episode length: 229.61
    Episode_Reward/reaching_object: 0.6290
    Episode_Reward/rotating_object: 129.2755
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.92s
                      Time elapsed: 00:15:02
                               ETA: 00:40:18

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 50103 steps/s (collection: 1.825s, learning 0.137s)
             Mean action noise std: 1.62
          Mean value_function loss: 73.8509
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 33.8813
                       Mean reward: 653.22
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 0.6161
    Episode_Reward/rotating_object: 126.7023
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.96s
                      Time elapsed: 00:15:04
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 52039 steps/s (collection: 1.794s, learning 0.095s)
             Mean action noise std: 1.62
          Mean value_function loss: 75.1387
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 33.8872
                       Mean reward: 649.79
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 133.2257
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.89s
                      Time elapsed: 00:15:06
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 51001 steps/s (collection: 1.833s, learning 0.094s)
             Mean action noise std: 1.62
          Mean value_function loss: 73.0250
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.8900
                       Mean reward: 662.04
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 0.6332
    Episode_Reward/rotating_object: 132.1446
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.93s
                      Time elapsed: 00:15:08
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 42444 steps/s (collection: 2.108s, learning 0.208s)
             Mean action noise std: 1.62
          Mean value_function loss: 72.1290
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.8949
                       Mean reward: 681.94
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.6429
    Episode_Reward/rotating_object: 130.0712
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.32s
                      Time elapsed: 00:15:11
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 49984 steps/s (collection: 1.856s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 75.9789
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.9003
                       Mean reward: 664.44
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 0.6427
    Episode_Reward/rotating_object: 129.1205
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.97s
                      Time elapsed: 00:15:13
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 49724 steps/s (collection: 1.840s, learning 0.137s)
             Mean action noise std: 1.62
          Mean value_function loss: 72.2532
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.9078
                       Mean reward: 664.37
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 0.6422
    Episode_Reward/rotating_object: 130.2043
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.98s
                      Time elapsed: 00:15:15
                               ETA: 00:40:02

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 48644 steps/s (collection: 1.884s, learning 0.137s)
             Mean action noise std: 1.62
          Mean value_function loss: 71.6492
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.9255
                       Mean reward: 706.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6487
    Episode_Reward/rotating_object: 133.0484
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.02s
                      Time elapsed: 00:15:17
                               ETA: 00:39:59

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 52732 steps/s (collection: 1.767s, learning 0.097s)
             Mean action noise std: 1.62
          Mean value_function loss: 73.3461
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 33.9391
                       Mean reward: 673.98
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 0.6407
    Episode_Reward/rotating_object: 132.7067
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.86s
                      Time elapsed: 00:15:18
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 51313 steps/s (collection: 1.773s, learning 0.143s)
             Mean action noise std: 1.63
          Mean value_function loss: 75.9166
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.9558
                       Mean reward: 620.73
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 0.6404
    Episode_Reward/rotating_object: 129.2810
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.92s
                      Time elapsed: 00:15:20
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 51918 steps/s (collection: 1.801s, learning 0.092s)
             Mean action noise std: 1.63
          Mean value_function loss: 72.3471
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.9721
                       Mean reward: 660.15
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 0.6417
    Episode_Reward/rotating_object: 131.0348
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.89s
                      Time elapsed: 00:15:22
                               ETA: 00:39:50

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 52100 steps/s (collection: 1.795s, learning 0.092s)
             Mean action noise std: 1.63
          Mean value_function loss: 75.5416
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.9881
                       Mean reward: 641.61
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 0.6397
    Episode_Reward/rotating_object: 132.0578
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.89s
                      Time elapsed: 00:15:24
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 52271 steps/s (collection: 1.788s, learning 0.093s)
             Mean action noise std: 1.63
          Mean value_function loss: 67.3092
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.9986
                       Mean reward: 658.74
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 0.6334
    Episode_Reward/rotating_object: 130.1199
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.88s
                      Time elapsed: 00:15:26
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 52625 steps/s (collection: 1.775s, learning 0.093s)
             Mean action noise std: 1.63
          Mean value_function loss: 63.5489
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 34.0028
                       Mean reward: 697.22
               Mean episode length: 247.13
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 133.8436
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.87s
                      Time elapsed: 00:15:28
                               ETA: 00:39:41

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 51714 steps/s (collection: 1.790s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 62.6476
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 34.0056
                       Mean reward: 636.77
               Mean episode length: 230.48
    Episode_Reward/reaching_object: 0.6415
    Episode_Reward/rotating_object: 132.2716
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.90s
                      Time elapsed: 00:15:30
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 51603 steps/s (collection: 1.806s, learning 0.099s)
             Mean action noise std: 1.63
          Mean value_function loss: 66.4822
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.0097
                       Mean reward: 671.28
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.6455
    Episode_Reward/rotating_object: 133.1655
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.91s
                      Time elapsed: 00:15:32
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 50961 steps/s (collection: 1.826s, learning 0.103s)
             Mean action noise std: 1.63
          Mean value_function loss: 61.3767
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 34.0130
                       Mean reward: 690.14
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.6539
    Episode_Reward/rotating_object: 135.5314
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.93s
                      Time elapsed: 00:15:34
                               ETA: 00:39:32

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 51445 steps/s (collection: 1.804s, learning 0.107s)
             Mean action noise std: 1.63
          Mean value_function loss: 58.2968
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.0156
                       Mean reward: 651.06
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.6549
    Episode_Reward/rotating_object: 134.1638
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.91s
                      Time elapsed: 00:15:35
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 51424 steps/s (collection: 1.802s, learning 0.110s)
             Mean action noise std: 1.63
          Mean value_function loss: 70.2638
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.0169
                       Mean reward: 659.81
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 0.6646
    Episode_Reward/rotating_object: 135.8857
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.91s
                      Time elapsed: 00:15:37
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 51499 steps/s (collection: 1.806s, learning 0.103s)
             Mean action noise std: 1.63
          Mean value_function loss: 72.6158
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.0229
                       Mean reward: 647.34
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 0.6454
    Episode_Reward/rotating_object: 132.1404
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.91s
                      Time elapsed: 00:15:39
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 48936 steps/s (collection: 1.862s, learning 0.147s)
             Mean action noise std: 1.63
          Mean value_function loss: 72.4862
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.0346
                       Mean reward: 657.12
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 135.9397
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.01s
                      Time elapsed: 00:15:41
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 52059 steps/s (collection: 1.797s, learning 0.092s)
             Mean action noise std: 1.64
          Mean value_function loss: 58.7636
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 34.0476
                       Mean reward: 689.10
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.6484
    Episode_Reward/rotating_object: 134.4899
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.89s
                      Time elapsed: 00:15:43
                               ETA: 00:39:18

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 52701 steps/s (collection: 1.755s, learning 0.110s)
             Mean action noise std: 1.64
          Mean value_function loss: 63.9547
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.0548
                       Mean reward: 682.44
               Mean episode length: 244.95
    Episode_Reward/reaching_object: 0.6544
    Episode_Reward/rotating_object: 134.3167
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.87s
                      Time elapsed: 00:15:45
                               ETA: 00:39:15

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 52434 steps/s (collection: 1.780s, learning 0.095s)
             Mean action noise std: 1.64
          Mean value_function loss: 64.9173
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 34.0596
                       Mean reward: 688.80
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 0.6470
    Episode_Reward/rotating_object: 135.8879
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.87s
                      Time elapsed: 00:15:47
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 49431 steps/s (collection: 1.895s, learning 0.094s)
             Mean action noise std: 1.64
          Mean value_function loss: 63.3062
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.0645
                       Mean reward: 712.01
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6582
    Episode_Reward/rotating_object: 136.4414
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.99s
                      Time elapsed: 00:15:49
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 51824 steps/s (collection: 1.765s, learning 0.132s)
             Mean action noise std: 1.64
          Mean value_function loss: 63.8974
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.0748
                       Mean reward: 701.37
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 0.6529
    Episode_Reward/rotating_object: 136.7423
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.90s
                      Time elapsed: 00:15:51
                               ETA: 00:39:06

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 52128 steps/s (collection: 1.764s, learning 0.122s)
             Mean action noise std: 1.64
          Mean value_function loss: 63.7452
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.0836
                       Mean reward: 664.88
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 134.3986
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.89s
                      Time elapsed: 00:15:53
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 51065 steps/s (collection: 1.779s, learning 0.146s)
             Mean action noise std: 1.64
          Mean value_function loss: 61.6760
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.0893
                       Mean reward: 660.10
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.6494
    Episode_Reward/rotating_object: 134.5155
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.93s
                      Time elapsed: 00:15:55
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 52694 steps/s (collection: 1.770s, learning 0.096s)
             Mean action noise std: 1.64
          Mean value_function loss: 63.9120
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.1079
                       Mean reward: 648.16
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 0.6546
    Episode_Reward/rotating_object: 137.4600
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.87s
                      Time elapsed: 00:15:57
                               ETA: 00:38:57

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 53099 steps/s (collection: 1.762s, learning 0.090s)
             Mean action noise std: 1.65
          Mean value_function loss: 60.0549
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.1316
                       Mean reward: 688.98
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 0.6477
    Episode_Reward/rotating_object: 134.2039
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.85s
                      Time elapsed: 00:15:58
                               ETA: 00:38:54

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 51794 steps/s (collection: 1.805s, learning 0.093s)
             Mean action noise std: 1.65
          Mean value_function loss: 58.3035
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.1408
                       Mean reward: 721.73
               Mean episode length: 247.25
    Episode_Reward/reaching_object: 0.6565
    Episode_Reward/rotating_object: 141.0508
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.90s
                      Time elapsed: 00:16:00
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 51668 steps/s (collection: 1.791s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 66.8726
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.1484
                       Mean reward: 682.83
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.6443
    Episode_Reward/rotating_object: 135.1808
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.90s
                      Time elapsed: 00:16:02
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 52155 steps/s (collection: 1.777s, learning 0.108s)
             Mean action noise std: 1.65
          Mean value_function loss: 54.2529
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.1567
                       Mean reward: 686.12
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 0.6455
    Episode_Reward/rotating_object: 137.9075
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.88s
                      Time elapsed: 00:16:04
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 52330 steps/s (collection: 1.745s, learning 0.134s)
             Mean action noise std: 1.65
          Mean value_function loss: 53.6208
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.1656
                       Mean reward: 681.91
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 0.6408
    Episode_Reward/rotating_object: 139.3105
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.88s
                      Time elapsed: 00:16:06
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 51561 steps/s (collection: 1.745s, learning 0.162s)
             Mean action noise std: 1.65
          Mean value_function loss: 44.7567
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.1746
                       Mean reward: 664.63
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 0.6448
    Episode_Reward/rotating_object: 135.2804
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.91s
                      Time elapsed: 00:16:08
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 50370 steps/s (collection: 1.807s, learning 0.145s)
             Mean action noise std: 1.65
          Mean value_function loss: 61.9421
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.1857
                       Mean reward: 659.31
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 0.6399
    Episode_Reward/rotating_object: 135.9835
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.95s
                      Time elapsed: 00:16:10
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 47311 steps/s (collection: 1.871s, learning 0.207s)
             Mean action noise std: 1.65
          Mean value_function loss: 46.3737
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.1945
                       Mean reward: 697.78
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 141.6986
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.08s
                      Time elapsed: 00:16:12
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 52253 steps/s (collection: 1.774s, learning 0.108s)
             Mean action noise std: 1.65
          Mean value_function loss: 52.1253
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.1979
                       Mean reward: 703.51
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.6540
    Episode_Reward/rotating_object: 140.5365
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.88s
                      Time elapsed: 00:16:14
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 52286 steps/s (collection: 1.772s, learning 0.108s)
             Mean action noise std: 1.65
          Mean value_function loss: 46.3714
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 34.2027
                       Mean reward: 700.28
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.6568
    Episode_Reward/rotating_object: 141.7584
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.88s
                      Time elapsed: 00:16:16
                               ETA: 00:38:28

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 49767 steps/s (collection: 1.844s, learning 0.131s)
             Mean action noise std: 1.66
          Mean value_function loss: 55.5285
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 34.2101
                       Mean reward: 690.87
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 0.6471
    Episode_Reward/rotating_object: 133.6811
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.98s
                      Time elapsed: 00:16:18
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 51464 steps/s (collection: 1.800s, learning 0.111s)
             Mean action noise std: 1.66
          Mean value_function loss: 53.3310
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.2268
                       Mean reward: 722.12
               Mean episode length: 246.47
    Episode_Reward/reaching_object: 0.6478
    Episode_Reward/rotating_object: 139.5311
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.91s
                      Time elapsed: 00:16:20
                               ETA: 00:38:23

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 50727 steps/s (collection: 1.838s, learning 0.100s)
             Mean action noise std: 1.66
          Mean value_function loss: 57.4865
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.2472
                       Mean reward: 702.10
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 0.6484
    Episode_Reward/rotating_object: 138.6996
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.94s
                      Time elapsed: 00:16:21
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 49372 steps/s (collection: 1.874s, learning 0.117s)
             Mean action noise std: 1.66
          Mean value_function loss: 52.8929
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.2569
                       Mean reward: 698.96
               Mean episode length: 244.19
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 139.5132
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.99s
                      Time elapsed: 00:16:23
                               ETA: 00:38:18

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 51575 steps/s (collection: 1.811s, learning 0.095s)
             Mean action noise std: 1.66
          Mean value_function loss: 65.0176
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 34.2676
                       Mean reward: 734.15
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.6428
    Episode_Reward/rotating_object: 141.5718
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.91s
                      Time elapsed: 00:16:25
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 50347 steps/s (collection: 1.833s, learning 0.120s)
             Mean action noise std: 1.66
          Mean value_function loss: 50.4776
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 34.2850
                       Mean reward: 683.56
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 0.6493
    Episode_Reward/rotating_object: 141.5244
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.95s
                      Time elapsed: 00:16:27
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 51093 steps/s (collection: 1.816s, learning 0.108s)
             Mean action noise std: 1.67
          Mean value_function loss: 47.4865
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.3049
                       Mean reward: 708.88
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 0.6536
    Episode_Reward/rotating_object: 140.6412
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.92s
                      Time elapsed: 00:16:29
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 49869 steps/s (collection: 1.848s, learning 0.124s)
             Mean action noise std: 1.67
          Mean value_function loss: 40.2447
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 34.3284
                       Mean reward: 709.67
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.6530
    Episode_Reward/rotating_object: 141.7546
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.97s
                      Time elapsed: 00:16:31
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 51025 steps/s (collection: 1.815s, learning 0.112s)
             Mean action noise std: 1.67
          Mean value_function loss: 50.9045
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.3379
                       Mean reward: 727.73
               Mean episode length: 247.21
    Episode_Reward/reaching_object: 0.6545
    Episode_Reward/rotating_object: 141.0428
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.93s
                      Time elapsed: 00:16:33
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 50180 steps/s (collection: 1.854s, learning 0.105s)
             Mean action noise std: 1.67
          Mean value_function loss: 42.8912
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.3523
                       Mean reward: 722.53
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6540
    Episode_Reward/rotating_object: 140.1209
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.96s
                      Time elapsed: 00:16:35
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 50739 steps/s (collection: 1.833s, learning 0.105s)
             Mean action noise std: 1.67
          Mean value_function loss: 50.9304
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.3610
                       Mean reward: 701.95
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 0.6519
    Episode_Reward/rotating_object: 142.0232
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.94s
                      Time elapsed: 00:16:37
                               ETA: 00:37:58

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 51126 steps/s (collection: 1.807s, learning 0.116s)
             Mean action noise std: 1.67
          Mean value_function loss: 48.6959
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.3740
                       Mean reward: 685.10
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 141.4617
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.92s
                      Time elapsed: 00:16:39
                               ETA: 00:37:55

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 51234 steps/s (collection: 1.822s, learning 0.097s)
             Mean action noise std: 1.68
          Mean value_function loss: 49.5832
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.3959
                       Mean reward: 698.67
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 0.6419
    Episode_Reward/rotating_object: 137.2553
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.92s
                      Time elapsed: 00:16:41
                               ETA: 00:37:53

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 46155 steps/s (collection: 1.924s, learning 0.206s)
             Mean action noise std: 1.68
          Mean value_function loss: 52.9228
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.4118
                       Mean reward: 741.57
               Mean episode length: 246.39
    Episode_Reward/reaching_object: 0.6484
    Episode_Reward/rotating_object: 140.4453
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.13s
                      Time elapsed: 00:16:43
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 50957 steps/s (collection: 1.796s, learning 0.134s)
             Mean action noise std: 1.68
          Mean value_function loss: 59.5511
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.4289
                       Mean reward: 694.74
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 0.6355
    Episode_Reward/rotating_object: 136.3641
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.93s
                      Time elapsed: 00:16:45
                               ETA: 00:37:48

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 51301 steps/s (collection: 1.809s, learning 0.108s)
             Mean action noise std: 1.68
          Mean value_function loss: 45.5454
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.4380
                       Mean reward: 736.94
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6506
    Episode_Reward/rotating_object: 141.5031
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.92s
                      Time elapsed: 00:16:47
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 50657 steps/s (collection: 1.781s, learning 0.160s)
             Mean action noise std: 1.68
          Mean value_function loss: 48.0954
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 34.4384
                       Mean reward: 727.11
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 0.6433
    Episode_Reward/rotating_object: 142.1458
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.94s
                      Time elapsed: 00:16:49
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 53343 steps/s (collection: 1.739s, learning 0.104s)
             Mean action noise std: 1.68
          Mean value_function loss: 49.1837
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.4427
                       Mean reward: 727.58
               Mean episode length: 249.42
    Episode_Reward/reaching_object: 0.6621
    Episode_Reward/rotating_object: 143.9075
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.84s
                      Time elapsed: 00:16:51
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 52107 steps/s (collection: 1.777s, learning 0.109s)
             Mean action noise std: 1.68
          Mean value_function loss: 50.6019
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.4518
                       Mean reward: 705.60
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 0.6483
    Episode_Reward/rotating_object: 142.4992
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.89s
                      Time elapsed: 00:16:52
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 51421 steps/s (collection: 1.818s, learning 0.094s)
             Mean action noise std: 1.68
          Mean value_function loss: 43.1452
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.4553
                       Mean reward: 700.41
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 0.6565
    Episode_Reward/rotating_object: 142.1764
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.91s
                      Time elapsed: 00:16:54
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 52330 steps/s (collection: 1.777s, learning 0.102s)
             Mean action noise std: 1.68
          Mean value_function loss: 43.8470
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.4598
                       Mean reward: 742.38
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6565
    Episode_Reward/rotating_object: 141.4549
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.88s
                      Time elapsed: 00:16:56
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 51611 steps/s (collection: 1.797s, learning 0.108s)
             Mean action noise std: 1.68
          Mean value_function loss: 53.1220
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 34.4671
                       Mean reward: 717.54
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 142.0936
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.90s
                      Time elapsed: 00:16:58
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 50727 steps/s (collection: 1.807s, learning 0.131s)
             Mean action noise std: 1.69
          Mean value_function loss: 53.7281
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.4810
                       Mean reward: 749.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 142.5257
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.94s
                      Time elapsed: 00:17:00
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 48957 steps/s (collection: 1.809s, learning 0.199s)
             Mean action noise std: 1.69
          Mean value_function loss: 48.2611
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.5025
                       Mean reward: 723.29
               Mean episode length: 245.05
    Episode_Reward/reaching_object: 0.6686
    Episode_Reward/rotating_object: 141.8506
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.01s
                      Time elapsed: 00:17:02
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 50502 steps/s (collection: 1.833s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 47.5877
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 34.5290
                       Mean reward: 708.42
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 0.6601
    Episode_Reward/rotating_object: 140.8524
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.95s
                      Time elapsed: 00:17:04
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 53997 steps/s (collection: 1.728s, learning 0.092s)
             Mean action noise std: 1.69
          Mean value_function loss: 52.8299
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 34.5438
                       Mean reward: 734.67
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 0.6623
    Episode_Reward/rotating_object: 143.8479
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.82s
                      Time elapsed: 00:17:06
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 51844 steps/s (collection: 1.768s, learning 0.129s)
             Mean action noise std: 1.69
          Mean value_function loss: 38.4958
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.5550
                       Mean reward: 756.79
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6697
    Episode_Reward/rotating_object: 145.3372
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.90s
                      Time elapsed: 00:17:08
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 52499 steps/s (collection: 1.765s, learning 0.107s)
             Mean action noise std: 1.69
          Mean value_function loss: 38.8857
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.5677
                       Mean reward: 728.40
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.6715
    Episode_Reward/rotating_object: 144.5205
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.87s
                      Time elapsed: 00:17:10
                               ETA: 00:37:12

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 52938 steps/s (collection: 1.748s, learning 0.109s)
             Mean action noise std: 1.70
          Mean value_function loss: 44.7731
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.5948
                       Mean reward: 720.21
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 0.6686
    Episode_Reward/rotating_object: 143.8591
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.86s
                      Time elapsed: 00:17:12
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 51807 steps/s (collection: 1.783s, learning 0.114s)
             Mean action noise std: 1.70
          Mean value_function loss: 42.8242
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.6135
                       Mean reward: 716.00
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.6588
    Episode_Reward/rotating_object: 142.7992
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.90s
                      Time elapsed: 00:17:13
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 52734 steps/s (collection: 1.767s, learning 0.097s)
             Mean action noise std: 1.70
          Mean value_function loss: 42.0290
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.6248
                       Mean reward: 748.38
               Mean episode length: 249.35
    Episode_Reward/reaching_object: 0.6622
    Episode_Reward/rotating_object: 143.3500
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.86s
                      Time elapsed: 00:17:15
                               ETA: 00:37:03

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 49836 steps/s (collection: 1.838s, learning 0.135s)
             Mean action noise std: 1.70
          Mean value_function loss: 38.2567
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.6394
                       Mean reward: 741.34
               Mean episode length: 248.32
    Episode_Reward/reaching_object: 0.6774
    Episode_Reward/rotating_object: 145.4053
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.97s
                      Time elapsed: 00:17:17
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 51857 steps/s (collection: 1.795s, learning 0.101s)
             Mean action noise std: 1.70
          Mean value_function loss: 40.8107
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.6489
                       Mean reward: 730.48
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 0.6696
    Episode_Reward/rotating_object: 143.6066
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.90s
                      Time elapsed: 00:17:19
                               ETA: 00:36:58

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 52703 steps/s (collection: 1.746s, learning 0.119s)
             Mean action noise std: 1.70
          Mean value_function loss: 40.5970
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.6698
                       Mean reward: 723.82
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 0.6690
    Episode_Reward/rotating_object: 141.8270
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.87s
                      Time elapsed: 00:17:21
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 49515 steps/s (collection: 1.861s, learning 0.124s)
             Mean action noise std: 1.71
          Mean value_function loss: 48.2503
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 34.6828
                       Mean reward: 739.57
               Mean episode length: 246.23
    Episode_Reward/reaching_object: 0.6667
    Episode_Reward/rotating_object: 143.9003
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.99s
                      Time elapsed: 00:17:23
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 51583 steps/s (collection: 1.797s, learning 0.109s)
             Mean action noise std: 1.71
          Mean value_function loss: 56.7317
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.7010
                       Mean reward: 727.73
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.6719
    Episode_Reward/rotating_object: 143.9321
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.91s
                      Time elapsed: 00:17:25
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 51778 steps/s (collection: 1.806s, learning 0.093s)
             Mean action noise std: 1.71
          Mean value_function loss: 53.5030
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.7201
                       Mean reward: 743.69
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.6747
    Episode_Reward/rotating_object: 144.1607
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.90s
                      Time elapsed: 00:17:27
                               ETA: 00:36:47

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 53140 steps/s (collection: 1.738s, learning 0.112s)
             Mean action noise std: 1.71
          Mean value_function loss: 46.3226
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 34.7347
                       Mean reward: 730.67
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.6690
    Episode_Reward/rotating_object: 145.8291
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.85s
                      Time elapsed: 00:17:29
                               ETA: 00:36:44

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 53614 steps/s (collection: 1.727s, learning 0.106s)
             Mean action noise std: 1.72
          Mean value_function loss: 45.6709
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.7579
                       Mean reward: 694.26
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 0.6732
    Episode_Reward/rotating_object: 143.0947
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.83s
                      Time elapsed: 00:17:30
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 53202 steps/s (collection: 1.737s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 52.3087
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.7827
                       Mean reward: 725.98
               Mean episode length: 244.87
    Episode_Reward/reaching_object: 0.6685
    Episode_Reward/rotating_object: 143.1803
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.85s
                      Time elapsed: 00:17:32
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 52661 steps/s (collection: 1.768s, learning 0.099s)
             Mean action noise std: 1.72
          Mean value_function loss: 53.5667
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.8038
                       Mean reward: 717.27
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.6716
    Episode_Reward/rotating_object: 141.7440
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.87s
                      Time elapsed: 00:17:34
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 52099 steps/s (collection: 1.750s, learning 0.137s)
             Mean action noise std: 1.72
          Mean value_function loss: 47.7538
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.8144
                       Mean reward: 746.78
               Mean episode length: 246.61
    Episode_Reward/reaching_object: 0.6733
    Episode_Reward/rotating_object: 144.1548
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.89s
                      Time elapsed: 00:17:36
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 51157 steps/s (collection: 1.791s, learning 0.131s)
             Mean action noise std: 1.72
          Mean value_function loss: 40.3678
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.8203
                       Mean reward: 734.56
               Mean episode length: 244.35
    Episode_Reward/reaching_object: 0.6696
    Episode_Reward/rotating_object: 143.8281
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.92s
                      Time elapsed: 00:17:38
                               ETA: 00:36:30

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 50997 steps/s (collection: 1.790s, learning 0.137s)
             Mean action noise std: 1.72
          Mean value_function loss: 48.3986
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 34.8303
                       Mean reward: 716.44
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 0.6741
    Episode_Reward/rotating_object: 143.5686
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.93s
                      Time elapsed: 00:17:40
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 51075 steps/s (collection: 1.799s, learning 0.126s)
             Mean action noise std: 1.72
          Mean value_function loss: 55.5371
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 34.8351
                       Mean reward: 691.95
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.6745
    Episode_Reward/rotating_object: 142.3144
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.92s
                      Time elapsed: 00:17:42
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 50929 steps/s (collection: 1.835s, learning 0.095s)
             Mean action noise std: 1.73
          Mean value_function loss: 65.7243
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 34.8519
                       Mean reward: 716.16
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 0.6641
    Episode_Reward/rotating_object: 142.0883
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.93s
                      Time elapsed: 00:17:44
                               ETA: 00:36:22

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 51750 steps/s (collection: 1.794s, learning 0.106s)
             Mean action noise std: 1.73
          Mean value_function loss: 61.9775
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.8823
                       Mean reward: 683.45
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 0.6713
    Episode_Reward/rotating_object: 139.4189
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.90s
                      Time elapsed: 00:17:46
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 52688 steps/s (collection: 1.758s, learning 0.108s)
             Mean action noise std: 1.73
          Mean value_function loss: 59.6290
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 34.9063
                       Mean reward: 740.64
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.6904
    Episode_Reward/rotating_object: 143.6774
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.87s
                      Time elapsed: 00:17:48
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 49403 steps/s (collection: 1.864s, learning 0.126s)
             Mean action noise std: 1.74
          Mean value_function loss: 49.4152
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 34.9328
                       Mean reward: 711.95
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 0.6870
    Episode_Reward/rotating_object: 141.5875
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 1.99s
                      Time elapsed: 00:17:50
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 52259 steps/s (collection: 1.758s, learning 0.123s)
             Mean action noise std: 1.74
          Mean value_function loss: 52.7112
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 34.9613
                       Mean reward: 682.76
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 0.6855
    Episode_Reward/rotating_object: 141.4669
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.88s
                      Time elapsed: 00:17:51
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 53012 steps/s (collection: 1.747s, learning 0.108s)
             Mean action noise std: 1.74
          Mean value_function loss: 53.9445
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 34.9723
                       Mean reward: 694.13
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 0.6784
    Episode_Reward/rotating_object: 140.4416
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.85s
                      Time elapsed: 00:17:53
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 52236 steps/s (collection: 1.746s, learning 0.135s)
             Mean action noise std: 1.74
          Mean value_function loss: 53.0559
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.9868
                       Mean reward: 735.85
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 0.6853
    Episode_Reward/rotating_object: 143.9396
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.88s
                      Time elapsed: 00:17:55
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 51130 steps/s (collection: 1.767s, learning 0.156s)
             Mean action noise std: 1.74
          Mean value_function loss: 47.4721
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 34.9961
                       Mean reward: 727.56
               Mean episode length: 247.00
    Episode_Reward/reaching_object: 0.6929
    Episode_Reward/rotating_object: 144.1620
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.92s
                      Time elapsed: 00:17:57
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 52467 steps/s (collection: 1.740s, learning 0.134s)
             Mean action noise std: 1.74
          Mean value_function loss: 46.7000
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.0169
                       Mean reward: 743.51
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 143.9298
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.87s
                      Time elapsed: 00:17:59
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 51579 steps/s (collection: 1.769s, learning 0.137s)
             Mean action noise std: 1.75
          Mean value_function loss: 55.9957
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.0392
                       Mean reward: 692.61
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 0.6873
    Episode_Reward/rotating_object: 142.6836
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.91s
                      Time elapsed: 00:18:01
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 49769 steps/s (collection: 1.849s, learning 0.127s)
             Mean action noise std: 1.75
          Mean value_function loss: 48.0338
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.0580
                       Mean reward: 710.72
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 0.6934
    Episode_Reward/rotating_object: 146.1619
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.98s
                      Time elapsed: 00:18:03
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 51715 steps/s (collection: 1.796s, learning 0.105s)
             Mean action noise std: 1.75
          Mean value_function loss: 48.3033
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.0749
                       Mean reward: 702.83
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 0.6913
    Episode_Reward/rotating_object: 142.6373
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.90s
                      Time elapsed: 00:18:05
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 52181 steps/s (collection: 1.782s, learning 0.102s)
             Mean action noise std: 1.75
          Mean value_function loss: 56.1241
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.0929
                       Mean reward: 738.96
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.7003
    Episode_Reward/rotating_object: 145.7222
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.88s
                      Time elapsed: 00:18:07
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 51744 steps/s (collection: 1.792s, learning 0.108s)
             Mean action noise std: 1.75
          Mean value_function loss: 50.3733
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.1157
                       Mean reward: 738.87
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7049
    Episode_Reward/rotating_object: 145.3000
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.90s
                      Time elapsed: 00:18:09
                               ETA: 00:35:47

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 52235 steps/s (collection: 1.772s, learning 0.110s)
             Mean action noise std: 1.76
          Mean value_function loss: 51.8259
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.1405
                       Mean reward: 694.69
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 0.7042
    Episode_Reward/rotating_object: 146.2161
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.88s
                      Time elapsed: 00:18:10
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 50598 steps/s (collection: 1.841s, learning 0.102s)
             Mean action noise std: 1.76
          Mean value_function loss: 55.2254
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.1656
                       Mean reward: 701.53
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 0.7014
    Episode_Reward/rotating_object: 142.5419
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.94s
                      Time elapsed: 00:18:12
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 51687 steps/s (collection: 1.793s, learning 0.109s)
             Mean action noise std: 1.76
          Mean value_function loss: 47.6019
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.1962
                       Mean reward: 716.81
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 0.7107
    Episode_Reward/rotating_object: 145.5865
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.90s
                      Time elapsed: 00:18:14
                               ETA: 00:35:39

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 50513 steps/s (collection: 1.791s, learning 0.155s)
             Mean action noise std: 1.77
          Mean value_function loss: 35.2150
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.2244
                       Mean reward: 713.73
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 0.6989
    Episode_Reward/rotating_object: 140.6489
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.95s
                      Time elapsed: 00:18:16
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 52099 steps/s (collection: 1.767s, learning 0.120s)
             Mean action noise std: 1.77
          Mean value_function loss: 48.4109
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.2469
                       Mean reward: 737.22
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 0.7091
    Episode_Reward/rotating_object: 146.5827
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.89s
                      Time elapsed: 00:18:18
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 51594 steps/s (collection: 1.766s, learning 0.140s)
             Mean action noise std: 1.77
          Mean value_function loss: 55.1859
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.2629
                       Mean reward: 720.56
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 0.7042
    Episode_Reward/rotating_object: 143.0558
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.91s
                      Time elapsed: 00:18:20
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 51416 steps/s (collection: 1.789s, learning 0.123s)
             Mean action noise std: 1.77
          Mean value_function loss: 59.5104
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 35.2851
                       Mean reward: 696.46
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 0.7098
    Episode_Reward/rotating_object: 146.6703
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.91s
                      Time elapsed: 00:18:22
                               ETA: 00:35:29

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 50961 steps/s (collection: 1.817s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 55.0013
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.3038
                       Mean reward: 726.89
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.7069
    Episode_Reward/rotating_object: 144.8508
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.93s
                      Time elapsed: 00:18:24
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 50897 steps/s (collection: 1.837s, learning 0.094s)
             Mean action noise std: 1.78
          Mean value_function loss: 64.6052
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.3209
                       Mean reward: 681.47
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 0.6852
    Episode_Reward/rotating_object: 137.9531
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.93s
                      Time elapsed: 00:18:26
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 50161 steps/s (collection: 1.862s, learning 0.098s)
             Mean action noise std: 1.78
          Mean value_function loss: 50.1652
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.3288
                       Mean reward: 728.97
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 0.6960
    Episode_Reward/rotating_object: 143.2587
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.96s
                      Time elapsed: 00:18:28
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 52132 steps/s (collection: 1.791s, learning 0.095s)
             Mean action noise std: 1.78
          Mean value_function loss: 36.5987
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 35.3427
                       Mean reward: 748.31
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7087
    Episode_Reward/rotating_object: 148.4029
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.89s
                      Time elapsed: 00:18:30
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 52081 steps/s (collection: 1.787s, learning 0.101s)
             Mean action noise std: 1.78
          Mean value_function loss: 55.1551
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 35.3656
                       Mean reward: 686.46
               Mean episode length: 235.37
    Episode_Reward/reaching_object: 0.7025
    Episode_Reward/rotating_object: 144.3199
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.89s
                      Time elapsed: 00:18:32
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 53283 steps/s (collection: 1.737s, learning 0.107s)
             Mean action noise std: 1.78
          Mean value_function loss: 43.1513
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.3904
                       Mean reward: 737.46
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 0.7002
    Episode_Reward/rotating_object: 146.3057
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.84s
                      Time elapsed: 00:18:33
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 52375 steps/s (collection: 1.785s, learning 0.092s)
             Mean action noise std: 1.79
          Mean value_function loss: 45.9933
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.4080
                       Mean reward: 743.80
               Mean episode length: 246.89
    Episode_Reward/reaching_object: 0.7037
    Episode_Reward/rotating_object: 144.8181
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.88s
                      Time elapsed: 00:18:35
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 51032 steps/s (collection: 1.772s, learning 0.154s)
             Mean action noise std: 1.79
          Mean value_function loss: 33.9558
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.4260
                       Mean reward: 713.79
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 0.7048
    Episode_Reward/rotating_object: 142.3404
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.93s
                      Time elapsed: 00:18:37
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 50986 steps/s (collection: 1.790s, learning 0.138s)
             Mean action noise std: 1.79
          Mean value_function loss: 48.1714
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 35.4357
                       Mean reward: 711.05
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 0.7087
    Episode_Reward/rotating_object: 143.8287
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.93s
                      Time elapsed: 00:18:39
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 51491 steps/s (collection: 1.792s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 44.1594
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.4616
                       Mean reward: 709.52
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 0.7028
    Episode_Reward/rotating_object: 145.5047
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.91s
                      Time elapsed: 00:18:41
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 51457 steps/s (collection: 1.812s, learning 0.098s)
             Mean action noise std: 1.79
          Mean value_function loss: 40.7333
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.4817
                       Mean reward: 720.64
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.7076
    Episode_Reward/rotating_object: 147.7224
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.91s
                      Time elapsed: 00:18:43
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 52183 steps/s (collection: 1.787s, learning 0.097s)
             Mean action noise std: 1.80
          Mean value_function loss: 48.6726
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 35.5010
                       Mean reward: 757.79
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.7087
    Episode_Reward/rotating_object: 146.0940
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.88s
                      Time elapsed: 00:18:45
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 51936 steps/s (collection: 1.794s, learning 0.099s)
             Mean action noise std: 1.80
          Mean value_function loss: 46.5003
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.5313
                       Mean reward: 757.33
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7115
    Episode_Reward/rotating_object: 147.4159
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 1.89s
                      Time elapsed: 00:18:47
                               ETA: 00:34:55

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 52587 steps/s (collection: 1.779s, learning 0.091s)
             Mean action noise std: 1.80
          Mean value_function loss: 45.6570
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.5609
                       Mean reward: 742.28
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 146.3476
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.87s
                      Time elapsed: 00:18:49
                               ETA: 00:34:52

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 51999 steps/s (collection: 1.792s, learning 0.098s)
             Mean action noise std: 1.81
          Mean value_function loss: 46.9744
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.5894
                       Mean reward: 701.64
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 146.0716
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.89s
                      Time elapsed: 00:18:50
                               ETA: 00:34:50

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 51248 steps/s (collection: 1.827s, learning 0.091s)
             Mean action noise std: 1.81
          Mean value_function loss: 40.2342
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.6176
                       Mean reward: 750.25
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 0.7122
    Episode_Reward/rotating_object: 145.5762
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.92s
                      Time elapsed: 00:18:52
                               ETA: 00:34:47

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 51334 steps/s (collection: 1.792s, learning 0.123s)
             Mean action noise std: 1.81
          Mean value_function loss: 47.9040
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.6338
                       Mean reward: 743.13
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.7154
    Episode_Reward/rotating_object: 146.9160
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.91s
                      Time elapsed: 00:18:54
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 51806 steps/s (collection: 1.799s, learning 0.098s)
             Mean action noise std: 1.81
          Mean value_function loss: 45.0550
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 35.6417
                       Mean reward: 716.54
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 0.7129
    Episode_Reward/rotating_object: 143.9120
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.90s
                      Time elapsed: 00:18:56
                               ETA: 00:34:42

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 49127 steps/s (collection: 1.880s, learning 0.121s)
             Mean action noise std: 1.81
          Mean value_function loss: 53.1594
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.6610
                       Mean reward: 694.29
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 141.8276
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.00s
                      Time elapsed: 00:18:58
                               ETA: 00:34:40

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 49086 steps/s (collection: 1.821s, learning 0.182s)
             Mean action noise std: 1.82
          Mean value_function loss: 46.8433
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.6810
                       Mean reward: 707.29
               Mean episode length: 240.38
    Episode_Reward/reaching_object: 0.7033
    Episode_Reward/rotating_object: 143.1020
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.00s
                      Time elapsed: 00:19:00
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 51969 steps/s (collection: 1.774s, learning 0.118s)
             Mean action noise std: 1.82
          Mean value_function loss: 45.6163
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 35.6984
                       Mean reward: 743.66
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 0.7134
    Episode_Reward/rotating_object: 145.8201
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.89s
                      Time elapsed: 00:19:02
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 50358 steps/s (collection: 1.842s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 40.4159
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 35.7230
                       Mean reward: 727.45
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 145.5670
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.95s
                      Time elapsed: 00:19:04
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 50987 steps/s (collection: 1.813s, learning 0.115s)
             Mean action noise std: 1.82
          Mean value_function loss: 43.1825
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.7437
                       Mean reward: 768.07
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.7093
    Episode_Reward/rotating_object: 145.1103
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.93s
                      Time elapsed: 00:19:06
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 53016 steps/s (collection: 1.761s, learning 0.094s)
             Mean action noise std: 1.82
          Mean value_function loss: 34.8157
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.7573
                       Mean reward: 752.53
               Mean episode length: 247.13
    Episode_Reward/reaching_object: 0.7231
    Episode_Reward/rotating_object: 148.2503
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.85s
                      Time elapsed: 00:19:08
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 50919 steps/s (collection: 1.821s, learning 0.109s)
             Mean action noise std: 1.83
          Mean value_function loss: 47.9775
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.7690
                       Mean reward: 686.45
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 145.7408
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.93s
                      Time elapsed: 00:19:10
                               ETA: 00:34:24

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 52118 steps/s (collection: 1.778s, learning 0.108s)
             Mean action noise std: 1.83
          Mean value_function loss: 51.3322
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.7884
                       Mean reward: 733.27
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 0.7090
    Episode_Reward/rotating_object: 147.1503
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.89s
                      Time elapsed: 00:19:12
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 49233 steps/s (collection: 1.867s, learning 0.130s)
             Mean action noise std: 1.83
          Mean value_function loss: 34.8842
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.8118
                       Mean reward: 723.72
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.7229
    Episode_Reward/rotating_object: 148.9551
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.00s
                      Time elapsed: 00:19:14
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 50194 steps/s (collection: 1.805s, learning 0.153s)
             Mean action noise std: 1.83
          Mean value_function loss: 39.8839
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.8249
                       Mean reward: 763.42
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.7205
    Episode_Reward/rotating_object: 150.0205
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.96s
                      Time elapsed: 00:19:16
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 52381 steps/s (collection: 1.779s, learning 0.098s)
             Mean action noise std: 1.83
          Mean value_function loss: 35.9477
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.8377
                       Mean reward: 738.51
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 0.7154
    Episode_Reward/rotating_object: 147.4765
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.88s
                      Time elapsed: 00:19:17
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 52925 steps/s (collection: 1.739s, learning 0.118s)
             Mean action noise std: 1.84
          Mean value_function loss: 37.2877
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 35.8543
                       Mean reward: 743.76
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.7179
    Episode_Reward/rotating_object: 145.0933
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.86s
                      Time elapsed: 00:19:19
                               ETA: 00:34:12

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 53033 steps/s (collection: 1.760s, learning 0.094s)
             Mean action noise std: 1.84
          Mean value_function loss: 44.9357
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.8757
                       Mean reward: 727.77
               Mean episode length: 240.43
    Episode_Reward/reaching_object: 0.7165
    Episode_Reward/rotating_object: 145.5005
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.85s
                      Time elapsed: 00:19:21
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 52656 steps/s (collection: 1.749s, learning 0.118s)
             Mean action noise std: 1.84
          Mean value_function loss: 40.3103
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.8914
                       Mean reward: 755.49
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 0.7201
    Episode_Reward/rotating_object: 148.0176
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.87s
                      Time elapsed: 00:19:23
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 52524 steps/s (collection: 1.755s, learning 0.117s)
             Mean action noise std: 1.84
          Mean value_function loss: 44.8515
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.9085
                       Mean reward: 742.73
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 149.0994
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.87s
                      Time elapsed: 00:19:25
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 52824 steps/s (collection: 1.750s, learning 0.111s)
             Mean action noise std: 1.85
          Mean value_function loss: 42.2294
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.9334
                       Mean reward: 752.38
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.7250
    Episode_Reward/rotating_object: 148.8066
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 1.86s
                      Time elapsed: 00:19:27
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 51137 steps/s (collection: 1.805s, learning 0.117s)
             Mean action noise std: 1.85
          Mean value_function loss: 36.0781
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.9474
                       Mean reward: 770.57
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.7311
    Episode_Reward/rotating_object: 149.8723
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 1.92s
                      Time elapsed: 00:19:29
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 51912 steps/s (collection: 1.791s, learning 0.102s)
             Mean action noise std: 1.85
          Mean value_function loss: 43.6918
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.9619
                       Mean reward: 742.66
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.7225
    Episode_Reward/rotating_object: 148.3637
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.89s
                      Time elapsed: 00:19:31
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 51673 steps/s (collection: 1.790s, learning 0.112s)
             Mean action noise std: 1.85
          Mean value_function loss: 49.6970
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.9799
                       Mean reward: 744.35
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 0.7225
    Episode_Reward/rotating_object: 148.6904
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 1.90s
                      Time elapsed: 00:19:32
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 52077 steps/s (collection: 1.775s, learning 0.113s)
             Mean action noise std: 1.85
          Mean value_function loss: 42.9907
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.0021
                       Mean reward: 701.37
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 0.7121
    Episode_Reward/rotating_object: 142.0887
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.89s
                      Time elapsed: 00:19:34
                               ETA: 00:33:51

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 52607 steps/s (collection: 1.760s, learning 0.109s)
             Mean action noise std: 1.86
          Mean value_function loss: 35.0149
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.0257
                       Mean reward: 731.07
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 146.6293
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 1.87s
                      Time elapsed: 00:19:36
                               ETA: 00:33:48

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 47111 steps/s (collection: 1.950s, learning 0.137s)
             Mean action noise std: 1.86
          Mean value_function loss: 39.1103
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.0478
                       Mean reward: 729.53
               Mean episode length: 240.43
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 145.3551
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.09s
                      Time elapsed: 00:19:38
                               ETA: 00:33:46

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 43185 steps/s (collection: 2.117s, learning 0.159s)
             Mean action noise std: 1.86
          Mean value_function loss: 34.1842
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.0639
                       Mean reward: 786.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 149.9838
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.28s
                      Time elapsed: 00:19:41
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 45351 steps/s (collection: 1.987s, learning 0.181s)
             Mean action noise std: 1.86
          Mean value_function loss: 42.1262
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 36.0784
                       Mean reward: 766.18
               Mean episode length: 246.14
    Episode_Reward/reaching_object: 0.7394
    Episode_Reward/rotating_object: 151.0690
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.17s
                      Time elapsed: 00:19:43
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 46561 steps/s (collection: 1.966s, learning 0.145s)
             Mean action noise std: 1.87
          Mean value_function loss: 38.6678
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.1080
                       Mean reward: 766.38
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7323
    Episode_Reward/rotating_object: 148.1555
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.11s
                      Time elapsed: 00:19:45
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 48654 steps/s (collection: 1.860s, learning 0.160s)
             Mean action noise std: 1.87
          Mean value_function loss: 36.1288
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.1269
                       Mean reward: 720.64
               Mean episode length: 242.48
    Episode_Reward/reaching_object: 0.7388
    Episode_Reward/rotating_object: 149.8498
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.02s
                      Time elapsed: 00:19:47
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 47857 steps/s (collection: 1.871s, learning 0.183s)
             Mean action noise std: 1.87
          Mean value_function loss: 35.4753
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.1420
                       Mean reward: 766.82
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 151.6425
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.05s
                      Time elapsed: 00:19:49
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 48005 steps/s (collection: 1.899s, learning 0.149s)
             Mean action noise std: 1.87
          Mean value_function loss: 31.1600
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.1670
                       Mean reward: 732.29
               Mean episode length: 245.00
    Episode_Reward/reaching_object: 0.7362
    Episode_Reward/rotating_object: 149.4164
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.05s
                      Time elapsed: 00:19:51
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 47143 steps/s (collection: 1.919s, learning 0.166s)
             Mean action noise std: 1.88
          Mean value_function loss: 38.3362
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.1966
                       Mean reward: 736.54
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 0.7360
    Episode_Reward/rotating_object: 148.1877
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.09s
                      Time elapsed: 00:19:53
                               ETA: 00:33:31

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 45607 steps/s (collection: 1.979s, learning 0.176s)
             Mean action noise std: 1.88
          Mean value_function loss: 47.2250
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 36.2206
                       Mean reward: 752.21
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 0.7305
    Episode_Reward/rotating_object: 148.1994
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.16s
                      Time elapsed: 00:19:55
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 48659 steps/s (collection: 1.900s, learning 0.121s)
             Mean action noise std: 1.88
          Mean value_function loss: 39.1672
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.2447
                       Mean reward: 749.69
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 147.1689
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.02s
                      Time elapsed: 00:19:57
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 48662 steps/s (collection: 1.854s, learning 0.167s)
             Mean action noise std: 1.89
          Mean value_function loss: 37.1738
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.2661
                       Mean reward: 751.61
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.7262
    Episode_Reward/rotating_object: 149.1458
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.02s
                      Time elapsed: 00:19:59
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 48154 steps/s (collection: 1.862s, learning 0.179s)
             Mean action noise std: 1.89
          Mean value_function loss: 46.1475
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.2839
                       Mean reward: 724.56
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 0.7264
    Episode_Reward/rotating_object: 147.9935
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.04s
                      Time elapsed: 00:20:01
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 49299 steps/s (collection: 1.818s, learning 0.176s)
             Mean action noise std: 1.89
          Mean value_function loss: 44.1257
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.2995
                       Mean reward: 755.51
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 145.6896
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.99s
                      Time elapsed: 00:20:03
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 48559 steps/s (collection: 1.868s, learning 0.157s)
             Mean action noise std: 1.89
          Mean value_function loss: 35.2734
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.3235
                       Mean reward: 739.72
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.7283
    Episode_Reward/rotating_object: 150.8554
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 18.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.02s
                      Time elapsed: 00:20:05
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 48448 steps/s (collection: 1.863s, learning 0.167s)
             Mean action noise std: 1.89
          Mean value_function loss: 41.7966
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.3394
                       Mean reward: 731.28
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 147.2943
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.03s
                      Time elapsed: 00:20:07
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 47221 steps/s (collection: 1.890s, learning 0.192s)
             Mean action noise std: 1.90
          Mean value_function loss: 39.1860
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.3660
                       Mean reward: 762.78
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 150.9838
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.08s
                      Time elapsed: 00:20:09
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 47297 steps/s (collection: 1.888s, learning 0.191s)
             Mean action noise std: 1.90
          Mean value_function loss: 33.5521
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 36.3873
                       Mean reward: 740.08
               Mean episode length: 243.32
    Episode_Reward/reaching_object: 0.7213
    Episode_Reward/rotating_object: 148.3312
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.08s
                      Time elapsed: 00:20:12
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 47453 steps/s (collection: 1.867s, learning 0.205s)
             Mean action noise std: 1.90
          Mean value_function loss: 32.8461
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 36.4110
                       Mean reward: 768.74
               Mean episode length: 248.70
    Episode_Reward/reaching_object: 0.7294
    Episode_Reward/rotating_object: 151.1787
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.07s
                      Time elapsed: 00:20:14
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 46653 steps/s (collection: 1.932s, learning 0.176s)
             Mean action noise std: 1.91
          Mean value_function loss: 37.6511
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.4349
                       Mean reward: 716.39
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 150.8474
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.11s
                      Time elapsed: 00:20:16
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 49130 steps/s (collection: 1.856s, learning 0.145s)
             Mean action noise std: 1.91
          Mean value_function loss: 31.4266
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.4613
                       Mean reward: 758.71
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 147.9082
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.00s
                      Time elapsed: 00:20:18
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 49119 steps/s (collection: 1.860s, learning 0.141s)
             Mean action noise std: 1.91
          Mean value_function loss: 31.8613
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.4814
                       Mean reward: 757.59
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7254
    Episode_Reward/rotating_object: 150.6165
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.00s
                      Time elapsed: 00:20:20
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 46136 steps/s (collection: 1.960s, learning 0.170s)
             Mean action noise std: 1.91
          Mean value_function loss: 40.6854
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.5048
                       Mean reward: 748.66
               Mean episode length: 246.34
    Episode_Reward/reaching_object: 0.7203
    Episode_Reward/rotating_object: 147.5655
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.13s
                      Time elapsed: 00:20:22
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 46727 steps/s (collection: 1.944s, learning 0.160s)
             Mean action noise std: 1.92
          Mean value_function loss: 43.2762
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.5152
                       Mean reward: 716.62
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 0.7235
    Episode_Reward/rotating_object: 148.4245
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.10s
                      Time elapsed: 00:20:24
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 47839 steps/s (collection: 1.876s, learning 0.179s)
             Mean action noise std: 1.92
          Mean value_function loss: 38.7629
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.5289
                       Mean reward: 752.13
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.7186
    Episode_Reward/rotating_object: 149.5690
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.05s
                      Time elapsed: 00:20:26
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 48927 steps/s (collection: 1.871s, learning 0.138s)
             Mean action noise std: 1.92
          Mean value_function loss: 33.3058
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.5328
                       Mean reward: 771.59
               Mean episode length: 244.35
    Episode_Reward/reaching_object: 0.7253
    Episode_Reward/rotating_object: 151.5915
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.01s
                      Time elapsed: 00:20:28
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 48157 steps/s (collection: 1.879s, learning 0.162s)
             Mean action noise std: 1.92
          Mean value_function loss: 50.2967
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 36.5376
                       Mean reward: 758.06
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 148.6782
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.04s
                      Time elapsed: 00:20:30
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 47274 steps/s (collection: 1.910s, learning 0.169s)
             Mean action noise std: 1.92
          Mean value_function loss: 44.9197
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.5551
                       Mean reward: 748.59
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 0.7315
    Episode_Reward/rotating_object: 150.8813
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.08s
                      Time elapsed: 00:20:32
                               ETA: 00:32:48

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 48011 steps/s (collection: 1.876s, learning 0.172s)
             Mean action noise std: 1.92
          Mean value_function loss: 40.7815
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.5772
                       Mean reward: 770.81
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 151.1278
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.05s
                      Time elapsed: 00:20:34
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 48656 steps/s (collection: 1.870s, learning 0.151s)
             Mean action noise std: 1.92
          Mean value_function loss: 43.5611
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 36.5965
                       Mean reward: 754.55
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 0.7230
    Episode_Reward/rotating_object: 149.5611
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.02s
                      Time elapsed: 00:20:36
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 47468 steps/s (collection: 1.912s, learning 0.159s)
             Mean action noise std: 1.93
          Mean value_function loss: 38.8990
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 36.6112
                       Mean reward: 781.72
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7361
    Episode_Reward/rotating_object: 152.4131
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.07s
                      Time elapsed: 00:20:38
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 48218 steps/s (collection: 1.896s, learning 0.143s)
             Mean action noise std: 1.93
          Mean value_function loss: 36.2849
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.6290
                       Mean reward: 770.21
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 149.9315
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.04s
                      Time elapsed: 00:20:40
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 48082 steps/s (collection: 1.872s, learning 0.172s)
             Mean action noise std: 1.93
          Mean value_function loss: 44.7169
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 36.6522
                       Mean reward: 747.90
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 0.7191
    Episode_Reward/rotating_object: 149.0588
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.04s
                      Time elapsed: 00:20:42
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 48164 steps/s (collection: 1.865s, learning 0.176s)
             Mean action noise std: 1.94
          Mean value_function loss: 32.5359
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.6868
                       Mean reward: 757.27
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 0.7275
    Episode_Reward/rotating_object: 149.9410
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.04s
                      Time elapsed: 00:20:44
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 47048 steps/s (collection: 1.945s, learning 0.145s)
             Mean action noise std: 1.94
          Mean value_function loss: 35.7036
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.7233
                       Mean reward: 770.09
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 151.7519
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.09s
                      Time elapsed: 00:20:46
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 48645 steps/s (collection: 1.866s, learning 0.155s)
             Mean action noise std: 1.94
          Mean value_function loss: 36.6243
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.7541
                       Mean reward: 747.21
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7298
    Episode_Reward/rotating_object: 152.5728
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.02s
                      Time elapsed: 00:20:48
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 47913 steps/s (collection: 1.842s, learning 0.210s)
             Mean action noise std: 1.95
          Mean value_function loss: 37.9655
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.7806
                       Mean reward: 733.33
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 147.0136
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.05s
                      Time elapsed: 00:20:51
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 47425 steps/s (collection: 1.916s, learning 0.157s)
             Mean action noise std: 1.95
          Mean value_function loss: 43.0490
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.8017
                       Mean reward: 742.13
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7270
    Episode_Reward/rotating_object: 150.6168
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.07s
                      Time elapsed: 00:20:53
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 47279 steps/s (collection: 1.924s, learning 0.155s)
             Mean action noise std: 1.95
          Mean value_function loss: 34.8020
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.8252
                       Mean reward: 771.12
               Mean episode length: 246.46
    Episode_Reward/reaching_object: 0.7311
    Episode_Reward/rotating_object: 152.3387
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.08s
                      Time elapsed: 00:20:55
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 47141 steps/s (collection: 1.973s, learning 0.112s)
             Mean action noise std: 1.95
          Mean value_function loss: 37.8456
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 36.8442
                       Mean reward: 707.47
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 0.7219
    Episode_Reward/rotating_object: 150.0428
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.09s
                      Time elapsed: 00:20:57
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 49622 steps/s (collection: 1.868s, learning 0.113s)
             Mean action noise std: 1.96
          Mean value_function loss: 35.2481
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 36.8565
                       Mean reward: 776.59
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7266
    Episode_Reward/rotating_object: 150.6207
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.98s
                      Time elapsed: 00:20:59
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 46851 steps/s (collection: 1.911s, learning 0.188s)
             Mean action noise std: 1.96
          Mean value_function loss: 49.0029
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.8726
                       Mean reward: 730.83
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 0.7248
    Episode_Reward/rotating_object: 149.1260
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.10s
                      Time elapsed: 00:21:01
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 48343 steps/s (collection: 1.887s, learning 0.147s)
             Mean action noise std: 1.96
          Mean value_function loss: 43.6707
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 36.8901
                       Mean reward: 763.02
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.7221
    Episode_Reward/rotating_object: 146.8778
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.03s
                      Time elapsed: 00:21:03
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 47761 steps/s (collection: 1.882s, learning 0.177s)
             Mean action noise std: 1.96
          Mean value_function loss: 36.5139
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 36.9096
                       Mean reward: 740.52
               Mean episode length: 242.15
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 148.4042
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.06s
                      Time elapsed: 00:21:05
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 47521 steps/s (collection: 1.937s, learning 0.132s)
             Mean action noise std: 1.97
          Mean value_function loss: 45.0668
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.9297
                       Mean reward: 775.32
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 150.3382
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.07s
                      Time elapsed: 00:21:07
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 48216 steps/s (collection: 1.913s, learning 0.126s)
             Mean action noise std: 1.97
          Mean value_function loss: 47.6926
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.9569
                       Mean reward: 733.69
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.7188
    Episode_Reward/rotating_object: 145.6003
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.04s
                      Time elapsed: 00:21:09
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 47230 steps/s (collection: 1.946s, learning 0.136s)
             Mean action noise std: 1.97
          Mean value_function loss: 39.1501
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.9714
                       Mean reward: 745.51
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.7396
    Episode_Reward/rotating_object: 151.5326
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.08s
                      Time elapsed: 00:21:11
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 47920 steps/s (collection: 1.928s, learning 0.123s)
             Mean action noise std: 1.97
          Mean value_function loss: 36.3601
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.9860
                       Mean reward: 769.70
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 151.7717
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.05s
                      Time elapsed: 00:21:13
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 44738 steps/s (collection: 2.003s, learning 0.195s)
             Mean action noise std: 1.97
          Mean value_function loss: 46.0297
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.0036
                       Mean reward: 746.27
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 0.7323
    Episode_Reward/rotating_object: 147.4223
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.20s
                      Time elapsed: 00:21:15
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 45983 steps/s (collection: 2.000s, learning 0.138s)
             Mean action noise std: 1.98
          Mean value_function loss: 39.5601
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.0252
                       Mean reward: 761.59
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 147.7517
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.14s
                      Time elapsed: 00:21:18
                               ETA: 00:31:59

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 41358 steps/s (collection: 2.188s, learning 0.189s)
             Mean action noise std: 1.98
          Mean value_function loss: 36.0066
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.0517
                       Mean reward: 750.76
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 149.9879
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.38s
                      Time elapsed: 00:21:20
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 45477 steps/s (collection: 2.035s, learning 0.127s)
             Mean action noise std: 1.98
          Mean value_function loss: 36.8693
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 37.0710
                       Mean reward: 762.86
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 146.9352
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.16s
                      Time elapsed: 00:21:22
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 47835 steps/s (collection: 1.903s, learning 0.152s)
             Mean action noise std: 1.98
          Mean value_function loss: 44.2466
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.0790
                       Mean reward: 751.31
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 147.7258
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.06s
                      Time elapsed: 00:21:24
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 46605 steps/s (collection: 1.949s, learning 0.160s)
             Mean action noise std: 1.98
          Mean value_function loss: 39.2673
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.0930
                       Mean reward: 733.77
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 0.7461
    Episode_Reward/rotating_object: 146.2208
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.11s
                      Time elapsed: 00:21:26
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 47585 steps/s (collection: 1.924s, learning 0.142s)
             Mean action noise std: 1.99
          Mean value_function loss: 41.0216
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 37.1119
                       Mean reward: 744.11
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 0.7668
    Episode_Reward/rotating_object: 151.2628
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.07s
                      Time elapsed: 00:21:28
                               ETA: 00:31:48

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 45990 steps/s (collection: 1.965s, learning 0.172s)
             Mean action noise std: 1.99
          Mean value_function loss: 35.7796
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.1421
                       Mean reward: 738.76
               Mean episode length: 246.63
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 151.2485
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.14s
                      Time elapsed: 00:21:30
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 46312 steps/s (collection: 1.933s, learning 0.189s)
             Mean action noise std: 1.99
          Mean value_function loss: 40.6372
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.1577
                       Mean reward: 759.77
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.7589
    Episode_Reward/rotating_object: 151.9227
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.12s
                      Time elapsed: 00:21:33
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 47513 steps/s (collection: 1.932s, learning 0.137s)
             Mean action noise std: 2.00
          Mean value_function loss: 29.9603
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.1792
                       Mean reward: 748.80
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7599
    Episode_Reward/rotating_object: 152.5240
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.07s
                      Time elapsed: 00:21:35
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 46043 steps/s (collection: 1.958s, learning 0.177s)
             Mean action noise std: 2.00
          Mean value_function loss: 39.0781
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.1937
                       Mean reward: 749.04
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 148.4256
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.14s
                      Time elapsed: 00:21:37
                               ETA: 00:31:40

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 47144 steps/s (collection: 1.939s, learning 0.146s)
             Mean action noise std: 2.00
          Mean value_function loss: 35.5460
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.2062
                       Mean reward: 757.39
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7647
    Episode_Reward/rotating_object: 152.2728
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.09s
                      Time elapsed: 00:21:39
                               ETA: 00:31:37

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 47346 steps/s (collection: 1.912s, learning 0.164s)
             Mean action noise std: 2.00
          Mean value_function loss: 45.7994
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.2294
                       Mean reward: 777.30
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.7565
    Episode_Reward/rotating_object: 151.6216
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.08s
                      Time elapsed: 00:21:41
                               ETA: 00:31:35

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 45418 steps/s (collection: 1.981s, learning 0.184s)
             Mean action noise std: 2.01
          Mean value_function loss: 47.1504
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.2598
                       Mean reward: 748.47
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 147.7006
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.16s
                      Time elapsed: 00:21:43
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 47374 steps/s (collection: 1.912s, learning 0.163s)
             Mean action noise std: 2.01
          Mean value_function loss: 43.6669
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 37.2881
                       Mean reward: 729.30
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 150.4922
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.08s
                      Time elapsed: 00:21:45
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 46191 steps/s (collection: 1.986s, learning 0.142s)
             Mean action noise std: 2.01
          Mean value_function loss: 46.0701
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.3110
                       Mean reward: 739.20
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 149.1457
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.13s
                      Time elapsed: 00:21:47
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 46860 steps/s (collection: 1.920s, learning 0.178s)
             Mean action noise std: 2.01
          Mean value_function loss: 49.2304
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.3273
                       Mean reward: 755.44
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.7574
    Episode_Reward/rotating_object: 150.5279
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.10s
                      Time elapsed: 00:21:49
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 46566 steps/s (collection: 1.936s, learning 0.175s)
             Mean action noise std: 2.02
          Mean value_function loss: 51.1303
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.3499
                       Mean reward: 703.98
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 0.7405
    Episode_Reward/rotating_object: 144.8335
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.11s
                      Time elapsed: 00:21:52
                               ETA: 00:31:24

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 46039 steps/s (collection: 1.942s, learning 0.194s)
             Mean action noise std: 2.02
          Mean value_function loss: 38.3873
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.3879
                       Mean reward: 778.68
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.7570
    Episode_Reward/rotating_object: 153.8847
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.14s
                      Time elapsed: 00:21:54
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 46131 steps/s (collection: 1.964s, learning 0.167s)
             Mean action noise std: 2.03
          Mean value_function loss: 47.1108
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.4329
                       Mean reward: 753.07
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 0.7457
    Episode_Reward/rotating_object: 149.4877
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.13s
                      Time elapsed: 00:21:56
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 48108 steps/s (collection: 1.910s, learning 0.134s)
             Mean action noise std: 2.03
          Mean value_function loss: 49.5363
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 37.4522
                       Mean reward: 754.76
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.7404
    Episode_Reward/rotating_object: 147.6318
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.04s
                      Time elapsed: 00:21:58
                               ETA: 00:31:18

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 46341 steps/s (collection: 1.957s, learning 0.164s)
             Mean action noise std: 2.03
          Mean value_function loss: 39.6956
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.4692
                       Mean reward: 752.96
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 148.6701
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.12s
                      Time elapsed: 00:22:00
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 45945 steps/s (collection: 1.945s, learning 0.194s)
             Mean action noise std: 2.03
          Mean value_function loss: 31.7452
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.4924
                       Mean reward: 756.65
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.7591
    Episode_Reward/rotating_object: 151.0483
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.14s
                      Time elapsed: 00:22:02
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 47785 steps/s (collection: 1.911s, learning 0.147s)
             Mean action noise std: 2.03
          Mean value_function loss: 41.4713
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 37.5145
                       Mean reward: 752.69
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 0.7443
    Episode_Reward/rotating_object: 148.1020
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.06s
                      Time elapsed: 00:22:04
                               ETA: 00:31:11

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 43893 steps/s (collection: 2.077s, learning 0.163s)
             Mean action noise std: 2.03
          Mean value_function loss: 37.3644
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.5221
                       Mean reward: 741.12
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 0.7545
    Episode_Reward/rotating_object: 150.9081
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.24s
                      Time elapsed: 00:22:06
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 45038 steps/s (collection: 1.991s, learning 0.192s)
             Mean action noise std: 2.04
          Mean value_function loss: 38.3477
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.5329
                       Mean reward: 754.19
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 147.4138
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.18s
                      Time elapsed: 00:22:09
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 44626 steps/s (collection: 2.044s, learning 0.159s)
             Mean action noise std: 2.04
          Mean value_function loss: 43.6494
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.5457
                       Mean reward: 724.48
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 147.4056
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.20s
                      Time elapsed: 00:22:11
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 43947 steps/s (collection: 2.096s, learning 0.141s)
             Mean action noise std: 2.04
          Mean value_function loss: 41.0877
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 37.5515
                       Mean reward: 748.78
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 0.7586
    Episode_Reward/rotating_object: 149.1195
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.24s
                      Time elapsed: 00:22:13
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 49370 steps/s (collection: 1.886s, learning 0.105s)
             Mean action noise std: 2.04
          Mean value_function loss: 34.5864
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 37.5688
                       Mean reward: 736.16
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.7658
    Episode_Reward/rotating_object: 150.1155
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.99s
                      Time elapsed: 00:22:15
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 49362 steps/s (collection: 1.887s, learning 0.105s)
             Mean action noise std: 2.04
          Mean value_function loss: 32.9068
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.5941
                       Mean reward: 756.04
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7617
    Episode_Reward/rotating_object: 148.1508
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.99s
                      Time elapsed: 00:22:17
                               ETA: 00:30:59

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 49942 steps/s (collection: 1.851s, learning 0.118s)
             Mean action noise std: 2.05
          Mean value_function loss: 41.9857
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.6084
                       Mean reward: 753.03
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7666
    Episode_Reward/rotating_object: 149.0417
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.97s
                      Time elapsed: 00:22:19
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 48972 steps/s (collection: 1.860s, learning 0.147s)
             Mean action noise std: 2.05
          Mean value_function loss: 42.1762
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 37.6276
                       Mean reward: 767.56
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 151.5509
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.01s
                      Time elapsed: 00:22:21
                               ETA: 00:30:54

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 49818 steps/s (collection: 1.844s, learning 0.129s)
             Mean action noise std: 2.05
          Mean value_function loss: 41.8386
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.6539
                       Mean reward: 771.76
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.7636
    Episode_Reward/rotating_object: 151.1668
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.97s
                      Time elapsed: 00:22:23
                               ETA: 00:30:52

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 50182 steps/s (collection: 1.857s, learning 0.102s)
             Mean action noise std: 2.06
          Mean value_function loss: 42.5790
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.6746
                       Mean reward: 718.14
               Mean episode length: 236.20
    Episode_Reward/reaching_object: 0.7631
    Episode_Reward/rotating_object: 149.9480
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.96s
                      Time elapsed: 00:22:25
                               ETA: 00:30:49

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 49303 steps/s (collection: 1.852s, learning 0.142s)
             Mean action noise std: 2.06
          Mean value_function loss: 49.7410
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.7000
                       Mean reward: 742.61
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 0.7630
    Episode_Reward/rotating_object: 150.1458
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.99s
                      Time elapsed: 00:22:27
                               ETA: 00:30:47

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 50678 steps/s (collection: 1.843s, learning 0.097s)
             Mean action noise std: 2.06
          Mean value_function loss: 49.9262
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 37.7196
                       Mean reward: 777.25
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7736
    Episode_Reward/rotating_object: 151.5195
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.94s
                      Time elapsed: 00:22:29
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 49952 steps/s (collection: 1.861s, learning 0.107s)
             Mean action noise std: 2.06
          Mean value_function loss: 45.4939
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.7490
                       Mean reward: 760.99
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 0.7590
    Episode_Reward/rotating_object: 149.7435
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.97s
                      Time elapsed: 00:22:31
                               ETA: 00:30:42

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 49646 steps/s (collection: 1.874s, learning 0.106s)
             Mean action noise std: 2.07
          Mean value_function loss: 36.6147
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.7710
                       Mean reward: 757.17
               Mean episode length: 246.41
    Episode_Reward/reaching_object: 0.7704
    Episode_Reward/rotating_object: 151.1358
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.98s
                      Time elapsed: 00:22:33
                               ETA: 00:30:40

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 49901 steps/s (collection: 1.873s, learning 0.097s)
             Mean action noise std: 2.07
          Mean value_function loss: 45.1015
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.7849
                       Mean reward: 756.46
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 0.7727
    Episode_Reward/rotating_object: 150.4009
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.97s
                      Time elapsed: 00:22:35
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 47238 steps/s (collection: 1.971s, learning 0.110s)
             Mean action noise std: 2.07
          Mean value_function loss: 40.8833
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.8045
                       Mean reward: 748.74
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 0.7631
    Episode_Reward/rotating_object: 151.5552
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.08s
                      Time elapsed: 00:22:37
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 48700 steps/s (collection: 1.898s, learning 0.121s)
             Mean action noise std: 2.08
          Mean value_function loss: 41.5371
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.8262
                       Mean reward: 730.23
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.7630
    Episode_Reward/rotating_object: 147.2341
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.02s
                      Time elapsed: 00:22:39
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 49372 steps/s (collection: 1.873s, learning 0.118s)
             Mean action noise std: 2.08
          Mean value_function loss: 49.7355
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.8462
                       Mean reward: 715.43
               Mean episode length: 232.08
    Episode_Reward/reaching_object: 0.7677
    Episode_Reward/rotating_object: 150.5131
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.99s
                      Time elapsed: 00:22:41
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 48690 steps/s (collection: 1.895s, learning 0.124s)
             Mean action noise std: 2.08
          Mean value_function loss: 44.4759
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 37.8654
                       Mean reward: 753.51
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.7671
    Episode_Reward/rotating_object: 150.6364
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.02s
                      Time elapsed: 00:22:43
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 48920 steps/s (collection: 1.853s, learning 0.156s)
             Mean action noise std: 2.08
          Mean value_function loss: 40.8749
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.8851
                       Mean reward: 768.14
               Mean episode length: 247.49
    Episode_Reward/reaching_object: 0.7731
    Episode_Reward/rotating_object: 149.6104
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.01s
                      Time elapsed: 00:22:45
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 47351 steps/s (collection: 1.895s, learning 0.181s)
             Mean action noise std: 2.08
          Mean value_function loss: 44.2100
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.9056
                       Mean reward: 741.61
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 0.7666
    Episode_Reward/rotating_object: 148.8579
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.08s
                      Time elapsed: 00:22:47
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 49179 steps/s (collection: 1.840s, learning 0.159s)
             Mean action noise std: 2.09
          Mean value_function loss: 52.5894
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.9242
                       Mean reward: 741.39
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 0.7608
    Episode_Reward/rotating_object: 148.1938
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.00s
                      Time elapsed: 00:22:49
                               ETA: 00:30:22

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 48505 steps/s (collection: 1.886s, learning 0.141s)
             Mean action noise std: 2.09
          Mean value_function loss: 48.1982
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.9550
                       Mean reward: 760.22
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 0.7728
    Episode_Reward/rotating_object: 152.7573
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.03s
                      Time elapsed: 00:22:51
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 47671 steps/s (collection: 1.916s, learning 0.146s)
             Mean action noise std: 2.10
          Mean value_function loss: 43.9493
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.9910
                       Mean reward: 759.79
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.7705
    Episode_Reward/rotating_object: 150.4464
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.06s
                      Time elapsed: 00:22:53
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 50272 steps/s (collection: 1.831s, learning 0.124s)
             Mean action noise std: 2.10
          Mean value_function loss: 38.3948
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.0136
                       Mean reward: 745.24
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.7750
    Episode_Reward/rotating_object: 151.9865
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.96s
                      Time elapsed: 00:22:55
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 48856 steps/s (collection: 1.882s, learning 0.130s)
             Mean action noise std: 2.10
          Mean value_function loss: 44.6905
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.0365
                       Mean reward: 769.41
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7816
    Episode_Reward/rotating_object: 154.1371
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.01s
                      Time elapsed: 00:22:57
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 48894 steps/s (collection: 1.846s, learning 0.165s)
             Mean action noise std: 2.10
          Mean value_function loss: 47.6354
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.0506
                       Mean reward: 726.31
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 0.7586
    Episode_Reward/rotating_object: 147.0856
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.01s
                      Time elapsed: 00:22:59
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 48641 steps/s (collection: 1.898s, learning 0.123s)
             Mean action noise std: 2.10
          Mean value_function loss: 50.5165
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.0634
                       Mean reward: 747.46
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 0.7642
    Episode_Reward/rotating_object: 149.2276
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.02s
                      Time elapsed: 00:23:01
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 50266 steps/s (collection: 1.825s, learning 0.131s)
             Mean action noise std: 2.11
          Mean value_function loss: 48.0660
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.0826
                       Mean reward: 736.91
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 0.7624
    Episode_Reward/rotating_object: 149.6909
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 1.96s
                      Time elapsed: 00:23:03
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 49571 steps/s (collection: 1.882s, learning 0.101s)
             Mean action noise std: 2.11
          Mean value_function loss: 44.6237
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.0949
                       Mean reward: 734.84
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 0.7627
    Episode_Reward/rotating_object: 147.3640
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 1.98s
                      Time elapsed: 00:23:05
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 50399 steps/s (collection: 1.831s, learning 0.119s)
             Mean action noise std: 2.11
          Mean value_function loss: 42.6814
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.1065
                       Mean reward: 731.95
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 0.7768
    Episode_Reward/rotating_object: 149.9082
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.95s
                      Time elapsed: 00:23:07
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 47901 steps/s (collection: 1.881s, learning 0.171s)
             Mean action noise std: 2.11
          Mean value_function loss: 51.3713
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.1248
                       Mean reward: 784.32
               Mean episode length: 249.92
    Episode_Reward/reaching_object: 0.7711
    Episode_Reward/rotating_object: 149.1143
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.05s
                      Time elapsed: 00:23:09
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 48394 steps/s (collection: 1.874s, learning 0.157s)
             Mean action noise std: 2.11
          Mean value_function loss: 40.9650
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.1379
                       Mean reward: 739.16
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 0.7684
    Episode_Reward/rotating_object: 149.5547
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.03s
                      Time elapsed: 00:23:11
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 49867 steps/s (collection: 1.833s, learning 0.139s)
             Mean action noise std: 2.12
          Mean value_function loss: 40.8022
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 38.1517
                       Mean reward: 756.57
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 0.7728
    Episode_Reward/rotating_object: 148.9581
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.97s
                      Time elapsed: 00:23:13
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 49323 steps/s (collection: 1.849s, learning 0.144s)
             Mean action noise std: 2.12
          Mean value_function loss: 35.8263
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.1832
                       Mean reward: 760.95
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 0.7737
    Episode_Reward/rotating_object: 152.9262
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.99s
                      Time elapsed: 00:23:15
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 48671 steps/s (collection: 1.862s, learning 0.158s)
             Mean action noise std: 2.12
          Mean value_function loss: 52.5708
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.2025
                       Mean reward: 781.82
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7680
    Episode_Reward/rotating_object: 151.3287
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.02s
                      Time elapsed: 00:23:17
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 49117 steps/s (collection: 1.853s, learning 0.148s)
             Mean action noise std: 2.13
          Mean value_function loss: 39.9663
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.2185
                       Mean reward: 715.25
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 0.7587
    Episode_Reward/rotating_object: 147.5808
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.00s
                      Time elapsed: 00:23:19
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 48614 steps/s (collection: 1.886s, learning 0.136s)
             Mean action noise std: 2.13
          Mean value_function loss: 59.6707
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.2367
                       Mean reward: 730.48
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 0.7602
    Episode_Reward/rotating_object: 149.0889
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.02s
                      Time elapsed: 00:23:21
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 48587 steps/s (collection: 1.925s, learning 0.099s)
             Mean action noise std: 2.13
          Mean value_function loss: 48.3167
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.2488
                       Mean reward: 762.61
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 0.7646
    Episode_Reward/rotating_object: 149.4808
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.02s
                      Time elapsed: 00:23:23
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 50034 steps/s (collection: 1.861s, learning 0.104s)
             Mean action noise std: 2.13
          Mean value_function loss: 54.6898
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.2599
                       Mean reward: 740.99
               Mean episode length: 240.83
    Episode_Reward/reaching_object: 0.7584
    Episode_Reward/rotating_object: 149.3467
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.96s
                      Time elapsed: 00:23:25
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 50949 steps/s (collection: 1.828s, learning 0.102s)
             Mean action noise std: 2.13
          Mean value_function loss: 48.0018
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 38.2753
                       Mean reward: 714.68
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 146.5749
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.93s
                      Time elapsed: 00:23:27
                               ETA: 00:29:38

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 49909 steps/s (collection: 1.831s, learning 0.138s)
             Mean action noise std: 2.14
          Mean value_function loss: 40.5194
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.3027
                       Mean reward: 766.39
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 148.8143
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.97s
                      Time elapsed: 00:23:29
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 51156 steps/s (collection: 1.784s, learning 0.138s)
             Mean action noise std: 2.14
          Mean value_function loss: 55.2964
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.3368
                       Mean reward: 762.05
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 149.3569
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.92s
                      Time elapsed: 00:23:31
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 49774 steps/s (collection: 1.850s, learning 0.125s)
             Mean action noise std: 2.14
          Mean value_function loss: 41.0772
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.3620
                       Mean reward: 769.85
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.7587
    Episode_Reward/rotating_object: 152.6221
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.97s
                      Time elapsed: 00:23:33
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 28968 steps/s (collection: 3.285s, learning 0.108s)
             Mean action noise std: 2.14
          Mean value_function loss: 33.5944
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.3766
                       Mean reward: 744.17
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 0.7605
    Episode_Reward/rotating_object: 149.4056
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.39s
                      Time elapsed: 00:23:36
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14614 steps/s (collection: 6.597s, learning 0.129s)
             Mean action noise std: 2.15
          Mean value_function loss: 37.9351
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.3874
                       Mean reward: 728.69
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 0.7583
    Episode_Reward/rotating_object: 152.7640
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.73s
                      Time elapsed: 00:23:43
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14675 steps/s (collection: 6.554s, learning 0.144s)
             Mean action noise std: 2.15
          Mean value_function loss: 36.8923
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.4013
                       Mean reward: 743.22
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 0.7533
    Episode_Reward/rotating_object: 150.2593
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.70s
                      Time elapsed: 00:23:50
                               ETA: 00:29:38

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14832 steps/s (collection: 6.476s, learning 0.152s)
             Mean action noise std: 2.15
          Mean value_function loss: 46.1679
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.4202
                       Mean reward: 769.24
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.7532
    Episode_Reward/rotating_object: 151.1191
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.63s
                      Time elapsed: 00:23:56
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14610 steps/s (collection: 6.603s, learning 0.126s)
             Mean action noise std: 2.15
          Mean value_function loss: 45.5124
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.4368
                       Mean reward: 725.95
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 150.0849
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.73s
                      Time elapsed: 00:24:03
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14387 steps/s (collection: 6.689s, learning 0.143s)
             Mean action noise std: 2.16
          Mean value_function loss: 36.9117
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.4516
                       Mean reward: 738.16
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 148.9286
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.83s
                      Time elapsed: 00:24:10
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14689 steps/s (collection: 6.566s, learning 0.126s)
             Mean action noise std: 2.16
          Mean value_function loss: 34.1341
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 38.4683
                       Mean reward: 762.56
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7585
    Episode_Reward/rotating_object: 152.6597
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.69s
                      Time elapsed: 00:24:16
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 15231 steps/s (collection: 6.334s, learning 0.120s)
             Mean action noise std: 2.16
          Mean value_function loss: 39.3551
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.4861
                       Mean reward: 763.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7550
    Episode_Reward/rotating_object: 149.4898
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.45s
                      Time elapsed: 00:24:23
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14524 steps/s (collection: 6.591s, learning 0.177s)
             Mean action noise std: 2.16
          Mean value_function loss: 45.6824
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.5063
                       Mean reward: 759.96
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 0.7581
    Episode_Reward/rotating_object: 153.5481
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.77s
                      Time elapsed: 00:24:30
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 22595 steps/s (collection: 4.250s, learning 0.101s)
             Mean action noise std: 2.17
          Mean value_function loss: 36.0373
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.5354
                       Mean reward: 752.42
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 0.7530
    Episode_Reward/rotating_object: 151.1203
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.35s
                      Time elapsed: 00:24:34
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 52632 steps/s (collection: 1.745s, learning 0.123s)
             Mean action noise std: 2.17
          Mean value_function loss: 53.4960
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.5599
                       Mean reward: 750.91
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 150.8047
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.87s
                      Time elapsed: 00:24:36
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 53353 steps/s (collection: 1.742s, learning 0.100s)
             Mean action noise std: 2.17
          Mean value_function loss: 43.1439
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.5708
                       Mean reward: 798.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7522
    Episode_Reward/rotating_object: 152.5802
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.84s
                      Time elapsed: 00:24:38
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 53391 steps/s (collection: 1.740s, learning 0.102s)
             Mean action noise std: 2.17
          Mean value_function loss: 52.5822
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.5772
                       Mean reward: 757.42
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 147.4707
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.84s
                      Time elapsed: 00:24:40
                               ETA: 00:29:51

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 51805 steps/s (collection: 1.775s, learning 0.123s)
             Mean action noise std: 2.17
          Mean value_function loss: 46.7405
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.5884
                       Mean reward: 747.95
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 150.0133
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.90s
                      Time elapsed: 00:24:42
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 51908 steps/s (collection: 1.760s, learning 0.134s)
             Mean action noise std: 2.18
          Mean value_function loss: 40.0009
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.5994
                       Mean reward: 788.32
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7594
    Episode_Reward/rotating_object: 153.8066
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.89s
                      Time elapsed: 00:24:43
                               ETA: 00:29:46

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 52777 steps/s (collection: 1.749s, learning 0.114s)
             Mean action noise std: 2.18
          Mean value_function loss: 34.8511
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.6081
                       Mean reward: 768.64
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7645
    Episode_Reward/rotating_object: 151.6002
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.86s
                      Time elapsed: 00:24:45
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 53695 steps/s (collection: 1.730s, learning 0.101s)
             Mean action noise std: 2.18
          Mean value_function loss: 51.2160
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.6192
                       Mean reward: 780.36
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 0.7565
    Episode_Reward/rotating_object: 150.3692
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.83s
                      Time elapsed: 00:24:47
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 54291 steps/s (collection: 1.711s, learning 0.100s)
             Mean action noise std: 2.18
          Mean value_function loss: 33.3365
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.6319
                       Mean reward: 785.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7694
    Episode_Reward/rotating_object: 153.6088
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.81s
                      Time elapsed: 00:24:49
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 53644 steps/s (collection: 1.725s, learning 0.108s)
             Mean action noise std: 2.19
          Mean value_function loss: 46.3149
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.6534
                       Mean reward: 782.59
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7658
    Episode_Reward/rotating_object: 153.0156
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.83s
                      Time elapsed: 00:24:51
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 51483 steps/s (collection: 1.806s, learning 0.103s)
             Mean action noise std: 2.19
          Mean value_function loss: 49.1168
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 38.6751
                       Mean reward: 748.30
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 0.7664
    Episode_Reward/rotating_object: 153.6523
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.91s
                      Time elapsed: 00:24:53
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 52346 steps/s (collection: 1.739s, learning 0.139s)
             Mean action noise std: 2.19
          Mean value_function loss: 37.8154
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.6981
                       Mean reward: 774.39
               Mean episode length: 246.54
    Episode_Reward/reaching_object: 0.7651
    Episode_Reward/rotating_object: 151.7475
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.88s
                      Time elapsed: 00:24:55
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 53251 steps/s (collection: 1.711s, learning 0.136s)
             Mean action noise std: 2.19
          Mean value_function loss: 46.9374
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.7169
                       Mean reward: 774.37
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 0.7583
    Episode_Reward/rotating_object: 151.8773
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.85s
                      Time elapsed: 00:24:56
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 52087 steps/s (collection: 1.765s, learning 0.122s)
             Mean action noise std: 2.20
          Mean value_function loss: 44.2942
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 38.7342
                       Mean reward: 760.85
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 0.7603
    Episode_Reward/rotating_object: 154.4402
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.89s
                      Time elapsed: 00:24:58
                               ETA: 00:29:26

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 51164 steps/s (collection: 1.806s, learning 0.115s)
             Mean action noise std: 2.20
          Mean value_function loss: 41.0646
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.7560
                       Mean reward: 776.49
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 150.3846
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.92s
                      Time elapsed: 00:25:00
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 52115 steps/s (collection: 1.786s, learning 0.101s)
             Mean action noise std: 2.20
          Mean value_function loss: 46.8476
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.7773
                       Mean reward: 782.66
               Mean episode length: 246.71
    Episode_Reward/reaching_object: 0.7584
    Episode_Reward/rotating_object: 153.3638
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.89s
                      Time elapsed: 00:25:02
                               ETA: 00:29:21

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 53123 steps/s (collection: 1.756s, learning 0.094s)
             Mean action noise std: 2.20
          Mean value_function loss: 34.6385
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.8004
                       Mean reward: 775.71
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.7626
    Episode_Reward/rotating_object: 152.9415
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.85s
                      Time elapsed: 00:25:04
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 53711 steps/s (collection: 1.733s, learning 0.098s)
             Mean action noise std: 2.21
          Mean value_function loss: 41.4760
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 38.8162
                       Mean reward: 756.33
               Mean episode length: 239.06
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 151.7531
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.83s
                      Time elapsed: 00:25:06
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 53834 steps/s (collection: 1.704s, learning 0.123s)
             Mean action noise std: 2.21
          Mean value_function loss: 33.2347
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.8295
                       Mean reward: 790.82
               Mean episode length: 247.40
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 149.8360
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.83s
                      Time elapsed: 00:25:08
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 53667 steps/s (collection: 1.724s, learning 0.108s)
             Mean action noise std: 2.21
          Mean value_function loss: 36.4965
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.8423
                       Mean reward: 750.09
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7538
    Episode_Reward/rotating_object: 150.4073
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.83s
                      Time elapsed: 00:25:09
                               ETA: 00:29:11

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 54806 steps/s (collection: 1.698s, learning 0.096s)
             Mean action noise std: 2.21
          Mean value_function loss: 42.7788
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 38.8673
                       Mean reward: 792.96
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 153.3070
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.79s
                      Time elapsed: 00:25:11
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 52158 steps/s (collection: 1.789s, learning 0.096s)
             Mean action noise std: 2.22
          Mean value_function loss: 43.0307
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.8967
                       Mean reward: 730.93
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 0.7376
    Episode_Reward/rotating_object: 147.0725
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.88s
                      Time elapsed: 00:25:13
                               ETA: 00:29:05

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 53467 steps/s (collection: 1.745s, learning 0.093s)
             Mean action noise std: 2.22
          Mean value_function loss: 33.6854
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.9187
                       Mean reward: 755.08
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 153.2063
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.84s
                      Time elapsed: 00:25:15
                               ETA: 00:29:03

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 52643 steps/s (collection: 1.759s, learning 0.108s)
             Mean action noise std: 2.22
          Mean value_function loss: 31.8695
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.9444
                       Mean reward: 787.58
               Mean episode length: 246.47
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 155.7132
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.87s
                      Time elapsed: 00:25:17
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 52940 steps/s (collection: 1.748s, learning 0.109s)
             Mean action noise std: 2.23
          Mean value_function loss: 48.6075
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.9756
                       Mean reward: 767.11
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 0.7340
    Episode_Reward/rotating_object: 146.8471
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.86s
                      Time elapsed: 00:25:19
                               ETA: 00:28:58

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 51626 steps/s (collection: 1.750s, learning 0.154s)
             Mean action noise std: 2.23
          Mean value_function loss: 43.4548
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.0049
                       Mean reward: 764.83
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.7571
    Episode_Reward/rotating_object: 153.5864
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.90s
                      Time elapsed: 00:25:21
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 51618 steps/s (collection: 1.759s, learning 0.146s)
             Mean action noise std: 2.23
          Mean value_function loss: 47.8535
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.0251
                       Mean reward: 741.09
               Mean episode length: 238.11
    Episode_Reward/reaching_object: 0.7471
    Episode_Reward/rotating_object: 151.7096
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.90s
                      Time elapsed: 00:25:22
                               ETA: 00:28:53

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 54334 steps/s (collection: 1.718s, learning 0.092s)
             Mean action noise std: 2.24
          Mean value_function loss: 48.5147
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.0430
                       Mean reward: 753.80
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 0.7426
    Episode_Reward/rotating_object: 151.4775
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.81s
                      Time elapsed: 00:25:24
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 54184 steps/s (collection: 1.725s, learning 0.090s)
             Mean action noise std: 2.24
          Mean value_function loss: 46.6396
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.0537
                       Mean reward: 766.99
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 0.7330
    Episode_Reward/rotating_object: 148.0888
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.81s
                      Time elapsed: 00:25:26
                               ETA: 00:28:48

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 52215 steps/s (collection: 1.770s, learning 0.113s)
             Mean action noise std: 2.24
          Mean value_function loss: 42.8285
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.0701
                       Mean reward: 777.70
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 151.6754
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.88s
                      Time elapsed: 00:25:28
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 53282 steps/s (collection: 1.738s, learning 0.107s)
             Mean action noise std: 2.24
          Mean value_function loss: 43.3239
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.0937
                       Mean reward: 729.14
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 150.4489
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.84s
                      Time elapsed: 00:25:30
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 53354 steps/s (collection: 1.710s, learning 0.133s)
             Mean action noise std: 2.25
          Mean value_function loss: 36.9218
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.1119
                       Mean reward: 767.44
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 152.2176
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.84s
                      Time elapsed: 00:25:32
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 53647 steps/s (collection: 1.736s, learning 0.096s)
             Mean action noise std: 2.25
          Mean value_function loss: 47.8444
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.1376
                       Mean reward: 736.90
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 151.5450
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.83s
                      Time elapsed: 00:25:33
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 51949 steps/s (collection: 1.763s, learning 0.130s)
             Mean action noise std: 2.25
          Mean value_function loss: 40.3196
               Mean surrogate loss: 0.0037
                 Mean entropy loss: 39.1612
                       Mean reward: 725.76
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 0.7323
    Episode_Reward/rotating_object: 150.0778
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.89s
                      Time elapsed: 00:25:35
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 53547 steps/s (collection: 1.741s, learning 0.095s)
             Mean action noise std: 2.25
          Mean value_function loss: 34.7848
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.1674
                       Mean reward: 780.77
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 0.7451
    Episode_Reward/rotating_object: 151.0649
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.84s
                      Time elapsed: 00:25:37
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 52728 steps/s (collection: 1.741s, learning 0.123s)
             Mean action noise std: 2.25
          Mean value_function loss: 43.1049
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.1790
                       Mean reward: 785.85
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 153.6367
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.86s
                      Time elapsed: 00:25:39
                               ETA: 00:28:30

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 53011 steps/s (collection: 1.741s, learning 0.114s)
             Mean action noise std: 2.26
          Mean value_function loss: 37.0019
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.1943
                       Mean reward: 773.86
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 0.7376
    Episode_Reward/rotating_object: 151.8678
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.85s
                      Time elapsed: 00:25:41
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 53128 steps/s (collection: 1.721s, learning 0.129s)
             Mean action noise std: 2.26
          Mean value_function loss: 44.1714
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.2080
                       Mean reward: 760.17
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 152.4487
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.85s
                      Time elapsed: 00:25:43
                               ETA: 00:28:25

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 51482 steps/s (collection: 1.713s, learning 0.197s)
             Mean action noise std: 2.26
          Mean value_function loss: 28.5542
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.2297
                       Mean reward: 794.03
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 151.4769
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.91s
                      Time elapsed: 00:25:45
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 53314 steps/s (collection: 1.702s, learning 0.142s)
             Mean action noise std: 2.26
          Mean value_function loss: 40.7663
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.2416
                       Mean reward: 781.99
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7425
    Episode_Reward/rotating_object: 152.4019
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.84s
                      Time elapsed: 00:25:47
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 54296 steps/s (collection: 1.718s, learning 0.093s)
             Mean action noise std: 2.26
          Mean value_function loss: 28.7688
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.2506
                       Mean reward: 793.80
               Mean episode length: 248.62
    Episode_Reward/reaching_object: 0.7408
    Episode_Reward/rotating_object: 154.0516
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.81s
                      Time elapsed: 00:25:48
                               ETA: 00:28:18

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 53572 steps/s (collection: 1.745s, learning 0.090s)
             Mean action noise std: 2.27
          Mean value_function loss: 43.1533
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.2577
                       Mean reward: 760.27
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 154.1213
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.83s
                      Time elapsed: 00:25:50
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 53940 steps/s (collection: 1.730s, learning 0.093s)
             Mean action noise std: 2.27
          Mean value_function loss: 46.1576
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.2672
                       Mean reward: 765.97
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 0.7370
    Episode_Reward/rotating_object: 151.3265
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.82s
                      Time elapsed: 00:25:52
                               ETA: 00:28:13

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 53739 steps/s (collection: 1.728s, learning 0.102s)
             Mean action noise std: 2.27
          Mean value_function loss: 44.5834
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.2822
                       Mean reward: 758.34
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 0.7407
    Episode_Reward/rotating_object: 153.6452
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.83s
                      Time elapsed: 00:25:54
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 52255 steps/s (collection: 1.719s, learning 0.162s)
             Mean action noise std: 2.27
          Mean value_function loss: 54.7036
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.3011
                       Mean reward: 736.65
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 0.7282
    Episode_Reward/rotating_object: 149.9155
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.88s
                      Time elapsed: 00:25:56
                               ETA: 00:28:08

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 54248 steps/s (collection: 1.715s, learning 0.097s)
             Mean action noise std: 2.28
          Mean value_function loss: 39.1402
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.3241
                       Mean reward: 774.84
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 155.9680
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.81s
                      Time elapsed: 00:25:58
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 53536 steps/s (collection: 1.747s, learning 0.090s)
             Mean action noise std: 2.28
          Mean value_function loss: 55.9164
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.3383
                       Mean reward: 735.42
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 0.7316
    Episode_Reward/rotating_object: 149.2063
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.84s
                      Time elapsed: 00:25:59
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 53472 steps/s (collection: 1.746s, learning 0.092s)
             Mean action noise std: 2.28
          Mean value_function loss: 50.9345
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 39.3483
                       Mean reward: 742.51
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 0.7349
    Episode_Reward/rotating_object: 149.1918
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.84s
                      Time elapsed: 00:26:01
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 53575 steps/s (collection: 1.743s, learning 0.092s)
             Mean action noise std: 2.28
          Mean value_function loss: 68.7556
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.3599
                       Mean reward: 734.71
               Mean episode length: 230.79
    Episode_Reward/reaching_object: 0.7103
    Episode_Reward/rotating_object: 145.1198
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.83s
                      Time elapsed: 00:26:03
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 54103 steps/s (collection: 1.708s, learning 0.109s)
             Mean action noise std: 2.28
          Mean value_function loss: 43.2398
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 39.3782
                       Mean reward: 755.22
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 152.1738
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.82s
                      Time elapsed: 00:26:05
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 52260 steps/s (collection: 1.727s, learning 0.154s)
             Mean action noise std: 2.29
          Mean value_function loss: 54.0271
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.4057
                       Mean reward: 745.84
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 0.7405
    Episode_Reward/rotating_object: 150.9733
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.88s
                      Time elapsed: 00:26:07
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 52442 steps/s (collection: 1.721s, learning 0.154s)
             Mean action noise std: 2.29
          Mean value_function loss: 53.3345
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.4333
                       Mean reward: 769.54
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 151.6073
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.87s
                      Time elapsed: 00:26:09
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 53237 steps/s (collection: 1.739s, learning 0.107s)
             Mean action noise std: 2.29
          Mean value_function loss: 44.1762
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.4509
                       Mean reward: 754.06
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 0.7379
    Episode_Reward/rotating_object: 148.7411
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.85s
                      Time elapsed: 00:26:10
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 52447 steps/s (collection: 1.774s, learning 0.101s)
             Mean action noise std: 2.29
          Mean value_function loss: 43.2117
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.4673
                       Mean reward: 791.78
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 0.7489
    Episode_Reward/rotating_object: 151.8163
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.87s
                      Time elapsed: 00:26:12
                               ETA: 00:27:45

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 54026 steps/s (collection: 1.724s, learning 0.095s)
             Mean action noise std: 2.30
          Mean value_function loss: 39.5748
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.4822
                       Mean reward: 752.66
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 0.7592
    Episode_Reward/rotating_object: 151.7143
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.82s
                      Time elapsed: 00:26:14
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 51815 steps/s (collection: 1.803s, learning 0.094s)
             Mean action noise std: 2.30
          Mean value_function loss: 57.1734
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.5029
                       Mean reward: 776.75
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7451
    Episode_Reward/rotating_object: 150.4223
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.90s
                      Time elapsed: 00:26:16
                               ETA: 00:27:40

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 53252 steps/s (collection: 1.732s, learning 0.114s)
             Mean action noise std: 2.30
          Mean value_function loss: 41.6893
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 39.5172
                       Mean reward: 781.17
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 149.7746
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.85s
                      Time elapsed: 00:26:18
                               ETA: 00:27:38

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 53489 steps/s (collection: 1.709s, learning 0.129s)
             Mean action noise std: 2.30
          Mean value_function loss: 59.5708
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.5319
                       Mean reward: 732.26
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 0.7360
    Episode_Reward/rotating_object: 145.0362
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.84s
                      Time elapsed: 00:26:20
                               ETA: 00:27:35

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 52921 steps/s (collection: 1.704s, learning 0.154s)
             Mean action noise std: 2.31
          Mean value_function loss: 42.2557
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.5516
                       Mean reward: 731.17
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 0.7572
    Episode_Reward/rotating_object: 154.3972
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.86s
                      Time elapsed: 00:26:22
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 53661 steps/s (collection: 1.737s, learning 0.095s)
             Mean action noise std: 2.31
          Mean value_function loss: 43.9587
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.5686
                       Mean reward: 775.91
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.7551
    Episode_Reward/rotating_object: 152.0556
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.83s
                      Time elapsed: 00:26:23
                               ETA: 00:27:30

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 53405 steps/s (collection: 1.744s, learning 0.097s)
             Mean action noise std: 2.31
          Mean value_function loss: 62.2098
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.5860
                       Mean reward: 714.50
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 0.7346
    Episode_Reward/rotating_object: 147.5736
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.84s
                      Time elapsed: 00:26:25
                               ETA: 00:27:28

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 52542 steps/s (collection: 1.774s, learning 0.097s)
             Mean action noise std: 2.31
          Mean value_function loss: 43.8260
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.5965
                       Mean reward: 769.14
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 0.7394
    Episode_Reward/rotating_object: 151.2386
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.87s
                      Time elapsed: 00:26:27
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 53124 steps/s (collection: 1.746s, learning 0.105s)
             Mean action noise std: 2.31
          Mean value_function loss: 33.1846
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.6080
                       Mean reward: 761.84
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 0.7557
    Episode_Reward/rotating_object: 152.7340
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.85s
                      Time elapsed: 00:26:29
                               ETA: 00:27:23

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 53707 steps/s (collection: 1.731s, learning 0.099s)
             Mean action noise std: 2.32
          Mean value_function loss: 40.2410
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.6259
                       Mean reward: 738.65
               Mean episode length: 234.16
    Episode_Reward/reaching_object: 0.7538
    Episode_Reward/rotating_object: 152.5308
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.83s
                      Time elapsed: 00:26:31
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 51486 steps/s (collection: 1.765s, learning 0.144s)
             Mean action noise std: 2.32
          Mean value_function loss: 45.5283
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.6539
                       Mean reward: 785.80
               Mean episode length: 245.13
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 151.9877
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.91s
                      Time elapsed: 00:26:33
                               ETA: 00:27:18

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 53230 steps/s (collection: 1.725s, learning 0.122s)
             Mean action noise std: 2.32
          Mean value_function loss: 40.2104
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.6748
                       Mean reward: 792.54
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7581
    Episode_Reward/rotating_object: 154.6823
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.85s
                      Time elapsed: 00:26:35
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 52153 steps/s (collection: 1.792s, learning 0.093s)
             Mean action noise std: 2.32
          Mean value_function loss: 50.5728
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.6835
                       Mean reward: 759.90
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.7425
    Episode_Reward/rotating_object: 150.3733
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.88s
                      Time elapsed: 00:26:36
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 52312 steps/s (collection: 1.784s, learning 0.096s)
             Mean action noise std: 2.32
          Mean value_function loss: 39.3778
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.6901
                       Mean reward: 790.33
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7535
    Episode_Reward/rotating_object: 152.8220
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.88s
                      Time elapsed: 00:26:38
                               ETA: 00:27:11

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 54032 steps/s (collection: 1.719s, learning 0.100s)
             Mean action noise std: 2.33
          Mean value_function loss: 45.2755
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.6973
                       Mean reward: 777.73
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.7559
    Episode_Reward/rotating_object: 153.0182
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.82s
                      Time elapsed: 00:26:40
                               ETA: 00:27:08

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 53956 steps/s (collection: 1.724s, learning 0.097s)
             Mean action noise std: 2.33
          Mean value_function loss: 40.7243
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.7141
                       Mean reward: 737.00
               Mean episode length: 237.05
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 152.6310
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.82s
                      Time elapsed: 00:26:42
                               ETA: 00:27:06

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 51687 steps/s (collection: 1.776s, learning 0.126s)
             Mean action noise std: 2.33
          Mean value_function loss: 45.1649
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.7283
                       Mean reward: 778.36
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 150.5070
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.90s
                      Time elapsed: 00:26:44
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 51823 steps/s (collection: 1.749s, learning 0.148s)
             Mean action noise std: 2.33
          Mean value_function loss: 36.4630
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 39.7448
                       Mean reward: 786.25
               Mean episode length: 246.58
    Episode_Reward/reaching_object: 0.7678
    Episode_Reward/rotating_object: 156.6740
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.90s
                      Time elapsed: 00:26:46
                               ETA: 00:27:01

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 52252 steps/s (collection: 1.750s, learning 0.132s)
             Mean action noise std: 2.34
          Mean value_function loss: 43.6491
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.7666
                       Mean reward: 777.55
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.7523
    Episode_Reward/rotating_object: 151.0593
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.88s
                      Time elapsed: 00:26:48
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 52915 steps/s (collection: 1.760s, learning 0.098s)
             Mean action noise std: 2.34
          Mean value_function loss: 36.7899
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 39.7858
                       Mean reward: 791.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7651
    Episode_Reward/rotating_object: 154.7463
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.86s
                      Time elapsed: 00:26:50
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 52894 steps/s (collection: 1.766s, learning 0.092s)
             Mean action noise std: 2.34
          Mean value_function loss: 41.8428
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 39.8086
                       Mean reward: 745.08
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 149.9212
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.86s
                      Time elapsed: 00:26:51
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 52734 steps/s (collection: 1.768s, learning 0.096s)
             Mean action noise std: 2.35
          Mean value_function loss: 41.5190
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.8295
                       Mean reward: 746.47
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 151.8391
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.86s
                      Time elapsed: 00:26:53
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 51417 steps/s (collection: 1.808s, learning 0.104s)
             Mean action noise std: 2.35
          Mean value_function loss: 38.5025
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.8414
                       Mean reward: 781.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 150.7913
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.91s
                      Time elapsed: 00:26:55
                               ETA: 00:26:49

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 52937 steps/s (collection: 1.729s, learning 0.128s)
             Mean action noise std: 2.35
          Mean value_function loss: 35.6212
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.8589
                       Mean reward: 765.04
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 153.8243
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.86s
                      Time elapsed: 00:26:57
                               ETA: 00:26:46

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 52930 steps/s (collection: 1.754s, learning 0.103s)
             Mean action noise std: 2.35
          Mean value_function loss: 47.5993
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.8806
                       Mean reward: 755.96
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 0.7377
    Episode_Reward/rotating_object: 149.7534
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.86s
                      Time elapsed: 00:26:59
                               ETA: 00:26:44

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 51882 steps/s (collection: 1.756s, learning 0.139s)
             Mean action noise std: 2.36
          Mean value_function loss: 39.4546
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.8981
                       Mean reward: 761.51
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 153.7529
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.89s
                      Time elapsed: 00:27:01
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 52967 steps/s (collection: 1.750s, learning 0.106s)
             Mean action noise std: 2.36
          Mean value_function loss: 40.8980
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.9191
                       Mean reward: 728.71
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 148.7438
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.86s
                      Time elapsed: 00:27:03
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 51672 steps/s (collection: 1.801s, learning 0.102s)
             Mean action noise std: 2.36
          Mean value_function loss: 43.4061
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.9389
                       Mean reward: 762.10
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 0.7488
    Episode_Reward/rotating_object: 155.5883
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.90s
                      Time elapsed: 00:27:05
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 52716 steps/s (collection: 1.773s, learning 0.092s)
             Mean action noise std: 2.36
          Mean value_function loss: 49.3788
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.9561
                       Mean reward: 772.68
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 0.7402
    Episode_Reward/rotating_object: 153.5341
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.86s
                      Time elapsed: 00:27:06
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 52629 steps/s (collection: 1.749s, learning 0.119s)
             Mean action noise std: 2.37
          Mean value_function loss: 43.3158
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.9748
                       Mean reward: 773.27
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 0.7407
    Episode_Reward/rotating_object: 151.1130
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.87s
                      Time elapsed: 00:27:08
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 53731 steps/s (collection: 1.710s, learning 0.120s)
             Mean action noise std: 2.37
          Mean value_function loss: 35.4197
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.9936
                       Mean reward: 757.95
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.7374
    Episode_Reward/rotating_object: 150.8106
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.83s
                      Time elapsed: 00:27:10
                               ETA: 00:26:29

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 53529 steps/s (collection: 1.731s, learning 0.106s)
             Mean action noise std: 2.37
          Mean value_function loss: 36.3264
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.0123
                       Mean reward: 784.06
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 154.3089
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.84s
                      Time elapsed: 00:27:12
                               ETA: 00:26:27

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 52161 steps/s (collection: 1.761s, learning 0.123s)
             Mean action noise std: 2.37
          Mean value_function loss: 47.6434
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.0272
                       Mean reward: 772.49
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.7344
    Episode_Reward/rotating_object: 149.8470
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.88s
                      Time elapsed: 00:27:14
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 52019 steps/s (collection: 1.799s, learning 0.091s)
             Mean action noise std: 2.38
          Mean value_function loss: 56.6649
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.0411
                       Mean reward: 757.63
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 0.7416
    Episode_Reward/rotating_object: 152.9241
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.89s
                      Time elapsed: 00:27:16
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 53077 steps/s (collection: 1.755s, learning 0.097s)
             Mean action noise std: 2.38
          Mean value_function loss: 47.0408
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.0514
                       Mean reward: 777.78
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 154.6330
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.85s
                      Time elapsed: 00:27:18
                               ETA: 00:26:20

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 53261 steps/s (collection: 1.754s, learning 0.091s)
             Mean action noise std: 2.38
          Mean value_function loss: 43.9290
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.0669
                       Mean reward: 773.35
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 152.4238
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.85s
                      Time elapsed: 00:27:19
                               ETA: 00:26:17

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 52832 steps/s (collection: 1.758s, learning 0.103s)
             Mean action noise std: 2.38
          Mean value_function loss: 49.7961
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.0864
                       Mean reward: 748.75
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 150.3573
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.86s
                      Time elapsed: 00:27:21
                               ETA: 00:26:15

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 52585 steps/s (collection: 1.778s, learning 0.092s)
             Mean action noise std: 2.38
          Mean value_function loss: 39.8170
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.0948
                       Mean reward: 732.21
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.7362
    Episode_Reward/rotating_object: 148.4591
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.87s
                      Time elapsed: 00:27:23
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 52028 steps/s (collection: 1.754s, learning 0.135s)
             Mean action noise std: 2.38
          Mean value_function loss: 38.0653
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.0980
                       Mean reward: 776.61
               Mean episode length: 245.29
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 154.2887
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.89s
                      Time elapsed: 00:27:25
                               ETA: 00:26:10

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 53055 steps/s (collection: 1.730s, learning 0.123s)
             Mean action noise std: 2.39
          Mean value_function loss: 46.5246
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.1048
                       Mean reward: 761.64
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 152.4647
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.85s
                      Time elapsed: 00:27:27
                               ETA: 00:26:08

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 52367 steps/s (collection: 1.767s, learning 0.110s)
             Mean action noise std: 2.39
          Mean value_function loss: 43.3820
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.1275
                       Mean reward: 767.40
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.7404
    Episode_Reward/rotating_object: 150.9237
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.88s
                      Time elapsed: 00:27:29
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 52452 steps/s (collection: 1.768s, learning 0.106s)
             Mean action noise std: 2.39
          Mean value_function loss: 34.9219
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.1444
                       Mean reward: 785.79
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 152.8430
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.87s
                      Time elapsed: 00:27:31
                               ETA: 00:26:03

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 53068 steps/s (collection: 1.756s, learning 0.096s)
             Mean action noise std: 2.39
          Mean value_function loss: 33.6830
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.1467
                       Mean reward: 770.97
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 153.9173
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.85s
                      Time elapsed: 00:27:32
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 52293 steps/s (collection: 1.773s, learning 0.107s)
             Mean action noise std: 2.40
          Mean value_function loss: 50.6166
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.1568
                       Mean reward: 774.56
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 151.6933
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.88s
                      Time elapsed: 00:27:34
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 52770 steps/s (collection: 1.757s, learning 0.106s)
             Mean action noise std: 2.40
          Mean value_function loss: 47.6258
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.1798
                       Mean reward: 763.71
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 152.8574
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.86s
                      Time elapsed: 00:27:36
                               ETA: 00:25:56

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 52926 steps/s (collection: 1.755s, learning 0.102s)
             Mean action noise std: 2.40
          Mean value_function loss: 39.5225
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 40.1957
                       Mean reward: 773.27
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 153.8363
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.86s
                      Time elapsed: 00:27:38
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 51919 steps/s (collection: 1.788s, learning 0.105s)
             Mean action noise std: 2.40
          Mean value_function loss: 51.9903
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.2149
                       Mean reward: 774.25
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 152.6230
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.89s
                      Time elapsed: 00:27:40
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 52365 steps/s (collection: 1.751s, learning 0.127s)
             Mean action noise std: 2.41
          Mean value_function loss: 40.3775
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.2329
                       Mean reward: 789.03
               Mean episode length: 244.70
    Episode_Reward/reaching_object: 0.7543
    Episode_Reward/rotating_object: 153.5825
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.88s
                      Time elapsed: 00:27:42
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 51719 steps/s (collection: 1.803s, learning 0.098s)
             Mean action noise std: 2.41
          Mean value_function loss: 43.9101
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 40.2437
                       Mean reward: 768.42
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 152.3849
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.90s
                      Time elapsed: 00:27:44
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 51972 steps/s (collection: 1.786s, learning 0.106s)
             Mean action noise std: 2.41
          Mean value_function loss: 40.4333
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.2641
                       Mean reward: 758.09
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 0.7617
    Episode_Reward/rotating_object: 153.2330
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.89s
                      Time elapsed: 00:27:46
                               ETA: 00:25:44

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 53626 steps/s (collection: 1.735s, learning 0.098s)
             Mean action noise std: 2.41
          Mean value_function loss: 42.5788
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.2789
                       Mean reward: 788.55
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.7609
    Episode_Reward/rotating_object: 153.2469
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.83s
                      Time elapsed: 00:27:47
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 52615 steps/s (collection: 1.769s, learning 0.099s)
             Mean action noise std: 2.41
          Mean value_function loss: 36.4384
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 40.2904
                       Mean reward: 741.89
               Mean episode length: 239.79
    Episode_Reward/reaching_object: 0.7595
    Episode_Reward/rotating_object: 152.7323
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 1.87s
                      Time elapsed: 00:27:49
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 52300 steps/s (collection: 1.759s, learning 0.121s)
             Mean action noise std: 2.42
          Mean value_function loss: 39.2964
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.3001
                       Mean reward: 777.11
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.7596
    Episode_Reward/rotating_object: 152.3590
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.88s
                      Time elapsed: 00:27:51
                               ETA: 00:25:37

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 52614 steps/s (collection: 1.754s, learning 0.114s)
             Mean action noise std: 2.42
          Mean value_function loss: 37.5517
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.3114
                       Mean reward: 772.33
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 0.7637
    Episode_Reward/rotating_object: 153.0005
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.87s
                      Time elapsed: 00:27:53
                               ETA: 00:25:34

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 53013 steps/s (collection: 1.760s, learning 0.094s)
             Mean action noise std: 2.42
          Mean value_function loss: 35.8221
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.3244
                       Mean reward: 775.56
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 0.7678
    Episode_Reward/rotating_object: 155.2064
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.85s
                      Time elapsed: 00:27:55
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 52998 steps/s (collection: 1.761s, learning 0.094s)
             Mean action noise std: 2.42
          Mean value_function loss: 32.5287
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.3285
                       Mean reward: 769.09
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 0.7676
    Episode_Reward/rotating_object: 154.3535
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.85s
                      Time elapsed: 00:27:57
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 52873 steps/s (collection: 1.756s, learning 0.104s)
             Mean action noise std: 2.42
          Mean value_function loss: 45.8813
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.3376
                       Mean reward: 743.53
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 150.3919
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.86s
                      Time elapsed: 00:27:59
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 54484 steps/s (collection: 1.711s, learning 0.093s)
             Mean action noise std: 2.42
          Mean value_function loss: 31.4655
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.3509
                       Mean reward: 791.77
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.7603
    Episode_Reward/rotating_object: 156.6697
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 1.80s
                      Time elapsed: 00:28:00
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 51680 steps/s (collection: 1.780s, learning 0.123s)
             Mean action noise std: 2.43
          Mean value_function loss: 34.1225
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.3608
                       Mean reward: 788.11
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.7612
    Episode_Reward/rotating_object: 154.7226
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.90s
                      Time elapsed: 00:28:02
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 53953 steps/s (collection: 1.732s, learning 0.090s)
             Mean action noise std: 2.43
          Mean value_function loss: 44.0295
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.3684
                       Mean reward: 760.94
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 0.7552
    Episode_Reward/rotating_object: 153.6779
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.82s
                      Time elapsed: 00:28:04
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 52901 steps/s (collection: 1.766s, learning 0.093s)
             Mean action noise std: 2.43
          Mean value_function loss: 32.0591
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 40.3823
                       Mean reward: 798.73
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.7631
    Episode_Reward/rotating_object: 156.0739
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 1.86s
                      Time elapsed: 00:28:06
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 53249 steps/s (collection: 1.738s, learning 0.109s)
             Mean action noise std: 2.43
          Mean value_function loss: 39.8391
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 40.3949
                       Mean reward: 785.12
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7596
    Episode_Reward/rotating_object: 155.2197
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 1.85s
                      Time elapsed: 00:28:08
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 53828 steps/s (collection: 1.735s, learning 0.091s)
             Mean action noise std: 2.43
          Mean value_function loss: 39.1225
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.4017
                       Mean reward: 751.01
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 154.2950
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 1.83s
                      Time elapsed: 00:28:10
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 53821 steps/s (collection: 1.730s, learning 0.097s)
             Mean action noise std: 2.44
          Mean value_function loss: 34.9006
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.4114
                       Mean reward: 799.42
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7540
    Episode_Reward/rotating_object: 152.5374
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.83s
                      Time elapsed: 00:28:12
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 52593 steps/s (collection: 1.766s, learning 0.104s)
             Mean action noise std: 2.44
          Mean value_function loss: 41.2432
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.4272
                       Mean reward: 767.18
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 152.6620
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.87s
                      Time elapsed: 00:28:13
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 54154 steps/s (collection: 1.719s, learning 0.097s)
             Mean action noise std: 2.44
          Mean value_function loss: 47.9505
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.4392
                       Mean reward: 755.78
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 153.5174
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.82s
                      Time elapsed: 00:28:15
                               ETA: 00:25:05

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 51487 steps/s (collection: 1.747s, learning 0.162s)
             Mean action noise std: 2.44
          Mean value_function loss: 48.7669
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.4498
                       Mean reward: 785.47
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 0.7487
    Episode_Reward/rotating_object: 154.7077
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.91s
                      Time elapsed: 00:28:17
                               ETA: 00:25:03

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 52825 steps/s (collection: 1.737s, learning 0.124s)
             Mean action noise std: 2.44
          Mean value_function loss: 51.6854
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.4608
                       Mean reward: 726.58
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 152.1849
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.86s
                      Time elapsed: 00:28:19
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 53369 steps/s (collection: 1.752s, learning 0.090s)
             Mean action noise std: 2.45
          Mean value_function loss: 38.6198
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.4827
                       Mean reward: 761.13
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 151.9949
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.84s
                      Time elapsed: 00:28:21
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 53658 steps/s (collection: 1.721s, learning 0.111s)
             Mean action noise std: 2.45
          Mean value_function loss: 48.8275
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.5004
                       Mean reward: 757.85
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 153.2477
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.83s
                      Time elapsed: 00:28:23
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 52677 steps/s (collection: 1.752s, learning 0.114s)
             Mean action noise std: 2.45
          Mean value_function loss: 46.6743
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.5147
                       Mean reward: 741.34
               Mean episode length: 234.81
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 152.8757
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.87s
                      Time elapsed: 00:28:25
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 51704 steps/s (collection: 1.777s, learning 0.125s)
             Mean action noise std: 2.45
          Mean value_function loss: 41.6926
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.5257
                       Mean reward: 796.53
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 157.1390
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.90s
                      Time elapsed: 00:28:26
                               ETA: 00:24:51

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 52024 steps/s (collection: 1.790s, learning 0.100s)
             Mean action noise std: 2.46
          Mean value_function loss: 49.0269
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.5412
                       Mean reward: 766.79
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 0.7338
    Episode_Reward/rotating_object: 151.9541
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.89s
                      Time elapsed: 00:28:28
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 52422 steps/s (collection: 1.769s, learning 0.106s)
             Mean action noise std: 2.46
          Mean value_function loss: 41.3546
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.5602
                       Mean reward: 771.98
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.7396
    Episode_Reward/rotating_object: 154.3931
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.88s
                      Time elapsed: 00:28:30
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 52850 steps/s (collection: 1.727s, learning 0.133s)
             Mean action noise std: 2.46
          Mean value_function loss: 41.6213
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.5823
                       Mean reward: 764.63
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 0.7362
    Episode_Reward/rotating_object: 153.6051
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.86s
                      Time elapsed: 00:28:32
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 53310 steps/s (collection: 1.738s, learning 0.106s)
             Mean action noise std: 2.46
          Mean value_function loss: 33.8593
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.5987
                       Mean reward: 789.56
               Mean episode length: 248.20
    Episode_Reward/reaching_object: 0.7403
    Episode_Reward/rotating_object: 155.3070
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.84s
                      Time elapsed: 00:28:34
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 51699 steps/s (collection: 1.802s, learning 0.100s)
             Mean action noise std: 2.47
          Mean value_function loss: 38.3424
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.6166
                       Mean reward: 773.84
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.7424
    Episode_Reward/rotating_object: 155.4332
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 1.90s
                      Time elapsed: 00:28:36
                               ETA: 00:24:39

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 52078 steps/s (collection: 1.786s, learning 0.102s)
             Mean action noise std: 2.47
          Mean value_function loss: 33.8053
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.6270
                       Mean reward: 792.44
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.7423
    Episode_Reward/rotating_object: 156.3310
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.89s
                      Time elapsed: 00:28:38
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 51110 steps/s (collection: 1.812s, learning 0.112s)
             Mean action noise std: 2.47
          Mean value_function loss: 46.6377
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.6403
                       Mean reward: 766.91
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 152.2798
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.92s
                      Time elapsed: 00:28:40
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 52502 steps/s (collection: 1.767s, learning 0.106s)
             Mean action noise std: 2.47
          Mean value_function loss: 44.0259
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.6538
                       Mean reward: 782.50
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 0.7319
    Episode_Reward/rotating_object: 153.0369
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.87s
                      Time elapsed: 00:28:41
                               ETA: 00:24:32

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 53123 steps/s (collection: 1.752s, learning 0.099s)
             Mean action noise std: 2.47
          Mean value_function loss: 56.3503
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 40.6707
                       Mean reward: 745.62
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 0.7323
    Episode_Reward/rotating_object: 152.8676
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.85s
                      Time elapsed: 00:28:43
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 51503 steps/s (collection: 1.810s, learning 0.099s)
             Mean action noise std: 2.48
          Mean value_function loss: 44.8516
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.6892
                       Mean reward: 780.50
               Mean episode length: 246.22
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 154.4384
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.91s
                      Time elapsed: 00:28:45
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 51840 steps/s (collection: 1.790s, learning 0.106s)
             Mean action noise std: 2.48
          Mean value_function loss: 38.1446
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.7038
                       Mean reward: 788.68
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 154.9201
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.90s
                      Time elapsed: 00:28:47
                               ETA: 00:24:25

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 51515 steps/s (collection: 1.761s, learning 0.147s)
             Mean action noise std: 2.48
          Mean value_function loss: 39.3285
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.7218
                       Mean reward: 781.74
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 153.4917
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 1.91s
                      Time elapsed: 00:28:49
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 52805 steps/s (collection: 1.745s, learning 0.117s)
             Mean action noise std: 2.49
          Mean value_function loss: 42.0913
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.7412
                       Mean reward: 790.70
               Mean episode length: 244.86
    Episode_Reward/reaching_object: 0.7388
    Episode_Reward/rotating_object: 152.7257
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.86s
                      Time elapsed: 00:28:51
                               ETA: 00:24:21

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 53430 steps/s (collection: 1.739s, learning 0.101s)
             Mean action noise std: 2.49
          Mean value_function loss: 43.4605
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.7557
                       Mean reward: 778.95
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.7489
    Episode_Reward/rotating_object: 156.1247
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.84s
                      Time elapsed: 00:28:53
                               ETA: 00:24:18

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 53314 steps/s (collection: 1.723s, learning 0.121s)
             Mean action noise std: 2.49
          Mean value_function loss: 27.3780
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.7740
                       Mean reward: 781.79
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 154.1446
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.84s
                      Time elapsed: 00:28:55
                               ETA: 00:24:16

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 53393 steps/s (collection: 1.748s, learning 0.094s)
             Mean action noise std: 2.49
          Mean value_function loss: 31.5868
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.7936
                       Mean reward: 771.87
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 0.7541
    Episode_Reward/rotating_object: 157.3993
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.84s
                      Time elapsed: 00:28:56
                               ETA: 00:24:14

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 52341 steps/s (collection: 1.748s, learning 0.130s)
             Mean action noise std: 2.49
          Mean value_function loss: 44.1777
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.8100
                       Mean reward: 776.11
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 155.0311
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.88s
                      Time elapsed: 00:28:58
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 52111 steps/s (collection: 1.790s, learning 0.096s)
             Mean action noise std: 2.50
          Mean value_function loss: 37.0594
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.8289
                       Mean reward: 741.14
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 0.7444
    Episode_Reward/rotating_object: 151.4904
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.89s
                      Time elapsed: 00:29:00
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 51975 steps/s (collection: 1.785s, learning 0.107s)
             Mean action noise std: 2.50
          Mean value_function loss: 43.9501
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.8480
                       Mean reward: 785.12
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.7428
    Episode_Reward/rotating_object: 151.0561
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.89s
                      Time elapsed: 00:29:02
                               ETA: 00:24:07

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 53077 steps/s (collection: 1.727s, learning 0.125s)
             Mean action noise std: 2.50
          Mean value_function loss: 35.8623
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 40.8584
                       Mean reward: 786.36
               Mean episode length: 246.42
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 153.8086
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.85s
                      Time elapsed: 00:29:04
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 53372 steps/s (collection: 1.745s, learning 0.097s)
             Mean action noise std: 2.50
          Mean value_function loss: 35.4757
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 40.8594
                       Mean reward: 766.39
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 154.2360
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.84s
                      Time elapsed: 00:29:06
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 52675 steps/s (collection: 1.763s, learning 0.103s)
             Mean action noise std: 2.50
          Mean value_function loss: 39.3475
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.8623
                       Mean reward: 773.92
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 152.8176
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.87s
                      Time elapsed: 00:29:08
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 51132 steps/s (collection: 1.782s, learning 0.140s)
             Mean action noise std: 2.50
          Mean value_function loss: 39.7527
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.8700
                       Mean reward: 764.80
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.7491
    Episode_Reward/rotating_object: 151.8641
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.92s
                      Time elapsed: 00:29:10
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 52320 steps/s (collection: 1.773s, learning 0.106s)
             Mean action noise std: 2.51
          Mean value_function loss: 35.5730
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.8879
                       Mean reward: 788.88
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7576
    Episode_Reward/rotating_object: 155.9148
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.88s
                      Time elapsed: 00:29:11
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 51680 steps/s (collection: 1.778s, learning 0.125s)
             Mean action noise std: 2.51
          Mean value_function loss: 32.7820
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.8991
                       Mean reward: 788.57
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7589
    Episode_Reward/rotating_object: 156.7686
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.90s
                      Time elapsed: 00:29:13
                               ETA: 00:23:53

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 51234 steps/s (collection: 1.800s, learning 0.119s)
             Mean action noise std: 2.51
          Mean value_function loss: 31.8046
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.9102
                       Mean reward: 773.03
               Mean episode length: 244.70
    Episode_Reward/reaching_object: 0.7655
    Episode_Reward/rotating_object: 156.5713
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.92s
                      Time elapsed: 00:29:15
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 50768 steps/s (collection: 1.785s, learning 0.151s)
             Mean action noise std: 2.51
          Mean value_function loss: 43.4125
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.9275
                       Mean reward: 758.29
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 152.2015
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.94s
                      Time elapsed: 00:29:17
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 52061 steps/s (collection: 1.756s, learning 0.132s)
             Mean action noise std: 2.52
          Mean value_function loss: 48.3237
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.9498
                       Mean reward: 751.15
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 150.7843
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.89s
                      Time elapsed: 00:29:19
                               ETA: 00:23:46

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 53106 steps/s (collection: 1.756s, learning 0.095s)
             Mean action noise std: 2.52
          Mean value_function loss: 40.5658
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.9606
                       Mean reward: 782.84
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7654
    Episode_Reward/rotating_object: 157.0734
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.85s
                      Time elapsed: 00:29:21
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 51325 steps/s (collection: 1.782s, learning 0.133s)
             Mean action noise std: 2.52
          Mean value_function loss: 37.4759
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.9762
                       Mean reward: 766.53
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 152.7505
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.92s
                      Time elapsed: 00:29:23
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 52236 steps/s (collection: 1.791s, learning 0.091s)
             Mean action noise std: 2.52
          Mean value_function loss: 45.9318
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.9846
                       Mean reward: 760.63
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 153.4162
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.88s
                      Time elapsed: 00:29:25
                               ETA: 00:23:39

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 51783 steps/s (collection: 1.787s, learning 0.111s)
             Mean action noise std: 2.52
          Mean value_function loss: 34.9173
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.9957
                       Mean reward: 782.33
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 152.7411
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.90s
                      Time elapsed: 00:29:27
                               ETA: 00:23:37

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 52458 steps/s (collection: 1.781s, learning 0.093s)
             Mean action noise std: 2.53
          Mean value_function loss: 27.6855
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.0124
                       Mean reward: 750.67
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 153.5020
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.87s
                      Time elapsed: 00:29:28
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 51437 steps/s (collection: 1.784s, learning 0.128s)
             Mean action noise std: 2.53
          Mean value_function loss: 34.7499
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.0317
                       Mean reward: 762.46
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 155.6980
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.91s
                      Time elapsed: 00:29:30
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 51572 steps/s (collection: 1.766s, learning 0.140s)
             Mean action noise std: 2.53
          Mean value_function loss: 43.3068
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.0415
                       Mean reward: 760.84
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 0.7599
    Episode_Reward/rotating_object: 154.6876
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.91s
                      Time elapsed: 00:29:32
                               ETA: 00:23:30

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 49712 steps/s (collection: 1.814s, learning 0.163s)
             Mean action noise std: 2.53
          Mean value_function loss: 30.9718
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 41.0574
                       Mean reward: 796.57
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 154.2704
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.98s
                      Time elapsed: 00:29:34
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 52447 steps/s (collection: 1.769s, learning 0.105s)
             Mean action noise std: 2.54
          Mean value_function loss: 40.0329
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.0762
                       Mean reward: 746.05
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 150.2538
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.87s
                      Time elapsed: 00:29:36
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 53771 steps/s (collection: 1.735s, learning 0.094s)
             Mean action noise std: 2.54
          Mean value_function loss: 59.3943
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.0887
                       Mean reward: 763.70
               Mean episode length: 239.45
    Episode_Reward/reaching_object: 0.7540
    Episode_Reward/rotating_object: 153.5059
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.83s
                      Time elapsed: 00:29:38
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 52168 steps/s (collection: 1.783s, learning 0.101s)
             Mean action noise std: 2.54
          Mean value_function loss: 36.1431
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.0997
                       Mean reward: 771.80
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 152.4143
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.88s
                      Time elapsed: 00:29:40
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 52831 steps/s (collection: 1.764s, learning 0.097s)
             Mean action noise std: 2.54
          Mean value_function loss: 39.9266
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.1119
                       Mean reward: 754.06
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 150.9167
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.86s
                      Time elapsed: 00:29:42
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 53005 steps/s (collection: 1.764s, learning 0.091s)
             Mean action noise std: 2.54
          Mean value_function loss: 49.4833
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.1199
                       Mean reward: 758.10
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 151.1678
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.85s
                      Time elapsed: 00:29:44
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 53176 steps/s (collection: 1.723s, learning 0.126s)
             Mean action noise std: 2.55
          Mean value_function loss: 44.6404
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.1268
                       Mean reward: 792.16
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7576
    Episode_Reward/rotating_object: 153.8044
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.85s
                      Time elapsed: 00:29:45
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 51341 steps/s (collection: 1.748s, learning 0.167s)
             Mean action noise std: 2.55
          Mean value_function loss: 45.0431
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.1340
                       Mean reward: 779.49
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 151.4251
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.91s
                      Time elapsed: 00:29:47
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 53974 steps/s (collection: 1.707s, learning 0.114s)
             Mean action noise std: 2.55
          Mean value_function loss: 36.0148
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 41.1460
                       Mean reward: 796.75
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 154.1336
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.82s
                      Time elapsed: 00:29:49
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 52309 steps/s (collection: 1.761s, learning 0.119s)
             Mean action noise std: 2.55
          Mean value_function loss: 45.5675
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.1658
                       Mean reward: 791.26
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 0.7605
    Episode_Reward/rotating_object: 154.8420
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.88s
                      Time elapsed: 00:29:51
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 51514 steps/s (collection: 1.788s, learning 0.120s)
             Mean action noise std: 2.55
          Mean value_function loss: 45.9823
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.1826
                       Mean reward: 750.58
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 152.0702
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.91s
                      Time elapsed: 00:29:53
                               ETA: 00:23:04

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 52040 steps/s (collection: 1.772s, learning 0.117s)
             Mean action noise std: 2.56
          Mean value_function loss: 34.4566
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.1926
                       Mean reward: 749.58
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 152.9420
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.89s
                      Time elapsed: 00:29:55
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 52971 steps/s (collection: 1.745s, learning 0.111s)
             Mean action noise std: 2.56
          Mean value_function loss: 39.3019
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.2041
                       Mean reward: 795.04
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7541
    Episode_Reward/rotating_object: 155.3425
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.86s
                      Time elapsed: 00:29:57
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 52646 steps/s (collection: 1.747s, learning 0.120s)
             Mean action noise std: 2.56
          Mean value_function loss: 45.1945
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.2158
                       Mean reward: 787.95
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 156.5733
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.87s
                      Time elapsed: 00:29:59
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 51238 steps/s (collection: 1.760s, learning 0.158s)
             Mean action noise std: 2.56
          Mean value_function loss: 38.2312
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.2307
                       Mean reward: 783.99
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 0.7554
    Episode_Reward/rotating_object: 155.8104
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.92s
                      Time elapsed: 00:30:00
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 51016 steps/s (collection: 1.786s, learning 0.141s)
             Mean action noise std: 2.57
          Mean value_function loss: 37.1472
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.2509
                       Mean reward: 780.69
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 158.2007
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 1.93s
                      Time elapsed: 00:30:02
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 52803 steps/s (collection: 1.720s, learning 0.142s)
             Mean action noise std: 2.57
          Mean value_function loss: 41.0102
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.2681
                       Mean reward: 773.57
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 0.7383
    Episode_Reward/rotating_object: 151.9125
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 1.86s
                      Time elapsed: 00:30:04
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 53273 steps/s (collection: 1.750s, learning 0.096s)
             Mean action noise std: 2.57
          Mean value_function loss: 35.5518
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.2859
                       Mean reward: 787.20
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 157.6050
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 1.85s
                      Time elapsed: 00:30:06
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 52751 steps/s (collection: 1.765s, learning 0.098s)
             Mean action noise std: 2.57
          Mean value_function loss: 33.2324
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.2980
                       Mean reward: 793.18
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 153.4106
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 1.86s
                      Time elapsed: 00:30:08
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 53350 steps/s (collection: 1.740s, learning 0.103s)
             Mean action noise std: 2.58
          Mean value_function loss: 45.2092
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.3089
                       Mean reward: 777.24
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 153.4714
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 1.84s
                      Time elapsed: 00:30:10
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 53195 steps/s (collection: 1.752s, learning 0.096s)
             Mean action noise std: 2.58
          Mean value_function loss: 38.9076
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.3244
                       Mean reward: 773.76
               Mean episode length: 240.38
    Episode_Reward/reaching_object: 0.7376
    Episode_Reward/rotating_object: 153.4048
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 1.85s
                      Time elapsed: 00:30:12
                               ETA: 00:22:41

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 51599 steps/s (collection: 1.773s, learning 0.133s)
             Mean action noise std: 2.58
          Mean value_function loss: 28.8333
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.3380
                       Mean reward: 756.58
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 154.5489
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.91s
                      Time elapsed: 00:30:14
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 52462 steps/s (collection: 1.731s, learning 0.143s)
             Mean action noise std: 2.58
          Mean value_function loss: 53.4311
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.3496
                       Mean reward: 784.56
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 152.1699
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 1.87s
                      Time elapsed: 00:30:15
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 52821 steps/s (collection: 1.710s, learning 0.151s)
             Mean action noise std: 2.58
          Mean value_function loss: 45.7666
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.3652
                       Mean reward: 785.48
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.7404
    Episode_Reward/rotating_object: 154.5345
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.86s
                      Time elapsed: 00:30:17
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 53309 steps/s (collection: 1.751s, learning 0.093s)
             Mean action noise std: 2.59
          Mean value_function loss: 49.3465
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 41.3875
                       Mean reward: 756.29
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 0.7392
    Episode_Reward/rotating_object: 152.2012
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 1.84s
                      Time elapsed: 00:30:19
                               ETA: 00:22:32

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 52437 steps/s (collection: 1.757s, learning 0.118s)
             Mean action noise std: 2.59
          Mean value_function loss: 41.3589
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.4065
                       Mean reward: 777.57
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 154.1098
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 1.87s
                      Time elapsed: 00:30:21
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 53501 steps/s (collection: 1.732s, learning 0.105s)
             Mean action noise std: 2.59
          Mean value_function loss: 45.7117
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.4221
                       Mean reward: 776.98
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 0.7336
    Episode_Reward/rotating_object: 151.1766
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.84s
                      Time elapsed: 00:30:23
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 52479 steps/s (collection: 1.756s, learning 0.118s)
             Mean action noise std: 2.60
          Mean value_function loss: 40.9762
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.4432
                       Mean reward: 791.59
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 155.2094
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.87s
                      Time elapsed: 00:30:25
                               ETA: 00:22:25

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 51535 steps/s (collection: 1.773s, learning 0.134s)
             Mean action noise std: 2.60
          Mean value_function loss: 34.1096
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.4543
                       Mean reward: 770.21
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 0.7428
    Episode_Reward/rotating_object: 154.4236
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.91s
                      Time elapsed: 00:30:27
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 52895 steps/s (collection: 1.732s, learning 0.127s)
             Mean action noise std: 2.60
          Mean value_function loss: 39.4622
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.4697
                       Mean reward: 818.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7414
    Episode_Reward/rotating_object: 156.2488
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.86s
                      Time elapsed: 00:30:29
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 52165 steps/s (collection: 1.750s, learning 0.134s)
             Mean action noise std: 2.60
          Mean value_function loss: 46.1450
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.4874
                       Mean reward: 778.58
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 152.1079
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.88s
                      Time elapsed: 00:30:30
                               ETA: 00:22:18

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 52191 steps/s (collection: 1.785s, learning 0.099s)
             Mean action noise std: 2.61
          Mean value_function loss: 48.0610
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.5121
                       Mean reward: 778.26
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 0.7352
    Episode_Reward/rotating_object: 153.1546
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.88s
                      Time elapsed: 00:30:32
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 49991 steps/s (collection: 1.832s, learning 0.134s)
             Mean action noise std: 2.61
          Mean value_function loss: 48.2671
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.5357
                       Mean reward: 780.36
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 153.5377
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.97s
                      Time elapsed: 00:30:34
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 52250 steps/s (collection: 1.790s, learning 0.092s)
             Mean action noise std: 2.61
          Mean value_function loss: 36.1309
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 41.5468
                       Mean reward: 792.55
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 157.0470
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.88s
                      Time elapsed: 00:30:36
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 53119 steps/s (collection: 1.757s, learning 0.094s)
             Mean action noise std: 2.61
          Mean value_function loss: 42.4844
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.5666
                       Mean reward: 782.90
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 155.0675
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.85s
                      Time elapsed: 00:30:38
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 52092 steps/s (collection: 1.789s, learning 0.098s)
             Mean action noise std: 2.62
          Mean value_function loss: 33.7580
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.5791
                       Mean reward: 792.98
               Mean episode length: 246.29
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 153.1853
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.89s
                      Time elapsed: 00:30:40
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 52067 steps/s (collection: 1.784s, learning 0.104s)
             Mean action noise std: 2.62
          Mean value_function loss: 51.8408
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.5876
                       Mean reward: 789.67
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.7400
    Episode_Reward/rotating_object: 152.3447
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.89s
                      Time elapsed: 00:30:42
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 52223 steps/s (collection: 1.790s, learning 0.092s)
             Mean action noise std: 2.62
          Mean value_function loss: 40.6509
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.5940
                       Mean reward: 779.50
               Mean episode length: 247.16
    Episode_Reward/reaching_object: 0.7409
    Episode_Reward/rotating_object: 151.0901
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.88s
                      Time elapsed: 00:30:44
                               ETA: 00:22:02

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 51837 steps/s (collection: 1.786s, learning 0.111s)
             Mean action noise std: 2.62
          Mean value_function loss: 38.3747
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.6066
                       Mean reward: 781.91
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 153.7597
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.90s
                      Time elapsed: 00:30:46
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 51488 steps/s (collection: 1.777s, learning 0.132s)
             Mean action noise std: 2.62
          Mean value_function loss: 26.3363
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.6197
                       Mean reward: 802.76
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 151.6609
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.91s
                      Time elapsed: 00:30:47
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 52674 steps/s (collection: 1.772s, learning 0.095s)
             Mean action noise std: 2.62
          Mean value_function loss: 35.0689
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.6305
                       Mean reward: 751.37
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 0.7546
    Episode_Reward/rotating_object: 153.4551
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.87s
                      Time elapsed: 00:30:49
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 51619 steps/s (collection: 1.800s, learning 0.104s)
             Mean action noise std: 2.63
          Mean value_function loss: 33.6281
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.6454
                       Mean reward: 794.07
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7587
    Episode_Reward/rotating_object: 155.8977
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.90s
                      Time elapsed: 00:30:51
                               ETA: 00:21:53

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 51746 steps/s (collection: 1.793s, learning 0.107s)
             Mean action noise std: 2.63
          Mean value_function loss: 36.5875
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.6611
                       Mean reward: 745.72
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 153.6012
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.90s
                      Time elapsed: 00:30:53
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 51640 steps/s (collection: 1.788s, learning 0.116s)
             Mean action noise std: 2.63
          Mean value_function loss: 37.2411
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.6712
                       Mean reward: 758.60
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.7639
    Episode_Reward/rotating_object: 154.1476
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.90s
                      Time elapsed: 00:30:55
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 51490 steps/s (collection: 1.796s, learning 0.114s)
             Mean action noise std: 2.63
          Mean value_function loss: 48.8152
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.6787
                       Mean reward: 775.13
               Mean episode length: 244.85
    Episode_Reward/reaching_object: 0.7522
    Episode_Reward/rotating_object: 152.6573
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.91s
                      Time elapsed: 00:30:57
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 52681 steps/s (collection: 1.765s, learning 0.101s)
             Mean action noise std: 2.63
          Mean value_function loss: 35.9829
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.6897
                       Mean reward: 798.36
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 152.9582
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 1.87s
                      Time elapsed: 00:30:59
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 51628 steps/s (collection: 1.778s, learning 0.126s)
             Mean action noise std: 2.64
          Mean value_function loss: 39.0620
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.7019
                       Mean reward: 785.25
               Mean episode length: 246.69
    Episode_Reward/reaching_object: 0.7708
    Episode_Reward/rotating_object: 156.6018
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.90s
                      Time elapsed: 00:31:01
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 52603 steps/s (collection: 1.769s, learning 0.100s)
             Mean action noise std: 2.64
          Mean value_function loss: 46.9715
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.7156
                       Mean reward: 727.69
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 151.5995
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.87s
                      Time elapsed: 00:31:03
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 51193 steps/s (collection: 1.770s, learning 0.151s)
             Mean action noise std: 2.64
          Mean value_function loss: 40.5724
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.7264
                       Mean reward: 773.97
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 0.7570
    Episode_Reward/rotating_object: 155.2920
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.92s
                      Time elapsed: 00:31:04
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 53386 steps/s (collection: 1.743s, learning 0.099s)
             Mean action noise std: 2.64
          Mean value_function loss: 42.1121
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.7314
                       Mean reward: 773.59
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 0.7576
    Episode_Reward/rotating_object: 151.2423
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.84s
                      Time elapsed: 00:31:06
                               ETA: 00:21:35

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 53417 steps/s (collection: 1.736s, learning 0.105s)
             Mean action noise std: 2.64
          Mean value_function loss: 28.8049
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.7334
                       Mean reward: 791.90
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7694
    Episode_Reward/rotating_object: 153.9009
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.84s
                      Time elapsed: 00:31:08
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 52968 steps/s (collection: 1.753s, learning 0.103s)
             Mean action noise std: 2.64
          Mean value_function loss: 48.6873
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 41.7382
                       Mean reward: 779.12
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.7648
    Episode_Reward/rotating_object: 155.8074
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.86s
                      Time elapsed: 00:31:10
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 52668 steps/s (collection: 1.774s, learning 0.093s)
             Mean action noise std: 2.64
          Mean value_function loss: 42.4481
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.7493
                       Mean reward: 755.75
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 0.7658
    Episode_Reward/rotating_object: 154.5744
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.87s
                      Time elapsed: 00:31:12
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 52514 steps/s (collection: 1.777s, learning 0.095s)
             Mean action noise std: 2.65
          Mean value_function loss: 42.2493
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.7548
                       Mean reward: 747.63
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.7571
    Episode_Reward/rotating_object: 153.2207
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.87s
                      Time elapsed: 00:31:14
                               ETA: 00:21:26

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 50523 steps/s (collection: 1.807s, learning 0.139s)
             Mean action noise std: 2.65
          Mean value_function loss: 43.2268
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.7682
                       Mean reward: 788.66
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 156.1511
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.95s
                      Time elapsed: 00:31:16
                               ETA: 00:21:24

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 50715 steps/s (collection: 1.777s, learning 0.162s)
             Mean action noise std: 2.65
          Mean value_function loss: 30.1943
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.7828
                       Mean reward: 769.74
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 152.2649
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.94s
                      Time elapsed: 00:31:18
                               ETA: 00:21:22

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 53012 steps/s (collection: 1.733s, learning 0.122s)
             Mean action noise std: 2.65
          Mean value_function loss: 34.1321
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.7921
                       Mean reward: 776.88
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 0.7680
    Episode_Reward/rotating_object: 154.1271
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.85s
                      Time elapsed: 00:31:20
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 52133 steps/s (collection: 1.788s, learning 0.098s)
             Mean action noise std: 2.65
          Mean value_function loss: 34.9008
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.7980
                       Mean reward: 787.14
               Mean episode length: 246.54
    Episode_Reward/reaching_object: 0.7774
    Episode_Reward/rotating_object: 157.9908
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 1.89s
                      Time elapsed: 00:31:21
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 51549 steps/s (collection: 1.808s, learning 0.099s)
             Mean action noise std: 2.65
          Mean value_function loss: 43.4812
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.8003
                       Mean reward: 734.98
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 153.3180
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 1.91s
                      Time elapsed: 00:31:23
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 52415 steps/s (collection: 1.770s, learning 0.106s)
             Mean action noise std: 2.66
          Mean value_function loss: 37.5855
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.8066
                       Mean reward: 782.24
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7653
    Episode_Reward/rotating_object: 156.2739
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 1.88s
                      Time elapsed: 00:31:25
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 52544 steps/s (collection: 1.751s, learning 0.120s)
             Mean action noise std: 2.66
          Mean value_function loss: 33.4315
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.8233
                       Mean reward: 779.49
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 0.7663
    Episode_Reward/rotating_object: 157.9132
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 1.87s
                      Time elapsed: 00:31:27
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 52149 steps/s (collection: 1.792s, learning 0.093s)
             Mean action noise std: 2.66
          Mean value_function loss: 44.5314
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.8442
                       Mean reward: 733.59
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 151.9064
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 1.89s
                      Time elapsed: 00:31:29
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 51900 steps/s (collection: 1.729s, learning 0.165s)
             Mean action noise std: 2.67
          Mean value_function loss: 29.1473
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.8565
                       Mean reward: 773.19
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 155.9633
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 1.89s
                      Time elapsed: 00:31:31
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 53516 steps/s (collection: 1.729s, learning 0.108s)
             Mean action noise std: 2.67
          Mean value_function loss: 40.4977
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.8652
                       Mean reward: 794.79
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 0.7569
    Episode_Reward/rotating_object: 158.4245
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 1.84s
                      Time elapsed: 00:31:33
                               ETA: 00:21:04

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 48989 steps/s (collection: 1.825s, learning 0.182s)
             Mean action noise std: 2.67
          Mean value_function loss: 41.0453
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.8784
                       Mean reward: 789.43
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.7608
    Episode_Reward/rotating_object: 158.0513
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.01s
                      Time elapsed: 00:31:35
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 52552 steps/s (collection: 1.773s, learning 0.098s)
             Mean action noise std: 2.67
          Mean value_function loss: 39.7448
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.8869
                       Mean reward: 754.55
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 154.3113
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 1.87s
                      Time elapsed: 00:31:37
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 52644 steps/s (collection: 1.776s, learning 0.091s)
             Mean action noise std: 2.67
          Mean value_function loss: 34.9227
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.8908
                       Mean reward: 788.40
               Mean episode length: 247.41
    Episode_Reward/reaching_object: 0.7554
    Episode_Reward/rotating_object: 155.6085
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 1.87s
                      Time elapsed: 00:31:38
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 51867 steps/s (collection: 1.791s, learning 0.104s)
             Mean action noise std: 2.67
          Mean value_function loss: 35.3693
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.9025
                       Mean reward: 774.00
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 0.7538
    Episode_Reward/rotating_object: 155.9503
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 1.90s
                      Time elapsed: 00:31:40
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 51689 steps/s (collection: 1.803s, learning 0.099s)
             Mean action noise std: 2.68
          Mean value_function loss: 39.6084
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.9199
                       Mean reward: 781.43
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 0.7451
    Episode_Reward/rotating_object: 153.9567
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.90s
                      Time elapsed: 00:31:42
                               ETA: 00:20:53

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 52543 steps/s (collection: 1.759s, learning 0.112s)
             Mean action noise std: 2.68
          Mean value_function loss: 29.6503
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.9297
                       Mean reward: 800.83
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7611
    Episode_Reward/rotating_object: 158.5284
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.87s
                      Time elapsed: 00:31:44
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 51843 steps/s (collection: 1.782s, learning 0.114s)
             Mean action noise std: 2.68
          Mean value_function loss: 33.2017
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.9410
                       Mean reward: 802.33
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.7568
    Episode_Reward/rotating_object: 155.7372
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 1.90s
                      Time elapsed: 00:31:46
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 52418 steps/s (collection: 1.731s, learning 0.144s)
             Mean action noise std: 2.68
          Mean value_function loss: 24.1146
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.9579
                       Mean reward: 780.22
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 0.7557
    Episode_Reward/rotating_object: 157.7435
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.88s
                      Time elapsed: 00:31:48
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 51586 steps/s (collection: 1.745s, learning 0.160s)
             Mean action noise std: 2.69
          Mean value_function loss: 33.0865
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.9720
                       Mean reward: 785.93
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 0.7564
    Episode_Reward/rotating_object: 156.4616
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 1.91s
                      Time elapsed: 00:31:50
                               ETA: 00:20:44

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 52382 steps/s (collection: 1.767s, learning 0.110s)
             Mean action noise std: 2.69
          Mean value_function loss: 32.2496
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.9827
                       Mean reward: 752.44
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 0.7428
    Episode_Reward/rotating_object: 151.6590
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 1.88s
                      Time elapsed: 00:31:52
                               ETA: 00:20:41

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 52587 steps/s (collection: 1.772s, learning 0.098s)
             Mean action noise std: 2.69
          Mean value_function loss: 53.8441
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.9905
                       Mean reward: 775.84
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 154.7685
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.87s
                      Time elapsed: 00:31:53
                               ETA: 00:20:39

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 52903 steps/s (collection: 1.757s, learning 0.101s)
             Mean action noise std: 2.69
          Mean value_function loss: 39.8191
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.0085
                       Mean reward: 764.53
               Mean episode length: 244.81
    Episode_Reward/reaching_object: 0.7539
    Episode_Reward/rotating_object: 156.2835
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.86s
                      Time elapsed: 00:31:55
                               ETA: 00:20:37

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 53656 steps/s (collection: 1.716s, learning 0.116s)
             Mean action noise std: 2.70
          Mean value_function loss: 38.7095
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.0327
                       Mean reward: 786.31
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 154.2671
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 1.83s
                      Time elapsed: 00:31:57
                               ETA: 00:20:35

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 53399 steps/s (collection: 1.748s, learning 0.093s)
             Mean action noise std: 2.70
          Mean value_function loss: 26.8900
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.0494
                       Mean reward: 800.52
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 158.4698
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.84s
                      Time elapsed: 00:31:59
                               ETA: 00:20:32

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 53106 steps/s (collection: 1.722s, learning 0.129s)
             Mean action noise std: 2.70
          Mean value_function loss: 36.7642
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.0678
                       Mean reward: 804.94
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.7491
    Episode_Reward/rotating_object: 155.9061
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.85s
                      Time elapsed: 00:32:01
                               ETA: 00:20:30

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 51546 steps/s (collection: 1.754s, learning 0.153s)
             Mean action noise std: 2.70
          Mean value_function loss: 35.6048
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.0809
                       Mean reward: 774.54
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 0.7503
    Episode_Reward/rotating_object: 155.9969
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.91s
                      Time elapsed: 00:32:03
                               ETA: 00:20:28

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 53045 steps/s (collection: 1.734s, learning 0.119s)
             Mean action noise std: 2.71
          Mean value_function loss: 30.6590
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.0914
                       Mean reward: 797.57
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 158.0011
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.85s
                      Time elapsed: 00:32:05
                               ETA: 00:20:26

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 52217 steps/s (collection: 1.785s, learning 0.098s)
             Mean action noise std: 2.71
          Mean value_function loss: 37.6706
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.0999
                       Mean reward: 784.73
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 155.2572
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.88s
                      Time elapsed: 00:32:07
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 52003 steps/s (collection: 1.785s, learning 0.105s)
             Mean action noise std: 2.71
          Mean value_function loss: 40.4268
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.1118
                       Mean reward: 785.39
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 156.0762
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 1.89s
                      Time elapsed: 00:32:08
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 51504 steps/s (collection: 1.800s, learning 0.109s)
             Mean action noise std: 2.71
          Mean value_function loss: 39.3731
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.1256
                       Mean reward: 774.60
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 154.5148
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 1.91s
                      Time elapsed: 00:32:10
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 52406 steps/s (collection: 1.766s, learning 0.110s)
             Mean action noise std: 2.71
          Mean value_function loss: 40.2497
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.1409
                       Mean reward: 756.27
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 153.9803
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.88s
                      Time elapsed: 00:32:12
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 52059 steps/s (collection: 1.784s, learning 0.104s)
             Mean action noise std: 2.72
          Mean value_function loss: 47.5169
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.1600
                       Mean reward: 801.68
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 153.3165
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.89s
                      Time elapsed: 00:32:14
                               ETA: 00:20:14

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 49187 steps/s (collection: 1.828s, learning 0.171s)
             Mean action noise std: 2.72
          Mean value_function loss: 32.8988
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.1692
                       Mean reward: 797.35
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 157.0238
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.00s
                      Time elapsed: 00:32:16
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 50807 steps/s (collection: 1.814s, learning 0.121s)
             Mean action noise std: 2.72
          Mean value_function loss: 33.9897
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.1781
                       Mean reward: 772.77
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 153.6825
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.93s
                      Time elapsed: 00:32:18
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 50035 steps/s (collection: 1.831s, learning 0.134s)
             Mean action noise std: 2.72
          Mean value_function loss: 37.0528
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.1929
                       Mean reward: 770.11
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 157.5478
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.96s
                      Time elapsed: 00:32:20
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 50671 steps/s (collection: 1.796s, learning 0.144s)
             Mean action noise std: 2.72
          Mean value_function loss: 41.2101
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.2006
                       Mean reward: 757.51
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 155.6601
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.94s
                      Time elapsed: 00:32:22
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 51585 steps/s (collection: 1.799s, learning 0.107s)
             Mean action noise std: 2.72
          Mean value_function loss: 38.5481
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.2079
                       Mean reward: 781.06
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 155.7590
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.91s
                      Time elapsed: 00:32:24
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 51503 steps/s (collection: 1.801s, learning 0.108s)
             Mean action noise std: 2.73
          Mean value_function loss: 32.4593
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.2123
                       Mean reward: 791.19
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 157.2917
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.91s
                      Time elapsed: 00:32:26
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 51082 steps/s (collection: 1.817s, learning 0.107s)
             Mean action noise std: 2.73
          Mean value_function loss: 44.1349
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.2225
                       Mean reward: 767.61
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 154.5917
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.92s
                      Time elapsed: 00:32:28
                               ETA: 00:19:59

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 52208 steps/s (collection: 1.776s, learning 0.107s)
             Mean action noise std: 2.73
          Mean value_function loss: 35.7122
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.2455
                       Mean reward: 803.96
               Mean episode length: 248.38
    Episode_Reward/reaching_object: 0.7604
    Episode_Reward/rotating_object: 158.0776
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.88s
                      Time elapsed: 00:32:30
                               ETA: 00:19:57

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 52128 steps/s (collection: 1.778s, learning 0.108s)
             Mean action noise std: 2.73
          Mean value_function loss: 37.7409
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.2656
                       Mean reward: 757.18
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 0.7586
    Episode_Reward/rotating_object: 154.7541
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 1.89s
                      Time elapsed: 00:32:31
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 50756 steps/s (collection: 1.812s, learning 0.125s)
             Mean action noise std: 2.74
          Mean value_function loss: 32.2920
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.2803
                       Mean reward: 792.88
               Mean episode length: 244.37
    Episode_Reward/reaching_object: 0.7688
    Episode_Reward/rotating_object: 158.9883
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.94s
                      Time elapsed: 00:32:33
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 51227 steps/s (collection: 1.810s, learning 0.109s)
             Mean action noise std: 2.74
          Mean value_function loss: 43.9722
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.2952
                       Mean reward: 769.77
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 154.7938
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.92s
                      Time elapsed: 00:32:35
                               ETA: 00:19:50

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 51290 steps/s (collection: 1.800s, learning 0.117s)
             Mean action noise std: 2.74
          Mean value_function loss: 43.5946
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.3046
                       Mean reward: 786.48
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 0.7653
    Episode_Reward/rotating_object: 158.3913
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.92s
                      Time elapsed: 00:32:37
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 52362 steps/s (collection: 1.778s, learning 0.100s)
             Mean action noise std: 2.74
          Mean value_function loss: 38.8856
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.3195
                       Mean reward: 764.79
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 0.7552
    Episode_Reward/rotating_object: 153.9515
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.88s
                      Time elapsed: 00:32:39
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 50966 steps/s (collection: 1.816s, learning 0.113s)
             Mean action noise std: 2.75
          Mean value_function loss: 36.8254
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.3464
                       Mean reward: 770.16
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 0.7653
    Episode_Reward/rotating_object: 155.7735
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.93s
                      Time elapsed: 00:32:41
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 50013 steps/s (collection: 1.787s, learning 0.179s)
             Mean action noise std: 2.75
          Mean value_function loss: 36.0974
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.3685
                       Mean reward: 771.65
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 0.7569
    Episode_Reward/rotating_object: 154.5304
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.97s
                      Time elapsed: 00:32:43
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 51740 steps/s (collection: 1.773s, learning 0.127s)
             Mean action noise std: 2.75
          Mean value_function loss: 31.9718
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.3830
                       Mean reward: 775.83
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 156.2219
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.90s
                      Time elapsed: 00:32:45
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 47539 steps/s (collection: 1.929s, learning 0.139s)
             Mean action noise std: 2.76
          Mean value_function loss: 43.0020
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.3965
                       Mean reward: 758.18
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 150.8913
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.07s
                      Time elapsed: 00:32:47
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 49422 steps/s (collection: 1.861s, learning 0.128s)
             Mean action noise std: 2.76
          Mean value_function loss: 33.0525
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.4064
                       Mean reward: 764.19
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 0.7591
    Episode_Reward/rotating_object: 155.9825
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.99s
                      Time elapsed: 00:32:49
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 50481 steps/s (collection: 1.805s, learning 0.143s)
             Mean action noise std: 2.76
          Mean value_function loss: 38.9278
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.4129
                       Mean reward: 805.01
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 157.6595
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.95s
                      Time elapsed: 00:32:51
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 49518 steps/s (collection: 1.829s, learning 0.157s)
             Mean action noise std: 2.76
          Mean value_function loss: 34.3646
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.4179
                       Mean reward: 791.08
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 0.7581
    Episode_Reward/rotating_object: 155.8130
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.99s
                      Time elapsed: 00:32:53
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 51134 steps/s (collection: 1.796s, learning 0.126s)
             Mean action noise std: 2.76
          Mean value_function loss: 40.6916
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 42.4207
                       Mean reward: 766.18
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 0.7634
    Episode_Reward/rotating_object: 156.2198
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.92s
                      Time elapsed: 00:32:55
                               ETA: 00:19:28

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 49558 steps/s (collection: 1.868s, learning 0.116s)
             Mean action noise std: 2.76
          Mean value_function loss: 47.9605
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.4235
                       Mean reward: 766.59
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 153.9366
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.98s
                      Time elapsed: 00:32:57
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 51351 steps/s (collection: 1.808s, learning 0.106s)
             Mean action noise std: 2.76
          Mean value_function loss: 50.3356
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.4326
                       Mean reward: 764.43
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 153.4020
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.91s
                      Time elapsed: 00:32:59
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 50293 steps/s (collection: 1.855s, learning 0.100s)
             Mean action noise std: 2.76
          Mean value_function loss: 37.0081
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.4492
                       Mean reward: 806.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7548
    Episode_Reward/rotating_object: 154.1754
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.95s
                      Time elapsed: 00:33:01
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 50002 steps/s (collection: 1.855s, learning 0.111s)
             Mean action noise std: 2.77
          Mean value_function loss: 39.9641
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.4608
                       Mean reward: 738.63
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 155.2861
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.97s
                      Time elapsed: 00:33:03
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 50992 steps/s (collection: 1.823s, learning 0.105s)
             Mean action noise std: 2.77
          Mean value_function loss: 42.5334
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.4738
                       Mean reward: 772.13
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 0.7581
    Episode_Reward/rotating_object: 155.0640
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.93s
                      Time elapsed: 00:33:05
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 50355 steps/s (collection: 1.835s, learning 0.117s)
             Mean action noise std: 2.77
          Mean value_function loss: 53.2094
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.4884
                       Mean reward: 777.62
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 154.2350
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.95s
                      Time elapsed: 00:33:06
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 50300 steps/s (collection: 1.827s, learning 0.127s)
             Mean action noise std: 2.77
          Mean value_function loss: 44.0446
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.5036
                       Mean reward: 760.15
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 149.2659
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.95s
                      Time elapsed: 00:33:08
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 50397 steps/s (collection: 1.835s, learning 0.116s)
             Mean action noise std: 2.78
          Mean value_function loss: 34.1130
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.5164
                       Mean reward: 792.01
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7714
    Episode_Reward/rotating_object: 156.5662
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.95s
                      Time elapsed: 00:33:10
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 48027 steps/s (collection: 1.914s, learning 0.133s)
             Mean action noise std: 2.78
          Mean value_function loss: 43.9142
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.5281
                       Mean reward: 771.01
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 0.7579
    Episode_Reward/rotating_object: 155.6046
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.05s
                      Time elapsed: 00:33:12
                               ETA: 00:19:09

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 50549 steps/s (collection: 1.828s, learning 0.117s)
             Mean action noise std: 2.78
          Mean value_function loss: 48.5528
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.5413
                       Mean reward: 773.47
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 0.7538
    Episode_Reward/rotating_object: 154.3315
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.94s
                      Time elapsed: 00:33:14
                               ETA: 00:19:07

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 51556 steps/s (collection: 1.798s, learning 0.109s)
             Mean action noise std: 2.78
          Mean value_function loss: 36.2750
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.5552
                       Mean reward: 761.79
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 0.7600
    Episode_Reward/rotating_object: 155.1424
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.91s
                      Time elapsed: 00:33:16
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 50017 steps/s (collection: 1.829s, learning 0.136s)
             Mean action noise std: 2.78
          Mean value_function loss: 50.1293
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.5673
                       Mean reward: 771.72
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 0.7532
    Episode_Reward/rotating_object: 153.0300
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.97s
                      Time elapsed: 00:33:18
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 49821 steps/s (collection: 1.840s, learning 0.134s)
             Mean action noise std: 2.78
          Mean value_function loss: 43.8369
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.5726
                       Mean reward: 793.01
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7563
    Episode_Reward/rotating_object: 154.8015
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.97s
                      Time elapsed: 00:33:20
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 50276 steps/s (collection: 1.785s, learning 0.170s)
             Mean action noise std: 2.79
          Mean value_function loss: 47.4818
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.5812
                       Mean reward: 760.90
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 0.7546
    Episode_Reward/rotating_object: 154.7788
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.96s
                      Time elapsed: 00:33:22
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 50734 steps/s (collection: 1.830s, learning 0.108s)
             Mean action noise std: 2.79
          Mean value_function loss: 35.5481
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.5953
                       Mean reward: 764.75
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 0.7580
    Episode_Reward/rotating_object: 154.0872
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.94s
                      Time elapsed: 00:33:24
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 49240 steps/s (collection: 1.855s, learning 0.142s)
             Mean action noise std: 2.79
          Mean value_function loss: 38.6279
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.6098
                       Mean reward: 780.73
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 0.7553
    Episode_Reward/rotating_object: 154.4775
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.00s
                      Time elapsed: 00:33:26
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 50454 steps/s (collection: 1.816s, learning 0.133s)
             Mean action noise std: 2.79
          Mean value_function loss: 36.2788
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.6188
                       Mean reward: 751.86
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 0.7451
    Episode_Reward/rotating_object: 153.8460
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.95s
                      Time elapsed: 00:33:28
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 51497 steps/s (collection: 1.809s, learning 0.100s)
             Mean action noise std: 2.79
          Mean value_function loss: 37.6894
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.6293
                       Mean reward: 804.20
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 0.7648
    Episode_Reward/rotating_object: 158.4404
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.91s
                      Time elapsed: 00:33:30
                               ETA: 00:18:49

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 50139 steps/s (collection: 1.862s, learning 0.099s)
             Mean action noise std: 2.80
          Mean value_function loss: 33.5384
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.6414
                       Mean reward: 805.41
               Mean episode length: 247.55
    Episode_Reward/reaching_object: 0.7624
    Episode_Reward/rotating_object: 157.5710
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.96s
                      Time elapsed: 00:33:32
                               ETA: 00:18:47

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 48517 steps/s (collection: 1.901s, learning 0.126s)
             Mean action noise std: 2.80
          Mean value_function loss: 21.4127
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.6504
                       Mean reward: 798.93
               Mean episode length: 247.15
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 156.7396
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.03s
                      Time elapsed: 00:33:34
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 49923 steps/s (collection: 1.854s, learning 0.115s)
             Mean action noise std: 2.80
          Mean value_function loss: 46.8688
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.6554
                       Mean reward: 790.72
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 0.7665
    Episode_Reward/rotating_object: 157.9642
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.97s
                      Time elapsed: 00:33:36
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 50871 steps/s (collection: 1.828s, learning 0.104s)
             Mean action noise std: 2.80
          Mean value_function loss: 40.1571
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.6593
                       Mean reward: 764.08
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 0.7594
    Episode_Reward/rotating_object: 155.3238
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.93s
                      Time elapsed: 00:33:38
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 50557 steps/s (collection: 1.839s, learning 0.106s)
             Mean action noise std: 2.80
          Mean value_function loss: 33.2340
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.6695
                       Mean reward: 785.14
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 156.6194
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.94s
                      Time elapsed: 00:33:40
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 50611 steps/s (collection: 1.825s, learning 0.117s)
             Mean action noise std: 2.80
          Mean value_function loss: 43.2296
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.6836
                       Mean reward: 797.00
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.7675
    Episode_Reward/rotating_object: 157.7915
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.94s
                      Time elapsed: 00:33:42
                               ETA: 00:18:36

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 50092 steps/s (collection: 1.844s, learning 0.118s)
             Mean action noise std: 2.81
          Mean value_function loss: 38.7812
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.6925
                       Mean reward: 757.38
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 0.7463
    Episode_Reward/rotating_object: 152.4019
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.96s
                      Time elapsed: 00:33:44
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 50441 steps/s (collection: 1.835s, learning 0.114s)
             Mean action noise std: 2.81
          Mean value_function loss: 50.3982
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.7024
                       Mean reward: 753.63
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 151.9277
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.95s
                      Time elapsed: 00:33:46
                               ETA: 00:18:32

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 50737 steps/s (collection: 1.817s, learning 0.120s)
             Mean action noise std: 2.81
          Mean value_function loss: 31.4527
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.7095
                       Mean reward: 780.82
               Mean episode length: 242.99
    Episode_Reward/reaching_object: 0.7645
    Episode_Reward/rotating_object: 155.5405
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.94s
                      Time elapsed: 00:33:48
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 49724 steps/s (collection: 1.845s, learning 0.132s)
             Mean action noise std: 2.81
          Mean value_function loss: 43.9945
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.7159
                       Mean reward: 762.05
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.7731
    Episode_Reward/rotating_object: 157.8037
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.98s
                      Time elapsed: 00:33:50
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 49298 steps/s (collection: 1.848s, learning 0.146s)
             Mean action noise std: 2.81
          Mean value_function loss: 36.0463
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.7249
                       Mean reward: 780.90
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 0.7652
    Episode_Reward/rotating_object: 156.9701
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.99s
                      Time elapsed: 00:33:52
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 48726 steps/s (collection: 1.914s, learning 0.104s)
             Mean action noise std: 2.81
          Mean value_function loss: 33.7639
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.7376
                       Mean reward: 778.78
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 0.7627
    Episode_Reward/rotating_object: 155.3551
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.02s
                      Time elapsed: 00:33:54
                               ETA: 00:18:23

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 49319 steps/s (collection: 1.873s, learning 0.121s)
             Mean action noise std: 2.82
          Mean value_function loss: 33.3122
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.7475
                       Mean reward: 761.76
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 0.7626
    Episode_Reward/rotating_object: 155.1984
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 1.99s
                      Time elapsed: 00:33:56
                               ETA: 00:18:21

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 48224 steps/s (collection: 1.937s, learning 0.101s)
             Mean action noise std: 2.82
          Mean value_function loss: 42.3182
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.7525
                       Mean reward: 796.37
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 0.7755
    Episode_Reward/rotating_object: 157.7346
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.04s
                      Time elapsed: 00:33:58
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 49647 steps/s (collection: 1.871s, learning 0.109s)
             Mean action noise std: 2.82
          Mean value_function loss: 35.4492
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.7583
                       Mean reward: 792.78
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.7751
    Episode_Reward/rotating_object: 155.7281
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 1.98s
                      Time elapsed: 00:34:00
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 49422 steps/s (collection: 1.869s, learning 0.120s)
             Mean action noise std: 2.82
          Mean value_function loss: 36.6187
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.7669
                       Mean reward: 792.80
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 0.7831
    Episode_Reward/rotating_object: 158.8873
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 1.99s
                      Time elapsed: 00:34:02
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 50280 steps/s (collection: 1.838s, learning 0.118s)
             Mean action noise std: 2.82
          Mean value_function loss: 48.7714
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.7787
                       Mean reward: 766.03
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.7665
    Episode_Reward/rotating_object: 154.2242
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.96s
                      Time elapsed: 00:34:04
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 50154 steps/s (collection: 1.837s, learning 0.123s)
             Mean action noise std: 2.82
          Mean value_function loss: 52.1226
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.7856
                       Mean reward: 734.16
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 0.7654
    Episode_Reward/rotating_object: 153.0447
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 1.96s
                      Time elapsed: 00:34:06
                               ETA: 00:18:10

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 49814 steps/s (collection: 1.846s, learning 0.128s)
             Mean action noise std: 2.82
          Mean value_function loss: 40.7320
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.7889
                       Mean reward: 757.10
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 0.7659
    Episode_Reward/rotating_object: 154.5811
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 1.97s
                      Time elapsed: 00:34:07
                               ETA: 00:18:08

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 49261 steps/s (collection: 1.885s, learning 0.110s)
             Mean action noise std: 2.82
          Mean value_function loss: 52.8237
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.7955
                       Mean reward: 741.96
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 0.7741
    Episode_Reward/rotating_object: 155.7045
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.00s
                      Time elapsed: 00:34:09
                               ETA: 00:18:06

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 48988 steps/s (collection: 1.889s, learning 0.117s)
             Mean action noise std: 2.83
          Mean value_function loss: 32.5219
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.7996
                       Mean reward: 804.91
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 0.7817
    Episode_Reward/rotating_object: 159.8144
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.01s
                      Time elapsed: 00:34:11
                               ETA: 00:18:04

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 48295 steps/s (collection: 1.920s, learning 0.115s)
             Mean action noise std: 2.83
          Mean value_function loss: 34.2780
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.8079
                       Mean reward: 774.51
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 0.7758
    Episode_Reward/rotating_object: 158.0346
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.04s
                      Time elapsed: 00:34:14
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 49767 steps/s (collection: 1.861s, learning 0.114s)
             Mean action noise std: 2.83
          Mean value_function loss: 33.8669
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.8199
                       Mean reward: 782.76
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 0.7677
    Episode_Reward/rotating_object: 156.7265
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.98s
                      Time elapsed: 00:34:15
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 50887 steps/s (collection: 1.828s, learning 0.104s)
             Mean action noise std: 2.83
          Mean value_function loss: 33.5470
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.8347
                       Mean reward: 803.55
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7659
    Episode_Reward/rotating_object: 157.2771
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.93s
                      Time elapsed: 00:34:17
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 50022 steps/s (collection: 1.806s, learning 0.159s)
             Mean action noise std: 2.83
          Mean value_function loss: 38.6894
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.8426
                       Mean reward: 787.98
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 0.7598
    Episode_Reward/rotating_object: 154.4715
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.97s
                      Time elapsed: 00:34:19
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 50095 steps/s (collection: 1.797s, learning 0.166s)
             Mean action noise std: 2.84
          Mean value_function loss: 30.0571
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.8534
                       Mean reward: 814.61
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7723
    Episode_Reward/rotating_object: 159.2230
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.96s
                      Time elapsed: 00:34:21
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 49059 steps/s (collection: 1.855s, learning 0.149s)
             Mean action noise std: 2.84
          Mean value_function loss: 55.4876
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.8681
                       Mean reward: 777.69
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 0.7570
    Episode_Reward/rotating_object: 155.2256
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.00s
                      Time elapsed: 00:34:23
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 48666 steps/s (collection: 1.858s, learning 0.162s)
             Mean action noise std: 2.84
          Mean value_function loss: 31.6684
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.8789
                       Mean reward: 819.79
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 0.7688
    Episode_Reward/rotating_object: 159.5954
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.02s
                      Time elapsed: 00:34:25
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 49139 steps/s (collection: 1.885s, learning 0.116s)
             Mean action noise std: 2.84
          Mean value_function loss: 45.9861
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.8844
                       Mean reward: 795.04
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7595
    Episode_Reward/rotating_object: 155.5895
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.00s
                      Time elapsed: 00:34:27
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 48400 steps/s (collection: 1.897s, learning 0.134s)
             Mean action noise std: 2.84
          Mean value_function loss: 39.1062
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.8901
                       Mean reward: 796.65
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 0.7570
    Episode_Reward/rotating_object: 155.1521
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.03s
                      Time elapsed: 00:34:29
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 49338 steps/s (collection: 1.883s, learning 0.109s)
             Mean action noise std: 2.84
          Mean value_function loss: 46.8077
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.8996
                       Mean reward: 776.36
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 0.7571
    Episode_Reward/rotating_object: 155.7712
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.99s
                      Time elapsed: 00:34:31
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 47858 steps/s (collection: 1.902s, learning 0.152s)
             Mean action noise std: 2.85
          Mean value_function loss: 36.1806
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.9099
                       Mean reward: 798.72
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 0.7603
    Episode_Reward/rotating_object: 154.4993
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.05s
                      Time elapsed: 00:34:33
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 49214 steps/s (collection: 1.828s, learning 0.169s)
             Mean action noise std: 2.85
          Mean value_function loss: 41.7806
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.9168
                       Mean reward: 755.36
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 153.9456
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.00s
                      Time elapsed: 00:34:35
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 48789 steps/s (collection: 1.914s, learning 0.101s)
             Mean action noise std: 2.85
          Mean value_function loss: 27.3970
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.9327
                       Mean reward: 796.95
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 157.9608
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.01s
                      Time elapsed: 00:34:37
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 50280 steps/s (collection: 1.846s, learning 0.110s)
             Mean action noise std: 2.85
          Mean value_function loss: 25.0496
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.9475
                       Mean reward: 816.52
               Mean episode length: 249.71
    Episode_Reward/reaching_object: 0.7677
    Episode_Reward/rotating_object: 156.5694
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 1.96s
                      Time elapsed: 00:34:39
                               ETA: 00:17:34

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 49240 steps/s (collection: 1.846s, learning 0.151s)
             Mean action noise std: 2.86
          Mean value_function loss: 54.2155
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.9628
                       Mean reward: 774.70
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 155.6081
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.00s
                      Time elapsed: 00:34:41
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 49495 steps/s (collection: 1.821s, learning 0.166s)
             Mean action noise std: 2.86
          Mean value_function loss: 46.2289
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.9779
                       Mean reward: 795.95
               Mean episode length: 241.49
    Episode_Reward/reaching_object: 0.7666
    Episode_Reward/rotating_object: 156.1261
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 1.99s
                      Time elapsed: 00:34:43
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 49243 steps/s (collection: 1.830s, learning 0.166s)
             Mean action noise std: 2.86
          Mean value_function loss: 32.9983
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.9944
                       Mean reward: 812.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7752
    Episode_Reward/rotating_object: 157.1605
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.00s
                      Time elapsed: 00:34:45
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 50043 steps/s (collection: 1.806s, learning 0.158s)
             Mean action noise std: 2.86
          Mean value_function loss: 35.2972
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.0037
                       Mean reward: 804.25
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7665
    Episode_Reward/rotating_object: 156.0626
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 1.96s
                      Time elapsed: 00:34:47
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14581 steps/s (collection: 6.611s, learning 0.131s)
             Mean action noise std: 2.86
          Mean value_function loss: 43.4357
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.0224
                       Mean reward: 788.74
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 0.7721
    Episode_Reward/rotating_object: 158.8293
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.74s
                      Time elapsed: 00:34:54
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14382 steps/s (collection: 6.698s, learning 0.137s)
             Mean action noise std: 2.87
          Mean value_function loss: 39.8161
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.0358
                       Mean reward: 786.55
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 0.7690
    Episode_Reward/rotating_object: 155.6325
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.83s
                      Time elapsed: 00:35:01
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14567 steps/s (collection: 6.625s, learning 0.123s)
             Mean action noise std: 2.87
          Mean value_function loss: 36.7223
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.0446
                       Mean reward: 803.25
               Mean episode length: 245.17
    Episode_Reward/reaching_object: 0.7752
    Episode_Reward/rotating_object: 158.9414
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.75s
                      Time elapsed: 00:35:08
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14268 steps/s (collection: 6.723s, learning 0.167s)
             Mean action noise std: 2.87
          Mean value_function loss: 34.2907
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.0549
                       Mean reward: 802.23
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 0.7679
    Episode_Reward/rotating_object: 156.1295
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.89s
                      Time elapsed: 00:35:15
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14389 steps/s (collection: 6.673s, learning 0.158s)
             Mean action noise std: 2.87
          Mean value_function loss: 38.6293
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.0721
                       Mean reward: 787.74
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 0.7737
    Episode_Reward/rotating_object: 158.6828
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.83s
                      Time elapsed: 00:35:21
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14524 steps/s (collection: 6.646s, learning 0.123s)
             Mean action noise std: 2.88
          Mean value_function loss: 32.9336
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.0898
                       Mean reward: 792.28
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7759
    Episode_Reward/rotating_object: 157.0812
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.77s
                      Time elapsed: 00:35:28
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 15490 steps/s (collection: 6.207s, learning 0.139s)
             Mean action noise std: 2.88
          Mean value_function loss: 50.3606
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 43.1024
                       Mean reward: 774.64
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 0.7710
    Episode_Reward/rotating_object: 155.8604
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.35s
                      Time elapsed: 00:35:35
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14575 steps/s (collection: 6.606s, learning 0.139s)
             Mean action noise std: 2.88
          Mean value_function loss: 31.3781
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.1044
                       Mean reward: 761.58
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 0.7689
    Episode_Reward/rotating_object: 153.2660
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.74s
                      Time elapsed: 00:35:41
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 17238 steps/s (collection: 5.603s, learning 0.100s)
             Mean action noise std: 2.88
          Mean value_function loss: 41.5819
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.1076
                       Mean reward: 785.46
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 0.7752
    Episode_Reward/rotating_object: 154.3080
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 5.70s
                      Time elapsed: 00:35:47
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 53881 steps/s (collection: 1.735s, learning 0.090s)
             Mean action noise std: 2.88
          Mean value_function loss: 36.4894
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.1141
                       Mean reward: 789.34
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.7678
    Episode_Reward/rotating_object: 155.2039
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.82s
                      Time elapsed: 00:35:49
                               ETA: 00:17:24

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 52121 steps/s (collection: 1.729s, learning 0.157s)
             Mean action noise std: 2.88
          Mean value_function loss: 43.8991
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.1240
                       Mean reward: 808.63
               Mean episode length: 246.71
    Episode_Reward/reaching_object: 0.7818
    Episode_Reward/rotating_object: 159.6225
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.89s
                      Time elapsed: 00:35:51
                               ETA: 00:17:22

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 52258 steps/s (collection: 1.757s, learning 0.124s)
             Mean action noise std: 2.89
          Mean value_function loss: 40.8313
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.1404
                       Mean reward: 785.66
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.7595
    Episode_Reward/rotating_object: 152.0375
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.88s
                      Time elapsed: 00:35:53
                               ETA: 00:17:20

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 50310 steps/s (collection: 1.836s, learning 0.118s)
             Mean action noise std: 2.89
          Mean value_function loss: 44.0166
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.1505
                       Mean reward: 813.99
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7588
    Episode_Reward/rotating_object: 155.0341
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.95s
                      Time elapsed: 00:35:55
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 50981 steps/s (collection: 1.821s, learning 0.107s)
             Mean action noise std: 2.89
          Mean value_function loss: 38.3434
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.1591
                       Mean reward: 802.65
               Mean episode length: 246.93
    Episode_Reward/reaching_object: 0.7695
    Episode_Reward/rotating_object: 156.4744
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.93s
                      Time elapsed: 00:35:56
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 54308 steps/s (collection: 1.701s, learning 0.109s)
             Mean action noise std: 2.89
          Mean value_function loss: 31.6548
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.1684
                       Mean reward: 779.21
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 0.7611
    Episode_Reward/rotating_object: 154.3543
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.81s
                      Time elapsed: 00:35:58
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 53388 steps/s (collection: 1.745s, learning 0.096s)
             Mean action noise std: 2.89
          Mean value_function loss: 41.2562
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.1854
                       Mean reward: 788.22
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 0.7720
    Episode_Reward/rotating_object: 159.7634
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.84s
                      Time elapsed: 00:36:00
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 53397 steps/s (collection: 1.751s, learning 0.090s)
             Mean action noise std: 2.90
          Mean value_function loss: 39.9269
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.1971
                       Mean reward: 791.01
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 0.7585
    Episode_Reward/rotating_object: 156.6358
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.84s
                      Time elapsed: 00:36:02
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 53894 steps/s (collection: 1.733s, learning 0.091s)
             Mean action noise std: 2.90
          Mean value_function loss: 25.6340
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.2074
                       Mean reward: 789.92
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 0.7756
    Episode_Reward/rotating_object: 159.6589
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.82s
                      Time elapsed: 00:36:04
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 53294 steps/s (collection: 1.735s, learning 0.110s)
             Mean action noise std: 2.90
          Mean value_function loss: 39.4023
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.2193
                       Mean reward: 797.72
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.7634
    Episode_Reward/rotating_object: 155.7776
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.84s
                      Time elapsed: 00:36:06
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 53632 steps/s (collection: 1.739s, learning 0.094s)
             Mean action noise std: 2.90
          Mean value_function loss: 40.3367
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.2353
                       Mean reward: 763.26
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 0.7626
    Episode_Reward/rotating_object: 156.8351
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.83s
                      Time elapsed: 00:36:07
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 54157 steps/s (collection: 1.715s, learning 0.101s)
             Mean action noise std: 2.91
          Mean value_function loss: 35.9971
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.2585
                       Mean reward: 787.37
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 0.7679
    Episode_Reward/rotating_object: 156.1405
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.82s
                      Time elapsed: 00:36:09
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 53578 steps/s (collection: 1.731s, learning 0.104s)
             Mean action noise std: 2.91
          Mean value_function loss: 33.2213
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.2784
                       Mean reward: 767.86
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 0.7573
    Episode_Reward/rotating_object: 154.5832
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.83s
                      Time elapsed: 00:36:11
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 52629 steps/s (collection: 1.739s, learning 0.129s)
             Mean action noise std: 2.91
          Mean value_function loss: 35.2402
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.2891
                       Mean reward: 793.86
               Mean episode length: 245.35
    Episode_Reward/reaching_object: 0.7714
    Episode_Reward/rotating_object: 157.3512
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.87s
                      Time elapsed: 00:36:13
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 51477 steps/s (collection: 1.782s, learning 0.128s)
             Mean action noise std: 2.91
          Mean value_function loss: 33.4105
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.3003
                       Mean reward: 750.02
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 0.7647
    Episode_Reward/rotating_object: 155.5707
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.91s
                      Time elapsed: 00:36:15
                               ETA: 00:16:53

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 51790 steps/s (collection: 1.792s, learning 0.106s)
             Mean action noise std: 2.92
          Mean value_function loss: 47.8693
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.3111
                       Mean reward: 752.15
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 0.7562
    Episode_Reward/rotating_object: 154.9006
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.90s
                      Time elapsed: 00:36:17
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 54145 steps/s (collection: 1.709s, learning 0.107s)
             Mean action noise std: 2.92
          Mean value_function loss: 32.3894
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.3263
                       Mean reward: 786.00
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 0.7673
    Episode_Reward/rotating_object: 158.1426
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.82s
                      Time elapsed: 00:36:19
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 54541 steps/s (collection: 1.709s, learning 0.094s)
             Mean action noise std: 2.92
          Mean value_function loss: 30.8285
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.3365
                       Mean reward: 783.19
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 0.7745
    Episode_Reward/rotating_object: 158.0156
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.80s
                      Time elapsed: 00:36:20
                               ETA: 00:16:46

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 53513 steps/s (collection: 1.741s, learning 0.096s)
             Mean action noise std: 2.92
          Mean value_function loss: 33.4920
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.3450
                       Mean reward: 788.51
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 0.7675
    Episode_Reward/rotating_object: 157.8749
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.84s
                      Time elapsed: 00:36:22
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 53585 steps/s (collection: 1.730s, learning 0.105s)
             Mean action noise std: 2.92
          Mean value_function loss: 44.0209
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.3544
                       Mean reward: 746.62
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 0.7644
    Episode_Reward/rotating_object: 155.9731
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.83s
                      Time elapsed: 00:36:24
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 51969 steps/s (collection: 1.794s, learning 0.098s)
             Mean action noise std: 2.93
          Mean value_function loss: 36.5378
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.3654
                       Mean reward: 770.40
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 0.7662
    Episode_Reward/rotating_object: 156.5819
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.89s
                      Time elapsed: 00:36:26
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 52933 steps/s (collection: 1.751s, learning 0.106s)
             Mean action noise std: 2.93
          Mean value_function loss: 43.1771
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.3800
                       Mean reward: 750.57
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 0.7583
    Episode_Reward/rotating_object: 155.6727
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.86s
                      Time elapsed: 00:36:28
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 52074 steps/s (collection: 1.795s, learning 0.093s)
             Mean action noise std: 2.93
          Mean value_function loss: 33.2333
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.3905
                       Mean reward: 786.33
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 0.7677
    Episode_Reward/rotating_object: 158.3139
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.89s
                      Time elapsed: 00:36:30
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 53638 steps/s (collection: 1.734s, learning 0.099s)
             Mean action noise std: 2.93
          Mean value_function loss: 45.2448
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.3969
                       Mean reward: 814.86
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.7640
    Episode_Reward/rotating_object: 158.5578
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.83s
                      Time elapsed: 00:36:32
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 52476 steps/s (collection: 1.779s, learning 0.094s)
             Mean action noise std: 2.93
          Mean value_function loss: 37.7821
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.4029
                       Mean reward: 797.42
               Mean episode length: 244.73
    Episode_Reward/reaching_object: 0.7765
    Episode_Reward/rotating_object: 161.1750
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.87s
                      Time elapsed: 00:36:33
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 53709 steps/s (collection: 1.729s, learning 0.101s)
             Mean action noise std: 2.93
          Mean value_function loss: 38.0714
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.4146
                       Mean reward: 783.02
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 0.7639
    Episode_Reward/rotating_object: 155.6723
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.83s
                      Time elapsed: 00:36:35
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 50524 steps/s (collection: 1.853s, learning 0.093s)
             Mean action noise std: 2.94
          Mean value_function loss: 31.3541
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.4280
                       Mean reward: 778.56
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 0.7664
    Episode_Reward/rotating_object: 158.1113
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.95s
                      Time elapsed: 00:36:37
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 51689 steps/s (collection: 1.781s, learning 0.121s)
             Mean action noise std: 2.94
          Mean value_function loss: 31.8363
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.4372
                       Mean reward: 779.14
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 156.8493
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.90s
                      Time elapsed: 00:36:39
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 52493 steps/s (collection: 1.751s, learning 0.122s)
             Mean action noise std: 2.94
          Mean value_function loss: 34.6994
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.4465
                       Mean reward: 792.34
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 0.7660
    Episode_Reward/rotating_object: 157.0423
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.87s
                      Time elapsed: 00:36:41
                               ETA: 00:16:21

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 52424 steps/s (collection: 1.779s, learning 0.097s)
             Mean action noise std: 2.94
          Mean value_function loss: 48.9466
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.4592
                       Mean reward: 749.84
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 0.7549
    Episode_Reward/rotating_object: 154.4201
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.88s
                      Time elapsed: 00:36:43
                               ETA: 00:16:19

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 53232 steps/s (collection: 1.737s, learning 0.110s)
             Mean action noise std: 2.94
          Mean value_function loss: 49.9421
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.4716
                       Mean reward: 776.89
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 0.7565
    Episode_Reward/rotating_object: 155.1597
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.85s
                      Time elapsed: 00:36:45
                               ETA: 00:16:17

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 53211 steps/s (collection: 1.754s, learning 0.093s)
             Mean action noise std: 2.95
          Mean value_function loss: 42.2834
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.4907
                       Mean reward: 774.96
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.7522
    Episode_Reward/rotating_object: 154.1862
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.85s
                      Time elapsed: 00:36:47
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 51758 steps/s (collection: 1.786s, learning 0.113s)
             Mean action noise std: 2.95
          Mean value_function loss: 36.6611
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.4998
                       Mean reward: 814.13
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7694
    Episode_Reward/rotating_object: 158.1503
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.90s
                      Time elapsed: 00:36:48
                               ETA: 00:16:13

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 52103 steps/s (collection: 1.790s, learning 0.097s)
             Mean action noise std: 2.95
          Mean value_function loss: 30.1535
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.5145
                       Mean reward: 782.25
               Mean episode length: 246.23
    Episode_Reward/reaching_object: 0.7668
    Episode_Reward/rotating_object: 156.0788
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.89s
                      Time elapsed: 00:36:50
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 53534 steps/s (collection: 1.733s, learning 0.104s)
             Mean action noise std: 2.95
          Mean value_function loss: 38.4876
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.5303
                       Mean reward: 802.21
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 0.7618
    Episode_Reward/rotating_object: 157.7544
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.84s
                      Time elapsed: 00:36:52
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 52195 steps/s (collection: 1.764s, learning 0.119s)
             Mean action noise std: 2.96
          Mean value_function loss: 39.1768
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.5495
                       Mean reward: 795.22
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.7622
    Episode_Reward/rotating_object: 158.2920
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.88s
                      Time elapsed: 00:36:54
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 53877 steps/s (collection: 1.733s, learning 0.092s)
             Mean action noise std: 2.96
          Mean value_function loss: 49.7188
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.5642
                       Mean reward: 802.64
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 152.5196
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.82s
                      Time elapsed: 00:36:56
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 54428 steps/s (collection: 1.709s, learning 0.097s)
             Mean action noise std: 2.96
          Mean value_function loss: 32.2395
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 43.5720
                       Mean reward: 809.54
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.7659
    Episode_Reward/rotating_object: 158.1480
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 1.81s
                      Time elapsed: 00:36:58
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 54065 steps/s (collection: 1.726s, learning 0.093s)
             Mean action noise std: 2.96
          Mean value_function loss: 34.9863
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.5776
                       Mean reward: 787.82
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7601
    Episode_Reward/rotating_object: 155.7709
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.82s
                      Time elapsed: 00:36:59
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 52449 steps/s (collection: 1.774s, learning 0.100s)
             Mean action noise std: 2.96
          Mean value_function loss: 36.0983
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.5881
                       Mean reward: 815.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7602
    Episode_Reward/rotating_object: 156.2798
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.87s
                      Time elapsed: 00:37:01
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 53140 steps/s (collection: 1.758s, learning 0.092s)
             Mean action noise std: 2.96
          Mean value_function loss: 30.8512
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.5970
                       Mean reward: 789.26
               Mean episode length: 243.15
    Episode_Reward/reaching_object: 0.7579
    Episode_Reward/rotating_object: 154.8369
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.85s
                      Time elapsed: 00:37:03
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 51945 steps/s (collection: 1.786s, learning 0.106s)
             Mean action noise std: 2.97
          Mean value_function loss: 44.7695
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.6048
                       Mean reward: 766.48
               Mean episode length: 236.98
    Episode_Reward/reaching_object: 0.7628
    Episode_Reward/rotating_object: 157.2536
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.89s
                      Time elapsed: 00:37:05
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 50852 steps/s (collection: 1.796s, learning 0.138s)
             Mean action noise std: 2.97
          Mean value_function loss: 47.0823
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.6175
                       Mean reward: 801.95
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.7686
    Episode_Reward/rotating_object: 158.9676
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 1.93s
                      Time elapsed: 00:37:07
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 52225 steps/s (collection: 1.758s, learning 0.125s)
             Mean action noise std: 2.97
          Mean value_function loss: 35.3637
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.6288
                       Mean reward: 800.54
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 155.4330
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.88s
                      Time elapsed: 00:37:09
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 51665 steps/s (collection: 1.770s, learning 0.133s)
             Mean action noise std: 2.97
          Mean value_function loss: 28.1861
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.6333
                       Mean reward: 800.93
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.7725
    Episode_Reward/rotating_object: 159.8031
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.90s
                      Time elapsed: 00:37:11
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 52937 steps/s (collection: 1.743s, learning 0.114s)
             Mean action noise std: 2.97
          Mean value_function loss: 40.1432
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.6406
                       Mean reward: 770.13
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 0.7642
    Episode_Reward/rotating_object: 156.9021
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.86s
                      Time elapsed: 00:37:13
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 53534 steps/s (collection: 1.722s, learning 0.115s)
             Mean action noise std: 2.97
          Mean value_function loss: 33.2822
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.6485
                       Mean reward: 781.66
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 0.7664
    Episode_Reward/rotating_object: 157.8824
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.84s
                      Time elapsed: 00:37:14
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 52787 steps/s (collection: 1.765s, learning 0.097s)
             Mean action noise std: 2.98
          Mean value_function loss: 37.6662
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.6560
                       Mean reward: 812.21
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.7703
    Episode_Reward/rotating_object: 158.4101
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.86s
                      Time elapsed: 00:37:16
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 54073 steps/s (collection: 1.727s, learning 0.091s)
             Mean action noise std: 2.98
          Mean value_function loss: 30.4964
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.6625
                       Mean reward: 802.58
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 0.7678
    Episode_Reward/rotating_object: 157.6788
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.82s
                      Time elapsed: 00:37:18
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 54353 steps/s (collection: 1.691s, learning 0.118s)
             Mean action noise std: 2.98
          Mean value_function loss: 33.1516
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.6740
                       Mean reward: 793.55
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 0.7595
    Episode_Reward/rotating_object: 157.3330
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.81s
                      Time elapsed: 00:37:20
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 52162 steps/s (collection: 1.730s, learning 0.155s)
             Mean action noise std: 2.98
          Mean value_function loss: 38.2863
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.6873
                       Mean reward: 785.87
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7569
    Episode_Reward/rotating_object: 155.7580
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.88s
                      Time elapsed: 00:37:22
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 54167 steps/s (collection: 1.698s, learning 0.117s)
             Mean action noise std: 2.98
          Mean value_function loss: 38.6947
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.6996
                       Mean reward: 791.06
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 0.7624
    Episode_Reward/rotating_object: 158.4730
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.81s
                      Time elapsed: 00:37:24
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 53877 steps/s (collection: 1.733s, learning 0.091s)
             Mean action noise std: 2.99
          Mean value_function loss: 36.9330
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.7106
                       Mean reward: 788.18
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7515
    Episode_Reward/rotating_object: 153.5101
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.82s
                      Time elapsed: 00:37:26
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 52982 steps/s (collection: 1.765s, learning 0.091s)
             Mean action noise std: 2.99
          Mean value_function loss: 38.5045
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.7244
                       Mean reward: 778.83
               Mean episode length: 244.51
    Episode_Reward/reaching_object: 0.7621
    Episode_Reward/rotating_object: 157.4135
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.86s
                      Time elapsed: 00:37:27
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 52784 steps/s (collection: 1.761s, learning 0.101s)
             Mean action noise std: 2.99
          Mean value_function loss: 41.8038
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.7353
                       Mean reward: 799.99
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7553
    Episode_Reward/rotating_object: 158.3362
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.86s
                      Time elapsed: 00:37:29
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 52199 steps/s (collection: 1.789s, learning 0.095s)
             Mean action noise std: 2.99
          Mean value_function loss: 39.4125
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.7477
                       Mean reward: 781.63
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 0.7574
    Episode_Reward/rotating_object: 156.3752
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.88s
                      Time elapsed: 00:37:31
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 52113 steps/s (collection: 1.791s, learning 0.096s)
             Mean action noise std: 2.99
          Mean value_function loss: 35.2893
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.7591
                       Mean reward: 794.86
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 0.7567
    Episode_Reward/rotating_object: 155.6959
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.89s
                      Time elapsed: 00:37:33
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 53313 steps/s (collection: 1.736s, learning 0.108s)
             Mean action noise std: 3.00
          Mean value_function loss: 45.0942
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.7658
                       Mean reward: 787.47
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 0.7554
    Episode_Reward/rotating_object: 155.7473
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.84s
                      Time elapsed: 00:37:35
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 53928 steps/s (collection: 1.727s, learning 0.095s)
             Mean action noise std: 3.00
          Mean value_function loss: 27.2007
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.7734
                       Mean reward: 804.33
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7633
    Episode_Reward/rotating_object: 158.4717
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.82s
                      Time elapsed: 00:37:37
                               ETA: 00:15:15

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 52939 steps/s (collection: 1.762s, learning 0.095s)
             Mean action noise std: 3.00
          Mean value_function loss: 38.8457
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 43.7754
                       Mean reward: 778.80
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.7571
    Episode_Reward/rotating_object: 155.8633
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.86s
                      Time elapsed: 00:37:39
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 53532 steps/s (collection: 1.738s, learning 0.099s)
             Mean action noise std: 3.00
          Mean value_function loss: 36.6112
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.7774
                       Mean reward: 807.07
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 0.7690
    Episode_Reward/rotating_object: 159.9390
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.84s
                      Time elapsed: 00:37:40
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 53192 steps/s (collection: 1.750s, learning 0.098s)
             Mean action noise std: 3.00
          Mean value_function loss: 45.9877
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.7827
                       Mean reward: 783.30
               Mean episode length: 243.04
    Episode_Reward/reaching_object: 0.7650
    Episode_Reward/rotating_object: 155.4206
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.85s
                      Time elapsed: 00:37:42
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 52780 steps/s (collection: 1.766s, learning 0.097s)
             Mean action noise std: 3.00
          Mean value_function loss: 46.3489
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.7874
                       Mean reward: 771.13
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.7554
    Episode_Reward/rotating_object: 155.2279
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.86s
                      Time elapsed: 00:37:44
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 53890 steps/s (collection: 1.726s, learning 0.098s)
             Mean action noise std: 3.00
          Mean value_function loss: 46.7736
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.7987
                       Mean reward: 775.42
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 152.9518
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.82s
                      Time elapsed: 00:37:46
                               ETA: 00:15:04

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 53904 steps/s (collection: 1.720s, learning 0.104s)
             Mean action noise std: 3.01
          Mean value_function loss: 33.6003
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.8159
                       Mean reward: 749.20
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 0.7661
    Episode_Reward/rotating_object: 154.9316
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.82s
                      Time elapsed: 00:37:48
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 53645 steps/s (collection: 1.729s, learning 0.104s)
             Mean action noise std: 3.01
          Mean value_function loss: 44.3772
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.8286
                       Mean reward: 773.77
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 0.7663
    Episode_Reward/rotating_object: 155.8483
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.83s
                      Time elapsed: 00:37:50
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 52673 steps/s (collection: 1.772s, learning 0.095s)
             Mean action noise std: 3.01
          Mean value_function loss: 37.2666
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.8378
                       Mean reward: 806.83
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 0.7611
    Episode_Reward/rotating_object: 155.9531
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.87s
                      Time elapsed: 00:37:51
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 51431 steps/s (collection: 1.813s, learning 0.099s)
             Mean action noise std: 3.01
          Mean value_function loss: 50.1005
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.8498
                       Mean reward: 781.91
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.7590
    Episode_Reward/rotating_object: 154.8208
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.91s
                      Time elapsed: 00:37:53
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 53567 steps/s (collection: 1.743s, learning 0.092s)
             Mean action noise std: 3.01
          Mean value_function loss: 46.9567
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.8637
                       Mean reward: 766.75
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 0.7647
    Episode_Reward/rotating_object: 157.0244
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.84s
                      Time elapsed: 00:37:55
                               ETA: 00:14:52

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 51742 steps/s (collection: 1.753s, learning 0.147s)
             Mean action noise std: 3.01
          Mean value_function loss: 36.0536
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.8745
                       Mean reward: 810.15
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 0.7595
    Episode_Reward/rotating_object: 155.2669
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.90s
                      Time elapsed: 00:37:57
                               ETA: 00:14:50

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 53450 steps/s (collection: 1.727s, learning 0.112s)
             Mean action noise std: 3.02
          Mean value_function loss: 32.2853
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.8837
                       Mean reward: 794.10
               Mean episode length: 246.29
    Episode_Reward/reaching_object: 0.7708
    Episode_Reward/rotating_object: 158.6269
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.84s
                      Time elapsed: 00:37:59
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 52760 steps/s (collection: 1.763s, learning 0.100s)
             Mean action noise std: 3.02
          Mean value_function loss: 30.6678
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.8968
                       Mean reward: 789.08
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 154.2398
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.86s
                      Time elapsed: 00:38:01
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 53366 steps/s (collection: 1.749s, learning 0.093s)
             Mean action noise std: 3.02
          Mean value_function loss: 35.2863
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.9125
                       Mean reward: 811.91
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.7747
    Episode_Reward/rotating_object: 159.9506
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.84s
                      Time elapsed: 00:38:03
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 52069 steps/s (collection: 1.769s, learning 0.119s)
             Mean action noise std: 3.02
          Mean value_function loss: 27.6014
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.9221
                       Mean reward: 767.85
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 0.7689
    Episode_Reward/rotating_object: 158.4416
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.89s
                      Time elapsed: 00:38:04
                               ETA: 00:14:41

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 52772 steps/s (collection: 1.770s, learning 0.093s)
             Mean action noise std: 3.03
          Mean value_function loss: 39.0345
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.9315
                       Mean reward: 745.01
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 0.7551
    Episode_Reward/rotating_object: 154.0795
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.86s
                      Time elapsed: 00:38:06
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 54012 steps/s (collection: 1.725s, learning 0.095s)
             Mean action noise std: 3.03
          Mean value_function loss: 40.5372
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.9467
                       Mean reward: 790.44
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 0.7545
    Episode_Reward/rotating_object: 156.3044
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.82s
                      Time elapsed: 00:38:08
                               ETA: 00:14:37

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 52894 steps/s (collection: 1.717s, learning 0.141s)
             Mean action noise std: 3.03
          Mean value_function loss: 44.3535
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.9569
                       Mean reward: 787.43
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7551
    Episode_Reward/rotating_object: 154.9219
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.86s
                      Time elapsed: 00:38:10
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 53976 steps/s (collection: 1.728s, learning 0.094s)
             Mean action noise std: 3.03
          Mean value_function loss: 40.7900
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.9660
                       Mean reward: 730.65
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 153.3840
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.82s
                      Time elapsed: 00:38:12
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 52275 steps/s (collection: 1.776s, learning 0.105s)
             Mean action noise std: 3.03
          Mean value_function loss: 45.8182
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.9770
                       Mean reward: 766.24
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 155.1254
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.88s
                      Time elapsed: 00:38:14
                               ETA: 00:14:30

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 53047 steps/s (collection: 1.745s, learning 0.108s)
             Mean action noise std: 3.04
          Mean value_function loss: 33.6647
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.9842
                       Mean reward: 785.28
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 0.7584
    Episode_Reward/rotating_object: 155.9063
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.85s
                      Time elapsed: 00:38:16
                               ETA: 00:14:28

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 53140 steps/s (collection: 1.740s, learning 0.110s)
             Mean action noise std: 3.04
          Mean value_function loss: 34.7848
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.9949
                       Mean reward: 749.92
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 154.4681
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.85s
                      Time elapsed: 00:38:17
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 51967 steps/s (collection: 1.755s, learning 0.137s)
             Mean action noise std: 3.04
          Mean value_function loss: 41.0177
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.0069
                       Mean reward: 779.32
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 0.7588
    Episode_Reward/rotating_object: 155.4827
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 1.89s
                      Time elapsed: 00:38:19
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 51258 steps/s (collection: 1.795s, learning 0.123s)
             Mean action noise std: 3.04
          Mean value_function loss: 35.6090
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.0196
                       Mean reward: 792.49
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 158.5936
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.92s
                      Time elapsed: 00:38:21
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 51674 steps/s (collection: 1.764s, learning 0.138s)
             Mean action noise std: 3.04
          Mean value_function loss: 27.2166
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.0259
                       Mean reward: 808.79
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.7692
    Episode_Reward/rotating_object: 158.8020
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.90s
                      Time elapsed: 00:38:23
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 51872 steps/s (collection: 1.740s, learning 0.155s)
             Mean action noise std: 3.05
          Mean value_function loss: 39.8661
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.0332
                       Mean reward: 769.09
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 0.7688
    Episode_Reward/rotating_object: 158.5728
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.90s
                      Time elapsed: 00:38:25
                               ETA: 00:14:17

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 51784 steps/s (collection: 1.793s, learning 0.105s)
             Mean action noise std: 3.05
          Mean value_function loss: 38.1503
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.0411
                       Mean reward: 796.91
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 0.7646
    Episode_Reward/rotating_object: 158.0094
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.90s
                      Time elapsed: 00:38:27
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 52484 steps/s (collection: 1.773s, learning 0.100s)
             Mean action noise std: 3.05
          Mean value_function loss: 50.7005
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.0489
                       Mean reward: 770.51
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 151.6114
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.87s
                      Time elapsed: 00:38:29
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 52125 steps/s (collection: 1.786s, learning 0.100s)
             Mean action noise std: 3.05
          Mean value_function loss: 47.2922
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.0584
                       Mean reward: 804.91
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 156.1684
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.89s
                      Time elapsed: 00:38:31
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 51891 steps/s (collection: 1.798s, learning 0.096s)
             Mean action noise std: 3.05
          Mean value_function loss: 49.5866
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.0669
                       Mean reward: 741.44
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 153.6633
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.89s
                      Time elapsed: 00:38:33
                               ETA: 00:14:08

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 53327 steps/s (collection: 1.749s, learning 0.095s)
             Mean action noise std: 3.05
          Mean value_function loss: 33.0165
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.0699
                       Mean reward: 814.32
               Mean episode length: 246.41
    Episode_Reward/reaching_object: 0.7700
    Episode_Reward/rotating_object: 158.2565
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.84s
                      Time elapsed: 00:38:34
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 52624 steps/s (collection: 1.773s, learning 0.095s)
             Mean action noise std: 3.05
          Mean value_function loss: 42.9646
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.0718
                       Mean reward: 724.67
               Mean episode length: 235.54
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 152.4368
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.87s
                      Time elapsed: 00:38:36
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 50695 steps/s (collection: 1.778s, learning 0.161s)
             Mean action noise std: 3.05
          Mean value_function loss: 37.2078
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.0781
                       Mean reward: 746.23
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 0.7592
    Episode_Reward/rotating_object: 154.5009
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.94s
                      Time elapsed: 00:38:38
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 50615 steps/s (collection: 1.815s, learning 0.127s)
             Mean action noise std: 3.06
          Mean value_function loss: 45.3812
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.0843
                       Mean reward: 785.43
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.7608
    Episode_Reward/rotating_object: 156.7859
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 1.94s
                      Time elapsed: 00:38:40
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 51124 steps/s (collection: 1.794s, learning 0.129s)
             Mean action noise std: 3.06
          Mean value_function loss: 49.3869
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.0917
                       Mean reward: 779.72
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 0.7587
    Episode_Reward/rotating_object: 155.7396
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.92s
                      Time elapsed: 00:38:42
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 49750 steps/s (collection: 1.849s, learning 0.127s)
             Mean action noise std: 3.06
          Mean value_function loss: 38.0737
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.0991
                       Mean reward: 795.77
               Mean episode length: 245.24
    Episode_Reward/reaching_object: 0.7745
    Episode_Reward/rotating_object: 158.9915
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 1.98s
                      Time elapsed: 00:38:44
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 52263 steps/s (collection: 1.789s, learning 0.092s)
             Mean action noise std: 3.06
          Mean value_function loss: 59.3463
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.1093
                       Mean reward: 754.55
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 153.0023
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.88s
                      Time elapsed: 00:38:46
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 52753 steps/s (collection: 1.766s, learning 0.098s)
             Mean action noise std: 3.06
          Mean value_function loss: 49.4536
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.1192
                       Mean reward: 783.23
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 0.7752
    Episode_Reward/rotating_object: 158.5683
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.86s
                      Time elapsed: 00:38:48
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 49327 steps/s (collection: 1.885s, learning 0.108s)
             Mean action noise std: 3.07
          Mean value_function loss: 39.0354
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.1308
                       Mean reward: 762.43
               Mean episode length: 235.74
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 155.7124
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 1.99s
                      Time elapsed: 00:38:50
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 46581 steps/s (collection: 1.998s, learning 0.113s)
             Mean action noise std: 3.07
          Mean value_function loss: 40.5505
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.1371
                       Mean reward: 809.94
               Mean episode length: 244.65
    Episode_Reward/reaching_object: 0.7673
    Episode_Reward/rotating_object: 157.1850
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.11s
                      Time elapsed: 00:38:52
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 52548 steps/s (collection: 1.768s, learning 0.103s)
             Mean action noise std: 3.07
          Mean value_function loss: 29.5506
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.1444
                       Mean reward: 784.91
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 0.7722
    Episode_Reward/rotating_object: 158.6515
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.87s
                      Time elapsed: 00:38:54
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 50694 steps/s (collection: 1.821s, learning 0.118s)
             Mean action noise std: 3.07
          Mean value_function loss: 38.3788
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.1486
                       Mean reward: 784.19
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 0.7601
    Episode_Reward/rotating_object: 156.4923
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.94s
                      Time elapsed: 00:38:56
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 51304 steps/s (collection: 1.799s, learning 0.118s)
             Mean action noise std: 3.07
          Mean value_function loss: 38.8428
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.1591
                       Mean reward: 796.05
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 0.7631
    Episode_Reward/rotating_object: 155.8986
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.92s
                      Time elapsed: 00:38:58
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 52962 steps/s (collection: 1.752s, learning 0.104s)
             Mean action noise std: 3.07
          Mean value_function loss: 44.3512
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.1718
                       Mean reward: 792.48
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 153.0926
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.86s
                      Time elapsed: 00:39:00
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 52767 steps/s (collection: 1.769s, learning 0.094s)
             Mean action noise std: 3.08
          Mean value_function loss: 44.7444
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.1801
                       Mean reward: 749.13
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 0.7603
    Episode_Reward/rotating_object: 156.1233
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.86s
                      Time elapsed: 00:39:01
                               ETA: 00:13:36

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 52324 steps/s (collection: 1.746s, learning 0.133s)
             Mean action noise std: 3.08
          Mean value_function loss: 34.9604
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.1843
                       Mean reward: 775.35
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 0.7533
    Episode_Reward/rotating_object: 152.4161
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.88s
                      Time elapsed: 00:39:03
                               ETA: 00:13:34

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 50837 steps/s (collection: 1.812s, learning 0.122s)
             Mean action noise std: 3.08
          Mean value_function loss: 43.6231
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.1934
                       Mean reward: 781.04
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 153.7987
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.93s
                      Time elapsed: 00:39:05
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 51690 steps/s (collection: 1.806s, learning 0.096s)
             Mean action noise std: 3.08
          Mean value_function loss: 44.8386
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.2063
                       Mean reward: 773.36
               Mean episode length: 236.28
    Episode_Reward/reaching_object: 0.7653
    Episode_Reward/rotating_object: 156.9306
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.90s
                      Time elapsed: 00:39:07
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 52453 steps/s (collection: 1.778s, learning 0.096s)
             Mean action noise std: 3.08
          Mean value_function loss: 49.5735
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.2153
                       Mean reward: 790.98
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 153.2958
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.87s
                      Time elapsed: 00:39:09
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 53119 steps/s (collection: 1.744s, learning 0.107s)
             Mean action noise std: 3.09
          Mean value_function loss: 45.0145
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.2297
                       Mean reward: 784.29
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 0.7558
    Episode_Reward/rotating_object: 154.9663
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.85s
                      Time elapsed: 00:39:11
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 52548 steps/s (collection: 1.773s, learning 0.098s)
             Mean action noise std: 3.09
          Mean value_function loss: 57.6792
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.2510
                       Mean reward: 766.72
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 154.4072
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.87s
                      Time elapsed: 00:39:13
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 51066 steps/s (collection: 1.832s, learning 0.093s)
             Mean action noise std: 3.09
          Mean value_function loss: 53.8520
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.2651
                       Mean reward: 761.36
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 0.7585
    Episode_Reward/rotating_object: 156.4446
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.93s
                      Time elapsed: 00:39:15
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 51551 steps/s (collection: 1.814s, learning 0.093s)
             Mean action noise std: 3.09
          Mean value_function loss: 58.2021
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.2743
                       Mean reward: 747.01
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 149.7162
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.91s
                      Time elapsed: 00:39:17
                               ETA: 00:13:18

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 51308 steps/s (collection: 1.823s, learning 0.093s)
             Mean action noise std: 3.09
          Mean value_function loss: 39.5069
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.2791
                       Mean reward: 753.45
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 0.7664
    Episode_Reward/rotating_object: 156.9052
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.92s
                      Time elapsed: 00:39:18
                               ETA: 00:13:16

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 52230 steps/s (collection: 1.790s, learning 0.092s)
             Mean action noise std: 3.09
          Mean value_function loss: 30.2327
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.2856
                       Mean reward: 780.87
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 0.7626
    Episode_Reward/rotating_object: 157.8509
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.88s
                      Time elapsed: 00:39:20
                               ETA: 00:13:14

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 51661 steps/s (collection: 1.749s, learning 0.154s)
             Mean action noise std: 3.10
          Mean value_function loss: 22.7963
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.2933
                       Mean reward: 778.21
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 0.7727
    Episode_Reward/rotating_object: 159.1549
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.90s
                      Time elapsed: 00:39:22
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 51698 steps/s (collection: 1.808s, learning 0.093s)
             Mean action noise std: 3.10
          Mean value_function loss: 37.5863
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.2997
                       Mean reward: 803.97
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7693
    Episode_Reward/rotating_object: 158.8731
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 1.90s
                      Time elapsed: 00:39:24
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 49777 steps/s (collection: 1.875s, learning 0.100s)
             Mean action noise std: 3.10
          Mean value_function loss: 36.2509
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.3065
                       Mean reward: 815.39
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.7661
    Episode_Reward/rotating_object: 158.5475
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.97s
                      Time elapsed: 00:39:26
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 51502 steps/s (collection: 1.814s, learning 0.095s)
             Mean action noise std: 3.10
          Mean value_function loss: 28.2977
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.3118
                       Mean reward: 809.52
               Mean episode length: 249.52
    Episode_Reward/reaching_object: 0.7734
    Episode_Reward/rotating_object: 158.0381
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.91s
                      Time elapsed: 00:39:28
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 52924 steps/s (collection: 1.750s, learning 0.107s)
             Mean action noise std: 3.10
          Mean value_function loss: 35.9758
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.3183
                       Mean reward: 806.76
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7710
    Episode_Reward/rotating_object: 158.1328
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.86s
                      Time elapsed: 00:39:30
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 52443 steps/s (collection: 1.759s, learning 0.116s)
             Mean action noise std: 3.11
          Mean value_function loss: 38.7384
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.3262
                       Mean reward: 800.94
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7674
    Episode_Reward/rotating_object: 156.3568
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.87s
                      Time elapsed: 00:39:32
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 51644 steps/s (collection: 1.801s, learning 0.102s)
             Mean action noise std: 3.11
          Mean value_function loss: 30.9124
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.3329
                       Mean reward: 771.02
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 0.7718
    Episode_Reward/rotating_object: 158.7965
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.90s
                      Time elapsed: 00:39:34
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 52595 steps/s (collection: 1.759s, learning 0.110s)
             Mean action noise std: 3.11
          Mean value_function loss: 43.1473
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.3383
                       Mean reward: 764.31
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 152.8497
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.87s
                      Time elapsed: 00:39:36
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 53766 steps/s (collection: 1.727s, learning 0.101s)
             Mean action noise std: 3.11
          Mean value_function loss: 35.4604
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.3507
                       Mean reward: 776.83
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 0.7592
    Episode_Reward/rotating_object: 156.3989
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.83s
                      Time elapsed: 00:39:37
                               ETA: 00:12:55

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 53112 steps/s (collection: 1.760s, learning 0.091s)
             Mean action noise std: 3.11
          Mean value_function loss: 41.3067
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.3611
                       Mean reward: 763.21
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 0.7580
    Episode_Reward/rotating_object: 154.3821
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.85s
                      Time elapsed: 00:39:39
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 53516 steps/s (collection: 1.741s, learning 0.096s)
             Mean action noise std: 3.11
          Mean value_function loss: 43.0491
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.3682
                       Mean reward: 768.62
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 0.7741
    Episode_Reward/rotating_object: 158.8837
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.84s
                      Time elapsed: 00:39:41
                               ETA: 00:12:50

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 52500 steps/s (collection: 1.764s, learning 0.108s)
             Mean action noise std: 3.11
          Mean value_function loss: 41.7441
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.3745
                       Mean reward: 791.92
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 0.7670
    Episode_Reward/rotating_object: 157.1299
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.87s
                      Time elapsed: 00:39:43
                               ETA: 00:12:48

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 51986 steps/s (collection: 1.797s, learning 0.094s)
             Mean action noise std: 3.12
          Mean value_function loss: 32.6147
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.3848
                       Mean reward: 795.34
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.7757
    Episode_Reward/rotating_object: 159.8970
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.89s
                      Time elapsed: 00:39:45
                               ETA: 00:12:46

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 53345 steps/s (collection: 1.751s, learning 0.092s)
             Mean action noise std: 3.12
          Mean value_function loss: 36.6908
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.3936
                       Mean reward: 805.99
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.7674
    Episode_Reward/rotating_object: 158.9485
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.84s
                      Time elapsed: 00:39:47
                               ETA: 00:12:44

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 52060 steps/s (collection: 1.774s, learning 0.114s)
             Mean action noise std: 3.12
          Mean value_function loss: 39.2730
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.4042
                       Mean reward: 790.05
               Mean episode length: 242.22
    Episode_Reward/reaching_object: 0.7647
    Episode_Reward/rotating_object: 155.7170
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.89s
                      Time elapsed: 00:39:49
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 51413 steps/s (collection: 1.756s, learning 0.156s)
             Mean action noise std: 3.12
          Mean value_function loss: 35.8398
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.4252
                       Mean reward: 815.52
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 0.7587
    Episode_Reward/rotating_object: 154.5889
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.91s
                      Time elapsed: 00:39:50
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 51656 steps/s (collection: 1.790s, learning 0.113s)
             Mean action noise std: 3.13
          Mean value_function loss: 33.0563
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.4365
                       Mean reward: 786.34
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 0.7743
    Episode_Reward/rotating_object: 158.4850
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.90s
                      Time elapsed: 00:39:52
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 53140 steps/s (collection: 1.751s, learning 0.099s)
             Mean action noise std: 3.13
          Mean value_function loss: 27.0074
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.4538
                       Mean reward: 812.51
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.7658
    Episode_Reward/rotating_object: 155.6794
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.85s
                      Time elapsed: 00:39:54
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 52444 steps/s (collection: 1.781s, learning 0.094s)
             Mean action noise std: 3.13
          Mean value_function loss: 28.7466
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.4730
                       Mean reward: 797.68
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 0.7734
    Episode_Reward/rotating_object: 155.8717
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.87s
                      Time elapsed: 00:39:56
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 52583 steps/s (collection: 1.773s, learning 0.096s)
             Mean action noise std: 3.14
          Mean value_function loss: 32.6722
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.4848
                       Mean reward: 790.67
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7769
    Episode_Reward/rotating_object: 158.7077
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.87s
                      Time elapsed: 00:39:58
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 51412 steps/s (collection: 1.809s, learning 0.103s)
             Mean action noise std: 3.14
          Mean value_function loss: 44.5186
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.4897
                       Mean reward: 788.53
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.7790
    Episode_Reward/rotating_object: 158.7792
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.91s
                      Time elapsed: 00:40:00
                               ETA: 00:12:29

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 52805 steps/s (collection: 1.739s, learning 0.123s)
             Mean action noise std: 3.14
          Mean value_function loss: 40.0441
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.4945
                       Mean reward: 799.33
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.7662
    Episode_Reward/rotating_object: 156.9212
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.86s
                      Time elapsed: 00:40:02
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 52255 steps/s (collection: 1.735s, learning 0.146s)
             Mean action noise std: 3.14
          Mean value_function loss: 38.4223
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.5044
                       Mean reward: 790.21
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 0.7639
    Episode_Reward/rotating_object: 155.4289
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.88s
                      Time elapsed: 00:40:04
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 51045 steps/s (collection: 1.788s, learning 0.138s)
             Mean action noise std: 3.14
          Mean value_function loss: 38.4153
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.5185
                       Mean reward: 790.66
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 0.7616
    Episode_Reward/rotating_object: 155.5256
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.93s
                      Time elapsed: 00:40:06
                               ETA: 00:12:22

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 51650 steps/s (collection: 1.791s, learning 0.113s)
             Mean action noise std: 3.14
          Mean value_function loss: 38.6439
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.5302
                       Mean reward: 781.85
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 0.7663
    Episode_Reward/rotating_object: 155.4137
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.90s
                      Time elapsed: 00:40:07
                               ETA: 00:12:20

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 52997 steps/s (collection: 1.757s, learning 0.098s)
             Mean action noise std: 3.15
          Mean value_function loss: 27.3174
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.5414
                       Mean reward: 801.55
               Mean episode length: 245.29
    Episode_Reward/reaching_object: 0.7704
    Episode_Reward/rotating_object: 158.4813
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.85s
                      Time elapsed: 00:40:09
                               ETA: 00:12:18

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 53455 steps/s (collection: 1.743s, learning 0.096s)
             Mean action noise std: 3.15
          Mean value_function loss: 46.3432
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.5534
                       Mean reward: 771.83
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.7678
    Episode_Reward/rotating_object: 158.4657
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.84s
                      Time elapsed: 00:40:11
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 53077 steps/s (collection: 1.753s, learning 0.099s)
             Mean action noise std: 3.15
          Mean value_function loss: 46.8320
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.5651
                       Mean reward: 804.08
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 0.7698
    Episode_Reward/rotating_object: 158.1461
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.85s
                      Time elapsed: 00:40:13
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 51310 steps/s (collection: 1.808s, learning 0.108s)
             Mean action noise std: 3.15
          Mean value_function loss: 37.9596
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.5771
                       Mean reward: 783.44
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 0.7627
    Episode_Reward/rotating_object: 155.2464
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.92s
                      Time elapsed: 00:40:15
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 52478 steps/s (collection: 1.770s, learning 0.104s)
             Mean action noise std: 3.16
          Mean value_function loss: 39.8774
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.5897
                       Mean reward: 798.23
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 0.7678
    Episode_Reward/rotating_object: 157.4071
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.87s
                      Time elapsed: 00:40:17
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 51909 steps/s (collection: 1.732s, learning 0.162s)
             Mean action noise std: 3.16
          Mean value_function loss: 37.5749
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.5983
                       Mean reward: 807.60
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 0.7674
    Episode_Reward/rotating_object: 158.9492
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.89s
                      Time elapsed: 00:40:19
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 52425 steps/s (collection: 1.739s, learning 0.136s)
             Mean action noise std: 3.16
          Mean value_function loss: 33.4091
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.6072
                       Mean reward: 796.97
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 0.7763
    Episode_Reward/rotating_object: 159.5219
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.88s
                      Time elapsed: 00:40:21
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 53919 steps/s (collection: 1.723s, learning 0.101s)
             Mean action noise std: 3.16
          Mean value_function loss: 36.4241
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.6190
                       Mean reward: 784.82
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 0.7637
    Episode_Reward/rotating_object: 156.6828
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.82s
                      Time elapsed: 00:40:22
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 52783 steps/s (collection: 1.759s, learning 0.104s)
             Mean action noise std: 3.16
          Mean value_function loss: 26.9862
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 44.6283
                       Mean reward: 798.72
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 0.7719
    Episode_Reward/rotating_object: 157.8247
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.86s
                      Time elapsed: 00:40:24
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 52726 steps/s (collection: 1.754s, learning 0.110s)
             Mean action noise std: 3.16
          Mean value_function loss: 33.5994
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.6322
                       Mean reward: 764.40
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 0.7680
    Episode_Reward/rotating_object: 159.1169
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.86s
                      Time elapsed: 00:40:26
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 53343 steps/s (collection: 1.748s, learning 0.095s)
             Mean action noise std: 3.17
          Mean value_function loss: 29.4537
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.6422
                       Mean reward: 796.08
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7730
    Episode_Reward/rotating_object: 160.3915
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.84s
                      Time elapsed: 00:40:28
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 50437 steps/s (collection: 1.834s, learning 0.115s)
             Mean action noise std: 3.17
          Mean value_function loss: 49.6271
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.6559
                       Mean reward: 775.76
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 153.8675
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.95s
                      Time elapsed: 00:40:30
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 49520 steps/s (collection: 1.824s, learning 0.161s)
             Mean action noise std: 3.17
          Mean value_function loss: 31.2270
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.6645
                       Mean reward: 804.35
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.7735
    Episode_Reward/rotating_object: 157.8674
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.99s
                      Time elapsed: 00:40:32
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 52324 steps/s (collection: 1.783s, learning 0.096s)
             Mean action noise std: 3.17
          Mean value_function loss: 33.1671
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.6774
                       Mean reward: 785.57
               Mean episode length: 246.43
    Episode_Reward/reaching_object: 0.7712
    Episode_Reward/rotating_object: 159.9936
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 1.88s
                      Time elapsed: 00:40:34
                               ETA: 00:11:50

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 51582 steps/s (collection: 1.786s, learning 0.120s)
             Mean action noise std: 3.17
          Mean value_function loss: 33.6217
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.6868
                       Mean reward: 778.98
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.7690
    Episode_Reward/rotating_object: 158.0193
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.91s
                      Time elapsed: 00:40:36
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 50885 steps/s (collection: 1.834s, learning 0.098s)
             Mean action noise std: 3.18
          Mean value_function loss: 46.0793
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.6947
                       Mean reward: 804.97
               Mean episode length: 246.24
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 156.0081
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 1.93s
                      Time elapsed: 00:40:38
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 51873 steps/s (collection: 1.786s, learning 0.109s)
             Mean action noise std: 3.18
          Mean value_function loss: 30.3450
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.7063
                       Mean reward: 800.95
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 157.3897
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 1.90s
                      Time elapsed: 00:40:39
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 51396 steps/s (collection: 1.818s, learning 0.095s)
             Mean action noise std: 3.18
          Mean value_function loss: 40.1240
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.7197
                       Mean reward: 770.10
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 0.7678
    Episode_Reward/rotating_object: 157.5053
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.91s
                      Time elapsed: 00:40:41
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 51564 steps/s (collection: 1.803s, learning 0.104s)
             Mean action noise std: 3.18
          Mean value_function loss: 39.3587
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.7287
                       Mean reward: 785.28
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 0.7609
    Episode_Reward/rotating_object: 157.0992
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 1.91s
                      Time elapsed: 00:40:43
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 51901 steps/s (collection: 1.790s, learning 0.104s)
             Mean action noise std: 3.19
          Mean value_function loss: 41.3080
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.7414
                       Mean reward: 805.03
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 0.7659
    Episode_Reward/rotating_object: 157.4888
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 1.89s
                      Time elapsed: 00:40:45
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 51506 steps/s (collection: 1.795s, learning 0.114s)
             Mean action noise std: 3.19
          Mean value_function loss: 41.5852
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.7551
                       Mean reward: 771.73
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 155.1796
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 1.91s
                      Time elapsed: 00:40:47
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 50847 steps/s (collection: 1.822s, learning 0.112s)
             Mean action noise std: 3.19
          Mean value_function loss: 43.8724
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.7687
                       Mean reward: 808.77
               Mean episode length: 246.95
    Episode_Reward/reaching_object: 0.7634
    Episode_Reward/rotating_object: 155.1079
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 1.93s
                      Time elapsed: 00:40:49
                               ETA: 00:11:32

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 51179 steps/s (collection: 1.831s, learning 0.090s)
             Mean action noise std: 3.19
          Mean value_function loss: 36.0771
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.7754
                       Mean reward: 771.83
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.7694
    Episode_Reward/rotating_object: 155.3240
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.92s
                      Time elapsed: 00:40:51
                               ETA: 00:11:30

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 51387 steps/s (collection: 1.817s, learning 0.096s)
             Mean action noise std: 3.19
          Mean value_function loss: 41.4668
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.7813
                       Mean reward: 769.93
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 0.7744
    Episode_Reward/rotating_object: 158.6374
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 1.91s
                      Time elapsed: 00:40:53
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 51482 steps/s (collection: 1.812s, learning 0.097s)
             Mean action noise std: 3.19
          Mean value_function loss: 49.1332
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.7913
                       Mean reward: 754.25
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.7613
    Episode_Reward/rotating_object: 153.1346
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.91s
                      Time elapsed: 00:40:55
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 52193 steps/s (collection: 1.787s, learning 0.096s)
             Mean action noise std: 3.20
          Mean value_function loss: 46.7193
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.7978
                       Mean reward: 787.90
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 157.8967
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 1.88s
                      Time elapsed: 00:40:57
                               ETA: 00:11:24

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 50873 steps/s (collection: 1.796s, learning 0.137s)
             Mean action noise std: 3.20
          Mean value_function loss: 35.4106
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.8034
                       Mean reward: 797.64
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 0.7696
    Episode_Reward/rotating_object: 156.4375
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 1.93s
                      Time elapsed: 00:40:59
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 52255 steps/s (collection: 1.787s, learning 0.094s)
             Mean action noise std: 3.20
          Mean value_function loss: 40.5526
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.8102
                       Mean reward: 788.93
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 0.7832
    Episode_Reward/rotating_object: 158.3485
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.88s
                      Time elapsed: 00:41:00
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 51938 steps/s (collection: 1.804s, learning 0.089s)
             Mean action noise std: 3.20
          Mean value_function loss: 30.1941
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.8206
                       Mean reward: 801.48
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 0.7716
    Episode_Reward/rotating_object: 154.8539
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.89s
                      Time elapsed: 00:41:02
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 51783 steps/s (collection: 1.801s, learning 0.098s)
             Mean action noise std: 3.20
          Mean value_function loss: 45.0054
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.8315
                       Mean reward: 804.50
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.7733
    Episode_Reward/rotating_object: 157.1850
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.90s
                      Time elapsed: 00:41:04
                               ETA: 00:11:15

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 51787 steps/s (collection: 1.804s, learning 0.094s)
             Mean action noise std: 3.21
          Mean value_function loss: 28.7659
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.8495
                       Mean reward: 797.37
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.7788
    Episode_Reward/rotating_object: 159.4618
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.90s
                      Time elapsed: 00:41:06
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 52372 steps/s (collection: 1.766s, learning 0.111s)
             Mean action noise std: 3.21
          Mean value_function loss: 43.5080
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.8624
                       Mean reward: 763.61
               Mean episode length: 238.68
    Episode_Reward/reaching_object: 0.7613
    Episode_Reward/rotating_object: 154.6799
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.88s
                      Time elapsed: 00:41:08
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 50499 steps/s (collection: 1.840s, learning 0.107s)
             Mean action noise std: 3.21
          Mean value_function loss: 38.5411
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.8696
                       Mean reward: 759.92
               Mean episode length: 233.53
    Episode_Reward/reaching_object: 0.7696
    Episode_Reward/rotating_object: 159.1441
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.95s
                      Time elapsed: 00:41:10
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 50932 steps/s (collection: 1.838s, learning 0.092s)
             Mean action noise std: 3.21
          Mean value_function loss: 38.8943
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.8747
                       Mean reward: 777.83
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 0.7654
    Episode_Reward/rotating_object: 156.6388
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.93s
                      Time elapsed: 00:41:12
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 53008 steps/s (collection: 1.754s, learning 0.100s)
             Mean action noise std: 3.21
          Mean value_function loss: 45.0981
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.8818
                       Mean reward: 809.37
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.7657
    Episode_Reward/rotating_object: 157.2808
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.85s
                      Time elapsed: 00:41:14
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 51944 steps/s (collection: 1.787s, learning 0.105s)
             Mean action noise std: 3.21
          Mean value_function loss: 54.0435
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.8881
                       Mean reward: 791.78
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 0.7567
    Episode_Reward/rotating_object: 155.0213
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.89s
                      Time elapsed: 00:41:16
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 52035 steps/s (collection: 1.794s, learning 0.095s)
             Mean action noise std: 3.21
          Mean value_function loss: 45.2646
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.8960
                       Mean reward: 793.62
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.7639
    Episode_Reward/rotating_object: 156.5883
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.89s
                      Time elapsed: 00:41:18
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 52204 steps/s (collection: 1.787s, learning 0.096s)
             Mean action noise std: 3.22
          Mean value_function loss: 35.2989
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.8984
                       Mean reward: 778.41
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 0.7644
    Episode_Reward/rotating_object: 156.6661
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.88s
                      Time elapsed: 00:41:19
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 51221 steps/s (collection: 1.824s, learning 0.095s)
             Mean action noise std: 3.22
          Mean value_function loss: 47.4569
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.9056
                       Mean reward: 821.88
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7594
    Episode_Reward/rotating_object: 156.3182
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.92s
                      Time elapsed: 00:41:21
                               ETA: 00:10:56

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 52170 steps/s (collection: 1.782s, learning 0.102s)
             Mean action noise std: 3.22
          Mean value_function loss: 41.4793
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.9174
                       Mean reward: 780.05
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 0.7657
    Episode_Reward/rotating_object: 157.5031
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.88s
                      Time elapsed: 00:41:23
                               ETA: 00:10:54

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 50816 steps/s (collection: 1.823s, learning 0.111s)
             Mean action noise std: 3.22
          Mean value_function loss: 36.3653
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.9257
                       Mean reward: 805.34
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7716
    Episode_Reward/rotating_object: 160.3715
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.93s
                      Time elapsed: 00:41:25
                               ETA: 00:10:52

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 52509 steps/s (collection: 1.764s, learning 0.108s)
             Mean action noise std: 3.22
          Mean value_function loss: 31.1157
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.9401
                       Mean reward: 804.66
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 0.7695
    Episode_Reward/rotating_object: 158.2708
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.87s
                      Time elapsed: 00:41:27
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 50896 steps/s (collection: 1.789s, learning 0.142s)
             Mean action noise std: 3.23
          Mean value_function loss: 41.1429
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.9512
                       Mean reward: 788.07
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 153.7654
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.93s
                      Time elapsed: 00:41:29
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 50789 steps/s (collection: 1.756s, learning 0.180s)
             Mean action noise std: 3.23
          Mean value_function loss: 33.4271
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.9608
                       Mean reward: 795.06
               Mean episode length: 244.91
    Episode_Reward/reaching_object: 0.7715
    Episode_Reward/rotating_object: 158.2798
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.94s
                      Time elapsed: 00:41:31
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 51750 steps/s (collection: 1.799s, learning 0.101s)
             Mean action noise std: 3.23
          Mean value_function loss: 44.7045
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.9680
                       Mean reward: 780.58
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 0.7619
    Episode_Reward/rotating_object: 157.1678
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.90s
                      Time elapsed: 00:41:33
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 52494 steps/s (collection: 1.777s, learning 0.096s)
             Mean action noise std: 3.23
          Mean value_function loss: 33.8907
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.9745
                       Mean reward: 803.09
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 0.7637
    Episode_Reward/rotating_object: 158.7236
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.87s
                      Time elapsed: 00:41:35
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 52084 steps/s (collection: 1.782s, learning 0.105s)
             Mean action noise std: 3.23
          Mean value_function loss: 37.0196
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.9806
                       Mean reward: 774.63
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 154.6668
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.89s
                      Time elapsed: 00:41:37
                               ETA: 00:10:39

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 52341 steps/s (collection: 1.772s, learning 0.106s)
             Mean action noise std: 3.23
          Mean value_function loss: 35.0211
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.9950
                       Mean reward: 798.40
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.7723
    Episode_Reward/rotating_object: 159.0595
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.88s
                      Time elapsed: 00:41:38
                               ETA: 00:10:37

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 51751 steps/s (collection: 1.787s, learning 0.113s)
             Mean action noise std: 3.24
          Mean value_function loss: 35.5509
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.0154
                       Mean reward: 820.44
               Mean episode length: 249.09
    Episode_Reward/reaching_object: 0.7568
    Episode_Reward/rotating_object: 154.0545
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.90s
                      Time elapsed: 00:41:40
                               ETA: 00:10:35

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 51448 steps/s (collection: 1.805s, learning 0.106s)
             Mean action noise std: 3.24
          Mean value_function loss: 40.5120
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 45.0264
                       Mean reward: 788.79
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 0.7614
    Episode_Reward/rotating_object: 156.0062
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.91s
                      Time elapsed: 00:41:42
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 52168 steps/s (collection: 1.791s, learning 0.093s)
             Mean action noise std: 3.24
          Mean value_function loss: 35.6473
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.0297
                       Mean reward: 765.35
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 0.7609
    Episode_Reward/rotating_object: 156.3051
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.88s
                      Time elapsed: 00:41:44
                               ETA: 00:10:30

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 51615 steps/s (collection: 1.800s, learning 0.105s)
             Mean action noise std: 3.24
          Mean value_function loss: 34.6970
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.0366
                       Mean reward: 781.50
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 0.7700
    Episode_Reward/rotating_object: 158.5281
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.90s
                      Time elapsed: 00:41:46
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 51225 steps/s (collection: 1.781s, learning 0.138s)
             Mean action noise std: 3.24
          Mean value_function loss: 28.8233
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.0432
                       Mean reward: 822.77
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7804
    Episode_Reward/rotating_object: 160.1727
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.92s
                      Time elapsed: 00:41:48
                               ETA: 00:10:26

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 51121 steps/s (collection: 1.825s, learning 0.098s)
             Mean action noise std: 3.25
          Mean value_function loss: 35.5516
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.0521
                       Mean reward: 803.43
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 0.7741
    Episode_Reward/rotating_object: 160.1469
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.92s
                      Time elapsed: 00:41:50
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 51282 steps/s (collection: 1.822s, learning 0.095s)
             Mean action noise std: 3.25
          Mean value_function loss: 22.5085
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.0606
                       Mean reward: 818.12
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7829
    Episode_Reward/rotating_object: 159.9939
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.92s
                      Time elapsed: 00:41:52
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 51265 steps/s (collection: 1.814s, learning 0.104s)
             Mean action noise std: 3.25
          Mean value_function loss: 32.5408
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.0646
                       Mean reward: 797.48
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 0.7809
    Episode_Reward/rotating_object: 161.9868
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.92s
                      Time elapsed: 00:41:54
                               ETA: 00:10:20

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 51570 steps/s (collection: 1.802s, learning 0.104s)
             Mean action noise std: 3.25
          Mean value_function loss: 31.9475
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.0688
                       Mean reward: 777.05
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 0.7769
    Episode_Reward/rotating_object: 158.1070
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.91s
                      Time elapsed: 00:41:56
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 50618 steps/s (collection: 1.803s, learning 0.139s)
             Mean action noise std: 3.25
          Mean value_function loss: 38.6882
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.0774
                       Mean reward: 793.14
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 0.7717
    Episode_Reward/rotating_object: 157.0248
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.94s
                      Time elapsed: 00:41:58
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 52497 steps/s (collection: 1.776s, learning 0.097s)
             Mean action noise std: 3.25
          Mean value_function loss: 27.9265
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.0881
                       Mean reward: 782.97
               Mean episode length: 242.46
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 156.8134
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.87s
                      Time elapsed: 00:41:59
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 52225 steps/s (collection: 1.779s, learning 0.103s)
             Mean action noise std: 3.26
          Mean value_function loss: 37.1922
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.0994
                       Mean reward: 794.90
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 0.7833
    Episode_Reward/rotating_object: 161.1893
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.88s
                      Time elapsed: 00:42:01
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 51657 steps/s (collection: 1.796s, learning 0.107s)
             Mean action noise std: 3.26
          Mean value_function loss: 38.7885
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.1128
                       Mean reward: 762.55
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 0.7594
    Episode_Reward/rotating_object: 153.9342
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.90s
                      Time elapsed: 00:42:03
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 51648 steps/s (collection: 1.808s, learning 0.096s)
             Mean action noise std: 3.26
          Mean value_function loss: 48.1448
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.1240
                       Mean reward: 741.47
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 0.7579
    Episode_Reward/rotating_object: 154.8306
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.90s
                      Time elapsed: 00:42:05
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 51045 steps/s (collection: 1.835s, learning 0.091s)
             Mean action noise std: 3.26
          Mean value_function loss: 35.9991
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.1338
                       Mean reward: 821.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7806
    Episode_Reward/rotating_object: 158.4884
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.93s
                      Time elapsed: 00:42:07
                               ETA: 00:10:05

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 51171 steps/s (collection: 1.801s, learning 0.120s)
             Mean action noise std: 3.26
          Mean value_function loss: 46.5213
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 45.1396
                       Mean reward: 785.80
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 0.7753
    Episode_Reward/rotating_object: 158.9708
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.92s
                      Time elapsed: 00:42:09
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 51406 steps/s (collection: 1.793s, learning 0.119s)
             Mean action noise std: 3.27
          Mean value_function loss: 39.3618
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.1442
                       Mean reward: 781.65
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 0.7696
    Episode_Reward/rotating_object: 155.9417
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.91s
                      Time elapsed: 00:42:11
                               ETA: 00:10:01

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 52280 steps/s (collection: 1.785s, learning 0.096s)
             Mean action noise std: 3.27
          Mean value_function loss: 53.6867
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.1515
                       Mean reward: 776.70
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 0.7643
    Episode_Reward/rotating_object: 155.4453
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.88s
                      Time elapsed: 00:42:13
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 53017 steps/s (collection: 1.764s, learning 0.091s)
             Mean action noise std: 3.27
          Mean value_function loss: 33.0483
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.1573
                       Mean reward: 784.00
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 0.7688
    Episode_Reward/rotating_object: 156.7863
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.85s
                      Time elapsed: 00:42:15
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 51892 steps/s (collection: 1.783s, learning 0.112s)
             Mean action noise std: 3.27
          Mean value_function loss: 40.1772
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.1643
                       Mean reward: 792.84
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 0.7755
    Episode_Reward/rotating_object: 158.0647
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.89s
                      Time elapsed: 00:42:17
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 51590 steps/s (collection: 1.801s, learning 0.105s)
             Mean action noise std: 3.27
          Mean value_function loss: 25.1177
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 45.1741
                       Mean reward: 784.08
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 0.7801
    Episode_Reward/rotating_object: 158.7911
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.91s
                      Time elapsed: 00:42:18
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 51023 steps/s (collection: 1.810s, learning 0.117s)
             Mean action noise std: 3.27
          Mean value_function loss: 32.1439
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 45.1793
                       Mean reward: 810.43
               Mean episode length: 244.51
    Episode_Reward/reaching_object: 0.7719
    Episode_Reward/rotating_object: 158.0188
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.93s
                      Time elapsed: 00:42:20
                               ETA: 00:09:50

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 51742 steps/s (collection: 1.804s, learning 0.096s)
             Mean action noise std: 3.27
          Mean value_function loss: 37.7244
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 45.1820
                       Mean reward: 803.16
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 0.7775
    Episode_Reward/rotating_object: 157.4710
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.90s
                      Time elapsed: 00:42:22
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 49417 steps/s (collection: 1.843s, learning 0.147s)
             Mean action noise std: 3.27
          Mean value_function loss: 47.3852
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.1856
                       Mean reward: 772.33
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 0.7627
    Episode_Reward/rotating_object: 155.0089
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.99s
                      Time elapsed: 00:42:24
                               ETA: 00:09:46

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 50279 steps/s (collection: 1.853s, learning 0.103s)
             Mean action noise std: 3.28
          Mean value_function loss: 40.1559
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.1937
                       Mean reward: 781.89
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 0.7709
    Episode_Reward/rotating_object: 157.7474
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.96s
                      Time elapsed: 00:42:26
                               ETA: 00:09:44

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 51593 steps/s (collection: 1.779s, learning 0.127s)
             Mean action noise std: 3.28
          Mean value_function loss: 41.1159
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.2036
                       Mean reward: 809.42
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.7752
    Episode_Reward/rotating_object: 159.3098
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.91s
                      Time elapsed: 00:42:28
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 50434 steps/s (collection: 1.815s, learning 0.135s)
             Mean action noise std: 3.28
          Mean value_function loss: 45.1840
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.2093
                       Mean reward: 761.72
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 156.5749
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.95s
                      Time elapsed: 00:42:30
                               ETA: 00:09:39

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 49554 steps/s (collection: 1.847s, learning 0.137s)
             Mean action noise std: 3.28
          Mean value_function loss: 44.8305
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.2210
                       Mean reward: 804.51
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7794
    Episode_Reward/rotating_object: 159.2020
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.98s
                      Time elapsed: 00:42:32
                               ETA: 00:09:37

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 52503 steps/s (collection: 1.756s, learning 0.117s)
             Mean action noise std: 3.28
          Mean value_function loss: 46.5872
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.2366
                       Mean reward: 797.58
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 0.7687
    Episode_Reward/rotating_object: 158.0343
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.87s
                      Time elapsed: 00:42:34
                               ETA: 00:09:35

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 50187 steps/s (collection: 1.854s, learning 0.105s)
             Mean action noise std: 3.29
          Mean value_function loss: 27.6806
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.2459
                       Mean reward: 793.21
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 0.7797
    Episode_Reward/rotating_object: 160.9341
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.96s
                      Time elapsed: 00:42:36
                               ETA: 00:09:33

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 51513 steps/s (collection: 1.811s, learning 0.098s)
             Mean action noise std: 3.29
          Mean value_function loss: 34.4597
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.2599
                       Mean reward: 791.13
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 0.7829
    Episode_Reward/rotating_object: 160.1001
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.91s
                      Time elapsed: 00:42:38
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 51053 steps/s (collection: 1.817s, learning 0.108s)
             Mean action noise std: 3.29
          Mean value_function loss: 28.3370
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.2683
                       Mean reward: 766.41
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 0.7657
    Episode_Reward/rotating_object: 154.6753
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.93s
                      Time elapsed: 00:42:40
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 51524 steps/s (collection: 1.799s, learning 0.108s)
             Mean action noise std: 3.29
          Mean value_function loss: 29.8873
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.2747
                       Mean reward: 822.87
               Mean episode length: 248.62
    Episode_Reward/reaching_object: 0.7888
    Episode_Reward/rotating_object: 161.1247
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.91s
                      Time elapsed: 00:42:42
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 50999 steps/s (collection: 1.833s, learning 0.094s)
             Mean action noise std: 3.29
          Mean value_function loss: 37.9645
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.2837
                       Mean reward: 797.70
               Mean episode length: 244.76
    Episode_Reward/reaching_object: 0.7778
    Episode_Reward/rotating_object: 159.0985
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.93s
                      Time elapsed: 00:42:44
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 51335 steps/s (collection: 1.820s, learning 0.095s)
             Mean action noise std: 3.30
          Mean value_function loss: 37.0029
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.2998
                       Mean reward: 778.94
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.7767
    Episode_Reward/rotating_object: 157.4307
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.91s
                      Time elapsed: 00:42:45
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 51285 steps/s (collection: 1.791s, learning 0.126s)
             Mean action noise std: 3.30
          Mean value_function loss: 29.6623
               Mean surrogate loss: 0.0069
                 Mean entropy loss: 45.3144
                       Mean reward: 771.83
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 0.7762
    Episode_Reward/rotating_object: 156.2889
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 1.92s
                      Time elapsed: 00:42:47
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 52296 steps/s (collection: 1.787s, learning 0.092s)
             Mean action noise std: 3.30
          Mean value_function loss: 33.0899
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 45.3162
                       Mean reward: 793.96
               Mean episode length: 247.25
    Episode_Reward/reaching_object: 0.7891
    Episode_Reward/rotating_object: 159.1057
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 1.88s
                      Time elapsed: 00:42:49
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 49675 steps/s (collection: 1.816s, learning 0.163s)
             Mean action noise std: 3.30
          Mean value_function loss: 56.3016
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.3173
                       Mean reward: 776.39
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 0.7674
    Episode_Reward/rotating_object: 156.1073
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 1.98s
                      Time elapsed: 00:42:51
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 50782 steps/s (collection: 1.825s, learning 0.111s)
             Mean action noise std: 3.30
          Mean value_function loss: 49.8204
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.3244
                       Mean reward: 784.99
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 0.7709
    Episode_Reward/rotating_object: 158.1929
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.94s
                      Time elapsed: 00:42:53
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 49851 steps/s (collection: 1.841s, learning 0.131s)
             Mean action noise std: 3.30
          Mean value_function loss: 50.0269
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.3363
                       Mean reward: 791.25
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 0.7606
    Episode_Reward/rotating_object: 155.3902
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 1.97s
                      Time elapsed: 00:42:55
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 49377 steps/s (collection: 1.856s, learning 0.135s)
             Mean action noise std: 3.30
          Mean value_function loss: 49.8552
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.3475
                       Mean reward: 762.90
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 0.7438
    Episode_Reward/rotating_object: 151.6207
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 1.99s
                      Time elapsed: 00:42:57
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 49990 steps/s (collection: 1.863s, learning 0.103s)
             Mean action noise std: 3.31
          Mean value_function loss: 47.8169
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.3559
                       Mean reward: 787.72
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7701
    Episode_Reward/rotating_object: 158.6244
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 1.97s
                      Time elapsed: 00:42:59
                               ETA: 00:09:08

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 49595 steps/s (collection: 1.841s, learning 0.142s)
             Mean action noise std: 3.31
          Mean value_function loss: 45.4064
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.3661
                       Mean reward: 775.41
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 0.7595
    Episode_Reward/rotating_object: 156.3917
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 1.98s
                      Time elapsed: 00:43:01
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 50912 steps/s (collection: 1.835s, learning 0.096s)
             Mean action noise std: 3.31
          Mean value_function loss: 47.2862
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.3819
                       Mean reward: 783.23
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 0.7618
    Episode_Reward/rotating_object: 157.7533
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 1.93s
                      Time elapsed: 00:43:03
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 50783 steps/s (collection: 1.837s, learning 0.099s)
             Mean action noise std: 3.31
          Mean value_function loss: 38.6027
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.3939
                       Mean reward: 752.66
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 0.7659
    Episode_Reward/rotating_object: 158.1717
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 1.94s
                      Time elapsed: 00:43:05
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 50445 steps/s (collection: 1.842s, learning 0.107s)
             Mean action noise std: 3.32
          Mean value_function loss: 50.3303
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.4058
                       Mean reward: 759.86
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 154.1562
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.95s
                      Time elapsed: 00:43:07
                               ETA: 00:08:59

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 49740 steps/s (collection: 1.864s, learning 0.112s)
             Mean action noise std: 3.32
          Mean value_function loss: 39.8069
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.4169
                       Mean reward: 776.41
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.7558
    Episode_Reward/rotating_object: 152.3710
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 1.98s
                      Time elapsed: 00:43:09
                               ETA: 00:08:57

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 48889 steps/s (collection: 1.906s, learning 0.105s)
             Mean action noise std: 3.32
          Mean value_function loss: 45.0839
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.4350
                       Mean reward: 790.51
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 0.7638
    Episode_Reward/rotating_object: 153.8569
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.01s
                      Time elapsed: 00:43:11
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 50270 steps/s (collection: 1.860s, learning 0.096s)
             Mean action noise std: 3.32
          Mean value_function loss: 39.1859
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.4426
                       Mean reward: 761.79
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 0.7742
    Episode_Reward/rotating_object: 156.3882
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 1.96s
                      Time elapsed: 00:43:13
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 50050 steps/s (collection: 1.834s, learning 0.130s)
             Mean action noise std: 3.32
          Mean value_function loss: 37.3037
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.4506
                       Mean reward: 734.34
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 0.7712
    Episode_Reward/rotating_object: 155.8677
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 1.96s
                      Time elapsed: 00:43:15
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 49126 steps/s (collection: 1.894s, learning 0.107s)
             Mean action noise std: 3.33
          Mean value_function loss: 32.9601
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.4574
                       Mean reward: 798.99
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.7770
    Episode_Reward/rotating_object: 158.4793
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.00s
                      Time elapsed: 00:43:17
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 49668 steps/s (collection: 1.853s, learning 0.127s)
             Mean action noise std: 3.33
          Mean value_function loss: 33.0162
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.4654
                       Mean reward: 824.21
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7815
    Episode_Reward/rotating_object: 158.5098
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 1.98s
                      Time elapsed: 00:43:19
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 49678 steps/s (collection: 1.873s, learning 0.106s)
             Mean action noise std: 3.33
          Mean value_function loss: 38.3356
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.4742
                       Mean reward: 776.05
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 0.7734
    Episode_Reward/rotating_object: 157.8915
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.98s
                      Time elapsed: 00:43:21
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 49374 steps/s (collection: 1.872s, learning 0.119s)
             Mean action noise std: 3.33
          Mean value_function loss: 48.5386
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.4825
                       Mean reward: 779.02
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 0.7520
    Episode_Reward/rotating_object: 151.9143
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 1.99s
                      Time elapsed: 00:43:23
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 49937 steps/s (collection: 1.850s, learning 0.118s)
             Mean action noise std: 3.33
          Mean value_function loss: 37.6322
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.4892
                       Mean reward: 782.59
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 0.7701
    Episode_Reward/rotating_object: 156.5686
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 1.97s
                      Time elapsed: 00:43:25
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 49876 steps/s (collection: 1.873s, learning 0.098s)
             Mean action noise std: 3.33
          Mean value_function loss: 43.4683
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.4953
                       Mean reward: 794.50
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 0.7754
    Episode_Reward/rotating_object: 156.9514
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 1.97s
                      Time elapsed: 00:43:27
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 49959 steps/s (collection: 1.853s, learning 0.115s)
             Mean action noise std: 3.34
          Mean value_function loss: 38.9882
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.5085
                       Mean reward: 793.70
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 0.7803
    Episode_Reward/rotating_object: 157.9853
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 1.97s
                      Time elapsed: 00:43:29
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 47361 steps/s (collection: 1.904s, learning 0.172s)
             Mean action noise std: 3.34
          Mean value_function loss: 47.4240
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.5244
                       Mean reward: 783.23
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 0.7728
    Episode_Reward/rotating_object: 157.4258
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.08s
                      Time elapsed: 00:43:31
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 49997 steps/s (collection: 1.849s, learning 0.118s)
             Mean action noise std: 3.34
          Mean value_function loss: 38.6959
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.5342
                       Mean reward: 791.17
               Mean episode length: 242.83
    Episode_Reward/reaching_object: 0.7774
    Episode_Reward/rotating_object: 156.7129
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 1.97s
                      Time elapsed: 00:43:33
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 47121 steps/s (collection: 1.893s, learning 0.193s)
             Mean action noise std: 3.34
          Mean value_function loss: 30.6117
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.5443
                       Mean reward: 815.49
               Mean episode length: 247.66
    Episode_Reward/reaching_object: 0.7655
    Episode_Reward/rotating_object: 155.1679
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.09s
                      Time elapsed: 00:43:35
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 48415 steps/s (collection: 1.927s, learning 0.103s)
             Mean action noise std: 3.34
          Mean value_function loss: 44.3447
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.5535
                       Mean reward: 750.79
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 0.7701
    Episode_Reward/rotating_object: 154.2716
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.03s
                      Time elapsed: 00:43:37
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 50092 steps/s (collection: 1.857s, learning 0.106s)
             Mean action noise std: 3.35
          Mean value_function loss: 37.9809
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.5620
                       Mean reward: 776.96
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.7640
    Episode_Reward/rotating_object: 154.7295
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 1.96s
                      Time elapsed: 00:43:39
                               ETA: 00:08:25

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 48325 steps/s (collection: 1.927s, learning 0.108s)
             Mean action noise std: 3.35
          Mean value_function loss: 49.6346
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.5716
                       Mean reward: 818.30
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.7765
    Episode_Reward/rotating_object: 158.6926
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.03s
                      Time elapsed: 00:43:41
                               ETA: 00:08:23

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 50479 steps/s (collection: 1.845s, learning 0.103s)
             Mean action noise std: 3.35
          Mean value_function loss: 38.4855
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.5805
                       Mean reward: 794.81
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 0.7731
    Episode_Reward/rotating_object: 156.8396
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 1.95s
                      Time elapsed: 00:43:43
                               ETA: 00:08:21

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 50058 steps/s (collection: 1.859s, learning 0.104s)
             Mean action noise std: 3.35
          Mean value_function loss: 31.3336
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.5821
                       Mean reward: 807.25
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 0.7910
    Episode_Reward/rotating_object: 160.8280
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 1.96s
                      Time elapsed: 00:43:45
                               ETA: 00:08:19

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 49758 steps/s (collection: 1.870s, learning 0.106s)
             Mean action noise std: 3.35
          Mean value_function loss: 35.0387
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.5858
                       Mean reward: 771.22
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 0.7837
    Episode_Reward/rotating_object: 159.1371
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 1.98s
                      Time elapsed: 00:43:47
                               ETA: 00:08:17

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 49140 steps/s (collection: 1.872s, learning 0.128s)
             Mean action noise std: 3.36
          Mean value_function loss: 36.7811
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.5934
                       Mean reward: 789.12
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 0.7764
    Episode_Reward/rotating_object: 157.1947
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.00s
                      Time elapsed: 00:43:49
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 51369 steps/s (collection: 1.812s, learning 0.102s)
             Mean action noise std: 3.36
          Mean value_function loss: 35.1972
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.5996
                       Mean reward: 821.16
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7813
    Episode_Reward/rotating_object: 159.2787
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 1.91s
                      Time elapsed: 00:43:51
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 49056 steps/s (collection: 1.857s, learning 0.146s)
             Mean action noise std: 3.36
          Mean value_function loss: 45.9333
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 45.6050
                       Mean reward: 785.28
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 0.7697
    Episode_Reward/rotating_object: 155.8130
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.00s
                      Time elapsed: 00:43:53
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 50031 steps/s (collection: 1.836s, learning 0.128s)
             Mean action noise std: 3.36
          Mean value_function loss: 36.0047
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.6171
                       Mean reward: 775.07
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 0.7822
    Episode_Reward/rotating_object: 159.4066
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 1.96s
                      Time elapsed: 00:43:55
                               ETA: 00:08:09

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 49245 steps/s (collection: 1.854s, learning 0.142s)
             Mean action noise std: 3.36
          Mean value_function loss: 42.1564
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.6296
                       Mean reward: 792.24
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 0.7761
    Episode_Reward/rotating_object: 156.6359
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.00s
                      Time elapsed: 00:43:57
                               ETA: 00:08:07

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 49157 steps/s (collection: 1.892s, learning 0.108s)
             Mean action noise std: 3.37
          Mean value_function loss: 39.3351
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.6384
                       Mean reward: 812.77
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7735
    Episode_Reward/rotating_object: 157.5030
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.00s
                      Time elapsed: 00:43:59
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 49782 steps/s (collection: 1.873s, learning 0.102s)
             Mean action noise std: 3.37
          Mean value_function loss: 37.8720
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.6450
                       Mean reward: 817.14
               Mean episode length: 246.90
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 153.6465
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 1.97s
                      Time elapsed: 00:44:01
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 48311 steps/s (collection: 1.872s, learning 0.163s)
             Mean action noise std: 3.37
          Mean value_function loss: 54.1573
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.6521
                       Mean reward: 772.94
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.7702
    Episode_Reward/rotating_object: 156.5251
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.03s
                      Time elapsed: 00:44:03
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 49302 steps/s (collection: 1.853s, learning 0.141s)
             Mean action noise std: 3.37
          Mean value_function loss: 37.9244
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.6624
                       Mean reward: 781.88
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 0.7754
    Episode_Reward/rotating_object: 158.2366
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.99s
                      Time elapsed: 00:44:05
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 47054 steps/s (collection: 1.983s, learning 0.106s)
             Mean action noise std: 3.37
          Mean value_function loss: 44.6626
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.6780
                       Mean reward: 793.65
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 0.7734
    Episode_Reward/rotating_object: 157.6652
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.09s
                      Time elapsed: 00:44:07
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 48727 steps/s (collection: 1.905s, learning 0.112s)
             Mean action noise std: 3.37
          Mean value_function loss: 31.2026
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.6848
                       Mean reward: 802.29
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 0.7779
    Episode_Reward/rotating_object: 158.7910
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.02s
                      Time elapsed: 00:44:09
                               ETA: 00:07:54

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 48559 steps/s (collection: 1.908s, learning 0.117s)
             Mean action noise std: 3.38
          Mean value_function loss: 46.4434
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.6873
                       Mean reward: 766.36
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.7711
    Episode_Reward/rotating_object: 155.8233
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.02s
                      Time elapsed: 00:44:11
                               ETA: 00:07:52

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 49865 steps/s (collection: 1.867s, learning 0.104s)
             Mean action noise std: 3.38
          Mean value_function loss: 37.8953
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.6986
                       Mean reward: 775.69
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 0.7797
    Episode_Reward/rotating_object: 157.7015
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 1.97s
                      Time elapsed: 00:44:13
                               ETA: 00:07:50

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 49327 steps/s (collection: 1.888s, learning 0.105s)
             Mean action noise std: 3.38
          Mean value_function loss: 44.0116
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.7126
                       Mean reward: 783.29
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 0.7754
    Episode_Reward/rotating_object: 156.7973
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 1.99s
                      Time elapsed: 00:44:15
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 48742 steps/s (collection: 1.913s, learning 0.104s)
             Mean action noise std: 3.38
          Mean value_function loss: 36.6989
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 45.7148
                       Mean reward: 760.27
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 0.7782
    Episode_Reward/rotating_object: 156.6834
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.02s
                      Time elapsed: 00:44:17
                               ETA: 00:07:46

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 46428 steps/s (collection: 1.997s, learning 0.121s)
             Mean action noise std: 3.38
          Mean value_function loss: 38.8400
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 45.7152
                       Mean reward: 789.36
               Mean episode length: 238.84
    Episode_Reward/reaching_object: 0.7768
    Episode_Reward/rotating_object: 156.4684
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.12s
                      Time elapsed: 00:44:19
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 49321 steps/s (collection: 1.883s, learning 0.110s)
             Mean action noise std: 3.38
          Mean value_function loss: 36.8910
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.7173
                       Mean reward: 794.29
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.7765
    Episode_Reward/rotating_object: 156.8121
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 1.99s
                      Time elapsed: 00:44:21
                               ETA: 00:07:41

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 48251 steps/s (collection: 1.903s, learning 0.134s)
             Mean action noise std: 3.38
          Mean value_function loss: 30.6975
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.7212
                       Mean reward: 805.42
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 0.7905
    Episode_Reward/rotating_object: 161.8624
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.04s
                      Time elapsed: 00:44:23
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 45750 steps/s (collection: 1.944s, learning 0.205s)
             Mean action noise std: 3.38
          Mean value_function loss: 26.4159
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.7233
                       Mean reward: 784.69
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 0.7883
    Episode_Reward/rotating_object: 159.6442
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.15s
                      Time elapsed: 00:44:25
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 49792 steps/s (collection: 1.857s, learning 0.117s)
             Mean action noise std: 3.38
          Mean value_function loss: 41.4050
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.7265
                       Mean reward: 790.46
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 0.7782
    Episode_Reward/rotating_object: 158.0473
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 1.97s
                      Time elapsed: 00:44:27
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 47755 steps/s (collection: 1.947s, learning 0.112s)
             Mean action noise std: 3.39
          Mean value_function loss: 37.2772
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.7351
                       Mean reward: 766.55
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 0.7807
    Episode_Reward/rotating_object: 157.2525
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.06s
                      Time elapsed: 00:44:29
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 46983 steps/s (collection: 1.958s, learning 0.135s)
             Mean action noise std: 3.39
          Mean value_function loss: 32.9286
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.7465
                       Mean reward: 776.36
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 0.7739
    Episode_Reward/rotating_object: 157.6265
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.09s
                      Time elapsed: 00:44:31
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 48082 steps/s (collection: 1.919s, learning 0.126s)
             Mean action noise std: 3.39
          Mean value_function loss: 32.9755
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.7524
                       Mean reward: 790.85
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 0.7777
    Episode_Reward/rotating_object: 157.9151
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.04s
                      Time elapsed: 00:44:33
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 48374 steps/s (collection: 1.920s, learning 0.112s)
             Mean action noise std: 3.39
          Mean value_function loss: 37.9234
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.7594
                       Mean reward: 809.81
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 0.7763
    Episode_Reward/rotating_object: 158.1633
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.03s
                      Time elapsed: 00:44:35
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 49518 steps/s (collection: 1.882s, learning 0.104s)
             Mean action noise std: 3.39
          Mean value_function loss: 43.5671
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.7695
                       Mean reward: 778.32
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 0.7737
    Episode_Reward/rotating_object: 156.8218
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 1.99s
                      Time elapsed: 00:44:37
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 48447 steps/s (collection: 1.898s, learning 0.131s)
             Mean action noise std: 3.39
          Mean value_function loss: 47.5126
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.7759
                       Mean reward: 750.85
               Mean episode length: 231.96
    Episode_Reward/reaching_object: 0.7645
    Episode_Reward/rotating_object: 155.4496
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.03s
                      Time elapsed: 00:44:39
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 48752 steps/s (collection: 1.915s, learning 0.102s)
             Mean action noise std: 3.40
          Mean value_function loss: 41.4003
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.7878
                       Mean reward: 797.10
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 0.7662
    Episode_Reward/rotating_object: 156.5536
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.02s
                      Time elapsed: 00:44:41
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 49692 steps/s (collection: 1.876s, learning 0.103s)
             Mean action noise std: 3.40
          Mean value_function loss: 44.5269
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.7976
                       Mean reward: 801.23
               Mean episode length: 242.88
    Episode_Reward/reaching_object: 0.7809
    Episode_Reward/rotating_object: 160.8457
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 1.98s
                      Time elapsed: 00:44:43
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 44553 steps/s (collection: 2.092s, learning 0.115s)
             Mean action noise std: 3.40
          Mean value_function loss: 35.4313
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 45.8072
                       Mean reward: 794.28
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 0.7520
    Episode_Reward/rotating_object: 153.6978
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.21s
                      Time elapsed: 00:44:45
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 45077 steps/s (collection: 2.024s, learning 0.157s)
             Mean action noise std: 3.40
          Mean value_function loss: 32.9134
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.8150
                       Mean reward: 783.31
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 0.7706
    Episode_Reward/rotating_object: 157.4612
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.18s
                      Time elapsed: 00:44:48
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 46479 steps/s (collection: 1.981s, learning 0.134s)
             Mean action noise std: 3.40
          Mean value_function loss: 39.6445
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 45.8225
                       Mean reward: 794.58
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 0.7795
    Episode_Reward/rotating_object: 161.0496
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.12s
                      Time elapsed: 00:44:50
                               ETA: 00:07:12

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 46408 steps/s (collection: 2.014s, learning 0.105s)
             Mean action noise std: 3.40
          Mean value_function loss: 28.6879
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.8293
                       Mean reward: 777.97
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 0.7791
    Episode_Reward/rotating_object: 161.3857
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.12s
                      Time elapsed: 00:44:52
                               ETA: 00:07:10

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 50204 steps/s (collection: 1.856s, learning 0.102s)
             Mean action noise std: 3.41
          Mean value_function loss: 35.4634
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.8426
                       Mean reward: 782.73
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.7742
    Episode_Reward/rotating_object: 157.6082
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 1.96s
                      Time elapsed: 00:44:54
                               ETA: 00:07:08

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 49039 steps/s (collection: 1.892s, learning 0.113s)
             Mean action noise std: 3.41
          Mean value_function loss: 30.5189
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.8549
                       Mean reward: 792.58
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 0.7754
    Episode_Reward/rotating_object: 158.2820
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.00s
                      Time elapsed: 00:44:56
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 50340 steps/s (collection: 1.844s, learning 0.109s)
             Mean action noise std: 3.41
          Mean value_function loss: 46.7918
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.8606
                       Mean reward: 789.00
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 0.7630
    Episode_Reward/rotating_object: 157.1208
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 1.95s
                      Time elapsed: 00:44:58
                               ETA: 00:07:04

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 50363 steps/s (collection: 1.821s, learning 0.131s)
             Mean action noise std: 3.41
          Mean value_function loss: 22.9614
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.8655
                       Mean reward: 800.49
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 0.7741
    Episode_Reward/rotating_object: 159.0805
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 1.95s
                      Time elapsed: 00:45:00
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 48089 steps/s (collection: 1.838s, learning 0.206s)
             Mean action noise std: 3.41
          Mean value_function loss: 46.6002
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.8727
                       Mean reward: 785.06
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 0.7756
    Episode_Reward/rotating_object: 159.5051
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.04s
                      Time elapsed: 00:45:02
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 50189 steps/s (collection: 1.836s, learning 0.123s)
             Mean action noise std: 3.42
          Mean value_function loss: 28.1329
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.8826
                       Mean reward: 816.77
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7725
    Episode_Reward/rotating_object: 159.5123
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 1.96s
                      Time elapsed: 00:45:04
                               ETA: 00:06:58

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 47503 steps/s (collection: 1.875s, learning 0.195s)
             Mean action noise std: 3.42
          Mean value_function loss: 27.4248
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.8911
                       Mean reward: 816.40
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7833
    Episode_Reward/rotating_object: 163.1555
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.07s
                      Time elapsed: 00:45:06
                               ETA: 00:06:56

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 48288 steps/s (collection: 1.917s, learning 0.119s)
             Mean action noise std: 3.42
          Mean value_function loss: 37.3085
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.9029
                       Mean reward: 809.49
               Mean episode length: 244.68
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 160.6151
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.04s
                      Time elapsed: 00:45:08
                               ETA: 00:06:53

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 49290 steps/s (collection: 1.874s, learning 0.120s)
             Mean action noise std: 3.42
          Mean value_function loss: 33.9593
               Mean surrogate loss: 0.0206
                 Mean entropy loss: 45.9130
                       Mean reward: 804.88
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 0.7686
    Episode_Reward/rotating_object: 159.3439
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 1.99s
                      Time elapsed: 00:45:10
                               ETA: 00:06:51

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 48296 steps/s (collection: 1.900s, learning 0.135s)
             Mean action noise std: 3.42
          Mean value_function loss: 29.3264
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 45.9164
                       Mean reward: 795.10
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 0.7715
    Episode_Reward/rotating_object: 159.6167
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.04s
                      Time elapsed: 00:45:12
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 49253 steps/s (collection: 1.869s, learning 0.127s)
             Mean action noise std: 3.42
          Mean value_function loss: 44.3576
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.9169
                       Mean reward: 781.28
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 0.7729
    Episode_Reward/rotating_object: 158.6290
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.00s
                      Time elapsed: 00:45:14
                               ETA: 00:06:47

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 46589 steps/s (collection: 1.998s, learning 0.112s)
             Mean action noise std: 3.42
          Mean value_function loss: 27.1874
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.9191
                       Mean reward: 790.64
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 0.7708
    Episode_Reward/rotating_object: 158.2178
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.11s
                      Time elapsed: 00:45:16
                               ETA: 00:06:45

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 50553 steps/s (collection: 1.840s, learning 0.105s)
             Mean action noise std: 3.42
          Mean value_function loss: 22.8009
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.9217
                       Mean reward: 823.85
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7912
    Episode_Reward/rotating_object: 161.9466
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 1.94s
                      Time elapsed: 00:45:18
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 47374 steps/s (collection: 1.954s, learning 0.121s)
             Mean action noise std: 3.43
          Mean value_function loss: 30.7415
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.9267
                       Mean reward: 805.21
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.7851
    Episode_Reward/rotating_object: 160.5533
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.08s
                      Time elapsed: 00:45:20
                               ETA: 00:06:41

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 48367 steps/s (collection: 1.897s, learning 0.136s)
             Mean action noise std: 3.43
          Mean value_function loss: 31.0469
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.9333
                       Mean reward: 801.67
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 0.7773
    Episode_Reward/rotating_object: 157.4304
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.03s
                      Time elapsed: 00:45:22
                               ETA: 00:06:39

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 47185 steps/s (collection: 1.942s, learning 0.142s)
             Mean action noise std: 3.43
          Mean value_function loss: 33.6223
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.9418
                       Mean reward: 792.66
               Mean episode length: 244.98
    Episode_Reward/reaching_object: 0.7850
    Episode_Reward/rotating_object: 159.5243
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.08s
                      Time elapsed: 00:45:24
                               ETA: 00:06:37

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 49525 steps/s (collection: 1.864s, learning 0.121s)
             Mean action noise std: 3.43
          Mean value_function loss: 27.3258
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.9558
                       Mean reward: 798.57
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.7788
    Episode_Reward/rotating_object: 159.1847
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.98s
                      Time elapsed: 00:45:26
                               ETA: 00:06:35

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 48893 steps/s (collection: 1.889s, learning 0.122s)
             Mean action noise std: 3.44
          Mean value_function loss: 26.9617
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.9649
                       Mean reward: 792.19
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 0.7877
    Episode_Reward/rotating_object: 161.1817
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.01s
                      Time elapsed: 00:45:28
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 49144 steps/s (collection: 1.837s, learning 0.164s)
             Mean action noise std: 3.44
          Mean value_function loss: 42.8055
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.9739
                       Mean reward: 766.13
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 0.7789
    Episode_Reward/rotating_object: 157.9140
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.00s
                      Time elapsed: 00:45:30
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 49593 steps/s (collection: 1.875s, learning 0.108s)
             Mean action noise std: 3.44
          Mean value_function loss: 30.5145
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.9830
                       Mean reward: 805.44
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 0.7822
    Episode_Reward/rotating_object: 160.2465
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.98s
                      Time elapsed: 00:45:32
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 50650 steps/s (collection: 1.837s, learning 0.104s)
             Mean action noise std: 3.44
          Mean value_function loss: 40.0647
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.9922
                       Mean reward: 809.43
               Mean episode length: 244.77
    Episode_Reward/reaching_object: 0.7830
    Episode_Reward/rotating_object: 160.6320
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.94s
                      Time elapsed: 00:45:34
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 49058 steps/s (collection: 1.874s, learning 0.130s)
             Mean action noise std: 3.44
          Mean value_function loss: 38.4389
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.0009
                       Mean reward: 807.16
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.7769
    Episode_Reward/rotating_object: 159.4644
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.00s
                      Time elapsed: 00:45:36
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 50085 steps/s (collection: 1.841s, learning 0.122s)
             Mean action noise std: 3.44
          Mean value_function loss: 27.3772
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.0104
                       Mean reward: 808.85
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7841
    Episode_Reward/rotating_object: 160.8764
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 1.96s
                      Time elapsed: 00:45:38
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 49346 steps/s (collection: 1.856s, learning 0.136s)
             Mean action noise std: 3.45
          Mean value_function loss: 47.2503
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.0168
                       Mean reward: 802.87
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 157.9710
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.99s
                      Time elapsed: 00:45:40
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 49710 steps/s (collection: 1.863s, learning 0.115s)
             Mean action noise std: 3.45
          Mean value_function loss: 49.4959
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.0251
                       Mean reward: 764.66
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 155.4095
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.98s
                      Time elapsed: 00:45:42
                               ETA: 00:06:18

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 48106 steps/s (collection: 1.895s, learning 0.148s)
             Mean action noise std: 3.45
          Mean value_function loss: 46.8948
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.0340
                       Mean reward: 816.75
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.7708
    Episode_Reward/rotating_object: 159.0535
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.04s
                      Time elapsed: 00:45:44
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 48103 steps/s (collection: 1.908s, learning 0.136s)
             Mean action noise std: 3.45
          Mean value_function loss: 38.5883
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.0434
                       Mean reward: 798.76
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 0.7776
    Episode_Reward/rotating_object: 159.8302
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.04s
                      Time elapsed: 00:45:46
                               ETA: 00:06:14

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 47502 steps/s (collection: 1.940s, learning 0.129s)
             Mean action noise std: 3.45
          Mean value_function loss: 26.3837
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 46.0513
                       Mean reward: 826.33
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7750
    Episode_Reward/rotating_object: 159.7626
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.07s
                      Time elapsed: 00:45:48
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 48877 steps/s (collection: 1.897s, learning 0.114s)
             Mean action noise std: 3.45
          Mean value_function loss: 29.4299
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.0546
                       Mean reward: 814.06
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7801
    Episode_Reward/rotating_object: 160.7296
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.01s
                      Time elapsed: 00:45:50
                               ETA: 00:06:10

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 48850 steps/s (collection: 1.871s, learning 0.142s)
             Mean action noise std: 3.46
          Mean value_function loss: 34.3385
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.0605
                       Mean reward: 776.00
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 0.7653
    Episode_Reward/rotating_object: 156.6347
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.01s
                      Time elapsed: 00:45:52
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 51213 steps/s (collection: 1.819s, learning 0.101s)
             Mean action noise std: 3.46
          Mean value_function loss: 36.2387
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.0672
                       Mean reward: 797.47
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 0.7747
    Episode_Reward/rotating_object: 156.7838
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 1.92s
                      Time elapsed: 00:45:54
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 50375 steps/s (collection: 1.822s, learning 0.129s)
             Mean action noise std: 3.46
          Mean value_function loss: 39.4100
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.0763
                       Mean reward: 801.59
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 0.7657
    Episode_Reward/rotating_object: 157.3167
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 1.95s
                      Time elapsed: 00:45:56
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 48032 steps/s (collection: 1.915s, learning 0.131s)
             Mean action noise std: 3.46
          Mean value_function loss: 41.9731
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.0878
                       Mean reward: 809.25
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7727
    Episode_Reward/rotating_object: 157.8896
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.05s
                      Time elapsed: 00:45:58
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 49022 steps/s (collection: 1.886s, learning 0.119s)
             Mean action noise std: 3.46
          Mean value_function loss: 51.6461
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.1020
                       Mean reward: 776.04
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 0.7622
    Episode_Reward/rotating_object: 155.0380
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.01s
                      Time elapsed: 00:46:00
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 48680 steps/s (collection: 1.895s, learning 0.125s)
             Mean action noise std: 3.47
          Mean value_function loss: 27.0365
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.1119
                       Mean reward: 785.25
               Mean episode length: 240.97
    Episode_Reward/reaching_object: 0.7768
    Episode_Reward/rotating_object: 158.5693
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.02s
                      Time elapsed: 00:46:02
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 50230 steps/s (collection: 1.856s, learning 0.101s)
             Mean action noise std: 3.47
          Mean value_function loss: 37.6957
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.1153
                       Mean reward: 779.31
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 0.7757
    Episode_Reward/rotating_object: 159.7348
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.96s
                      Time elapsed: 00:46:04
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 49559 steps/s (collection: 1.873s, learning 0.111s)
             Mean action noise std: 3.47
          Mean value_function loss: 35.3880
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.1239
                       Mean reward: 758.65
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.7695
    Episode_Reward/rotating_object: 157.0440
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.98s
                      Time elapsed: 00:46:06
                               ETA: 00:05:53

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 49524 steps/s (collection: 1.852s, learning 0.133s)
             Mean action noise std: 3.47
          Mean value_function loss: 28.5182
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 46.1351
                       Mean reward: 787.33
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.7822
    Episode_Reward/rotating_object: 161.7413
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 1.98s
                      Time elapsed: 00:46:08
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 49219 steps/s (collection: 1.860s, learning 0.138s)
             Mean action noise std: 3.47
          Mean value_function loss: 39.1093
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.1399
                       Mean reward: 793.05
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.7764
    Episode_Reward/rotating_object: 159.1493
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.00s
                      Time elapsed: 00:46:10
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 20174 steps/s (collection: 4.739s, learning 0.134s)
             Mean action noise std: 3.47
          Mean value_function loss: 40.4543
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 46.1485
                       Mean reward: 794.19
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.7830
    Episode_Reward/rotating_object: 161.5653
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 4.87s
                      Time elapsed: 00:46:15
                               ETA: 00:05:47

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14427 steps/s (collection: 6.683s, learning 0.131s)
             Mean action noise std: 3.48
          Mean value_function loss: 44.6302
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.1568
                       Mean reward: 788.51
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 0.7591
    Episode_Reward/rotating_object: 154.4418
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.81s
                      Time elapsed: 00:46:22
                               ETA: 00:05:45

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14342 steps/s (collection: 6.717s, learning 0.137s)
             Mean action noise std: 3.48
          Mean value_function loss: 23.7015
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.1612
                       Mean reward: 794.22
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 0.7670
    Episode_Reward/rotating_object: 156.5892
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.85s
                      Time elapsed: 00:46:28
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14404 steps/s (collection: 6.681s, learning 0.143s)
             Mean action noise std: 3.48
          Mean value_function loss: 29.7233
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.1678
                       Mean reward: 819.45
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7759
    Episode_Reward/rotating_object: 158.8209
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.82s
                      Time elapsed: 00:46:35
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14529 steps/s (collection: 6.600s, learning 0.166s)
             Mean action noise std: 3.48
          Mean value_function loss: 20.3592
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.1768
                       Mean reward: 823.11
               Mean episode length: 248.33
    Episode_Reward/reaching_object: 0.7806
    Episode_Reward/rotating_object: 159.3514
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.77s
                      Time elapsed: 00:46:42
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 14269 steps/s (collection: 6.718s, learning 0.171s)
             Mean action noise std: 3.48
          Mean value_function loss: 35.9003
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 46.1874
                       Mean reward: 800.65
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.7751
    Episode_Reward/rotating_object: 158.8336
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.89s
                      Time elapsed: 00:46:49
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14047 steps/s (collection: 6.868s, learning 0.130s)
             Mean action noise std: 3.48
          Mean value_function loss: 44.1484
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.1922
                       Mean reward: 794.96
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.7679
    Episode_Reward/rotating_object: 158.0681
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 7.00s
                      Time elapsed: 00:46:56
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14517 steps/s (collection: 6.649s, learning 0.123s)
             Mean action noise std: 3.49
          Mean value_function loss: 39.6568
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.1990
                       Mean reward: 795.19
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 0.7647
    Episode_Reward/rotating_object: 157.8904
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.77s
                      Time elapsed: 00:47:03
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 12806 steps/s (collection: 7.421s, learning 0.256s)
             Mean action noise std: 3.49
          Mean value_function loss: 28.0459
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.2078
                       Mean reward: 814.57
               Mean episode length: 244.76
    Episode_Reward/reaching_object: 0.7692
    Episode_Reward/rotating_object: 158.5179
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.68s
                      Time elapsed: 00:47:10
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 42177 steps/s (collection: 2.150s, learning 0.181s)
             Mean action noise std: 3.49
          Mean value_function loss: 30.4745
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.2129
                       Mean reward: 806.94
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 0.7758
    Episode_Reward/rotating_object: 161.3696
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.33s
                      Time elapsed: 00:47:13
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 48365 steps/s (collection: 1.927s, learning 0.106s)
             Mean action noise std: 3.49
          Mean value_function loss: 34.6607
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.2161
                       Mean reward: 802.49
               Mean episode length: 244.69
    Episode_Reward/reaching_object: 0.7695
    Episode_Reward/rotating_object: 159.3566
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.03s
                      Time elapsed: 00:47:15
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 51251 steps/s (collection: 1.746s, learning 0.172s)
             Mean action noise std: 3.49
          Mean value_function loss: 29.9454
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.2228
                       Mean reward: 781.87
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 0.7658
    Episode_Reward/rotating_object: 158.1423
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.92s
                      Time elapsed: 00:47:17
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 52534 steps/s (collection: 1.766s, learning 0.105s)
             Mean action noise std: 3.49
          Mean value_function loss: 29.1435
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.2303
                       Mean reward: 795.87
               Mean episode length: 242.80
    Episode_Reward/reaching_object: 0.7835
    Episode_Reward/rotating_object: 162.2285
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.87s
                      Time elapsed: 00:47:19
                               ETA: 00:05:26

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 50621 steps/s (collection: 1.798s, learning 0.144s)
             Mean action noise std: 3.49
          Mean value_function loss: 36.5273
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.2355
                       Mean reward: 802.16
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 156.8374
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.94s
                      Time elapsed: 00:47:21
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 49658 steps/s (collection: 1.857s, learning 0.123s)
             Mean action noise std: 3.50
          Mean value_function loss: 30.9284
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.2441
                       Mean reward: 811.51
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 160.6832
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 1.98s
                      Time elapsed: 00:47:22
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 50172 steps/s (collection: 1.813s, learning 0.147s)
             Mean action noise std: 3.50
          Mean value_function loss: 26.0128
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.2520
                       Mean reward: 830.56
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7814
    Episode_Reward/rotating_object: 164.7109
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.96s
                      Time elapsed: 00:47:24
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 47796 steps/s (collection: 1.932s, learning 0.125s)
             Mean action noise std: 3.50
          Mean value_function loss: 45.9117
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 46.2618
                       Mean reward: 811.94
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 0.7584
    Episode_Reward/rotating_object: 157.5248
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.06s
                      Time elapsed: 00:47:27
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 51203 steps/s (collection: 1.826s, learning 0.094s)
             Mean action noise std: 3.50
          Mean value_function loss: 33.7831
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.2760
                       Mean reward: 806.15
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 158.7180
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.92s
                      Time elapsed: 00:47:28
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 47659 steps/s (collection: 1.913s, learning 0.150s)
             Mean action noise std: 3.50
          Mean value_function loss: 36.3716
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 46.2846
                       Mean reward: 760.39
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 0.7604
    Episode_Reward/rotating_object: 157.3122
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.06s
                      Time elapsed: 00:47:30
                               ETA: 00:05:14

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 53508 steps/s (collection: 1.747s, learning 0.091s)
             Mean action noise std: 3.51
          Mean value_function loss: 34.7783
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.2978
                       Mean reward: 795.09
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 0.7651
    Episode_Reward/rotating_object: 159.9740
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.84s
                      Time elapsed: 00:47:32
                               ETA: 00:05:12

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 48081 steps/s (collection: 1.865s, learning 0.180s)
             Mean action noise std: 3.51
          Mean value_function loss: 36.3780
               Mean surrogate loss: 0.0085
                 Mean entropy loss: 46.3093
                       Mean reward: 805.92
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.7652
    Episode_Reward/rotating_object: 159.7991
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.04s
                      Time elapsed: 00:47:34
                               ETA: 00:05:09

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 51287 steps/s (collection: 1.804s, learning 0.113s)
             Mean action noise std: 3.51
          Mean value_function loss: 35.2957
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 46.3107
                       Mean reward: 796.50
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 0.7663
    Episode_Reward/rotating_object: 158.9716
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.92s
                      Time elapsed: 00:47:36
                               ETA: 00:05:07

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 52667 steps/s (collection: 1.768s, learning 0.099s)
             Mean action noise std: 3.51
          Mean value_function loss: 37.2554
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.3145
                       Mean reward: 795.42
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 0.7624
    Episode_Reward/rotating_object: 158.1365
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.87s
                      Time elapsed: 00:47:38
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 53746 steps/s (collection: 1.735s, learning 0.095s)
             Mean action noise std: 3.51
          Mean value_function loss: 29.3562
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.3224
                       Mean reward: 812.63
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 0.7708
    Episode_Reward/rotating_object: 160.9306
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.83s
                      Time elapsed: 00:47:40
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 52802 steps/s (collection: 1.761s, learning 0.101s)
             Mean action noise std: 3.51
          Mean value_function loss: 38.4057
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.3325
                       Mean reward: 816.82
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 0.7601
    Episode_Reward/rotating_object: 158.3878
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.86s
                      Time elapsed: 00:47:42
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 52541 steps/s (collection: 1.774s, learning 0.097s)
             Mean action noise std: 3.52
          Mean value_function loss: 38.9216
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.3444
                       Mean reward: 813.71
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.7622
    Episode_Reward/rotating_object: 158.1799
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 1.87s
                      Time elapsed: 00:47:44
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 52181 steps/s (collection: 1.780s, learning 0.104s)
             Mean action noise std: 3.52
          Mean value_function loss: 25.9642
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.3541
                       Mean reward: 789.22
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 0.7563
    Episode_Reward/rotating_object: 156.8342
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.88s
                      Time elapsed: 00:47:46
                               ETA: 00:04:57

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 51799 steps/s (collection: 1.749s, learning 0.149s)
             Mean action noise std: 3.52
          Mean value_function loss: 39.6056
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 46.3631
                       Mean reward: 818.09
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.7656
    Episode_Reward/rotating_object: 160.0403
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.90s
                      Time elapsed: 00:47:47
                               ETA: 00:04:55

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 52390 steps/s (collection: 1.763s, learning 0.113s)
             Mean action noise std: 3.52
          Mean value_function loss: 41.2071
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.3721
                       Mean reward: 806.92
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.7653
    Episode_Reward/rotating_object: 159.3851
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.88s
                      Time elapsed: 00:47:49
                               ETA: 00:04:52

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 52820 steps/s (collection: 1.768s, learning 0.093s)
             Mean action noise std: 3.52
          Mean value_function loss: 43.7915
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.3781
                       Mean reward: 779.38
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 0.7570
    Episode_Reward/rotating_object: 159.1360
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.86s
                      Time elapsed: 00:47:51
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 52137 steps/s (collection: 1.760s, learning 0.125s)
             Mean action noise std: 3.52
          Mean value_function loss: 36.9069
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.3829
                       Mean reward: 805.87
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.7649
    Episode_Reward/rotating_object: 160.6207
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.89s
                      Time elapsed: 00:47:53
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 53500 steps/s (collection: 1.740s, learning 0.098s)
             Mean action noise std: 3.53
          Mean value_function loss: 38.5072
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.3877
                       Mean reward: 815.07
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.7599
    Episode_Reward/rotating_object: 159.6906
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.84s
                      Time elapsed: 00:47:55
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 51778 steps/s (collection: 1.799s, learning 0.099s)
             Mean action noise std: 3.53
          Mean value_function loss: 33.8965
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.3918
                       Mean reward: 771.81
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 0.7574
    Episode_Reward/rotating_object: 157.6332
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.90s
                      Time elapsed: 00:47:57
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 52773 steps/s (collection: 1.749s, learning 0.114s)
             Mean action noise std: 3.53
          Mean value_function loss: 33.9591
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.3989
                       Mean reward: 796.53
               Mean episode length: 240.96
    Episode_Reward/reaching_object: 0.7600
    Episode_Reward/rotating_object: 158.4406
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.86s
                      Time elapsed: 00:47:59
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 52324 steps/s (collection: 1.731s, learning 0.148s)
             Mean action noise std: 3.53
          Mean value_function loss: 32.7658
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.4077
                       Mean reward: 815.33
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 0.7621
    Episode_Reward/rotating_object: 159.2306
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.88s
                      Time elapsed: 00:48:01
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 53915 steps/s (collection: 1.719s, learning 0.105s)
             Mean action noise std: 3.53
          Mean value_function loss: 24.3342
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.4171
                       Mean reward: 805.61
               Mean episode length: 245.10
    Episode_Reward/reaching_object: 0.7681
    Episode_Reward/rotating_object: 160.9707
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.82s
                      Time elapsed: 00:48:02
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 53168 steps/s (collection: 1.745s, learning 0.104s)
             Mean action noise std: 3.54
          Mean value_function loss: 32.9027
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 46.4274
                       Mean reward: 820.43
               Mean episode length: 248.37
    Episode_Reward/reaching_object: 0.7640
    Episode_Reward/rotating_object: 159.8385
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.85s
                      Time elapsed: 00:48:04
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 52341 steps/s (collection: 1.781s, learning 0.097s)
             Mean action noise std: 3.54
          Mean value_function loss: 45.5324
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.4360
                       Mean reward: 786.96
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 0.7653
    Episode_Reward/rotating_object: 160.1049
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.88s
                      Time elapsed: 00:48:06
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 52444 steps/s (collection: 1.779s, learning 0.096s)
             Mean action noise std: 3.54
          Mean value_function loss: 35.8014
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 46.4419
                       Mean reward: 788.15
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 0.7614
    Episode_Reward/rotating_object: 157.9795
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.87s
                      Time elapsed: 00:48:08
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 52588 steps/s (collection: 1.757s, learning 0.113s)
             Mean action noise std: 3.54
          Mean value_function loss: 40.8120
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.4478
                       Mean reward: 794.84
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 0.7613
    Episode_Reward/rotating_object: 160.0224
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.87s
                      Time elapsed: 00:48:10
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 53564 steps/s (collection: 1.735s, learning 0.100s)
             Mean action noise std: 3.54
          Mean value_function loss: 37.8517
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 46.4549
                       Mean reward: 803.13
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 0.7603
    Episode_Reward/rotating_object: 157.1135
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.84s
                      Time elapsed: 00:48:12
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 51736 steps/s (collection: 1.777s, learning 0.124s)
             Mean action noise std: 3.54
          Mean value_function loss: 32.4775
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.4602
                       Mean reward: 791.10
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.7583
    Episode_Reward/rotating_object: 157.2208
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.90s
                      Time elapsed: 00:48:14
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 50839 steps/s (collection: 1.827s, learning 0.107s)
             Mean action noise std: 3.55
          Mean value_function loss: 31.5340
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.4694
                       Mean reward: 806.74
               Mean episode length: 245.17
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 160.3667
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.93s
                      Time elapsed: 00:48:16
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 48317 steps/s (collection: 1.848s, learning 0.186s)
             Mean action noise std: 3.55
          Mean value_function loss: 36.9362
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.4801
                       Mean reward: 793.42
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 0.7702
    Episode_Reward/rotating_object: 161.1136
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.03s
                      Time elapsed: 00:48:18
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 53692 steps/s (collection: 1.736s, learning 0.095s)
             Mean action noise std: 3.55
          Mean value_function loss: 28.5036
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 46.4959
                       Mean reward: 801.39
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 0.7652
    Episode_Reward/rotating_object: 158.5318
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.83s
                      Time elapsed: 00:48:19
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 51945 steps/s (collection: 1.781s, learning 0.112s)
             Mean action noise std: 3.55
          Mean value_function loss: 36.5970
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.5022
                       Mean reward: 786.68
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 158.1759
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.89s
                      Time elapsed: 00:48:21
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 48896 steps/s (collection: 1.913s, learning 0.097s)
             Mean action noise std: 3.56
          Mean value_function loss: 37.0720
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.5114
                       Mean reward: 824.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7702
    Episode_Reward/rotating_object: 161.2658
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.01s
                      Time elapsed: 00:48:23
                               ETA: 00:04:14

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 51828 steps/s (collection: 1.796s, learning 0.101s)
             Mean action noise std: 3.56
          Mean value_function loss: 36.6572
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 46.5186
                       Mean reward: 771.30
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 159.5333
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.90s
                      Time elapsed: 00:48:25
                               ETA: 00:04:12

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 49749 steps/s (collection: 1.828s, learning 0.148s)
             Mean action noise std: 3.56
          Mean value_function loss: 39.7968
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.5262
                       Mean reward: 808.39
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7692
    Episode_Reward/rotating_object: 161.6591
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.98s
                      Time elapsed: 00:48:27
                               ETA: 00:04:10

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 49150 steps/s (collection: 1.844s, learning 0.156s)
             Mean action noise std: 3.56
          Mean value_function loss: 37.7484
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.5415
                       Mean reward: 800.81
               Mean episode length: 242.79
    Episode_Reward/reaching_object: 0.7670
    Episode_Reward/rotating_object: 159.6507
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.00s
                      Time elapsed: 00:48:29
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 51569 steps/s (collection: 1.799s, learning 0.108s)
             Mean action noise std: 3.56
          Mean value_function loss: 37.3045
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.5517
                       Mean reward: 786.71
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 0.7668
    Episode_Reward/rotating_object: 156.9569
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.91s
                      Time elapsed: 00:48:31
                               ETA: 00:04:06

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 51866 steps/s (collection: 1.785s, learning 0.111s)
             Mean action noise std: 3.57
          Mean value_function loss: 25.1080
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.5580
                       Mean reward: 821.24
               Mean episode length: 247.57
    Episode_Reward/reaching_object: 0.7727
    Episode_Reward/rotating_object: 161.0149
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.90s
                      Time elapsed: 00:48:33
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 51839 steps/s (collection: 1.739s, learning 0.157s)
             Mean action noise std: 3.57
          Mean value_function loss: 29.0274
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.5704
                       Mean reward: 787.72
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 0.7642
    Episode_Reward/rotating_object: 157.4684
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.90s
                      Time elapsed: 00:48:35
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 51395 steps/s (collection: 1.757s, learning 0.156s)
             Mean action noise std: 3.57
          Mean value_function loss: 28.8314
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.5806
                       Mean reward: 799.50
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 0.7642
    Episode_Reward/rotating_object: 158.9788
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.91s
                      Time elapsed: 00:48:37
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 51906 steps/s (collection: 1.749s, learning 0.145s)
             Mean action noise std: 3.57
          Mean value_function loss: 36.3263
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.5877
                       Mean reward: 796.97
               Mean episode length: 244.83
    Episode_Reward/reaching_object: 0.7673
    Episode_Reward/rotating_object: 158.0441
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.89s
                      Time elapsed: 00:48:39
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 53760 steps/s (collection: 1.731s, learning 0.098s)
             Mean action noise std: 3.57
          Mean value_function loss: 33.9942
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.5925
                       Mean reward: 797.98
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 0.7699
    Episode_Reward/rotating_object: 160.9833
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.83s
                      Time elapsed: 00:48:41
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 52133 steps/s (collection: 1.794s, learning 0.092s)
             Mean action noise std: 3.57
          Mean value_function loss: 25.4145
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.6012
                       Mean reward: 779.76
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 0.7680
    Episode_Reward/rotating_object: 160.2552
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.89s
                      Time elapsed: 00:48:42
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 53452 steps/s (collection: 1.743s, learning 0.096s)
             Mean action noise std: 3.58
          Mean value_function loss: 36.3172
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.6118
                       Mean reward: 791.98
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 0.7658
    Episode_Reward/rotating_object: 159.8220
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.84s
                      Time elapsed: 00:48:44
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 54298 steps/s (collection: 1.716s, learning 0.094s)
             Mean action noise std: 3.58
          Mean value_function loss: 32.8687
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.6241
                       Mean reward: 820.63
               Mean episode length: 245.46
    Episode_Reward/reaching_object: 0.7741
    Episode_Reward/rotating_object: 163.0657
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.81s
                      Time elapsed: 00:48:46
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 52718 steps/s (collection: 1.736s, learning 0.129s)
             Mean action noise std: 3.58
          Mean value_function loss: 35.8162
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 46.6366
                       Mean reward: 798.60
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.7683
    Episode_Reward/rotating_object: 160.7253
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.86s
                      Time elapsed: 00:48:48
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 50374 steps/s (collection: 1.800s, learning 0.151s)
             Mean action noise std: 3.58
          Mean value_function loss: 30.1034
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.6419
                       Mean reward: 794.06
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 0.7720
    Episode_Reward/rotating_object: 162.1170
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.95s
                      Time elapsed: 00:48:50
                               ETA: 00:03:44

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 51804 steps/s (collection: 1.743s, learning 0.155s)
             Mean action noise std: 3.58
          Mean value_function loss: 35.7437
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.6426
                       Mean reward: 828.58
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 160.4456
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.90s
                      Time elapsed: 00:48:52
                               ETA: 00:03:42

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 53462 steps/s (collection: 1.741s, learning 0.098s)
             Mean action noise std: 3.58
          Mean value_function loss: 37.2186
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.6457
                       Mean reward: 814.97
               Mean episode length: 247.16
    Episode_Reward/reaching_object: 0.7663
    Episode_Reward/rotating_object: 159.9488
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.84s
                      Time elapsed: 00:48:54
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 52953 steps/s (collection: 1.766s, learning 0.091s)
             Mean action noise std: 3.58
          Mean value_function loss: 42.8734
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.6505
                       Mean reward: 801.86
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.7655
    Episode_Reward/rotating_object: 159.3412
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.86s
                      Time elapsed: 00:48:55
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 52148 steps/s (collection: 1.779s, learning 0.106s)
             Mean action noise std: 3.59
          Mean value_function loss: 34.4893
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.6563
                       Mean reward: 812.77
               Mean episode length: 246.66
    Episode_Reward/reaching_object: 0.7654
    Episode_Reward/rotating_object: 159.1340
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.89s
                      Time elapsed: 00:48:57
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 52748 steps/s (collection: 1.762s, learning 0.102s)
             Mean action noise std: 3.59
          Mean value_function loss: 33.6274
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 46.6640
                       Mean reward: 822.14
               Mean episode length: 249.43
    Episode_Reward/reaching_object: 0.7646
    Episode_Reward/rotating_object: 159.7261
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.86s
                      Time elapsed: 00:48:59
                               ETA: 00:03:34

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 52727 steps/s (collection: 1.739s, learning 0.126s)
             Mean action noise std: 3.59
          Mean value_function loss: 47.9375
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.6672
                       Mean reward: 801.68
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 0.7621
    Episode_Reward/rotating_object: 159.6830
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.86s
                      Time elapsed: 00:49:01
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 51689 steps/s (collection: 1.770s, learning 0.132s)
             Mean action noise std: 3.59
          Mean value_function loss: 34.8804
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.6719
                       Mean reward: 801.79
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 158.3215
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.90s
                      Time elapsed: 00:49:03
                               ETA: 00:03:30

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 52094 steps/s (collection: 1.787s, learning 0.100s)
             Mean action noise std: 3.59
          Mean value_function loss: 29.6863
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.6843
                       Mean reward: 825.34
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 0.7722
    Episode_Reward/rotating_object: 160.5766
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.89s
                      Time elapsed: 00:49:05
                               ETA: 00:03:27

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 50259 steps/s (collection: 1.824s, learning 0.132s)
             Mean action noise std: 3.59
          Mean value_function loss: 35.7596
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.6950
                       Mean reward: 782.71
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 0.7644
    Episode_Reward/rotating_object: 158.0172
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.96s
                      Time elapsed: 00:49:07
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 49548 steps/s (collection: 1.892s, learning 0.092s)
             Mean action noise std: 3.60
          Mean value_function loss: 27.3388
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.7004
                       Mean reward: 805.78
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7677
    Episode_Reward/rotating_object: 158.1031
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.98s
                      Time elapsed: 00:49:09
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 52774 steps/s (collection: 1.769s, learning 0.094s)
             Mean action noise std: 3.60
          Mean value_function loss: 34.8582
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.7056
                       Mean reward: 832.50
               Mean episode length: 249.14
    Episode_Reward/reaching_object: 0.7765
    Episode_Reward/rotating_object: 162.1405
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.86s
                      Time elapsed: 00:49:11
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 51846 steps/s (collection: 1.780s, learning 0.116s)
             Mean action noise std: 3.60
          Mean value_function loss: 25.4877
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 46.7115
                       Mean reward: 808.15
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.7664
    Episode_Reward/rotating_object: 158.8323
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.90s
                      Time elapsed: 00:49:13
                               ETA: 00:03:19

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 51005 steps/s (collection: 1.812s, learning 0.116s)
             Mean action noise std: 3.60
          Mean value_function loss: 33.9310
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 46.7155
                       Mean reward: 787.95
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 158.8573
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.93s
                      Time elapsed: 00:49:15
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 51919 steps/s (collection: 1.780s, learning 0.114s)
             Mean action noise std: 3.60
          Mean value_function loss: 30.6182
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.7188
                       Mean reward: 819.99
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.7736
    Episode_Reward/rotating_object: 162.0912
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.89s
                      Time elapsed: 00:49:16
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 51074 steps/s (collection: 1.808s, learning 0.117s)
             Mean action noise std: 3.60
          Mean value_function loss: 32.3013
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.7250
                       Mean reward: 802.07
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.7630
    Episode_Reward/rotating_object: 158.6807
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.92s
                      Time elapsed: 00:49:18
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 51945 steps/s (collection: 1.791s, learning 0.101s)
             Mean action noise std: 3.60
          Mean value_function loss: 32.9032
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.7306
                       Mean reward: 784.04
               Mean episode length: 240.76
    Episode_Reward/reaching_object: 0.7769
    Episode_Reward/rotating_object: 162.2720
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.89s
                      Time elapsed: 00:49:20
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 50776 steps/s (collection: 1.833s, learning 0.103s)
             Mean action noise std: 3.60
          Mean value_function loss: 22.9630
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.7370
                       Mean reward: 798.76
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 0.7574
    Episode_Reward/rotating_object: 157.9328
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.94s
                      Time elapsed: 00:49:22
                               ETA: 00:03:08

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 51218 steps/s (collection: 1.764s, learning 0.155s)
             Mean action noise std: 3.61
          Mean value_function loss: 29.5650
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.7434
                       Mean reward: 803.33
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.7765
    Episode_Reward/rotating_object: 161.8216
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.92s
                      Time elapsed: 00:49:24
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 50510 steps/s (collection: 1.806s, learning 0.140s)
             Mean action noise std: 3.61
          Mean value_function loss: 28.3162
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 46.7489
                       Mean reward: 777.13
               Mean episode length: 239.93
    Episode_Reward/reaching_object: 0.7728
    Episode_Reward/rotating_object: 159.6212
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.95s
                      Time elapsed: 00:49:26
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 51486 steps/s (collection: 1.765s, learning 0.144s)
             Mean action noise std: 3.61
          Mean value_function loss: 42.1326
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.7540
                       Mean reward: 803.36
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 0.7620
    Episode_Reward/rotating_object: 159.0835
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.91s
                      Time elapsed: 00:49:28
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 49204 steps/s (collection: 1.813s, learning 0.185s)
             Mean action noise std: 3.61
          Mean value_function loss: 33.5103
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.7597
                       Mean reward: 797.75
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 0.7631
    Episode_Reward/rotating_object: 157.7159
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.00s
                      Time elapsed: 00:49:30
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 52149 steps/s (collection: 1.782s, learning 0.103s)
             Mean action noise std: 3.61
          Mean value_function loss: 27.4779
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.7659
                       Mean reward: 797.13
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 0.7628
    Episode_Reward/rotating_object: 158.3438
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.89s
                      Time elapsed: 00:49:32
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 52110 steps/s (collection: 1.783s, learning 0.104s)
             Mean action noise std: 3.61
          Mean value_function loss: 37.5546
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.7728
                       Mean reward: 811.36
               Mean episode length: 245.34
    Episode_Reward/reaching_object: 0.7760
    Episode_Reward/rotating_object: 161.7074
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.89s
                      Time elapsed: 00:49:34
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 52246 steps/s (collection: 1.781s, learning 0.101s)
             Mean action noise std: 3.61
          Mean value_function loss: 27.6885
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.7821
                       Mean reward: 796.85
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 0.7754
    Episode_Reward/rotating_object: 161.7829
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.88s
                      Time elapsed: 00:49:36
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 52135 steps/s (collection: 1.778s, learning 0.108s)
             Mean action noise std: 3.62
          Mean value_function loss: 30.3458
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.7869
                       Mean reward: 810.79
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 0.7720
    Episode_Reward/rotating_object: 161.0872
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.89s
                      Time elapsed: 00:49:37
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 51831 steps/s (collection: 1.790s, learning 0.107s)
             Mean action noise std: 3.62
          Mean value_function loss: 30.5472
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.7908
                       Mean reward: 801.80
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.7802
    Episode_Reward/rotating_object: 163.3708
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.90s
                      Time elapsed: 00:49:39
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 52414 steps/s (collection: 1.772s, learning 0.103s)
             Mean action noise std: 3.62
          Mean value_function loss: 52.1194
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.7961
                       Mean reward: 749.83
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 0.7570
    Episode_Reward/rotating_object: 158.1259
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.88s
                      Time elapsed: 00:49:41
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 50134 steps/s (collection: 1.811s, learning 0.150s)
             Mean action noise std: 3.62
          Mean value_function loss: 42.1673
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.8039
                       Mean reward: 803.52
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 0.7563
    Episode_Reward/rotating_object: 156.5084
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.96s
                      Time elapsed: 00:49:43
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 51538 steps/s (collection: 1.769s, learning 0.139s)
             Mean action noise std: 3.62
          Mean value_function loss: 30.7799
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.8126
                       Mean reward: 818.80
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 0.7622
    Episode_Reward/rotating_object: 157.4696
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.91s
                      Time elapsed: 00:49:45
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 50354 steps/s (collection: 1.779s, learning 0.174s)
             Mean action noise std: 3.62
          Mean value_function loss: 40.3841
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.8179
                       Mean reward: 794.21
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 0.7697
    Episode_Reward/rotating_object: 160.4527
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.95s
                      Time elapsed: 00:49:47
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 51745 steps/s (collection: 1.757s, learning 0.143s)
             Mean action noise std: 3.63
          Mean value_function loss: 26.3900
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.8251
                       Mean reward: 807.16
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 0.7584
    Episode_Reward/rotating_object: 158.1472
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.90s
                      Time elapsed: 00:49:49
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 52666 steps/s (collection: 1.753s, learning 0.113s)
             Mean action noise std: 3.63
          Mean value_function loss: 28.8074
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.8319
                       Mean reward: 813.66
               Mean episode length: 249.91
    Episode_Reward/reaching_object: 0.7715
    Episode_Reward/rotating_object: 159.7968
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.87s
                      Time elapsed: 00:49:51
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 51427 steps/s (collection: 1.794s, learning 0.117s)
             Mean action noise std: 3.63
          Mean value_function loss: 39.1238
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.8366
                       Mean reward: 800.26
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 0.7623
    Episode_Reward/rotating_object: 158.8990
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.91s
                      Time elapsed: 00:49:53
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 49408 steps/s (collection: 1.895s, learning 0.095s)
             Mean action noise std: 3.63
          Mean value_function loss: 41.2010
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 46.8426
                       Mean reward: 818.83
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7658
    Episode_Reward/rotating_object: 160.1938
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.99s
                      Time elapsed: 00:49:55
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 50732 steps/s (collection: 1.831s, learning 0.107s)
             Mean action noise std: 3.63
          Mean value_function loss: 32.4635
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 46.8502
                       Mean reward: 821.00
               Mean episode length: 247.40
    Episode_Reward/reaching_object: 0.7626
    Episode_Reward/rotating_object: 158.7417
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.94s
                      Time elapsed: 00:49:57
                               ETA: 00:02:31

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 49350 steps/s (collection: 1.841s, learning 0.151s)
             Mean action noise std: 3.64
          Mean value_function loss: 42.4588
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.8577
                       Mean reward: 777.24
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 0.7568
    Episode_Reward/rotating_object: 158.3296
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.99s
                      Time elapsed: 00:49:59
                               ETA: 00:02:28

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 52527 steps/s (collection: 1.783s, learning 0.088s)
             Mean action noise std: 3.64
          Mean value_function loss: 26.4725
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.8697
                       Mean reward: 817.04
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7637
    Episode_Reward/rotating_object: 158.3535
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.87s
                      Time elapsed: 00:50:01
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 51774 steps/s (collection: 1.779s, learning 0.120s)
             Mean action noise std: 3.64
          Mean value_function loss: 33.1657
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 46.8756
                       Mean reward: 790.93
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 0.7640
    Episode_Reward/rotating_object: 158.9434
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.90s
                      Time elapsed: 00:50:02
                               ETA: 00:02:24

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 50872 steps/s (collection: 1.827s, learning 0.105s)
             Mean action noise std: 3.64
          Mean value_function loss: 39.6832
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.8845
                       Mean reward: 817.57
               Mean episode length: 247.33
    Episode_Reward/reaching_object: 0.7673
    Episode_Reward/rotating_object: 160.1017
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.93s
                      Time elapsed: 00:50:04
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 51519 steps/s (collection: 1.817s, learning 0.091s)
             Mean action noise std: 3.64
          Mean value_function loss: 33.6697
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 46.8936
                       Mean reward: 778.12
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 0.7626
    Episode_Reward/rotating_object: 158.2834
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.91s
                      Time elapsed: 00:50:06
                               ETA: 00:02:20

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 51258 steps/s (collection: 1.807s, learning 0.110s)
             Mean action noise std: 3.64
          Mean value_function loss: 34.5892
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.8990
                       Mean reward: 807.33
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 0.7696
    Episode_Reward/rotating_object: 160.4946
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.92s
                      Time elapsed: 00:50:08
                               ETA: 00:02:18

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 50741 steps/s (collection: 1.841s, learning 0.097s)
             Mean action noise std: 3.64
          Mean value_function loss: 28.9905
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.9003
                       Mean reward: 795.38
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 0.7563
    Episode_Reward/rotating_object: 156.3604
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.94s
                      Time elapsed: 00:50:10
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 51042 steps/s (collection: 1.771s, learning 0.155s)
             Mean action noise std: 3.65
          Mean value_function loss: 32.2084
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.8987
                       Mean reward: 775.42
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 0.7640
    Episode_Reward/rotating_object: 158.7139
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.93s
                      Time elapsed: 00:50:12
                               ETA: 00:02:14

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 50875 steps/s (collection: 1.803s, learning 0.129s)
             Mean action noise std: 3.65
          Mean value_function loss: 30.3803
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.9001
                       Mean reward: 819.75
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7738
    Episode_Reward/rotating_object: 161.7024
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.93s
                      Time elapsed: 00:50:14
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 50935 steps/s (collection: 1.812s, learning 0.118s)
             Mean action noise std: 3.65
          Mean value_function loss: 35.0722
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.9054
                       Mean reward: 797.38
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 0.7764
    Episode_Reward/rotating_object: 162.4670
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.93s
                      Time elapsed: 00:50:16
                               ETA: 00:02:09

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 52575 steps/s (collection: 1.762s, learning 0.108s)
             Mean action noise std: 3.65
          Mean value_function loss: 31.4086
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 46.9119
                       Mean reward: 786.03
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 0.7693
    Episode_Reward/rotating_object: 159.9160
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.87s
                      Time elapsed: 00:50:18
                               ETA: 00:02:07

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 51950 steps/s (collection: 1.789s, learning 0.103s)
             Mean action noise std: 3.65
          Mean value_function loss: 31.8683
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.9147
                       Mean reward: 784.43
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.7650
    Episode_Reward/rotating_object: 159.5721
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.89s
                      Time elapsed: 00:50:20
                               ETA: 00:02:05

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 50998 steps/s (collection: 1.816s, learning 0.112s)
             Mean action noise std: 3.65
          Mean value_function loss: 18.9892
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 46.9188
                       Mean reward: 820.07
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7801
    Episode_Reward/rotating_object: 163.3023
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.93s
                      Time elapsed: 00:50:22
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 49155 steps/s (collection: 1.840s, learning 0.160s)
             Mean action noise std: 3.65
          Mean value_function loss: 34.6102
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.9209
                       Mean reward: 833.64
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7719
    Episode_Reward/rotating_object: 160.9632
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.00s
                      Time elapsed: 00:50:24
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 46569 steps/s (collection: 1.951s, learning 0.160s)
             Mean action noise std: 3.66
          Mean value_function loss: 25.2681
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.9269
                       Mean reward: 814.20
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 0.7785
    Episode_Reward/rotating_object: 162.5733
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.11s
                      Time elapsed: 00:50:26
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 51685 steps/s (collection: 1.810s, learning 0.092s)
             Mean action noise std: 3.66
          Mean value_function loss: 37.5669
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 46.9308
                       Mean reward: 792.97
               Mean episode length: 238.97
    Episode_Reward/reaching_object: 0.7572
    Episode_Reward/rotating_object: 156.7032
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.90s
                      Time elapsed: 00:50:28
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 46126 steps/s (collection: 2.026s, learning 0.105s)
             Mean action noise std: 3.66
          Mean value_function loss: 31.1636
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.9374
                       Mean reward: 832.40
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7720
    Episode_Reward/rotating_object: 161.8133
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.13s
                      Time elapsed: 00:50:30
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 52046 steps/s (collection: 1.798s, learning 0.091s)
             Mean action noise std: 3.66
          Mean value_function loss: 21.5373
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 46.9491
                       Mean reward: 831.49
               Mean episode length: 248.58
    Episode_Reward/reaching_object: 0.7750
    Episode_Reward/rotating_object: 161.3232
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.89s
                      Time elapsed: 00:50:32
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 51671 steps/s (collection: 1.802s, learning 0.100s)
             Mean action noise std: 3.66
          Mean value_function loss: 29.0710
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.9574
                       Mean reward: 809.02
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 0.7661
    Episode_Reward/rotating_object: 160.4995
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.90s
                      Time elapsed: 00:50:34
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 51271 steps/s (collection: 1.806s, learning 0.112s)
             Mean action noise std: 3.66
          Mean value_function loss: 30.2107
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 46.9647
                       Mean reward: 812.41
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 0.7757
    Episode_Reward/rotating_object: 164.1014
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.92s
                      Time elapsed: 00:50:35
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 52254 steps/s (collection: 1.741s, learning 0.141s)
             Mean action noise std: 3.66
          Mean value_function loss: 26.5378
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.9689
                       Mean reward: 786.87
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 0.7720
    Episode_Reward/rotating_object: 161.6339
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.88s
                      Time elapsed: 00:50:37
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 51109 steps/s (collection: 1.760s, learning 0.164s)
             Mean action noise std: 3.67
          Mean value_function loss: 41.1953
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.9769
                       Mean reward: 787.68
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 158.1697
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.92s
                      Time elapsed: 00:50:39
                               ETA: 00:01:44

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 51435 steps/s (collection: 1.811s, learning 0.101s)
             Mean action noise std: 3.67
          Mean value_function loss: 21.6129
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 46.9819
                       Mean reward: 829.79
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7711
    Episode_Reward/rotating_object: 162.0619
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.91s
                      Time elapsed: 00:50:41
                               ETA: 00:01:42

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 52673 steps/s (collection: 1.777s, learning 0.090s)
             Mean action noise std: 3.67
          Mean value_function loss: 49.5212
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 46.9876
                       Mean reward: 811.67
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7620
    Episode_Reward/rotating_object: 159.0925
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.87s
                      Time elapsed: 00:50:43
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 51758 steps/s (collection: 1.805s, learning 0.094s)
             Mean action noise std: 3.67
          Mean value_function loss: 26.3882
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.9910
                       Mean reward: 808.40
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 0.7602
    Episode_Reward/rotating_object: 159.3719
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.90s
                      Time elapsed: 00:50:45
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 51646 steps/s (collection: 1.808s, learning 0.096s)
             Mean action noise std: 3.67
          Mean value_function loss: 24.7488
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 46.9949
                       Mean reward: 789.28
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 0.7690
    Episode_Reward/rotating_object: 161.0941
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.90s
                      Time elapsed: 00:50:47
                               ETA: 00:01:36

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 48376 steps/s (collection: 1.930s, learning 0.102s)
             Mean action noise std: 3.67
          Mean value_function loss: 23.5762
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 47.0008
                       Mean reward: 814.57
               Mean episode length: 247.16
    Episode_Reward/reaching_object: 0.7729
    Episode_Reward/rotating_object: 161.0335
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.03s
                      Time elapsed: 00:50:49
                               ETA: 00:01:34

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 51887 steps/s (collection: 1.805s, learning 0.090s)
             Mean action noise std: 3.67
          Mean value_function loss: 30.3505
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 47.0041
                       Mean reward: 803.83
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 0.7690
    Episode_Reward/rotating_object: 160.8736
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.89s
                      Time elapsed: 00:50:51
                               ETA: 00:01:32

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 52858 steps/s (collection: 1.754s, learning 0.106s)
             Mean action noise std: 3.68
          Mean value_function loss: 35.4515
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.0102
                       Mean reward: 798.18
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 161.6143
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.86s
                      Time elapsed: 00:50:53
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 49797 steps/s (collection: 1.869s, learning 0.105s)
             Mean action noise std: 3.68
          Mean value_function loss: 28.3359
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 47.0215
                       Mean reward: 810.71
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 0.7736
    Episode_Reward/rotating_object: 160.8350
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.97s
                      Time elapsed: 00:50:55
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 51791 steps/s (collection: 1.790s, learning 0.108s)
             Mean action noise std: 3.68
          Mean value_function loss: 39.0018
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 47.0264
                       Mean reward: 806.91
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 0.7591
    Episode_Reward/rotating_object: 158.2530
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.90s
                      Time elapsed: 00:50:56
                               ETA: 00:01:25

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 52409 steps/s (collection: 1.780s, learning 0.096s)
             Mean action noise std: 3.68
          Mean value_function loss: 23.8077
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.0279
                       Mean reward: 788.22
               Mean episode length: 240.23
    Episode_Reward/reaching_object: 0.7640
    Episode_Reward/rotating_object: 158.2603
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.88s
                      Time elapsed: 00:50:58
                               ETA: 00:01:23

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 52678 steps/s (collection: 1.766s, learning 0.101s)
             Mean action noise std: 3.68
          Mean value_function loss: 23.2532
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.0318
                       Mean reward: 808.11
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 0.7738
    Episode_Reward/rotating_object: 162.3940
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.87s
                      Time elapsed: 00:51:00
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 52907 steps/s (collection: 1.757s, learning 0.101s)
             Mean action noise std: 3.68
          Mean value_function loss: 35.7790
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.0395
                       Mean reward: 822.76
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7691
    Episode_Reward/rotating_object: 161.5583
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.86s
                      Time elapsed: 00:51:02
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 51066 steps/s (collection: 1.833s, learning 0.092s)
             Mean action noise std: 3.68
          Mean value_function loss: 33.2000
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.0455
                       Mean reward: 784.95
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 0.7642
    Episode_Reward/rotating_object: 160.1439
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.93s
                      Time elapsed: 00:51:04
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 49361 steps/s (collection: 1.894s, learning 0.098s)
             Mean action noise std: 3.68
          Mean value_function loss: 24.5223
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.0494
                       Mean reward: 793.26
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 0.7726
    Episode_Reward/rotating_object: 162.1290
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.99s
                      Time elapsed: 00:51:06
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 50490 steps/s (collection: 1.800s, learning 0.147s)
             Mean action noise std: 3.69
          Mean value_function loss: 47.6029
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.0559
                       Mean reward: 790.64
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 0.7637
    Episode_Reward/rotating_object: 159.7132
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.95s
                      Time elapsed: 00:51:08
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 50802 steps/s (collection: 1.839s, learning 0.096s)
             Mean action noise std: 3.69
          Mean value_function loss: 24.9484
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.0628
                       Mean reward: 829.64
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.7711
    Episode_Reward/rotating_object: 161.5138
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.94s
                      Time elapsed: 00:51:10
                               ETA: 00:01:11

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 52660 steps/s (collection: 1.771s, learning 0.096s)
             Mean action noise std: 3.69
          Mean value_function loss: 21.6101
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 47.0663
                       Mean reward: 829.50
               Mean episode length: 249.94
    Episode_Reward/reaching_object: 0.7832
    Episode_Reward/rotating_object: 164.2795
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.87s
                      Time elapsed: 00:51:12
                               ETA: 00:01:09

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 51471 steps/s (collection: 1.803s, learning 0.107s)
             Mean action noise std: 3.69
          Mean value_function loss: 33.5859
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 47.0672
                       Mean reward: 805.84
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 0.7668
    Episode_Reward/rotating_object: 160.1398
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.91s
                      Time elapsed: 00:51:14
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 51863 steps/s (collection: 1.779s, learning 0.117s)
             Mean action noise std: 3.69
          Mean value_function loss: 28.8239
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 47.0685
                       Mean reward: 797.58
               Mean episode length: 242.07
    Episode_Reward/reaching_object: 0.7647
    Episode_Reward/rotating_object: 159.5172
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.90s
                      Time elapsed: 00:51:16
                               ETA: 00:01:04

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 51058 steps/s (collection: 1.768s, learning 0.157s)
             Mean action noise std: 3.69
          Mean value_function loss: 30.6782
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 47.0698
                       Mean reward: 804.30
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.7672
    Episode_Reward/rotating_object: 160.6792
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.93s
                      Time elapsed: 00:51:17
                               ETA: 00:01:02

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 51961 steps/s (collection: 1.780s, learning 0.112s)
             Mean action noise std: 3.69
          Mean value_function loss: 38.9545
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.0722
                       Mean reward: 799.15
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 0.7559
    Episode_Reward/rotating_object: 159.0630
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.89s
                      Time elapsed: 00:51:19
                               ETA: 00:01:00

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 52322 steps/s (collection: 1.789s, learning 0.090s)
             Mean action noise std: 3.69
          Mean value_function loss: 21.7895
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.0798
                       Mean reward: 818.88
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7735
    Episode_Reward/rotating_object: 161.6602
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.88s
                      Time elapsed: 00:51:21
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 52090 steps/s (collection: 1.792s, learning 0.096s)
             Mean action noise std: 3.69
          Mean value_function loss: 27.2615
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 47.0855
                       Mean reward: 817.09
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 0.7632
    Episode_Reward/rotating_object: 160.7664
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.89s
                      Time elapsed: 00:51:23
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 52577 steps/s (collection: 1.772s, learning 0.098s)
             Mean action noise std: 3.69
          Mean value_function loss: 30.9763
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.0903
                       Mean reward: 798.48
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 0.7618
    Episode_Reward/rotating_object: 159.0432
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.87s
                      Time elapsed: 00:51:25
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 51742 steps/s (collection: 1.798s, learning 0.102s)
             Mean action noise std: 3.70
          Mean value_function loss: 25.0161
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.0947
                       Mean reward: 824.33
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7741
    Episode_Reward/rotating_object: 162.4780
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.90s
                      Time elapsed: 00:51:27
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 50142 steps/s (collection: 1.834s, learning 0.126s)
             Mean action noise std: 3.70
          Mean value_function loss: 31.8111
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 47.0986
                       Mean reward: 825.98
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.7667
    Episode_Reward/rotating_object: 160.3380
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.96s
                      Time elapsed: 00:51:29
                               ETA: 00:00:50

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 51702 steps/s (collection: 1.810s, learning 0.092s)
             Mean action noise std: 3.70
          Mean value_function loss: 30.5544
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.1023
                       Mean reward: 802.45
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.7642
    Episode_Reward/rotating_object: 159.1089
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.90s
                      Time elapsed: 00:51:31
                               ETA: 00:00:48

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 51659 steps/s (collection: 1.759s, learning 0.144s)
             Mean action noise std: 3.70
          Mean value_function loss: 26.4123
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.1056
                       Mean reward: 817.25
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 0.7788
    Episode_Reward/rotating_object: 162.6924
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.90s
                      Time elapsed: 00:51:33
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 51004 steps/s (collection: 1.786s, learning 0.142s)
             Mean action noise std: 3.70
          Mean value_function loss: 28.2705
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 47.1096
                       Mean reward: 797.18
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 0.7645
    Episode_Reward/rotating_object: 160.0054
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.93s
                      Time elapsed: 00:51:35
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 51597 steps/s (collection: 1.737s, learning 0.168s)
             Mean action noise std: 3.70
          Mean value_function loss: 31.5530
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.1178
                       Mean reward: 818.98
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7752
    Episode_Reward/rotating_object: 161.9211
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.91s
                      Time elapsed: 00:51:37
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 52775 steps/s (collection: 1.762s, learning 0.101s)
             Mean action noise std: 3.70
          Mean value_function loss: 39.8000
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 47.1308
                       Mean reward: 827.15
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7685
    Episode_Reward/rotating_object: 160.8958
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.86s
                      Time elapsed: 00:51:38
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 52615 steps/s (collection: 1.776s, learning 0.092s)
             Mean action noise std: 3.71
          Mean value_function loss: 17.4347
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 47.1371
                       Mean reward: 819.11
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 0.7675
    Episode_Reward/rotating_object: 161.0150
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.87s
                      Time elapsed: 00:51:40
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 51137 steps/s (collection: 1.813s, learning 0.110s)
             Mean action noise std: 3.71
          Mean value_function loss: 22.1780
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.1426
                       Mean reward: 792.24
               Mean episode length: 243.10
    Episode_Reward/reaching_object: 0.7827
    Episode_Reward/rotating_object: 163.3937
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.92s
                      Time elapsed: 00:51:42
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 51663 steps/s (collection: 1.794s, learning 0.109s)
             Mean action noise std: 3.71
          Mean value_function loss: 39.6756
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 47.1520
                       Mean reward: 835.40
               Mean episode length: 248.54
    Episode_Reward/reaching_object: 0.7638
    Episode_Reward/rotating_object: 160.2932
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.90s
                      Time elapsed: 00:51:44
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 51115 steps/s (collection: 1.827s, learning 0.096s)
             Mean action noise std: 3.71
          Mean value_function loss: 30.6348
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 47.1627
                       Mean reward: 818.52
               Mean episode length: 244.77
    Episode_Reward/reaching_object: 0.7726
    Episode_Reward/rotating_object: 161.8297
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.92s
                      Time elapsed: 00:51:46
                               ETA: 00:00:31

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 52059 steps/s (collection: 1.779s, learning 0.110s)
             Mean action noise std: 3.71
          Mean value_function loss: 28.7943
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.1698
                       Mean reward: 811.80
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 0.7788
    Episode_Reward/rotating_object: 164.6797
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 18.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.89s
                      Time elapsed: 00:51:48
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 50755 steps/s (collection: 1.789s, learning 0.148s)
             Mean action noise std: 3.71
          Mean value_function loss: 27.5255
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 47.1750
                       Mean reward: 816.78
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 0.7684
    Episode_Reward/rotating_object: 161.6659
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.94s
                      Time elapsed: 00:51:50
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 51063 steps/s (collection: 1.807s, learning 0.118s)
             Mean action noise std: 3.72
          Mean value_function loss: 34.4643
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 47.1793
                       Mean reward: 779.02
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 156.9301
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.93s
                      Time elapsed: 00:51:52
                               ETA: 00:00:25

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 50906 steps/s (collection: 1.789s, learning 0.142s)
             Mean action noise std: 3.72
          Mean value_function loss: 27.3476
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 47.1841
                       Mean reward: 817.11
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 0.7630
    Episode_Reward/rotating_object: 160.0482
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.93s
                      Time elapsed: 00:51:54
                               ETA: 00:00:22

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 52275 steps/s (collection: 1.778s, learning 0.102s)
             Mean action noise std: 3.72
          Mean value_function loss: 30.0090
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.1873
                       Mean reward: 799.82
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 0.7661
    Episode_Reward/rotating_object: 161.5869
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.88s
                      Time elapsed: 00:51:56
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 52560 steps/s (collection: 1.767s, learning 0.104s)
             Mean action noise std: 3.72
          Mean value_function loss: 31.8682
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.1930
                       Mean reward: 814.00
               Mean episode length: 244.70
    Episode_Reward/reaching_object: 0.7672
    Episode_Reward/rotating_object: 160.9317
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.87s
                      Time elapsed: 00:51:57
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 51771 steps/s (collection: 1.779s, learning 0.120s)
             Mean action noise std: 3.72
          Mean value_function loss: 32.5565
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 47.1989
                       Mean reward: 815.04
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 0.7630
    Episode_Reward/rotating_object: 160.7322
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.90s
                      Time elapsed: 00:51:59
                               ETA: 00:00:16

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 51230 steps/s (collection: 1.818s, learning 0.101s)
             Mean action noise std: 3.72
          Mean value_function loss: 33.1448
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 47.2065
                       Mean reward: 777.11
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 0.7580
    Episode_Reward/rotating_object: 159.5287
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.92s
                      Time elapsed: 00:52:01
                               ETA: 00:00:14

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 52629 steps/s (collection: 1.766s, learning 0.102s)
             Mean action noise std: 3.73
          Mean value_function loss: 26.3308
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.2147
                       Mean reward: 816.45
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.7713
    Episode_Reward/rotating_object: 162.7158
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.87s
                      Time elapsed: 00:52:03
                               ETA: 00:00:12

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 50986 steps/s (collection: 1.804s, learning 0.124s)
             Mean action noise std: 3.73
          Mean value_function loss: 30.3902
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 47.2208
                       Mean reward: 805.70
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.7732
    Episode_Reward/rotating_object: 162.4450
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.93s
                      Time elapsed: 00:52:05
                               ETA: 00:00:10

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 49580 steps/s (collection: 1.855s, learning 0.128s)
             Mean action noise std: 3.73
          Mean value_function loss: 43.4289
               Mean surrogate loss: 0.0353
                 Mean entropy loss: 47.2280
                       Mean reward: 825.73
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 0.7646
    Episode_Reward/rotating_object: 159.9684
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 18.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.98s
                      Time elapsed: 00:52:07
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 49040 steps/s (collection: 1.912s, learning 0.093s)
             Mean action noise std: 3.73
          Mean value_function loss: 44.9526
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 47.2297
                       Mean reward: 815.62
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 0.7632
    Episode_Reward/rotating_object: 160.1622
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.00s
                      Time elapsed: 00:52:09
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 50243 steps/s (collection: 1.865s, learning 0.092s)
             Mean action noise std: 3.73
          Mean value_function loss: 29.4165
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 47.2286
                       Mean reward: 795.80
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 0.7592
    Episode_Reward/rotating_object: 158.5272
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.96s
                      Time elapsed: 00:52:11
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 50838 steps/s (collection: 1.834s, learning 0.100s)
             Mean action noise std: 3.73
          Mean value_function loss: 42.5712
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 47.2285
                       Mean reward: 766.73
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 0.7608
    Episode_Reward/rotating_object: 159.8260
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.93s
                      Time elapsed: 00:52:13
                               ETA: 00:00:02

