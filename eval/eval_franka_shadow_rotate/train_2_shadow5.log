################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10726 steps/s (collection: 8.856s, learning 0.309s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0023
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.0374
                       Mean reward: 0.00
               Mean episode length: 21.21
    Episode_Reward/reaching_object: 0.0011
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0005
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.16s
                      Time elapsed: 00:00:09
                               ETA: 03:49:07

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 15234 steps/s (collection: 6.300s, learning 0.153s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.1585
                       Mean reward: 0.00
               Mean episode length: 45.83
    Episode_Reward/reaching_object: 0.0029
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.45s
                      Time elapsed: 00:00:15
                               ETA: 03:15:05

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 10651 steps/s (collection: 8.999s, learning 0.230s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.2023
                       Mean reward: 0.00
               Mean episode length: 69.78
    Episode_Reward/reaching_object: 0.0045
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0023
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 9.23s
                      Time elapsed: 00:00:24
                               ETA: 03:26:46

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14857 steps/s (collection: 6.439s, learning 0.177s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.2308
                       Mean reward: 0.01
               Mean episode length: 93.42
    Episode_Reward/reaching_object: 0.0064
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0021
          Episode_Reward/joint_vel: -0.0032
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.62s
                      Time elapsed: 00:00:31
                               ETA: 03:16:15

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 15737 steps/s (collection: 6.092s, learning 0.154s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.2562
                       Mean reward: 0.01
               Mean episode length: 117.74
    Episode_Reward/reaching_object: 0.0082
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0027
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.25s
                      Time elapsed: 00:00:37
                               ETA: 03:08:02

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 15904 steps/s (collection: 6.017s, learning 0.164s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.2728
                       Mean reward: 0.01
               Mean episode length: 141.96
    Episode_Reward/reaching_object: 0.0102
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.18s
                      Time elapsed: 00:00:43
                               ETA: 03:02:16

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 17429 steps/s (collection: 5.478s, learning 0.163s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 44.3020
                       Mean reward: 0.01
               Mean episode length: 165.77
    Episode_Reward/reaching_object: 0.0119
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 5.64s
                      Time elapsed: 00:00:49
                               ETA: 02:56:11

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 16661 steps/s (collection: 5.743s, learning 0.157s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 44.3187
                       Mean reward: 0.01
               Mean episode length: 189.36
    Episode_Reward/reaching_object: 0.0139
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 5.90s
                      Time elapsed: 00:00:55
                               ETA: 02:52:24

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 18773 steps/s (collection: 5.121s, learning 0.115s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 44.2931
                       Mean reward: 0.01
               Mean episode length: 213.10
    Episode_Reward/reaching_object: 0.0157
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.24s
                      Time elapsed: 00:01:00
                               ETA: 02:47:37

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 51364 steps/s (collection: 1.796s, learning 0.118s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 44.3054
                       Mean reward: 0.02
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 0.0185
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.91s
                      Time elapsed: 00:01:02
                               ETA: 02:35:30

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 53984 steps/s (collection: 1.702s, learning 0.119s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 44.3240
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0227
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.82s
                      Time elapsed: 00:01:04
                               ETA: 02:25:23

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 55808 steps/s (collection: 1.648s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 44.3092
                       Mean reward: 0.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0250
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.76s
                      Time elapsed: 00:01:06
                               ETA: 02:16:49

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 55839 steps/s (collection: 1.641s, learning 0.120s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 44.3404
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0303
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.76s
                      Time elapsed: 00:01:07
                               ETA: 02:09:34

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 55243 steps/s (collection: 1.657s, learning 0.122s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 44.3950
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0350
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.78s
                      Time elapsed: 00:01:09
                               ETA: 02:03:23

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 53812 steps/s (collection: 1.693s, learning 0.134s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 44.4624
                       Mean reward: 0.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0433
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.83s
                      Time elapsed: 00:01:11
                               ETA: 01:58:06

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 49441 steps/s (collection: 1.852s, learning 0.136s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 44.5613
                       Mean reward: 0.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0568
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.99s
                      Time elapsed: 00:01:13
                               ETA: 01:53:43

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 55477 steps/s (collection: 1.636s, learning 0.136s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0007
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 44.6098
                       Mean reward: 0.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0807
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.77s
                      Time elapsed: 00:01:15
                               ETA: 01:49:32

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 47812 steps/s (collection: 1.925s, learning 0.132s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0013
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 44.6979
                       Mean reward: 0.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1025
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 2.06s
                      Time elapsed: 00:01:17
                               ETA: 01:46:12

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 49091 steps/s (collection: 1.884s, learning 0.118s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0023
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 44.7509
                       Mean reward: 0.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1408
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 2.00s
                      Time elapsed: 00:01:19
                               ETA: 01:43:09

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 51431 steps/s (collection: 1.782s, learning 0.130s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0036
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 44.8090
                       Mean reward: 0.95
               Mean episode length: 249.43
    Episode_Reward/reaching_object: 0.1801
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.91s
                      Time elapsed: 00:01:21
                               ETA: 01:40:17

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 48524 steps/s (collection: 1.895s, learning 0.131s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0060
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 44.8901
                       Mean reward: 1.39
               Mean episode length: 249.37
    Episode_Reward/reaching_object: 0.2490
    Episode_Reward/rotating_object: 0.0010
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 2.03s
                      Time elapsed: 00:01:23
                               ETA: 01:37:49

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 49325 steps/s (collection: 1.880s, learning 0.113s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 44.9551
                       Mean reward: 1.56
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.3019
    Episode_Reward/rotating_object: 0.0013
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.99s
                      Time elapsed: 00:01:25
                               ETA: 01:35:33

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 49671 steps/s (collection: 1.867s, learning 0.113s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0107
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.0512
                       Mean reward: 2.09
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 0.3776
    Episode_Reward/rotating_object: 0.0075
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.98s
                      Time elapsed: 00:01:27
                               ETA: 01:33:27

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 47242 steps/s (collection: 1.966s, learning 0.115s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0252
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 45.0976
                       Mean reward: 2.45
               Mean episode length: 240.62
    Episode_Reward/reaching_object: 0.4275
    Episode_Reward/rotating_object: 0.0095
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.08s
                      Time elapsed: 00:01:29
                               ETA: 01:31:38

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 47479 steps/s (collection: 1.934s, learning 0.137s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0285
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 45.1747
                       Mean reward: 2.42
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 0.4884
    Episode_Reward/rotating_object: 0.0192
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 9.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.07s
                      Time elapsed: 00:01:31
                               ETA: 01:29:56

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 45532 steps/s (collection: 2.017s, learning 0.142s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0974
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.2399
                       Mean reward: 3.34
               Mean episode length: 226.02
    Episode_Reward/reaching_object: 0.5131
    Episode_Reward/rotating_object: 0.0452
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 7.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.16s
                      Time elapsed: 00:01:33
                               ETA: 01:28:28

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 43189 steps/s (collection: 2.156s, learning 0.120s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0719
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.3781
                       Mean reward: 3.23
               Mean episode length: 221.45
    Episode_Reward/reaching_object: 0.5316
    Episode_Reward/rotating_object: 0.0358
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 5.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.28s
                      Time elapsed: 00:01:35
                               ETA: 01:27:12

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 46532 steps/s (collection: 1.971s, learning 0.142s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0491
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.4930
                       Mean reward: 3.05
               Mean episode length: 213.63
    Episode_Reward/reaching_object: 0.5669
    Episode_Reward/rotating_object: 0.0474
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 3.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.11s
                      Time elapsed: 00:01:37
                               ETA: 01:25:53

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 45263 steps/s (collection: 2.037s, learning 0.135s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0677
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.6295
                       Mean reward: 3.15
               Mean episode length: 212.55
    Episode_Reward/reaching_object: 0.5745
    Episode_Reward/rotating_object: 0.0357
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 2.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.17s
                      Time elapsed: 00:01:40
                               ETA: 01:24:42

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 45090 steps/s (collection: 2.039s, learning 0.141s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.1247
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.7919
                       Mean reward: 4.05
               Mean episode length: 212.86
    Episode_Reward/reaching_object: 0.5955
    Episode_Reward/rotating_object: 0.0952
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 2.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.18s
                      Time elapsed: 00:01:42
                               ETA: 01:23:36

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 35005 steps/s (collection: 2.694s, learning 0.115s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0611
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.9044
                       Mean reward: 3.32
               Mean episode length: 211.67
    Episode_Reward/reaching_object: 0.6099
    Episode_Reward/rotating_object: 0.0355
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 2.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.81s
                      Time elapsed: 00:01:45
                               ETA: 01:23:04

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 45584 steps/s (collection: 2.051s, learning 0.106s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1011
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.0899
                       Mean reward: 3.69
               Mean episode length: 210.82
    Episode_Reward/reaching_object: 0.6323
    Episode_Reward/rotating_object: 0.0465
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 2.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.16s
                      Time elapsed: 00:01:47
                               ETA: 01:22:04

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 46388 steps/s (collection: 2.011s, learning 0.109s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0924
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.2167
                       Mean reward: 4.55
               Mean episode length: 211.17
    Episode_Reward/reaching_object: 0.6916
    Episode_Reward/rotating_object: 0.1089
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 2.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.12s
                      Time elapsed: 00:01:49
                               ETA: 01:21:06

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 45839 steps/s (collection: 2.035s, learning 0.109s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1586
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.3210
                       Mean reward: 3.73
               Mean episode length: 216.36
    Episode_Reward/reaching_object: 0.7124
    Episode_Reward/rotating_object: 0.1201
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 3.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.14s
                      Time elapsed: 00:01:51
                               ETA: 01:20:12

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 43794 steps/s (collection: 2.128s, learning 0.117s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1033
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.4240
                       Mean reward: 4.22
               Mean episode length: 222.67
    Episode_Reward/reaching_object: 0.7702
    Episode_Reward/rotating_object: 0.1476
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 4.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.24s
                      Time elapsed: 00:01:53
                               ETA: 01:19:25

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 44084 steps/s (collection: 2.062s, learning 0.167s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.2685
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.5890
                       Mean reward: 5.29
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 0.7952
    Episode_Reward/rotating_object: 0.1561
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 6.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.23s
                      Time elapsed: 00:01:56
                               ETA: 01:18:41

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 40160 steps/s (collection: 2.318s, learning 0.130s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3909
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.6528
                       Mean reward: 4.70
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 0.8440
    Episode_Reward/rotating_object: 0.1181
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 8.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.45s
                      Time elapsed: 00:01:58
                               ETA: 01:18:07

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 45983 steps/s (collection: 2.022s, learning 0.116s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.4980
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.7559
                       Mean reward: 5.74
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 0.8795
    Episode_Reward/rotating_object: 0.1892
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 10.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.14s
                      Time elapsed: 00:02:00
                               ETA: 01:17:23

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 43927 steps/s (collection: 2.113s, learning 0.125s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.3890
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 46.9629
                       Mean reward: 5.91
               Mean episode length: 240.97
    Episode_Reward/reaching_object: 0.9146
    Episode_Reward/rotating_object: 0.4411
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 10.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.24s
                      Time elapsed: 00:02:02
                               ETA: 01:16:44

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 41648 steps/s (collection: 2.212s, learning 0.148s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.4615
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 47.0813
                       Mean reward: 5.61
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 0.9432
    Episode_Reward/rotating_object: 0.1980
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.36s
                      Time elapsed: 00:02:05
                               ETA: 01:16:12

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 45350 steps/s (collection: 2.047s, learning 0.121s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.5796
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 47.2193
                       Mean reward: 7.62
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 0.9083
    Episode_Reward/rotating_object: 0.3215
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.17s
                      Time elapsed: 00:02:07
                               ETA: 01:15:35

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 44956 steps/s (collection: 2.070s, learning 0.117s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.6970
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 47.4543
                       Mean reward: 7.35
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 0.9637
    Episode_Reward/rotating_object: 0.3865
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.19s
                      Time elapsed: 00:02:09
                               ETA: 01:15:00

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 40083 steps/s (collection: 2.324s, learning 0.129s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.3653
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 47.5263
                       Mean reward: 5.64
               Mean episode length: 244.37
    Episode_Reward/reaching_object: 0.9637
    Episode_Reward/rotating_object: 0.4941
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.45s
                      Time elapsed: 00:02:12
                               ETA: 01:14:35

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 41791 steps/s (collection: 2.233s, learning 0.120s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.2205
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.7255
                       Mean reward: 6.40
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 1.0068
    Episode_Reward/rotating_object: 0.2823
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.35s
                      Time elapsed: 00:02:14
                               ETA: 01:14:08

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 45028 steps/s (collection: 2.061s, learning 0.122s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.2546
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.8563
                       Mean reward: 6.77
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 0.9875
    Episode_Reward/rotating_object: 0.3393
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.18s
                      Time elapsed: 00:02:16
                               ETA: 01:13:37

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 44604 steps/s (collection: 2.096s, learning 0.108s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.3869
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.9597
                       Mean reward: 6.34
               Mean episode length: 246.54
    Episode_Reward/reaching_object: 1.0272
    Episode_Reward/rotating_object: 0.4741
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.20s
                      Time elapsed: 00:02:18
                               ETA: 01:13:08

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 45534 steps/s (collection: 2.041s, learning 0.118s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.5686
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.1001
                       Mean reward: 6.67
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 1.0007
    Episode_Reward/rotating_object: 0.3634
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.16s
                      Time elapsed: 00:02:20
                               ETA: 01:12:38

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 42677 steps/s (collection: 2.150s, learning 0.154s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.3186
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.2556
                       Mean reward: 6.09
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 0.9894
    Episode_Reward/rotating_object: 0.4590
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.30s
                      Time elapsed: 00:02:23
                               ETA: 01:12:14

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 40685 steps/s (collection: 2.299s, learning 0.118s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.4910
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.3888
                       Mean reward: 8.05
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.0298
    Episode_Reward/rotating_object: 0.3968
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.42s
                      Time elapsed: 00:02:25
                               ETA: 01:11:55

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 41375 steps/s (collection: 2.237s, learning 0.139s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.3545
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.5096
                       Mean reward: 8.42
               Mean episode length: 245.39
    Episode_Reward/reaching_object: 1.0544
    Episode_Reward/rotating_object: 0.5132
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.38s
                      Time elapsed: 00:02:27
                               ETA: 01:11:34

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 36151 steps/s (collection: 2.610s, learning 0.109s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.3822
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 48.6940
                       Mean reward: 5.54
               Mean episode length: 240.58
    Episode_Reward/reaching_object: 1.0154
    Episode_Reward/rotating_object: 0.4015
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.72s
                      Time elapsed: 00:02:30
                               ETA: 01:11:25

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 41203 steps/s (collection: 2.285s, learning 0.101s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.6774
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.8388
                       Mean reward: 8.87
               Mean episode length: 246.39
    Episode_Reward/reaching_object: 1.0769
    Episode_Reward/rotating_object: 0.3980
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.39s
                      Time elapsed: 00:02:33
                               ETA: 01:11:06

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 43712 steps/s (collection: 2.128s, learning 0.121s)
             Mean action noise std: 1.18
          Mean value_function loss: 0.7213
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.0095
                       Mean reward: 7.26
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 1.0425
    Episode_Reward/rotating_object: 0.4166
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.25s
                      Time elapsed: 00:02:35
                               ETA: 01:10:44

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 41689 steps/s (collection: 2.219s, learning 0.139s)
             Mean action noise std: 1.18
          Mean value_function loss: 0.7296
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.1090
                       Mean reward: 9.19
               Mean episode length: 244.87
    Episode_Reward/reaching_object: 1.0713
    Episode_Reward/rotating_object: 0.7567
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.36s
                      Time elapsed: 00:02:37
                               ETA: 01:10:26

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 44508 steps/s (collection: 2.094s, learning 0.115s)
             Mean action noise std: 1.19
          Mean value_function loss: 1.1160
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.2793
                       Mean reward: 7.61
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.0706
    Episode_Reward/rotating_object: 0.6066
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.21s
                      Time elapsed: 00:02:39
                               ETA: 01:10:04

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 45423 steps/s (collection: 2.052s, learning 0.112s)
             Mean action noise std: 1.19
          Mean value_function loss: 0.9873
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.3542
                       Mean reward: 10.93
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.1012
    Episode_Reward/rotating_object: 0.9496
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.16s
                      Time elapsed: 00:02:42
                               ETA: 01:09:42

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 44567 steps/s (collection: 2.083s, learning 0.123s)
             Mean action noise std: 1.20
          Mean value_function loss: 0.8866
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 49.5204
                       Mean reward: 9.03
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 1.1083
    Episode_Reward/rotating_object: 0.5622
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.21s
                      Time elapsed: 00:02:44
                               ETA: 01:09:21

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 44404 steps/s (collection: 2.101s, learning 0.113s)
             Mean action noise std: 1.20
          Mean value_function loss: 0.8148
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.6478
                       Mean reward: 8.80
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 1.0674
    Episode_Reward/rotating_object: 0.6842
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.21s
                      Time elapsed: 00:02:46
                               ETA: 01:09:02

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 39168 steps/s (collection: 2.374s, learning 0.136s)
             Mean action noise std: 1.21
          Mean value_function loss: 0.8994
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.8031
                       Mean reward: 6.37
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 1.0829
    Episode_Reward/rotating_object: 0.7087
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.51s
                      Time elapsed: 00:02:49
                               ETA: 01:08:50

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 44413 steps/s (collection: 2.074s, learning 0.139s)
             Mean action noise std: 1.21
          Mean value_function loss: 0.7401
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.8840
                       Mean reward: 10.87
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 1.1390
    Episode_Reward/rotating_object: 0.9350
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.21s
                      Time elapsed: 00:02:51
                               ETA: 01:08:32

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 42635 steps/s (collection: 2.182s, learning 0.124s)
             Mean action noise std: 1.22
          Mean value_function loss: 0.7837
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.0130
                       Mean reward: 10.18
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 1.1408
    Episode_Reward/rotating_object: 1.1541
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.31s
                      Time elapsed: 00:02:53
                               ETA: 01:08:16

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 44615 steps/s (collection: 2.104s, learning 0.100s)
             Mean action noise std: 1.22
          Mean value_function loss: 0.9488
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.1310
                       Mean reward: 8.94
               Mean episode length: 236.74
    Episode_Reward/reaching_object: 1.0848
    Episode_Reward/rotating_object: 0.6803
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.20s
                      Time elapsed: 00:02:55
                               ETA: 01:07:58

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 37753 steps/s (collection: 2.418s, learning 0.186s)
             Mean action noise std: 1.23
          Mean value_function loss: 0.8861
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.2407
                       Mean reward: 7.80
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 1.1124
    Episode_Reward/rotating_object: 0.9770
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.60s
                      Time elapsed: 00:02:58
                               ETA: 01:07:50

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 41782 steps/s (collection: 2.236s, learning 0.117s)
             Mean action noise std: 1.23
          Mean value_function loss: 0.9502
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 50.3429
                       Mean reward: 9.15
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 1.1624
    Episode_Reward/rotating_object: 0.8796
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.35s
                      Time elapsed: 00:03:00
                               ETA: 01:07:37

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 41679 steps/s (collection: 2.239s, learning 0.120s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.2152
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.4327
                       Mean reward: 9.94
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 0.8535
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.36s
                      Time elapsed: 00:03:03
                               ETA: 01:07:23

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 42572 steps/s (collection: 2.176s, learning 0.134s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.5612
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.5650
                       Mean reward: 14.38
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 1.1668
    Episode_Reward/rotating_object: 1.0847
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.31s
                      Time elapsed: 00:03:05
                               ETA: 01:07:10

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 43683 steps/s (collection: 2.133s, learning 0.118s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.2616
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.6580
                       Mean reward: 10.80
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 0.8984
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.25s
                      Time elapsed: 00:03:07
                               ETA: 01:06:55

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 43030 steps/s (collection: 2.172s, learning 0.113s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.5798
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.7859
                       Mean reward: 13.97
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 1.1594
    Episode_Reward/rotating_object: 1.0336
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.28s
                      Time elapsed: 00:03:09
                               ETA: 01:06:41

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 44120 steps/s (collection: 2.100s, learning 0.128s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.2015
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.9223
                       Mean reward: 9.23
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.1665
    Episode_Reward/rotating_object: 0.9485
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.23s
                      Time elapsed: 00:03:12
                               ETA: 01:06:27

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 43361 steps/s (collection: 2.128s, learning 0.140s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.7395
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.0508
                       Mean reward: 9.50
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 0.9577
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.27s
                      Time elapsed: 00:03:14
                               ETA: 01:06:13

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 42208 steps/s (collection: 2.198s, learning 0.131s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.7982
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.1532
                       Mean reward: 11.57
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 1.1855
    Episode_Reward/rotating_object: 1.2667
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.33s
                      Time elapsed: 00:03:16
                               ETA: 01:06:02

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 41477 steps/s (collection: 2.243s, learning 0.127s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.8260
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.2407
                       Mean reward: 11.46
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.1749
    Episode_Reward/rotating_object: 1.0518
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.37s
                      Time elapsed: 00:03:19
                               ETA: 01:05:51

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 42474 steps/s (collection: 2.188s, learning 0.127s)
             Mean action noise std: 1.27
          Mean value_function loss: 2.2963
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.3584
                       Mean reward: 14.00
               Mean episode length: 242.77
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 1.2034
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.31s
                      Time elapsed: 00:03:21
                               ETA: 01:05:39

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 42109 steps/s (collection: 2.217s, learning 0.118s)
             Mean action noise std: 1.28
          Mean value_function loss: 1.3131
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.4782
                       Mean reward: 15.58
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 2.0905
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.33s
                      Time elapsed: 00:03:23
                               ETA: 01:05:28

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 42920 steps/s (collection: 2.155s, learning 0.136s)
             Mean action noise std: 1.28
          Mean value_function loss: 1.3760
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.5907
                       Mean reward: 11.40
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.2315
    Episode_Reward/rotating_object: 1.2154
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.29s
                      Time elapsed: 00:03:26
                               ETA: 01:05:17

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 44279 steps/s (collection: 2.097s, learning 0.123s)
             Mean action noise std: 1.29
          Mean value_function loss: 1.5593
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.7228
                       Mean reward: 15.51
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 1.2637
    Episode_Reward/rotating_object: 1.6313
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.22s
                      Time elapsed: 00:03:28
                               ETA: 01:05:04

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 43210 steps/s (collection: 2.163s, learning 0.112s)
             Mean action noise std: 1.29
          Mean value_function loss: 1.3301
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.8488
                       Mean reward: 13.52
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.2048
    Episode_Reward/rotating_object: 1.2320
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.28s
                      Time elapsed: 00:03:30
                               ETA: 01:04:53

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 42984 steps/s (collection: 2.165s, learning 0.122s)
             Mean action noise std: 1.30
          Mean value_function loss: 1.4154
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.9357
                       Mean reward: 15.61
               Mean episode length: 244.79
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 1.4352
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.29s
                      Time elapsed: 00:03:32
                               ETA: 01:04:42

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 44863 steps/s (collection: 2.080s, learning 0.111s)
             Mean action noise std: 1.30
          Mean value_function loss: 1.8456
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.0529
                       Mean reward: 10.51
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.2348
    Episode_Reward/rotating_object: 1.2295
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.19s
                      Time elapsed: 00:03:34
                               ETA: 01:04:29

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 44482 steps/s (collection: 2.081s, learning 0.129s)
             Mean action noise std: 1.30
          Mean value_function loss: 1.6114
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.1297
                       Mean reward: 14.83
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2565
    Episode_Reward/rotating_object: 1.7434
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.21s
                      Time elapsed: 00:03:37
                               ETA: 01:04:18

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 40590 steps/s (collection: 2.295s, learning 0.127s)
             Mean action noise std: 1.31
          Mean value_function loss: 1.8438
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.2125
                       Mean reward: 11.94
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.2589
    Episode_Reward/rotating_object: 1.3274
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.42s
                      Time elapsed: 00:03:39
                               ETA: 01:04:10

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 44498 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 1.31
          Mean value_function loss: 1.7459
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 52.2744
                       Mean reward: 11.32
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 1.4407
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.21s
                      Time elapsed: 00:03:41
                               ETA: 01:03:58

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 44998 steps/s (collection: 2.071s, learning 0.114s)
             Mean action noise std: 1.31
          Mean value_function loss: 1.6372
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.3781
                       Mean reward: 13.62
               Mean episode length: 249.03
    Episode_Reward/reaching_object: 1.2973
    Episode_Reward/rotating_object: 1.6111
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.18s
                      Time elapsed: 00:03:44
                               ETA: 01:03:47

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 43403 steps/s (collection: 2.130s, learning 0.135s)
             Mean action noise std: 1.32
          Mean value_function loss: 1.6450
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.4604
                       Mean reward: 17.26
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 1.2263
    Episode_Reward/rotating_object: 1.4251
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.26s
                      Time elapsed: 00:03:46
                               ETA: 01:03:37

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 40809 steps/s (collection: 2.296s, learning 0.113s)
             Mean action noise std: 1.32
          Mean value_function loss: 2.3291
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.5558
                       Mean reward: 18.02
               Mean episode length: 244.68
    Episode_Reward/reaching_object: 1.2732
    Episode_Reward/rotating_object: 1.8423
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.41s
                      Time elapsed: 00:03:48
                               ETA: 01:03:29

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 44147 steps/s (collection: 2.119s, learning 0.108s)
             Mean action noise std: 1.33
          Mean value_function loss: 1.8955
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.6824
                       Mean reward: 10.06
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 1.2509
    Episode_Reward/rotating_object: 1.6419
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.23s
                      Time elapsed: 00:03:50
                               ETA: 01:03:19

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 45526 steps/s (collection: 2.041s, learning 0.118s)
             Mean action noise std: 1.33
          Mean value_function loss: 1.5556
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 52.8092
                       Mean reward: 16.22
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 1.2386
    Episode_Reward/rotating_object: 1.8973
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.16s
                      Time elapsed: 00:03:53
                               ETA: 01:03:08

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 45728 steps/s (collection: 2.052s, learning 0.098s)
             Mean action noise std: 1.34
          Mean value_function loss: 1.7589
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 52.8938
                       Mean reward: 15.18
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 1.2298
    Episode_Reward/rotating_object: 1.4317
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.15s
                      Time elapsed: 00:03:55
                               ETA: 01:02:57

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 45149 steps/s (collection: 2.062s, learning 0.116s)
             Mean action noise std: 1.34
          Mean value_function loss: 1.8827
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.9764
                       Mean reward: 13.49
               Mean episode length: 248.52
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 1.4830
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.18s
                      Time elapsed: 00:03:57
                               ETA: 01:02:46

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 44363 steps/s (collection: 2.099s, learning 0.117s)
             Mean action noise std: 1.34
          Mean value_function loss: 1.7621
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 53.0100
                       Mean reward: 17.90
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 1.8880
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.22s
                      Time elapsed: 00:03:59
                               ETA: 01:02:36

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 45077 steps/s (collection: 2.063s, learning 0.118s)
             Mean action noise std: 1.34
          Mean value_function loss: 2.1978
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.0822
                       Mean reward: 17.00
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 1.8575
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.18s
                      Time elapsed: 00:04:01
                               ETA: 01:02:26

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 44488 steps/s (collection: 2.081s, learning 0.129s)
             Mean action noise std: 1.35
          Mean value_function loss: 2.4107
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 53.2064
                       Mean reward: 16.76
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 1.7227
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.21s
                      Time elapsed: 00:04:04
                               ETA: 01:02:17

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 45798 steps/s (collection: 2.027s, learning 0.119s)
             Mean action noise std: 1.35
          Mean value_function loss: 2.5719
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.3113
                       Mean reward: 13.22
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 1.6829
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.15s
                      Time elapsed: 00:04:06
                               ETA: 01:02:06

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 44704 steps/s (collection: 2.072s, learning 0.127s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.3620
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.3806
                       Mean reward: 16.47
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 1.2172
    Episode_Reward/rotating_object: 1.8498
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.20s
                      Time elapsed: 00:04:08
                               ETA: 01:01:57

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 42633 steps/s (collection: 2.182s, learning 0.124s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.0677
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 53.4754
                       Mean reward: 17.60
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 1.1910
    Episode_Reward/rotating_object: 1.8838
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.31s
                      Time elapsed: 00:04:10
                               ETA: 01:01:49

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 43878 steps/s (collection: 2.100s, learning 0.141s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.4117
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.5671
                       Mean reward: 13.90
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 1.4953
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.24s
                      Time elapsed: 00:04:12
                               ETA: 01:01:41

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 44290 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 1.37
          Mean value_function loss: 2.6003
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.6675
                       Mean reward: 19.62
               Mean episode length: 247.14
    Episode_Reward/reaching_object: 1.1813
    Episode_Reward/rotating_object: 2.1429
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.22s
                      Time elapsed: 00:04:15
                               ETA: 01:01:32

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 43932 steps/s (collection: 2.123s, learning 0.115s)
             Mean action noise std: 1.37
          Mean value_function loss: 2.2203
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.7576
                       Mean reward: 12.52
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 1.1742
    Episode_Reward/rotating_object: 2.2001
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.24s
                      Time elapsed: 00:04:17
                               ETA: 01:01:24

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 44953 steps/s (collection: 2.063s, learning 0.124s)
             Mean action noise std: 1.38
          Mean value_function loss: 2.4836
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.8320
                       Mean reward: 15.66
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 1.1153
    Episode_Reward/rotating_object: 1.5539
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.19s
                      Time elapsed: 00:04:19
                               ETA: 01:01:15

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 44971 steps/s (collection: 2.075s, learning 0.111s)
             Mean action noise std: 1.38
          Mean value_function loss: 2.8658
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.9237
                       Mean reward: 17.35
               Mean episode length: 247.37
    Episode_Reward/reaching_object: 1.1574
    Episode_Reward/rotating_object: 2.1533
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.19s
                      Time elapsed: 00:04:21
                               ETA: 01:01:06

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 44322 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 1.39
          Mean value_function loss: 3.1897
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.0400
                       Mean reward: 15.51
               Mean episode length: 242.80
    Episode_Reward/reaching_object: 1.1432
    Episode_Reward/rotating_object: 1.8024
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.22s
                      Time elapsed: 00:04:23
                               ETA: 01:00:58

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 44480 steps/s (collection: 2.091s, learning 0.119s)
             Mean action noise std: 1.39
          Mean value_function loss: 2.6039
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.1641
                       Mean reward: 15.07
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 1.7895
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.21s
                      Time elapsed: 00:04:26
                               ETA: 01:00:50

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 45335 steps/s (collection: 2.040s, learning 0.129s)
             Mean action noise std: 1.40
          Mean value_function loss: 2.7443
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.2615
                       Mean reward: 16.12
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 1.1630
    Episode_Reward/rotating_object: 2.3901
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.17s
                      Time elapsed: 00:04:28
                               ETA: 01:00:42

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 44334 steps/s (collection: 2.102s, learning 0.116s)
             Mean action noise std: 1.40
          Mean value_function loss: 2.7733
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.3331
                       Mean reward: 16.32
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.1120
    Episode_Reward/rotating_object: 2.1518
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.22s
                      Time elapsed: 00:04:30
                               ETA: 01:00:34

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 45092 steps/s (collection: 2.049s, learning 0.131s)
             Mean action noise std: 1.40
          Mean value_function loss: 2.8748
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.4205
                       Mean reward: 18.34
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.1858
    Episode_Reward/rotating_object: 2.1340
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.18s
                      Time elapsed: 00:04:32
                               ETA: 01:00:26

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 45350 steps/s (collection: 2.050s, learning 0.118s)
             Mean action noise std: 1.41
          Mean value_function loss: 2.7399
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 54.5249
                       Mean reward: 12.42
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 1.1638
    Episode_Reward/rotating_object: 1.7069
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.17s
                      Time elapsed: 00:04:34
                               ETA: 01:00:17

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 45731 steps/s (collection: 2.041s, learning 0.109s)
             Mean action noise std: 1.41
          Mean value_function loss: 2.8675
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 54.6285
                       Mean reward: 16.01
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.1824
    Episode_Reward/rotating_object: 2.0996
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.15s
                      Time elapsed: 00:04:37
                               ETA: 01:00:09

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 44269 steps/s (collection: 2.090s, learning 0.131s)
             Mean action noise std: 1.42
          Mean value_function loss: 3.5037
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.7304
                       Mean reward: 19.37
               Mean episode length: 238.12
    Episode_Reward/reaching_object: 1.1376
    Episode_Reward/rotating_object: 1.9732
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.22s
                      Time elapsed: 00:04:39
                               ETA: 01:00:02

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 42943 steps/s (collection: 2.155s, learning 0.134s)
             Mean action noise std: 1.42
          Mean value_function loss: 3.6895
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.8384
                       Mean reward: 13.22
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 1.1684
    Episode_Reward/rotating_object: 1.9933
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.29s
                      Time elapsed: 00:04:41
                               ETA: 00:59:55

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 45560 steps/s (collection: 2.016s, learning 0.142s)
             Mean action noise std: 1.43
          Mean value_function loss: 4.4676
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 54.9417
                       Mean reward: 19.73
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 1.1710
    Episode_Reward/rotating_object: 2.3216
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.16s
                      Time elapsed: 00:04:43
                               ETA: 00:59:47

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 45696 steps/s (collection: 2.033s, learning 0.118s)
             Mean action noise std: 1.43
          Mean value_function loss: 3.7803
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.0351
                       Mean reward: 12.50
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 1.1312
    Episode_Reward/rotating_object: 1.9889
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.15s
                      Time elapsed: 00:04:45
                               ETA: 00:59:39

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 46607 steps/s (collection: 1.993s, learning 0.117s)
             Mean action noise std: 1.43
          Mean value_function loss: 3.6940
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 55.1215
                       Mean reward: 21.29
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 1.1429
    Episode_Reward/rotating_object: 2.2742
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.11s
                      Time elapsed: 00:04:47
                               ETA: 00:59:31

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 45476 steps/s (collection: 2.040s, learning 0.122s)
             Mean action noise std: 1.44
          Mean value_function loss: 3.2522
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.2087
                       Mean reward: 18.31
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.1474
    Episode_Reward/rotating_object: 2.2735
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.16s
                      Time elapsed: 00:04:50
                               ETA: 00:59:23

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 44870 steps/s (collection: 2.071s, learning 0.120s)
             Mean action noise std: 1.44
          Mean value_function loss: 3.1864
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.2794
                       Mean reward: 16.11
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 1.1322
    Episode_Reward/rotating_object: 2.7153
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.19s
                      Time elapsed: 00:04:52
                               ETA: 00:59:16

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 43755 steps/s (collection: 2.097s, learning 0.149s)
             Mean action noise std: 1.44
          Mean value_function loss: 3.4870
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.3374
                       Mean reward: 19.97
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 1.1537
    Episode_Reward/rotating_object: 3.0388
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.25s
                      Time elapsed: 00:04:54
                               ETA: 00:59:10

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 43703 steps/s (collection: 2.122s, learning 0.127s)
             Mean action noise std: 1.45
          Mean value_function loss: 4.1255
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.4260
                       Mean reward: 14.94
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.1768
    Episode_Reward/rotating_object: 2.3047
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.25s
                      Time elapsed: 00:04:56
                               ETA: 00:59:04

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 45048 steps/s (collection: 2.070s, learning 0.113s)
             Mean action noise std: 1.45
          Mean value_function loss: 3.3211
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.4952
                       Mean reward: 19.06
               Mean episode length: 246.92
    Episode_Reward/reaching_object: 1.1310
    Episode_Reward/rotating_object: 2.4461
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.18s
                      Time elapsed: 00:04:59
                               ETA: 00:58:56

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 41035 steps/s (collection: 2.284s, learning 0.112s)
             Mean action noise std: 1.45
          Mean value_function loss: 3.8181
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 55.5441
                       Mean reward: 15.01
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 1.1191
    Episode_Reward/rotating_object: 2.0651
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.40s
                      Time elapsed: 00:05:01
                               ETA: 00:58:52

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 45067 steps/s (collection: 2.058s, learning 0.123s)
             Mean action noise std: 1.45
          Mean value_function loss: 3.6478
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.5633
                       Mean reward: 16.08
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 1.1714
    Episode_Reward/rotating_object: 2.5995
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.18s
                      Time elapsed: 00:05:03
                               ETA: 00:58:45

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 45789 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 3.9800
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.6131
                       Mean reward: 13.71
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.1401
    Episode_Reward/rotating_object: 2.0196
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.15s
                      Time elapsed: 00:05:05
                               ETA: 00:58:38

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 46412 steps/s (collection: 2.002s, learning 0.117s)
             Mean action noise std: 1.46
          Mean value_function loss: 4.0991
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.7130
                       Mean reward: 18.48
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 1.1599
    Episode_Reward/rotating_object: 2.0003
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.12s
                      Time elapsed: 00:05:07
                               ETA: 00:58:31

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 46432 steps/s (collection: 1.987s, learning 0.131s)
             Mean action noise std: 1.47
          Mean value_function loss: 4.0026
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.8148
                       Mean reward: 22.22
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.1164
    Episode_Reward/rotating_object: 2.8796
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.12s
                      Time elapsed: 00:05:09
                               ETA: 00:58:23

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 43851 steps/s (collection: 2.109s, learning 0.133s)
             Mean action noise std: 1.47
          Mean value_function loss: 4.4522
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 55.8837
                       Mean reward: 19.21
               Mean episode length: 246.39
    Episode_Reward/reaching_object: 1.1480
    Episode_Reward/rotating_object: 2.5935
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.24s
                      Time elapsed: 00:05:12
                               ETA: 00:58:17

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 45099 steps/s (collection: 2.044s, learning 0.135s)
             Mean action noise std: 1.47
          Mean value_function loss: 5.4032
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 55.9689
                       Mean reward: 18.67
               Mean episode length: 241.01
    Episode_Reward/reaching_object: 1.1415
    Episode_Reward/rotating_object: 2.6033
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.18s
                      Time elapsed: 00:05:14
                               ETA: 00:58:11

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 45483 steps/s (collection: 2.049s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 4.4379
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 56.0516
                       Mean reward: 16.28
               Mean episode length: 245.19
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 2.6177
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.16s
                      Time elapsed: 00:05:16
                               ETA: 00:58:04

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 45082 steps/s (collection: 2.046s, learning 0.135s)
             Mean action noise std: 1.48
          Mean value_function loss: 4.9272
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 56.1313
                       Mean reward: 13.78
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 1.1458
    Episode_Reward/rotating_object: 2.3767
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.18s
                      Time elapsed: 00:05:18
                               ETA: 00:57:58

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 45448 steps/s (collection: 2.042s, learning 0.121s)
             Mean action noise std: 1.48
          Mean value_function loss: 3.8776
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.1864
                       Mean reward: 20.99
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 1.1451
    Episode_Reward/rotating_object: 2.9275
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.16s
                      Time elapsed: 00:05:20
                               ETA: 00:57:51

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 44694 steps/s (collection: 2.087s, learning 0.112s)
             Mean action noise std: 1.49
          Mean value_function loss: 4.4185
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.2401
                       Mean reward: 20.27
               Mean episode length: 242.83
    Episode_Reward/reaching_object: 1.1725
    Episode_Reward/rotating_object: 2.5059
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.20s
                      Time elapsed: 00:05:23
                               ETA: 00:57:45

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 45903 steps/s (collection: 2.019s, learning 0.123s)
             Mean action noise std: 1.49
          Mean value_function loss: 4.2689
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.3014
                       Mean reward: 16.35
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.1470
    Episode_Reward/rotating_object: 2.3041
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.14s
                      Time elapsed: 00:05:25
                               ETA: 00:57:39

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 45771 steps/s (collection: 2.028s, learning 0.120s)
             Mean action noise std: 1.49
          Mean value_function loss: 4.4607
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.3691
                       Mean reward: 13.47
               Mean episode length: 244.77
    Episode_Reward/reaching_object: 1.1472
    Episode_Reward/rotating_object: 2.4802
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.15s
                      Time elapsed: 00:05:27
                               ETA: 00:57:32

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 45985 steps/s (collection: 2.035s, learning 0.103s)
             Mean action noise std: 1.50
          Mean value_function loss: 5.2571
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 56.4307
                       Mean reward: 23.08
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.1282
    Episode_Reward/rotating_object: 3.4685
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.14s
                      Time elapsed: 00:05:29
                               ETA: 00:57:26

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 43217 steps/s (collection: 2.166s, learning 0.109s)
             Mean action noise std: 1.50
          Mean value_function loss: 4.5826
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 56.4974
                       Mean reward: 15.03
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 1.1380
    Episode_Reward/rotating_object: 2.8451
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.27s
                      Time elapsed: 00:05:31
                               ETA: 00:57:21

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 46681 steps/s (collection: 1.994s, learning 0.112s)
             Mean action noise std: 1.50
          Mean value_function loss: 3.9231
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 56.5603
                       Mean reward: 15.52
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.1310
    Episode_Reward/rotating_object: 2.3356
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.11s
                      Time elapsed: 00:05:33
                               ETA: 00:57:14

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 45190 steps/s (collection: 2.053s, learning 0.122s)
             Mean action noise std: 1.51
          Mean value_function loss: 4.0157
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 56.6444
                       Mean reward: 25.45
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 1.1523
    Episode_Reward/rotating_object: 2.9531
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.18s
                      Time elapsed: 00:05:36
                               ETA: 00:57:08

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 43951 steps/s (collection: 2.097s, learning 0.140s)
             Mean action noise std: 1.51
          Mean value_function loss: 4.5500
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.7339
                       Mean reward: 18.47
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.1266
    Episode_Reward/rotating_object: 2.4438
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.24s
                      Time elapsed: 00:05:38
                               ETA: 00:57:03

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 43501 steps/s (collection: 2.119s, learning 0.141s)
             Mean action noise std: 1.51
          Mean value_function loss: 4.8106
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.8072
                       Mean reward: 17.21
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.1605
    Episode_Reward/rotating_object: 2.4698
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.26s
                      Time elapsed: 00:05:40
                               ETA: 00:56:58

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 43791 steps/s (collection: 2.119s, learning 0.126s)
             Mean action noise std: 1.52
          Mean value_function loss: 4.3066
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.8695
                       Mean reward: 16.08
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.1538
    Episode_Reward/rotating_object: 2.6648
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.24s
                      Time elapsed: 00:05:42
                               ETA: 00:56:53

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 45388 steps/s (collection: 2.048s, learning 0.118s)
             Mean action noise std: 1.52
          Mean value_function loss: 3.7621
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.9099
                       Mean reward: 14.57
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.1210
    Episode_Reward/rotating_object: 2.3423
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.17s
                      Time elapsed: 00:05:44
                               ETA: 00:56:47

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 45080 steps/s (collection: 2.059s, learning 0.122s)
             Mean action noise std: 1.52
          Mean value_function loss: 5.0541
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 56.9902
                       Mean reward: 17.98
               Mean episode length: 236.16
    Episode_Reward/reaching_object: 1.1468
    Episode_Reward/rotating_object: 3.0525
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.18s
                      Time elapsed: 00:05:47
                               ETA: 00:56:41

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 45517 steps/s (collection: 2.036s, learning 0.124s)
             Mean action noise std: 1.53
          Mean value_function loss: 5.5339
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.0688
                       Mean reward: 16.42
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.1377
    Episode_Reward/rotating_object: 1.9951
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.16s
                      Time elapsed: 00:05:49
                               ETA: 00:56:35

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 44893 steps/s (collection: 2.060s, learning 0.130s)
             Mean action noise std: 1.53
          Mean value_function loss: 5.9740
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.1263
                       Mean reward: 17.83
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 1.1536
    Episode_Reward/rotating_object: 2.4148
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.19s
                      Time elapsed: 00:05:51
                               ETA: 00:56:30

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 44599 steps/s (collection: 2.095s, learning 0.109s)
             Mean action noise std: 1.53
          Mean value_function loss: 5.0759
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.1767
                       Mean reward: 15.40
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 1.1508
    Episode_Reward/rotating_object: 2.5949
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.20s
                      Time elapsed: 00:05:53
                               ETA: 00:56:25

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 40541 steps/s (collection: 2.310s, learning 0.115s)
             Mean action noise std: 1.54
          Mean value_function loss: 4.9378
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 57.2474
                       Mean reward: 16.97
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 2.2216
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.42s
                      Time elapsed: 00:05:56
                               ETA: 00:56:22

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 44723 steps/s (collection: 2.072s, learning 0.127s)
             Mean action noise std: 1.54
          Mean value_function loss: 5.1789
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.3324
                       Mean reward: 18.78
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.1689
    Episode_Reward/rotating_object: 2.9574
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.20s
                      Time elapsed: 00:05:58
                               ETA: 00:56:16

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 44581 steps/s (collection: 2.092s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 5.1539
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.4073
                       Mean reward: 16.70
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.1366
    Episode_Reward/rotating_object: 2.5326
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.21s
                      Time elapsed: 00:06:00
                               ETA: 00:56:11

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 42818 steps/s (collection: 2.152s, learning 0.144s)
             Mean action noise std: 1.55
          Mean value_function loss: 5.6997
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.4928
                       Mean reward: 19.78
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 1.1465
    Episode_Reward/rotating_object: 3.0072
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.30s
                      Time elapsed: 00:06:02
                               ETA: 00:56:07

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 44356 steps/s (collection: 2.066s, learning 0.150s)
             Mean action noise std: 1.55
          Mean value_function loss: 4.8661
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.5456
                       Mean reward: 22.29
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 1.1142
    Episode_Reward/rotating_object: 3.1147
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.22s
                      Time elapsed: 00:06:05
                               ETA: 00:56:02

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 44769 steps/s (collection: 2.081s, learning 0.115s)
             Mean action noise std: 1.55
          Mean value_function loss: 5.7333
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.6066
                       Mean reward: 21.54
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 1.1449
    Episode_Reward/rotating_object: 3.6801
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.20s
                      Time elapsed: 00:06:07
                               ETA: 00:55:57

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 46082 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 1.56
          Mean value_function loss: 4.7104
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.6653
                       Mean reward: 14.63
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 1.1318
    Episode_Reward/rotating_object: 2.7332
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.13s
                      Time elapsed: 00:06:09
                               ETA: 00:55:51

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 44636 steps/s (collection: 2.077s, learning 0.125s)
             Mean action noise std: 1.56
          Mean value_function loss: 5.4589
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.7567
                       Mean reward: 16.09
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 1.1241
    Episode_Reward/rotating_object: 2.3823
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.20s
                      Time elapsed: 00:06:11
                               ETA: 00:55:46

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 45078 steps/s (collection: 2.065s, learning 0.116s)
             Mean action noise std: 1.56
          Mean value_function loss: 5.8523
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.8142
                       Mean reward: 18.35
               Mean episode length: 244.86
    Episode_Reward/reaching_object: 1.1507
    Episode_Reward/rotating_object: 3.1419
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.18s
                      Time elapsed: 00:06:13
                               ETA: 00:55:41

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 43706 steps/s (collection: 2.130s, learning 0.119s)
             Mean action noise std: 1.57
          Mean value_function loss: 6.3513
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.8499
                       Mean reward: 13.42
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.1110
    Episode_Reward/rotating_object: 2.8880
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.25s
                      Time elapsed: 00:06:16
                               ETA: 00:55:37

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 44484 steps/s (collection: 2.100s, learning 0.110s)
             Mean action noise std: 1.57
          Mean value_function loss: 6.0744
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.8983
                       Mean reward: 14.46
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.1247
    Episode_Reward/rotating_object: 2.6971
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.21s
                      Time elapsed: 00:06:18
                               ETA: 00:55:32

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 44936 steps/s (collection: 2.061s, learning 0.127s)
             Mean action noise std: 1.57
          Mean value_function loss: 6.6154
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.9437
                       Mean reward: 18.95
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.1090
    Episode_Reward/rotating_object: 2.6808
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.19s
                      Time elapsed: 00:06:20
                               ETA: 00:55:27

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 42475 steps/s (collection: 2.195s, learning 0.119s)
             Mean action noise std: 1.57
          Mean value_function loss: 6.8946
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.0076
                       Mean reward: 18.90
               Mean episode length: 242.29
    Episode_Reward/reaching_object: 1.1444
    Episode_Reward/rotating_object: 2.9367
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.31s
                      Time elapsed: 00:06:22
                               ETA: 00:55:23

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 45255 steps/s (collection: 2.062s, learning 0.110s)
             Mean action noise std: 1.58
          Mean value_function loss: 6.1268
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.0561
                       Mean reward: 20.82
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.1571
    Episode_Reward/rotating_object: 3.0114
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.17s
                      Time elapsed: 00:06:24
                               ETA: 00:55:18

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 44102 steps/s (collection: 2.092s, learning 0.137s)
             Mean action noise std: 1.58
          Mean value_function loss: 6.9642
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.1082
                       Mean reward: 24.64
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.1368
    Episode_Reward/rotating_object: 3.2375
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.23s
                      Time elapsed: 00:06:27
                               ETA: 00:55:14

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 44027 steps/s (collection: 2.105s, learning 0.128s)
             Mean action noise std: 1.58
          Mean value_function loss: 5.9094
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.1438
                       Mean reward: 23.06
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 1.1341
    Episode_Reward/rotating_object: 3.6756
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.23s
                      Time elapsed: 00:06:29
                               ETA: 00:55:09

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 45572 steps/s (collection: 2.047s, learning 0.110s)
             Mean action noise std: 1.58
          Mean value_function loss: 6.0640
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 58.1913
                       Mean reward: 35.24
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.1211
    Episode_Reward/rotating_object: 3.5611
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.16s
                      Time elapsed: 00:06:31
                               ETA: 00:55:04

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 38872 steps/s (collection: 2.415s, learning 0.114s)
             Mean action noise std: 1.59
          Mean value_function loss: 5.6243
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 58.2498
                       Mean reward: 24.36
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 1.1099
    Episode_Reward/rotating_object: 3.2289
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.53s
                      Time elapsed: 00:06:34
                               ETA: 00:55:02

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 45929 steps/s (collection: 2.029s, learning 0.112s)
             Mean action noise std: 1.59
          Mean value_function loss: 5.1551
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.2944
                       Mean reward: 20.56
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.0933
    Episode_Reward/rotating_object: 2.8846
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.14s
                      Time elapsed: 00:06:36
                               ETA: 00:54:57

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 45512 steps/s (collection: 2.045s, learning 0.115s)
             Mean action noise std: 1.59
          Mean value_function loss: 6.6561
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.3530
                       Mean reward: 18.96
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.1088
    Episode_Reward/rotating_object: 3.1116
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.16s
                      Time elapsed: 00:06:38
                               ETA: 00:54:52

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 45320 steps/s (collection: 2.055s, learning 0.114s)
             Mean action noise std: 1.59
          Mean value_function loss: 6.1106
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.4010
                       Mean reward: 15.55
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.0980
    Episode_Reward/rotating_object: 3.3355
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.17s
                      Time elapsed: 00:06:40
                               ETA: 00:54:47

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 43964 steps/s (collection: 2.101s, learning 0.135s)
             Mean action noise std: 1.60
          Mean value_function loss: 6.3861
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.4401
                       Mean reward: 19.85
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.0887
    Episode_Reward/rotating_object: 3.0967
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.24s
                      Time elapsed: 00:06:42
                               ETA: 00:54:43

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 45676 steps/s (collection: 2.031s, learning 0.122s)
             Mean action noise std: 1.60
          Mean value_function loss: 5.8811
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.4945
                       Mean reward: 14.74
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 1.0854
    Episode_Reward/rotating_object: 3.0942
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.15s
                      Time elapsed: 00:06:44
                               ETA: 00:54:38

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 44809 steps/s (collection: 2.066s, learning 0.128s)
             Mean action noise std: 1.60
          Mean value_function loss: 7.1535
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.5412
                       Mean reward: 17.81
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.0933
    Episode_Reward/rotating_object: 2.8565
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.19s
                      Time elapsed: 00:06:47
                               ETA: 00:54:33

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 46026 steps/s (collection: 2.031s, learning 0.105s)
             Mean action noise std: 1.60
          Mean value_function loss: 6.4833
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.5872
                       Mean reward: 22.76
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.0674
    Episode_Reward/rotating_object: 3.5677
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.14s
                      Time elapsed: 00:06:49
                               ETA: 00:54:28

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 45370 steps/s (collection: 2.041s, learning 0.126s)
             Mean action noise std: 1.61
          Mean value_function loss: 6.3854
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.6397
                       Mean reward: 22.36
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 1.0912
    Episode_Reward/rotating_object: 3.5359
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.17s
                      Time elapsed: 00:06:51
                               ETA: 00:54:24

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 44226 steps/s (collection: 2.114s, learning 0.109s)
             Mean action noise std: 1.61
          Mean value_function loss: 6.1938
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 58.6969
                       Mean reward: 16.80
               Mean episode length: 247.37
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 2.6765
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.22s
                      Time elapsed: 00:06:53
                               ETA: 00:54:20

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 44238 steps/s (collection: 2.110s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 8.1817
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.7833
                       Mean reward: 19.42
               Mean episode length: 236.25
    Episode_Reward/reaching_object: 1.0440
    Episode_Reward/rotating_object: 2.5431
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.22s
                      Time elapsed: 00:06:55
                               ETA: 00:54:15

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 44240 steps/s (collection: 2.094s, learning 0.128s)
             Mean action noise std: 1.62
          Mean value_function loss: 7.8493
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.8473
                       Mean reward: 25.84
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 3.5178
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.22s
                      Time elapsed: 00:06:58
                               ETA: 00:54:11

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 44445 steps/s (collection: 2.097s, learning 0.115s)
             Mean action noise std: 1.62
          Mean value_function loss: 9.0722
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.8933
                       Mean reward: 19.22
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 1.0558
    Episode_Reward/rotating_object: 3.2124
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.21s
                      Time elapsed: 00:07:00
                               ETA: 00:54:07

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 45335 steps/s (collection: 2.061s, learning 0.107s)
             Mean action noise std: 1.62
          Mean value_function loss: 7.8943
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 58.9391
                       Mean reward: 17.84
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.0385
    Episode_Reward/rotating_object: 3.5095
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.17s
                      Time elapsed: 00:07:02
                               ETA: 00:54:02

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 44865 steps/s (collection: 2.085s, learning 0.106s)
             Mean action noise std: 1.63
          Mean value_function loss: 9.2184
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 58.9873
                       Mean reward: 26.16
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 4.4374
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.19s
                      Time elapsed: 00:07:04
                               ETA: 00:53:58

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 43909 steps/s (collection: 2.096s, learning 0.143s)
             Mean action noise std: 1.63
          Mean value_function loss: 8.9899
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.0445
                       Mean reward: 25.09
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.0463
    Episode_Reward/rotating_object: 3.6443
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.24s
                      Time elapsed: 00:07:06
                               ETA: 00:53:54

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 45223 steps/s (collection: 2.057s, learning 0.117s)
             Mean action noise std: 1.63
          Mean value_function loss: 9.6665
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 59.0929
                       Mean reward: 19.56
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.0359
    Episode_Reward/rotating_object: 3.3353
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.17s
                      Time elapsed: 00:07:09
                               ETA: 00:53:50

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 45302 steps/s (collection: 2.042s, learning 0.128s)
             Mean action noise std: 1.63
          Mean value_function loss: 9.0944
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 59.1531
                       Mean reward: 31.93
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 1.0628
    Episode_Reward/rotating_object: 4.1932
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.17s
                      Time elapsed: 00:07:11
                               ETA: 00:53:45

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 44677 steps/s (collection: 2.069s, learning 0.131s)
             Mean action noise std: 1.64
          Mean value_function loss: 9.3352
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.2003
                       Mean reward: 21.67
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 1.0086
    Episode_Reward/rotating_object: 4.1964
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.20s
                      Time elapsed: 00:07:13
                               ETA: 00:53:41

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 43039 steps/s (collection: 2.162s, learning 0.122s)
             Mean action noise std: 1.64
          Mean value_function loss: 9.5957
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 59.2524
                       Mean reward: 18.36
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.0446
    Episode_Reward/rotating_object: 3.8548
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.28s
                      Time elapsed: 00:07:15
                               ETA: 00:53:37

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 44717 steps/s (collection: 2.068s, learning 0.131s)
             Mean action noise std: 1.64
          Mean value_function loss: 9.5705
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 59.3261
                       Mean reward: 15.48
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.0083
    Episode_Reward/rotating_object: 3.4265
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.20s
                      Time elapsed: 00:07:17
                               ETA: 00:53:33

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 45152 steps/s (collection: 2.041s, learning 0.136s)
             Mean action noise std: 1.65
          Mean value_function loss: 9.3825
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 59.3959
                       Mean reward: 17.27
               Mean episode length: 231.91
    Episode_Reward/reaching_object: 1.0085
    Episode_Reward/rotating_object: 3.1722
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.18s
                      Time elapsed: 00:07:20
                               ETA: 00:53:29

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 45685 steps/s (collection: 2.035s, learning 0.117s)
             Mean action noise std: 1.65
          Mean value_function loss: 9.9137
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.4526
                       Mean reward: 30.42
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 1.0648
    Episode_Reward/rotating_object: 4.5302
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.15s
                      Time elapsed: 00:07:22
                               ETA: 00:53:24

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 40818 steps/s (collection: 2.225s, learning 0.184s)
             Mean action noise std: 1.65
          Mean value_function loss: 9.3809
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.4822
                       Mean reward: 33.57
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.0236
    Episode_Reward/rotating_object: 4.4358
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.41s
                      Time elapsed: 00:07:24
                               ETA: 00:53:22

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 41845 steps/s (collection: 2.219s, learning 0.131s)
             Mean action noise std: 1.65
          Mean value_function loss: 8.2215
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.5096
                       Mean reward: 47.79
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 4.9742
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.35s
                      Time elapsed: 00:07:26
                               ETA: 00:53:19

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 44439 steps/s (collection: 2.066s, learning 0.147s)
             Mean action noise std: 1.66
          Mean value_function loss: 10.5098
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.5631
                       Mean reward: 18.43
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 0.9969
    Episode_Reward/rotating_object: 3.4397
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.21s
                      Time elapsed: 00:07:29
                               ETA: 00:53:15

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 40836 steps/s (collection: 2.204s, learning 0.203s)
             Mean action noise std: 1.66
          Mean value_function loss: 8.8867
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 59.6043
                       Mean reward: 26.06
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.0111
    Episode_Reward/rotating_object: 4.0834
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.41s
                      Time elapsed: 00:07:31
                               ETA: 00:53:12

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 42145 steps/s (collection: 2.207s, learning 0.125s)
             Mean action noise std: 1.66
          Mean value_function loss: 9.6238
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 59.6635
                       Mean reward: 20.99
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 1.0184
    Episode_Reward/rotating_object: 3.8774
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.33s
                      Time elapsed: 00:07:33
                               ETA: 00:53:09

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 43434 steps/s (collection: 2.138s, learning 0.126s)
             Mean action noise std: 1.66
          Mean value_function loss: 10.2124
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 59.7069
                       Mean reward: 31.69
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 4.6132
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.26s
                      Time elapsed: 00:07:36
                               ETA: 00:53:06

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 44020 steps/s (collection: 2.110s, learning 0.123s)
             Mean action noise std: 1.67
          Mean value_function loss: 10.0225
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 59.7626
                       Mean reward: 15.28
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 0.9873
    Episode_Reward/rotating_object: 2.8458
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.23s
                      Time elapsed: 00:07:38
                               ETA: 00:53:02

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 46224 steps/s (collection: 2.004s, learning 0.123s)
             Mean action noise std: 1.67
          Mean value_function loss: 10.9745
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 59.8240
                       Mean reward: 17.85
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 0.9926
    Episode_Reward/rotating_object: 3.9073
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.13s
                      Time elapsed: 00:07:40
                               ETA: 00:52:57

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 45838 steps/s (collection: 2.035s, learning 0.110s)
             Mean action noise std: 1.67
          Mean value_function loss: 11.1163
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.8793
                       Mean reward: 23.98
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 1.0269
    Episode_Reward/rotating_object: 4.4893
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.14s
                      Time elapsed: 00:07:42
                               ETA: 00:52:53

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 45399 steps/s (collection: 2.049s, learning 0.116s)
             Mean action noise std: 1.68
          Mean value_function loss: 10.0868
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 59.9195
                       Mean reward: 27.60
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.0215
    Episode_Reward/rotating_object: 4.5131
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.17s
                      Time elapsed: 00:07:44
                               ETA: 00:52:49

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 45638 steps/s (collection: 2.036s, learning 0.118s)
             Mean action noise std: 1.68
          Mean value_function loss: 10.4346
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.9781
                       Mean reward: 29.46
               Mean episode length: 240.66
    Episode_Reward/reaching_object: 1.0151
    Episode_Reward/rotating_object: 4.8407
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.15s
                      Time elapsed: 00:07:47
                               ETA: 00:52:45

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 46245 steps/s (collection: 2.012s, learning 0.113s)
             Mean action noise std: 1.68
          Mean value_function loss: 10.8377
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 60.0213
                       Mean reward: 31.25
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 0.9954
    Episode_Reward/rotating_object: 4.7986
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.13s
                      Time elapsed: 00:07:49
                               ETA: 00:52:40

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 44581 steps/s (collection: 2.077s, learning 0.128s)
             Mean action noise std: 1.68
          Mean value_function loss: 10.9950
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 60.0838
                       Mean reward: 26.26
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.0131
    Episode_Reward/rotating_object: 4.3771
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.21s
                      Time elapsed: 00:07:51
                               ETA: 00:52:36

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 41827 steps/s (collection: 2.230s, learning 0.120s)
             Mean action noise std: 1.69
          Mean value_function loss: 9.8543
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 60.1315
                       Mean reward: 27.97
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 0.9843
    Episode_Reward/rotating_object: 4.5431
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.35s
                      Time elapsed: 00:07:53
                               ETA: 00:52:34

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 44461 steps/s (collection: 2.107s, learning 0.104s)
             Mean action noise std: 1.69
          Mean value_function loss: 10.7362
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 60.1825
                       Mean reward: 24.45
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 0.9985
    Episode_Reward/rotating_object: 5.2920
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.21s
                      Time elapsed: 00:07:55
                               ETA: 00:52:30

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 41525 steps/s (collection: 2.247s, learning 0.121s)
             Mean action noise std: 1.69
          Mean value_function loss: 10.4481
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 60.2435
                       Mean reward: 30.50
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 0.9961
    Episode_Reward/rotating_object: 4.5277
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.37s
                      Time elapsed: 00:07:58
                               ETA: 00:52:27

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 44456 steps/s (collection: 2.080s, learning 0.132s)
             Mean action noise std: 1.70
          Mean value_function loss: 11.7138
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 60.2946
                       Mean reward: 30.88
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 0.9895
    Episode_Reward/rotating_object: 5.1572
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.21s
                      Time elapsed: 00:08:00
                               ETA: 00:52:23

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 45591 steps/s (collection: 2.039s, learning 0.118s)
             Mean action noise std: 1.70
          Mean value_function loss: 11.3352
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 60.3447
                       Mean reward: 22.90
               Mean episode length: 234.36
    Episode_Reward/reaching_object: 0.9880
    Episode_Reward/rotating_object: 3.8112
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.16s
                      Time elapsed: 00:08:02
                               ETA: 00:52:19

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 43293 steps/s (collection: 2.144s, learning 0.127s)
             Mean action noise std: 1.70
          Mean value_function loss: 10.5513
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 60.4021
                       Mean reward: 24.35
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 0.9584
    Episode_Reward/rotating_object: 4.1643
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.27s
                      Time elapsed: 00:08:04
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 43894 steps/s (collection: 2.102s, learning 0.138s)
             Mean action noise std: 1.70
          Mean value_function loss: 12.7886
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 60.4692
                       Mean reward: 33.10
               Mean episode length: 237.80
    Episode_Reward/reaching_object: 1.0099
    Episode_Reward/rotating_object: 5.9535
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.24s
                      Time elapsed: 00:08:07
                               ETA: 00:52:12

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 26518 steps/s (collection: 3.386s, learning 0.321s)
             Mean action noise std: 1.71
          Mean value_function loss: 12.4340
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 60.5175
                       Mean reward: 20.50
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.0233
    Episode_Reward/rotating_object: 5.1128
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 3.71s
                      Time elapsed: 00:08:10
                               ETA: 00:52:18

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 21215 steps/s (collection: 4.354s, learning 0.280s)
             Mean action noise std: 1.71
          Mean value_function loss: 12.2469
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 60.5556
                       Mean reward: 22.04
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 0.9491
    Episode_Reward/rotating_object: 3.7407
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 4.63s
                      Time elapsed: 00:08:15
                               ETA: 00:52:30

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 24405 steps/s (collection: 3.753s, learning 0.275s)
             Mean action noise std: 1.71
          Mean value_function loss: 12.0372
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 60.5954
                       Mean reward: 32.53
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 0.9812
    Episode_Reward/rotating_object: 5.4735
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 4.03s
                      Time elapsed: 00:08:19
                               ETA: 00:52:38

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 24258 steps/s (collection: 3.775s, learning 0.277s)
             Mean action noise std: 1.71
          Mean value_function loss: 10.5556
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 60.6327
                       Mean reward: 31.33
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.0012
    Episode_Reward/rotating_object: 4.9160
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 4.05s
                      Time elapsed: 00:08:23
                               ETA: 00:52:45

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 24018 steps/s (collection: 3.826s, learning 0.267s)
             Mean action noise std: 1.72
          Mean value_function loss: 10.8282
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 60.6829
                       Mean reward: 24.09
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 0.9843
    Episode_Reward/rotating_object: 3.9774
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 4.09s
                      Time elapsed: 00:08:27
                               ETA: 00:52:53

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 23537 steps/s (collection: 3.880s, learning 0.296s)
             Mean action noise std: 1.72
          Mean value_function loss: 12.0212
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 60.7411
                       Mean reward: 27.08
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 0.9576
    Episode_Reward/rotating_object: 4.9919
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 4.18s
                      Time elapsed: 00:08:31
                               ETA: 00:53:01

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 22912 steps/s (collection: 4.053s, learning 0.238s)
             Mean action noise std: 1.72
          Mean value_function loss: 11.6430
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 60.7838
                       Mean reward: 24.95
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.9966
    Episode_Reward/rotating_object: 4.7739
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 4.29s
                      Time elapsed: 00:08:36
                               ETA: 00:53:10

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 24009 steps/s (collection: 3.797s, learning 0.297s)
             Mean action noise std: 1.72
          Mean value_function loss: 11.5735
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 60.8228
                       Mean reward: 26.73
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 0.9643
    Episode_Reward/rotating_object: 4.7447
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 4.09s
                      Time elapsed: 00:08:40
                               ETA: 00:53:18

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 24189 steps/s (collection: 3.791s, learning 0.273s)
             Mean action noise std: 1.73
          Mean value_function loss: 12.9595
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.8562
                       Mean reward: 29.78
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 0.9886
    Episode_Reward/rotating_object: 4.3506
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 4.06s
                      Time elapsed: 00:08:44
                               ETA: 00:53:25

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 23760 steps/s (collection: 3.874s, learning 0.264s)
             Mean action noise std: 1.73
          Mean value_function loss: 12.8911
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 60.8885
                       Mean reward: 21.01
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.9832
    Episode_Reward/rotating_object: 4.5988
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 4.14s
                      Time elapsed: 00:08:48
                               ETA: 00:53:33

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 23695 steps/s (collection: 3.866s, learning 0.283s)
             Mean action noise std: 1.73
          Mean value_function loss: 12.0627
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 60.9383
                       Mean reward: 31.85
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.9818
    Episode_Reward/rotating_object: 5.2573
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 4.15s
                      Time elapsed: 00:08:52
                               ETA: 00:53:40

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 23466 steps/s (collection: 3.915s, learning 0.274s)
             Mean action noise std: 1.73
          Mean value_function loss: 12.1415
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 60.9867
                       Mean reward: 35.95
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 0.9514
    Episode_Reward/rotating_object: 5.1388
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 4.19s
                      Time elapsed: 00:08:56
                               ETA: 00:53:48

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 24693 steps/s (collection: 3.705s, learning 0.276s)
             Mean action noise std: 1.74
          Mean value_function loss: 12.2882
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.0383
                       Mean reward: 29.80
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 0.9868
    Episode_Reward/rotating_object: 4.6309
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 3.98s
                      Time elapsed: 00:09:00
                               ETA: 00:53:54

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 24552 steps/s (collection: 3.720s, learning 0.284s)
             Mean action noise std: 1.74
          Mean value_function loss: 12.8036
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.0631
                       Mean reward: 32.89
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 0.9825
    Episode_Reward/rotating_object: 5.4369
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 4.00s
                      Time elapsed: 00:09:04
                               ETA: 00:54:00

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 24248 steps/s (collection: 3.767s, learning 0.287s)
             Mean action noise std: 1.74
          Mean value_function loss: 13.3133
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.0913
                       Mean reward: 25.23
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 0.9933
    Episode_Reward/rotating_object: 4.1017
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 4.05s
                      Time elapsed: 00:09:08
                               ETA: 00:54:07

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 24547 steps/s (collection: 3.728s, learning 0.277s)
             Mean action noise std: 1.74
          Mean value_function loss: 11.9662
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.1280
                       Mean reward: 33.09
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 0.9803
    Episode_Reward/rotating_object: 5.3446
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 4.00s
                      Time elapsed: 00:09:12
                               ETA: 00:54:13

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 22894 steps/s (collection: 4.054s, learning 0.240s)
             Mean action noise std: 1.74
          Mean value_function loss: 11.6363
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.1475
                       Mean reward: 28.97
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.0289
    Episode_Reward/rotating_object: 5.1709
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 4.29s
                      Time elapsed: 00:09:17
                               ETA: 00:54:21

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 24883 steps/s (collection: 3.684s, learning 0.267s)
             Mean action noise std: 1.74
          Mean value_function loss: 13.3345
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.1747
                       Mean reward: 25.51
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.9758
    Episode_Reward/rotating_object: 5.0827
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 3.95s
                      Time elapsed: 00:09:21
                               ETA: 00:54:26

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 24629 steps/s (collection: 3.725s, learning 0.267s)
             Mean action noise std: 1.75
          Mean value_function loss: 15.0273
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 61.2144
                       Mean reward: 39.57
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 0.9676
    Episode_Reward/rotating_object: 5.7860
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 3.99s
                      Time elapsed: 00:09:25
                               ETA: 00:54:32

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 24515 steps/s (collection: 3.761s, learning 0.249s)
             Mean action noise std: 1.75
          Mean value_function loss: 13.3762
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 61.2614
                       Mean reward: 37.16
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 0.9901
    Episode_Reward/rotating_object: 6.1669
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 4.01s
                      Time elapsed: 00:09:29
                               ETA: 00:54:38

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 24020 steps/s (collection: 3.826s, learning 0.266s)
             Mean action noise std: 1.75
          Mean value_function loss: 18.0589
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.3224
                       Mean reward: 25.46
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 0.9817
    Episode_Reward/rotating_object: 5.9693
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 4.09s
                      Time elapsed: 00:09:33
                               ETA: 00:54:44

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 25194 steps/s (collection: 3.650s, learning 0.252s)
             Mean action noise std: 1.75
          Mean value_function loss: 14.4237
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 61.3642
                       Mean reward: 22.90
               Mean episode length: 219.30
    Episode_Reward/reaching_object: 0.9440
    Episode_Reward/rotating_object: 4.9654
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 3.90s
                      Time elapsed: 00:09:37
                               ETA: 00:54:49

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 25502 steps/s (collection: 3.576s, learning 0.279s)
             Mean action noise std: 1.76
          Mean value_function loss: 14.4958
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 61.4125
                       Mean reward: 34.05
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 0.9688
    Episode_Reward/rotating_object: 6.0332
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 3.85s
                      Time elapsed: 00:09:40
                               ETA: 00:54:54

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 25806 steps/s (collection: 3.569s, learning 0.241s)
             Mean action noise std: 1.76
          Mean value_function loss: 12.7716
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 61.4516
                       Mean reward: 35.64
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 0.9656
    Episode_Reward/rotating_object: 5.7777
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 3.81s
                      Time elapsed: 00:09:44
                               ETA: 00:54:58

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 24806 steps/s (collection: 3.720s, learning 0.243s)
             Mean action noise std: 1.76
          Mean value_function loss: 13.1773
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 61.4919
                       Mean reward: 27.33
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.9938
    Episode_Reward/rotating_object: 6.2074
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 3.96s
                      Time elapsed: 00:09:48
                               ETA: 00:55:03

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 24932 steps/s (collection: 3.697s, learning 0.246s)
             Mean action noise std: 1.76
          Mean value_function loss: 15.3434
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.5330
                       Mean reward: 32.06
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 0.9941
    Episode_Reward/rotating_object: 6.0099
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 3.94s
                      Time elapsed: 00:09:52
                               ETA: 00:55:08

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 24239 steps/s (collection: 3.826s, learning 0.229s)
             Mean action noise std: 1.77
          Mean value_function loss: 13.1106
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 61.5667
                       Mean reward: 37.87
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 0.9998
    Episode_Reward/rotating_object: 5.5516
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 4.06s
                      Time elapsed: 00:09:56
                               ETA: 00:55:14

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 32272 steps/s (collection: 2.940s, learning 0.106s)
             Mean action noise std: 1.77
          Mean value_function loss: 15.8311
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.6041
                       Mean reward: 30.15
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.0024
    Episode_Reward/rotating_object: 5.2908
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 3.05s
                      Time elapsed: 00:09:59
                               ETA: 00:55:14

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 47461 steps/s (collection: 1.959s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 16.6811
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 61.6225
                       Mean reward: 40.82
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 0.9804
    Episode_Reward/rotating_object: 6.3319
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.07s
                      Time elapsed: 00:10:01
                               ETA: 00:55:08

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 48246 steps/s (collection: 1.917s, learning 0.121s)
             Mean action noise std: 1.77
          Mean value_function loss: 13.3909
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 61.6577
                       Mean reward: 44.51
               Mean episode length: 245.20
    Episode_Reward/reaching_object: 1.0066
    Episode_Reward/rotating_object: 7.0309
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.04s
                      Time elapsed: 00:10:03
                               ETA: 00:55:02

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 48214 steps/s (collection: 1.912s, learning 0.127s)
             Mean action noise std: 1.77
          Mean value_function loss: 15.4818
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.7016
                       Mean reward: 35.15
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 0.9468
    Episode_Reward/rotating_object: 5.9879
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.04s
                      Time elapsed: 00:10:05
                               ETA: 00:54:57

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 47404 steps/s (collection: 1.942s, learning 0.132s)
             Mean action noise std: 1.78
          Mean value_function loss: 14.9397
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 61.7508
                       Mean reward: 29.58
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 0.9849
    Episode_Reward/rotating_object: 5.3627
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.07s
                      Time elapsed: 00:10:07
                               ETA: 00:54:51

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 49101 steps/s (collection: 1.880s, learning 0.122s)
             Mean action noise std: 1.78
          Mean value_function loss: 15.7825
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 61.8132
                       Mean reward: 34.16
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 0.9796
    Episode_Reward/rotating_object: 5.6137
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.00s
                      Time elapsed: 00:10:09
                               ETA: 00:54:46

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 48881 steps/s (collection: 1.902s, learning 0.109s)
             Mean action noise std: 1.78
          Mean value_function loss: 14.7320
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.8609
                       Mean reward: 34.12
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 0.9941
    Episode_Reward/rotating_object: 6.1659
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.01s
                      Time elapsed: 00:10:11
                               ETA: 00:54:40

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 48743 steps/s (collection: 1.902s, learning 0.115s)
             Mean action noise std: 1.79
          Mean value_function loss: 13.5794
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.9015
                       Mean reward: 44.43
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 0.9544
    Episode_Reward/rotating_object: 7.4557
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.02s
                      Time elapsed: 00:10:13
                               ETA: 00:54:34

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 48139 steps/s (collection: 1.922s, learning 0.121s)
             Mean action noise std: 1.79
          Mean value_function loss: 13.5170
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 61.9391
                       Mean reward: 42.80
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 0.9505
    Episode_Reward/rotating_object: 5.8063
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.04s
                      Time elapsed: 00:10:16
                               ETA: 00:54:29

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 47886 steps/s (collection: 1.938s, learning 0.115s)
             Mean action noise std: 1.79
          Mean value_function loss: 12.6547
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.9831
                       Mean reward: 35.14
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 0.9773
    Episode_Reward/rotating_object: 5.5778
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.05s
                      Time elapsed: 00:10:18
                               ETA: 00:54:23

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 48072 steps/s (collection: 1.930s, learning 0.115s)
             Mean action noise std: 1.79
          Mean value_function loss: 13.4210
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 62.0408
                       Mean reward: 25.62
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 0.9137
    Episode_Reward/rotating_object: 5.0037
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.04s
                      Time elapsed: 00:10:20
                               ETA: 00:54:18

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 48853 steps/s (collection: 1.903s, learning 0.110s)
             Mean action noise std: 1.80
          Mean value_function loss: 16.0002
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.0773
                       Mean reward: 31.01
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 0.9513
    Episode_Reward/rotating_object: 5.2464
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.01s
                      Time elapsed: 00:10:22
                               ETA: 00:54:12

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 48639 steps/s (collection: 1.907s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 15.4324
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 62.1130
                       Mean reward: 45.19
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 0.9503
    Episode_Reward/rotating_object: 6.3787
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.02s
                      Time elapsed: 00:10:24
                               ETA: 00:54:07

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 48743 steps/s (collection: 1.907s, learning 0.110s)
             Mean action noise std: 1.80
          Mean value_function loss: 14.6645
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 62.1510
                       Mean reward: 38.36
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 0.9790
    Episode_Reward/rotating_object: 6.9180
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.02s
                      Time elapsed: 00:10:26
                               ETA: 00:54:01

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 47549 steps/s (collection: 1.937s, learning 0.131s)
             Mean action noise std: 1.80
          Mean value_function loss: 15.0464
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 62.1923
                       Mean reward: 35.44
               Mean episode length: 230.10
    Episode_Reward/reaching_object: 0.9362
    Episode_Reward/rotating_object: 5.1053
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.07s
                      Time elapsed: 00:10:28
                               ETA: 00:53:56

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 46885 steps/s (collection: 1.979s, learning 0.118s)
             Mean action noise std: 1.80
          Mean value_function loss: 12.2888
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.2277
                       Mean reward: 40.07
               Mean episode length: 232.31
    Episode_Reward/reaching_object: 0.9499
    Episode_Reward/rotating_object: 6.6669
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.10s
                      Time elapsed: 00:10:30
                               ETA: 00:53:51

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 47317 steps/s (collection: 1.945s, learning 0.133s)
             Mean action noise std: 1.81
          Mean value_function loss: 14.2052
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 62.2753
                       Mean reward: 36.79
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 0.9490
    Episode_Reward/rotating_object: 5.8859
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.08s
                      Time elapsed: 00:10:32
                               ETA: 00:53:46

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 48657 steps/s (collection: 1.921s, learning 0.100s)
             Mean action noise std: 1.81
          Mean value_function loss: 14.7476
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 62.3159
                       Mean reward: 32.22
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 0.9912
    Episode_Reward/rotating_object: 6.6495
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.02s
                      Time elapsed: 00:10:34
                               ETA: 00:53:41

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 46874 steps/s (collection: 1.986s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 14.0980
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 62.3432
                       Mean reward: 43.48
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 0.9499
    Episode_Reward/rotating_object: 7.9329
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.10s
                      Time elapsed: 00:10:36
                               ETA: 00:53:36

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 42857 steps/s (collection: 2.184s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 15.3570
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.3875
                       Mean reward: 47.48
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 0.9575
    Episode_Reward/rotating_object: 7.7312
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.29s
                      Time elapsed: 00:10:38
                               ETA: 00:53:32

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 47001 steps/s (collection: 1.974s, learning 0.117s)
             Mean action noise std: 1.81
          Mean value_function loss: 12.7013
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.4102
                       Mean reward: 45.80
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.0087
    Episode_Reward/rotating_object: 6.6382
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.09s
                      Time elapsed: 00:10:40
                               ETA: 00:53:27

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 47352 steps/s (collection: 1.957s, learning 0.119s)
             Mean action noise std: 1.82
          Mean value_function loss: 15.4321
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 62.4410
                       Mean reward: 30.91
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 0.9773
    Episode_Reward/rotating_object: 6.3283
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.08s
                      Time elapsed: 00:10:42
                               ETA: 00:53:22

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 46801 steps/s (collection: 1.968s, learning 0.132s)
             Mean action noise std: 1.82
          Mean value_function loss: 14.3998
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 62.4800
                       Mean reward: 43.06
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 0.9499
    Episode_Reward/rotating_object: 6.9793
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.10s
                      Time elapsed: 00:10:45
                               ETA: 00:53:17

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 45094 steps/s (collection: 2.058s, learning 0.122s)
             Mean action noise std: 1.82
          Mean value_function loss: 16.1880
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 62.5034
                       Mean reward: 32.00
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 1.0004
    Episode_Reward/rotating_object: 5.8060
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.18s
                      Time elapsed: 00:10:47
                               ETA: 00:53:12

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 42038 steps/s (collection: 2.222s, learning 0.117s)
             Mean action noise std: 1.82
          Mean value_function loss: 12.8807
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 62.5340
                       Mean reward: 44.43
               Mean episode length: 240.83
    Episode_Reward/reaching_object: 0.9947
    Episode_Reward/rotating_object: 6.5769
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.34s
                      Time elapsed: 00:10:49
                               ETA: 00:53:09

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 46777 steps/s (collection: 1.995s, learning 0.107s)
             Mean action noise std: 1.82
          Mean value_function loss: 15.2627
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 62.5748
                       Mean reward: 31.88
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 0.9546
    Episode_Reward/rotating_object: 5.8770
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.10s
                      Time elapsed: 00:10:51
                               ETA: 00:53:04

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 46710 steps/s (collection: 1.981s, learning 0.123s)
             Mean action noise std: 1.83
          Mean value_function loss: 12.7514
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.6136
                       Mean reward: 28.76
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 0.9824
    Episode_Reward/rotating_object: 5.7646
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.10s
                      Time elapsed: 00:10:53
                               ETA: 00:52:59

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 46558 steps/s (collection: 1.984s, learning 0.128s)
             Mean action noise std: 1.83
          Mean value_function loss: 15.3989
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 62.6534
                       Mean reward: 49.43
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 0.9930
    Episode_Reward/rotating_object: 6.3762
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.11s
                      Time elapsed: 00:10:55
                               ETA: 00:52:55

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 47304 steps/s (collection: 1.950s, learning 0.128s)
             Mean action noise std: 1.83
          Mean value_function loss: 13.5897
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.6950
                       Mean reward: 32.29
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 0.9660
    Episode_Reward/rotating_object: 6.3836
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.08s
                      Time elapsed: 00:10:58
                               ETA: 00:52:50

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 46330 steps/s (collection: 1.984s, learning 0.138s)
             Mean action noise std: 1.84
          Mean value_function loss: 15.4155
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 62.7479
                       Mean reward: 40.52
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 0.9905
    Episode_Reward/rotating_object: 6.6502
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.12s
                      Time elapsed: 00:11:00
                               ETA: 00:52:45

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 47546 steps/s (collection: 1.938s, learning 0.130s)
             Mean action noise std: 1.84
          Mean value_function loss: 16.4046
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.7951
                       Mean reward: 31.97
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 0.9584
    Episode_Reward/rotating_object: 6.7870
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.07s
                      Time elapsed: 00:11:02
                               ETA: 00:52:40

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 48104 steps/s (collection: 1.908s, learning 0.136s)
             Mean action noise std: 1.84
          Mean value_function loss: 16.5893
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 62.8535
                       Mean reward: 42.31
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 0.9450
    Episode_Reward/rotating_object: 6.8408
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.04s
                      Time elapsed: 00:11:04
                               ETA: 00:52:35

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 46922 steps/s (collection: 1.956s, learning 0.140s)
             Mean action noise std: 1.84
          Mean value_function loss: 17.3233
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 62.8950
                       Mean reward: 49.71
               Mean episode length: 238.68
    Episode_Reward/reaching_object: 0.9613
    Episode_Reward/rotating_object: 7.7470
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.10s
                      Time elapsed: 00:11:06
                               ETA: 00:52:31

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 47194 steps/s (collection: 1.956s, learning 0.127s)
             Mean action noise std: 1.85
          Mean value_function loss: 14.1947
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 62.9439
                       Mean reward: 34.66
               Mean episode length: 227.82
    Episode_Reward/reaching_object: 0.9483
    Episode_Reward/rotating_object: 6.6669
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.08s
                      Time elapsed: 00:11:08
                               ETA: 00:52:26

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 45884 steps/s (collection: 2.015s, learning 0.127s)
             Mean action noise std: 1.85
          Mean value_function loss: 18.6598
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.9952
                       Mean reward: 36.18
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 0.9561
    Episode_Reward/rotating_object: 5.5755
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.14s
                      Time elapsed: 00:11:10
                               ETA: 00:52:22

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 46245 steps/s (collection: 1.989s, learning 0.137s)
             Mean action noise std: 1.85
          Mean value_function loss: 20.8833
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.0479
                       Mean reward: 34.29
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 0.9663
    Episode_Reward/rotating_object: 6.6870
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.13s
                      Time elapsed: 00:11:12
                               ETA: 00:52:17

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 47761 steps/s (collection: 1.946s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 21.6905
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.0902
                       Mean reward: 46.78
               Mean episode length: 222.39
    Episode_Reward/reaching_object: 0.9546
    Episode_Reward/rotating_object: 7.6286
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.06s
                      Time elapsed: 00:11:14
                               ETA: 00:52:12

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 45927 steps/s (collection: 2.001s, learning 0.139s)
             Mean action noise std: 1.86
          Mean value_function loss: 17.4011
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 63.1395
                       Mean reward: 43.36
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.9476
    Episode_Reward/rotating_object: 7.2029
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.14s
                      Time elapsed: 00:11:16
                               ETA: 00:52:08

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 47167 steps/s (collection: 1.960s, learning 0.124s)
             Mean action noise std: 1.86
          Mean value_function loss: 20.9308
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.1731
                       Mean reward: 42.90
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 0.9839
    Episode_Reward/rotating_object: 9.0038
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.08s
                      Time elapsed: 00:11:18
                               ETA: 00:52:03

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 45262 steps/s (collection: 2.044s, learning 0.128s)
             Mean action noise std: 1.86
          Mean value_function loss: 18.6547
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 63.2081
                       Mean reward: 35.92
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 0.9444
    Episode_Reward/rotating_object: 8.0134
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.17s
                      Time elapsed: 00:11:21
                               ETA: 00:51:59

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 46008 steps/s (collection: 1.994s, learning 0.143s)
             Mean action noise std: 1.87
          Mean value_function loss: 19.0327
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 63.2572
                       Mean reward: 37.06
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 0.9454
    Episode_Reward/rotating_object: 7.3568
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.14s
                      Time elapsed: 00:11:23
                               ETA: 00:51:55

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 46976 steps/s (collection: 1.974s, learning 0.119s)
             Mean action noise std: 1.87
          Mean value_function loss: 20.9285
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 63.3138
                       Mean reward: 50.70
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 0.9763
    Episode_Reward/rotating_object: 6.9803
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.09s
                      Time elapsed: 00:11:25
                               ETA: 00:51:50

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 48053 steps/s (collection: 1.914s, learning 0.131s)
             Mean action noise std: 1.87
          Mean value_function loss: 20.6719
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 63.3681
                       Mean reward: 47.67
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 0.9585
    Episode_Reward/rotating_object: 7.8591
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.05s
                      Time elapsed: 00:11:27
                               ETA: 00:51:46

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 46172 steps/s (collection: 1.995s, learning 0.134s)
             Mean action noise std: 1.88
          Mean value_function loss: 20.6237
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 63.4115
                       Mean reward: 53.23
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 0.9777
    Episode_Reward/rotating_object: 9.1761
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.13s
                      Time elapsed: 00:11:29
                               ETA: 00:51:41

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 46856 steps/s (collection: 1.969s, learning 0.129s)
             Mean action noise std: 1.88
          Mean value_function loss: 19.6596
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.4544
                       Mean reward: 34.96
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 0.9860
    Episode_Reward/rotating_object: 8.0250
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.10s
                      Time elapsed: 00:11:31
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 46357 steps/s (collection: 1.976s, learning 0.145s)
             Mean action noise std: 1.88
          Mean value_function loss: 20.7413
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.5006
                       Mean reward: 55.62
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 0.9873
    Episode_Reward/rotating_object: 9.0764
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.12s
                      Time elapsed: 00:11:33
                               ETA: 00:51:32

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 45875 steps/s (collection: 2.011s, learning 0.132s)
             Mean action noise std: 1.88
          Mean value_function loss: 19.6153
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 63.5388
                       Mean reward: 43.57
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 0.9844
    Episode_Reward/rotating_object: 7.1758
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.14s
                      Time elapsed: 00:11:35
                               ETA: 00:51:28

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 46639 steps/s (collection: 1.973s, learning 0.135s)
             Mean action noise std: 1.89
          Mean value_function loss: 18.5288
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.5854
                       Mean reward: 48.47
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 0.9783
    Episode_Reward/rotating_object: 8.1923
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.11s
                      Time elapsed: 00:11:38
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 46178 steps/s (collection: 1.994s, learning 0.135s)
             Mean action noise std: 1.89
          Mean value_function loss: 20.1943
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 63.6315
                       Mean reward: 41.71
               Mean episode length: 222.61
    Episode_Reward/reaching_object: 0.9652
    Episode_Reward/rotating_object: 7.5466
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.13s
                      Time elapsed: 00:11:40
                               ETA: 00:51:20

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 46620 steps/s (collection: 1.965s, learning 0.144s)
             Mean action noise std: 1.89
          Mean value_function loss: 19.5575
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 63.6654
                       Mean reward: 38.74
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 0.9605
    Episode_Reward/rotating_object: 7.4939
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.11s
                      Time elapsed: 00:11:42
                               ETA: 00:51:15

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 46188 steps/s (collection: 2.000s, learning 0.128s)
             Mean action noise std: 1.89
          Mean value_function loss: 19.1890
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 63.6867
                       Mean reward: 53.95
               Mean episode length: 224.81
    Episode_Reward/reaching_object: 0.9912
    Episode_Reward/rotating_object: 7.9151
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.13s
                      Time elapsed: 00:11:44
                               ETA: 00:51:11

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 46584 steps/s (collection: 1.978s, learning 0.133s)
             Mean action noise std: 1.89
          Mean value_function loss: 21.8962
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 63.7258
                       Mean reward: 46.76
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 0.9765
    Episode_Reward/rotating_object: 8.4075
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.11s
                      Time elapsed: 00:11:46
                               ETA: 00:51:07

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 46450 steps/s (collection: 1.983s, learning 0.133s)
             Mean action noise std: 1.90
          Mean value_function loss: 22.7572
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 63.7597
                       Mean reward: 37.11
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 0.9538
    Episode_Reward/rotating_object: 6.8306
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.12s
                      Time elapsed: 00:11:48
                               ETA: 00:51:03

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 41538 steps/s (collection: 2.235s, learning 0.132s)
             Mean action noise std: 1.90
          Mean value_function loss: 20.4333
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 63.7943
                       Mean reward: 52.69
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.0395
    Episode_Reward/rotating_object: 9.8220
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.37s
                      Time elapsed: 00:11:50
                               ETA: 00:50:59

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 43930 steps/s (collection: 2.110s, learning 0.127s)
             Mean action noise std: 1.90
          Mean value_function loss: 23.7716
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 63.8395
                       Mean reward: 50.17
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 0.9852
    Episode_Reward/rotating_object: 7.4044
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.24s
                      Time elapsed: 00:11:53
                               ETA: 00:50:56

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 42070 steps/s (collection: 2.190s, learning 0.147s)
             Mean action noise std: 1.90
          Mean value_function loss: 25.6098
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 63.8775
                       Mean reward: 33.31
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 0.9912
    Episode_Reward/rotating_object: 6.5335
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.34s
                      Time elapsed: 00:11:55
                               ETA: 00:50:53

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 46562 steps/s (collection: 1.971s, learning 0.141s)
             Mean action noise std: 1.91
          Mean value_function loss: 24.5632
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 63.9174
                       Mean reward: 40.37
               Mean episode length: 226.00
    Episode_Reward/reaching_object: 0.9958
    Episode_Reward/rotating_object: 7.7545
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.11s
                      Time elapsed: 00:11:57
                               ETA: 00:50:48

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 42263 steps/s (collection: 2.182s, learning 0.144s)
             Mean action noise std: 1.91
          Mean value_function loss: 24.0533
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 63.9680
                       Mean reward: 53.16
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 0.9839
    Episode_Reward/rotating_object: 9.1803
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.33s
                      Time elapsed: 00:11:59
                               ETA: 00:50:45

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 43904 steps/s (collection: 2.108s, learning 0.131s)
             Mean action noise std: 1.91
          Mean value_function loss: 26.0705
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 64.0090
                       Mean reward: 47.04
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 1.0283
    Episode_Reward/rotating_object: 8.4883
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.24s
                      Time elapsed: 00:12:02
                               ETA: 00:50:41

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 45446 steps/s (collection: 2.024s, learning 0.139s)
             Mean action noise std: 1.91
          Mean value_function loss: 23.6213
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 64.0443
                       Mean reward: 41.79
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 1.0270
    Episode_Reward/rotating_object: 8.6936
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.16s
                      Time elapsed: 00:12:04
                               ETA: 00:50:37

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 44824 steps/s (collection: 2.046s, learning 0.147s)
             Mean action noise std: 1.92
          Mean value_function loss: 25.5402
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 64.0815
                       Mean reward: 46.27
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 0.9886
    Episode_Reward/rotating_object: 9.0633
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.19s
                      Time elapsed: 00:12:06
                               ETA: 00:50:34

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 46708 steps/s (collection: 1.972s, learning 0.133s)
             Mean action noise std: 1.92
          Mean value_function loss: 25.7794
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 64.1188
                       Mean reward: 40.83
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.0242
    Episode_Reward/rotating_object: 9.5032
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.10s
                      Time elapsed: 00:12:08
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 45573 steps/s (collection: 2.020s, learning 0.138s)
             Mean action noise std: 1.92
          Mean value_function loss: 26.3527
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 64.1579
                       Mean reward: 56.14
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 1.0074
    Episode_Reward/rotating_object: 8.0495
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.16s
                      Time elapsed: 00:12:10
                               ETA: 00:50:26

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 46243 steps/s (collection: 1.989s, learning 0.137s)
             Mean action noise std: 1.92
          Mean value_function loss: 27.9972
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 64.1917
                       Mean reward: 51.04
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 0.9893
    Episode_Reward/rotating_object: 7.8623
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.13s
                      Time elapsed: 00:12:12
                               ETA: 00:50:21

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 46788 steps/s (collection: 1.973s, learning 0.128s)
             Mean action noise std: 1.92
          Mean value_function loss: 30.3025
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 64.2211
                       Mean reward: 50.42
               Mean episode length: 232.20
    Episode_Reward/reaching_object: 0.9950
    Episode_Reward/rotating_object: 9.2572
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.10s
                      Time elapsed: 00:12:15
                               ETA: 00:50:17

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 47589 steps/s (collection: 1.935s, learning 0.131s)
             Mean action noise std: 1.93
          Mean value_function loss: 26.1210
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.2633
                       Mean reward: 49.41
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 0.9994
    Episode_Reward/rotating_object: 10.5469
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.07s
                      Time elapsed: 00:12:17
                               ETA: 00:50:13

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 47810 steps/s (collection: 1.944s, learning 0.112s)
             Mean action noise std: 1.93
          Mean value_function loss: 24.0774
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 64.3043
                       Mean reward: 64.66
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 1.0061
    Episode_Reward/rotating_object: 10.2060
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.06s
                      Time elapsed: 00:12:19
                               ETA: 00:50:09

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 47228 steps/s (collection: 1.955s, learning 0.126s)
             Mean action noise std: 1.93
          Mean value_function loss: 23.4779
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.3417
                       Mean reward: 61.52
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.0209
    Episode_Reward/rotating_object: 9.4816
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.08s
                      Time elapsed: 00:12:21
                               ETA: 00:50:05

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 45997 steps/s (collection: 2.018s, learning 0.120s)
             Mean action noise std: 1.94
          Mean value_function loss: 26.0406
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.3929
                       Mean reward: 52.08
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.0057
    Episode_Reward/rotating_object: 9.0643
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.14s
                      Time elapsed: 00:12:23
                               ETA: 00:50:01

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 46562 steps/s (collection: 1.977s, learning 0.134s)
             Mean action noise std: 1.94
          Mean value_function loss: 27.2492
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 64.4345
                       Mean reward: 43.99
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 0.9907
    Episode_Reward/rotating_object: 9.8439
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.11s
                      Time elapsed: 00:12:25
                               ETA: 00:49:57

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 43823 steps/s (collection: 2.107s, learning 0.136s)
             Mean action noise std: 1.94
          Mean value_function loss: 27.4457
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.4660
                       Mean reward: 48.85
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.0275
    Episode_Reward/rotating_object: 9.3465
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.24s
                      Time elapsed: 00:12:27
                               ETA: 00:49:53

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 44353 steps/s (collection: 2.085s, learning 0.132s)
             Mean action noise std: 1.94
          Mean value_function loss: 28.1029
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 64.5087
                       Mean reward: 54.50
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.0246
    Episode_Reward/rotating_object: 9.4587
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.22s
                      Time elapsed: 00:12:29
                               ETA: 00:49:49

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 45347 steps/s (collection: 2.045s, learning 0.123s)
             Mean action noise std: 1.95
          Mean value_function loss: 29.4048
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.5483
                       Mean reward: 54.38
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 0.9905
    Episode_Reward/rotating_object: 9.8998
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.17s
                      Time elapsed: 00:12:32
                               ETA: 00:49:46

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 46534 steps/s (collection: 1.974s, learning 0.139s)
             Mean action noise std: 1.95
          Mean value_function loss: 31.9962
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 64.5884
                       Mean reward: 49.19
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.0002
    Episode_Reward/rotating_object: 9.2105
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.11s
                      Time elapsed: 00:12:34
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 45203 steps/s (collection: 2.034s, learning 0.141s)
             Mean action noise std: 1.95
          Mean value_function loss: 29.9546
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 64.6336
                       Mean reward: 43.70
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 9.9953
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.17s
                      Time elapsed: 00:12:36
                               ETA: 00:49:38

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 45180 steps/s (collection: 1.996s, learning 0.180s)
             Mean action noise std: 1.95
          Mean value_function loss: 32.6187
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 64.6786
                       Mean reward: 63.29
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.0207
    Episode_Reward/rotating_object: 10.6841
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.18s
                      Time elapsed: 00:12:38
                               ETA: 00:49:34

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 46633 steps/s (collection: 1.949s, learning 0.159s)
             Mean action noise std: 1.96
          Mean value_function loss: 31.4003
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 64.7166
                       Mean reward: 65.41
               Mean episode length: 236.26
    Episode_Reward/reaching_object: 1.0621
    Episode_Reward/rotating_object: 10.1639
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.11s
                      Time elapsed: 00:12:40
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 46861 steps/s (collection: 1.975s, learning 0.123s)
             Mean action noise std: 1.96
          Mean value_function loss: 30.0662
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 64.7523
                       Mean reward: 69.08
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.0508
    Episode_Reward/rotating_object: 12.8309
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.10s
                      Time elapsed: 00:12:42
                               ETA: 00:49:26

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 46172 steps/s (collection: 1.994s, learning 0.135s)
             Mean action noise std: 1.96
          Mean value_function loss: 29.7936
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.7831
                       Mean reward: 61.49
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 11.3230
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.13s
                      Time elapsed: 00:12:44
                               ETA: 00:49:22

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 46034 steps/s (collection: 1.997s, learning 0.139s)
             Mean action noise std: 1.96
          Mean value_function loss: 27.9976
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.8192
                       Mean reward: 41.61
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 1.0268
    Episode_Reward/rotating_object: 8.4532
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0540
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.14s
                      Time elapsed: 00:12:47
                               ETA: 00:49:19

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 40853 steps/s (collection: 2.213s, learning 0.193s)
             Mean action noise std: 1.97
          Mean value_function loss: 28.9916
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.8594
                       Mean reward: 81.99
               Mean episode length: 229.88
    Episode_Reward/reaching_object: 1.0712
    Episode_Reward/rotating_object: 12.2298
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.41s
                      Time elapsed: 00:12:49
                               ETA: 00:49:16

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 39405 steps/s (collection: 2.373s, learning 0.122s)
             Mean action noise std: 1.97
          Mean value_function loss: 27.6608
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 64.9004
                       Mean reward: 57.66
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 1.0627
    Episode_Reward/rotating_object: 11.8811
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.49s
                      Time elapsed: 00:12:51
                               ETA: 00:49:13

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 44560 steps/s (collection: 2.077s, learning 0.129s)
             Mean action noise std: 1.97
          Mean value_function loss: 33.8583
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 64.9342
                       Mean reward: 71.49
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.0729
    Episode_Reward/rotating_object: 11.6035
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.21s
                      Time elapsed: 00:12:54
                               ETA: 00:49:10

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 40912 steps/s (collection: 2.251s, learning 0.152s)
             Mean action noise std: 1.97
          Mean value_function loss: 32.1061
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 64.9681
                       Mean reward: 63.47
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.0745
    Episode_Reward/rotating_object: 13.4738
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.40s
                      Time elapsed: 00:12:56
                               ETA: 00:49:07

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 45542 steps/s (collection: 2.019s, learning 0.139s)
             Mean action noise std: 1.97
          Mean value_function loss: 29.9153
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 65.0051
                       Mean reward: 54.43
               Mean episode length: 231.16
    Episode_Reward/reaching_object: 1.0669
    Episode_Reward/rotating_object: 11.8467
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.16s
                      Time elapsed: 00:12:58
                               ETA: 00:49:03

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 46412 steps/s (collection: 1.987s, learning 0.131s)
             Mean action noise std: 1.98
          Mean value_function loss: 27.9141
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.0296
                       Mean reward: 51.35
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.0322
    Episode_Reward/rotating_object: 9.3848
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.12s
                      Time elapsed: 00:13:00
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 46973 steps/s (collection: 1.962s, learning 0.131s)
             Mean action noise std: 1.98
          Mean value_function loss: 28.7866
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 65.0546
                       Mean reward: 76.88
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.0784
    Episode_Reward/rotating_object: 12.9137
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.09s
                      Time elapsed: 00:13:02
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 46883 steps/s (collection: 1.958s, learning 0.139s)
             Mean action noise std: 1.98
          Mean value_function loss: 28.7541
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 65.0890
                       Mean reward: 53.16
               Mean episode length: 228.18
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 11.1794
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.10s
                      Time elapsed: 00:13:05
                               ETA: 00:48:52

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 46604 steps/s (collection: 1.971s, learning 0.138s)
             Mean action noise std: 1.98
          Mean value_function loss: 29.6082
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.1152
                       Mean reward: 52.72
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.0289
    Episode_Reward/rotating_object: 10.1776
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.11s
                      Time elapsed: 00:13:07
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 46499 steps/s (collection: 1.988s, learning 0.126s)
             Mean action noise std: 1.98
          Mean value_function loss: 30.3894
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 65.1563
                       Mean reward: 55.28
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.0611
    Episode_Reward/rotating_object: 11.1324
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0539
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.11s
                      Time elapsed: 00:13:09
                               ETA: 00:48:44

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 46095 steps/s (collection: 2.007s, learning 0.126s)
             Mean action noise std: 1.99
          Mean value_function loss: 34.2655
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 65.1848
                       Mean reward: 67.02
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.0556
    Episode_Reward/rotating_object: 11.0012
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.13s
                      Time elapsed: 00:13:11
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 47028 steps/s (collection: 1.974s, learning 0.116s)
             Mean action noise std: 1.99
          Mean value_function loss: 33.4086
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 65.2102
                       Mean reward: 38.13
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.0365
    Episode_Reward/rotating_object: 11.0192
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.09s
                      Time elapsed: 00:13:13
                               ETA: 00:48:36

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 46610 steps/s (collection: 1.965s, learning 0.144s)
             Mean action noise std: 1.99
          Mean value_function loss: 37.1748
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 65.2512
                       Mean reward: 59.21
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 9.9333
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.11s
                      Time elapsed: 00:13:15
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 46307 steps/s (collection: 1.987s, learning 0.136s)
             Mean action noise std: 1.99
          Mean value_function loss: 34.6164
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 65.2855
                       Mean reward: 48.52
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 1.0969
    Episode_Reward/rotating_object: 10.7336
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.12s
                      Time elapsed: 00:13:17
                               ETA: 00:48:29

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 45038 steps/s (collection: 2.033s, learning 0.150s)
             Mean action noise std: 1.99
          Mean value_function loss: 30.7117
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 65.3193
                       Mean reward: 50.70
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 11.0173
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.18s
                      Time elapsed: 00:13:19
                               ETA: 00:48:25

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 45512 steps/s (collection: 2.019s, learning 0.141s)
             Mean action noise std: 2.00
          Mean value_function loss: 36.1186
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 65.3582
                       Mean reward: 48.92
               Mean episode length: 226.65
    Episode_Reward/reaching_object: 1.0492
    Episode_Reward/rotating_object: 9.4870
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.16s
                      Time elapsed: 00:13:22
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 45474 steps/s (collection: 2.037s, learning 0.125s)
             Mean action noise std: 2.00
          Mean value_function loss: 32.3417
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.3915
                       Mean reward: 46.38
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.0948
    Episode_Reward/rotating_object: 9.8143
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.16s
                      Time elapsed: 00:13:24
                               ETA: 00:48:18

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 45544 steps/s (collection: 2.055s, learning 0.104s)
             Mean action noise std: 2.00
          Mean value_function loss: 38.4740
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 65.4195
                       Mean reward: 63.62
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.0814
    Episode_Reward/rotating_object: 11.5133
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.16s
                      Time elapsed: 00:13:26
                               ETA: 00:48:15

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 45871 steps/s (collection: 2.036s, learning 0.107s)
             Mean action noise std: 2.00
          Mean value_function loss: 28.5292
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 65.4599
                       Mean reward: 52.95
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 11.5953
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.14s
                      Time elapsed: 00:13:28
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 43594 steps/s (collection: 2.156s, learning 0.099s)
             Mean action noise std: 2.01
          Mean value_function loss: 34.1523
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.5021
                       Mean reward: 62.38
               Mean episode length: 229.85
    Episode_Reward/reaching_object: 1.0918
    Episode_Reward/rotating_object: 13.1714
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.25s
                      Time elapsed: 00:13:30
                               ETA: 00:48:08

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 46522 steps/s (collection: 2.003s, learning 0.110s)
             Mean action noise std: 2.01
          Mean value_function loss: 31.6394
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 65.5293
                       Mean reward: 64.32
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 1.1028
    Episode_Reward/rotating_object: 10.7236
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.11s
                      Time elapsed: 00:13:32
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 47031 steps/s (collection: 1.986s, learning 0.104s)
             Mean action noise std: 2.01
          Mean value_function loss: 31.1053
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 65.5663
                       Mean reward: 65.64
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 1.1027
    Episode_Reward/rotating_object: 12.6687
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.09s
                      Time elapsed: 00:13:35
                               ETA: 00:48:00

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 47995 steps/s (collection: 1.953s, learning 0.096s)
             Mean action noise std: 2.01
          Mean value_function loss: 27.9320
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 65.6025
                       Mean reward: 67.89
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 11.4902
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0539
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.05s
                      Time elapsed: 00:13:37
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 46897 steps/s (collection: 1.980s, learning 0.116s)
             Mean action noise std: 2.02
          Mean value_function loss: 28.5589
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.6392
                       Mean reward: 74.28
               Mean episode length: 227.40
    Episode_Reward/reaching_object: 1.0495
    Episode_Reward/rotating_object: 12.1905
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.10s
                      Time elapsed: 00:13:39
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 17341 steps/s (collection: 5.500s, learning 0.169s)
             Mean action noise std: 2.02
          Mean value_function loss: 36.0533
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.6672
                       Mean reward: 64.05
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.1153
    Episode_Reward/rotating_object: 13.2261
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.67s
                      Time elapsed: 00:13:44
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 12762 steps/s (collection: 7.539s, learning 0.164s)
             Mean action noise std: 2.02
          Mean value_function loss: 30.3361
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.6900
                       Mean reward: 59.92
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.1087
    Episode_Reward/rotating_object: 13.2697
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 7.70s
                      Time elapsed: 00:13:52
                               ETA: 00:48:17

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 12689 steps/s (collection: 7.565s, learning 0.182s)
             Mean action noise std: 2.02
          Mean value_function loss: 29.0734
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 65.7249
                       Mean reward: 60.24
               Mean episode length: 226.01
    Episode_Reward/reaching_object: 1.0867
    Episode_Reward/rotating_object: 12.8113
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 7.75s
                      Time elapsed: 00:14:00
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 12810 steps/s (collection: 7.507s, learning 0.167s)
             Mean action noise std: 2.02
          Mean value_function loss: 27.1373
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 65.7625
                       Mean reward: 96.11
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.0998
    Episode_Reward/rotating_object: 12.0579
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 7.67s
                      Time elapsed: 00:14:07
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 15871 steps/s (collection: 6.050s, learning 0.144s)
             Mean action noise std: 2.03
          Mean value_function loss: 34.8329
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.8043
                       Mean reward: 74.60
               Mean episode length: 230.10
    Episode_Reward/reaching_object: 1.1253
    Episode_Reward/rotating_object: 12.5867
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.19s
                      Time elapsed: 00:14:14
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 12885 steps/s (collection: 7.468s, learning 0.161s)
             Mean action noise std: 2.03
          Mean value_function loss: 36.7157
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.8483
                       Mean reward: 82.30
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 12.2672
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 7.63s
                      Time elapsed: 00:14:21
                               ETA: 00:49:13

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 13041 steps/s (collection: 7.359s, learning 0.179s)
             Mean action noise std: 2.03
          Mean value_function loss: 36.2834
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.8795
                       Mean reward: 76.24
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.1199
    Episode_Reward/rotating_object: 12.9788
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 7.54s
                      Time elapsed: 00:14:29
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 13090 steps/s (collection: 7.349s, learning 0.161s)
             Mean action noise std: 2.03
          Mean value_function loss: 36.5172
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 65.9107
                       Mean reward: 78.79
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 1.1501
    Episode_Reward/rotating_object: 14.2834
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 7.51s
                      Time elapsed: 00:14:36
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 11399 steps/s (collection: 8.452s, learning 0.172s)
             Mean action noise std: 2.03
          Mean value_function loss: 32.9308
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.9379
                       Mean reward: 63.39
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 1.1742
    Episode_Reward/rotating_object: 15.3277
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 8.62s
                      Time elapsed: 00:14:45
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 46579 steps/s (collection: 1.972s, learning 0.139s)
             Mean action noise std: 2.04
          Mean value_function loss: 33.2465
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 65.9755
                       Mean reward: 73.34
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 15.3108
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.11s
                      Time elapsed: 00:14:47
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 41589 steps/s (collection: 2.208s, learning 0.156s)
             Mean action noise std: 2.04
          Mean value_function loss: 41.3019
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 66.0063
                       Mean reward: 72.47
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.1887
    Episode_Reward/rotating_object: 13.6356
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.36s
                      Time elapsed: 00:14:49
                               ETA: 00:49:53

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 35165 steps/s (collection: 2.626s, learning 0.170s)
             Mean action noise std: 2.04
          Mean value_function loss: 39.9602
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 66.0298
                       Mean reward: 79.25
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 1.1727
    Episode_Reward/rotating_object: 12.8272
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.80s
                      Time elapsed: 00:14:52
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 40081 steps/s (collection: 2.238s, learning 0.215s)
             Mean action noise std: 2.04
          Mean value_function loss: 38.1818
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 66.0597
                       Mean reward: 96.45
               Mean episode length: 228.72
    Episode_Reward/reaching_object: 1.1545
    Episode_Reward/rotating_object: 13.2260
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.45s
                      Time elapsed: 00:14:55
                               ETA: 00:49:48

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 37841 steps/s (collection: 2.399s, learning 0.199s)
             Mean action noise std: 2.05
          Mean value_function loss: 35.6423
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 66.0968
                       Mean reward: 81.09
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 1.1533
    Episode_Reward/rotating_object: 13.3676
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.60s
                      Time elapsed: 00:14:57
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 36715 steps/s (collection: 2.459s, learning 0.218s)
             Mean action noise std: 2.05
          Mean value_function loss: 34.9698
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 66.1292
                       Mean reward: 59.90
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 14.7135
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.68s
                      Time elapsed: 00:15:00
                               ETA: 00:49:43

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 40955 steps/s (collection: 2.189s, learning 0.211s)
             Mean action noise std: 2.05
          Mean value_function loss: 34.8804
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 66.1591
                       Mean reward: 77.51
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 1.1777
    Episode_Reward/rotating_object: 13.8442
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.40s
                      Time elapsed: 00:15:02
                               ETA: 00:49:40

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 37565 steps/s (collection: 2.476s, learning 0.141s)
             Mean action noise std: 2.05
          Mean value_function loss: 41.2020
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.1865
                       Mean reward: 74.80
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.1652
    Episode_Reward/rotating_object: 13.6238
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.62s
                      Time elapsed: 00:15:05
                               ETA: 00:49:37

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 40741 steps/s (collection: 2.249s, learning 0.164s)
             Mean action noise std: 2.05
          Mean value_function loss: 35.4796
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 66.2168
                       Mean reward: 67.16
               Mean episode length: 223.00
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 13.9506
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.41s
                      Time elapsed: 00:15:07
                               ETA: 00:49:34

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 38610 steps/s (collection: 2.371s, learning 0.175s)
             Mean action noise std: 2.06
          Mean value_function loss: 32.8237
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 66.2492
                       Mean reward: 98.83
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.1811
    Episode_Reward/rotating_object: 15.7091
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.55s
                      Time elapsed: 00:15:10
                               ETA: 00:49:31

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 41069 steps/s (collection: 2.201s, learning 0.193s)
             Mean action noise std: 2.06
          Mean value_function loss: 37.6113
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 66.2807
                       Mean reward: 81.73
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 1.1927
    Episode_Reward/rotating_object: 12.9800
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.39s
                      Time elapsed: 00:15:12
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 36665 steps/s (collection: 2.507s, learning 0.174s)
             Mean action noise std: 2.06
          Mean value_function loss: 44.4993
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 66.3225
                       Mean reward: 75.31
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 1.1733
    Episode_Reward/rotating_object: 14.0015
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.68s
                      Time elapsed: 00:15:15
                               ETA: 00:49:26

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 39468 steps/s (collection: 2.296s, learning 0.195s)
             Mean action noise std: 2.06
          Mean value_function loss: 39.0189
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.3594
                       Mean reward: 64.96
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 1.1852
    Episode_Reward/rotating_object: 13.6291
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.49s
                      Time elapsed: 00:15:17
                               ETA: 00:49:23

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 37872 steps/s (collection: 2.325s, learning 0.271s)
             Mean action noise std: 2.06
          Mean value_function loss: 34.4248
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 66.3845
                       Mean reward: 78.89
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 15.8085
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.60s
                      Time elapsed: 00:15:20
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 38896 steps/s (collection: 2.334s, learning 0.193s)
             Mean action noise std: 2.07
          Mean value_function loss: 36.4688
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 66.4122
                       Mean reward: 72.76
               Mean episode length: 227.52
    Episode_Reward/reaching_object: 1.1855
    Episode_Reward/rotating_object: 14.4945
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.53s
                      Time elapsed: 00:15:23
                               ETA: 00:49:18

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 41760 steps/s (collection: 2.108s, learning 0.246s)
             Mean action noise std: 2.07
          Mean value_function loss: 40.8888
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.4500
                       Mean reward: 68.86
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.2105
    Episode_Reward/rotating_object: 12.6953
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.35s
                      Time elapsed: 00:15:25
                               ETA: 00:49:14

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 39532 steps/s (collection: 2.292s, learning 0.195s)
             Mean action noise std: 2.07
          Mean value_function loss: 37.5101
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 66.4861
                       Mean reward: 94.37
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.2056
    Episode_Reward/rotating_object: 16.0753
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.49s
                      Time elapsed: 00:15:27
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 39108 steps/s (collection: 2.277s, learning 0.237s)
             Mean action noise std: 2.07
          Mean value_function loss: 35.8145
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 66.5196
                       Mean reward: 95.69
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 16.1189
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.51s
                      Time elapsed: 00:15:30
                               ETA: 00:49:09

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 38998 steps/s (collection: 2.305s, learning 0.216s)
             Mean action noise std: 2.08
          Mean value_function loss: 31.2215
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.5594
                       Mean reward: 86.44
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 16.2097
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.52s
                      Time elapsed: 00:15:32
                               ETA: 00:49:06

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 40769 steps/s (collection: 2.220s, learning 0.191s)
             Mean action noise std: 2.08
          Mean value_function loss: 29.0935
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 66.6019
                       Mean reward: 89.86
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.2394
    Episode_Reward/rotating_object: 15.9250
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.41s
                      Time elapsed: 00:15:35
                               ETA: 00:49:03

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 38683 steps/s (collection: 2.313s, learning 0.229s)
             Mean action noise std: 2.08
          Mean value_function loss: 36.2631
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 66.6343
                       Mean reward: 112.22
               Mean episode length: 229.85
    Episode_Reward/reaching_object: 1.2167
    Episode_Reward/rotating_object: 16.6220
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.54s
                      Time elapsed: 00:15:37
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 39816 steps/s (collection: 2.295s, learning 0.174s)
             Mean action noise std: 2.08
          Mean value_function loss: 34.0473
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 66.6706
                       Mean reward: 69.22
               Mean episode length: 229.45
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 14.1272
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.47s
                      Time elapsed: 00:15:40
                               ETA: 00:48:57

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 39252 steps/s (collection: 2.314s, learning 0.190s)
             Mean action noise std: 2.09
          Mean value_function loss: 37.2687
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 66.7053
                       Mean reward: 74.67
               Mean episode length: 228.06
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 15.1305
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.50s
                      Time elapsed: 00:15:42
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 42672 steps/s (collection: 2.145s, learning 0.159s)
             Mean action noise std: 2.09
          Mean value_function loss: 34.1754
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 66.7347
                       Mean reward: 59.59
               Mean episode length: 220.57
    Episode_Reward/reaching_object: 1.2053
    Episode_Reward/rotating_object: 15.3706
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.30s
                      Time elapsed: 00:15:45
                               ETA: 00:48:51

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 41789 steps/s (collection: 2.110s, learning 0.242s)
             Mean action noise std: 2.09
          Mean value_function loss: 37.3878
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 66.7598
                       Mean reward: 78.90
               Mean episode length: 222.51
    Episode_Reward/reaching_object: 1.2019
    Episode_Reward/rotating_object: 15.6603
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.35s
                      Time elapsed: 00:15:47
                               ETA: 00:48:47

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 42445 steps/s (collection: 2.120s, learning 0.196s)
             Mean action noise std: 2.09
          Mean value_function loss: 39.0660
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 66.7944
                       Mean reward: 82.55
               Mean episode length: 228.50
    Episode_Reward/reaching_object: 1.2262
    Episode_Reward/rotating_object: 16.6555
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.32s
                      Time elapsed: 00:15:49
                               ETA: 00:48:44

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 42804 steps/s (collection: 2.108s, learning 0.189s)
             Mean action noise std: 2.09
          Mean value_function loss: 36.1323
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 66.8205
                       Mean reward: 87.59
               Mean episode length: 230.18
    Episode_Reward/reaching_object: 1.2282
    Episode_Reward/rotating_object: 15.4408
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.30s
                      Time elapsed: 00:15:52
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 39838 steps/s (collection: 2.276s, learning 0.191s)
             Mean action noise std: 2.10
          Mean value_function loss: 37.0849
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 66.8446
                       Mean reward: 77.35
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.2165
    Episode_Reward/rotating_object: 15.7714
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.47s
                      Time elapsed: 00:15:54
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 42847 steps/s (collection: 2.095s, learning 0.199s)
             Mean action noise std: 2.10
          Mean value_function loss: 36.5944
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 66.8747
                       Mean reward: 102.12
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.2641
    Episode_Reward/rotating_object: 14.6398
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.29s
                      Time elapsed: 00:15:56
                               ETA: 00:48:34

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 40470 steps/s (collection: 2.198s, learning 0.231s)
             Mean action noise std: 2.10
          Mean value_function loss: 37.4988
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 66.9067
                       Mean reward: 85.40
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 16.7378
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.43s
                      Time elapsed: 00:15:59
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 41305 steps/s (collection: 2.182s, learning 0.198s)
             Mean action noise std: 2.10
          Mean value_function loss: 39.4690
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 66.9348
                       Mean reward: 104.94
               Mean episode length: 214.30
    Episode_Reward/reaching_object: 1.2489
    Episode_Reward/rotating_object: 18.9373
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.38s
                      Time elapsed: 00:16:01
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 41521 steps/s (collection: 2.218s, learning 0.149s)
             Mean action noise std: 2.10
          Mean value_function loss: 34.4323
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 66.9583
                       Mean reward: 96.43
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 1.2451
    Episode_Reward/rotating_object: 16.2495
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.37s
                      Time elapsed: 00:16:04
                               ETA: 00:48:25

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 44247 steps/s (collection: 2.100s, learning 0.122s)
             Mean action noise std: 2.11
          Mean value_function loss: 35.2285
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 66.9871
                       Mean reward: 73.19
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.2722
    Episode_Reward/rotating_object: 16.1171
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.22s
                      Time elapsed: 00:16:06
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 45974 steps/s (collection: 1.956s, learning 0.183s)
             Mean action noise std: 2.11
          Mean value_function loss: 35.1805
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 67.0130
                       Mean reward: 89.89
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.2930
    Episode_Reward/rotating_object: 17.8542
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.14s
                      Time elapsed: 00:16:08
                               ETA: 00:48:17

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 47450 steps/s (collection: 1.921s, learning 0.151s)
             Mean action noise std: 2.11
          Mean value_function loss: 38.0829
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 67.0383
                       Mean reward: 85.93
               Mean episode length: 226.98
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 18.5573
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.07s
                      Time elapsed: 00:16:10
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 46606 steps/s (collection: 1.971s, learning 0.138s)
             Mean action noise std: 2.11
          Mean value_function loss: 38.5601
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 67.0631
                       Mean reward: 78.29
               Mean episode length: 225.48
    Episode_Reward/reaching_object: 1.2531
    Episode_Reward/rotating_object: 15.3744
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.11s
                      Time elapsed: 00:16:12
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 44523 steps/s (collection: 2.029s, learning 0.179s)
             Mean action noise std: 2.11
          Mean value_function loss: 36.3121
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.0914
                       Mean reward: 84.70
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.2238
    Episode_Reward/rotating_object: 17.2594
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.21s
                      Time elapsed: 00:16:14
                               ETA: 00:48:05

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 47206 steps/s (collection: 1.954s, learning 0.128s)
             Mean action noise std: 2.11
          Mean value_function loss: 37.2509
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.1207
                       Mean reward: 92.95
               Mean episode length: 224.09
    Episode_Reward/reaching_object: 1.2524
    Episode_Reward/rotating_object: 17.8838
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.08s
                      Time elapsed: 00:16:16
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 47175 steps/s (collection: 1.966s, learning 0.118s)
             Mean action noise std: 2.12
          Mean value_function loss: 40.6727
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 67.1504
                       Mean reward: 99.18
               Mean episode length: 220.35
    Episode_Reward/reaching_object: 1.2321
    Episode_Reward/rotating_object: 17.0994
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.08s
                      Time elapsed: 00:16:19
                               ETA: 00:47:57

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 46879 steps/s (collection: 1.938s, learning 0.159s)
             Mean action noise std: 2.12
          Mean value_function loss: 40.3592
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 67.1757
                       Mean reward: 87.36
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.2798
    Episode_Reward/rotating_object: 16.9975
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.10s
                      Time elapsed: 00:16:21
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 45166 steps/s (collection: 2.016s, learning 0.160s)
             Mean action noise std: 2.12
          Mean value_function loss: 38.4880
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 67.2072
                       Mean reward: 109.58
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 1.2472
    Episode_Reward/rotating_object: 18.4785
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.18s
                      Time elapsed: 00:16:23
                               ETA: 00:47:50

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 48156 steps/s (collection: 1.908s, learning 0.134s)
             Mean action noise std: 2.12
          Mean value_function loss: 39.6601
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 67.2390
                       Mean reward: 81.25
               Mean episode length: 221.15
    Episode_Reward/reaching_object: 1.2452
    Episode_Reward/rotating_object: 16.8735
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.04s
                      Time elapsed: 00:16:25
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 45688 steps/s (collection: 1.969s, learning 0.183s)
             Mean action noise std: 2.12
          Mean value_function loss: 32.6830
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.2667
                       Mean reward: 84.93
               Mean episode length: 223.32
    Episode_Reward/reaching_object: 1.2628
    Episode_Reward/rotating_object: 19.7256
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.15s
                      Time elapsed: 00:16:27
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 46540 steps/s (collection: 1.970s, learning 0.143s)
             Mean action noise std: 2.13
          Mean value_function loss: 33.6723
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 67.3032
                       Mean reward: 111.40
               Mean episode length: 215.28
    Episode_Reward/reaching_object: 1.2260
    Episode_Reward/rotating_object: 19.4409
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.11s
                      Time elapsed: 00:16:29
                               ETA: 00:47:38

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 46591 steps/s (collection: 2.006s, learning 0.104s)
             Mean action noise std: 2.13
          Mean value_function loss: 41.5452
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 67.3351
                       Mean reward: 106.88
               Mean episode length: 222.08
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 19.8568
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.11s
                      Time elapsed: 00:16:31
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 42573 steps/s (collection: 2.190s, learning 0.119s)
             Mean action noise std: 2.13
          Mean value_function loss: 37.9126
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 67.3650
                       Mean reward: 99.71
               Mean episode length: 225.18
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 17.5417
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.31s
                      Time elapsed: 00:16:34
                               ETA: 00:47:31

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 47770 steps/s (collection: 1.942s, learning 0.116s)
             Mean action noise std: 2.13
          Mean value_function loss: 36.5274
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.3901
                       Mean reward: 114.45
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 1.2619
    Episode_Reward/rotating_object: 17.9088
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.06s
                      Time elapsed: 00:16:36
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 46894 steps/s (collection: 1.939s, learning 0.157s)
             Mean action noise std: 2.13
          Mean value_function loss: 33.9972
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.4116
                       Mean reward: 90.39
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.2780
    Episode_Reward/rotating_object: 18.3523
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.10s
                      Time elapsed: 00:16:38
                               ETA: 00:47:23

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 46710 steps/s (collection: 1.964s, learning 0.140s)
             Mean action noise std: 2.14
          Mean value_function loss: 38.1104
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 67.4541
                       Mean reward: 96.51
               Mean episode length: 225.68
    Episode_Reward/reaching_object: 1.2636
    Episode_Reward/rotating_object: 21.2713
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.10s
                      Time elapsed: 00:16:40
                               ETA: 00:47:19

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 45834 steps/s (collection: 1.952s, learning 0.193s)
             Mean action noise std: 2.14
          Mean value_function loss: 36.1042
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 67.4866
                       Mean reward: 99.92
               Mean episode length: 221.39
    Episode_Reward/reaching_object: 1.2765
    Episode_Reward/rotating_object: 17.9310
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.14s
                      Time elapsed: 00:16:42
                               ETA: 00:47:15

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 45358 steps/s (collection: 1.993s, learning 0.174s)
             Mean action noise std: 2.14
          Mean value_function loss: 44.1912
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 67.5118
                       Mean reward: 84.06
               Mean episode length: 215.88
    Episode_Reward/reaching_object: 1.2700
    Episode_Reward/rotating_object: 19.6251
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.17s
                      Time elapsed: 00:16:44
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 48177 steps/s (collection: 1.930s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 40.6472
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 67.5345
                       Mean reward: 86.00
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 1.2848
    Episode_Reward/rotating_object: 17.4643
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.04s
                      Time elapsed: 00:16:46
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 44006 steps/s (collection: 2.080s, learning 0.154s)
             Mean action noise std: 2.15
          Mean value_function loss: 45.7138
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 67.5658
                       Mean reward: 97.21
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 1.2764
    Episode_Reward/rotating_object: 17.9214
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.23s
                      Time elapsed: 00:16:48
                               ETA: 00:47:04

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 45903 steps/s (collection: 2.032s, learning 0.110s)
             Mean action noise std: 2.15
          Mean value_function loss: 44.1763
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 67.5995
                       Mean reward: 105.08
               Mean episode length: 223.86
    Episode_Reward/reaching_object: 1.2956
    Episode_Reward/rotating_object: 19.1016
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.14s
                      Time elapsed: 00:16:51
                               ETA: 00:47:01

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 43767 steps/s (collection: 2.031s, learning 0.215s)
             Mean action noise std: 2.15
          Mean value_function loss: 47.6204
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.6334
                       Mean reward: 92.46
               Mean episode length: 226.60
    Episode_Reward/reaching_object: 1.2854
    Episode_Reward/rotating_object: 17.5106
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.25s
                      Time elapsed: 00:16:53
                               ETA: 00:46:57

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 42962 steps/s (collection: 2.122s, learning 0.167s)
             Mean action noise std: 2.15
          Mean value_function loss: 35.4267
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 67.6689
                       Mean reward: 93.18
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.2801
    Episode_Reward/rotating_object: 19.3551
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.29s
                      Time elapsed: 00:16:55
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 46229 steps/s (collection: 1.949s, learning 0.178s)
             Mean action noise std: 2.16
          Mean value_function loss: 40.2649
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 67.7020
                       Mean reward: 97.06
               Mean episode length: 225.69
    Episode_Reward/reaching_object: 1.3017
    Episode_Reward/rotating_object: 18.7039
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.13s
                      Time elapsed: 00:16:57
                               ETA: 00:46:50

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 46567 steps/s (collection: 1.992s, learning 0.119s)
             Mean action noise std: 2.16
          Mean value_function loss: 36.7854
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 67.7352
                       Mean reward: 101.42
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.3106
    Episode_Reward/rotating_object: 19.8313
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.11s
                      Time elapsed: 00:16:59
                               ETA: 00:46:46

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 48245 steps/s (collection: 1.911s, learning 0.126s)
             Mean action noise std: 2.16
          Mean value_function loss: 44.9023
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 67.7705
                       Mean reward: 122.01
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.2719
    Episode_Reward/rotating_object: 19.6882
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.04s
                      Time elapsed: 00:17:01
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 45612 steps/s (collection: 2.007s, learning 0.149s)
             Mean action noise std: 2.16
          Mean value_function loss: 37.9392
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.8002
                       Mean reward: 106.91
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.3200
    Episode_Reward/rotating_object: 21.8417
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.16s
                      Time elapsed: 00:17:03
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 46168 steps/s (collection: 2.021s, learning 0.108s)
             Mean action noise std: 2.16
          Mean value_function loss: 40.7798
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.8261
                       Mean reward: 91.74
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.3179
    Episode_Reward/rotating_object: 20.5354
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.13s
                      Time elapsed: 00:17:06
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 46531 steps/s (collection: 1.949s, learning 0.164s)
             Mean action noise std: 2.17
          Mean value_function loss: 40.7741
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.8568
                       Mean reward: 126.25
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.2856
    Episode_Reward/rotating_object: 22.9197
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.11s
                      Time elapsed: 00:17:08
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 48944 steps/s (collection: 1.900s, learning 0.108s)
             Mean action noise std: 2.17
          Mean value_function loss: 40.8018
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 67.8976
                       Mean reward: 118.58
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.2993
    Episode_Reward/rotating_object: 22.9915
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.01s
                      Time elapsed: 00:17:10
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 48861 steps/s (collection: 1.894s, learning 0.118s)
             Mean action noise std: 2.17
          Mean value_function loss: 40.6556
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 67.9264
                       Mean reward: 122.22
               Mean episode length: 222.24
    Episode_Reward/reaching_object: 1.2820
    Episode_Reward/rotating_object: 21.7130
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.01s
                      Time elapsed: 00:17:12
                               ETA: 00:46:23

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 42490 steps/s (collection: 2.204s, learning 0.110s)
             Mean action noise std: 2.17
          Mean value_function loss: 48.0915
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 67.9517
                       Mean reward: 114.75
               Mean episode length: 220.32
    Episode_Reward/reaching_object: 1.2789
    Episode_Reward/rotating_object: 21.7053
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.31s
                      Time elapsed: 00:17:14
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 45135 steps/s (collection: 2.019s, learning 0.159s)
             Mean action noise std: 2.17
          Mean value_function loss: 43.7366
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 67.9776
                       Mean reward: 87.69
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 1.3350
    Episode_Reward/rotating_object: 21.2145
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.18s
                      Time elapsed: 00:17:16
                               ETA: 00:46:17

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 44442 steps/s (collection: 2.077s, learning 0.135s)
             Mean action noise std: 2.18
          Mean value_function loss: 40.4807
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 68.0029
                       Mean reward: 112.47
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 1.2843
    Episode_Reward/rotating_object: 21.2779
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.21s
                      Time elapsed: 00:17:18
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 45759 steps/s (collection: 1.999s, learning 0.150s)
             Mean action noise std: 2.18
          Mean value_function loss: 48.3969
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.0336
                       Mean reward: 107.31
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.2996
    Episode_Reward/rotating_object: 21.7000
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.15s
                      Time elapsed: 00:17:21
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 44469 steps/s (collection: 2.079s, learning 0.132s)
             Mean action noise std: 2.18
          Mean value_function loss: 45.7985
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.0651
                       Mean reward: 115.91
               Mean episode length: 230.07
    Episode_Reward/reaching_object: 1.2943
    Episode_Reward/rotating_object: 24.0996
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.21s
                      Time elapsed: 00:17:23
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 46092 steps/s (collection: 1.974s, learning 0.159s)
             Mean action noise std: 2.18
          Mean value_function loss: 41.1132
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 68.0960
                       Mean reward: 95.36
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.3055
    Episode_Reward/rotating_object: 22.8271
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.13s
                      Time elapsed: 00:17:25
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 45456 steps/s (collection: 1.983s, learning 0.179s)
             Mean action noise std: 2.19
          Mean value_function loss: 41.5317
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 68.1273
                       Mean reward: 134.92
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 1.2977
    Episode_Reward/rotating_object: 21.0521
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.16s
                      Time elapsed: 00:17:27
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 41811 steps/s (collection: 2.212s, learning 0.139s)
             Mean action noise std: 2.19
          Mean value_function loss: 37.0023
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 68.1570
                       Mean reward: 120.96
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 1.2581
    Episode_Reward/rotating_object: 20.0356
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.35s
                      Time elapsed: 00:17:29
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 45050 steps/s (collection: 2.016s, learning 0.166s)
             Mean action noise std: 2.19
          Mean value_function loss: 42.9181
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 68.1886
                       Mean reward: 116.99
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.2953
    Episode_Reward/rotating_object: 21.5789
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.18s
                      Time elapsed: 00:17:32
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 37865 steps/s (collection: 2.439s, learning 0.158s)
             Mean action noise std: 2.19
          Mean value_function loss: 39.4170
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 68.2224
                       Mean reward: 130.97
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.3139
    Episode_Reward/rotating_object: 25.1898
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.60s
                      Time elapsed: 00:17:34
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 46750 steps/s (collection: 1.997s, learning 0.106s)
             Mean action noise std: 2.19
          Mean value_function loss: 41.1608
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 68.2530
                       Mean reward: 145.05
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 1.2894
    Episode_Reward/rotating_object: 24.9181
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.10s
                      Time elapsed: 00:17:36
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 46338 steps/s (collection: 2.015s, learning 0.106s)
             Mean action noise std: 2.20
          Mean value_function loss: 54.4684
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 68.2789
                       Mean reward: 113.22
               Mean episode length: 223.71
    Episode_Reward/reaching_object: 1.2622
    Episode_Reward/rotating_object: 22.3639
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.12s
                      Time elapsed: 00:17:38
                               ETA: 00:45:43

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 43429 steps/s (collection: 2.111s, learning 0.152s)
             Mean action noise std: 2.20
          Mean value_function loss: 40.7457
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 68.3120
                       Mean reward: 115.64
               Mean episode length: 225.75
    Episode_Reward/reaching_object: 1.2725
    Episode_Reward/rotating_object: 22.2864
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.26s
                      Time elapsed: 00:17:41
                               ETA: 00:45:40

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 45085 steps/s (collection: 2.030s, learning 0.150s)
             Mean action noise std: 2.20
          Mean value_function loss: 43.0612
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 68.3484
                       Mean reward: 130.83
               Mean episode length: 214.62
    Episode_Reward/reaching_object: 1.3075
    Episode_Reward/rotating_object: 23.8477
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.18s
                      Time elapsed: 00:17:43
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 44823 steps/s (collection: 2.093s, learning 0.100s)
             Mean action noise std: 2.20
          Mean value_function loss: 43.5930
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.3899
                       Mean reward: 108.27
               Mean episode length: 224.67
    Episode_Reward/reaching_object: 1.3003
    Episode_Reward/rotating_object: 22.0854
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.19s
                      Time elapsed: 00:17:45
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 45428 steps/s (collection: 1.981s, learning 0.183s)
             Mean action noise std: 2.21
          Mean value_function loss: 41.9757
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 68.4288
                       Mean reward: 134.52
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 1.3003
    Episode_Reward/rotating_object: 23.3899
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.16s
                      Time elapsed: 00:17:47
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 45530 steps/s (collection: 2.027s, learning 0.132s)
             Mean action noise std: 2.21
          Mean value_function loss: 35.0434
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.4624
                       Mean reward: 129.89
               Mean episode length: 224.68
    Episode_Reward/reaching_object: 1.3065
    Episode_Reward/rotating_object: 24.1273
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.16s
                      Time elapsed: 00:17:49
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 47216 steps/s (collection: 1.933s, learning 0.149s)
             Mean action noise std: 2.21
          Mean value_function loss: 43.1604
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 68.4959
                       Mean reward: 105.59
               Mean episode length: 224.09
    Episode_Reward/reaching_object: 1.2904
    Episode_Reward/rotating_object: 22.1421
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.08s
                      Time elapsed: 00:17:51
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 47722 steps/s (collection: 1.912s, learning 0.148s)
             Mean action noise std: 2.21
          Mean value_function loss: 45.5925
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 68.5186
                       Mean reward: 115.93
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 1.3341
    Episode_Reward/rotating_object: 22.7711
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.06s
                      Time elapsed: 00:17:54
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 46742 steps/s (collection: 1.965s, learning 0.138s)
             Mean action noise std: 2.22
          Mean value_function loss: 42.3430
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.5486
                       Mean reward: 108.31
               Mean episode length: 212.20
    Episode_Reward/reaching_object: 1.3115
    Episode_Reward/rotating_object: 21.9489
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.10s
                      Time elapsed: 00:17:56
                               ETA: 00:45:15

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 45457 steps/s (collection: 2.038s, learning 0.125s)
             Mean action noise std: 2.22
          Mean value_function loss: 39.3707
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 68.5784
                       Mean reward: 115.92
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 1.2878
    Episode_Reward/rotating_object: 22.1214
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.16s
                      Time elapsed: 00:17:58
                               ETA: 00:45:12

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 46726 steps/s (collection: 1.986s, learning 0.118s)
             Mean action noise std: 2.22
          Mean value_function loss: 43.5491
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 68.6025
                       Mean reward: 96.14
               Mean episode length: 211.37
    Episode_Reward/reaching_object: 1.2642
    Episode_Reward/rotating_object: 21.3584
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.10s
                      Time elapsed: 00:18:00
                               ETA: 00:45:08

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 45072 steps/s (collection: 1.988s, learning 0.193s)
             Mean action noise std: 2.22
          Mean value_function loss: 44.7139
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 68.6355
                       Mean reward: 105.34
               Mean episode length: 213.30
    Episode_Reward/reaching_object: 1.2680
    Episode_Reward/rotating_object: 20.3417
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.18s
                      Time elapsed: 00:18:02
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 47126 steps/s (collection: 1.994s, learning 0.092s)
             Mean action noise std: 2.22
          Mean value_function loss: 45.2411
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 68.6681
                       Mean reward: 174.77
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.3383
    Episode_Reward/rotating_object: 26.7262
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.09s
                      Time elapsed: 00:18:04
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 46734 steps/s (collection: 1.951s, learning 0.153s)
             Mean action noise std: 2.23
          Mean value_function loss: 49.4190
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 68.6956
                       Mean reward: 125.33
               Mean episode length: 221.87
    Episode_Reward/reaching_object: 1.3120
    Episode_Reward/rotating_object: 22.8009
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.10s
                      Time elapsed: 00:18:06
                               ETA: 00:44:58

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 46469 steps/s (collection: 1.971s, learning 0.145s)
             Mean action noise std: 2.23
          Mean value_function loss: 45.3098
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 68.7269
                       Mean reward: 102.89
               Mean episode length: 218.37
    Episode_Reward/reaching_object: 1.3097
    Episode_Reward/rotating_object: 22.0255
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.12s
                      Time elapsed: 00:18:08
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 45566 steps/s (collection: 2.015s, learning 0.142s)
             Mean action noise std: 2.23
          Mean value_function loss: 43.4038
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 68.7573
                       Mean reward: 129.95
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 1.3169
    Episode_Reward/rotating_object: 23.8587
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.16s
                      Time elapsed: 00:18:11
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 46732 steps/s (collection: 1.958s, learning 0.146s)
             Mean action noise std: 2.23
          Mean value_function loss: 42.0845
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 68.7907
                       Mean reward: 137.06
               Mean episode length: 228.11
    Episode_Reward/reaching_object: 1.3122
    Episode_Reward/rotating_object: 24.0879
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.10s
                      Time elapsed: 00:18:13
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 46952 steps/s (collection: 1.992s, learning 0.102s)
             Mean action noise std: 2.23
          Mean value_function loss: 41.8485
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 68.8121
                       Mean reward: 143.20
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 1.3180
    Episode_Reward/rotating_object: 21.9544
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.09s
                      Time elapsed: 00:18:15
                               ETA: 00:44:43

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 46303 steps/s (collection: 1.999s, learning 0.124s)
             Mean action noise std: 2.24
          Mean value_function loss: 38.8022
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 68.8400
                       Mean reward: 111.54
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.3495
    Episode_Reward/rotating_object: 24.1486
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.12s
                      Time elapsed: 00:18:17
                               ETA: 00:44:40

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 46591 steps/s (collection: 1.987s, learning 0.123s)
             Mean action noise std: 2.24
          Mean value_function loss: 49.5120
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.8607
                       Mean reward: 101.13
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 1.3381
    Episode_Reward/rotating_object: 22.7559
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.11s
                      Time elapsed: 00:18:19
                               ETA: 00:44:37

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 45350 steps/s (collection: 2.008s, learning 0.160s)
             Mean action noise std: 2.24
          Mean value_function loss: 48.3664
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 68.8831
                       Mean reward: 133.75
               Mean episode length: 224.53
    Episode_Reward/reaching_object: 1.3049
    Episode_Reward/rotating_object: 21.9063
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.17s
                      Time elapsed: 00:18:21
                               ETA: 00:44:33

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 47273 steps/s (collection: 1.933s, learning 0.147s)
             Mean action noise std: 2.24
          Mean value_function loss: 39.0638
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 68.9104
                       Mean reward: 129.02
               Mean episode length: 216.24
    Episode_Reward/reaching_object: 1.2877
    Episode_Reward/rotating_object: 23.5305
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.08s
                      Time elapsed: 00:18:23
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 45119 steps/s (collection: 1.975s, learning 0.204s)
             Mean action noise std: 2.24
          Mean value_function loss: 45.3244
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 68.9443
                       Mean reward: 111.42
               Mean episode length: 223.08
    Episode_Reward/reaching_object: 1.3160
    Episode_Reward/rotating_object: 23.1341
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.18s
                      Time elapsed: 00:18:25
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 45764 steps/s (collection: 2.021s, learning 0.127s)
             Mean action noise std: 2.25
          Mean value_function loss: 48.6264
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 68.9723
                       Mean reward: 137.69
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.3189
    Episode_Reward/rotating_object: 22.7730
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.15s
                      Time elapsed: 00:18:28
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 44436 steps/s (collection: 2.084s, learning 0.128s)
             Mean action noise std: 2.25
          Mean value_function loss: 45.7880
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 69.0066
                       Mean reward: 117.68
               Mean episode length: 224.85
    Episode_Reward/reaching_object: 1.3256
    Episode_Reward/rotating_object: 23.6402
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.21s
                      Time elapsed: 00:18:30
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 47455 steps/s (collection: 1.965s, learning 0.106s)
             Mean action noise std: 2.25
          Mean value_function loss: 47.4142
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 69.0351
                       Mean reward: 120.22
               Mean episode length: 222.36
    Episode_Reward/reaching_object: 1.3017
    Episode_Reward/rotating_object: 22.5801
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.07s
                      Time elapsed: 00:18:32
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 45754 steps/s (collection: 2.043s, learning 0.105s)
             Mean action noise std: 2.25
          Mean value_function loss: 51.0615
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 69.0594
                       Mean reward: 124.47
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.2820
    Episode_Reward/rotating_object: 23.9411
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.15s
                      Time elapsed: 00:18:34
                               ETA: 00:44:13

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 47306 steps/s (collection: 1.948s, learning 0.130s)
             Mean action noise std: 2.25
          Mean value_function loss: 53.4494
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 69.0824
                       Mean reward: 114.75
               Mean episode length: 219.44
    Episode_Reward/reaching_object: 1.2895
    Episode_Reward/rotating_object: 23.6281
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.08s
                      Time elapsed: 00:18:36
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 45355 steps/s (collection: 2.041s, learning 0.126s)
             Mean action noise std: 2.26
          Mean value_function loss: 57.6330
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 69.1093
                       Mean reward: 156.67
               Mean episode length: 218.37
    Episode_Reward/reaching_object: 1.2913
    Episode_Reward/rotating_object: 25.3801
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.17s
                      Time elapsed: 00:18:38
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 46656 steps/s (collection: 1.947s, learning 0.160s)
             Mean action noise std: 2.26
          Mean value_function loss: 40.9655
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 69.1407
                       Mean reward: 119.56
               Mean episode length: 220.77
    Episode_Reward/reaching_object: 1.2755
    Episode_Reward/rotating_object: 23.4803
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.11s
                      Time elapsed: 00:18:40
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 44223 steps/s (collection: 2.016s, learning 0.207s)
             Mean action noise std: 2.26
          Mean value_function loss: 43.0268
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 69.1649
                       Mean reward: 151.08
               Mean episode length: 226.00
    Episode_Reward/reaching_object: 1.2818
    Episode_Reward/rotating_object: 25.9569
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.22s
                      Time elapsed: 00:18:43
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 42471 steps/s (collection: 2.126s, learning 0.188s)
             Mean action noise std: 2.26
          Mean value_function loss: 48.9674
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 69.1881
                       Mean reward: 130.18
               Mean episode length: 211.40
    Episode_Reward/reaching_object: 1.3072
    Episode_Reward/rotating_object: 26.7870
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.31s
                      Time elapsed: 00:18:45
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 45110 steps/s (collection: 2.052s, learning 0.127s)
             Mean action noise std: 2.26
          Mean value_function loss: 39.2138
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 69.2075
                       Mean reward: 153.75
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.3000
    Episode_Reward/rotating_object: 24.8760
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.18s
                      Time elapsed: 00:18:47
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 46070 steps/s (collection: 1.987s, learning 0.146s)
             Mean action noise std: 2.27
          Mean value_function loss: 42.1023
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 69.2348
                       Mean reward: 127.22
               Mean episode length: 226.64
    Episode_Reward/reaching_object: 1.3103
    Episode_Reward/rotating_object: 25.0838
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.13s
                      Time elapsed: 00:18:49
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 46112 steps/s (collection: 1.972s, learning 0.159s)
             Mean action noise std: 2.27
          Mean value_function loss: 45.7798
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 69.2647
                       Mean reward: 139.43
               Mean episode length: 212.44
    Episode_Reward/reaching_object: 1.2471
    Episode_Reward/rotating_object: 25.9569
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.13s
                      Time elapsed: 00:18:51
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 44949 steps/s (collection: 2.055s, learning 0.132s)
             Mean action noise std: 2.27
          Mean value_function loss: 51.2115
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 69.2903
                       Mean reward: 105.13
               Mean episode length: 220.54
    Episode_Reward/reaching_object: 1.3401
    Episode_Reward/rotating_object: 23.0838
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.19s
                      Time elapsed: 00:18:54
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 46416 steps/s (collection: 2.013s, learning 0.105s)
             Mean action noise std: 2.27
          Mean value_function loss: 47.0973
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 69.3206
                       Mean reward: 156.02
               Mean episode length: 220.90
    Episode_Reward/reaching_object: 1.3030
    Episode_Reward/rotating_object: 27.6930
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.12s
                      Time elapsed: 00:18:56
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 47963 steps/s (collection: 1.924s, learning 0.126s)
             Mean action noise std: 2.27
          Mean value_function loss: 45.9914
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 69.3400
                       Mean reward: 126.22
               Mean episode length: 229.90
    Episode_Reward/reaching_object: 1.3043
    Episode_Reward/rotating_object: 25.1279
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.05s
                      Time elapsed: 00:18:58
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 48217 steps/s (collection: 1.912s, learning 0.127s)
             Mean action noise std: 2.27
          Mean value_function loss: 45.5625
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 69.3660
                       Mean reward: 119.13
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 1.3261
    Episode_Reward/rotating_object: 24.5281
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.04s
                      Time elapsed: 00:19:00
                               ETA: 00:43:33

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 46322 steps/s (collection: 1.971s, learning 0.151s)
             Mean action noise std: 2.28
          Mean value_function loss: 43.4803
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 69.3926
                       Mean reward: 145.27
               Mean episode length: 218.66
    Episode_Reward/reaching_object: 1.2895
    Episode_Reward/rotating_object: 23.5948
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.12s
                      Time elapsed: 00:19:02
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 47356 steps/s (collection: 1.928s, learning 0.148s)
             Mean action noise std: 2.28
          Mean value_function loss: 45.2652
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 69.4202
                       Mean reward: 129.32
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.3184
    Episode_Reward/rotating_object: 26.5468
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.08s
                      Time elapsed: 00:19:04
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 46586 steps/s (collection: 1.969s, learning 0.142s)
             Mean action noise std: 2.28
          Mean value_function loss: 47.7107
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 69.4486
                       Mean reward: 133.31
               Mean episode length: 221.63
    Episode_Reward/reaching_object: 1.2994
    Episode_Reward/rotating_object: 24.3606
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.11s
                      Time elapsed: 00:19:06
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 45104 steps/s (collection: 2.021s, learning 0.159s)
             Mean action noise std: 2.28
          Mean value_function loss: 50.0731
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 69.4774
                       Mean reward: 147.53
               Mean episode length: 228.18
    Episode_Reward/reaching_object: 1.3005
    Episode_Reward/rotating_object: 26.6612
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.18s
                      Time elapsed: 00:19:08
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 45913 steps/s (collection: 1.977s, learning 0.164s)
             Mean action noise std: 2.28
          Mean value_function loss: 51.1379
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 69.5031
                       Mean reward: 126.42
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.3555
    Episode_Reward/rotating_object: 27.1323
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.14s
                      Time elapsed: 00:19:10
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 47225 steps/s (collection: 1.914s, learning 0.168s)
             Mean action noise std: 2.29
          Mean value_function loss: 45.7530
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 69.5282
                       Mean reward: 133.86
               Mean episode length: 220.41
    Episode_Reward/reaching_object: 1.2900
    Episode_Reward/rotating_object: 26.1632
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.08s
                      Time elapsed: 00:19:12
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 47784 steps/s (collection: 1.951s, learning 0.107s)
             Mean action noise std: 2.29
          Mean value_function loss: 47.3415
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 69.5542
                       Mean reward: 125.15
               Mean episode length: 227.27
    Episode_Reward/reaching_object: 1.3096
    Episode_Reward/rotating_object: 25.9566
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.06s
                      Time elapsed: 00:19:14
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 44889 steps/s (collection: 2.041s, learning 0.149s)
             Mean action noise std: 2.29
          Mean value_function loss: 49.6356
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 69.5704
                       Mean reward: 153.33
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.3092
    Episode_Reward/rotating_object: 26.6540
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.19s
                      Time elapsed: 00:19:17
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 46946 steps/s (collection: 1.956s, learning 0.138s)
             Mean action noise std: 2.29
          Mean value_function loss: 44.2157
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 69.5964
                       Mean reward: 147.64
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.3211
    Episode_Reward/rotating_object: 27.6627
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.09s
                      Time elapsed: 00:19:19
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 45062 steps/s (collection: 2.004s, learning 0.177s)
             Mean action noise std: 2.29
          Mean value_function loss: 54.5748
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 69.6240
                       Mean reward: 131.69
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.3137
    Episode_Reward/rotating_object: 27.0118
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.18s
                      Time elapsed: 00:19:21
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 46650 steps/s (collection: 1.954s, learning 0.154s)
             Mean action noise std: 2.30
          Mean value_function loss: 47.3004
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 69.6465
                       Mean reward: 174.06
               Mean episode length: 222.85
    Episode_Reward/reaching_object: 1.3025
    Episode_Reward/rotating_object: 27.7869
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.11s
                      Time elapsed: 00:19:23
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 48791 steps/s (collection: 1.894s, learning 0.121s)
             Mean action noise std: 2.30
          Mean value_function loss: 49.0534
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.6662
                       Mean reward: 142.51
               Mean episode length: 229.91
    Episode_Reward/reaching_object: 1.3232
    Episode_Reward/rotating_object: 25.5872
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.01s
                      Time elapsed: 00:19:25
                               ETA: 00:42:52

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 46801 steps/s (collection: 1.941s, learning 0.159s)
             Mean action noise std: 2.30
          Mean value_function loss: 47.5342
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 69.6931
                       Mean reward: 151.27
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.2991
    Episode_Reward/rotating_object: 27.5370
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.10s
                      Time elapsed: 00:19:27
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 45473 steps/s (collection: 2.038s, learning 0.124s)
             Mean action noise std: 2.30
          Mean value_function loss: 45.7332
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 69.7215
                       Mean reward: 143.64
               Mean episode length: 224.10
    Episode_Reward/reaching_object: 1.3021
    Episode_Reward/rotating_object: 28.4166
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.16s
                      Time elapsed: 00:19:29
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 46006 steps/s (collection: 1.966s, learning 0.171s)
             Mean action noise std: 2.30
          Mean value_function loss: 45.0177
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 69.7502
                       Mean reward: 108.56
               Mean episode length: 224.20
    Episode_Reward/reaching_object: 1.3210
    Episode_Reward/rotating_object: 26.6619
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.14s
                      Time elapsed: 00:19:31
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 43823 steps/s (collection: 2.073s, learning 0.171s)
             Mean action noise std: 2.31
          Mean value_function loss: 48.8738
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 69.7812
                       Mean reward: 137.62
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.3207
    Episode_Reward/rotating_object: 28.4175
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.24s
                      Time elapsed: 00:19:34
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 46404 steps/s (collection: 1.986s, learning 0.133s)
             Mean action noise std: 2.31
          Mean value_function loss: 52.8956
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 69.8081
                       Mean reward: 169.92
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.3330
    Episode_Reward/rotating_object: 28.9347
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0543
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.12s
                      Time elapsed: 00:19:36
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 46933 steps/s (collection: 1.975s, learning 0.120s)
             Mean action noise std: 2.31
          Mean value_function loss: 47.8024
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 69.8448
                       Mean reward: 153.25
               Mean episode length: 224.83
    Episode_Reward/reaching_object: 1.2804
    Episode_Reward/rotating_object: 27.5619
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.09s
                      Time elapsed: 00:19:38
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 45787 steps/s (collection: 2.043s, learning 0.104s)
             Mean action noise std: 2.31
          Mean value_function loss: 46.3004
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 69.8756
                       Mean reward: 166.51
               Mean episode length: 231.94
    Episode_Reward/reaching_object: 1.2896
    Episode_Reward/rotating_object: 29.2127
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.15s
                      Time elapsed: 00:19:40
                               ETA: 00:42:30

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 46505 steps/s (collection: 1.991s, learning 0.123s)
             Mean action noise std: 2.32
          Mean value_function loss: 43.7679
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 69.9113
                       Mean reward: 162.62
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.2506
    Episode_Reward/rotating_object: 28.7874
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.11s
                      Time elapsed: 00:19:42
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 47771 steps/s (collection: 1.942s, learning 0.116s)
             Mean action noise std: 2.32
          Mean value_function loss: 43.3301
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 69.9409
                       Mean reward: 161.06
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.2896
    Episode_Reward/rotating_object: 29.1354
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.06s
                      Time elapsed: 00:19:44
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 48580 steps/s (collection: 1.890s, learning 0.133s)
             Mean action noise std: 2.32
          Mean value_function loss: 50.4411
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 69.9671
                       Mean reward: 108.88
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.2966
    Episode_Reward/rotating_object: 29.9016
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.02s
                      Time elapsed: 00:19:46
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 46441 steps/s (collection: 2.010s, learning 0.107s)
             Mean action noise std: 2.32
          Mean value_function loss: 42.9883
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 69.9958
                       Mean reward: 134.00
               Mean episode length: 226.79
    Episode_Reward/reaching_object: 1.2716
    Episode_Reward/rotating_object: 27.0840
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.12s
                      Time elapsed: 00:19:48
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 46277 steps/s (collection: 1.982s, learning 0.143s)
             Mean action noise std: 2.32
          Mean value_function loss: 45.2529
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.0220
                       Mean reward: 149.35
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 1.2791
    Episode_Reward/rotating_object: 29.7458
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.12s
                      Time elapsed: 00:19:51
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 44347 steps/s (collection: 2.055s, learning 0.162s)
             Mean action noise std: 2.33
          Mean value_function loss: 41.7329
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 70.0492
                       Mean reward: 144.33
               Mean episode length: 224.11
    Episode_Reward/reaching_object: 1.2826
    Episode_Reward/rotating_object: 27.7433
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.22s
                      Time elapsed: 00:19:53
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 48597 steps/s (collection: 1.906s, learning 0.117s)
             Mean action noise std: 2.33
          Mean value_function loss: 49.8953
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 70.0698
                       Mean reward: 175.80
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 1.2701
    Episode_Reward/rotating_object: 28.7287
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.02s
                      Time elapsed: 00:19:55
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 45016 steps/s (collection: 2.046s, learning 0.138s)
             Mean action noise std: 2.33
          Mean value_function loss: 40.8785
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 70.0974
                       Mean reward: 136.12
               Mean episode length: 213.62
    Episode_Reward/reaching_object: 1.2783
    Episode_Reward/rotating_object: 26.7345
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0543
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.18s
                      Time elapsed: 00:19:57
                               ETA: 00:42:03

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 41621 steps/s (collection: 2.207s, learning 0.155s)
             Mean action noise std: 2.33
          Mean value_function loss: 47.9950
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 70.1285
                       Mean reward: 203.58
               Mean episode length: 226.10
    Episode_Reward/reaching_object: 1.2669
    Episode_Reward/rotating_object: 27.9514
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.36s
                      Time elapsed: 00:19:59
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 41508 steps/s (collection: 2.241s, learning 0.128s)
             Mean action noise std: 2.33
          Mean value_function loss: 44.6792
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 70.1628
                       Mean reward: 134.61
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.2885
    Episode_Reward/rotating_object: 25.9290
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.37s
                      Time elapsed: 00:20:02
                               ETA: 00:41:58

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 43620 steps/s (collection: 2.140s, learning 0.114s)
             Mean action noise std: 2.34
          Mean value_function loss: 41.4756
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 70.1858
                       Mean reward: 177.66
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.3289
    Episode_Reward/rotating_object: 28.7738
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.25s
                      Time elapsed: 00:20:04
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 44634 steps/s (collection: 2.054s, learning 0.149s)
             Mean action noise std: 2.34
          Mean value_function loss: 46.1964
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 70.2161
                       Mean reward: 140.83
               Mean episode length: 222.28
    Episode_Reward/reaching_object: 1.2683
    Episode_Reward/rotating_object: 29.3933
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.20s
                      Time elapsed: 00:20:06
                               ETA: 00:41:52

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 45781 steps/s (collection: 1.990s, learning 0.157s)
             Mean action noise std: 2.34
          Mean value_function loss: 47.4164
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 70.2487
                       Mean reward: 142.17
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.2961
    Episode_Reward/rotating_object: 29.1484
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.15s
                      Time elapsed: 00:20:08
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 42510 steps/s (collection: 2.139s, learning 0.174s)
             Mean action noise std: 2.34
          Mean value_function loss: 46.8336
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 70.2753
                       Mean reward: 174.80
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.2951
    Episode_Reward/rotating_object: 30.3657
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.31s
                      Time elapsed: 00:20:11
                               ETA: 00:41:46

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 44398 steps/s (collection: 2.084s, learning 0.130s)
             Mean action noise std: 2.35
          Mean value_function loss: 50.5125
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 70.3037
                       Mean reward: 160.53
               Mean episode length: 227.92
    Episode_Reward/reaching_object: 1.2998
    Episode_Reward/rotating_object: 28.0285
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.21s
                      Time elapsed: 00:20:13
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 46327 steps/s (collection: 1.978s, learning 0.144s)
             Mean action noise std: 2.35
          Mean value_function loss: 55.3882
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 70.3398
                       Mean reward: 176.16
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 1.3529
    Episode_Reward/rotating_object: 30.7945
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.12s
                      Time elapsed: 00:20:15
                               ETA: 00:41:40

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 45371 steps/s (collection: 2.016s, learning 0.151s)
             Mean action noise std: 2.35
          Mean value_function loss: 44.2240
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 70.3750
                       Mean reward: 131.05
               Mean episode length: 229.98
    Episode_Reward/reaching_object: 1.3053
    Episode_Reward/rotating_object: 26.6290
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.17s
                      Time elapsed: 00:20:17
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 44388 steps/s (collection: 2.079s, learning 0.136s)
             Mean action noise std: 2.35
          Mean value_function loss: 56.5972
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 70.4078
                       Mean reward: 130.56
               Mean episode length: 228.62
    Episode_Reward/reaching_object: 1.3092
    Episode_Reward/rotating_object: 28.1634
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.21s
                      Time elapsed: 00:20:19
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 45564 steps/s (collection: 2.043s, learning 0.115s)
             Mean action noise std: 2.35
          Mean value_function loss: 53.5223
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 70.4314
                       Mean reward: 173.60
               Mean episode length: 228.50
    Episode_Reward/reaching_object: 1.2940
    Episode_Reward/rotating_object: 28.6413
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.16s
                      Time elapsed: 00:20:21
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 44758 steps/s (collection: 2.030s, learning 0.167s)
             Mean action noise std: 2.36
          Mean value_function loss: 40.8640
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 70.4576
                       Mean reward: 143.61
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.3359
    Episode_Reward/rotating_object: 28.4294
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0574
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.20s
                      Time elapsed: 00:20:24
                               ETA: 00:41:27

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 46682 steps/s (collection: 1.911s, learning 0.195s)
             Mean action noise std: 2.36
          Mean value_function loss: 40.1755
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 70.4831
                       Mean reward: 168.02
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.3156
    Episode_Reward/rotating_object: 27.5576
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0582
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.11s
                      Time elapsed: 00:20:26
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 43950 steps/s (collection: 2.074s, learning 0.163s)
             Mean action noise std: 2.36
          Mean value_function loss: 54.7581
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 70.5081
                       Mean reward: 130.53
               Mean episode length: 218.68
    Episode_Reward/reaching_object: 1.3061
    Episode_Reward/rotating_object: 29.2365
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.24s
                      Time elapsed: 00:20:28
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 44213 steps/s (collection: 2.094s, learning 0.130s)
             Mean action noise std: 2.36
          Mean value_function loss: 44.1644
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 70.5279
                       Mean reward: 124.05
               Mean episode length: 223.17
    Episode_Reward/reaching_object: 1.3046
    Episode_Reward/rotating_object: 30.7853
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.22s
                      Time elapsed: 00:20:30
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 43724 steps/s (collection: 2.110s, learning 0.138s)
             Mean action noise std: 2.36
          Mean value_function loss: 44.5056
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 70.5552
                       Mean reward: 155.78
               Mean episode length: 225.99
    Episode_Reward/reaching_object: 1.3048
    Episode_Reward/rotating_object: 30.0851
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.25s
                      Time elapsed: 00:20:32
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 44811 steps/s (collection: 2.027s, learning 0.166s)
             Mean action noise std: 2.37
          Mean value_function loss: 42.0528
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 70.5968
                       Mean reward: 125.23
               Mean episode length: 226.00
    Episode_Reward/reaching_object: 1.3201
    Episode_Reward/rotating_object: 30.4419
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0594
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.19s
                      Time elapsed: 00:20:35
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 46825 steps/s (collection: 1.997s, learning 0.103s)
             Mean action noise std: 2.37
          Mean value_function loss: 52.0934
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 70.6346
                       Mean reward: 154.82
               Mean episode length: 225.81
    Episode_Reward/reaching_object: 1.3098
    Episode_Reward/rotating_object: 31.7461
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.10s
                      Time elapsed: 00:20:37
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 41416 steps/s (collection: 2.246s, learning 0.127s)
             Mean action noise std: 2.37
          Mean value_function loss: 50.9471
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 70.6545
                       Mean reward: 121.79
               Mean episode length: 213.07
    Episode_Reward/reaching_object: 1.3101
    Episode_Reward/rotating_object: 29.8494
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.37s
                      Time elapsed: 00:20:39
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 46230 steps/s (collection: 2.011s, learning 0.116s)
             Mean action noise std: 2.37
          Mean value_function loss: 42.2281
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 70.6725
                       Mean reward: 170.50
               Mean episode length: 224.91
    Episode_Reward/reaching_object: 1.3076
    Episode_Reward/rotating_object: 28.7809
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.13s
                      Time elapsed: 00:20:41
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 45300 steps/s (collection: 2.061s, learning 0.109s)
             Mean action noise std: 2.38
          Mean value_function loss: 51.5272
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 70.7024
                       Mean reward: 139.61
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 1.3148
    Episode_Reward/rotating_object: 29.9210
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0582
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.17s
                      Time elapsed: 00:20:43
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 46468 steps/s (collection: 2.004s, learning 0.112s)
             Mean action noise std: 2.38
          Mean value_function loss: 47.9785
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 70.7271
                       Mean reward: 178.66
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 1.3063
    Episode_Reward/rotating_object: 30.5619
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.12s
                      Time elapsed: 00:20:46
                               ETA: 00:40:57

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 43992 steps/s (collection: 2.054s, learning 0.180s)
             Mean action noise std: 2.38
          Mean value_function loss: 46.3617
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 70.7542
                       Mean reward: 132.54
               Mean episode length: 224.91
    Episode_Reward/reaching_object: 1.3089
    Episode_Reward/rotating_object: 29.3903
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.23s
                      Time elapsed: 00:20:48
                               ETA: 00:40:54

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 45860 steps/s (collection: 2.004s, learning 0.139s)
             Mean action noise std: 2.38
          Mean value_function loss: 47.6017
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 70.7918
                       Mean reward: 161.20
               Mean episode length: 229.00
    Episode_Reward/reaching_object: 1.2984
    Episode_Reward/rotating_object: 29.1310
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.14s
                      Time elapsed: 00:20:50
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 46816 steps/s (collection: 1.949s, learning 0.151s)
             Mean action noise std: 2.38
          Mean value_function loss: 42.0289
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 70.8194
                       Mean reward: 167.78
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.3085
    Episode_Reward/rotating_object: 31.3262
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.10s
                      Time elapsed: 00:20:52
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 46090 steps/s (collection: 1.986s, learning 0.147s)
             Mean action noise std: 2.39
          Mean value_function loss: 42.2974
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 70.8479
                       Mean reward: 154.94
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 1.3289
    Episode_Reward/rotating_object: 28.3860
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.13s
                      Time elapsed: 00:20:54
                               ETA: 00:40:45

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 44069 steps/s (collection: 2.118s, learning 0.113s)
             Mean action noise std: 2.39
          Mean value_function loss: 42.3335
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 70.8725
                       Mean reward: 180.02
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.3271
    Episode_Reward/rotating_object: 33.1193
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.23s
                      Time elapsed: 00:20:56
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 43467 steps/s (collection: 2.119s, learning 0.143s)
             Mean action noise std: 2.39
          Mean value_function loss: 51.5864
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.8910
                       Mean reward: 162.76
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.2896
    Episode_Reward/rotating_object: 28.8247
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.26s
                      Time elapsed: 00:20:59
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 46183 steps/s (collection: 2.003s, learning 0.126s)
             Mean action noise std: 2.39
          Mean value_function loss: 45.4783
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 70.9084
                       Mean reward: 172.11
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.3021
    Episode_Reward/rotating_object: 31.1241
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.13s
                      Time elapsed: 00:21:01
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 43293 steps/s (collection: 2.116s, learning 0.155s)
             Mean action noise std: 2.39
          Mean value_function loss: 49.4879
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.9328
                       Mean reward: 157.61
               Mean episode length: 227.51
    Episode_Reward/reaching_object: 1.3294
    Episode_Reward/rotating_object: 30.6504
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.27s
                      Time elapsed: 00:21:03
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 42499 steps/s (collection: 2.159s, learning 0.154s)
             Mean action noise std: 2.40
          Mean value_function loss: 42.7206
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 70.9609
                       Mean reward: 151.46
               Mean episode length: 225.25
    Episode_Reward/reaching_object: 1.3127
    Episode_Reward/rotating_object: 30.3967
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.31s
                      Time elapsed: 00:21:05
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 41800 steps/s (collection: 2.161s, learning 0.191s)
             Mean action noise std: 2.40
          Mean value_function loss: 47.2862
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 70.9874
                       Mean reward: 186.50
               Mean episode length: 227.27
    Episode_Reward/reaching_object: 1.3423
    Episode_Reward/rotating_object: 29.7625
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0631
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.35s
                      Time elapsed: 00:21:08
                               ETA: 00:40:28

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 43589 steps/s (collection: 2.062s, learning 0.194s)
             Mean action noise std: 2.40
          Mean value_function loss: 46.7305
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 71.0162
                       Mean reward: 159.88
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.3317
    Episode_Reward/rotating_object: 31.3436
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0611
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.26s
                      Time elapsed: 00:21:10
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 44218 steps/s (collection: 2.063s, learning 0.161s)
             Mean action noise std: 2.40
          Mean value_function loss: 42.7197
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.0401
                       Mean reward: 133.44
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.3281
    Episode_Reward/rotating_object: 28.0492
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0622
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.22s
                      Time elapsed: 00:21:12
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 44268 steps/s (collection: 2.116s, learning 0.105s)
             Mean action noise std: 2.40
          Mean value_function loss: 52.4811
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 71.0621
                       Mean reward: 140.64
               Mean episode length: 218.54
    Episode_Reward/reaching_object: 1.3004
    Episode_Reward/rotating_object: 30.4316
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.22s
                      Time elapsed: 00:21:14
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 45893 steps/s (collection: 2.005s, learning 0.137s)
             Mean action noise std: 2.40
          Mean value_function loss: 50.9044
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.0796
                       Mean reward: 142.18
               Mean episode length: 222.51
    Episode_Reward/reaching_object: 1.3062
    Episode_Reward/rotating_object: 30.2207
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.14s
                      Time elapsed: 00:21:17
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 42926 steps/s (collection: 2.064s, learning 0.226s)
             Mean action noise std: 2.41
          Mean value_function loss: 45.0826
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 71.0961
                       Mean reward: 159.08
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 1.3267
    Episode_Reward/rotating_object: 32.3273
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0614
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.29s
                      Time elapsed: 00:21:19
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 43460 steps/s (collection: 2.153s, learning 0.109s)
             Mean action noise std: 2.41
          Mean value_function loss: 51.7736
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 71.1230
                       Mean reward: 162.78
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.3728
    Episode_Reward/rotating_object: 30.6720
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0632
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.26s
                      Time elapsed: 00:21:21
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 44232 steps/s (collection: 2.058s, learning 0.164s)
             Mean action noise std: 2.41
          Mean value_function loss: 59.7989
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.1523
                       Mean reward: 136.92
               Mean episode length: 221.49
    Episode_Reward/reaching_object: 1.3064
    Episode_Reward/rotating_object: 30.2868
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0605
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.22s
                      Time elapsed: 00:21:23
                               ETA: 00:40:07

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 43817 steps/s (collection: 2.084s, learning 0.159s)
             Mean action noise std: 2.41
          Mean value_function loss: 50.3338
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 71.1835
                       Mean reward: 163.04
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.3226
    Episode_Reward/rotating_object: 29.6495
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0613
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.24s
                      Time elapsed: 00:21:26
                               ETA: 00:40:04

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 44087 steps/s (collection: 2.046s, learning 0.184s)
             Mean action noise std: 2.41
          Mean value_function loss: 51.0365
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.2162
                       Mean reward: 151.92
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 1.3149
    Episode_Reward/rotating_object: 29.5838
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.23s
                      Time elapsed: 00:21:28
                               ETA: 00:40:02

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 42785 steps/s (collection: 2.165s, learning 0.133s)
             Mean action noise std: 2.42
          Mean value_function loss: 51.9848
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 71.2352
                       Mean reward: 179.95
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 1.2838
    Episode_Reward/rotating_object: 33.0386
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.30s
                      Time elapsed: 00:21:30
                               ETA: 00:39:59

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 42626 steps/s (collection: 2.111s, learning 0.195s)
             Mean action noise std: 2.42
          Mean value_function loss: 56.1035
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 71.2638
                       Mean reward: 164.61
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 1.3097
    Episode_Reward/rotating_object: 32.2586
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.31s
                      Time elapsed: 00:21:32
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 43739 steps/s (collection: 2.111s, learning 0.137s)
             Mean action noise std: 2.42
          Mean value_function loss: 56.0800
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 71.2906
                       Mean reward: 197.54
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.3130
    Episode_Reward/rotating_object: 32.3309
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0615
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.25s
                      Time elapsed: 00:21:35
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 45390 steps/s (collection: 2.034s, learning 0.132s)
             Mean action noise std: 2.42
          Mean value_function loss: 54.0808
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.3197
                       Mean reward: 159.20
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.2829
    Episode_Reward/rotating_object: 30.2776
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.17s
                      Time elapsed: 00:21:37
                               ETA: 00:39:50

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 45869 steps/s (collection: 2.014s, learning 0.130s)
             Mean action noise std: 2.42
          Mean value_function loss: 57.4389
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 71.3364
                       Mean reward: 164.85
               Mean episode length: 226.42
    Episode_Reward/reaching_object: 1.2904
    Episode_Reward/rotating_object: 29.8077
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0592
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.14s
                      Time elapsed: 00:21:39
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 44425 steps/s (collection: 2.063s, learning 0.150s)
             Mean action noise std: 2.43
          Mean value_function loss: 51.7214
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 71.3548
                       Mean reward: 193.15
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 1.3275
    Episode_Reward/rotating_object: 36.3919
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.21s
                      Time elapsed: 00:21:41
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 46629 steps/s (collection: 1.993s, learning 0.116s)
             Mean action noise std: 2.43
          Mean value_function loss: 54.1218
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 71.3736
                       Mean reward: 179.39
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 1.3197
    Episode_Reward/rotating_object: 32.5762
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.11s
                      Time elapsed: 00:21:43
                               ETA: 00:39:41

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 46636 steps/s (collection: 1.978s, learning 0.130s)
             Mean action noise std: 2.43
          Mean value_function loss: 51.1024
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.3967
                       Mean reward: 170.03
               Mean episode length: 221.32
    Episode_Reward/reaching_object: 1.2998
    Episode_Reward/rotating_object: 32.3294
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.11s
                      Time elapsed: 00:21:45
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 43198 steps/s (collection: 2.135s, learning 0.141s)
             Mean action noise std: 2.43
          Mean value_function loss: 47.7948
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 71.4265
                       Mean reward: 178.28
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.2808
    Episode_Reward/rotating_object: 33.6057
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0586
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.28s
                      Time elapsed: 00:21:48
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 46562 steps/s (collection: 1.983s, learning 0.128s)
             Mean action noise std: 2.43
          Mean value_function loss: 54.8841
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 71.4625
                       Mean reward: 180.57
               Mean episode length: 224.58
    Episode_Reward/reaching_object: 1.3056
    Episode_Reward/rotating_object: 33.6889
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.11s
                      Time elapsed: 00:21:50
                               ETA: 00:39:32

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 46402 steps/s (collection: 1.963s, learning 0.155s)
             Mean action noise std: 2.44
          Mean value_function loss: 50.6148
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 71.4921
                       Mean reward: 151.37
               Mean episode length: 226.39
    Episode_Reward/reaching_object: 1.3337
    Episode_Reward/rotating_object: 32.5003
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.12s
                      Time elapsed: 00:21:52
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 43418 steps/s (collection: 2.087s, learning 0.177s)
             Mean action noise std: 2.44
          Mean value_function loss: 50.1215
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 71.5274
                       Mean reward: 180.02
               Mean episode length: 237.05
    Episode_Reward/reaching_object: 1.3060
    Episode_Reward/rotating_object: 33.6472
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.26s
                      Time elapsed: 00:21:54
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 44561 steps/s (collection: 2.052s, learning 0.154s)
             Mean action noise std: 2.44
          Mean value_function loss: 49.1092
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 71.5518
                       Mean reward: 150.73
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.3605
    Episode_Reward/rotating_object: 32.0641
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.21s
                      Time elapsed: 00:21:56
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 44539 steps/s (collection: 2.061s, learning 0.147s)
             Mean action noise std: 2.44
          Mean value_function loss: 51.5119
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 71.5832
                       Mean reward: 178.83
               Mean episode length: 221.82
    Episode_Reward/reaching_object: 1.3165
    Episode_Reward/rotating_object: 32.6184
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.21s
                      Time elapsed: 00:21:59
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 45643 steps/s (collection: 2.031s, learning 0.123s)
             Mean action noise std: 2.45
          Mean value_function loss: 50.7110
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 71.6184
                       Mean reward: 176.26
               Mean episode length: 222.67
    Episode_Reward/reaching_object: 1.3207
    Episode_Reward/rotating_object: 32.3425
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.15s
                      Time elapsed: 00:22:01
                               ETA: 00:39:18

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 44715 steps/s (collection: 2.032s, learning 0.166s)
             Mean action noise std: 2.45
          Mean value_function loss: 53.5902
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 71.6456
                       Mean reward: 196.11
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.3294
    Episode_Reward/rotating_object: 33.5107
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.20s
                      Time elapsed: 00:22:03
                               ETA: 00:39:15

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 45833 steps/s (collection: 1.969s, learning 0.176s)
             Mean action noise std: 2.45
          Mean value_function loss: 50.5791
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 71.6737
                       Mean reward: 176.89
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 1.3087
    Episode_Reward/rotating_object: 32.0478
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0594
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.14s
                      Time elapsed: 00:22:05
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 47257 steps/s (collection: 1.939s, learning 0.141s)
             Mean action noise std: 2.45
          Mean value_function loss: 49.3634
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 71.7028
                       Mean reward: 198.20
               Mean episode length: 223.36
    Episode_Reward/reaching_object: 1.3115
    Episode_Reward/rotating_object: 34.5590
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.08s
                      Time elapsed: 00:22:07
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 45595 steps/s (collection: 1.990s, learning 0.166s)
             Mean action noise std: 2.46
          Mean value_function loss: 44.6629
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.7326
                       Mean reward: 159.54
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.3423
    Episode_Reward/rotating_object: 34.0719
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.16s
                      Time elapsed: 00:22:09
                               ETA: 00:39:06

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 43798 steps/s (collection: 2.093s, learning 0.152s)
             Mean action noise std: 2.46
          Mean value_function loss: 50.7500
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 71.7601
                       Mean reward: 163.25
               Mean episode length: 228.50
    Episode_Reward/reaching_object: 1.3025
    Episode_Reward/rotating_object: 30.8903
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.24s
                      Time elapsed: 00:22:12
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 46955 steps/s (collection: 1.928s, learning 0.166s)
             Mean action noise std: 2.46
          Mean value_function loss: 52.6608
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 71.7835
                       Mean reward: 150.20
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.3398
    Episode_Reward/rotating_object: 35.0572
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.09s
                      Time elapsed: 00:22:14
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 45213 steps/s (collection: 2.037s, learning 0.137s)
             Mean action noise std: 2.46
          Mean value_function loss: 52.6764
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 71.8180
                       Mean reward: 156.33
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.2981
    Episode_Reward/rotating_object: 30.8698
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.17s
                      Time elapsed: 00:22:16
                               ETA: 00:38:57

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 45954 steps/s (collection: 1.959s, learning 0.180s)
             Mean action noise std: 2.47
          Mean value_function loss: 49.4762
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 71.8564
                       Mean reward: 151.72
               Mean episode length: 214.91
    Episode_Reward/reaching_object: 1.2982
    Episode_Reward/rotating_object: 32.9928
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.14s
                      Time elapsed: 00:22:18
                               ETA: 00:38:54

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 43006 steps/s (collection: 2.108s, learning 0.178s)
             Mean action noise std: 2.47
          Mean value_function loss: 54.8296
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 71.8861
                       Mean reward: 165.62
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.3207
    Episode_Reward/rotating_object: 32.0477
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.29s
                      Time elapsed: 00:22:20
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 45956 steps/s (collection: 1.975s, learning 0.164s)
             Mean action noise std: 2.47
          Mean value_function loss: 48.0600
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.9150
                       Mean reward: 151.46
               Mean episode length: 220.42
    Episode_Reward/reaching_object: 1.2931
    Episode_Reward/rotating_object: 33.2610
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.14s
                      Time elapsed: 00:22:22
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 44105 steps/s (collection: 2.028s, learning 0.201s)
             Mean action noise std: 2.47
          Mean value_function loss: 52.7401
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 71.9501
                       Mean reward: 151.77
               Mean episode length: 218.76
    Episode_Reward/reaching_object: 1.2877
    Episode_Reward/rotating_object: 31.8728
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.23s
                      Time elapsed: 00:22:25
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 43885 steps/s (collection: 2.025s, learning 0.215s)
             Mean action noise std: 2.48
          Mean value_function loss: 49.0926
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 71.9820
                       Mean reward: 178.23
               Mean episode length: 223.15
    Episode_Reward/reaching_object: 1.3121
    Episode_Reward/rotating_object: 32.4336
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0614
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.24s
                      Time elapsed: 00:22:27
                               ETA: 00:38:43

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 42565 steps/s (collection: 2.106s, learning 0.204s)
             Mean action noise std: 2.48
          Mean value_function loss: 46.4137
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 72.0132
                       Mean reward: 142.52
               Mean episode length: 223.49
    Episode_Reward/reaching_object: 1.3304
    Episode_Reward/rotating_object: 33.8658
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.31s
                      Time elapsed: 00:22:29
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 41654 steps/s (collection: 2.198s, learning 0.162s)
             Mean action noise std: 2.48
          Mean value_function loss: 56.1593
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 72.0398
                       Mean reward: 158.60
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 1.2983
    Episode_Reward/rotating_object: 28.9166
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.36s
                      Time elapsed: 00:22:32
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 44388 steps/s (collection: 2.062s, learning 0.152s)
             Mean action noise std: 2.48
          Mean value_function loss: 58.7477
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 72.0665
                       Mean reward: 155.08
               Mean episode length: 226.60
    Episode_Reward/reaching_object: 1.3209
    Episode_Reward/rotating_object: 32.7680
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.21s
                      Time elapsed: 00:22:34
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 44576 steps/s (collection: 2.042s, learning 0.164s)
             Mean action noise std: 2.49
          Mean value_function loss: 51.8129
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.1035
                       Mean reward: 173.54
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 1.2899
    Episode_Reward/rotating_object: 31.6258
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.21s
                      Time elapsed: 00:22:36
                               ETA: 00:38:32

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 44985 steps/s (collection: 2.047s, learning 0.139s)
             Mean action noise std: 2.49
          Mean value_function loss: 54.2739
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.1310
                       Mean reward: 186.53
               Mean episode length: 220.55
    Episode_Reward/reaching_object: 1.2641
    Episode_Reward/rotating_object: 32.6806
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.19s
                      Time elapsed: 00:22:38
                               ETA: 00:38:29

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 42153 steps/s (collection: 2.134s, learning 0.198s)
             Mean action noise std: 2.49
          Mean value_function loss: 54.4413
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 72.1595
                       Mean reward: 174.79
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 1.3215
    Episode_Reward/rotating_object: 31.6145
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.33s
                      Time elapsed: 00:22:40
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 44003 steps/s (collection: 2.059s, learning 0.175s)
             Mean action noise std: 2.49
          Mean value_function loss: 52.8205
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 72.1797
                       Mean reward: 170.71
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 1.2925
    Episode_Reward/rotating_object: 27.9136
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.23s
                      Time elapsed: 00:22:43
                               ETA: 00:38:23

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 44984 steps/s (collection: 2.029s, learning 0.156s)
             Mean action noise std: 2.49
          Mean value_function loss: 52.4074
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 72.2056
                       Mean reward: 148.15
               Mean episode length: 219.51
    Episode_Reward/reaching_object: 1.2612
    Episode_Reward/rotating_object: 31.9809
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.19s
                      Time elapsed: 00:22:45
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 44888 steps/s (collection: 2.014s, learning 0.176s)
             Mean action noise std: 2.50
          Mean value_function loss: 55.1712
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 72.2304
                       Mean reward: 130.56
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 1.3212
    Episode_Reward/rotating_object: 32.9840
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0613
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.19s
                      Time elapsed: 00:22:47
                               ETA: 00:38:18

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 45596 steps/s (collection: 1.978s, learning 0.178s)
             Mean action noise std: 2.50
          Mean value_function loss: 58.9672
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.2549
                       Mean reward: 141.28
               Mean episode length: 220.49
    Episode_Reward/reaching_object: 1.3071
    Episode_Reward/rotating_object: 29.3360
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0587
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.16s
                      Time elapsed: 00:22:49
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 42891 steps/s (collection: 2.103s, learning 0.189s)
             Mean action noise std: 2.50
          Mean value_function loss: 48.7657
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 72.2892
                       Mean reward: 162.67
               Mean episode length: 221.06
    Episode_Reward/reaching_object: 1.3518
    Episode_Reward/rotating_object: 34.5550
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.29s
                      Time elapsed: 00:22:52
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 44409 steps/s (collection: 2.079s, learning 0.134s)
             Mean action noise std: 2.50
          Mean value_function loss: 50.7348
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 72.3137
                       Mean reward: 198.68
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 1.2734
    Episode_Reward/rotating_object: 33.1489
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0583
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.21s
                      Time elapsed: 00:22:54
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 46140 steps/s (collection: 2.004s, learning 0.126s)
             Mean action noise std: 2.50
          Mean value_function loss: 61.0574
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.3402
                       Mean reward: 199.92
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.3288
    Episode_Reward/rotating_object: 33.4133
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.13s
                      Time elapsed: 00:22:56
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 40284 steps/s (collection: 2.274s, learning 0.167s)
             Mean action noise std: 2.51
          Mean value_function loss: 52.0090
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 72.3687
                       Mean reward: 173.41
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 1.3610
    Episode_Reward/rotating_object: 37.1793
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0625
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.44s
                      Time elapsed: 00:22:58
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 43268 steps/s (collection: 2.120s, learning 0.152s)
             Mean action noise std: 2.51
          Mean value_function loss: 55.1793
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 72.4034
                       Mean reward: 181.12
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.3277
    Episode_Reward/rotating_object: 34.2284
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.27s
                      Time elapsed: 00:23:01
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 40093 steps/s (collection: 2.322s, learning 0.130s)
             Mean action noise std: 2.51
          Mean value_function loss: 52.4122
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 72.4295
                       Mean reward: 154.54
               Mean episode length: 217.01
    Episode_Reward/reaching_object: 1.2967
    Episode_Reward/rotating_object: 31.2709
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.45s
                      Time elapsed: 00:23:03
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 43969 steps/s (collection: 2.023s, learning 0.213s)
             Mean action noise std: 2.51
          Mean value_function loss: 55.9684
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 72.4485
                       Mean reward: 179.95
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 1.3219
    Episode_Reward/rotating_object: 33.2755
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.24s
                      Time elapsed: 00:23:05
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 44867 steps/s (collection: 2.017s, learning 0.174s)
             Mean action noise std: 2.52
          Mean value_function loss: 64.4331
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 72.4808
                       Mean reward: 176.78
               Mean episode length: 218.70
    Episode_Reward/reaching_object: 1.3169
    Episode_Reward/rotating_object: 32.6908
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.19s
                      Time elapsed: 00:23:07
                               ETA: 00:37:53

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 46779 steps/s (collection: 1.962s, learning 0.139s)
             Mean action noise std: 2.52
          Mean value_function loss: 56.2514
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.5152
                       Mean reward: 177.30
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 1.3222
    Episode_Reward/rotating_object: 38.0725
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.10s
                      Time elapsed: 00:23:10
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 42686 steps/s (collection: 2.174s, learning 0.129s)
             Mean action noise std: 2.52
          Mean value_function loss: 54.2168
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 72.5451
                       Mean reward: 185.94
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.3205
    Episode_Reward/rotating_object: 33.7264
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.30s
                      Time elapsed: 00:23:12
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 44769 steps/s (collection: 2.068s, learning 0.128s)
             Mean action noise std: 2.52
          Mean value_function loss: 53.6443
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 72.5729
                       Mean reward: 151.61
               Mean episode length: 225.69
    Episode_Reward/reaching_object: 1.3044
    Episode_Reward/rotating_object: 31.9250
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0608
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.20s
                      Time elapsed: 00:23:14
                               ETA: 00:37:44

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 43291 steps/s (collection: 2.097s, learning 0.174s)
             Mean action noise std: 2.53
          Mean value_function loss: 53.4451
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 72.6021
                       Mean reward: 188.28
               Mean episode length: 228.26
    Episode_Reward/reaching_object: 1.3195
    Episode_Reward/rotating_object: 34.9841
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.27s
                      Time elapsed: 00:23:16
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 44251 steps/s (collection: 2.071s, learning 0.151s)
             Mean action noise std: 2.53
          Mean value_function loss: 56.8162
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 72.6294
                       Mean reward: 192.23
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 1.3155
    Episode_Reward/rotating_object: 35.8907
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.22s
                      Time elapsed: 00:23:19
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 40095 steps/s (collection: 2.250s, learning 0.202s)
             Mean action noise std: 2.53
          Mean value_function loss: 54.6788
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.6534
                       Mean reward: 149.45
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 1.2981
    Episode_Reward/rotating_object: 33.0132
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0583
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.45s
                      Time elapsed: 00:23:21
                               ETA: 00:37:37

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 45412 steps/s (collection: 2.014s, learning 0.151s)
             Mean action noise std: 2.53
          Mean value_function loss: 53.2260
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 72.6923
                       Mean reward: 141.75
               Mean episode length: 218.27
    Episode_Reward/reaching_object: 1.3152
    Episode_Reward/rotating_object: 33.2111
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0587
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.16s
                      Time elapsed: 00:23:23
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 45663 steps/s (collection: 2.023s, learning 0.130s)
             Mean action noise std: 2.54
          Mean value_function loss: 55.3845
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.7158
                       Mean reward: 152.48
               Mean episode length: 219.52
    Episode_Reward/reaching_object: 1.3079
    Episode_Reward/rotating_object: 33.0408
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.15s
                      Time elapsed: 00:23:25
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 45235 steps/s (collection: 2.017s, learning 0.156s)
             Mean action noise std: 2.54
          Mean value_function loss: 54.6342
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 72.7510
                       Mean reward: 196.10
               Mean episode length: 223.26
    Episode_Reward/reaching_object: 1.3327
    Episode_Reward/rotating_object: 35.2069
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0597
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.17s
                      Time elapsed: 00:23:27
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 47192 steps/s (collection: 1.955s, learning 0.128s)
             Mean action noise std: 2.54
          Mean value_function loss: 54.6393
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.7801
                       Mean reward: 192.98
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 1.3265
    Episode_Reward/rotating_object: 33.9594
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.08s
                      Time elapsed: 00:23:30
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 40960 steps/s (collection: 2.256s, learning 0.144s)
             Mean action noise std: 2.54
          Mean value_function loss: 58.0887
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 72.8064
                       Mean reward: 189.85
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.3317
    Episode_Reward/rotating_object: 35.8329
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.40s
                      Time elapsed: 00:23:32
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 45895 steps/s (collection: 2.011s, learning 0.131s)
             Mean action noise std: 2.55
          Mean value_function loss: 56.6738
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.8426
                       Mean reward: 165.41
               Mean episode length: 227.43
    Episode_Reward/reaching_object: 1.3090
    Episode_Reward/rotating_object: 32.1333
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.14s
                      Time elapsed: 00:23:34
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 44550 steps/s (collection: 2.040s, learning 0.166s)
             Mean action noise std: 2.55
          Mean value_function loss: 61.8539
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 72.8706
                       Mean reward: 187.48
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.3374
    Episode_Reward/rotating_object: 37.5201
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.21s
                      Time elapsed: 00:23:36
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 43729 steps/s (collection: 2.132s, learning 0.116s)
             Mean action noise std: 2.55
          Mean value_function loss: 65.2501
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 72.8963
                       Mean reward: 149.95
               Mean episode length: 221.29
    Episode_Reward/reaching_object: 1.3247
    Episode_Reward/rotating_object: 32.7869
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.25s
                      Time elapsed: 00:23:39
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 44418 steps/s (collection: 2.057s, learning 0.156s)
             Mean action noise std: 2.55
          Mean value_function loss: 62.5061
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 72.9269
                       Mean reward: 193.97
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 1.3167
    Episode_Reward/rotating_object: 33.9738
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.21s
                      Time elapsed: 00:23:41
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 44492 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 2.56
          Mean value_function loss: 58.4604
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 72.9576
                       Mean reward: 161.85
               Mean episode length: 220.57
    Episode_Reward/reaching_object: 1.3160
    Episode_Reward/rotating_object: 33.3762
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.21s
                      Time elapsed: 00:23:43
                               ETA: 00:37:08

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 45965 steps/s (collection: 2.000s, learning 0.139s)
             Mean action noise std: 2.56
          Mean value_function loss: 59.9244
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.9800
                       Mean reward: 146.47
               Mean episode length: 215.06
    Episode_Reward/reaching_object: 1.3160
    Episode_Reward/rotating_object: 33.7949
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.14s
                      Time elapsed: 00:23:45
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 42963 steps/s (collection: 2.118s, learning 0.170s)
             Mean action noise std: 2.56
          Mean value_function loss: 60.2635
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 73.0099
                       Mean reward: 211.02
               Mean episode length: 220.64
    Episode_Reward/reaching_object: 1.3058
    Episode_Reward/rotating_object: 34.9423
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.29s
                      Time elapsed: 00:23:47
                               ETA: 00:37:03

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 46489 steps/s (collection: 1.958s, learning 0.156s)
             Mean action noise std: 2.56
          Mean value_function loss: 58.4222
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 73.0408
                       Mean reward: 182.10
               Mean episode length: 223.50
    Episode_Reward/reaching_object: 1.3121
    Episode_Reward/rotating_object: 34.2749
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.11s
                      Time elapsed: 00:23:50
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 43620 steps/s (collection: 2.014s, learning 0.239s)
             Mean action noise std: 2.56
          Mean value_function loss: 60.6580
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 73.0651
                       Mean reward: 155.57
               Mean episode length: 216.19
    Episode_Reward/reaching_object: 1.3243
    Episode_Reward/rotating_object: 34.4090
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.25s
                      Time elapsed: 00:23:52
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 46951 steps/s (collection: 1.963s, learning 0.131s)
             Mean action noise std: 2.57
          Mean value_function loss: 55.1652
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 73.0879
                       Mean reward: 163.50
               Mean episode length: 219.96
    Episode_Reward/reaching_object: 1.3281
    Episode_Reward/rotating_object: 33.5050
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.09s
                      Time elapsed: 00:23:54
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 48582 steps/s (collection: 1.907s, learning 0.117s)
             Mean action noise std: 2.57
          Mean value_function loss: 59.9942
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 73.1132
                       Mean reward: 172.82
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 1.3221
    Episode_Reward/rotating_object: 31.3592
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0610
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.02s
                      Time elapsed: 00:23:56
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 44093 steps/s (collection: 2.102s, learning 0.128s)
             Mean action noise std: 2.57
          Mean value_function loss: 56.8649
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 73.1435
                       Mean reward: 199.93
               Mean episode length: 218.59
    Episode_Reward/reaching_object: 1.3006
    Episode_Reward/rotating_object: 36.9393
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.23s
                      Time elapsed: 00:23:58
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 46251 steps/s (collection: 2.002s, learning 0.123s)
             Mean action noise std: 2.57
          Mean value_function loss: 55.4412
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 73.1740
                       Mean reward: 183.73
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 1.3136
    Episode_Reward/rotating_object: 33.7828
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0610
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.13s
                      Time elapsed: 00:24:00
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 46853 steps/s (collection: 1.930s, learning 0.168s)
             Mean action noise std: 2.58
          Mean value_function loss: 50.4294
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 73.2015
                       Mean reward: 172.60
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 1.3467
    Episode_Reward/rotating_object: 32.4877
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.10s
                      Time elapsed: 00:24:02
                               ETA: 00:36:43

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 46905 steps/s (collection: 1.974s, learning 0.122s)
             Mean action noise std: 2.58
          Mean value_function loss: 55.4687
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 73.2346
                       Mean reward: 156.06
               Mean episode length: 219.71
    Episode_Reward/reaching_object: 1.3012
    Episode_Reward/rotating_object: 30.6706
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.10s
                      Time elapsed: 00:24:04
                               ETA: 00:36:40

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 45930 steps/s (collection: 1.925s, learning 0.215s)
             Mean action noise std: 2.58
          Mean value_function loss: 60.6146
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 73.2679
                       Mean reward: 181.75
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.3642
    Episode_Reward/rotating_object: 35.8084
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0617
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.14s
                      Time elapsed: 00:24:07
                               ETA: 00:36:37

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 48496 steps/s (collection: 1.900s, learning 0.127s)
             Mean action noise std: 2.59
          Mean value_function loss: 58.6224
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 73.3081
                       Mean reward: 172.86
               Mean episode length: 219.03
    Episode_Reward/reaching_object: 1.3139
    Episode_Reward/rotating_object: 31.8338
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.03s
                      Time elapsed: 00:24:09
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 48129 steps/s (collection: 1.907s, learning 0.135s)
             Mean action noise std: 2.59
          Mean value_function loss: 64.3143
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 73.3365
                       Mean reward: 196.57
               Mean episode length: 226.53
    Episode_Reward/reaching_object: 1.3247
    Episode_Reward/rotating_object: 33.6364
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.04s
                      Time elapsed: 00:24:11
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 45352 steps/s (collection: 2.031s, learning 0.137s)
             Mean action noise std: 2.59
          Mean value_function loss: 59.0898
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 73.3692
                       Mean reward: 171.41
               Mean episode length: 215.93
    Episode_Reward/reaching_object: 1.2873
    Episode_Reward/rotating_object: 33.4697
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0586
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.17s
                      Time elapsed: 00:24:13
                               ETA: 00:36:28

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 49523 steps/s (collection: 1.856s, learning 0.129s)
             Mean action noise std: 2.59
          Mean value_function loss: 54.5146
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 73.4033
                       Mean reward: 180.73
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 1.2906
    Episode_Reward/rotating_object: 31.7329
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0592
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.98s
                      Time elapsed: 00:24:15
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 49732 steps/s (collection: 1.865s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 56.1542
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 73.4280
                       Mean reward: 186.20
               Mean episode length: 225.63
    Episode_Reward/reaching_object: 1.3084
    Episode_Reward/rotating_object: 33.4993
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0590
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 1.98s
                      Time elapsed: 00:24:17
                               ETA: 00:36:22

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 46642 steps/s (collection: 1.973s, learning 0.134s)
             Mean action noise std: 2.60
          Mean value_function loss: 65.1972
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.4500
                       Mean reward: 204.31
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 1.3166
    Episode_Reward/rotating_object: 37.3704
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.11s
                      Time elapsed: 00:24:19
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 46603 steps/s (collection: 1.978s, learning 0.131s)
             Mean action noise std: 2.60
          Mean value_function loss: 60.8412
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 73.4876
                       Mean reward: 165.01
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.2896
    Episode_Reward/rotating_object: 33.1359
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0592
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.11s
                      Time elapsed: 00:24:21
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 49016 steps/s (collection: 1.893s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 58.4313
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 73.5202
                       Mean reward: 178.41
               Mean episode length: 216.77
    Episode_Reward/reaching_object: 1.2821
    Episode_Reward/rotating_object: 33.6886
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.01s
                      Time elapsed: 00:24:23
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 49354 steps/s (collection: 1.897s, learning 0.095s)
             Mean action noise std: 2.61
          Mean value_function loss: 56.7876
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 73.5644
                       Mean reward: 195.66
               Mean episode length: 221.61
    Episode_Reward/reaching_object: 1.2681
    Episode_Reward/rotating_object: 30.8541
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.99s
                      Time elapsed: 00:24:25
                               ETA: 00:36:10

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 46938 steps/s (collection: 1.999s, learning 0.096s)
             Mean action noise std: 2.61
          Mean value_function loss: 70.7776
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.6006
                       Mean reward: 172.89
               Mean episode length: 216.09
    Episode_Reward/reaching_object: 1.3213
    Episode_Reward/rotating_object: 34.7298
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.09s
                      Time elapsed: 00:24:27
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 49141 steps/s (collection: 1.881s, learning 0.120s)
             Mean action noise std: 2.61
          Mean value_function loss: 58.3589
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 73.6258
                       Mean reward: 181.29
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 1.3211
    Episode_Reward/rotating_object: 33.2142
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.00s
                      Time elapsed: 00:24:29
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 49284 steps/s (collection: 1.864s, learning 0.131s)
             Mean action noise std: 2.62
          Mean value_function loss: 65.5136
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 73.6643
                       Mean reward: 153.10
               Mean episode length: 218.30
    Episode_Reward/reaching_object: 1.3164
    Episode_Reward/rotating_object: 32.4680
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0615
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.99s
                      Time elapsed: 00:24:31
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 48750 steps/s (collection: 1.913s, learning 0.104s)
             Mean action noise std: 2.62
          Mean value_function loss: 59.6233
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.7011
                       Mean reward: 165.22
               Mean episode length: 220.46
    Episode_Reward/reaching_object: 1.2987
    Episode_Reward/rotating_object: 31.8761
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.02s
                      Time elapsed: 00:24:33
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 48432 steps/s (collection: 1.901s, learning 0.129s)
             Mean action noise std: 2.62
          Mean value_function loss: 63.6314
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 73.7277
                       Mean reward: 151.35
               Mean episode length: 216.34
    Episode_Reward/reaching_object: 1.2733
    Episode_Reward/rotating_object: 30.0169
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0597
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.03s
                      Time elapsed: 00:24:35
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 47531 steps/s (collection: 1.949s, learning 0.120s)
             Mean action noise std: 2.62
          Mean value_function loss: 63.7180
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 73.7495
                       Mean reward: 185.50
               Mean episode length: 210.54
    Episode_Reward/reaching_object: 1.2998
    Episode_Reward/rotating_object: 38.9923
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.07s
                      Time elapsed: 00:24:37
                               ETA: 00:35:52

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 49056 steps/s (collection: 1.872s, learning 0.132s)
             Mean action noise std: 2.63
          Mean value_function loss: 54.9647
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 73.7785
                       Mean reward: 171.17
               Mean episode length: 222.65
    Episode_Reward/reaching_object: 1.3212
    Episode_Reward/rotating_object: 35.9574
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.00s
                      Time elapsed: 00:24:39
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 46495 steps/s (collection: 1.968s, learning 0.147s)
             Mean action noise std: 2.63
          Mean value_function loss: 57.6381
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.7982
                       Mean reward: 163.31
               Mean episode length: 224.31
    Episode_Reward/reaching_object: 1.3040
    Episode_Reward/rotating_object: 32.0340
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.11s
                      Time elapsed: 00:24:41
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 46516 steps/s (collection: 1.978s, learning 0.136s)
             Mean action noise std: 2.63
          Mean value_function loss: 64.2121
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 73.8266
                       Mean reward: 189.84
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 1.3425
    Episode_Reward/rotating_object: 34.2781
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.11s
                      Time elapsed: 00:24:43
                               ETA: 00:35:43

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 46614 steps/s (collection: 1.936s, learning 0.173s)
             Mean action noise std: 2.63
          Mean value_function loss: 56.1944
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 73.8533
                       Mean reward: 194.40
               Mean episode length: 216.05
    Episode_Reward/reaching_object: 1.3251
    Episode_Reward/rotating_object: 36.1292
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.11s
                      Time elapsed: 00:24:46
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 48527 steps/s (collection: 1.868s, learning 0.158s)
             Mean action noise std: 2.63
          Mean value_function loss: 59.9781
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.8829
                       Mean reward: 182.31
               Mean episode length: 214.59
    Episode_Reward/reaching_object: 1.2707
    Episode_Reward/rotating_object: 32.1356
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0610
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.03s
                      Time elapsed: 00:24:48
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 49352 steps/s (collection: 1.887s, learning 0.105s)
             Mean action noise std: 2.64
          Mean value_function loss: 68.8630
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 73.9205
                       Mean reward: 185.21
               Mean episode length: 222.13
    Episode_Reward/reaching_object: 1.3242
    Episode_Reward/rotating_object: 37.4970
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0617
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.99s
                      Time elapsed: 00:24:50
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 45553 steps/s (collection: 2.032s, learning 0.126s)
             Mean action noise std: 2.64
          Mean value_function loss: 67.3975
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 73.9467
                       Mean reward: 186.76
               Mean episode length: 215.00
    Episode_Reward/reaching_object: 1.3243
    Episode_Reward/rotating_object: 35.7523
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.16s
                      Time elapsed: 00:24:52
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 45982 steps/s (collection: 1.953s, learning 0.185s)
             Mean action noise std: 2.64
          Mean value_function loss: 59.6981
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 73.9693
                       Mean reward: 180.98
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.3469
    Episode_Reward/rotating_object: 35.4538
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.14s
                      Time elapsed: 00:24:54
                               ETA: 00:35:29

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 38977 steps/s (collection: 2.363s, learning 0.159s)
             Mean action noise std: 2.64
          Mean value_function loss: 61.9604
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 74.0011
                       Mean reward: 167.91
               Mean episode length: 218.56
    Episode_Reward/reaching_object: 1.3297
    Episode_Reward/rotating_object: 34.0609
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.52s
                      Time elapsed: 00:24:56
                               ETA: 00:35:27

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 41912 steps/s (collection: 2.165s, learning 0.180s)
             Mean action noise std: 2.65
          Mean value_function loss: 65.3960
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 74.0291
                       Mean reward: 178.81
               Mean episode length: 224.91
    Episode_Reward/reaching_object: 1.3242
    Episode_Reward/rotating_object: 34.3376
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0614
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.35s
                      Time elapsed: 00:24:59
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 45294 steps/s (collection: 2.052s, learning 0.119s)
             Mean action noise std: 2.65
          Mean value_function loss: 60.9525
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 74.0494
                       Mean reward: 165.20
               Mean episode length: 215.50
    Episode_Reward/reaching_object: 1.2737
    Episode_Reward/rotating_object: 31.3172
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.17s
                      Time elapsed: 00:25:01
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 45246 steps/s (collection: 2.008s, learning 0.165s)
             Mean action noise std: 2.65
          Mean value_function loss: 62.5048
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.0815
                       Mean reward: 201.80
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 1.3253
    Episode_Reward/rotating_object: 37.0060
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0621
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.17s
                      Time elapsed: 00:25:03
                               ETA: 00:35:18

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 46046 steps/s (collection: 1.988s, learning 0.147s)
             Mean action noise std: 2.65
          Mean value_function loss: 52.7486
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 74.1106
                       Mean reward: 176.37
               Mean episode length: 220.24
    Episode_Reward/reaching_object: 1.3130
    Episode_Reward/rotating_object: 34.6375
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.13s
                      Time elapsed: 00:25:05
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 38902 steps/s (collection: 2.259s, learning 0.268s)
             Mean action noise std: 2.66
          Mean value_function loss: 62.5605
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 74.1356
                       Mean reward: 184.08
               Mean episode length: 222.35
    Episode_Reward/reaching_object: 1.2768
    Episode_Reward/rotating_object: 31.1163
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0622
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.53s
                      Time elapsed: 00:25:08
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 44363 steps/s (collection: 2.089s, learning 0.127s)
             Mean action noise std: 2.66
          Mean value_function loss: 61.4210
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 74.1711
                       Mean reward: 183.83
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 1.3361
    Episode_Reward/rotating_object: 36.0120
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0622
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.22s
                      Time elapsed: 00:25:10
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 43732 steps/s (collection: 2.111s, learning 0.137s)
             Mean action noise std: 2.66
          Mean value_function loss: 62.7567
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 74.2021
                       Mean reward: 176.64
               Mean episode length: 211.85
    Episode_Reward/reaching_object: 1.2590
    Episode_Reward/rotating_object: 34.3568
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0590
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.25s
                      Time elapsed: 00:25:12
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 46068 steps/s (collection: 1.972s, learning 0.162s)
             Mean action noise std: 2.66
          Mean value_function loss: 64.3644
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 74.2282
                       Mean reward: 186.42
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.3254
    Episode_Reward/rotating_object: 34.9163
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.13s
                      Time elapsed: 00:25:14
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 45185 steps/s (collection: 2.038s, learning 0.138s)
             Mean action noise std: 2.67
          Mean value_function loss: 56.8997
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 74.2515
                       Mean reward: 193.47
               Mean episode length: 213.92
    Episode_Reward/reaching_object: 1.2910
    Episode_Reward/rotating_object: 37.3172
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.18s
                      Time elapsed: 00:25:17
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 45396 steps/s (collection: 2.009s, learning 0.156s)
             Mean action noise std: 2.67
          Mean value_function loss: 55.5592
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.2906
                       Mean reward: 182.94
               Mean episode length: 220.13
    Episode_Reward/reaching_object: 1.2953
    Episode_Reward/rotating_object: 34.2429
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.17s
                      Time elapsed: 00:25:19
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 45241 steps/s (collection: 2.020s, learning 0.153s)
             Mean action noise std: 2.67
          Mean value_function loss: 61.9374
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 74.3293
                       Mean reward: 176.94
               Mean episode length: 229.02
    Episode_Reward/reaching_object: 1.3120
    Episode_Reward/rotating_object: 35.6229
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.17s
                      Time elapsed: 00:25:21
                               ETA: 00:34:57

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 44970 steps/s (collection: 2.010s, learning 0.176s)
             Mean action noise std: 2.68
          Mean value_function loss: 54.9037
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 74.3570
                       Mean reward: 212.32
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.2999
    Episode_Reward/rotating_object: 35.3584
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.19s
                      Time elapsed: 00:25:23
                               ETA: 00:34:54

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 46297 steps/s (collection: 1.987s, learning 0.136s)
             Mean action noise std: 2.68
          Mean value_function loss: 62.1436
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 74.3903
                       Mean reward: 154.71
               Mean episode length: 216.58
    Episode_Reward/reaching_object: 1.2840
    Episode_Reward/rotating_object: 33.2925
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.12s
                      Time elapsed: 00:25:25
                               ETA: 00:34:52

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 45357 steps/s (collection: 1.990s, learning 0.177s)
             Mean action noise std: 2.68
          Mean value_function loss: 66.9043
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 74.4298
                       Mean reward: 226.78
               Mean episode length: 226.15
    Episode_Reward/reaching_object: 1.2854
    Episode_Reward/rotating_object: 35.8497
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.17s
                      Time elapsed: 00:25:27
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 44940 steps/s (collection: 2.011s, learning 0.176s)
             Mean action noise std: 2.69
          Mean value_function loss: 68.8528
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 74.4734
                       Mean reward: 162.79
               Mean episode length: 221.25
    Episode_Reward/reaching_object: 1.2390
    Episode_Reward/rotating_object: 33.9562
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.19s
                      Time elapsed: 00:25:30
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 44534 steps/s (collection: 2.013s, learning 0.195s)
             Mean action noise std: 2.69
          Mean value_function loss: 61.1531
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 74.5074
                       Mean reward: 219.90
               Mean episode length: 215.51
    Episode_Reward/reaching_object: 1.2676
    Episode_Reward/rotating_object: 36.3744
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.21s
                      Time elapsed: 00:25:32
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 42730 steps/s (collection: 2.153s, learning 0.147s)
             Mean action noise std: 2.69
          Mean value_function loss: 63.3544
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 74.5303
                       Mean reward: 220.84
               Mean episode length: 222.76
    Episode_Reward/reaching_object: 1.2904
    Episode_Reward/rotating_object: 38.7372
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.30s
                      Time elapsed: 00:25:34
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 43793 steps/s (collection: 2.071s, learning 0.174s)
             Mean action noise std: 2.69
          Mean value_function loss: 69.5415
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 74.5710
                       Mean reward: 194.09
               Mean episode length: 219.74
    Episode_Reward/reaching_object: 1.2919
    Episode_Reward/rotating_object: 35.3600
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0594
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.24s
                      Time elapsed: 00:25:36
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 40397 steps/s (collection: 2.223s, learning 0.210s)
             Mean action noise std: 2.70
          Mean value_function loss: 68.8201
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 74.6081
                       Mean reward: 169.78
               Mean episode length: 223.68
    Episode_Reward/reaching_object: 1.2772
    Episode_Reward/rotating_object: 35.2198
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.43s
                      Time elapsed: 00:25:39
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 43842 steps/s (collection: 2.133s, learning 0.110s)
             Mean action noise std: 2.70
          Mean value_function loss: 71.6736
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 74.6364
                       Mean reward: 174.04
               Mean episode length: 221.76
    Episode_Reward/reaching_object: 1.2872
    Episode_Reward/rotating_object: 34.3633
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0584
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.24s
                      Time elapsed: 00:25:41
                               ETA: 00:34:33

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 44431 steps/s (collection: 2.032s, learning 0.180s)
             Mean action noise std: 2.70
          Mean value_function loss: 62.2032
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 74.6616
                       Mean reward: 162.20
               Mean episode length: 222.51
    Episode_Reward/reaching_object: 1.2709
    Episode_Reward/rotating_object: 34.9979
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0587
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.21s
                      Time elapsed: 00:25:43
                               ETA: 00:34:31

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 45146 steps/s (collection: 2.015s, learning 0.162s)
             Mean action noise std: 2.71
          Mean value_function loss: 59.1057
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 74.7051
                       Mean reward: 184.81
               Mean episode length: 213.13
    Episode_Reward/reaching_object: 1.2949
    Episode_Reward/rotating_object: 37.0425
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.18s
                      Time elapsed: 00:25:45
                               ETA: 00:34:28

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 44657 steps/s (collection: 2.052s, learning 0.149s)
             Mean action noise std: 2.71
          Mean value_function loss: 57.6323
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 74.7384
                       Mean reward: 205.67
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 1.2785
    Episode_Reward/rotating_object: 37.9441
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0574
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.20s
                      Time elapsed: 00:25:48
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 43114 steps/s (collection: 2.089s, learning 0.191s)
             Mean action noise std: 2.71
          Mean value_function loss: 56.7068
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.7676
                       Mean reward: 188.10
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.2770
    Episode_Reward/rotating_object: 35.7637
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.28s
                      Time elapsed: 00:25:50
                               ETA: 00:34:23

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 47978 steps/s (collection: 1.902s, learning 0.147s)
             Mean action noise std: 2.71
          Mean value_function loss: 58.8391
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 74.7993
                       Mean reward: 179.23
               Mean episode length: 223.90
    Episode_Reward/reaching_object: 1.2760
    Episode_Reward/rotating_object: 35.8675
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.05s
                      Time elapsed: 00:25:52
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 46975 steps/s (collection: 1.948s, learning 0.145s)
             Mean action noise std: 2.72
          Mean value_function loss: 60.7528
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 74.8367
                       Mean reward: 173.43
               Mean episode length: 224.71
    Episode_Reward/reaching_object: 1.3037
    Episode_Reward/rotating_object: 39.0144
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.09s
                      Time elapsed: 00:25:54
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 45457 steps/s (collection: 2.022s, learning 0.140s)
             Mean action noise std: 2.72
          Mean value_function loss: 59.2784
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 74.8812
                       Mean reward: 184.23
               Mean episode length: 216.14
    Episode_Reward/reaching_object: 1.3168
    Episode_Reward/rotating_object: 35.9267
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0587
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.16s
                      Time elapsed: 00:25:56
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 46842 steps/s (collection: 1.986s, learning 0.113s)
             Mean action noise std: 2.72
          Mean value_function loss: 66.4068
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 74.9118
                       Mean reward: 188.72
               Mean episode length: 219.32
    Episode_Reward/reaching_object: 1.3012
    Episode_Reward/rotating_object: 38.4233
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.10s
                      Time elapsed: 00:25:58
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 46432 steps/s (collection: 2.012s, learning 0.106s)
             Mean action noise std: 2.73
          Mean value_function loss: 62.8523
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 74.9422
                       Mean reward: 216.21
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.3362
    Episode_Reward/rotating_object: 37.5595
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.12s
                      Time elapsed: 00:26:00
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 48454 steps/s (collection: 1.925s, learning 0.104s)
             Mean action noise std: 2.73
          Mean value_function loss: 60.9390
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.9672
                       Mean reward: 224.52
               Mean episode length: 223.28
    Episode_Reward/reaching_object: 1.3017
    Episode_Reward/rotating_object: 36.7911
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.03s
                      Time elapsed: 00:26:02
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 44253 steps/s (collection: 2.078s, learning 0.144s)
             Mean action noise std: 2.73
          Mean value_function loss: 60.4708
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 74.9987
                       Mean reward: 178.12
               Mean episode length: 217.62
    Episode_Reward/reaching_object: 1.2995
    Episode_Reward/rotating_object: 33.7496
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.22s
                      Time elapsed: 00:26:05
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 44294 steps/s (collection: 2.050s, learning 0.170s)
             Mean action noise std: 2.74
          Mean value_function loss: 71.1775
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 75.0394
                       Mean reward: 165.07
               Mean episode length: 213.20
    Episode_Reward/reaching_object: 1.3180
    Episode_Reward/rotating_object: 34.6114
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.22s
                      Time elapsed: 00:26:07
                               ETA: 00:34:00

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 45005 steps/s (collection: 2.048s, learning 0.136s)
             Mean action noise std: 2.74
          Mean value_function loss: 69.5441
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 75.0719
                       Mean reward: 138.63
               Mean episode length: 203.15
    Episode_Reward/reaching_object: 1.2738
    Episode_Reward/rotating_object: 32.9669
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.18s
                      Time elapsed: 00:26:09
                               ETA: 00:33:58

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 47076 steps/s (collection: 1.939s, learning 0.149s)
             Mean action noise std: 2.74
          Mean value_function loss: 69.3557
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 75.1119
                       Mean reward: 183.42
               Mean episode length: 209.78
    Episode_Reward/reaching_object: 1.3042
    Episode_Reward/rotating_object: 38.2263
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.09s
                      Time elapsed: 00:26:11
                               ETA: 00:33:55

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 46264 steps/s (collection: 2.007s, learning 0.118s)
             Mean action noise std: 2.75
          Mean value_function loss: 73.9358
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 75.1461
                       Mean reward: 189.18
               Mean episode length: 212.04
    Episode_Reward/reaching_object: 1.2993
    Episode_Reward/rotating_object: 36.7974
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.12s
                      Time elapsed: 00:26:13
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 43713 steps/s (collection: 2.114s, learning 0.135s)
             Mean action noise std: 2.75
          Mean value_function loss: 65.8533
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 75.1792
                       Mean reward: 167.86
               Mean episode length: 222.05
    Episode_Reward/reaching_object: 1.3429
    Episode_Reward/rotating_object: 37.6109
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.25s
                      Time elapsed: 00:26:15
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 48309 steps/s (collection: 1.930s, learning 0.105s)
             Mean action noise std: 2.75
          Mean value_function loss: 68.8219
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 75.2165
                       Mean reward: 226.03
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 1.3262
    Episode_Reward/rotating_object: 37.8657
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.03s
                      Time elapsed: 00:26:17
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 43755 steps/s (collection: 2.117s, learning 0.130s)
             Mean action noise std: 2.76
          Mean value_function loss: 78.6576
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 75.2491
                       Mean reward: 194.59
               Mean episode length: 219.16
    Episode_Reward/reaching_object: 1.3064
    Episode_Reward/rotating_object: 35.8947
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.25s
                      Time elapsed: 00:26:20
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 44416 steps/s (collection: 2.070s, learning 0.144s)
             Mean action noise std: 2.76
          Mean value_function loss: 69.2445
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 75.2815
                       Mean reward: 176.53
               Mean episode length: 224.75
    Episode_Reward/reaching_object: 1.3313
    Episode_Reward/rotating_object: 36.0530
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0605
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.21s
                      Time elapsed: 00:26:22
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 48614 steps/s (collection: 1.896s, learning 0.126s)
             Mean action noise std: 2.76
          Mean value_function loss: 76.1008
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 75.3067
                       Mean reward: 186.83
               Mean episode length: 219.99
    Episode_Reward/reaching_object: 1.3202
    Episode_Reward/rotating_object: 38.0319
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.02s
                      Time elapsed: 00:26:24
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 45603 steps/s (collection: 2.042s, learning 0.114s)
             Mean action noise std: 2.76
          Mean value_function loss: 65.5158
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 75.3396
                       Mean reward: 221.43
               Mean episode length: 218.13
    Episode_Reward/reaching_object: 1.3164
    Episode_Reward/rotating_object: 38.0035
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.16s
                      Time elapsed: 00:26:26
                               ETA: 00:33:36

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 42984 steps/s (collection: 2.147s, learning 0.140s)
             Mean action noise std: 2.77
          Mean value_function loss: 73.2093
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 75.3780
                       Mean reward: 189.15
               Mean episode length: 205.67
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 34.6106
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.29s
                      Time elapsed: 00:26:28
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 46364 steps/s (collection: 1.986s, learning 0.135s)
             Mean action noise std: 2.77
          Mean value_function loss: 67.3003
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 75.4071
                       Mean reward: 216.39
               Mean episode length: 234.14
    Episode_Reward/reaching_object: 1.3082
    Episode_Reward/rotating_object: 37.6254
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.12s
                      Time elapsed: 00:26:31
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 47991 steps/s (collection: 1.900s, learning 0.148s)
             Mean action noise std: 2.77
          Mean value_function loss: 72.5610
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 75.4435
                       Mean reward: 178.27
               Mean episode length: 209.91
    Episode_Reward/reaching_object: 1.2817
    Episode_Reward/rotating_object: 32.7595
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.05s
                      Time elapsed: 00:26:33
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 46507 steps/s (collection: 1.982s, learning 0.132s)
             Mean action noise std: 2.78
          Mean value_function loss: 73.0992
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 75.4880
                       Mean reward: 215.69
               Mean episode length: 228.13
    Episode_Reward/reaching_object: 1.3639
    Episode_Reward/rotating_object: 40.8250
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.11s
                      Time elapsed: 00:26:35
                               ETA: 00:33:25

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 41615 steps/s (collection: 2.174s, learning 0.188s)
             Mean action noise std: 2.78
          Mean value_function loss: 78.4368
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 75.5264
                       Mean reward: 191.07
               Mean episode length: 223.31
    Episode_Reward/reaching_object: 1.3003
    Episode_Reward/rotating_object: 35.5357
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.36s
                      Time elapsed: 00:26:37
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 26789 steps/s (collection: 3.553s, learning 0.117s)
             Mean action noise std: 2.78
          Mean value_function loss: 68.4108
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 75.5660
                       Mean reward: 204.60
               Mean episode length: 223.50
    Episode_Reward/reaching_object: 1.3107
    Episode_Reward/rotating_object: 42.9511
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0605
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.67s
                      Time elapsed: 00:26:41
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 13791 steps/s (collection: 6.967s, learning 0.161s)
             Mean action noise std: 2.79
          Mean value_function loss: 71.4504
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 75.6119
                       Mean reward: 190.85
               Mean episode length: 219.11
    Episode_Reward/reaching_object: 1.2972
    Episode_Reward/rotating_object: 38.1333
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 7.13s
                      Time elapsed: 00:26:48
                               ETA: 00:33:25

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 13880 steps/s (collection: 6.863s, learning 0.219s)
             Mean action noise std: 2.79
          Mean value_function loss: 68.0252
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 75.6377
                       Mean reward: 168.26
               Mean episode length: 209.63
    Episode_Reward/reaching_object: 1.2863
    Episode_Reward/rotating_object: 34.0971
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0587
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 7.08s
                      Time elapsed: 00:26:55
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 13988 steps/s (collection: 6.848s, learning 0.179s)
             Mean action noise std: 2.79
          Mean value_function loss: 69.2103
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 75.6629
                       Mean reward: 208.73
               Mean episode length: 222.11
    Episode_Reward/reaching_object: 1.3222
    Episode_Reward/rotating_object: 39.6858
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 7.03s
                      Time elapsed: 00:27:02
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14277 steps/s (collection: 6.752s, learning 0.133s)
             Mean action noise std: 2.80
          Mean value_function loss: 69.5577
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 75.6918
                       Mean reward: 205.23
               Mean episode length: 210.62
    Episode_Reward/reaching_object: 1.2777
    Episode_Reward/rotating_object: 35.8514
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.89s
                      Time elapsed: 00:27:09
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14357 steps/s (collection: 6.699s, learning 0.148s)
             Mean action noise std: 2.80
          Mean value_function loss: 65.3068
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 75.7224
                       Mean reward: 180.91
               Mean episode length: 212.49
    Episode_Reward/reaching_object: 1.2882
    Episode_Reward/rotating_object: 36.5165
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.85s
                      Time elapsed: 00:27:16
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14442 steps/s (collection: 6.643s, learning 0.164s)
             Mean action noise std: 2.80
          Mean value_function loss: 70.7874
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 75.7450
                       Mean reward: 188.51
               Mean episode length: 221.05
    Episode_Reward/reaching_object: 1.3439
    Episode_Reward/rotating_object: 39.0775
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0594
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.81s
                      Time elapsed: 00:27:22
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14340 steps/s (collection: 6.687s, learning 0.169s)
             Mean action noise std: 2.80
          Mean value_function loss: 66.5051
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 75.7769
                       Mean reward: 203.82
               Mean episode length: 222.19
    Episode_Reward/reaching_object: 1.3280
    Episode_Reward/rotating_object: 38.6627
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0611
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.86s
                      Time elapsed: 00:27:29
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14536 steps/s (collection: 6.593s, learning 0.170s)
             Mean action noise std: 2.81
          Mean value_function loss: 66.4380
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 75.8106
                       Mean reward: 200.59
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 1.3251
    Episode_Reward/rotating_object: 37.1283
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0605
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.76s
                      Time elapsed: 00:27:36
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 20321 steps/s (collection: 4.675s, learning 0.163s)
             Mean action noise std: 2.81
          Mean value_function loss: 67.0243
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 75.8523
                       Mean reward: 218.32
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.3170
    Episode_Reward/rotating_object: 38.3065
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.84s
                      Time elapsed: 00:27:41
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 46383 steps/s (collection: 2.011s, learning 0.108s)
             Mean action noise std: 2.81
          Mean value_function loss: 57.9513
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 75.8908
                       Mean reward: 219.57
               Mean episode length: 215.27
    Episode_Reward/reaching_object: 1.2952
    Episode_Reward/rotating_object: 36.4781
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.12s
                      Time elapsed: 00:27:43
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 46233 steps/s (collection: 2.009s, learning 0.117s)
             Mean action noise std: 2.82
          Mean value_function loss: 65.3629
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 75.9232
                       Mean reward: 173.44
               Mean episode length: 219.53
    Episode_Reward/reaching_object: 1.3189
    Episode_Reward/rotating_object: 37.1721
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.13s
                      Time elapsed: 00:27:45
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 48308 steps/s (collection: 1.899s, learning 0.136s)
             Mean action noise std: 2.82
          Mean value_function loss: 69.7506
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 75.9683
                       Mean reward: 204.18
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 1.3206
    Episode_Reward/rotating_object: 41.2726
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.03s
                      Time elapsed: 00:27:47
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 48890 steps/s (collection: 1.919s, learning 0.092s)
             Mean action noise std: 2.82
          Mean value_function loss: 60.5908
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 76.0062
                       Mean reward: 202.56
               Mean episode length: 215.39
    Episode_Reward/reaching_object: 1.2653
    Episode_Reward/rotating_object: 36.3124
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.01s
                      Time elapsed: 00:27:49
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 49512 steps/s (collection: 1.857s, learning 0.128s)
             Mean action noise std: 2.83
          Mean value_function loss: 64.9132
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 76.0360
                       Mean reward: 207.70
               Mean episode length: 216.98
    Episode_Reward/reaching_object: 1.2819
    Episode_Reward/rotating_object: 35.7294
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0597
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.99s
                      Time elapsed: 00:27:51
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 46672 steps/s (collection: 1.939s, learning 0.168s)
             Mean action noise std: 2.83
          Mean value_function loss: 65.8758
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 76.0637
                       Mean reward: 186.07
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.2986
    Episode_Reward/rotating_object: 38.7733
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.11s
                      Time elapsed: 00:27:53
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 49308 steps/s (collection: 1.850s, learning 0.144s)
             Mean action noise std: 2.83
          Mean value_function loss: 61.8016
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 76.0989
                       Mean reward: 209.56
               Mean episode length: 222.69
    Episode_Reward/reaching_object: 1.2852
    Episode_Reward/rotating_object: 37.2684
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.99s
                      Time elapsed: 00:27:55
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 46680 steps/s (collection: 1.938s, learning 0.168s)
             Mean action noise std: 2.84
          Mean value_function loss: 59.4956
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 76.1423
                       Mean reward: 201.63
               Mean episode length: 223.28
    Episode_Reward/reaching_object: 1.3323
    Episode_Reward/rotating_object: 39.3435
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0592
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.11s
                      Time elapsed: 00:27:57
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 48385 steps/s (collection: 1.905s, learning 0.127s)
             Mean action noise std: 2.84
          Mean value_function loss: 70.7831
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 76.1893
                       Mean reward: 185.29
               Mean episode length: 213.50
    Episode_Reward/reaching_object: 1.2725
    Episode_Reward/rotating_object: 40.8350
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0584
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.03s
                      Time elapsed: 00:27:59
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 46955 steps/s (collection: 1.956s, learning 0.137s)
             Mean action noise std: 2.85
          Mean value_function loss: 73.9342
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 76.2347
                       Mean reward: 198.86
               Mean episode length: 207.75
    Episode_Reward/reaching_object: 1.2736
    Episode_Reward/rotating_object: 36.9081
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.09s
                      Time elapsed: 00:28:02
                               ETA: 00:33:18

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 49195 steps/s (collection: 1.903s, learning 0.096s)
             Mean action noise std: 2.85
          Mean value_function loss: 77.0622
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 76.2734
                       Mean reward: 209.48
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 1.2875
    Episode_Reward/rotating_object: 36.3202
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.00s
                      Time elapsed: 00:28:04
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 47788 steps/s (collection: 1.910s, learning 0.147s)
             Mean action noise std: 2.85
          Mean value_function loss: 77.9801
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 76.3056
                       Mean reward: 199.64
               Mean episode length: 201.73
    Episode_Reward/reaching_object: 1.2409
    Episode_Reward/rotating_object: 40.7826
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.06s
                      Time elapsed: 00:28:06
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 41483 steps/s (collection: 2.232s, learning 0.138s)
             Mean action noise std: 2.86
          Mean value_function loss: 62.1550
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 76.3386
                       Mean reward: 215.93
               Mean episode length: 219.75
    Episode_Reward/reaching_object: 1.2714
    Episode_Reward/rotating_object: 38.4978
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.37s
                      Time elapsed: 00:28:08
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 46491 steps/s (collection: 1.973s, learning 0.142s)
             Mean action noise std: 2.86
          Mean value_function loss: 73.3014
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 76.3784
                       Mean reward: 171.48
               Mean episode length: 211.58
    Episode_Reward/reaching_object: 1.2654
    Episode_Reward/rotating_object: 33.9054
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0584
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.11s
                      Time elapsed: 00:28:10
                               ETA: 00:33:07

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 47398 steps/s (collection: 1.930s, learning 0.144s)
             Mean action noise std: 2.86
          Mean value_function loss: 61.6336
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 76.4097
                       Mean reward: 211.67
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 1.2985
    Episode_Reward/rotating_object: 36.3916
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.07s
                      Time elapsed: 00:28:12
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 45718 steps/s (collection: 1.949s, learning 0.201s)
             Mean action noise std: 2.87
          Mean value_function loss: 72.7586
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 76.4412
                       Mean reward: 196.21
               Mean episode length: 219.10
    Episode_Reward/reaching_object: 1.2657
    Episode_Reward/rotating_object: 35.3804
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0592
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.15s
                      Time elapsed: 00:28:14
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 47016 steps/s (collection: 1.907s, learning 0.184s)
             Mean action noise std: 2.87
          Mean value_function loss: 74.5232
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 76.4881
                       Mean reward: 185.10
               Mean episode length: 216.86
    Episode_Reward/reaching_object: 1.2501
    Episode_Reward/rotating_object: 35.8436
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.09s
                      Time elapsed: 00:28:16
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 46648 steps/s (collection: 1.959s, learning 0.148s)
             Mean action noise std: 2.87
          Mean value_function loss: 82.7290
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 76.5315
                       Mean reward: 178.80
               Mean episode length: 204.20
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 34.3288
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.11s
                      Time elapsed: 00:28:19
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 48475 steps/s (collection: 1.905s, learning 0.123s)
             Mean action noise std: 2.88
          Mean value_function loss: 72.8508
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 76.5567
                       Mean reward: 175.26
               Mean episode length: 209.31
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 34.8610
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.03s
                      Time elapsed: 00:28:21
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 46202 steps/s (collection: 1.931s, learning 0.196s)
             Mean action noise std: 2.88
          Mean value_function loss: 72.3863
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 76.5927
                       Mean reward: 140.74
               Mean episode length: 193.98
    Episode_Reward/reaching_object: 1.2751
    Episode_Reward/rotating_object: 37.6498
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.13s
                      Time elapsed: 00:28:23
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 48019 steps/s (collection: 1.891s, learning 0.157s)
             Mean action noise std: 2.88
          Mean value_function loss: 67.5169
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 76.6299
                       Mean reward: 178.50
               Mean episode length: 211.77
    Episode_Reward/reaching_object: 1.2636
    Episode_Reward/rotating_object: 36.6807
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0610
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.05s
                      Time elapsed: 00:28:25
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 46793 steps/s (collection: 1.931s, learning 0.170s)
             Mean action noise std: 2.89
          Mean value_function loss: 71.6780
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 76.6574
                       Mean reward: 197.16
               Mean episode length: 216.55
    Episode_Reward/reaching_object: 1.2839
    Episode_Reward/rotating_object: 40.5770
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0608
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.10s
                      Time elapsed: 00:28:27
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 45951 steps/s (collection: 2.013s, learning 0.126s)
             Mean action noise std: 2.89
          Mean value_function loss: 80.0883
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 76.6855
                       Mean reward: 168.71
               Mean episode length: 212.77
    Episode_Reward/reaching_object: 1.2825
    Episode_Reward/rotating_object: 34.0757
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.14s
                      Time elapsed: 00:28:29
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 47341 steps/s (collection: 1.954s, learning 0.122s)
             Mean action noise std: 2.89
          Mean value_function loss: 76.5968
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 76.7242
                       Mean reward: 219.76
               Mean episode length: 209.83
    Episode_Reward/reaching_object: 1.3087
    Episode_Reward/rotating_object: 40.8295
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.08s
                      Time elapsed: 00:28:31
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 48256 steps/s (collection: 1.931s, learning 0.107s)
             Mean action noise std: 2.89
          Mean value_function loss: 75.4075
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 76.7550
                       Mean reward: 174.45
               Mean episode length: 214.76
    Episode_Reward/reaching_object: 1.2967
    Episode_Reward/rotating_object: 35.4235
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.04s
                      Time elapsed: 00:28:33
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 45205 steps/s (collection: 2.011s, learning 0.164s)
             Mean action noise std: 2.90
          Mean value_function loss: 85.3967
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 76.7870
                       Mean reward: 206.99
               Mean episode length: 224.96
    Episode_Reward/reaching_object: 1.3088
    Episode_Reward/rotating_object: 37.1472
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0611
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.17s
                      Time elapsed: 00:28:35
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 47716 steps/s (collection: 1.923s, learning 0.138s)
             Mean action noise std: 2.90
          Mean value_function loss: 67.9929
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 76.8240
                       Mean reward: 200.75
               Mean episode length: 215.04
    Episode_Reward/reaching_object: 1.3240
    Episode_Reward/rotating_object: 37.3772
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.06s
                      Time elapsed: 00:28:37
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 47834 steps/s (collection: 1.939s, learning 0.116s)
             Mean action noise std: 2.90
          Mean value_function loss: 74.9521
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 76.8584
                       Mean reward: 206.71
               Mean episode length: 211.17
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 31.7612
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0592
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.06s
                      Time elapsed: 00:28:39
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 46958 steps/s (collection: 1.961s, learning 0.132s)
             Mean action noise std: 2.91
          Mean value_function loss: 75.5216
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 76.8841
                       Mean reward: 171.87
               Mean episode length: 221.78
    Episode_Reward/reaching_object: 1.2753
    Episode_Reward/rotating_object: 34.9361
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.09s
                      Time elapsed: 00:28:41
                               ETA: 00:32:24

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 48168 steps/s (collection: 1.895s, learning 0.146s)
             Mean action noise std: 2.91
          Mean value_function loss: 71.4951
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 76.9130
                       Mean reward: 206.93
               Mean episode length: 213.91
    Episode_Reward/reaching_object: 1.2964
    Episode_Reward/rotating_object: 39.2018
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.04s
                      Time elapsed: 00:28:43
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 48398 steps/s (collection: 1.891s, learning 0.140s)
             Mean action noise std: 2.91
          Mean value_function loss: 74.4753
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 76.9577
                       Mean reward: 177.73
               Mean episode length: 208.92
    Episode_Reward/reaching_object: 1.2797
    Episode_Reward/rotating_object: 36.7849
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.03s
                      Time elapsed: 00:28:46
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 46600 steps/s (collection: 1.968s, learning 0.141s)
             Mean action noise std: 2.92
          Mean value_function loss: 78.8502
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 76.9966
                       Mean reward: 189.77
               Mean episode length: 213.87
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 35.9921
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.11s
                      Time elapsed: 00:28:48
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 48086 steps/s (collection: 1.926s, learning 0.118s)
             Mean action noise std: 2.92
          Mean value_function loss: 75.1972
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 77.0375
                       Mean reward: 219.26
               Mean episode length: 217.28
    Episode_Reward/reaching_object: 1.3197
    Episode_Reward/rotating_object: 38.7937
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.04s
                      Time elapsed: 00:28:50
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 47749 steps/s (collection: 1.939s, learning 0.120s)
             Mean action noise std: 2.93
          Mean value_function loss: 62.6729
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 77.0759
                       Mean reward: 199.34
               Mean episode length: 198.96
    Episode_Reward/reaching_object: 1.2589
    Episode_Reward/rotating_object: 38.9491
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.06s
                      Time elapsed: 00:28:52
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 47189 steps/s (collection: 1.941s, learning 0.143s)
             Mean action noise std: 2.93
          Mean value_function loss: 65.9185
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 77.1178
                       Mean reward: 210.65
               Mean episode length: 216.74
    Episode_Reward/reaching_object: 1.2533
    Episode_Reward/rotating_object: 37.7468
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.08s
                      Time elapsed: 00:28:54
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 46164 steps/s (collection: 2.003s, learning 0.127s)
             Mean action noise std: 2.93
          Mean value_function loss: 71.0284
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 77.1615
                       Mean reward: 188.85
               Mean episode length: 206.22
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 38.0644
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.13s
                      Time elapsed: 00:28:56
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 48404 steps/s (collection: 1.918s, learning 0.113s)
             Mean action noise std: 2.94
          Mean value_function loss: 68.2930
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 77.2008
                       Mean reward: 198.23
               Mean episode length: 208.91
    Episode_Reward/reaching_object: 1.2223
    Episode_Reward/rotating_object: 38.5421
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.03s
                      Time elapsed: 00:28:58
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 46356 steps/s (collection: 1.979s, learning 0.142s)
             Mean action noise std: 2.94
          Mean value_function loss: 64.5280
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 77.2407
                       Mean reward: 205.25
               Mean episode length: 214.88
    Episode_Reward/reaching_object: 1.2553
    Episode_Reward/rotating_object: 39.0354
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.12s
                      Time elapsed: 00:29:00
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 46698 steps/s (collection: 1.953s, learning 0.152s)
             Mean action noise std: 2.94
          Mean value_function loss: 68.8580
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 77.2751
                       Mean reward: 213.65
               Mean episode length: 216.35
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 39.2664
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.11s
                      Time elapsed: 00:29:02
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 47581 steps/s (collection: 1.924s, learning 0.142s)
             Mean action noise std: 2.95
          Mean value_function loss: 69.1838
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 77.3107
                       Mean reward: 199.42
               Mean episode length: 213.83
    Episode_Reward/reaching_object: 1.2386
    Episode_Reward/rotating_object: 35.8588
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.07s
                      Time elapsed: 00:29:04
                               ETA: 00:31:52

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 47962 steps/s (collection: 1.921s, learning 0.129s)
             Mean action noise std: 2.95
          Mean value_function loss: 71.2902
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 77.3399
                       Mean reward: 249.55
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 1.2842
    Episode_Reward/rotating_object: 41.8997
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.05s
                      Time elapsed: 00:29:06
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 45287 steps/s (collection: 1.982s, learning 0.189s)
             Mean action noise std: 2.96
          Mean value_function loss: 76.3442
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 77.3784
                       Mean reward: 162.81
               Mean episode length: 206.58
    Episode_Reward/reaching_object: 1.2627
    Episode_Reward/rotating_object: 34.7518
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.17s
                      Time elapsed: 00:29:08
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 43779 steps/s (collection: 2.024s, learning 0.221s)
             Mean action noise std: 2.96
          Mean value_function loss: 66.7943
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 77.4237
                       Mean reward: 194.99
               Mean episode length: 209.47
    Episode_Reward/reaching_object: 1.2927
    Episode_Reward/rotating_object: 37.1697
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.25s
                      Time elapsed: 00:29:11
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 44548 steps/s (collection: 2.081s, learning 0.126s)
             Mean action noise std: 2.96
          Mean value_function loss: 68.5102
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 77.4683
                       Mean reward: 208.90
               Mean episode length: 212.99
    Episode_Reward/reaching_object: 1.2619
    Episode_Reward/rotating_object: 39.9049
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0614
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.21s
                      Time elapsed: 00:29:13
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 44823 steps/s (collection: 2.043s, learning 0.150s)
             Mean action noise std: 2.97
          Mean value_function loss: 74.3046
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 77.5013
                       Mean reward: 183.08
               Mean episode length: 189.85
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 39.0952
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.19s
                      Time elapsed: 00:29:15
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 46380 steps/s (collection: 1.995s, learning 0.124s)
             Mean action noise std: 2.97
          Mean value_function loss: 72.8888
               Mean surrogate loss: -0.0113
                 Mean entropy loss: 77.5321
                       Mean reward: 219.27
               Mean episode length: 223.31
    Episode_Reward/reaching_object: 1.2860
    Episode_Reward/rotating_object: 37.8926
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0633
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.12s
                      Time elapsed: 00:29:17
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 42775 steps/s (collection: 2.079s, learning 0.220s)
             Mean action noise std: 2.97
          Mean value_function loss: 65.2517
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 77.5691
                       Mean reward: 197.07
               Mean episode length: 206.91
    Episode_Reward/reaching_object: 1.2622
    Episode_Reward/rotating_object: 36.5411
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0625
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.30s
                      Time elapsed: 00:29:20
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 46903 steps/s (collection: 1.992s, learning 0.104s)
             Mean action noise std: 2.98
          Mean value_function loss: 70.4247
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 77.6077
                       Mean reward: 185.28
               Mean episode length: 201.79
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 33.9261
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.10s
                      Time elapsed: 00:29:22
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 50637 steps/s (collection: 1.830s, learning 0.111s)
             Mean action noise std: 2.98
          Mean value_function loss: 70.8815
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 77.6528
                       Mean reward: 179.06
               Mean episode length: 216.25
    Episode_Reward/reaching_object: 1.2682
    Episode_Reward/rotating_object: 38.1960
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0622
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.94s
                      Time elapsed: 00:29:24
                               ETA: 00:31:28

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 49502 steps/s (collection: 1.874s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 78.4310
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 77.6958
                       Mean reward: 171.64
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.2511
    Episode_Reward/rotating_object: 35.2232
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0625
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.99s
                      Time elapsed: 00:29:26
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 50909 steps/s (collection: 1.836s, learning 0.095s)
             Mean action noise std: 2.99
          Mean value_function loss: 72.1774
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 77.7345
                       Mean reward: 205.01
               Mean episode length: 220.51
    Episode_Reward/reaching_object: 1.3251
    Episode_Reward/rotating_object: 41.5111
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.93s
                      Time elapsed: 00:29:28
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 50033 steps/s (collection: 1.846s, learning 0.119s)
             Mean action noise std: 2.99
          Mean value_function loss: 75.4916
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 77.7628
                       Mean reward: 172.56
               Mean episode length: 207.90
    Episode_Reward/reaching_object: 1.2222
    Episode_Reward/rotating_object: 34.8396
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0622
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.96s
                      Time elapsed: 00:29:29
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 49491 steps/s (collection: 1.864s, learning 0.122s)
             Mean action noise std: 2.99
          Mean value_function loss: 81.3322
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 77.7913
                       Mean reward: 175.94
               Mean episode length: 224.36
    Episode_Reward/reaching_object: 1.2977
    Episode_Reward/rotating_object: 35.0382
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.99s
                      Time elapsed: 00:29:31
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 47148 steps/s (collection: 1.952s, learning 0.133s)
             Mean action noise std: 3.00
          Mean value_function loss: 79.4742
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 77.8281
                       Mean reward: 197.36
               Mean episode length: 219.78
    Episode_Reward/reaching_object: 1.2444
    Episode_Reward/rotating_object: 37.5088
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.08s
                      Time elapsed: 00:29:34
                               ETA: 00:31:13

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 46607 steps/s (collection: 2.011s, learning 0.099s)
             Mean action noise std: 3.00
          Mean value_function loss: 83.3989
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 77.8620
                       Mean reward: 164.91
               Mean episode length: 212.41
    Episode_Reward/reaching_object: 1.2497
    Episode_Reward/rotating_object: 38.4185
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.11s
                      Time elapsed: 00:29:36
                               ETA: 00:31:10

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 43201 steps/s (collection: 2.084s, learning 0.192s)
             Mean action noise std: 3.01
          Mean value_function loss: 85.0520
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 77.8997
                       Mean reward: 206.79
               Mean episode length: 209.96
    Episode_Reward/reaching_object: 1.2852
    Episode_Reward/rotating_object: 40.0873
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0631
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.28s
                      Time elapsed: 00:29:38
                               ETA: 00:31:08

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 42307 steps/s (collection: 2.168s, learning 0.156s)
             Mean action noise std: 3.01
          Mean value_function loss: 79.8536
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 77.9286
                       Mean reward: 213.13
               Mean episode length: 220.16
    Episode_Reward/reaching_object: 1.2985
    Episode_Reward/rotating_object: 40.1688
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0631
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.32s
                      Time elapsed: 00:29:40
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 46363 steps/s (collection: 1.997s, learning 0.123s)
             Mean action noise std: 3.01
          Mean value_function loss: 77.0994
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 77.9608
                       Mean reward: 223.63
               Mean episode length: 218.42
    Episode_Reward/reaching_object: 1.2474
    Episode_Reward/rotating_object: 37.7944
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0633
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.12s
                      Time elapsed: 00:29:42
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 39672 steps/s (collection: 2.336s, learning 0.142s)
             Mean action noise std: 3.02
          Mean value_function loss: 71.6957
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 77.9973
                       Mean reward: 203.66
               Mean episode length: 205.41
    Episode_Reward/reaching_object: 1.2768
    Episode_Reward/rotating_object: 39.6308
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0629
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.48s
                      Time elapsed: 00:29:45
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 40340 steps/s (collection: 2.256s, learning 0.181s)
             Mean action noise std: 3.02
          Mean value_function loss: 82.1646
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 78.0426
                       Mean reward: 214.44
               Mean episode length: 214.61
    Episode_Reward/reaching_object: 1.2758
    Episode_Reward/rotating_object: 40.0929
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.44s
                      Time elapsed: 00:29:47
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 40905 steps/s (collection: 2.236s, learning 0.167s)
             Mean action noise std: 3.02
          Mean value_function loss: 86.0294
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.0831
                       Mean reward: 196.02
               Mean episode length: 208.15
    Episode_Reward/reaching_object: 1.2625
    Episode_Reward/rotating_object: 40.2349
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0617
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.40s
                      Time elapsed: 00:29:50
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 45283 steps/s (collection: 2.073s, learning 0.098s)
             Mean action noise std: 3.03
          Mean value_function loss: 80.9983
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 78.1185
                       Mean reward: 187.92
               Mean episode length: 207.58
    Episode_Reward/reaching_object: 1.2461
    Episode_Reward/rotating_object: 38.8279
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.17s
                      Time elapsed: 00:29:52
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 43763 steps/s (collection: 2.122s, learning 0.124s)
             Mean action noise std: 3.03
          Mean value_function loss: 76.3958
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 78.1540
                       Mean reward: 215.91
               Mean episode length: 212.17
    Episode_Reward/reaching_object: 1.2669
    Episode_Reward/rotating_object: 43.1803
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.25s
                      Time elapsed: 00:29:54
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 39973 steps/s (collection: 2.350s, learning 0.110s)
             Mean action noise std: 3.03
          Mean value_function loss: 80.1160
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 78.1908
                       Mean reward: 200.90
               Mean episode length: 219.29
    Episode_Reward/reaching_object: 1.2766
    Episode_Reward/rotating_object: 39.8746
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0634
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.46s
                      Time elapsed: 00:29:57
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 45765 steps/s (collection: 2.002s, learning 0.146s)
             Mean action noise std: 3.04
          Mean value_function loss: 81.5017
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 78.2259
                       Mean reward: 262.00
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.2718
    Episode_Reward/rotating_object: 36.6766
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.15s
                      Time elapsed: 00:29:59
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 43101 steps/s (collection: 2.163s, learning 0.118s)
             Mean action noise std: 3.04
          Mean value_function loss: 88.3547
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 78.2653
                       Mean reward: 227.82
               Mean episode length: 218.39
    Episode_Reward/reaching_object: 1.2987
    Episode_Reward/rotating_object: 40.6113
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.28s
                      Time elapsed: 00:30:01
                               ETA: 00:30:42

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 43482 steps/s (collection: 2.115s, learning 0.146s)
             Mean action noise std: 3.05
          Mean value_function loss: 77.9577
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 78.3071
                       Mean reward: 180.05
               Mean episode length: 202.53
    Episode_Reward/reaching_object: 1.2458
    Episode_Reward/rotating_object: 36.3665
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.26s
                      Time elapsed: 00:30:03
                               ETA: 00:30:40

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 34891 steps/s (collection: 2.683s, learning 0.134s)
             Mean action noise std: 3.05
          Mean value_function loss: 77.9871
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 78.3355
                       Mean reward: 203.67
               Mean episode length: 215.55
    Episode_Reward/reaching_object: 1.2792
    Episode_Reward/rotating_object: 36.2390
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0630
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.82s
                      Time elapsed: 00:30:06
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 41362 steps/s (collection: 2.259s, learning 0.118s)
             Mean action noise std: 3.05
          Mean value_function loss: 80.5930
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 78.3688
                       Mean reward: 213.64
               Mean episode length: 218.59
    Episode_Reward/reaching_object: 1.2802
    Episode_Reward/rotating_object: 40.0922
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0640
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.38s
                      Time elapsed: 00:30:08
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 41679 steps/s (collection: 2.233s, learning 0.126s)
             Mean action noise std: 3.06
          Mean value_function loss: 77.6369
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 78.4021
                       Mean reward: 212.74
               Mean episode length: 213.24
    Episode_Reward/reaching_object: 1.2384
    Episode_Reward/rotating_object: 36.7800
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.36s
                      Time elapsed: 00:30:11
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 45652 steps/s (collection: 2.013s, learning 0.141s)
             Mean action noise std: 3.06
          Mean value_function loss: 95.6516
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 78.4332
                       Mean reward: 222.15
               Mean episode length: 211.12
    Episode_Reward/reaching_object: 1.2844
    Episode_Reward/rotating_object: 41.9071
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0633
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.15s
                      Time elapsed: 00:30:13
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 41567 steps/s (collection: 2.247s, learning 0.118s)
             Mean action noise std: 3.06
          Mean value_function loss: 88.5145
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 78.4674
                       Mean reward: 208.93
               Mean episode length: 220.33
    Episode_Reward/reaching_object: 1.2971
    Episode_Reward/rotating_object: 38.9914
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.36s
                      Time elapsed: 00:30:15
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 37823 steps/s (collection: 2.427s, learning 0.172s)
             Mean action noise std: 3.07
          Mean value_function loss: 91.4275
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 78.5075
                       Mean reward: 198.69
               Mean episode length: 215.84
    Episode_Reward/reaching_object: 1.2944
    Episode_Reward/rotating_object: 40.3335
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.60s
                      Time elapsed: 00:30:18
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 41027 steps/s (collection: 2.294s, learning 0.102s)
             Mean action noise std: 3.07
          Mean value_function loss: 90.3774
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 78.5434
                       Mean reward: 219.93
               Mean episode length: 208.69
    Episode_Reward/reaching_object: 1.2917
    Episode_Reward/rotating_object: 42.2731
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.40s
                      Time elapsed: 00:30:20
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 48750 steps/s (collection: 1.920s, learning 0.097s)
             Mean action noise std: 3.07
          Mean value_function loss: 92.7905
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 78.5745
                       Mean reward: 215.16
               Mean episode length: 210.45
    Episode_Reward/reaching_object: 1.2668
    Episode_Reward/rotating_object: 43.5209
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.02s
                      Time elapsed: 00:30:22
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 48956 steps/s (collection: 1.912s, learning 0.096s)
             Mean action noise std: 3.08
          Mean value_function loss: 79.2817
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 78.5963
                       Mean reward: 210.41
               Mean episode length: 207.35
    Episode_Reward/reaching_object: 1.2804
    Episode_Reward/rotating_object: 41.4695
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.01s
                      Time elapsed: 00:30:24
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 50252 steps/s (collection: 1.865s, learning 0.092s)
             Mean action noise std: 3.08
          Mean value_function loss: 91.8336
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.6261
                       Mean reward: 179.89
               Mean episode length: 204.08
    Episode_Reward/reaching_object: 1.2968
    Episode_Reward/rotating_object: 40.3193
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.96s
                      Time elapsed: 00:30:26
                               ETA: 00:30:14

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 49402 steps/s (collection: 1.897s, learning 0.093s)
             Mean action noise std: 3.08
          Mean value_function loss: 78.3301
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 78.6519
                       Mean reward: 224.68
               Mean episode length: 206.48
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 39.7178
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0621
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.99s
                      Time elapsed: 00:30:28
                               ETA: 00:30:11

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 49453 steps/s (collection: 1.867s, learning 0.121s)
             Mean action noise std: 3.08
          Mean value_function loss: 82.9398
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 78.6684
                       Mean reward: 240.74
               Mean episode length: 218.61
    Episode_Reward/reaching_object: 1.2966
    Episode_Reward/rotating_object: 41.7944
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.99s
                      Time elapsed: 00:30:30
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 49057 steps/s (collection: 1.886s, learning 0.118s)
             Mean action noise std: 3.09
          Mean value_function loss: 88.3504
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 78.6963
                       Mean reward: 227.67
               Mean episode length: 213.56
    Episode_Reward/reaching_object: 1.2825
    Episode_Reward/rotating_object: 37.5521
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.00s
                      Time elapsed: 00:30:32
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 49919 steps/s (collection: 1.856s, learning 0.113s)
             Mean action noise std: 3.09
          Mean value_function loss: 79.1674
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 78.7316
                       Mean reward: 225.24
               Mean episode length: 208.59
    Episode_Reward/reaching_object: 1.2787
    Episode_Reward/rotating_object: 40.8133
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.97s
                      Time elapsed: 00:30:34
                               ETA: 00:30:03

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 49983 steps/s (collection: 1.873s, learning 0.094s)
             Mean action noise std: 3.09
          Mean value_function loss: 82.4383
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 78.7661
                       Mean reward: 172.38
               Mean episode length: 200.77
    Episode_Reward/reaching_object: 1.2758
    Episode_Reward/rotating_object: 37.5107
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.97s
                      Time elapsed: 00:30:36
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 46161 steps/s (collection: 2.017s, learning 0.113s)
             Mean action noise std: 3.10
          Mean value_function loss: 89.7229
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 78.7989
                       Mean reward: 199.74
               Mean episode length: 212.59
    Episode_Reward/reaching_object: 1.2860
    Episode_Reward/rotating_object: 40.6568
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.13s
                      Time elapsed: 00:30:38
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 48776 steps/s (collection: 1.919s, learning 0.096s)
             Mean action noise std: 3.10
          Mean value_function loss: 83.0424
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 78.8340
                       Mean reward: 249.99
               Mean episode length: 226.60
    Episode_Reward/reaching_object: 1.2941
    Episode_Reward/rotating_object: 42.6324
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.02s
                      Time elapsed: 00:30:40
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 48306 steps/s (collection: 1.884s, learning 0.151s)
             Mean action noise std: 3.10
          Mean value_function loss: 94.4830
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 78.8685
                       Mean reward: 184.54
               Mean episode length: 199.94
    Episode_Reward/reaching_object: 1.2433
    Episode_Reward/rotating_object: 36.7619
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.04s
                      Time elapsed: 00:30:42
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 36817 steps/s (collection: 2.455s, learning 0.215s)
             Mean action noise std: 3.11
          Mean value_function loss: 83.9777
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 78.8971
                       Mean reward: 196.44
               Mean episode length: 209.72
    Episode_Reward/reaching_object: 1.2931
    Episode_Reward/rotating_object: 41.6416
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.67s
                      Time elapsed: 00:30:45
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 43184 steps/s (collection: 2.134s, learning 0.142s)
             Mean action noise std: 3.11
          Mean value_function loss: 83.0502
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 78.9396
                       Mean reward: 223.68
               Mean episode length: 212.72
    Episode_Reward/reaching_object: 1.2414
    Episode_Reward/rotating_object: 38.5147
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.28s
                      Time elapsed: 00:30:47
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 42983 steps/s (collection: 2.075s, learning 0.212s)
             Mean action noise std: 3.11
          Mean value_function loss: 82.7709
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 78.9746
                       Mean reward: 186.90
               Mean episode length: 198.32
    Episode_Reward/reaching_object: 1.2565
    Episode_Reward/rotating_object: 38.4679
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.29s
                      Time elapsed: 00:30:50
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 39016 steps/s (collection: 2.381s, learning 0.139s)
             Mean action noise std: 3.12
          Mean value_function loss: 89.1463
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 78.9965
                       Mean reward: 241.08
               Mean episode length: 217.85
    Episode_Reward/reaching_object: 1.2917
    Episode_Reward/rotating_object: 46.2512
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.52s
                      Time elapsed: 00:30:52
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 44630 steps/s (collection: 2.096s, learning 0.107s)
             Mean action noise std: 3.12
          Mean value_function loss: 87.5013
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 79.0244
                       Mean reward: 209.60
               Mean episode length: 214.40
    Episode_Reward/reaching_object: 1.2802
    Episode_Reward/rotating_object: 38.8495
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.20s
                      Time elapsed: 00:30:54
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 45101 steps/s (collection: 2.080s, learning 0.099s)
             Mean action noise std: 3.12
          Mean value_function loss: 80.9980
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 79.0519
                       Mean reward: 223.98
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 1.2778
    Episode_Reward/rotating_object: 40.5315
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.18s
                      Time elapsed: 00:30:57
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 49439 steps/s (collection: 1.890s, learning 0.098s)
             Mean action noise std: 3.13
          Mean value_function loss: 84.6138
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 79.0846
                       Mean reward: 243.67
               Mean episode length: 216.04
    Episode_Reward/reaching_object: 1.2749
    Episode_Reward/rotating_object: 43.2938
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.99s
                      Time elapsed: 00:30:59
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 47734 steps/s (collection: 1.942s, learning 0.118s)
             Mean action noise std: 3.13
          Mean value_function loss: 92.1559
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 79.1156
                       Mean reward: 242.92
               Mean episode length: 210.09
    Episode_Reward/reaching_object: 1.2524
    Episode_Reward/rotating_object: 40.8557
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.06s
                      Time elapsed: 00:31:01
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 49104 steps/s (collection: 1.886s, learning 0.116s)
             Mean action noise std: 3.13
          Mean value_function loss: 84.8626
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 79.1416
                       Mean reward: 206.33
               Mean episode length: 213.61
    Episode_Reward/reaching_object: 1.2728
    Episode_Reward/rotating_object: 38.7892
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.00s
                      Time elapsed: 00:31:03
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 49998 steps/s (collection: 1.856s, learning 0.110s)
             Mean action noise std: 3.14
          Mean value_function loss: 95.0901
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 79.1712
                       Mean reward: 195.47
               Mean episode length: 209.17
    Episode_Reward/reaching_object: 1.2755
    Episode_Reward/rotating_object: 42.4042
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.97s
                      Time elapsed: 00:31:05
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 49602 steps/s (collection: 1.873s, learning 0.109s)
             Mean action noise std: 3.14
          Mean value_function loss: 93.2328
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 79.2074
                       Mean reward: 228.39
               Mean episode length: 203.56
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 43.1753
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.98s
                      Time elapsed: 00:31:07
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 49661 steps/s (collection: 1.878s, learning 0.101s)
             Mean action noise std: 3.14
          Mean value_function loss: 86.5241
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 79.2498
                       Mean reward: 196.53
               Mean episode length: 194.93
    Episode_Reward/reaching_object: 1.2297
    Episode_Reward/rotating_object: 38.8986
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.98s
                      Time elapsed: 00:31:09
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 49780 steps/s (collection: 1.882s, learning 0.093s)
             Mean action noise std: 3.15
          Mean value_function loss: 96.9925
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 79.2822
                       Mean reward: 260.68
               Mean episode length: 220.28
    Episode_Reward/reaching_object: 1.2868
    Episode_Reward/rotating_object: 44.9230
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.97s
                      Time elapsed: 00:31:10
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 50936 steps/s (collection: 1.834s, learning 0.096s)
             Mean action noise std: 3.15
          Mean value_function loss: 81.0263
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 79.3154
                       Mean reward: 226.60
               Mean episode length: 208.66
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 42.3600
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.93s
                      Time elapsed: 00:31:12
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 49459 steps/s (collection: 1.895s, learning 0.093s)
             Mean action noise std: 3.15
          Mean value_function loss: 82.3041
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 79.3529
                       Mean reward: 180.14
               Mean episode length: 205.06
    Episode_Reward/reaching_object: 1.2638
    Episode_Reward/rotating_object: 40.5460
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0633
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.99s
                      Time elapsed: 00:31:14
                               ETA: 00:29:11

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 48040 steps/s (collection: 1.954s, learning 0.093s)
             Mean action noise std: 3.16
          Mean value_function loss: 87.3958
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 79.3799
                       Mean reward: 191.14
               Mean episode length: 201.25
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 42.7556
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.05s
                      Time elapsed: 00:31:16
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 48395 steps/s (collection: 1.932s, learning 0.099s)
             Mean action noise std: 3.16
          Mean value_function loss: 83.6810
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 79.4147
                       Mean reward: 190.67
               Mean episode length: 211.70
    Episode_Reward/reaching_object: 1.2382
    Episode_Reward/rotating_object: 38.4595
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.03s
                      Time elapsed: 00:31:18
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 49810 steps/s (collection: 1.879s, learning 0.095s)
             Mean action noise std: 3.16
          Mean value_function loss: 90.6976
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 79.4413
                       Mean reward: 242.16
               Mean episode length: 223.71
    Episode_Reward/reaching_object: 1.2708
    Episode_Reward/rotating_object: 44.2334
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.97s
                      Time elapsed: 00:31:20
                               ETA: 00:29:03

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 47662 steps/s (collection: 1.960s, learning 0.102s)
             Mean action noise std: 3.17
          Mean value_function loss: 86.8945
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 79.4791
                       Mean reward: 240.59
               Mean episode length: 209.74
    Episode_Reward/reaching_object: 1.2634
    Episode_Reward/rotating_object: 44.1185
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.06s
                      Time elapsed: 00:31:23
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 48423 steps/s (collection: 1.911s, learning 0.120s)
             Mean action noise std: 3.17
          Mean value_function loss: 83.5661
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 79.5246
                       Mean reward: 179.26
               Mean episode length: 207.32
    Episode_Reward/reaching_object: 1.2695
    Episode_Reward/rotating_object: 41.4645
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.03s
                      Time elapsed: 00:31:25
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 49324 steps/s (collection: 1.889s, learning 0.105s)
             Mean action noise std: 3.18
          Mean value_function loss: 82.2051
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.5598
                       Mean reward: 206.16
               Mean episode length: 205.09
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 44.2966
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.99s
                      Time elapsed: 00:31:27
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 49927 steps/s (collection: 1.867s, learning 0.102s)
             Mean action noise std: 3.18
          Mean value_function loss: 81.9788
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 79.5957
                       Mean reward: 217.59
               Mean episode length: 205.11
    Episode_Reward/reaching_object: 1.2685
    Episode_Reward/rotating_object: 45.1234
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.97s
                      Time elapsed: 00:31:29
                               ETA: 00:28:52

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 49287 steps/s (collection: 1.894s, learning 0.101s)
             Mean action noise std: 3.18
          Mean value_function loss: 84.3777
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 79.6280
                       Mean reward: 194.57
               Mean episode length: 186.20
    Episode_Reward/reaching_object: 1.2206
    Episode_Reward/rotating_object: 41.0517
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.99s
                      Time elapsed: 00:31:31
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 49465 steps/s (collection: 1.895s, learning 0.092s)
             Mean action noise std: 3.19
          Mean value_function loss: 86.1002
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 79.6516
                       Mean reward: 258.98
               Mean episode length: 218.83
    Episode_Reward/reaching_object: 1.2253
    Episode_Reward/rotating_object: 42.5287
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.99s
                      Time elapsed: 00:31:32
                               ETA: 00:28:46

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 50380 steps/s (collection: 1.862s, learning 0.089s)
             Mean action noise std: 3.19
          Mean value_function loss: 82.2736
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 79.6785
                       Mean reward: 203.21
               Mean episode length: 191.17
    Episode_Reward/reaching_object: 1.1655
    Episode_Reward/rotating_object: 37.3700
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.95s
                      Time elapsed: 00:31:34
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 48827 steps/s (collection: 1.914s, learning 0.099s)
             Mean action noise std: 3.19
          Mean value_function loss: 85.0021
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 79.7133
                       Mean reward: 202.25
               Mean episode length: 196.27
    Episode_Reward/reaching_object: 1.2245
    Episode_Reward/rotating_object: 41.5905
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.01s
                      Time elapsed: 00:31:36
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 50190 steps/s (collection: 1.859s, learning 0.100s)
             Mean action noise std: 3.20
          Mean value_function loss: 90.8466
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 79.7476
                       Mean reward: 197.90
               Mean episode length: 199.25
    Episode_Reward/reaching_object: 1.2065
    Episode_Reward/rotating_object: 38.8748
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.96s
                      Time elapsed: 00:31:38
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 49627 steps/s (collection: 1.885s, learning 0.096s)
             Mean action noise std: 3.20
          Mean value_function loss: 94.0083
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 79.7786
                       Mean reward: 206.74
               Mean episode length: 203.51
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 46.8049
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.98s
                      Time elapsed: 00:31:40
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 49010 steps/s (collection: 1.899s, learning 0.107s)
             Mean action noise std: 3.20
          Mean value_function loss: 86.9422
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 79.8077
                       Mean reward: 221.98
               Mean episode length: 216.47
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 40.8074
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.01s
                      Time elapsed: 00:31:42
                               ETA: 00:28:32

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 46542 steps/s (collection: 2.000s, learning 0.112s)
             Mean action noise std: 3.21
          Mean value_function loss: 85.6357
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 79.8454
                       Mean reward: 187.24
               Mean episode length: 208.02
    Episode_Reward/reaching_object: 1.2802
    Episode_Reward/rotating_object: 40.8935
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.11s
                      Time elapsed: 00:31:45
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 49804 steps/s (collection: 1.858s, learning 0.116s)
             Mean action noise std: 3.21
          Mean value_function loss: 85.7223
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 79.8862
                       Mean reward: 192.35
               Mean episode length: 208.19
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 42.5621
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 1.97s
                      Time elapsed: 00:31:46
                               ETA: 00:28:27

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 50169 steps/s (collection: 1.856s, learning 0.103s)
             Mean action noise std: 3.22
          Mean value_function loss: 84.0194
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 79.9245
                       Mean reward: 264.58
               Mean episode length: 211.15
    Episode_Reward/reaching_object: 1.2423
    Episode_Reward/rotating_object: 45.4837
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0634
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.96s
                      Time elapsed: 00:31:48
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 50355 steps/s (collection: 1.856s, learning 0.097s)
             Mean action noise std: 3.22
          Mean value_function loss: 86.2579
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 79.9654
                       Mean reward: 221.04
               Mean episode length: 211.40
    Episode_Reward/reaching_object: 1.2352
    Episode_Reward/rotating_object: 42.9464
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.95s
                      Time elapsed: 00:31:50
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 49979 steps/s (collection: 1.867s, learning 0.100s)
             Mean action noise std: 3.23
          Mean value_function loss: 78.0060
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 80.0090
                       Mean reward: 246.71
               Mean episode length: 216.35
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 42.6092
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.97s
                      Time elapsed: 00:31:52
                               ETA: 00:28:18

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 50612 steps/s (collection: 1.848s, learning 0.095s)
             Mean action noise std: 3.23
          Mean value_function loss: 79.5632
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 80.0570
                       Mean reward: 227.31
               Mean episode length: 209.88
    Episode_Reward/reaching_object: 1.2240
    Episode_Reward/rotating_object: 42.1292
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.94s
                      Time elapsed: 00:31:54
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 49785 steps/s (collection: 1.881s, learning 0.093s)
             Mean action noise std: 3.24
          Mean value_function loss: 88.7140
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 80.0992
                       Mean reward: 229.48
               Mean episode length: 210.12
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 41.7548
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.97s
                      Time elapsed: 00:31:56
                               ETA: 00:28:13

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 50204 steps/s (collection: 1.867s, learning 0.091s)
             Mean action noise std: 3.24
          Mean value_function loss: 85.1415
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 80.1448
                       Mean reward: 184.71
               Mean episode length: 199.48
    Episode_Reward/reaching_object: 1.2172
    Episode_Reward/rotating_object: 40.9066
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.96s
                      Time elapsed: 00:31:58
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 49661 steps/s (collection: 1.882s, learning 0.098s)
             Mean action noise std: 3.24
          Mean value_function loss: 81.6349
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 80.1776
                       Mean reward: 185.33
               Mean episode length: 208.84
    Episode_Reward/reaching_object: 1.2450
    Episode_Reward/rotating_object: 41.5594
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.98s
                      Time elapsed: 00:32:00
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 49388 steps/s (collection: 1.874s, learning 0.116s)
             Mean action noise std: 3.25
          Mean value_function loss: 78.5387
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 80.2084
                       Mean reward: 205.20
               Mean episode length: 213.07
    Episode_Reward/reaching_object: 1.2552
    Episode_Reward/rotating_object: 40.8475
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.99s
                      Time elapsed: 00:32:02
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 50283 steps/s (collection: 1.841s, learning 0.114s)
             Mean action noise std: 3.25
          Mean value_function loss: 84.9443
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 80.2460
                       Mean reward: 191.13
               Mean episode length: 198.68
    Episode_Reward/reaching_object: 1.2241
    Episode_Reward/rotating_object: 41.9514
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.96s
                      Time elapsed: 00:32:04
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 49736 steps/s (collection: 1.861s, learning 0.116s)
             Mean action noise std: 3.25
          Mean value_function loss: 86.2644
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 80.2804
                       Mean reward: 160.70
               Mean episode length: 194.48
    Episode_Reward/reaching_object: 1.1904
    Episode_Reward/rotating_object: 38.5065
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0633
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.98s
                      Time elapsed: 00:32:06
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 50027 steps/s (collection: 1.868s, learning 0.097s)
             Mean action noise std: 3.26
          Mean value_function loss: 88.7970
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 80.3096
                       Mean reward: 210.61
               Mean episode length: 199.21
    Episode_Reward/reaching_object: 1.2455
    Episode_Reward/rotating_object: 43.6998
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.96s
                      Time elapsed: 00:32:08
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 49916 steps/s (collection: 1.870s, learning 0.100s)
             Mean action noise std: 3.26
          Mean value_function loss: 87.3845
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 80.3480
                       Mean reward: 213.32
               Mean episode length: 193.29
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 42.3894
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.97s
                      Time elapsed: 00:32:10
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 49924 steps/s (collection: 1.867s, learning 0.103s)
             Mean action noise std: 3.27
          Mean value_function loss: 98.2037
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 80.3873
                       Mean reward: 254.45
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 1.2552
    Episode_Reward/rotating_object: 40.4513
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.97s
                      Time elapsed: 00:32:12
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 49023 steps/s (collection: 1.900s, learning 0.106s)
             Mean action noise std: 3.27
          Mean value_function loss: 100.8754
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 80.4224
                       Mean reward: 195.25
               Mean episode length: 191.94
    Episode_Reward/reaching_object: 1.2045
    Episode_Reward/rotating_object: 40.7712
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.01s
                      Time elapsed: 00:32:14
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 49435 steps/s (collection: 1.884s, learning 0.104s)
             Mean action noise std: 3.27
          Mean value_function loss: 98.8624
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 80.4627
                       Mean reward: 206.36
               Mean episode length: 208.29
    Episode_Reward/reaching_object: 1.2239
    Episode_Reward/rotating_object: 42.2842
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.99s
                      Time elapsed: 00:32:16
                               ETA: 00:27:45

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 49291 steps/s (collection: 1.898s, learning 0.096s)
             Mean action noise std: 3.28
          Mean value_function loss: 92.5519
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 80.4984
                       Mean reward: 236.52
               Mean episode length: 212.48
    Episode_Reward/reaching_object: 1.1885
    Episode_Reward/rotating_object: 39.8504
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.99s
                      Time elapsed: 00:32:18
                               ETA: 00:27:42

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 49375 steps/s (collection: 1.892s, learning 0.099s)
             Mean action noise std: 3.28
          Mean value_function loss: 85.8572
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 80.5369
                       Mean reward: 187.55
               Mean episode length: 195.41
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 42.2311
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.99s
                      Time elapsed: 00:32:20
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 44789 steps/s (collection: 2.094s, learning 0.101s)
             Mean action noise std: 3.29
          Mean value_function loss: 90.1912
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 80.5721
                       Mean reward: 227.01
               Mean episode length: 211.13
    Episode_Reward/reaching_object: 1.2672
    Episode_Reward/rotating_object: 42.7944
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.19s
                      Time elapsed: 00:32:22
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 48965 steps/s (collection: 1.910s, learning 0.098s)
             Mean action noise std: 3.29
          Mean value_function loss: 80.3003
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 80.6157
                       Mean reward: 200.86
               Mean episode length: 197.87
    Episode_Reward/reaching_object: 1.1941
    Episode_Reward/rotating_object: 39.6298
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.01s
                      Time elapsed: 00:32:24
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 49024 steps/s (collection: 1.888s, learning 0.118s)
             Mean action noise std: 3.29
          Mean value_function loss: 96.8927
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 80.6537
                       Mean reward: 210.02
               Mean episode length: 210.36
    Episode_Reward/reaching_object: 1.2590
    Episode_Reward/rotating_object: 44.5031
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.01s
                      Time elapsed: 00:32:26
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 48388 steps/s (collection: 1.924s, learning 0.108s)
             Mean action noise std: 3.30
          Mean value_function loss: 90.4071
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 80.6877
                       Mean reward: 198.35
               Mean episode length: 204.19
    Episode_Reward/reaching_object: 1.2588
    Episode_Reward/rotating_object: 40.2128
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.03s
                      Time elapsed: 00:32:28
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 48805 steps/s (collection: 1.896s, learning 0.119s)
             Mean action noise std: 3.30
          Mean value_function loss: 93.3192
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 80.7264
                       Mean reward: 211.81
               Mean episode length: 217.33
    Episode_Reward/reaching_object: 1.2729
    Episode_Reward/rotating_object: 46.5153
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.01s
                      Time elapsed: 00:32:30
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 48635 steps/s (collection: 1.903s, learning 0.118s)
             Mean action noise std: 3.31
          Mean value_function loss: 103.8751
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 80.7604
                       Mean reward: 165.92
               Mean episode length: 197.10
    Episode_Reward/reaching_object: 1.2282
    Episode_Reward/rotating_object: 41.6695
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.02s
                      Time elapsed: 00:32:32
                               ETA: 00:27:23

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 48193 steps/s (collection: 1.919s, learning 0.121s)
             Mean action noise std: 3.31
          Mean value_function loss: 99.8844
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 80.8031
                       Mean reward: 242.73
               Mean episode length: 216.68
    Episode_Reward/reaching_object: 1.2895
    Episode_Reward/rotating_object: 45.2746
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.04s
                      Time elapsed: 00:32:34
                               ETA: 00:27:21

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 48729 steps/s (collection: 1.902s, learning 0.115s)
             Mean action noise std: 3.31
          Mean value_function loss: 88.4348
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 80.8405
                       Mean reward: 205.31
               Mean episode length: 202.74
    Episode_Reward/reaching_object: 1.2423
    Episode_Reward/rotating_object: 39.8588
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.02s
                      Time elapsed: 00:32:36
                               ETA: 00:27:18

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 48884 steps/s (collection: 1.912s, learning 0.099s)
             Mean action noise std: 3.32
          Mean value_function loss: 93.0646
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 80.8742
                       Mean reward: 235.69
               Mean episode length: 203.01
    Episode_Reward/reaching_object: 1.2692
    Episode_Reward/rotating_object: 44.0292
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.01s
                      Time elapsed: 00:32:38
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 48483 steps/s (collection: 1.928s, learning 0.099s)
             Mean action noise std: 3.32
          Mean value_function loss: 89.4809
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 80.8981
                       Mean reward: 210.89
               Mean episode length: 203.36
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 39.6712
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.03s
                      Time elapsed: 00:32:40
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 48926 steps/s (collection: 1.904s, learning 0.105s)
             Mean action noise std: 3.32
          Mean value_function loss: 99.4254
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 80.9244
                       Mean reward: 233.17
               Mean episode length: 209.97
    Episode_Reward/reaching_object: 1.2263
    Episode_Reward/rotating_object: 42.9729
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.01s
                      Time elapsed: 00:32:42
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 48262 steps/s (collection: 1.934s, learning 0.103s)
             Mean action noise std: 3.33
          Mean value_function loss: 92.5170
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 80.9588
                       Mean reward: 230.69
               Mean episode length: 210.09
    Episode_Reward/reaching_object: 1.2593
    Episode_Reward/rotating_object: 46.0456
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0690
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.04s
                      Time elapsed: 00:32:44
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 48475 steps/s (collection: 1.921s, learning 0.107s)
             Mean action noise std: 3.33
          Mean value_function loss: 92.2234
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 81.0065
                       Mean reward: 250.38
               Mean episode length: 221.63
    Episode_Reward/reaching_object: 1.2575
    Episode_Reward/rotating_object: 45.5856
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0686
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.03s
                      Time elapsed: 00:32:46
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 48275 steps/s (collection: 1.928s, learning 0.109s)
             Mean action noise std: 3.34
          Mean value_function loss: 102.2774
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 81.0393
                       Mean reward: 203.11
               Mean episode length: 199.64
    Episode_Reward/reaching_object: 1.2295
    Episode_Reward/rotating_object: 44.5525
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.04s
                      Time elapsed: 00:32:49
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 47950 steps/s (collection: 1.943s, learning 0.107s)
             Mean action noise std: 3.34
          Mean value_function loss: 91.1118
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 81.0693
                       Mean reward: 263.08
               Mean episode length: 214.20
    Episode_Reward/reaching_object: 1.2107
    Episode_Reward/rotating_object: 43.4136
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.05s
                      Time elapsed: 00:32:51
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 48139 steps/s (collection: 1.939s, learning 0.103s)
             Mean action noise std: 3.34
          Mean value_function loss: 91.4883
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 81.0991
                       Mean reward: 230.46
               Mean episode length: 210.69
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 43.2144
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.04s
                      Time elapsed: 00:32:53
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 49430 steps/s (collection: 1.896s, learning 0.093s)
             Mean action noise std: 3.35
          Mean value_function loss: 91.8049
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 81.1334
                       Mean reward: 197.20
               Mean episode length: 203.09
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 42.7283
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.99s
                      Time elapsed: 00:32:55
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 48738 steps/s (collection: 1.911s, learning 0.106s)
             Mean action noise std: 3.35
          Mean value_function loss: 94.9811
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 81.1596
                       Mean reward: 226.81
               Mean episode length: 209.51
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 42.7886
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.02s
                      Time elapsed: 00:32:57
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 48281 steps/s (collection: 1.931s, learning 0.105s)
             Mean action noise std: 3.35
          Mean value_function loss: 94.1015
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 81.1839
                       Mean reward: 191.73
               Mean episode length: 195.81
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 43.0008
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.04s
                      Time elapsed: 00:32:59
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 48552 steps/s (collection: 1.920s, learning 0.105s)
             Mean action noise std: 3.36
          Mean value_function loss: 92.4682
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 81.2180
                       Mean reward: 255.58
               Mean episode length: 215.91
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 45.1580
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.02s
                      Time elapsed: 00:33:01
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 48044 steps/s (collection: 1.945s, learning 0.102s)
             Mean action noise std: 3.36
          Mean value_function loss: 95.8915
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 81.2501
                       Mean reward: 222.23
               Mean episode length: 196.33
    Episode_Reward/reaching_object: 1.2456
    Episode_Reward/rotating_object: 42.0722
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.05s
                      Time elapsed: 00:33:03
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 48040 steps/s (collection: 1.932s, learning 0.114s)
             Mean action noise std: 3.36
          Mean value_function loss: 94.5509
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 81.2774
                       Mean reward: 214.45
               Mean episode length: 189.91
    Episode_Reward/reaching_object: 1.2259
    Episode_Reward/rotating_object: 41.9580
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.05s
                      Time elapsed: 00:33:05
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 46999 steps/s (collection: 1.980s, learning 0.112s)
             Mean action noise std: 3.37
          Mean value_function loss: 98.7820
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 81.3034
                       Mean reward: 250.20
               Mean episode length: 209.54
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 49.3682
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.09s
                      Time elapsed: 00:33:07
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 48239 steps/s (collection: 1.932s, learning 0.106s)
             Mean action noise std: 3.37
          Mean value_function loss: 107.6617
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 81.3347
                       Mean reward: 190.40
               Mean episode length: 199.19
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 40.4348
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0696
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.04s
                      Time elapsed: 00:33:09
                               ETA: 00:26:35

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 46765 steps/s (collection: 1.988s, learning 0.114s)
             Mean action noise std: 3.37
          Mean value_function loss: 101.5592
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 81.3721
                       Mean reward: 200.39
               Mean episode length: 207.29
    Episode_Reward/reaching_object: 1.2583
    Episode_Reward/rotating_object: 41.2456
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0713
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.10s
                      Time elapsed: 00:33:11
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 45949 steps/s (collection: 2.020s, learning 0.120s)
             Mean action noise std: 3.38
          Mean value_function loss: 101.5327
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 81.3999
                       Mean reward: 221.88
               Mean episode length: 204.78
    Episode_Reward/reaching_object: 1.2478
    Episode_Reward/rotating_object: 45.3888
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0714
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.14s
                      Time elapsed: 00:33:13
                               ETA: 00:26:30

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 47239 steps/s (collection: 1.965s, learning 0.116s)
             Mean action noise std: 3.38
          Mean value_function loss: 108.3712
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 81.4275
                       Mean reward: 189.13
               Mean episode length: 188.90
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 39.6758
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.08s
                      Time elapsed: 00:33:15
                               ETA: 00:26:27

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 47582 steps/s (collection: 1.961s, learning 0.105s)
             Mean action noise std: 3.38
          Mean value_function loss: 106.0358
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 81.4570
                       Mean reward: 201.33
               Mean episode length: 193.38
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 43.6611
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0726
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.07s
                      Time elapsed: 00:33:17
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 47859 steps/s (collection: 1.952s, learning 0.102s)
             Mean action noise std: 3.39
          Mean value_function loss: 96.9904
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 81.4864
                       Mean reward: 208.99
               Mean episode length: 201.41
    Episode_Reward/reaching_object: 1.2247
    Episode_Reward/rotating_object: 43.2696
        Episode_Reward/action_rate: -0.0707
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.05s
                      Time elapsed: 00:33:19
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 47677 steps/s (collection: 1.957s, learning 0.105s)
             Mean action noise std: 3.39
          Mean value_function loss: 93.8495
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 81.5275
                       Mean reward: 232.97
               Mean episode length: 200.06
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 43.8373
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.06s
                      Time elapsed: 00:33:21
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 47084 steps/s (collection: 1.989s, learning 0.099s)
             Mean action noise std: 3.39
          Mean value_function loss: 88.7037
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 81.5586
                       Mean reward: 239.16
               Mean episode length: 206.16
    Episode_Reward/reaching_object: 1.2556
    Episode_Reward/rotating_object: 45.4068
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.09s
                      Time elapsed: 00:33:23
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 47642 steps/s (collection: 1.958s, learning 0.105s)
             Mean action noise std: 3.40
          Mean value_function loss: 99.4023
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 81.5845
                       Mean reward: 220.99
               Mean episode length: 204.82
    Episode_Reward/reaching_object: 1.2283
    Episode_Reward/rotating_object: 46.1510
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.06s
                      Time elapsed: 00:33:26
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 47497 steps/s (collection: 1.964s, learning 0.106s)
             Mean action noise std: 3.40
          Mean value_function loss: 94.6527
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 81.6239
                       Mean reward: 227.04
               Mean episode length: 196.16
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 45.8443
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.07s
                      Time elapsed: 00:33:28
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 47381 steps/s (collection: 1.973s, learning 0.102s)
             Mean action noise std: 3.41
          Mean value_function loss: 100.3230
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 81.6691
                       Mean reward: 203.95
               Mean episode length: 186.38
    Episode_Reward/reaching_object: 1.2239
    Episode_Reward/rotating_object: 43.9503
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0710
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.07s
                      Time elapsed: 00:33:30
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 47521 steps/s (collection: 1.949s, learning 0.120s)
             Mean action noise std: 3.41
          Mean value_function loss: 105.4722
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 81.6912
                       Mean reward: 225.40
               Mean episode length: 203.49
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 41.6746
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.07s
                      Time elapsed: 00:33:32
                               ETA: 00:26:06

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 47016 steps/s (collection: 1.979s, learning 0.112s)
             Mean action noise std: 3.41
          Mean value_function loss: 107.3100
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 81.7137
                       Mean reward: 235.12
               Mean episode length: 194.47
    Episode_Reward/reaching_object: 1.2146
    Episode_Reward/rotating_object: 46.8719
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.09s
                      Time elapsed: 00:33:34
                               ETA: 00:26:03

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 47278 steps/s (collection: 1.967s, learning 0.112s)
             Mean action noise std: 3.41
          Mean value_function loss: 109.0265
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 81.7315
                       Mean reward: 227.22
               Mean episode length: 202.16
    Episode_Reward/reaching_object: 1.2180
    Episode_Reward/rotating_object: 47.0049
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0710
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.08s
                      Time elapsed: 00:33:36
                               ETA: 00:26:01

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 47254 steps/s (collection: 1.978s, learning 0.102s)
             Mean action noise std: 3.42
          Mean value_function loss: 105.2723
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 81.7534
                       Mean reward: 192.59
               Mean episode length: 192.80
    Episode_Reward/reaching_object: 1.1804
    Episode_Reward/rotating_object: 44.8709
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.08s
                      Time elapsed: 00:33:38
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 47749 steps/s (collection: 1.954s, learning 0.105s)
             Mean action noise std: 3.42
          Mean value_function loss: 108.4288
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 81.7915
                       Mean reward: 174.85
               Mean episode length: 192.30
    Episode_Reward/reaching_object: 1.1818
    Episode_Reward/rotating_object: 41.5828
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.06s
                      Time elapsed: 00:33:40
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 47904 steps/s (collection: 1.945s, learning 0.107s)
             Mean action noise std: 3.43
          Mean value_function loss: 103.6527
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 81.8350
                       Mean reward: 231.56
               Mean episode length: 208.37
    Episode_Reward/reaching_object: 1.2312
    Episode_Reward/rotating_object: 46.6106
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0713
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.05s
                      Time elapsed: 00:33:42
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 46096 steps/s (collection: 2.028s, learning 0.105s)
             Mean action noise std: 3.43
          Mean value_function loss: 97.8288
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 81.8708
                       Mean reward: 230.43
               Mean episode length: 197.31
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 42.8778
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.13s
                      Time elapsed: 00:33:44
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 48396 steps/s (collection: 1.936s, learning 0.095s)
             Mean action noise std: 3.43
          Mean value_function loss: 104.7711
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 81.8977
                       Mean reward: 212.76
               Mean episode length: 191.34
    Episode_Reward/reaching_object: 1.1548
    Episode_Reward/rotating_object: 41.0604
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.03s
                      Time elapsed: 00:33:46
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 45774 steps/s (collection: 2.028s, learning 0.120s)
             Mean action noise std: 3.44
          Mean value_function loss: 102.4261
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 81.9257
                       Mean reward: 232.53
               Mean episode length: 206.26
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 45.6867
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.15s
                      Time elapsed: 00:33:48
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 45976 steps/s (collection: 2.036s, learning 0.103s)
             Mean action noise std: 3.44
          Mean value_function loss: 110.2428
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 81.9517
                       Mean reward: 200.40
               Mean episode length: 198.27
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 44.0615
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.14s
                      Time elapsed: 00:33:51
                               ETA: 00:25:42

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 47438 steps/s (collection: 1.969s, learning 0.103s)
             Mean action noise std: 3.44
          Mean value_function loss: 111.7014
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 81.9806
                       Mean reward: 184.23
               Mean episode length: 191.26
    Episode_Reward/reaching_object: 1.1882
    Episode_Reward/rotating_object: 43.5843
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.07s
                      Time elapsed: 00:33:53
                               ETA: 00:25:40

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 47628 steps/s (collection: 1.967s, learning 0.097s)
             Mean action noise std: 3.45
          Mean value_function loss: 107.9125
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 82.0033
                       Mean reward: 238.52
               Mean episode length: 199.65
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 46.6464
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.06s
                      Time elapsed: 00:33:55
                               ETA: 00:25:37

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 47507 steps/s (collection: 1.966s, learning 0.104s)
             Mean action noise std: 3.45
          Mean value_function loss: 100.1903
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 82.0302
                       Mean reward: 210.17
               Mean episode length: 195.24
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 42.1951
        Episode_Reward/action_rate: -0.0707
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.07s
                      Time elapsed: 00:33:57
                               ETA: 00:25:35

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 46416 steps/s (collection: 1.991s, learning 0.127s)
             Mean action noise std: 3.45
          Mean value_function loss: 103.9649
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 82.0561
                       Mean reward: 258.17
               Mean episode length: 202.48
    Episode_Reward/reaching_object: 1.2328
    Episode_Reward/rotating_object: 48.7209
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.12s
                      Time elapsed: 00:33:59
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 46954 steps/s (collection: 1.994s, learning 0.100s)
             Mean action noise std: 3.46
          Mean value_function loss: 113.2790
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 82.0882
                       Mean reward: 205.22
               Mean episode length: 197.39
    Episode_Reward/reaching_object: 1.2177
    Episode_Reward/rotating_object: 42.4184
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.09s
                      Time elapsed: 00:34:01
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 47150 steps/s (collection: 1.958s, learning 0.127s)
             Mean action noise std: 3.46
          Mean value_function loss: 110.9819
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 82.1193
                       Mean reward: 256.61
               Mean episode length: 207.46
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 48.5611
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.08s
                      Time elapsed: 00:34:03
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 46353 steps/s (collection: 1.993s, learning 0.128s)
             Mean action noise std: 3.46
          Mean value_function loss: 112.2143
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 82.1453
                       Mean reward: 244.67
               Mean episode length: 207.82
    Episode_Reward/reaching_object: 1.2178
    Episode_Reward/rotating_object: 45.4017
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.12s
                      Time elapsed: 00:34:05
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 47258 steps/s (collection: 1.973s, learning 0.107s)
             Mean action noise std: 3.46
          Mean value_function loss: 104.6416
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 82.1619
                       Mean reward: 256.65
               Mean episode length: 217.22
    Episode_Reward/reaching_object: 1.2293
    Episode_Reward/rotating_object: 48.1134
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.08s
                      Time elapsed: 00:34:07
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 44756 steps/s (collection: 2.075s, learning 0.121s)
             Mean action noise std: 3.47
          Mean value_function loss: 105.5477
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 82.1820
                       Mean reward: 258.50
               Mean episode length: 197.00
    Episode_Reward/reaching_object: 1.2550
    Episode_Reward/rotating_object: 49.2325
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.20s
                      Time elapsed: 00:34:09
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 46842 steps/s (collection: 1.993s, learning 0.106s)
             Mean action noise std: 3.47
          Mean value_function loss: 111.8767
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 82.2071
                       Mean reward: 238.14
               Mean episode length: 197.08
    Episode_Reward/reaching_object: 1.2036
    Episode_Reward/rotating_object: 48.5623
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.10s
                      Time elapsed: 00:34:12
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 46694 steps/s (collection: 1.977s, learning 0.128s)
             Mean action noise std: 3.47
          Mean value_function loss: 104.8961
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 82.2360
                       Mean reward: 259.86
               Mean episode length: 200.21
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 48.8729
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.11s
                      Time elapsed: 00:34:14
                               ETA: 00:25:14

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 47328 steps/s (collection: 1.974s, learning 0.103s)
             Mean action noise std: 3.48
          Mean value_function loss: 104.6389
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 82.2705
                       Mean reward: 232.92
               Mean episode length: 196.96
    Episode_Reward/reaching_object: 1.1832
    Episode_Reward/rotating_object: 45.3391
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0717
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.08s
                      Time elapsed: 00:34:16
                               ETA: 00:25:11

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 46273 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 3.48
          Mean value_function loss: 111.6152
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 82.3096
                       Mean reward: 233.95
               Mean episode length: 197.37
    Episode_Reward/reaching_object: 1.2382
    Episode_Reward/rotating_object: 48.9308
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0744
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.12s
                      Time elapsed: 00:34:18
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 46976 steps/s (collection: 1.968s, learning 0.125s)
             Mean action noise std: 3.49
          Mean value_function loss: 112.5790
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 82.3411
                       Mean reward: 217.06
               Mean episode length: 193.81
    Episode_Reward/reaching_object: 1.2211
    Episode_Reward/rotating_object: 44.3558
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.09s
                      Time elapsed: 00:34:20
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 46886 steps/s (collection: 1.979s, learning 0.118s)
             Mean action noise std: 3.49
          Mean value_function loss: 105.5355
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 82.3642
                       Mean reward: 236.86
               Mean episode length: 203.95
    Episode_Reward/reaching_object: 1.1777
    Episode_Reward/rotating_object: 43.7665
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.10s
                      Time elapsed: 00:34:22
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 46939 steps/s (collection: 1.976s, learning 0.118s)
             Mean action noise std: 3.49
          Mean value_function loss: 106.0826
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 82.3965
                       Mean reward: 246.44
               Mean episode length: 195.17
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 43.8022
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.09s
                      Time elapsed: 00:34:24
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 46143 steps/s (collection: 2.009s, learning 0.122s)
             Mean action noise std: 3.50
          Mean value_function loss: 119.1169
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 82.4358
                       Mean reward: 247.00
               Mean episode length: 203.93
    Episode_Reward/reaching_object: 1.2239
    Episode_Reward/rotating_object: 47.4632
        Episode_Reward/action_rate: -0.0762
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.13s
                      Time elapsed: 00:34:26
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 47259 steps/s (collection: 1.954s, learning 0.127s)
             Mean action noise std: 3.50
          Mean value_function loss: 93.6161
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 82.4636
                       Mean reward: 220.06
               Mean episode length: 202.31
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 43.6425
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.08s
                      Time elapsed: 00:34:28
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 45299 steps/s (collection: 2.047s, learning 0.124s)
             Mean action noise std: 3.50
          Mean value_function loss: 97.1410
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 82.4922
                       Mean reward: 257.97
               Mean episode length: 204.55
    Episode_Reward/reaching_object: 1.2339
    Episode_Reward/rotating_object: 48.3923
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.17s
                      Time elapsed: 00:34:31
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 47050 steps/s (collection: 1.958s, learning 0.131s)
             Mean action noise std: 3.51
          Mean value_function loss: 102.8887
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 82.5179
                       Mean reward: 268.05
               Mean episode length: 204.97
    Episode_Reward/reaching_object: 1.2328
    Episode_Reward/rotating_object: 51.6972
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.09s
                      Time elapsed: 00:34:33
                               ETA: 00:24:51

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 47473 steps/s (collection: 1.940s, learning 0.131s)
             Mean action noise std: 3.51
          Mean value_function loss: 102.6645
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 82.5412
                       Mean reward: 244.36
               Mean episode length: 208.80
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 46.8433
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0715
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.07s
                      Time elapsed: 00:34:35
                               ETA: 00:24:48

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 46279 steps/s (collection: 1.987s, learning 0.138s)
             Mean action noise std: 3.52
          Mean value_function loss: 109.2501
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 82.5773
                       Mean reward: 224.73
               Mean episode length: 205.60
    Episode_Reward/reaching_object: 1.1974
    Episode_Reward/rotating_object: 49.2440
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.12s
                      Time elapsed: 00:34:37
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 47224 steps/s (collection: 1.959s, learning 0.123s)
             Mean action noise std: 3.52
          Mean value_function loss: 105.6530
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 82.6147
                       Mean reward: 287.36
               Mean episode length: 218.11
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 48.1729
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.08s
                      Time elapsed: 00:34:39
                               ETA: 00:24:43

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 47318 steps/s (collection: 1.944s, learning 0.133s)
             Mean action noise std: 3.52
          Mean value_function loss: 95.0638
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 82.6404
                       Mean reward: 227.50
               Mean episode length: 205.96
    Episode_Reward/reaching_object: 1.2137
    Episode_Reward/rotating_object: 47.1345
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0729
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.08s
                      Time elapsed: 00:34:41
                               ETA: 00:24:41

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 47055 steps/s (collection: 1.979s, learning 0.110s)
             Mean action noise std: 3.52
          Mean value_function loss: 102.2000
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 82.6616
                       Mean reward: 263.26
               Mean episode length: 218.99
    Episode_Reward/reaching_object: 1.2624
    Episode_Reward/rotating_object: 50.8532
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0750
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.09s
                      Time elapsed: 00:34:43
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 44121 steps/s (collection: 2.119s, learning 0.109s)
             Mean action noise std: 3.53
          Mean value_function loss: 102.2799
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 82.6734
                       Mean reward: 264.52
               Mean episode length: 215.44
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 50.8826
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.23s
                      Time elapsed: 00:34:45
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 46788 steps/s (collection: 1.983s, learning 0.118s)
             Mean action noise std: 3.53
          Mean value_function loss: 103.0504
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 82.7023
                       Mean reward: 254.85
               Mean episode length: 209.38
    Episode_Reward/reaching_object: 1.2251
    Episode_Reward/rotating_object: 50.0081
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0731
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.10s
                      Time elapsed: 00:34:47
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 45850 steps/s (collection: 2.036s, learning 0.108s)
             Mean action noise std: 3.53
          Mean value_function loss: 109.8282
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 82.7404
                       Mean reward: 268.55
               Mean episode length: 206.34
    Episode_Reward/reaching_object: 1.2241
    Episode_Reward/rotating_object: 48.9525
        Episode_Reward/action_rate: -0.0785
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.14s
                      Time elapsed: 00:34:50
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 42495 steps/s (collection: 2.032s, learning 0.282s)
             Mean action noise std: 3.54
          Mean value_function loss: 109.8220
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 82.7710
                       Mean reward: 228.45
               Mean episode length: 199.46
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 45.7333
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.31s
                      Time elapsed: 00:34:52
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 37265 steps/s (collection: 2.454s, learning 0.184s)
             Mean action noise std: 3.54
          Mean value_function loss: 102.8929
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 82.7966
                       Mean reward: 232.59
               Mean episode length: 209.95
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 46.4295
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.64s
                      Time elapsed: 00:34:54
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 41013 steps/s (collection: 2.219s, learning 0.178s)
             Mean action noise std: 3.54
          Mean value_function loss: 119.8507
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 82.8197
                       Mean reward: 213.15
               Mean episode length: 200.44
    Episode_Reward/reaching_object: 1.2441
    Episode_Reward/rotating_object: 47.5006
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0747
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.40s
                      Time elapsed: 00:34:57
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 41098 steps/s (collection: 2.240s, learning 0.152s)
             Mean action noise std: 3.55
          Mean value_function loss: 108.6617
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 82.8439
                       Mean reward: 234.89
               Mean episode length: 193.85
    Episode_Reward/reaching_object: 1.2019
    Episode_Reward/rotating_object: 46.8981
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0738
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.39s
                      Time elapsed: 00:34:59
                               ETA: 00:24:21

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 44145 steps/s (collection: 2.088s, learning 0.139s)
             Mean action noise std: 3.55
          Mean value_function loss: 120.1617
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 82.8688
                       Mean reward: 255.17
               Mean episode length: 211.04
    Episode_Reward/reaching_object: 1.1912
    Episode_Reward/rotating_object: 46.9601
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.23s
                      Time elapsed: 00:35:02
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 44432 steps/s (collection: 2.039s, learning 0.174s)
             Mean action noise std: 3.55
          Mean value_function loss: 114.5324
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 82.8974
                       Mean reward: 295.70
               Mean episode length: 220.50
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 48.0333
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.21s
                      Time elapsed: 00:35:04
                               ETA: 00:24:16

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 39700 steps/s (collection: 2.299s, learning 0.177s)
             Mean action noise std: 3.56
          Mean value_function loss: 118.2586
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 82.9211
                       Mean reward: 242.31
               Mean episode length: 202.72
    Episode_Reward/reaching_object: 1.2230
    Episode_Reward/rotating_object: 45.9158
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.48s
                      Time elapsed: 00:35:06
                               ETA: 00:24:14

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 45854 steps/s (collection: 2.009s, learning 0.135s)
             Mean action noise std: 3.56
          Mean value_function loss: 123.7171
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 82.9364
                       Mean reward: 252.65
               Mean episode length: 201.83
    Episode_Reward/reaching_object: 1.2163
    Episode_Reward/rotating_object: 47.1952
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.14s
                      Time elapsed: 00:35:08
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 40296 steps/s (collection: 2.264s, learning 0.175s)
             Mean action noise std: 3.56
          Mean value_function loss: 110.7169
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 82.9538
                       Mean reward: 239.98
               Mean episode length: 206.57
    Episode_Reward/reaching_object: 1.1947
    Episode_Reward/rotating_object: 48.0436
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0742
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.44s
                      Time elapsed: 00:35:11
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 43808 steps/s (collection: 2.098s, learning 0.146s)
             Mean action noise std: 3.56
          Mean value_function loss: 116.8677
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 82.9765
                       Mean reward: 223.15
               Mean episode length: 179.20
    Episode_Reward/reaching_object: 1.1530
    Episode_Reward/rotating_object: 50.6249
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.24s
                      Time elapsed: 00:35:13
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 43459 steps/s (collection: 2.125s, learning 0.137s)
             Mean action noise std: 3.57
          Mean value_function loss: 93.8516
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 82.9986
                       Mean reward: 268.42
               Mean episode length: 209.63
    Episode_Reward/reaching_object: 1.2099
    Episode_Reward/rotating_object: 46.7247
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.26s
                      Time elapsed: 00:35:15
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 44421 steps/s (collection: 2.079s, learning 0.134s)
             Mean action noise std: 3.57
          Mean value_function loss: 112.2624
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 83.0288
                       Mean reward: 199.41
               Mean episode length: 187.39
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 43.1461
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.21s
                      Time elapsed: 00:35:18
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 42813 steps/s (collection: 2.137s, learning 0.159s)
             Mean action noise std: 3.57
          Mean value_function loss: 110.3577
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 83.0574
                       Mean reward: 241.51
               Mean episode length: 198.76
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 52.6541
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0750
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.30s
                      Time elapsed: 00:35:20
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 44733 steps/s (collection: 2.069s, learning 0.128s)
             Mean action noise std: 3.58
          Mean value_function loss: 112.8632
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 83.0902
                       Mean reward: 238.30
               Mean episode length: 199.17
    Episode_Reward/reaching_object: 1.2152
    Episode_Reward/rotating_object: 52.0546
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.20s
                      Time elapsed: 00:35:22
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 44703 steps/s (collection: 2.060s, learning 0.139s)
             Mean action noise std: 3.58
          Mean value_function loss: 116.0041
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 83.1134
                       Mean reward: 289.15
               Mean episode length: 216.55
    Episode_Reward/reaching_object: 1.2144
    Episode_Reward/rotating_object: 49.4116
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.20s
                      Time elapsed: 00:35:24
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 46301 steps/s (collection: 2.023s, learning 0.101s)
             Mean action noise std: 3.58
          Mean value_function loss: 111.8193
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 83.1340
                       Mean reward: 297.37
               Mean episode length: 218.42
    Episode_Reward/reaching_object: 1.1979
    Episode_Reward/rotating_object: 48.9615
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0740
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.12s
                      Time elapsed: 00:35:26
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 44729 steps/s (collection: 2.056s, learning 0.142s)
             Mean action noise std: 3.59
          Mean value_function loss: 120.2114
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 83.1558
                       Mean reward: 233.30
               Mean episode length: 210.18
    Episode_Reward/reaching_object: 1.2061
    Episode_Reward/rotating_object: 46.0486
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.20s
                      Time elapsed: 00:35:29
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 45403 steps/s (collection: 2.047s, learning 0.118s)
             Mean action noise std: 3.59
          Mean value_function loss: 118.0996
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 83.1764
                       Mean reward: 209.94
               Mean episode length: 202.77
    Episode_Reward/reaching_object: 1.1736
    Episode_Reward/rotating_object: 47.2258
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.17s
                      Time elapsed: 00:35:31
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 43323 steps/s (collection: 2.087s, learning 0.182s)
             Mean action noise std: 3.59
          Mean value_function loss: 120.2861
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 83.1920
                       Mean reward: 266.98
               Mean episode length: 198.19
    Episode_Reward/reaching_object: 1.2189
    Episode_Reward/rotating_object: 52.7551
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.27s
                      Time elapsed: 00:35:33
                               ETA: 00:23:44

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 44698 steps/s (collection: 2.060s, learning 0.140s)
             Mean action noise std: 3.59
          Mean value_function loss: 121.2608
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.2153
                       Mean reward: 244.13
               Mean episode length: 196.14
    Episode_Reward/reaching_object: 1.1597
    Episode_Reward/rotating_object: 44.3704
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0713
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.20s
                      Time elapsed: 00:35:35
                               ETA: 00:23:42

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 40860 steps/s (collection: 2.242s, learning 0.164s)
             Mean action noise std: 3.60
          Mean value_function loss: 113.7700
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 83.2371
                       Mean reward: 292.31
               Mean episode length: 205.76
    Episode_Reward/reaching_object: 1.1899
    Episode_Reward/rotating_object: 48.4113
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0730
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.41s
                      Time elapsed: 00:35:38
                               ETA: 00:23:39

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 44562 steps/s (collection: 2.074s, learning 0.132s)
             Mean action noise std: 3.60
          Mean value_function loss: 120.6564
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 83.2725
                       Mean reward: 301.65
               Mean episode length: 216.21
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 50.7658
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0757
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.21s
                      Time elapsed: 00:35:40
                               ETA: 00:23:37

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 43055 steps/s (collection: 2.085s, learning 0.199s)
             Mean action noise std: 3.60
          Mean value_function loss: 117.6324
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 83.2979
                       Mean reward: 245.19
               Mean episode length: 202.67
    Episode_Reward/reaching_object: 1.2537
    Episode_Reward/rotating_object: 52.0963
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.28s
                      Time elapsed: 00:35:42
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 45713 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 113.8879
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 83.3288
                       Mean reward: 246.84
               Mean episode length: 200.16
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 47.7491
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.15s
                      Time elapsed: 00:35:44
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 44678 steps/s (collection: 2.046s, learning 0.155s)
             Mean action noise std: 3.61
          Mean value_function loss: 117.5549
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.3629
                       Mean reward: 237.15
               Mean episode length: 199.04
    Episode_Reward/reaching_object: 1.2395
    Episode_Reward/rotating_object: 48.0356
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.20s
                      Time elapsed: 00:35:46
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 44483 steps/s (collection: 2.096s, learning 0.114s)
             Mean action noise std: 3.61
          Mean value_function loss: 118.9147
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.3923
                       Mean reward: 274.70
               Mean episode length: 202.02
    Episode_Reward/reaching_object: 1.2264
    Episode_Reward/rotating_object: 48.5413
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.21s
                      Time elapsed: 00:35:49
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 43175 steps/s (collection: 2.096s, learning 0.181s)
             Mean action noise std: 3.62
          Mean value_function loss: 116.6014
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 83.4168
                       Mean reward: 265.42
               Mean episode length: 205.06
    Episode_Reward/reaching_object: 1.2597
    Episode_Reward/rotating_object: 51.5385
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.28s
                      Time elapsed: 00:35:51
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 41871 steps/s (collection: 2.219s, learning 0.129s)
             Mean action noise std: 3.62
          Mean value_function loss: 116.1304
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 83.4374
                       Mean reward: 315.77
               Mean episode length: 208.08
    Episode_Reward/reaching_object: 1.2292
    Episode_Reward/rotating_object: 54.3541
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0766
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.35s
                      Time elapsed: 00:35:53
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 43898 steps/s (collection: 2.100s, learning 0.139s)
             Mean action noise std: 3.62
          Mean value_function loss: 111.8783
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 83.4582
                       Mean reward: 231.70
               Mean episode length: 210.79
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 49.4875
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.24s
                      Time elapsed: 00:35:55
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 44284 steps/s (collection: 2.084s, learning 0.136s)
             Mean action noise std: 3.63
          Mean value_function loss: 127.0071
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 83.4901
                       Mean reward: 260.52
               Mean episode length: 196.94
    Episode_Reward/reaching_object: 1.1709
    Episode_Reward/rotating_object: 49.6189
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.22s
                      Time elapsed: 00:35:58
                               ETA: 00:23:17

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 44653 steps/s (collection: 2.057s, learning 0.145s)
             Mean action noise std: 3.63
          Mean value_function loss: 120.2621
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 83.5207
                       Mean reward: 234.47
               Mean episode length: 198.31
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 49.0872
        Episode_Reward/action_rate: -0.0819
          Episode_Reward/joint_vel: -0.0764
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.20s
                      Time elapsed: 00:36:00
                               ETA: 00:23:15

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 44552 steps/s (collection: 2.082s, learning 0.125s)
             Mean action noise std: 3.63
          Mean value_function loss: 120.1398
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 83.5474
                       Mean reward: 279.07
               Mean episode length: 206.68
    Episode_Reward/reaching_object: 1.2077
    Episode_Reward/rotating_object: 47.1870
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.21s
                      Time elapsed: 00:36:02
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 45427 steps/s (collection: 2.051s, learning 0.113s)
             Mean action noise std: 3.64
          Mean value_function loss: 120.5021
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 83.5718
                       Mean reward: 300.65
               Mean episode length: 207.29
    Episode_Reward/reaching_object: 1.2269
    Episode_Reward/rotating_object: 52.0900
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0757
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.16s
                      Time elapsed: 00:36:04
                               ETA: 00:23:10

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 41344 steps/s (collection: 2.197s, learning 0.181s)
             Mean action noise std: 3.64
          Mean value_function loss: 112.1983
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 83.5959
                       Mean reward: 256.11
               Mean episode length: 206.50
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 49.4710
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.38s
                      Time elapsed: 00:36:07
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 43198 steps/s (collection: 2.144s, learning 0.132s)
             Mean action noise std: 3.64
          Mean value_function loss: 114.1239
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 83.6227
                       Mean reward: 255.69
               Mean episode length: 205.46
    Episode_Reward/reaching_object: 1.2342
    Episode_Reward/rotating_object: 53.0345
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.28s
                      Time elapsed: 00:36:09
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 43749 steps/s (collection: 2.063s, learning 0.184s)
             Mean action noise std: 3.65
          Mean value_function loss: 112.0030
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 83.6437
                       Mean reward: 260.46
               Mean episode length: 202.25
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 49.9064
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0753
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.25s
                      Time elapsed: 00:36:11
                               ETA: 00:23:03

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 43043 steps/s (collection: 2.089s, learning 0.195s)
             Mean action noise std: 3.65
          Mean value_function loss: 119.8915
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 83.6724
                       Mean reward: 271.43
               Mean episode length: 200.84
    Episode_Reward/reaching_object: 1.2167
    Episode_Reward/rotating_object: 50.7633
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0761
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.28s
                      Time elapsed: 00:36:13
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 42340 steps/s (collection: 2.114s, learning 0.208s)
             Mean action noise std: 3.65
          Mean value_function loss: 112.1587
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.6852
                       Mean reward: 255.47
               Mean episode length: 209.78
    Episode_Reward/reaching_object: 1.2531
    Episode_Reward/rotating_object: 54.1782
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0789
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.32s
                      Time elapsed: 00:36:16
                               ETA: 00:22:58

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 38067 steps/s (collection: 2.393s, learning 0.189s)
             Mean action noise std: 3.65
          Mean value_function loss: 122.2957
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.7045
                       Mean reward: 293.52
               Mean episode length: 209.68
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 51.7970
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0786
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.58s
                      Time elapsed: 00:36:18
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 43695 steps/s (collection: 2.141s, learning 0.109s)
             Mean action noise std: 3.66
          Mean value_function loss: 119.0294
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 83.7328
                       Mean reward: 244.18
               Mean episode length: 177.07
    Episode_Reward/reaching_object: 1.1659
    Episode_Reward/rotating_object: 53.1486
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.25s
                      Time elapsed: 00:36:21
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 39957 steps/s (collection: 2.331s, learning 0.130s)
             Mean action noise std: 3.66
          Mean value_function loss: 118.8875
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.7638
                       Mean reward: 265.13
               Mean episode length: 193.28
    Episode_Reward/reaching_object: 1.1792
    Episode_Reward/rotating_object: 51.2804
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.46s
                      Time elapsed: 00:36:23
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 46615 steps/s (collection: 1.989s, learning 0.120s)
             Mean action noise std: 3.66
          Mean value_function loss: 117.2456
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 83.7971
                       Mean reward: 244.39
               Mean episode length: 205.75
    Episode_Reward/reaching_object: 1.2223
    Episode_Reward/rotating_object: 49.6941
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.11s
                      Time elapsed: 00:36:25
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 46513 steps/s (collection: 1.993s, learning 0.120s)
             Mean action noise std: 3.67
          Mean value_function loss: 109.3385
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.8280
                       Mean reward: 270.53
               Mean episode length: 204.59
    Episode_Reward/reaching_object: 1.2144
    Episode_Reward/rotating_object: 52.1203
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.11s
                      Time elapsed: 00:36:27
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 47233 steps/s (collection: 1.961s, learning 0.120s)
             Mean action noise std: 3.67
          Mean value_function loss: 108.4990
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 83.8570
                       Mean reward: 284.14
               Mean episode length: 205.04
    Episode_Reward/reaching_object: 1.2262
    Episode_Reward/rotating_object: 53.3167
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.08s
                      Time elapsed: 00:36:29
                               ETA: 00:22:43

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 47049 steps/s (collection: 1.970s, learning 0.120s)
             Mean action noise std: 3.67
          Mean value_function loss: 116.0430
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 83.8795
                       Mean reward: 316.58
               Mean episode length: 208.17
    Episode_Reward/reaching_object: 1.2178
    Episode_Reward/rotating_object: 56.4538
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.09s
                      Time elapsed: 00:36:31
                               ETA: 00:22:41

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 47469 steps/s (collection: 1.946s, learning 0.125s)
             Mean action noise std: 3.68
          Mean value_function loss: 126.4019
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 83.8953
                       Mean reward: 288.30
               Mean episode length: 212.99
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 49.8776
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0788
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.07s
                      Time elapsed: 00:36:34
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 47214 steps/s (collection: 1.980s, learning 0.102s)
             Mean action noise std: 3.68
          Mean value_function loss: 118.6224
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 83.9186
                       Mean reward: 265.35
               Mean episode length: 198.20
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 52.6361
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0758
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.08s
                      Time elapsed: 00:36:36
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 44757 steps/s (collection: 2.087s, learning 0.110s)
             Mean action noise std: 3.68
          Mean value_function loss: 114.2668
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 83.9364
                       Mean reward: 308.83
               Mean episode length: 218.60
    Episode_Reward/reaching_object: 1.2234
    Episode_Reward/rotating_object: 52.4677
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.20s
                      Time elapsed: 00:36:38
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 44265 steps/s (collection: 2.098s, learning 0.123s)
             Mean action noise std: 3.68
          Mean value_function loss: 118.0471
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 83.9527
                       Mean reward: 290.25
               Mean episode length: 208.68
    Episode_Reward/reaching_object: 1.2435
    Episode_Reward/rotating_object: 54.8002
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.22s
                      Time elapsed: 00:36:40
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 45322 steps/s (collection: 2.001s, learning 0.168s)
             Mean action noise std: 3.69
          Mean value_function loss: 120.2552
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 83.9664
                       Mean reward: 261.98
               Mean episode length: 195.11
    Episode_Reward/reaching_object: 1.1713
    Episode_Reward/rotating_object: 50.9548
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.17s
                      Time elapsed: 00:36:42
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 40575 steps/s (collection: 2.232s, learning 0.191s)
             Mean action noise std: 3.69
          Mean value_function loss: 125.8933
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 83.9804
                       Mean reward: 262.58
               Mean episode length: 204.57
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 53.4708
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0764
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.42s
                      Time elapsed: 00:36:45
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 38266 steps/s (collection: 2.354s, learning 0.215s)
             Mean action noise std: 3.69
          Mean value_function loss: 122.7665
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 84.0007
                       Mean reward: 274.18
               Mean episode length: 205.01
    Episode_Reward/reaching_object: 1.2125
    Episode_Reward/rotating_object: 54.6194
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0749
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.57s
                      Time elapsed: 00:36:47
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 42041 steps/s (collection: 2.212s, learning 0.126s)
             Mean action noise std: 3.69
          Mean value_function loss: 120.7120
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 84.0187
                       Mean reward: 273.97
               Mean episode length: 203.01
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 52.1001
        Episode_Reward/action_rate: -0.0848
          Episode_Reward/joint_vel: -0.0754
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.34s
                      Time elapsed: 00:36:50
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 42721 steps/s (collection: 2.148s, learning 0.153s)
             Mean action noise std: 3.70
          Mean value_function loss: 123.3910
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 84.0461
                       Mean reward: 298.25
               Mean episode length: 217.33
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 53.6873
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.30s
                      Time elapsed: 00:36:52
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 39208 steps/s (collection: 2.342s, learning 0.166s)
             Mean action noise std: 3.70
          Mean value_function loss: 124.6708
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 84.0755
                       Mean reward: 265.50
               Mean episode length: 213.31
    Episode_Reward/reaching_object: 1.2545
    Episode_Reward/rotating_object: 52.8331
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.51s
                      Time elapsed: 00:36:54
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 46290 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 3.70
          Mean value_function loss: 120.3002
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 84.0987
                       Mean reward: 273.87
               Mean episode length: 210.70
    Episode_Reward/reaching_object: 1.2552
    Episode_Reward/rotating_object: 57.5909
        Episode_Reward/action_rate: -0.0889
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.12s
                      Time elapsed: 00:36:56
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 44742 steps/s (collection: 2.084s, learning 0.113s)
             Mean action noise std: 3.71
          Mean value_function loss: 116.1841
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 84.1237
                       Mean reward: 300.52
               Mean episode length: 210.30
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 58.2476
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0770
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.20s
                      Time elapsed: 00:36:59
                               ETA: 00:22:11

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 48249 steps/s (collection: 1.937s, learning 0.100s)
             Mean action noise std: 3.71
          Mean value_function loss: 120.9931
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 84.1437
                       Mean reward: 280.00
               Mean episode length: 203.01
    Episode_Reward/reaching_object: 1.1664
    Episode_Reward/rotating_object: 52.5002
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.04s
                      Time elapsed: 00:37:01
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 47505 steps/s (collection: 1.956s, learning 0.114s)
             Mean action noise std: 3.71
          Mean value_function loss: 120.4333
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 84.1610
                       Mean reward: 243.20
               Mean episode length: 199.54
    Episode_Reward/reaching_object: 1.2045
    Episode_Reward/rotating_object: 54.5891
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0750
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.07s
                      Time elapsed: 00:37:03
                               ETA: 00:22:06

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 46331 steps/s (collection: 2.005s, learning 0.117s)
             Mean action noise std: 3.72
          Mean value_function loss: 114.8228
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 84.1862
                       Mean reward: 298.87
               Mean episode length: 210.33
    Episode_Reward/reaching_object: 1.2634
    Episode_Reward/rotating_object: 55.7314
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.12s
                      Time elapsed: 00:37:05
                               ETA: 00:22:04

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 48607 steps/s (collection: 1.906s, learning 0.116s)
             Mean action noise std: 3.72
          Mean value_function loss: 111.5722
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 84.2133
                       Mean reward: 244.58
               Mean episode length: 209.42
    Episode_Reward/reaching_object: 1.2554
    Episode_Reward/rotating_object: 51.2481
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.02s
                      Time elapsed: 00:37:07
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 48839 steps/s (collection: 1.898s, learning 0.115s)
             Mean action noise std: 3.72
          Mean value_function loss: 115.4640
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 84.2380
                       Mean reward: 296.59
               Mean episode length: 203.89
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 53.8330
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.01s
                      Time elapsed: 00:37:09
                               ETA: 00:21:59

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 48909 steps/s (collection: 1.901s, learning 0.109s)
             Mean action noise std: 3.73
          Mean value_function loss: 113.5755
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 84.2590
                       Mean reward: 252.95
               Mean episode length: 196.48
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 53.3212
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.01s
                      Time elapsed: 00:37:11
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 46970 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 3.73
          Mean value_function loss: 114.9401
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 84.2841
                       Mean reward: 271.02
               Mean episode length: 205.26
    Episode_Reward/reaching_object: 1.2614
    Episode_Reward/rotating_object: 56.0932
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.09s
                      Time elapsed: 00:37:13
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 48790 steps/s (collection: 1.894s, learning 0.121s)
             Mean action noise std: 3.73
          Mean value_function loss: 113.2844
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 84.3103
                       Mean reward: 289.54
               Mean episode length: 211.46
    Episode_Reward/reaching_object: 1.1979
    Episode_Reward/rotating_object: 49.5578
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.01s
                      Time elapsed: 00:37:15
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 48518 steps/s (collection: 1.928s, learning 0.098s)
             Mean action noise std: 3.73
          Mean value_function loss: 114.3441
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 84.3255
                       Mean reward: 271.97
               Mean episode length: 205.17
    Episode_Reward/reaching_object: 1.2214
    Episode_Reward/rotating_object: 52.9401
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.03s
                      Time elapsed: 00:37:17
                               ETA: 00:21:48

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 49565 steps/s (collection: 1.884s, learning 0.099s)
             Mean action noise std: 3.74
          Mean value_function loss: 110.8919
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 84.3425
                       Mean reward: 297.00
               Mean episode length: 212.52
    Episode_Reward/reaching_object: 1.2251
    Episode_Reward/rotating_object: 54.2928
        Episode_Reward/action_rate: -0.0891
          Episode_Reward/joint_vel: -0.0757
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.98s
                      Time elapsed: 00:37:19
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 49354 steps/s (collection: 1.896s, learning 0.096s)
             Mean action noise std: 3.74
          Mean value_function loss: 119.5243
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 84.3696
                       Mean reward: 282.86
               Mean episode length: 203.84
    Episode_Reward/reaching_object: 1.2021
    Episode_Reward/rotating_object: 56.4267
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.99s
                      Time elapsed: 00:37:21
                               ETA: 00:21:43

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 48226 steps/s (collection: 1.937s, learning 0.101s)
             Mean action noise std: 3.74
          Mean value_function loss: 121.4994
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 84.3909
                       Mean reward: 292.82
               Mean episode length: 206.08
    Episode_Reward/reaching_object: 1.1950
    Episode_Reward/rotating_object: 53.5919
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.04s
                      Time elapsed: 00:37:23
                               ETA: 00:21:41

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 48369 steps/s (collection: 1.932s, learning 0.100s)
             Mean action noise std: 3.75
          Mean value_function loss: 117.2342
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 84.4180
                       Mean reward: 309.68
               Mean episode length: 212.24
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 54.0082
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0733
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.03s
                      Time elapsed: 00:37:25
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 47924 steps/s (collection: 1.943s, learning 0.108s)
             Mean action noise std: 3.75
          Mean value_function loss: 120.1809
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 84.4448
                       Mean reward: 276.99
               Mean episode length: 196.37
    Episode_Reward/reaching_object: 1.1724
    Episode_Reward/rotating_object: 52.2466
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.05s
                      Time elapsed: 00:37:27
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 48420 steps/s (collection: 1.931s, learning 0.099s)
             Mean action noise std: 3.75
          Mean value_function loss: 122.8655
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 84.4670
                       Mean reward: 274.39
               Mean episode length: 195.68
    Episode_Reward/reaching_object: 1.1989
    Episode_Reward/rotating_object: 54.0167
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.03s
                      Time elapsed: 00:37:29
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 49259 steps/s (collection: 1.890s, learning 0.106s)
             Mean action noise std: 3.76
          Mean value_function loss: 126.9306
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 84.4886
                       Mean reward: 295.00
               Mean episode length: 208.80
    Episode_Reward/reaching_object: 1.2471
    Episode_Reward/rotating_object: 58.0280
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.00s
                      Time elapsed: 00:37:31
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 47179 steps/s (collection: 1.976s, learning 0.108s)
             Mean action noise std: 3.76
          Mean value_function loss: 122.1529
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 84.5110
                       Mean reward: 288.94
               Mean episode length: 204.84
    Episode_Reward/reaching_object: 1.2091
    Episode_Reward/rotating_object: 53.9274
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.08s
                      Time elapsed: 00:37:33
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 48980 steps/s (collection: 1.911s, learning 0.096s)
             Mean action noise std: 3.76
          Mean value_function loss: 109.9899
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 84.5345
                       Mean reward: 248.42
               Mean episode length: 201.00
    Episode_Reward/reaching_object: 1.2223
    Episode_Reward/rotating_object: 52.4319
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.01s
                      Time elapsed: 00:37:35
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 47966 steps/s (collection: 1.949s, learning 0.100s)
             Mean action noise std: 3.77
          Mean value_function loss: 131.1693
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 84.5599
                       Mean reward: 316.73
               Mean episode length: 206.72
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 58.6841
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.05s
                      Time elapsed: 00:37:37
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 48808 steps/s (collection: 1.910s, learning 0.104s)
             Mean action noise std: 3.77
          Mean value_function loss: 125.0223
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 84.5852
                       Mean reward: 306.56
               Mean episode length: 208.08
    Episode_Reward/reaching_object: 1.2598
    Episode_Reward/rotating_object: 58.9392
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.01s
                      Time elapsed: 00:37:39
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 49139 steps/s (collection: 1.904s, learning 0.096s)
             Mean action noise std: 3.77
          Mean value_function loss: 122.4263
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 84.6086
                       Mean reward: 290.43
               Mean episode length: 213.64
    Episode_Reward/reaching_object: 1.2563
    Episode_Reward/rotating_object: 57.7929
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0747
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.00s
                      Time elapsed: 00:37:41
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 46955 steps/s (collection: 1.977s, learning 0.117s)
             Mean action noise std: 3.78
          Mean value_function loss: 116.7658
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 84.6310
                       Mean reward: 315.78
               Mean episode length: 217.66
    Episode_Reward/reaching_object: 1.2619
    Episode_Reward/rotating_object: 57.9613
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.09s
                      Time elapsed: 00:37:43
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 47947 steps/s (collection: 1.928s, learning 0.122s)
             Mean action noise std: 3.78
          Mean value_function loss: 126.0996
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 84.6474
                       Mean reward: 262.40
               Mean episode length: 196.55
    Episode_Reward/reaching_object: 1.2146
    Episode_Reward/rotating_object: 53.6571
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0770
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.05s
                      Time elapsed: 00:37:45
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 48498 steps/s (collection: 1.919s, learning 0.108s)
             Mean action noise std: 3.78
          Mean value_function loss: 122.9103
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 84.6545
                       Mean reward: 288.52
               Mean episode length: 202.89
    Episode_Reward/reaching_object: 1.2289
    Episode_Reward/rotating_object: 55.8640
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.03s
                      Time elapsed: 00:37:48
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 48083 steps/s (collection: 1.925s, learning 0.119s)
             Mean action noise std: 3.78
          Mean value_function loss: 123.7158
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 84.6717
                       Mean reward: 247.10
               Mean episode length: 192.72
    Episode_Reward/reaching_object: 1.2187
    Episode_Reward/rotating_object: 56.1729
        Episode_Reward/action_rate: -0.0893
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.04s
                      Time elapsed: 00:37:50
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 48121 steps/s (collection: 1.921s, learning 0.122s)
             Mean action noise std: 3.78
          Mean value_function loss: 124.8746
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 84.6969
                       Mean reward: 235.40
               Mean episode length: 191.23
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 51.2183
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.04s
                      Time elapsed: 00:37:52
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 48821 steps/s (collection: 1.888s, learning 0.126s)
             Mean action noise std: 3.79
          Mean value_function loss: 128.5763
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 84.7193
                       Mean reward: 288.79
               Mean episode length: 202.16
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 54.6056
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.01s
                      Time elapsed: 00:37:54
                               ETA: 00:21:03

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 48478 steps/s (collection: 1.909s, learning 0.119s)
             Mean action noise std: 3.79
          Mean value_function loss: 119.2297
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 84.7435
                       Mean reward: 317.01
               Mean episode length: 207.02
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 58.4365
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.03s
                      Time elapsed: 00:37:56
                               ETA: 00:21:00

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 48908 steps/s (collection: 1.897s, learning 0.113s)
             Mean action noise std: 3.80
          Mean value_function loss: 128.7289
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 84.7828
                       Mean reward: 276.97
               Mean episode length: 206.42
    Episode_Reward/reaching_object: 1.2211
    Episode_Reward/rotating_object: 55.6428
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.01s
                      Time elapsed: 00:37:58
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 48813 steps/s (collection: 1.906s, learning 0.108s)
             Mean action noise std: 3.80
          Mean value_function loss: 135.8248
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 84.8268
                       Mean reward: 265.14
               Mean episode length: 203.73
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 57.1239
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.01s
                      Time elapsed: 00:38:00
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 49305 steps/s (collection: 1.889s, learning 0.105s)
             Mean action noise std: 3.80
          Mean value_function loss: 120.0841
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.8448
                       Mean reward: 247.47
               Mean episode length: 201.57
    Episode_Reward/reaching_object: 1.2424
    Episode_Reward/rotating_object: 55.8225
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.99s
                      Time elapsed: 00:38:02
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 49874 steps/s (collection: 1.870s, learning 0.101s)
             Mean action noise std: 3.81
          Mean value_function loss: 127.9756
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 84.8632
                       Mean reward: 272.95
               Mean episode length: 208.03
    Episode_Reward/reaching_object: 1.2380
    Episode_Reward/rotating_object: 55.6640
        Episode_Reward/action_rate: -0.0921
          Episode_Reward/joint_vel: -0.0766
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.97s
                      Time elapsed: 00:38:04
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 48964 steps/s (collection: 1.899s, learning 0.109s)
             Mean action noise std: 3.81
          Mean value_function loss: 134.4332
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 84.8877
                       Mean reward: 320.77
               Mean episode length: 210.72
    Episode_Reward/reaching_object: 1.2266
    Episode_Reward/rotating_object: 61.1137
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.01s
                      Time elapsed: 00:38:06
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 49482 steps/s (collection: 1.883s, learning 0.104s)
             Mean action noise std: 3.81
          Mean value_function loss: 125.1231
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 84.9123
                       Mean reward: 285.58
               Mean episode length: 206.43
    Episode_Reward/reaching_object: 1.2079
    Episode_Reward/rotating_object: 56.7192
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.99s
                      Time elapsed: 00:38:08
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 49258 steps/s (collection: 1.887s, learning 0.109s)
             Mean action noise std: 3.81
          Mean value_function loss: 134.7280
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 84.9306
                       Mean reward: 334.83
               Mean episode length: 209.05
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 60.1908
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0730
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.00s
                      Time elapsed: 00:38:10
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 48557 steps/s (collection: 1.898s, learning 0.126s)
             Mean action noise std: 3.82
          Mean value_function loss: 122.2485
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 84.9576
                       Mean reward: 294.02
               Mean episode length: 207.32
    Episode_Reward/reaching_object: 1.2684
    Episode_Reward/rotating_object: 58.3230
        Episode_Reward/action_rate: -0.0933
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.02s
                      Time elapsed: 00:38:12
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 48156 steps/s (collection: 1.917s, learning 0.125s)
             Mean action noise std: 3.82
          Mean value_function loss: 132.1917
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 84.9802
                       Mean reward: 300.55
               Mean episode length: 195.99
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 59.9714
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.04s
                      Time elapsed: 00:38:14
                               ETA: 00:20:37

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 45987 steps/s (collection: 2.012s, learning 0.126s)
             Mean action noise std: 3.82
          Mean value_function loss: 124.8638
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 84.9972
                       Mean reward: 252.32
               Mean episode length: 189.39
    Episode_Reward/reaching_object: 1.1602
    Episode_Reward/rotating_object: 54.2126
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.14s
                      Time elapsed: 00:38:16
                               ETA: 00:20:35

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 47559 steps/s (collection: 1.941s, learning 0.126s)
             Mean action noise std: 3.82
          Mean value_function loss: 128.4398
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 85.0101
                       Mean reward: 282.08
               Mean episode length: 197.59
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 58.6212
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.07s
                      Time elapsed: 00:38:18
                               ETA: 00:20:32

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 49138 steps/s (collection: 1.891s, learning 0.110s)
             Mean action noise std: 3.83
          Mean value_function loss: 126.5489
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 85.0308
                       Mean reward: 283.25
               Mean episode length: 188.69
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 61.1210
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.00s
                      Time elapsed: 00:38:20
                               ETA: 00:20:30

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 48697 steps/s (collection: 1.910s, learning 0.109s)
             Mean action noise std: 3.83
          Mean value_function loss: 132.7987
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 85.0536
                       Mean reward: 306.50
               Mean episode length: 204.94
    Episode_Reward/reaching_object: 1.2231
    Episode_Reward/rotating_object: 57.9009
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.02s
                      Time elapsed: 00:38:22
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 49158 steps/s (collection: 1.892s, learning 0.108s)
             Mean action noise std: 3.84
          Mean value_function loss: 125.7216
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 85.0859
                       Mean reward: 297.67
               Mean episode length: 204.77
    Episode_Reward/reaching_object: 1.2122
    Episode_Reward/rotating_object: 58.6117
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0744
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.00s
                      Time elapsed: 00:38:24
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 48663 steps/s (collection: 1.911s, learning 0.109s)
             Mean action noise std: 3.84
          Mean value_function loss: 112.0305
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 85.1059
                       Mean reward: 370.39
               Mean episode length: 200.98
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 61.9436
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.02s
                      Time elapsed: 00:38:26
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 48803 steps/s (collection: 1.906s, learning 0.109s)
             Mean action noise std: 3.84
          Mean value_function loss: 124.3869
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 85.1213
                       Mean reward: 285.53
               Mean episode length: 219.74
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 55.2749
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0749
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.01s
                      Time elapsed: 00:38:28
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 45942 steps/s (collection: 2.008s, learning 0.132s)
             Mean action noise std: 3.84
          Mean value_function loss: 121.1774
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 85.1444
                       Mean reward: 307.87
               Mean episode length: 212.20
    Episode_Reward/reaching_object: 1.2224
    Episode_Reward/rotating_object: 61.4644
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.14s
                      Time elapsed: 00:38:30
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 47796 steps/s (collection: 1.940s, learning 0.117s)
             Mean action noise std: 3.85
          Mean value_function loss: 128.2138
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 85.1635
                       Mean reward: 326.35
               Mean episode length: 208.45
    Episode_Reward/reaching_object: 1.2423
    Episode_Reward/rotating_object: 64.3752
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0742
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.06s
                      Time elapsed: 00:38:32
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 35597 steps/s (collection: 2.506s, learning 0.256s)
             Mean action noise std: 3.85
          Mean value_function loss: 128.5530
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 85.1811
                       Mean reward: 349.27
               Mean episode length: 216.47
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 63.0641
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.76s
                      Time elapsed: 00:38:35
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 17712 steps/s (collection: 5.170s, learning 0.380s)
             Mean action noise std: 3.85
          Mean value_function loss: 125.0994
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 85.2018
                       Mean reward: 325.57
               Mean episode length: 207.41
    Episode_Reward/reaching_object: 1.2113
    Episode_Reward/rotating_object: 60.8299
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 5.55s
                      Time elapsed: 00:38:40
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 16212 steps/s (collection: 5.499s, learning 0.564s)
             Mean action noise std: 3.85
          Mean value_function loss: 114.3359
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 85.2162
                       Mean reward: 292.25
               Mean episode length: 203.87
    Episode_Reward/reaching_object: 1.2136
    Episode_Reward/rotating_object: 57.5812
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 6.06s
                      Time elapsed: 00:38:47
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 15128 steps/s (collection: 6.051s, learning 0.447s)
             Mean action noise std: 3.86
          Mean value_function loss: 119.7218
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 85.2435
                       Mean reward: 312.84
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.1896
    Episode_Reward/rotating_object: 58.8121
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 6.50s
                      Time elapsed: 00:38:53
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 15815 steps/s (collection: 5.823s, learning 0.392s)
             Mean action noise std: 3.86
          Mean value_function loss: 124.5010
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 85.2630
                       Mean reward: 274.22
               Mean episode length: 199.71
    Episode_Reward/reaching_object: 1.1703
    Episode_Reward/rotating_object: 58.3325
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 6.22s
                      Time elapsed: 00:38:59
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 21928 steps/s (collection: 4.234s, learning 0.249s)
             Mean action noise std: 3.86
          Mean value_function loss: 119.2694
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 85.2781
                       Mean reward: 249.19
               Mean episode length: 189.73
    Episode_Reward/reaching_object: 1.1675
    Episode_Reward/rotating_object: 55.7785
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0712
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 4.48s
                      Time elapsed: 00:39:04
                               ETA: 00:20:09

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 23609 steps/s (collection: 3.886s, learning 0.278s)
             Mean action noise std: 3.86
          Mean value_function loss: 118.7774
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 85.2959
                       Mean reward: 334.89
               Mean episode length: 195.62
    Episode_Reward/reaching_object: 1.1768
    Episode_Reward/rotating_object: 58.7538
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0714
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 4.16s
                      Time elapsed: 00:39:08
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 24284 steps/s (collection: 3.761s, learning 0.287s)
             Mean action noise std: 3.87
          Mean value_function loss: 125.9255
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 85.3154
                       Mean reward: 345.63
               Mean episode length: 213.74
    Episode_Reward/reaching_object: 1.2105
    Episode_Reward/rotating_object: 61.2758
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0753
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 4.05s
                      Time elapsed: 00:39:12
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 21531 steps/s (collection: 4.208s, learning 0.357s)
             Mean action noise std: 3.87
          Mean value_function loss: 128.5274
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 85.3317
                       Mean reward: 345.50
               Mean episode length: 205.22
    Episode_Reward/reaching_object: 1.1888
    Episode_Reward/rotating_object: 59.1883
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 4.57s
                      Time elapsed: 00:39:16
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 25809 steps/s (collection: 3.606s, learning 0.203s)
             Mean action noise std: 3.87
          Mean value_function loss: 122.6299
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 85.3478
                       Mean reward: 316.95
               Mean episode length: 215.90
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 61.1234
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 3.81s
                      Time elapsed: 00:39:20
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 24691 steps/s (collection: 3.750s, learning 0.231s)
             Mean action noise std: 3.87
          Mean value_function loss: 135.8742
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 85.3704
                       Mean reward: 319.40
               Mean episode length: 207.05
    Episode_Reward/reaching_object: 1.2041
    Episode_Reward/rotating_object: 63.0366
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 3.98s
                      Time elapsed: 00:39:24
                               ETA: 00:20:02

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 23776 steps/s (collection: 3.891s, learning 0.243s)
             Mean action noise std: 3.88
          Mean value_function loss: 130.8691
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 85.3885
                       Mean reward: 317.10
               Mean episode length: 207.05
    Episode_Reward/reaching_object: 1.1817
    Episode_Reward/rotating_object: 59.0769
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 4.13s
                      Time elapsed: 00:39:28
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 19349 steps/s (collection: 4.732s, learning 0.349s)
             Mean action noise std: 3.88
          Mean value_function loss: 128.1660
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 85.4015
                       Mean reward: 309.75
               Mean episode length: 204.91
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 57.0663
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 5.08s
                      Time elapsed: 00:39:33
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 18301 steps/s (collection: 5.114s, learning 0.258s)
             Mean action noise std: 3.88
          Mean value_function loss: 126.0573
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 85.4182
                       Mean reward: 312.40
               Mean episode length: 193.40
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 60.7278
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 5.37s
                      Time elapsed: 00:39:39
                               ETA: 00:19:59

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 17847 steps/s (collection: 5.260s, learning 0.248s)
             Mean action noise std: 3.88
          Mean value_function loss: 128.0561
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 85.4361
                       Mean reward: 245.54
               Mean episode length: 200.99
    Episode_Reward/reaching_object: 1.2395
    Episode_Reward/rotating_object: 59.2695
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 5.51s
                      Time elapsed: 00:39:44
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 24588 steps/s (collection: 3.695s, learning 0.303s)
             Mean action noise std: 3.89
          Mean value_function loss: 138.2127
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 85.4539
                       Mean reward: 334.72
               Mean episode length: 210.70
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 65.3726
        Episode_Reward/action_rate: -0.0958
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 4.00s
                      Time elapsed: 00:39:48
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 6896 steps/s (collection: 13.992s, learning 0.263s)
             Mean action noise std: 3.89
          Mean value_function loss: 128.4213
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 85.4655
                       Mean reward: 323.36
               Mean episode length: 201.07
    Episode_Reward/reaching_object: 1.1554
    Episode_Reward/rotating_object: 57.3898
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 14.25s
                      Time elapsed: 00:40:03
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 6751 steps/s (collection: 14.307s, learning 0.253s)
             Mean action noise std: 3.89
          Mean value_function loss: 121.9262
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 85.4836
                       Mean reward: 302.43
               Mean episode length: 197.44
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 62.5895
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 14.56s
                      Time elapsed: 00:40:17
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 8027 steps/s (collection: 12.119s, learning 0.127s)
             Mean action noise std: 3.90
          Mean value_function loss: 135.5675
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 85.5122
                       Mean reward: 288.57
               Mean episode length: 201.12
    Episode_Reward/reaching_object: 1.2167
    Episode_Reward/rotating_object: 59.3998
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0752
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 12.25s
                      Time elapsed: 00:40:29
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14411 steps/s (collection: 6.673s, learning 0.149s)
             Mean action noise std: 3.90
          Mean value_function loss: 121.8564
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 85.5350
                       Mean reward: 360.90
               Mean episode length: 208.51
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 61.1931
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0752
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.82s
                      Time elapsed: 00:40:36
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 13651 steps/s (collection: 7.060s, learning 0.141s)
             Mean action noise std: 3.90
          Mean value_function loss: 132.4945
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 85.5610
                       Mean reward: 298.31
               Mean episode length: 205.54
    Episode_Reward/reaching_object: 1.2172
    Episode_Reward/rotating_object: 60.5682
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 7.20s
                      Time elapsed: 00:40:43
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14140 steps/s (collection: 6.829s, learning 0.123s)
             Mean action noise std: 3.91
          Mean value_function loss: 120.1206
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 85.5904
                       Mean reward: 295.79
               Mean episode length: 202.04
    Episode_Reward/reaching_object: 1.1793
    Episode_Reward/rotating_object: 58.9857
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.95s
                      Time elapsed: 00:40:50
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 13295 steps/s (collection: 7.191s, learning 0.203s)
             Mean action noise std: 3.91
          Mean value_function loss: 127.9842
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 85.6118
                       Mean reward: 268.62
               Mean episode length: 202.68
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 57.4890
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0763
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 7.39s
                      Time elapsed: 00:40:58
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 7819 steps/s (collection: 12.041s, learning 0.531s)
             Mean action noise std: 3.91
          Mean value_function loss: 128.0459
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 85.6373
                       Mean reward: 323.31
               Mean episode length: 199.71
    Episode_Reward/reaching_object: 1.1804
    Episode_Reward/rotating_object: 56.3295
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 12.57s
                      Time elapsed: 00:41:10
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 5756 steps/s (collection: 16.979s, learning 0.098s)
             Mean action noise std: 3.92
          Mean value_function loss: 141.1437
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 85.6656
                       Mean reward: 346.74
               Mean episode length: 204.88
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 63.7746
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 17.08s
                      Time elapsed: 00:41:27
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 47313 steps/s (collection: 1.976s, learning 0.102s)
             Mean action noise std: 3.92
          Mean value_function loss: 128.5201
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 85.6836
                       Mean reward: 290.49
               Mean episode length: 199.65
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 57.5955
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.08s
                      Time elapsed: 00:41:30
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 48030 steps/s (collection: 1.938s, learning 0.109s)
             Mean action noise std: 3.92
          Mean value_function loss: 131.1170
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 85.6956
                       Mean reward: 330.74
               Mean episode length: 210.01
    Episode_Reward/reaching_object: 1.1947
    Episode_Reward/rotating_object: 60.4897
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0753
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.05s
                      Time elapsed: 00:41:32
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 41425 steps/s (collection: 2.196s, learning 0.177s)
             Mean action noise std: 3.92
          Mean value_function loss: 128.9953
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 85.7137
                       Mean reward: 332.90
               Mean episode length: 205.63
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 62.5130
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.37s
                      Time elapsed: 00:41:34
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 41332 steps/s (collection: 2.191s, learning 0.187s)
             Mean action noise std: 3.92
          Mean value_function loss: 138.7709
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 85.7312
                       Mean reward: 265.41
               Mean episode length: 195.66
    Episode_Reward/reaching_object: 1.1580
    Episode_Reward/rotating_object: 61.5822
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0726
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.38s
                      Time elapsed: 00:41:36
                               ETA: 00:20:02

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 38056 steps/s (collection: 2.400s, learning 0.183s)
             Mean action noise std: 3.93
          Mean value_function loss: 126.9967
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 85.7449
                       Mean reward: 354.86
               Mean episode length: 215.91
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 67.0396
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.58s
                      Time elapsed: 00:41:39
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 40099 steps/s (collection: 2.287s, learning 0.164s)
             Mean action noise std: 3.93
          Mean value_function loss: 124.8635
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 85.7660
                       Mean reward: 299.69
               Mean episode length: 191.21
    Episode_Reward/reaching_object: 1.1343
    Episode_Reward/rotating_object: 59.5776
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.45s
                      Time elapsed: 00:41:41
                               ETA: 00:19:57

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 36903 steps/s (collection: 2.481s, learning 0.183s)
             Mean action noise std: 3.94
          Mean value_function loss: 134.3528
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 85.7969
                       Mean reward: 302.47
               Mean episode length: 192.41
    Episode_Reward/reaching_object: 1.2011
    Episode_Reward/rotating_object: 63.0367
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0742
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.66s
                      Time elapsed: 00:41:44
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 39862 steps/s (collection: 2.261s, learning 0.205s)
             Mean action noise std: 3.94
          Mean value_function loss: 132.2255
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 85.8266
                       Mean reward: 299.15
               Mean episode length: 182.75
    Episode_Reward/reaching_object: 1.1474
    Episode_Reward/rotating_object: 58.9059
        Episode_Reward/action_rate: -0.0929
          Episode_Reward/joint_vel: -0.0731
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.47s
                      Time elapsed: 00:41:46
                               ETA: 00:19:53

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 40372 steps/s (collection: 2.230s, learning 0.205s)
             Mean action noise std: 3.94
          Mean value_function loss: 125.5685
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 85.8496
                       Mean reward: 340.83
               Mean episode length: 208.95
    Episode_Reward/reaching_object: 1.2269
    Episode_Reward/rotating_object: 61.3434
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.43s
                      Time elapsed: 00:41:49
                               ETA: 00:19:50

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 36390 steps/s (collection: 2.476s, learning 0.225s)
             Mean action noise std: 3.94
          Mean value_function loss: 131.0974
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 85.8581
                       Mean reward: 323.24
               Mean episode length: 203.99
    Episode_Reward/reaching_object: 1.2274
    Episode_Reward/rotating_object: 71.1476
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.70s
                      Time elapsed: 00:41:52
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 40989 steps/s (collection: 2.225s, learning 0.173s)
             Mean action noise std: 3.95
          Mean value_function loss: 128.0771
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 85.8741
                       Mean reward: 296.90
               Mean episode length: 178.68
    Episode_Reward/reaching_object: 1.1221
    Episode_Reward/rotating_object: 64.1568
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.40s
                      Time elapsed: 00:41:54
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 36196 steps/s (collection: 2.475s, learning 0.241s)
             Mean action noise std: 3.95
          Mean value_function loss: 126.8123
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 85.8889
                       Mean reward: 280.22
               Mean episode length: 189.97
    Episode_Reward/reaching_object: 1.1803
    Episode_Reward/rotating_object: 65.2490
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0703
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.72s
                      Time elapsed: 00:41:57
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 32187 steps/s (collection: 2.763s, learning 0.292s)
             Mean action noise std: 3.95
          Mean value_function loss: 124.7681
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 85.9055
                       Mean reward: 263.70
               Mean episode length: 172.64
    Episode_Reward/reaching_object: 1.1328
    Episode_Reward/rotating_object: 63.2516
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 3.05s
                      Time elapsed: 00:42:00
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 32820 steps/s (collection: 2.701s, learning 0.295s)
             Mean action noise std: 3.95
          Mean value_function loss: 128.3087
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 85.9302
                       Mean reward: 322.37
               Mean episode length: 202.01
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 69.6154
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 3.00s
                      Time elapsed: 00:42:03
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 28100 steps/s (collection: 3.235s, learning 0.264s)
             Mean action noise std: 3.96
          Mean value_function loss: 126.6735
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 85.9556
                       Mean reward: 353.64
               Mean episode length: 211.20
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 62.6540
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 3.50s
                      Time elapsed: 00:42:06
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 26510 steps/s (collection: 3.392s, learning 0.316s)
             Mean action noise std: 3.96
          Mean value_function loss: 120.0826
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 85.9857
                       Mean reward: 335.51
               Mean episode length: 197.12
    Episode_Reward/reaching_object: 1.1679
    Episode_Reward/rotating_object: 62.5490
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 3.71s
                      Time elapsed: 00:42:10
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 25228 steps/s (collection: 3.550s, learning 0.347s)
             Mean action noise std: 3.97
          Mean value_function loss: 138.5067
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 86.0137
                       Mean reward: 279.96
               Mean episode length: 191.07
    Episode_Reward/reaching_object: 1.1235
    Episode_Reward/rotating_object: 57.5382
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0714
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 3.90s
                      Time elapsed: 00:42:14
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 25531 steps/s (collection: 3.514s, learning 0.337s)
             Mean action noise std: 3.97
          Mean value_function loss: 129.8541
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 86.0355
                       Mean reward: 342.51
               Mean episode length: 200.58
    Episode_Reward/reaching_object: 1.1768
    Episode_Reward/rotating_object: 65.0511
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0735
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 3.85s
                      Time elapsed: 00:42:18
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 27445 steps/s (collection: 3.290s, learning 0.292s)
             Mean action noise std: 3.97
          Mean value_function loss: 132.3233
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 86.0520
                       Mean reward: 336.13
               Mean episode length: 189.13
    Episode_Reward/reaching_object: 1.1939
    Episode_Reward/rotating_object: 65.4965
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0749
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 3.58s
                      Time elapsed: 00:42:21
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 28733 steps/s (collection: 3.147s, learning 0.275s)
             Mean action noise std: 3.98
          Mean value_function loss: 137.7192
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 86.0782
                       Mean reward: 296.03
               Mean episode length: 196.52
    Episode_Reward/reaching_object: 1.1759
    Episode_Reward/rotating_object: 58.8301
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 3.42s
                      Time elapsed: 00:42:25
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 28323 steps/s (collection: 3.242s, learning 0.229s)
             Mean action noise std: 3.98
          Mean value_function loss: 135.6154
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 86.0966
                       Mean reward: 339.89
               Mean episode length: 212.14
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 65.6729
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 3.47s
                      Time elapsed: 00:42:28
                               ETA: 00:19:25

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 33260 steps/s (collection: 2.703s, learning 0.253s)
             Mean action noise std: 3.98
          Mean value_function loss: 139.8625
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 86.1140
                       Mean reward: 320.47
               Mean episode length: 204.39
    Episode_Reward/reaching_object: 1.1741
    Episode_Reward/rotating_object: 60.7092
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.96s
                      Time elapsed: 00:42:31
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 33619 steps/s (collection: 2.652s, learning 0.272s)
             Mean action noise std: 3.98
          Mean value_function loss: 133.3391
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 86.1343
                       Mean reward: 361.36
               Mean episode length: 198.22
    Episode_Reward/reaching_object: 1.1807
    Episode_Reward/rotating_object: 60.7380
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0749
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.92s
                      Time elapsed: 00:42:34
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 32002 steps/s (collection: 2.802s, learning 0.270s)
             Mean action noise std: 3.99
          Mean value_function loss: 121.0721
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 86.1563
                       Mean reward: 351.12
               Mean episode length: 213.34
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 66.5995
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0731
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 3.07s
                      Time elapsed: 00:42:37
                               ETA: 00:19:18

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 36501 steps/s (collection: 2.457s, learning 0.237s)
             Mean action noise std: 3.99
          Mean value_function loss: 127.0311
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 86.1933
                       Mean reward: 316.04
               Mean episode length: 198.57
    Episode_Reward/reaching_object: 1.1580
    Episode_Reward/rotating_object: 62.4704
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0730
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.69s
                      Time elapsed: 00:42:40
                               ETA: 00:19:16

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 35254 steps/s (collection: 2.571s, learning 0.218s)
             Mean action noise std: 4.00
          Mean value_function loss: 128.0651
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 86.2332
                       Mean reward: 347.21
               Mean episode length: 207.82
    Episode_Reward/reaching_object: 1.2180
    Episode_Reward/rotating_object: 67.1312
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.79s
                      Time elapsed: 00:42:43
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 34425 steps/s (collection: 2.662s, learning 0.194s)
             Mean action noise std: 4.00
          Mean value_function loss: 142.8089
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.2519
                       Mean reward: 324.96
               Mean episode length: 200.07
    Episode_Reward/reaching_object: 1.1789
    Episode_Reward/rotating_object: 63.7507
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0740
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.86s
                      Time elapsed: 00:42:45
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 33977 steps/s (collection: 2.716s, learning 0.178s)
             Mean action noise std: 4.00
          Mean value_function loss: 125.1793
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 86.2644
                       Mean reward: 274.27
               Mean episode length: 190.16
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 64.1856
        Episode_Reward/action_rate: -0.0998
          Episode_Reward/joint_vel: -0.0763
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.89s
                      Time elapsed: 00:42:48
                               ETA: 00:19:09

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 37210 steps/s (collection: 2.472s, learning 0.170s)
             Mean action noise std: 4.00
          Mean value_function loss: 139.3317
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 86.2820
                       Mean reward: 288.14
               Mean episode length: 195.36
    Episode_Reward/reaching_object: 1.1664
    Episode_Reward/rotating_object: 64.6860
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.64s
                      Time elapsed: 00:42:51
                               ETA: 00:19:07

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 37044 steps/s (collection: 2.454s, learning 0.200s)
             Mean action noise std: 4.01
          Mean value_function loss: 132.8019
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 86.3024
                       Mean reward: 395.08
               Mean episode length: 209.86
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 67.4832
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0747
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.65s
                      Time elapsed: 00:42:54
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 35734 steps/s (collection: 2.601s, learning 0.150s)
             Mean action noise std: 4.01
          Mean value_function loss: 125.6110
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 86.3262
                       Mean reward: 291.98
               Mean episode length: 191.03
    Episode_Reward/reaching_object: 1.1601
    Episode_Reward/rotating_object: 63.2003
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.75s
                      Time elapsed: 00:42:56
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 35491 steps/s (collection: 2.529s, learning 0.241s)
             Mean action noise std: 4.02
          Mean value_function loss: 138.2112
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 86.3564
                       Mean reward: 282.63
               Mean episode length: 199.51
    Episode_Reward/reaching_object: 1.1675
    Episode_Reward/rotating_object: 63.8097
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0752
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.77s
                      Time elapsed: 00:42:59
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 29741 steps/s (collection: 2.969s, learning 0.337s)
             Mean action noise std: 4.02
          Mean value_function loss: 124.6224
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.3854
                       Mean reward: 275.31
               Mean episode length: 192.15
    Episode_Reward/reaching_object: 1.1894
    Episode_Reward/rotating_object: 63.3208
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0769
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 3.31s
                      Time elapsed: 00:43:03
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 29038 steps/s (collection: 3.070s, learning 0.315s)
             Mean action noise std: 4.02
          Mean value_function loss: 131.0903
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 86.4051
                       Mean reward: 327.65
               Mean episode length: 192.20
    Episode_Reward/reaching_object: 1.2414
    Episode_Reward/rotating_object: 68.9748
        Episode_Reward/action_rate: -0.1033
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 3.39s
                      Time elapsed: 00:43:06
                               ETA: 00:18:55

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 30071 steps/s (collection: 3.109s, learning 0.160s)
             Mean action noise std: 4.02
          Mean value_function loss: 126.4955
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 86.4228
                       Mean reward: 279.81
               Mean episode length: 186.34
    Episode_Reward/reaching_object: 1.1526
    Episode_Reward/rotating_object: 62.0195
        Episode_Reward/action_rate: -0.0973
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 3.27s
                      Time elapsed: 00:43:09
                               ETA: 00:18:53

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 23630 steps/s (collection: 3.823s, learning 0.337s)
             Mean action noise std: 4.03
          Mean value_function loss: 131.8768
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 86.4450
                       Mean reward: 312.00
               Mean episode length: 193.07
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 63.9617
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0742
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 4.16s
                      Time elapsed: 00:43:13
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 23919 steps/s (collection: 3.849s, learning 0.261s)
             Mean action noise std: 4.03
          Mean value_function loss: 134.5612
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 86.4685
                       Mean reward: 332.74
               Mean episode length: 201.17
    Episode_Reward/reaching_object: 1.1980
    Episode_Reward/rotating_object: 68.9969
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 4.11s
                      Time elapsed: 00:43:17
                               ETA: 00:18:50

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 23198 steps/s (collection: 3.924s, learning 0.314s)
             Mean action noise std: 4.03
          Mean value_function loss: 128.2874
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 86.4900
                       Mean reward: 346.74
               Mean episode length: 203.35
    Episode_Reward/reaching_object: 1.1467
    Episode_Reward/rotating_object: 60.1172
        Episode_Reward/action_rate: -0.0973
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 4.24s
                      Time elapsed: 00:43:22
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 24421 steps/s (collection: 3.804s, learning 0.222s)
             Mean action noise std: 4.04
          Mean value_function loss: 128.2662
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 86.5215
                       Mean reward: 321.73
               Mean episode length: 196.50
    Episode_Reward/reaching_object: 1.1673
    Episode_Reward/rotating_object: 66.0096
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0754
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 4.03s
                      Time elapsed: 00:43:26
                               ETA: 00:18:46

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 24791 steps/s (collection: 3.694s, learning 0.271s)
             Mean action noise std: 4.04
          Mean value_function loss: 133.1908
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 86.5494
                       Mean reward: 338.95
               Mean episode length: 200.11
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 65.4912
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0789
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 3.97s
                      Time elapsed: 00:43:30
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 22086 steps/s (collection: 4.146s, learning 0.305s)
             Mean action noise std: 4.05
          Mean value_function loss: 134.2217
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 86.5758
                       Mean reward: 297.51
               Mean episode length: 189.47
    Episode_Reward/reaching_object: 1.2061
    Episode_Reward/rotating_object: 66.6397
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0769
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 4.45s
                      Time elapsed: 00:43:34
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 25590 steps/s (collection: 3.596s, learning 0.246s)
             Mean action noise std: 4.05
          Mean value_function loss: 136.5650
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 86.5967
                       Mean reward: 368.26
               Mean episode length: 206.26
    Episode_Reward/reaching_object: 1.2115
    Episode_Reward/rotating_object: 69.4971
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0765
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 3.84s
                      Time elapsed: 00:43:38
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 25199 steps/s (collection: 3.640s, learning 0.261s)
             Mean action noise std: 4.05
          Mean value_function loss: 126.5831
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 86.6107
                       Mean reward: 318.72
               Mean episode length: 196.00
    Episode_Reward/reaching_object: 1.1845
    Episode_Reward/rotating_object: 62.3165
        Episode_Reward/action_rate: -0.1011
          Episode_Reward/joint_vel: -0.0789
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 3.90s
                      Time elapsed: 00:43:42
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 27000 steps/s (collection: 3.423s, learning 0.218s)
             Mean action noise std: 4.05
          Mean value_function loss: 130.4039
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 86.6245
                       Mean reward: 327.15
               Mean episode length: 200.50
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 64.1044
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 3.64s
                      Time elapsed: 00:43:45
                               ETA: 00:18:37

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 23622 steps/s (collection: 3.946s, learning 0.215s)
             Mean action noise std: 4.06
          Mean value_function loss: 120.7968
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 86.6478
                       Mean reward: 296.65
               Mean episode length: 201.07
    Episode_Reward/reaching_object: 1.2287
    Episode_Reward/rotating_object: 67.0449
        Episode_Reward/action_rate: -0.1047
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 4.16s
                      Time elapsed: 00:43:50
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 20409 steps/s (collection: 4.513s, learning 0.304s)
             Mean action noise std: 4.06
          Mean value_function loss: 126.9920
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 86.6661
                       Mean reward: 370.58
               Mean episode length: 202.83
    Episode_Reward/reaching_object: 1.1693
    Episode_Reward/rotating_object: 68.5046
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0716
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 4.82s
                      Time elapsed: 00:43:54
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 24934 steps/s (collection: 3.644s, learning 0.299s)
             Mean action noise std: 4.06
          Mean value_function loss: 139.1048
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 86.6884
                       Mean reward: 320.67
               Mean episode length: 195.89
    Episode_Reward/reaching_object: 1.1667
    Episode_Reward/rotating_object: 63.3699
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0754
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 3.94s
                      Time elapsed: 00:43:58
                               ETA: 00:18:32

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 20060 steps/s (collection: 4.637s, learning 0.264s)
             Mean action noise std: 4.07
          Mean value_function loss: 123.5350
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.7112
                       Mean reward: 285.07
               Mean episode length: 194.63
    Episode_Reward/reaching_object: 1.2141
    Episode_Reward/rotating_object: 66.5274
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 4.90s
                      Time elapsed: 00:44:03
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 24651 steps/s (collection: 3.716s, learning 0.272s)
             Mean action noise std: 4.07
          Mean value_function loss: 136.1550
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 86.7241
                       Mean reward: 403.13
               Mean episode length: 201.50
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 71.8074
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0765
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 3.99s
                      Time elapsed: 00:44:07
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 18362 steps/s (collection: 4.942s, learning 0.411s)
             Mean action noise std: 4.07
          Mean value_function loss: 138.7905
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 86.7449
                       Mean reward: 312.51
               Mean episode length: 184.25
    Episode_Reward/reaching_object: 1.1827
    Episode_Reward/rotating_object: 69.5244
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0738
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 5.35s
                      Time elapsed: 00:44:13
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 21508 steps/s (collection: 4.315s, learning 0.255s)
             Mean action noise std: 4.07
          Mean value_function loss: 129.9162
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.7643
                       Mean reward: 339.08
               Mean episode length: 202.90
    Episode_Reward/reaching_object: 1.1958
    Episode_Reward/rotating_object: 66.6167
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0765
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 4.57s
                      Time elapsed: 00:44:17
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 23537 steps/s (collection: 3.970s, learning 0.206s)
             Mean action noise std: 4.08
          Mean value_function loss: 136.2889
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.7801
                       Mean reward: 326.51
               Mean episode length: 200.51
    Episode_Reward/reaching_object: 1.1692
    Episode_Reward/rotating_object: 66.8963
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 4.18s
                      Time elapsed: 00:44:21
                               ETA: 00:18:23

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 21261 steps/s (collection: 4.212s, learning 0.411s)
             Mean action noise std: 4.08
          Mean value_function loss: 134.8562
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 86.7988
                       Mean reward: 338.45
               Mean episode length: 203.73
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 67.2863
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0729
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 4.62s
                      Time elapsed: 00:44:26
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 16368 steps/s (collection: 5.573s, learning 0.432s)
             Mean action noise std: 4.08
          Mean value_function loss: 133.1448
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 86.8232
                       Mean reward: 336.29
               Mean episode length: 209.13
    Episode_Reward/reaching_object: 1.2257
    Episode_Reward/rotating_object: 67.6098
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 6.01s
                      Time elapsed: 00:44:32
                               ETA: 00:18:21

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 17708 steps/s (collection: 5.282s, learning 0.269s)
             Mean action noise std: 4.09
          Mean value_function loss: 138.5544
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 86.8439
                       Mean reward: 370.66
               Mean episode length: 204.68
    Episode_Reward/reaching_object: 1.2041
    Episode_Reward/rotating_object: 68.3037
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0765
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 5.55s
                      Time elapsed: 00:44:38
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 23377 steps/s (collection: 3.862s, learning 0.344s)
             Mean action noise std: 4.09
          Mean value_function loss: 132.0000
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 86.8681
                       Mean reward: 278.19
               Mean episode length: 182.76
    Episode_Reward/reaching_object: 1.1601
    Episode_Reward/rotating_object: 64.2562
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 4.21s
                      Time elapsed: 00:44:42
                               ETA: 00:18:18

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 20496 steps/s (collection: 4.485s, learning 0.311s)
             Mean action noise std: 4.09
          Mean value_function loss: 127.2197
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 86.8866
                       Mean reward: 349.66
               Mean episode length: 210.71
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 68.7414
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 4.80s
                      Time elapsed: 00:44:47
                               ETA: 00:18:16

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 19417 steps/s (collection: 4.804s, learning 0.259s)
             Mean action noise std: 4.10
          Mean value_function loss: 131.6358
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 86.9027
                       Mean reward: 344.01
               Mean episode length: 205.77
    Episode_Reward/reaching_object: 1.1827
    Episode_Reward/rotating_object: 65.2771
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 5.06s
                      Time elapsed: 00:44:52
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 18846 steps/s (collection: 4.930s, learning 0.286s)
             Mean action noise std: 4.10
          Mean value_function loss: 129.4013
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 86.9226
                       Mean reward: 359.54
               Mean episode length: 204.64
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 69.0683
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0807
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 5.22s
                      Time elapsed: 00:44:57
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 21013 steps/s (collection: 4.421s, learning 0.257s)
             Mean action noise std: 4.10
          Mean value_function loss: 139.2506
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 86.9391
                       Mean reward: 402.21
               Mean episode length: 216.85
    Episode_Reward/reaching_object: 1.2290
    Episode_Reward/rotating_object: 70.4635
        Episode_Reward/action_rate: -0.1078
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 4.68s
                      Time elapsed: 00:45:02
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 21599 steps/s (collection: 4.305s, learning 0.246s)
             Mean action noise std: 4.10
          Mean value_function loss: 131.3664
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 86.9529
                       Mean reward: 347.09
               Mean episode length: 203.82
    Episode_Reward/reaching_object: 1.1742
    Episode_Reward/rotating_object: 68.2730
        Episode_Reward/action_rate: -0.1033
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 4.55s
                      Time elapsed: 00:45:06
                               ETA: 00:18:10

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 20182 steps/s (collection: 4.463s, learning 0.408s)
             Mean action noise std: 4.11
          Mean value_function loss: 135.3773
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 86.9707
                       Mean reward: 387.38
               Mean episode length: 215.12
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 72.4545
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0757
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 4.87s
                      Time elapsed: 00:45:11
                               ETA: 00:18:08

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 21631 steps/s (collection: 4.340s, learning 0.204s)
             Mean action noise std: 4.11
          Mean value_function loss: 124.1632
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 86.9915
                       Mean reward: 400.54
               Mean episode length: 212.49
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 71.4823
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0758
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 4.54s
                      Time elapsed: 00:45:16
                               ETA: 00:18:06

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 21303 steps/s (collection: 4.221s, learning 0.393s)
             Mean action noise std: 4.11
          Mean value_function loss: 131.5650
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 87.0102
                       Mean reward: 314.73
               Mean episode length: 188.60
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 71.4099
        Episode_Reward/action_rate: -0.1044
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 4.61s
                      Time elapsed: 00:45:20
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 19770 steps/s (collection: 4.528s, learning 0.444s)
             Mean action noise std: 4.11
          Mean value_function loss: 126.9460
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 87.0302
                       Mean reward: 357.76
               Mean episode length: 201.24
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 70.3678
        Episode_Reward/action_rate: -0.1076
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 4.97s
                      Time elapsed: 00:45:25
                               ETA: 00:18:03

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 18500 steps/s (collection: 5.002s, learning 0.312s)
             Mean action noise std: 4.12
          Mean value_function loss: 133.4714
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 87.0483
                       Mean reward: 338.34
               Mean episode length: 202.95
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 67.2346
        Episode_Reward/action_rate: -0.1056
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 5.31s
                      Time elapsed: 00:45:30
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 15816 steps/s (collection: 5.780s, learning 0.435s)
             Mean action noise std: 4.12
          Mean value_function loss: 129.7771
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 87.0651
                       Mean reward: 351.44
               Mean episode length: 205.08
    Episode_Reward/reaching_object: 1.1973
    Episode_Reward/rotating_object: 67.9318
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 6.22s
                      Time elapsed: 00:45:37
                               ETA: 00:18:01

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 17729 steps/s (collection: 5.163s, learning 0.382s)
             Mean action noise std: 4.12
          Mean value_function loss: 122.1656
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 87.0853
                       Mean reward: 347.47
               Mean episode length: 208.74
    Episode_Reward/reaching_object: 1.2452
    Episode_Reward/rotating_object: 73.1686
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 5.54s
                      Time elapsed: 00:45:42
                               ETA: 00:17:59

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 22877 steps/s (collection: 4.027s, learning 0.270s)
             Mean action noise std: 4.13
          Mean value_function loss: 135.6087
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 87.1029
                       Mean reward: 346.92
               Mean episode length: 210.26
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 68.1645
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 4.30s
                      Time elapsed: 00:45:46
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 22535 steps/s (collection: 3.900s, learning 0.462s)
             Mean action noise std: 4.13
          Mean value_function loss: 125.7169
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 87.1191
                       Mean reward: 335.55
               Mean episode length: 203.68
    Episode_Reward/reaching_object: 1.2002
    Episode_Reward/rotating_object: 66.9387
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0798
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 4.36s
                      Time elapsed: 00:45:51
                               ETA: 00:17:56

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 17012 steps/s (collection: 5.403s, learning 0.375s)
             Mean action noise std: 4.13
          Mean value_function loss: 134.0436
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.1380
                       Mean reward: 377.00
               Mean episode length: 208.83
    Episode_Reward/reaching_object: 1.2212
    Episode_Reward/rotating_object: 70.7074
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 5.78s
                      Time elapsed: 00:45:57
                               ETA: 00:17:54

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 16591 steps/s (collection: 5.411s, learning 0.514s)
             Mean action noise std: 4.13
          Mean value_function loss: 141.5687
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 87.1525
                       Mean reward: 309.94
               Mean episode length: 207.28
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 67.1507
        Episode_Reward/action_rate: -0.1065
          Episode_Reward/joint_vel: -0.0740
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 5.93s
                      Time elapsed: 00:46:03
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 18416 steps/s (collection: 4.877s, learning 0.461s)
             Mean action noise std: 4.13
          Mean value_function loss: 138.4855
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 87.1600
                       Mean reward: 389.08
               Mean episode length: 210.50
    Episode_Reward/reaching_object: 1.2232
    Episode_Reward/rotating_object: 71.5734
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 5.34s
                      Time elapsed: 00:46:08
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 19004 steps/s (collection: 4.737s, learning 0.435s)
             Mean action noise std: 4.14
          Mean value_function loss: 134.6139
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 87.1721
                       Mean reward: 368.67
               Mean episode length: 209.98
    Episode_Reward/reaching_object: 1.1580
    Episode_Reward/rotating_object: 67.2517
        Episode_Reward/action_rate: -0.1043
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 5.17s
                      Time elapsed: 00:46:13
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 17557 steps/s (collection: 5.184s, learning 0.415s)
             Mean action noise std: 4.14
          Mean value_function loss: 132.7619
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 87.1974
                       Mean reward: 356.25
               Mean episode length: 203.94
    Episode_Reward/reaching_object: 1.1825
    Episode_Reward/rotating_object: 68.8949
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0747
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 5.60s
                      Time elapsed: 00:46:19
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 16750 steps/s (collection: 5.381s, learning 0.488s)
             Mean action noise std: 4.15
          Mean value_function loss: 137.0018
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 87.2227
                       Mean reward: 343.25
               Mean episode length: 205.61
    Episode_Reward/reaching_object: 1.2549
    Episode_Reward/rotating_object: 73.3181
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 5.87s
                      Time elapsed: 00:46:25
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 17862 steps/s (collection: 5.245s, learning 0.258s)
             Mean action noise std: 4.15
          Mean value_function loss: 132.7667
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 87.2488
                       Mean reward: 358.49
               Mean episode length: 199.19
    Episode_Reward/reaching_object: 1.2053
    Episode_Reward/rotating_object: 72.8354
        Episode_Reward/action_rate: -0.1088
          Episode_Reward/joint_vel: -0.0757
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 5.50s
                      Time elapsed: 00:46:30
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 16634 steps/s (collection: 5.476s, learning 0.433s)
             Mean action noise std: 4.15
          Mean value_function loss: 140.5002
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 87.2766
                       Mean reward: 371.17
               Mean episode length: 204.34
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 73.8089
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0758
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 5.91s
                      Time elapsed: 00:46:36
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 18025 steps/s (collection: 4.924s, learning 0.529s)
             Mean action noise std: 4.15
          Mean value_function loss: 131.4425
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 87.2895
                       Mean reward: 365.86
               Mean episode length: 204.53
    Episode_Reward/reaching_object: 1.1934
    Episode_Reward/rotating_object: 71.3774
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 5.45s
                      Time elapsed: 00:46:41
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 17501 steps/s (collection: 5.293s, learning 0.324s)
             Mean action noise std: 4.16
          Mean value_function loss: 122.4679
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 87.3062
                       Mean reward: 369.33
               Mean episode length: 205.36
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 74.4849
        Episode_Reward/action_rate: -0.1115
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 5.62s
                      Time elapsed: 00:46:47
                               ETA: 00:17:42

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 18176 steps/s (collection: 5.153s, learning 0.255s)
             Mean action noise std: 4.16
          Mean value_function loss: 135.7596
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 87.3151
                       Mean reward: 365.08
               Mean episode length: 201.06
    Episode_Reward/reaching_object: 1.1888
    Episode_Reward/rotating_object: 73.4668
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 5.41s
                      Time elapsed: 00:46:52
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 22876 steps/s (collection: 4.187s, learning 0.111s)
             Mean action noise std: 4.16
          Mean value_function loss: 126.9268
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 87.3261
                       Mean reward: 377.43
               Mean episode length: 209.53
    Episode_Reward/reaching_object: 1.2277
    Episode_Reward/rotating_object: 70.9547
        Episode_Reward/action_rate: -0.1106
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 4.30s
                      Time elapsed: 00:46:57
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 48017 steps/s (collection: 1.945s, learning 0.103s)
             Mean action noise std: 4.16
          Mean value_function loss: 128.1112
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 87.3453
                       Mean reward: 393.98
               Mean episode length: 209.55
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 72.7289
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0731
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.05s
                      Time elapsed: 00:46:59
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 47763 steps/s (collection: 1.963s, learning 0.095s)
             Mean action noise std: 4.17
          Mean value_function loss: 129.8952
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 87.3605
                       Mean reward: 375.76
               Mean episode length: 198.86
    Episode_Reward/reaching_object: 1.1948
    Episode_Reward/rotating_object: 76.7333
        Episode_Reward/action_rate: -0.1094
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.06s
                      Time elapsed: 00:47:01
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 48307 steps/s (collection: 1.926s, learning 0.109s)
             Mean action noise std: 4.17
          Mean value_function loss: 123.7320
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 87.3833
                       Mean reward: 400.11
               Mean episode length: 217.02
    Episode_Reward/reaching_object: 1.2602
    Episode_Reward/rotating_object: 80.3477
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.03s
                      Time elapsed: 00:47:03
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 48148 steps/s (collection: 1.941s, learning 0.101s)
             Mean action noise std: 4.17
          Mean value_function loss: 141.0336
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 87.4030
                       Mean reward: 382.16
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.2239
    Episode_Reward/rotating_object: 76.2336
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0750
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.04s
                      Time elapsed: 00:47:05
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 42460 steps/s (collection: 2.198s, learning 0.117s)
             Mean action noise std: 4.18
          Mean value_function loss: 134.5860
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 87.4240
                       Mean reward: 381.06
               Mean episode length: 210.45
    Episode_Reward/reaching_object: 1.2095
    Episode_Reward/rotating_object: 72.1665
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.32s
                      Time elapsed: 00:47:07
                               ETA: 00:17:24

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 40271 steps/s (collection: 2.280s, learning 0.161s)
             Mean action noise std: 4.18
          Mean value_function loss: 131.1128
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 87.4438
                       Mean reward: 394.90
               Mean episode length: 206.01
    Episode_Reward/reaching_object: 1.1677
    Episode_Reward/rotating_object: 72.5287
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.44s
                      Time elapsed: 00:47:10
                               ETA: 00:17:22

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 42753 steps/s (collection: 2.087s, learning 0.212s)
             Mean action noise std: 4.18
          Mean value_function loss: 128.3339
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 87.4689
                       Mean reward: 328.32
               Mean episode length: 199.34
    Episode_Reward/reaching_object: 1.2126
    Episode_Reward/rotating_object: 75.2395
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.30s
                      Time elapsed: 00:47:12
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 39323 steps/s (collection: 2.279s, learning 0.221s)
             Mean action noise std: 4.19
          Mean value_function loss: 127.6251
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 87.4996
                       Mean reward: 385.07
               Mean episode length: 207.21
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 78.9926
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0704
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.50s
                      Time elapsed: 00:47:14
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 35031 steps/s (collection: 2.568s, learning 0.238s)
             Mean action noise std: 4.19
          Mean value_function loss: 129.8120
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 87.5311
                       Mean reward: 378.02
               Mean episode length: 216.58
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 73.2805
        Episode_Reward/action_rate: -0.1146
          Episode_Reward/joint_vel: -0.0769
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.81s
                      Time elapsed: 00:47:17
                               ETA: 00:17:14

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 39332 steps/s (collection: 2.320s, learning 0.180s)
             Mean action noise std: 4.19
          Mean value_function loss: 143.2846
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.5464
                       Mean reward: 394.82
               Mean episode length: 204.28
    Episode_Reward/reaching_object: 1.1314
    Episode_Reward/rotating_object: 69.4777
        Episode_Reward/action_rate: -0.1070
          Episode_Reward/joint_vel: -0.0712
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.50s
                      Time elapsed: 00:47:20
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 38195 steps/s (collection: 2.383s, learning 0.191s)
             Mean action noise std: 4.20
          Mean value_function loss: 136.1596
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 87.5601
                       Mean reward: 365.10
               Mean episode length: 199.37
    Episode_Reward/reaching_object: 1.1953
    Episode_Reward/rotating_object: 75.8432
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.57s
                      Time elapsed: 00:47:22
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 40551 steps/s (collection: 2.246s, learning 0.178s)
             Mean action noise std: 4.20
          Mean value_function loss: 138.5434
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 87.5769
                       Mean reward: 361.48
               Mean episode length: 199.19
    Episode_Reward/reaching_object: 1.1732
    Episode_Reward/rotating_object: 72.2790
        Episode_Reward/action_rate: -0.1101
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.42s
                      Time elapsed: 00:47:25
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 43892 steps/s (collection: 2.113s, learning 0.127s)
             Mean action noise std: 4.20
          Mean value_function loss: 132.0260
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 87.5987
                       Mean reward: 354.95
               Mean episode length: 206.00
    Episode_Reward/reaching_object: 1.1894
    Episode_Reward/rotating_object: 75.7730
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.24s
                      Time elapsed: 00:47:27
                               ETA: 00:17:03

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 39134 steps/s (collection: 2.249s, learning 0.263s)
             Mean action noise std: 4.20
          Mean value_function loss: 139.6443
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 87.6138
                       Mean reward: 390.79
               Mean episode length: 214.54
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 75.6698
        Episode_Reward/action_rate: -0.1132
          Episode_Reward/joint_vel: -0.0752
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.51s
                      Time elapsed: 00:47:29
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 45373 steps/s (collection: 2.041s, learning 0.125s)
             Mean action noise std: 4.21
          Mean value_function loss: 142.1615
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.6260
                       Mean reward: 391.73
               Mean episode length: 201.92
    Episode_Reward/reaching_object: 1.1778
    Episode_Reward/rotating_object: 72.7756
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0738
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.17s
                      Time elapsed: 00:47:32
                               ETA: 00:16:58

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 38214 steps/s (collection: 2.399s, learning 0.173s)
             Mean action noise std: 4.21
          Mean value_function loss: 139.3842
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 87.6428
                       Mean reward: 389.88
               Mean episode length: 201.17
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 77.8197
        Episode_Reward/action_rate: -0.1116
          Episode_Reward/joint_vel: -0.0715
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.57s
                      Time elapsed: 00:47:34
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 38927 steps/s (collection: 2.316s, learning 0.209s)
             Mean action noise std: 4.21
          Mean value_function loss: 130.3304
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 87.6595
                       Mean reward: 379.53
               Mean episode length: 202.61
    Episode_Reward/reaching_object: 1.1726
    Episode_Reward/rotating_object: 69.8950
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.53s
                      Time elapsed: 00:47:37
                               ETA: 00:16:53

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 39632 steps/s (collection: 2.368s, learning 0.112s)
             Mean action noise std: 4.21
          Mean value_function loss: 123.7163
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 87.6754
                       Mean reward: 385.95
               Mean episode length: 213.98
    Episode_Reward/reaching_object: 1.1968
    Episode_Reward/rotating_object: 73.1896
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0770
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.48s
                      Time elapsed: 00:47:39
                               ETA: 00:16:50

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 38343 steps/s (collection: 2.405s, learning 0.159s)
             Mean action noise std: 4.22
          Mean value_function loss: 131.0037
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 87.6983
                       Mean reward: 354.63
               Mean episode length: 195.14
    Episode_Reward/reaching_object: 1.1838
    Episode_Reward/rotating_object: 75.8014
        Episode_Reward/action_rate: -0.1106
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.56s
                      Time elapsed: 00:47:42
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 41280 steps/s (collection: 2.257s, learning 0.125s)
             Mean action noise std: 4.22
          Mean value_function loss: 141.3446
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 87.7267
                       Mean reward: 430.31
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 81.1493
        Episode_Reward/action_rate: -0.1170
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.38s
                      Time elapsed: 00:47:44
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 45111 steps/s (collection: 2.060s, learning 0.119s)
             Mean action noise std: 4.22
          Mean value_function loss: 134.7201
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 87.7463
                       Mean reward: 418.41
               Mean episode length: 215.09
    Episode_Reward/reaching_object: 1.2229
    Episode_Reward/rotating_object: 77.3831
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.18s
                      Time elapsed: 00:47:46
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 43295 steps/s (collection: 2.126s, learning 0.145s)
             Mean action noise std: 4.23
          Mean value_function loss: 140.0070
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 87.7611
                       Mean reward: 407.68
               Mean episode length: 212.05
    Episode_Reward/reaching_object: 1.2184
    Episode_Reward/rotating_object: 77.2536
        Episode_Reward/action_rate: -0.1143
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.27s
                      Time elapsed: 00:47:49
                               ETA: 00:16:40

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 43603 steps/s (collection: 2.115s, learning 0.140s)
             Mean action noise std: 4.23
          Mean value_function loss: 137.0090
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 87.7780
                       Mean reward: 365.28
               Mean episode length: 195.25
    Episode_Reward/reaching_object: 1.1829
    Episode_Reward/rotating_object: 76.6893
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0733
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.25s
                      Time elapsed: 00:47:51
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 45826 steps/s (collection: 1.994s, learning 0.151s)
             Mean action noise std: 4.23
          Mean value_function loss: 139.3295
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 87.7892
                       Mean reward: 368.28
               Mean episode length: 201.48
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 78.6741
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.15s
                      Time elapsed: 00:47:53
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 42628 steps/s (collection: 2.173s, learning 0.133s)
             Mean action noise std: 4.24
          Mean value_function loss: 141.6530
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 87.8056
                       Mean reward: 366.99
               Mean episode length: 199.86
    Episode_Reward/reaching_object: 1.2201
    Episode_Reward/rotating_object: 74.6687
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0760
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.31s
                      Time elapsed: 00:47:55
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 35396 steps/s (collection: 2.547s, learning 0.231s)
             Mean action noise std: 4.24
          Mean value_function loss: 146.9908
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 87.8331
                       Mean reward: 360.99
               Mean episode length: 202.94
    Episode_Reward/reaching_object: 1.1975
    Episode_Reward/rotating_object: 74.1730
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.78s
                      Time elapsed: 00:47:58
                               ETA: 00:16:29

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 32003 steps/s (collection: 2.909s, learning 0.163s)
             Mean action noise std: 4.24
          Mean value_function loss: 146.5635
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 87.8444
                       Mean reward: 423.06
               Mean episode length: 214.69
    Episode_Reward/reaching_object: 1.1851
    Episode_Reward/rotating_object: 74.2188
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0716
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 3.07s
                      Time elapsed: 00:48:01
                               ETA: 00:16:27

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 38068 steps/s (collection: 2.368s, learning 0.214s)
             Mean action noise std: 4.24
          Mean value_function loss: 134.9229
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 87.8525
                       Mean reward: 340.80
               Mean episode length: 192.65
    Episode_Reward/reaching_object: 1.1989
    Episode_Reward/rotating_object: 74.2966
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.58s
                      Time elapsed: 00:48:04
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 39185 steps/s (collection: 2.262s, learning 0.247s)
             Mean action noise std: 4.24
          Mean value_function loss: 127.2359
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 87.8599
                       Mean reward: 429.00
               Mean episode length: 206.20
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 75.6452
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.51s
                      Time elapsed: 00:48:06
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 38974 steps/s (collection: 2.294s, learning 0.228s)
             Mean action noise std: 4.25
          Mean value_function loss: 128.5681
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 87.8774
                       Mean reward: 393.69
               Mean episode length: 201.02
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 78.2801
        Episode_Reward/action_rate: -0.1139
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.52s
                      Time elapsed: 00:48:09
                               ETA: 00:16:19

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 37773 steps/s (collection: 2.377s, learning 0.226s)
             Mean action noise std: 4.25
          Mean value_function loss: 123.5259
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 87.8999
                       Mean reward: 408.14
               Mean episode length: 211.39
    Episode_Reward/reaching_object: 1.1923
    Episode_Reward/rotating_object: 76.7033
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0717
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.60s
                      Time elapsed: 00:48:11
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 37126 steps/s (collection: 2.399s, learning 0.249s)
             Mean action noise std: 4.25
          Mean value_function loss: 138.1899
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.9155
                       Mean reward: 399.73
               Mean episode length: 205.89
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 77.1107
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0717
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.65s
                      Time elapsed: 00:48:14
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 32014 steps/s (collection: 2.798s, learning 0.273s)
             Mean action noise std: 4.25
          Mean value_function loss: 132.3084
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 87.9309
                       Mean reward: 404.16
               Mean episode length: 203.58
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 77.8914
        Episode_Reward/action_rate: -0.1152
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 3.07s
                      Time elapsed: 00:48:17
                               ETA: 00:16:11

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 32596 steps/s (collection: 2.798s, learning 0.218s)
             Mean action noise std: 4.26
          Mean value_function loss: 138.7209
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 87.9517
                       Mean reward: 366.77
               Mean episode length: 205.58
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 76.9327
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 3.02s
                      Time elapsed: 00:48:20
                               ETA: 00:16:09

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 34592 steps/s (collection: 2.526s, learning 0.316s)
             Mean action noise std: 4.26
          Mean value_function loss: 136.4120
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 87.9742
                       Mean reward: 410.17
               Mean episode length: 214.47
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 81.0848
        Episode_Reward/action_rate: -0.1198
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.84s
                      Time elapsed: 00:48:23
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 30554 steps/s (collection: 2.954s, learning 0.264s)
             Mean action noise std: 4.27
          Mean value_function loss: 136.5380
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.9980
                       Mean reward: 397.74
               Mean episode length: 203.32
    Episode_Reward/reaching_object: 1.1854
    Episode_Reward/rotating_object: 75.3169
        Episode_Reward/action_rate: -0.1144
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 3.22s
                      Time elapsed: 00:48:26
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 34635 steps/s (collection: 2.620s, learning 0.218s)
             Mean action noise std: 4.27
          Mean value_function loss: 136.9173
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.0155
                       Mean reward: 368.92
               Mean episode length: 198.23
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 75.0026
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.84s
                      Time elapsed: 00:48:29
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 36058 steps/s (collection: 2.538s, learning 0.188s)
             Mean action noise std: 4.27
          Mean value_function loss: 134.1845
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.0260
                       Mean reward: 372.42
               Mean episode length: 204.86
    Episode_Reward/reaching_object: 1.2386
    Episode_Reward/rotating_object: 79.8205
        Episode_Reward/action_rate: -0.1185
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.73s
                      Time elapsed: 00:48:32
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 33981 steps/s (collection: 2.624s, learning 0.269s)
             Mean action noise std: 4.27
          Mean value_function loss: 137.7654
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 88.0374
                       Mean reward: 352.40
               Mean episode length: 182.25
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 79.2660
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.89s
                      Time elapsed: 00:48:35
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 31195 steps/s (collection: 2.886s, learning 0.265s)
             Mean action noise std: 4.27
          Mean value_function loss: 132.4254
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 88.0548
                       Mean reward: 402.08
               Mean episode length: 206.57
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 78.5401
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 3.15s
                      Time elapsed: 00:48:38
                               ETA: 00:15:54

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 32304 steps/s (collection: 2.759s, learning 0.284s)
             Mean action noise std: 4.28
          Mean value_function loss: 136.8441
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 88.0698
                       Mean reward: 437.42
               Mean episode length: 213.40
    Episode_Reward/reaching_object: 1.2133
    Episode_Reward/rotating_object: 78.1110
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0730
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 3.04s
                      Time elapsed: 00:48:41
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 34524 steps/s (collection: 2.621s, learning 0.227s)
             Mean action noise std: 4.28
          Mean value_function loss: 139.1958
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 88.0792
                       Mean reward: 384.23
               Mean episode length: 191.18
    Episode_Reward/reaching_object: 1.1763
    Episode_Reward/rotating_object: 76.9758
        Episode_Reward/action_rate: -0.1140
          Episode_Reward/joint_vel: -0.0689
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.85s
                      Time elapsed: 00:48:44
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 36036 steps/s (collection: 2.472s, learning 0.256s)
             Mean action noise std: 4.28
          Mean value_function loss: 128.7709
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 88.1014
                       Mean reward: 438.40
               Mean episode length: 209.71
    Episode_Reward/reaching_object: 1.1834
    Episode_Reward/rotating_object: 80.4488
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.73s
                      Time elapsed: 00:48:46
                               ETA: 00:15:47

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 36737 steps/s (collection: 2.476s, learning 0.200s)
             Mean action noise std: 4.29
          Mean value_function loss: 132.1750
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 88.1288
                       Mean reward: 372.43
               Mean episode length: 197.38
    Episode_Reward/reaching_object: 1.1971
    Episode_Reward/rotating_object: 76.3653
        Episode_Reward/action_rate: -0.1167
          Episode_Reward/joint_vel: -0.0717
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.68s
                      Time elapsed: 00:48:49
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 38666 steps/s (collection: 2.298s, learning 0.244s)
             Mean action noise std: 4.29
          Mean value_function loss: 134.1920
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 88.1472
                       Mean reward: 403.69
               Mean episode length: 212.59
    Episode_Reward/reaching_object: 1.2683
    Episode_Reward/rotating_object: 86.3556
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.54s
                      Time elapsed: 00:48:52
                               ETA: 00:15:42

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 37539 steps/s (collection: 2.364s, learning 0.255s)
             Mean action noise std: 4.29
          Mean value_function loss: 131.4849
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 88.1682
                       Mean reward: 406.57
               Mean episode length: 207.74
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 77.7650
        Episode_Reward/action_rate: -0.1181
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.62s
                      Time elapsed: 00:48:54
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 38847 steps/s (collection: 2.297s, learning 0.234s)
             Mean action noise std: 4.30
          Mean value_function loss: 140.1284
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 88.1914
                       Mean reward: 418.49
               Mean episode length: 207.60
    Episode_Reward/reaching_object: 1.2234
    Episode_Reward/rotating_object: 80.7674
        Episode_Reward/action_rate: -0.1191
          Episode_Reward/joint_vel: -0.0710
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.53s
                      Time elapsed: 00:48:57
                               ETA: 00:15:36

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 37381 steps/s (collection: 2.437s, learning 0.193s)
             Mean action noise std: 4.30
          Mean value_function loss: 125.9357
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 88.2065
                       Mean reward: 414.46
               Mean episode length: 203.97
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 82.9661
        Episode_Reward/action_rate: -0.1172
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.63s
                      Time elapsed: 00:48:59
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 37441 steps/s (collection: 2.403s, learning 0.222s)
             Mean action noise std: 4.30
          Mean value_function loss: 119.4645
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 88.2269
                       Mean reward: 413.82
               Mean episode length: 202.79
    Episode_Reward/reaching_object: 1.1640
    Episode_Reward/rotating_object: 76.9237
        Episode_Reward/action_rate: -0.1155
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.63s
                      Time elapsed: 00:49:02
                               ETA: 00:15:31

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 34243 steps/s (collection: 2.617s, learning 0.254s)
             Mean action noise std: 4.31
          Mean value_function loss: 126.5509
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 88.2511
                       Mean reward: 357.03
               Mean episode length: 211.12
    Episode_Reward/reaching_object: 1.2181
    Episode_Reward/rotating_object: 80.4106
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.87s
                      Time elapsed: 00:49:05
                               ETA: 00:15:29

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 34211 steps/s (collection: 2.597s, learning 0.277s)
             Mean action noise std: 4.31
          Mean value_function loss: 132.0733
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 88.2714
                       Mean reward: 430.94
               Mean episode length: 220.44
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 80.4243
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.87s
                      Time elapsed: 00:49:08
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 36097 steps/s (collection: 2.466s, learning 0.257s)
             Mean action noise std: 4.31
          Mean value_function loss: 118.1740
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 88.2818
                       Mean reward: 413.21
               Mean episode length: 210.85
    Episode_Reward/reaching_object: 1.2133
    Episode_Reward/rotating_object: 83.9902
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.72s
                      Time elapsed: 00:49:11
                               ETA: 00:15:24

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 38489 steps/s (collection: 2.330s, learning 0.224s)
             Mean action noise std: 4.31
          Mean value_function loss: 129.2743
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 88.2952
                       Mean reward: 442.79
               Mean episode length: 214.37
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 77.5406
        Episode_Reward/action_rate: -0.1189
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.55s
                      Time elapsed: 00:49:13
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 33748 steps/s (collection: 2.690s, learning 0.223s)
             Mean action noise std: 4.32
          Mean value_function loss: 132.2935
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 88.3100
                       Mean reward: 436.52
               Mean episode length: 201.45
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 82.3190
        Episode_Reward/action_rate: -0.1174
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.91s
                      Time elapsed: 00:49:16
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 34535 steps/s (collection: 2.541s, learning 0.305s)
             Mean action noise std: 4.32
          Mean value_function loss: 130.8201
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 88.3302
                       Mean reward: 401.62
               Mean episode length: 209.28
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 83.3220
        Episode_Reward/action_rate: -0.1190
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.85s
                      Time elapsed: 00:49:19
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 37823 steps/s (collection: 2.387s, learning 0.212s)
             Mean action noise std: 4.32
          Mean value_function loss: 142.5702
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 88.3465
                       Mean reward: 455.91
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 1.2084
    Episode_Reward/rotating_object: 81.1230
        Episode_Reward/action_rate: -0.1204
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.60s
                      Time elapsed: 00:49:21
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 35250 steps/s (collection: 2.597s, learning 0.192s)
             Mean action noise std: 4.32
          Mean value_function loss: 130.0234
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 88.3574
                       Mean reward: 376.10
               Mean episode length: 200.37
    Episode_Reward/reaching_object: 1.2112
    Episode_Reward/rotating_object: 81.2223
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.79s
                      Time elapsed: 00:49:24
                               ETA: 00:15:11

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 38738 steps/s (collection: 2.333s, learning 0.205s)
             Mean action noise std: 4.33
          Mean value_function loss: 139.1033
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 88.3804
                       Mean reward: 390.47
               Mean episode length: 188.74
    Episode_Reward/reaching_object: 1.1556
    Episode_Reward/rotating_object: 78.1647
        Episode_Reward/action_rate: -0.1153
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.54s
                      Time elapsed: 00:49:27
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 37562 steps/s (collection: 2.370s, learning 0.247s)
             Mean action noise std: 4.33
          Mean value_function loss: 136.1651
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 88.4089
                       Mean reward: 376.78
               Mean episode length: 198.86
    Episode_Reward/reaching_object: 1.1607
    Episode_Reward/rotating_object: 78.0944
        Episode_Reward/action_rate: -0.1171
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.62s
                      Time elapsed: 00:49:29
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 32968 steps/s (collection: 2.713s, learning 0.269s)
             Mean action noise std: 4.34
          Mean value_function loss: 134.7840
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.4294
                       Mean reward: 380.59
               Mean episode length: 187.90
    Episode_Reward/reaching_object: 1.1828
    Episode_Reward/rotating_object: 79.2550
        Episode_Reward/action_rate: -0.1166
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.98s
                      Time elapsed: 00:49:32
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 38764 steps/s (collection: 2.295s, learning 0.241s)
             Mean action noise std: 4.34
          Mean value_function loss: 126.9040
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 88.4401
                       Mean reward: 430.67
               Mean episode length: 205.46
    Episode_Reward/reaching_object: 1.2125
    Episode_Reward/rotating_object: 83.8262
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.54s
                      Time elapsed: 00:49:35
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 34858 steps/s (collection: 2.564s, learning 0.256s)
             Mean action noise std: 4.34
          Mean value_function loss: 136.2581
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 88.4625
                       Mean reward: 356.47
               Mean episode length: 187.97
    Episode_Reward/reaching_object: 1.1855
    Episode_Reward/rotating_object: 81.6549
        Episode_Reward/action_rate: -0.1175
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.82s
                      Time elapsed: 00:49:38
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 36990 steps/s (collection: 2.421s, learning 0.237s)
             Mean action noise std: 4.34
          Mean value_function loss: 128.5681
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 88.4825
                       Mean reward: 429.34
               Mean episode length: 206.82
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 83.0763
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.66s
                      Time elapsed: 00:49:40
                               ETA: 00:14:56

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 31737 steps/s (collection: 2.777s, learning 0.320s)
             Mean action noise std: 4.35
          Mean value_function loss: 133.0686
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 88.4990
                       Mean reward: 455.23
               Mean episode length: 216.30
    Episode_Reward/reaching_object: 1.2245
    Episode_Reward/rotating_object: 83.2831
        Episode_Reward/action_rate: -0.1209
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 3.10s
                      Time elapsed: 00:49:43
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 34308 steps/s (collection: 2.622s, learning 0.243s)
             Mean action noise std: 4.35
          Mean value_function loss: 136.1391
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 88.5224
                       Mean reward: 423.83
               Mean episode length: 207.76
    Episode_Reward/reaching_object: 1.1888
    Episode_Reward/rotating_object: 81.8227
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.87s
                      Time elapsed: 00:49:46
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 32921 steps/s (collection: 2.799s, learning 0.187s)
             Mean action noise std: 4.35
          Mean value_function loss: 128.0915
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 88.5437
                       Mean reward: 439.72
               Mean episode length: 211.17
    Episode_Reward/reaching_object: 1.2409
    Episode_Reward/rotating_object: 85.2610
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.99s
                      Time elapsed: 00:49:49
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 34410 steps/s (collection: 2.611s, learning 0.246s)
             Mean action noise std: 4.36
          Mean value_function loss: 128.6465
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 88.5615
                       Mean reward: 427.88
               Mean episode length: 212.18
    Episode_Reward/reaching_object: 1.2070
    Episode_Reward/rotating_object: 81.5838
        Episode_Reward/action_rate: -0.1198
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.86s
                      Time elapsed: 00:49:52
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 31446 steps/s (collection: 2.872s, learning 0.254s)
             Mean action noise std: 4.36
          Mean value_function loss: 131.6230
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 88.5750
                       Mean reward: 441.30
               Mean episode length: 209.32
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 86.0834
        Episode_Reward/action_rate: -0.1201
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 3.13s
                      Time elapsed: 00:49:55
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 32667 steps/s (collection: 2.725s, learning 0.284s)
             Mean action noise std: 4.36
          Mean value_function loss: 137.6703
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 88.5889
                       Mean reward: 404.52
               Mean episode length: 198.61
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 76.1334
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 3.01s
                      Time elapsed: 00:49:58
                               ETA: 00:14:41

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 33472 steps/s (collection: 2.684s, learning 0.253s)
             Mean action noise std: 4.37
          Mean value_function loss: 139.3423
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 88.6110
                       Mean reward: 459.55
               Mean episode length: 212.43
    Episode_Reward/reaching_object: 1.2130
    Episode_Reward/rotating_object: 84.9986
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.94s
                      Time elapsed: 00:50:01
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 33137 steps/s (collection: 2.686s, learning 0.281s)
             Mean action noise std: 4.37
          Mean value_function loss: 127.5643
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 88.6218
                       Mean reward: 421.18
               Mean episode length: 207.09
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 83.0851
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.97s
                      Time elapsed: 00:50:04
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 36432 steps/s (collection: 2.436s, learning 0.263s)
             Mean action noise std: 4.37
          Mean value_function loss: 137.0101
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 88.6312
                       Mean reward: 415.57
               Mean episode length: 202.51
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 79.0657
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.70s
                      Time elapsed: 00:50:07
                               ETA: 00:14:34

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 32830 steps/s (collection: 2.721s, learning 0.274s)
             Mean action noise std: 4.37
          Mean value_function loss: 132.6994
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 88.6467
                       Mean reward: 393.30
               Mean episode length: 198.27
    Episode_Reward/reaching_object: 1.2319
    Episode_Reward/rotating_object: 87.0083
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.99s
                      Time elapsed: 00:50:10
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 34567 steps/s (collection: 2.563s, learning 0.281s)
             Mean action noise std: 4.38
          Mean value_function loss: 128.4885
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 88.6751
                       Mean reward: 473.56
               Mean episode length: 218.46
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 84.4057
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.84s
                      Time elapsed: 00:50:13
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 25924 steps/s (collection: 3.518s, learning 0.273s)
             Mean action noise std: 4.38
          Mean value_function loss: 122.4715
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 88.7023
                       Mean reward: 439.82
               Mean episode length: 207.22
    Episode_Reward/reaching_object: 1.2458
    Episode_Reward/rotating_object: 89.6614
        Episode_Reward/action_rate: -0.1250
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 3.79s
                      Time elapsed: 00:50:17
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 29013 steps/s (collection: 3.066s, learning 0.322s)
             Mean action noise std: 4.38
          Mean value_function loss: 117.1402
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 88.7118
                       Mean reward: 480.45
               Mean episode length: 214.22
    Episode_Reward/reaching_object: 1.1867
    Episode_Reward/rotating_object: 84.6338
        Episode_Reward/action_rate: -0.1199
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 3.39s
                      Time elapsed: 00:50:20
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 31108 steps/s (collection: 2.889s, learning 0.271s)
             Mean action noise std: 4.38
          Mean value_function loss: 126.5248
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 88.7224
                       Mean reward: 430.77
               Mean episode length: 206.49
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 84.2076
        Episode_Reward/action_rate: -0.1224
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 3.16s
                      Time elapsed: 00:50:23
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 29319 steps/s (collection: 3.067s, learning 0.286s)
             Mean action noise std: 4.39
          Mean value_function loss: 119.6515
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 88.7300
                       Mean reward: 387.91
               Mean episode length: 204.22
    Episode_Reward/reaching_object: 1.2466
    Episode_Reward/rotating_object: 87.9354
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 3.35s
                      Time elapsed: 00:50:26
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 37858 steps/s (collection: 2.432s, learning 0.165s)
             Mean action noise std: 4.39
          Mean value_function loss: 125.8631
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 88.7473
                       Mean reward: 449.83
               Mean episode length: 208.80
    Episode_Reward/reaching_object: 1.2017
    Episode_Reward/rotating_object: 85.1948
        Episode_Reward/action_rate: -0.1235
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.60s
                      Time elapsed: 00:50:29
                               ETA: 00:14:17

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 37229 steps/s (collection: 2.404s, learning 0.237s)
             Mean action noise std: 4.39
          Mean value_function loss: 119.4824
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.7650
                       Mean reward: 442.28
               Mean episode length: 217.20
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 84.2754
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.64s
                      Time elapsed: 00:50:32
                               ETA: 00:14:14

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 35896 steps/s (collection: 2.500s, learning 0.238s)
             Mean action noise std: 4.39
          Mean value_function loss: 124.5278
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 88.7795
                       Mean reward: 370.87
               Mean episode length: 187.09
    Episode_Reward/reaching_object: 1.1956
    Episode_Reward/rotating_object: 80.4657
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.74s
                      Time elapsed: 00:50:34
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 34159 steps/s (collection: 2.697s, learning 0.181s)
             Mean action noise std: 4.40
          Mean value_function loss: 127.3194
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 88.7983
                       Mean reward: 414.62
               Mean episode length: 201.86
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 87.4580
        Episode_Reward/action_rate: -0.1236
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.88s
                      Time elapsed: 00:50:37
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 35487 steps/s (collection: 2.600s, learning 0.170s)
             Mean action noise std: 4.40
          Mean value_function loss: 131.0207
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 88.8159
                       Mean reward: 440.59
               Mean episode length: 204.36
    Episode_Reward/reaching_object: 1.2065
    Episode_Reward/rotating_object: 85.4962
        Episode_Reward/action_rate: -0.1224
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.77s
                      Time elapsed: 00:50:40
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 36442 steps/s (collection: 2.512s, learning 0.186s)
             Mean action noise std: 4.41
          Mean value_function loss: 126.3069
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 88.8369
                       Mean reward: 468.03
               Mean episode length: 219.39
    Episode_Reward/reaching_object: 1.1857
    Episode_Reward/rotating_object: 85.3801
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.70s
                      Time elapsed: 00:50:43
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 32142 steps/s (collection: 2.846s, learning 0.213s)
             Mean action noise std: 4.41
          Mean value_function loss: 124.6149
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 88.8595
                       Mean reward: 382.39
               Mean episode length: 194.33
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 82.1579
        Episode_Reward/action_rate: -0.1212
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 3.06s
                      Time elapsed: 00:50:46
                               ETA: 00:14:01

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 32300 steps/s (collection: 2.826s, learning 0.218s)
             Mean action noise std: 4.41
          Mean value_function loss: 127.5735
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 88.8703
                       Mean reward: 471.10
               Mean episode length: 215.80
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 84.9936
        Episode_Reward/action_rate: -0.1239
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 3.04s
                      Time elapsed: 00:50:49
                               ETA: 00:13:59

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 31622 steps/s (collection: 2.884s, learning 0.225s)
             Mean action noise std: 4.41
          Mean value_function loss: 129.6449
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 88.8777
                       Mean reward: 485.93
               Mean episode length: 219.54
    Episode_Reward/reaching_object: 1.2561
    Episode_Reward/rotating_object: 91.5851
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 3.11s
                      Time elapsed: 00:50:52
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 32393 steps/s (collection: 2.783s, learning 0.252s)
             Mean action noise std: 4.42
          Mean value_function loss: 132.4381
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 88.8954
                       Mean reward: 389.48
               Mean episode length: 200.47
    Episode_Reward/reaching_object: 1.1841
    Episode_Reward/rotating_object: 83.1732
        Episode_Reward/action_rate: -0.1222
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 3.03s
                      Time elapsed: 00:50:55
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 27656 steps/s (collection: 3.297s, learning 0.258s)
             Mean action noise std: 4.42
          Mean value_function loss: 128.1103
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 88.9193
                       Mean reward: 449.37
               Mean episode length: 210.34
    Episode_Reward/reaching_object: 1.2090
    Episode_Reward/rotating_object: 87.9350
        Episode_Reward/action_rate: -0.1235
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 3.55s
                      Time elapsed: 00:50:59
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 31800 steps/s (collection: 2.761s, learning 0.330s)
             Mean action noise std: 4.42
          Mean value_function loss: 126.7116
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.9339
                       Mean reward: 424.58
               Mean episode length: 207.56
    Episode_Reward/reaching_object: 1.2581
    Episode_Reward/rotating_object: 86.4489
        Episode_Reward/action_rate: -0.1288
          Episode_Reward/joint_vel: -0.0710
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 3.09s
                      Time elapsed: 00:51:02
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 27441 steps/s (collection: 3.244s, learning 0.339s)
             Mean action noise std: 4.42
          Mean value_function loss: 124.6142
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 88.9379
                       Mean reward: 448.33
               Mean episode length: 209.34
    Episode_Reward/reaching_object: 1.2307
    Episode_Reward/rotating_object: 87.3907
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 3.58s
                      Time elapsed: 00:51:05
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 25587 steps/s (collection: 3.638s, learning 0.204s)
             Mean action noise std: 4.42
          Mean value_function loss: 115.8065
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 88.9423
                       Mean reward: 434.05
               Mean episode length: 207.22
    Episode_Reward/reaching_object: 1.2564
    Episode_Reward/rotating_object: 88.9521
        Episode_Reward/action_rate: -0.1284
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 3.84s
                      Time elapsed: 00:51:09
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 23520 steps/s (collection: 3.853s, learning 0.327s)
             Mean action noise std: 4.43
          Mean value_function loss: 127.7858
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 88.9563
                       Mean reward: 417.77
               Mean episode length: 208.29
    Episode_Reward/reaching_object: 1.2295
    Episode_Reward/rotating_object: 86.8956
        Episode_Reward/action_rate: -0.1273
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 4.18s
                      Time elapsed: 00:51:13
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 23563 steps/s (collection: 3.969s, learning 0.203s)
             Mean action noise std: 4.43
          Mean value_function loss: 127.0839
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 88.9790
                       Mean reward: 471.81
               Mean episode length: 210.73
    Episode_Reward/reaching_object: 1.2241
    Episode_Reward/rotating_object: 89.6371
        Episode_Reward/action_rate: -0.1257
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 4.17s
                      Time elapsed: 00:51:17
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 42095 steps/s (collection: 2.209s, learning 0.127s)
             Mean action noise std: 4.43
          Mean value_function loss: 126.2244
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 89.0073
                       Mean reward: 433.06
               Mean episode length: 209.24
    Episode_Reward/reaching_object: 1.2603
    Episode_Reward/rotating_object: 92.1865
        Episode_Reward/action_rate: -0.1300
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.34s
                      Time elapsed: 00:51:20
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 41906 steps/s (collection: 2.209s, learning 0.137s)
             Mean action noise std: 4.44
          Mean value_function loss: 125.3046
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 89.0300
                       Mean reward: 400.24
               Mean episode length: 198.04
    Episode_Reward/reaching_object: 1.2555
    Episode_Reward/rotating_object: 90.1790
        Episode_Reward/action_rate: -0.1290
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.35s
                      Time elapsed: 00:51:22
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 44754 steps/s (collection: 2.088s, learning 0.108s)
             Mean action noise std: 4.44
          Mean value_function loss: 133.2339
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 89.0469
                       Mean reward: 486.47
               Mean episode length: 213.84
    Episode_Reward/reaching_object: 1.2499
    Episode_Reward/rotating_object: 90.2192
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.20s
                      Time elapsed: 00:51:24
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 40372 steps/s (collection: 2.301s, learning 0.134s)
             Mean action noise std: 4.44
          Mean value_function loss: 129.6783
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 89.0623
                       Mean reward: 447.69
               Mean episode length: 215.82
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 90.9360
        Episode_Reward/action_rate: -0.1270
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.43s
                      Time elapsed: 00:51:27
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 33196 steps/s (collection: 2.602s, learning 0.360s)
             Mean action noise std: 4.44
          Mean value_function loss: 127.5951
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 89.0734
                       Mean reward: 419.39
               Mean episode length: 201.77
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 88.5295
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.96s
                      Time elapsed: 00:51:30
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 29784 steps/s (collection: 3.110s, learning 0.191s)
             Mean action noise std: 4.45
          Mean value_function loss: 130.4205
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 89.0954
                       Mean reward: 440.10
               Mean episode length: 204.59
    Episode_Reward/reaching_object: 1.2042
    Episode_Reward/rotating_object: 86.5049
        Episode_Reward/action_rate: -0.1270
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 3.30s
                      Time elapsed: 00:51:33
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 32440 steps/s (collection: 2.750s, learning 0.281s)
             Mean action noise std: 4.45
          Mean value_function loss: 124.0761
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 89.1205
                       Mean reward: 439.59
               Mean episode length: 213.59
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 88.9314
        Episode_Reward/action_rate: -0.1280
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 3.03s
                      Time elapsed: 00:51:36
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 35138 steps/s (collection: 2.622s, learning 0.176s)
             Mean action noise std: 4.46
          Mean value_function loss: 126.9276
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 89.1402
                       Mean reward: 476.33
               Mean episode length: 214.72
    Episode_Reward/reaching_object: 1.2356
    Episode_Reward/rotating_object: 91.8872
        Episode_Reward/action_rate: -0.1282
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.80s
                      Time elapsed: 00:51:39
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 32346 steps/s (collection: 2.845s, learning 0.195s)
             Mean action noise std: 4.46
          Mean value_function loss: 135.8079
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 89.1608
                       Mean reward: 478.92
               Mean episode length: 211.18
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 90.7087
        Episode_Reward/action_rate: -0.1275
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 3.04s
                      Time elapsed: 00:51:42
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 30320 steps/s (collection: 3.073s, learning 0.170s)
             Mean action noise std: 4.46
          Mean value_function loss: 118.8935
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 89.1745
                       Mean reward: 460.87
               Mean episode length: 218.78
    Episode_Reward/reaching_object: 1.2432
    Episode_Reward/rotating_object: 90.0136
        Episode_Reward/action_rate: -0.1294
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 3.24s
                      Time elapsed: 00:51:45
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 29475 steps/s (collection: 3.132s, learning 0.204s)
             Mean action noise std: 4.46
          Mean value_function loss: 122.4490
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 89.1853
                       Mean reward: 405.33
               Mean episode length: 200.22
    Episode_Reward/reaching_object: 1.2235
    Episode_Reward/rotating_object: 89.6027
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 3.34s
                      Time elapsed: 00:51:48
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 29107 steps/s (collection: 3.206s, learning 0.172s)
             Mean action noise std: 4.46
          Mean value_function loss: 129.3099
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 89.1930
                       Mean reward: 493.47
               Mean episode length: 217.20
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 89.3101
        Episode_Reward/action_rate: -0.1279
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 3.38s
                      Time elapsed: 00:51:52
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 31196 steps/s (collection: 2.925s, learning 0.226s)
             Mean action noise std: 4.47
          Mean value_function loss: 128.5309
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 89.2101
                       Mean reward: 503.99
               Mean episode length: 214.87
    Episode_Reward/reaching_object: 1.2214
    Episode_Reward/rotating_object: 86.5436
        Episode_Reward/action_rate: -0.1275
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 3.15s
                      Time elapsed: 00:51:55
                               ETA: 00:13:07

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 32408 steps/s (collection: 2.866s, learning 0.168s)
             Mean action noise std: 4.47
          Mean value_function loss: 120.4618
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 89.2364
                       Mean reward: 454.01
               Mean episode length: 206.22
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 85.0495
        Episode_Reward/action_rate: -0.1278
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 3.03s
                      Time elapsed: 00:51:58
                               ETA: 00:13:05

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 34886 steps/s (collection: 2.624s, learning 0.194s)
             Mean action noise std: 4.47
          Mean value_function loss: 126.6973
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.2569
                       Mean reward: 486.74
               Mean episode length: 213.73
    Episode_Reward/reaching_object: 1.2202
    Episode_Reward/rotating_object: 90.2099
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.82s
                      Time elapsed: 00:52:01
                               ETA: 00:13:02

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 35760 steps/s (collection: 2.552s, learning 0.197s)
             Mean action noise std: 4.48
          Mean value_function loss: 133.2348
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 89.2769
                       Mean reward: 460.31
               Mean episode length: 214.44
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 93.0939
        Episode_Reward/action_rate: -0.1307
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.75s
                      Time elapsed: 00:52:04
                               ETA: 00:13:00

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 35291 steps/s (collection: 2.573s, learning 0.212s)
             Mean action noise std: 4.48
          Mean value_function loss: 126.3401
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.2956
                       Mean reward: 436.29
               Mean episode length: 214.60
    Episode_Reward/reaching_object: 1.2374
    Episode_Reward/rotating_object: 90.2049
        Episode_Reward/action_rate: -0.1298
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.79s
                      Time elapsed: 00:52:06
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 34339 steps/s (collection: 2.689s, learning 0.174s)
             Mean action noise std: 4.48
          Mean value_function loss: 128.3848
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 89.3043
                       Mean reward: 474.41
               Mean episode length: 210.42
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 85.8382
        Episode_Reward/action_rate: -0.1257
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.86s
                      Time elapsed: 00:52:09
                               ETA: 00:12:55

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 33818 steps/s (collection: 2.703s, learning 0.204s)
             Mean action noise std: 4.48
          Mean value_function loss: 124.2721
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 89.3201
                       Mean reward: 453.09
               Mean episode length: 210.86
    Episode_Reward/reaching_object: 1.2453
    Episode_Reward/rotating_object: 89.0921
        Episode_Reward/action_rate: -0.1320
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.91s
                      Time elapsed: 00:52:12
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 33712 steps/s (collection: 2.712s, learning 0.204s)
             Mean action noise std: 4.49
          Mean value_function loss: 125.7789
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 89.3311
                       Mean reward: 474.28
               Mean episode length: 217.30
    Episode_Reward/reaching_object: 1.2497
    Episode_Reward/rotating_object: 91.7510
        Episode_Reward/action_rate: -0.1315
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.92s
                      Time elapsed: 00:52:15
                               ETA: 00:12:50

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 32761 steps/s (collection: 2.796s, learning 0.205s)
             Mean action noise std: 4.49
          Mean value_function loss: 126.8626
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 89.3396
                       Mean reward: 495.36
               Mean episode length: 217.85
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 91.8244
        Episode_Reward/action_rate: -0.1303
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 3.00s
                      Time elapsed: 00:52:18
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 38068 steps/s (collection: 2.371s, learning 0.211s)
             Mean action noise std: 4.49
          Mean value_function loss: 132.1407
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 89.3549
                       Mean reward: 455.48
               Mean episode length: 203.27
    Episode_Reward/reaching_object: 1.2687
    Episode_Reward/rotating_object: 93.5378
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.58s
                      Time elapsed: 00:52:21
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 36523 steps/s (collection: 2.405s, learning 0.287s)
             Mean action noise std: 4.50
          Mean value_function loss: 123.1829
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 89.3794
                       Mean reward: 466.17
               Mean episode length: 220.14
    Episode_Reward/reaching_object: 1.2652
    Episode_Reward/rotating_object: 92.3450
        Episode_Reward/action_rate: -0.1333
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.69s
                      Time elapsed: 00:52:23
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 37696 steps/s (collection: 2.317s, learning 0.290s)
             Mean action noise std: 4.50
          Mean value_function loss: 128.1103
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 89.3967
                       Mean reward: 485.75
               Mean episode length: 215.21
    Episode_Reward/reaching_object: 1.2737
    Episode_Reward/rotating_object: 97.9722
        Episode_Reward/action_rate: -0.1340
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.61s
                      Time elapsed: 00:52:26
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 38786 steps/s (collection: 2.362s, learning 0.172s)
             Mean action noise std: 4.50
          Mean value_function loss: 128.2794
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 89.4083
                       Mean reward: 491.05
               Mean episode length: 216.83
    Episode_Reward/reaching_object: 1.2812
    Episode_Reward/rotating_object: 92.0076
        Episode_Reward/action_rate: -0.1358
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.53s
                      Time elapsed: 00:52:28
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 40953 steps/s (collection: 2.205s, learning 0.195s)
             Mean action noise std: 4.50
          Mean value_function loss: 122.1183
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 89.4275
                       Mean reward: 475.23
               Mean episode length: 211.62
    Episode_Reward/reaching_object: 1.2643
    Episode_Reward/rotating_object: 96.9457
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0635
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.40s
                      Time elapsed: 00:52:31
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 39276 steps/s (collection: 2.322s, learning 0.181s)
             Mean action noise std: 4.51
          Mean value_function loss: 135.7949
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 89.4502
                       Mean reward: 401.66
               Mean episode length: 210.22
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 86.6405
        Episode_Reward/action_rate: -0.1289
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.50s
                      Time elapsed: 00:52:33
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 36708 steps/s (collection: 2.487s, learning 0.191s)
             Mean action noise std: 4.51
          Mean value_function loss: 132.0153
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 89.4777
                       Mean reward: 480.06
               Mean episode length: 223.80
    Episode_Reward/reaching_object: 1.2332
    Episode_Reward/rotating_object: 92.3750
        Episode_Reward/action_rate: -0.1315
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.68s
                      Time elapsed: 00:52:36
                               ETA: 00:12:29

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 38541 steps/s (collection: 2.352s, learning 0.199s)
             Mean action noise std: 4.52
          Mean value_function loss: 129.5993
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 89.5079
                       Mean reward: 489.07
               Mean episode length: 219.94
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 92.2398
        Episode_Reward/action_rate: -0.1331
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.55s
                      Time elapsed: 00:52:39
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 38151 steps/s (collection: 2.355s, learning 0.222s)
             Mean action noise std: 4.52
          Mean value_function loss: 125.3677
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 89.5208
                       Mean reward: 486.71
               Mean episode length: 215.49
    Episode_Reward/reaching_object: 1.2232
    Episode_Reward/rotating_object: 92.1993
        Episode_Reward/action_rate: -0.1317
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.58s
                      Time elapsed: 00:52:41
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 37754 steps/s (collection: 2.386s, learning 0.218s)
             Mean action noise std: 4.52
          Mean value_function loss: 123.5730
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 89.5363
                       Mean reward: 511.15
               Mean episode length: 220.09
    Episode_Reward/reaching_object: 1.2472
    Episode_Reward/rotating_object: 93.0900
        Episode_Reward/action_rate: -0.1347
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.60s
                      Time elapsed: 00:52:44
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 36198 steps/s (collection: 2.521s, learning 0.195s)
             Mean action noise std: 4.53
          Mean value_function loss: 128.2153
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 89.5611
                       Mean reward: 458.00
               Mean episode length: 216.00
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 89.4781
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.72s
                      Time elapsed: 00:52:46
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 36458 steps/s (collection: 2.492s, learning 0.205s)
             Mean action noise std: 4.53
          Mean value_function loss: 132.0628
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 89.5776
                       Mean reward: 484.49
               Mean episode length: 213.50
    Episode_Reward/reaching_object: 1.1975
    Episode_Reward/rotating_object: 88.5438
        Episode_Reward/action_rate: -0.1305
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.70s
                      Time elapsed: 00:52:49
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 38647 steps/s (collection: 2.315s, learning 0.228s)
             Mean action noise std: 4.53
          Mean value_function loss: 130.8252
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 89.5845
                       Mean reward: 504.96
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 95.0788
        Episode_Reward/action_rate: -0.1368
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.54s
                      Time elapsed: 00:52:52
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 37492 steps/s (collection: 2.440s, learning 0.182s)
             Mean action noise std: 4.53
          Mean value_function loss: 136.7821
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 89.6015
                       Mean reward: 458.79
               Mean episode length: 218.15
    Episode_Reward/reaching_object: 1.2542
    Episode_Reward/rotating_object: 96.3356
        Episode_Reward/action_rate: -0.1365
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.62s
                      Time elapsed: 00:52:54
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 36275 steps/s (collection: 2.450s, learning 0.260s)
             Mean action noise std: 4.54
          Mean value_function loss: 132.1454
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 89.6239
                       Mean reward: 460.19
               Mean episode length: 209.69
    Episode_Reward/reaching_object: 1.1987
    Episode_Reward/rotating_object: 90.8560
        Episode_Reward/action_rate: -0.1323
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.71s
                      Time elapsed: 00:52:57
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 33588 steps/s (collection: 2.696s, learning 0.230s)
             Mean action noise std: 4.54
          Mean value_function loss: 136.7828
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 89.6413
                       Mean reward: 442.23
               Mean episode length: 206.13
    Episode_Reward/reaching_object: 1.2483
    Episode_Reward/rotating_object: 94.8635
        Episode_Reward/action_rate: -0.1379
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.93s
                      Time elapsed: 00:53:00
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 29787 steps/s (collection: 3.083s, learning 0.218s)
             Mean action noise std: 4.54
          Mean value_function loss: 125.3332
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 89.6628
                       Mean reward: 526.71
               Mean episode length: 225.06
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 93.1048
        Episode_Reward/action_rate: -0.1326
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 3.30s
                      Time elapsed: 00:53:03
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 29061 steps/s (collection: 3.122s, learning 0.260s)
             Mean action noise std: 4.55
          Mean value_function loss: 127.9314
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 89.6904
                       Mean reward: 500.52
               Mean episode length: 218.61
    Episode_Reward/reaching_object: 1.2890
    Episode_Reward/rotating_object: 98.7659
        Episode_Reward/action_rate: -0.1415
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 3.38s
                      Time elapsed: 00:53:07
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 33988 steps/s (collection: 2.679s, learning 0.214s)
             Mean action noise std: 4.55
          Mean value_function loss: 124.8853
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 89.7124
                       Mean reward: 471.91
               Mean episode length: 217.60
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 94.2849
        Episode_Reward/action_rate: -0.1371
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.89s
                      Time elapsed: 00:53:10
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 34881 steps/s (collection: 2.659s, learning 0.160s)
             Mean action noise std: 4.55
          Mean value_function loss: 133.9349
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 89.7224
                       Mean reward: 450.72
               Mean episode length: 210.73
    Episode_Reward/reaching_object: 1.2456
    Episode_Reward/rotating_object: 95.5862
        Episode_Reward/action_rate: -0.1373
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.82s
                      Time elapsed: 00:53:12
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 34920 steps/s (collection: 2.638s, learning 0.178s)
             Mean action noise std: 4.56
          Mean value_function loss: 119.3025
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 89.7338
                       Mean reward: 520.70
               Mean episode length: 221.68
    Episode_Reward/reaching_object: 1.2485
    Episode_Reward/rotating_object: 95.6724
        Episode_Reward/action_rate: -0.1382
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.82s
                      Time elapsed: 00:53:15
                               ETA: 00:11:53

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 35589 steps/s (collection: 2.558s, learning 0.205s)
             Mean action noise std: 4.56
          Mean value_function loss: 128.8159
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 89.7534
                       Mean reward: 514.29
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 1.2946
    Episode_Reward/rotating_object: 98.3193
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0689
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.76s
                      Time elapsed: 00:53:18
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 34616 steps/s (collection: 2.641s, learning 0.199s)
             Mean action noise std: 4.56
          Mean value_function loss: 139.4348
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 89.7779
                       Mean reward: 411.28
               Mean episode length: 209.33
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 88.9222
        Episode_Reward/action_rate: -0.1348
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.84s
                      Time elapsed: 00:53:21
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 35812 steps/s (collection: 2.584s, learning 0.161s)
             Mean action noise std: 4.57
          Mean value_function loss: 123.9773
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 89.7965
                       Mean reward: 414.43
               Mean episode length: 191.46
    Episode_Reward/reaching_object: 1.1728
    Episode_Reward/rotating_object: 89.8925
        Episode_Reward/action_rate: -0.1322
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.74s
                      Time elapsed: 00:53:24
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 36493 steps/s (collection: 2.497s, learning 0.197s)
             Mean action noise std: 4.57
          Mean value_function loss: 131.6837
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 89.8133
                       Mean reward: 476.97
               Mean episode length: 219.53
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 91.0017
        Episode_Reward/action_rate: -0.1373
          Episode_Reward/joint_vel: -0.0690
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.69s
                      Time elapsed: 00:53:26
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 33680 steps/s (collection: 2.634s, learning 0.285s)
             Mean action noise std: 4.57
          Mean value_function loss: 126.4150
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 89.8333
                       Mean reward: 440.85
               Mean episode length: 216.78
    Episode_Reward/reaching_object: 1.2737
    Episode_Reward/rotating_object: 91.9042
        Episode_Reward/action_rate: -0.1415
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.92s
                      Time elapsed: 00:53:29
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 32125 steps/s (collection: 2.873s, learning 0.187s)
             Mean action noise std: 4.58
          Mean value_function loss: 119.6129
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 89.8499
                       Mean reward: 440.35
               Mean episode length: 206.37
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 88.2510
        Episode_Reward/action_rate: -0.1340
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 3.06s
                      Time elapsed: 00:53:32
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 35458 steps/s (collection: 2.566s, learning 0.207s)
             Mean action noise std: 4.58
          Mean value_function loss: 125.4914
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 89.8618
                       Mean reward: 522.82
               Mean episode length: 221.27
    Episode_Reward/reaching_object: 1.2466
    Episode_Reward/rotating_object: 96.7439
        Episode_Reward/action_rate: -0.1386
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.77s
                      Time elapsed: 00:53:35
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 31743 steps/s (collection: 2.848s, learning 0.249s)
             Mean action noise std: 4.58
          Mean value_function loss: 116.9201
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 89.8761
                       Mean reward: 455.07
               Mean episode length: 212.62
    Episode_Reward/reaching_object: 1.2520
    Episode_Reward/rotating_object: 95.4245
        Episode_Reward/action_rate: -0.1394
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 3.10s
                      Time elapsed: 00:53:38
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 27753 steps/s (collection: 3.297s, learning 0.245s)
             Mean action noise std: 4.58
          Mean value_function loss: 129.3646
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 89.8917
                       Mean reward: 465.92
               Mean episode length: 214.95
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 90.2623
        Episode_Reward/action_rate: -0.1373
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 3.54s
                      Time elapsed: 00:53:42
                               ETA: 00:11:30

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 27092 steps/s (collection: 3.377s, learning 0.252s)
             Mean action noise std: 4.58
          Mean value_function loss: 131.8175
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 89.9018
                       Mean reward: 440.40
               Mean episode length: 202.54
    Episode_Reward/reaching_object: 1.2137
    Episode_Reward/rotating_object: 89.5607
        Episode_Reward/action_rate: -0.1357
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 3.63s
                      Time elapsed: 00:53:45
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 26930 steps/s (collection: 3.402s, learning 0.248s)
             Mean action noise std: 4.59
          Mean value_function loss: 117.0179
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 89.9175
                       Mean reward: 476.34
               Mean episode length: 214.77
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 93.8729
        Episode_Reward/action_rate: -0.1379
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 3.65s
                      Time elapsed: 00:53:49
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 27540 steps/s (collection: 3.336s, learning 0.233s)
             Mean action noise std: 4.59
          Mean value_function loss: 124.2664
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 89.9420
                       Mean reward: 498.98
               Mean episode length: 220.89
    Episode_Reward/reaching_object: 1.2716
    Episode_Reward/rotating_object: 96.9881
        Episode_Reward/action_rate: -0.1404
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 3.57s
                      Time elapsed: 00:53:52
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 26527 steps/s (collection: 3.469s, learning 0.237s)
             Mean action noise std: 4.59
          Mean value_function loss: 129.1547
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 89.9643
                       Mean reward: 492.99
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 1.2596
    Episode_Reward/rotating_object: 95.2561
        Episode_Reward/action_rate: -0.1397
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 3.71s
                      Time elapsed: 00:53:56
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 26113 steps/s (collection: 3.450s, learning 0.315s)
             Mean action noise std: 4.60
          Mean value_function loss: 118.3801
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 89.9737
                       Mean reward: 489.66
               Mean episode length: 218.06
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 96.1360
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 3.76s
                      Time elapsed: 00:54:00
                               ETA: 00:11:18

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 25114 steps/s (collection: 3.587s, learning 0.327s)
             Mean action noise std: 4.60
          Mean value_function loss: 110.4402
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 89.9819
                       Mean reward: 425.65
               Mean episode length: 206.21
    Episode_Reward/reaching_object: 1.2357
    Episode_Reward/rotating_object: 92.3040
        Episode_Reward/action_rate: -0.1384
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 3.91s
                      Time elapsed: 00:54:04
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 21433 steps/s (collection: 4.156s, learning 0.430s)
             Mean action noise std: 4.60
          Mean value_function loss: 119.2113
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 89.9970
                       Mean reward: 509.90
               Mean episode length: 218.19
    Episode_Reward/reaching_object: 1.2536
    Episode_Reward/rotating_object: 95.0422
        Episode_Reward/action_rate: -0.1403
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 4.59s
                      Time elapsed: 00:54:08
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 22199 steps/s (collection: 4.139s, learning 0.289s)
             Mean action noise std: 4.60
          Mean value_function loss: 128.2779
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 90.0125
                       Mean reward: 479.58
               Mean episode length: 204.08
    Episode_Reward/reaching_object: 1.2376
    Episode_Reward/rotating_object: 94.5049
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 4.43s
                      Time elapsed: 00:54:13
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 25322 steps/s (collection: 3.630s, learning 0.253s)
             Mean action noise std: 4.61
          Mean value_function loss: 113.3915
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 90.0303
                       Mean reward: 485.71
               Mean episode length: 223.14
    Episode_Reward/reaching_object: 1.2549
    Episode_Reward/rotating_object: 94.4407
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 3.88s
                      Time elapsed: 00:54:17
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 25586 steps/s (collection: 3.599s, learning 0.243s)
             Mean action noise std: 4.61
          Mean value_function loss: 126.5593
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 90.0452
                       Mean reward: 489.49
               Mean episode length: 213.77
    Episode_Reward/reaching_object: 1.2177
    Episode_Reward/rotating_object: 92.5554
        Episode_Reward/action_rate: -0.1377
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 3.84s
                      Time elapsed: 00:54:21
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 23063 steps/s (collection: 4.004s, learning 0.258s)
             Mean action noise std: 4.61
          Mean value_function loss: 122.0189
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 90.0648
                       Mean reward: 473.16
               Mean episode length: 211.00
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 97.1671
        Episode_Reward/action_rate: -0.1394
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 4.26s
                      Time elapsed: 00:54:25
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 23991 steps/s (collection: 3.851s, learning 0.246s)
             Mean action noise std: 4.62
          Mean value_function loss: 125.9343
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 90.0873
                       Mean reward: 488.88
               Mean episode length: 211.81
    Episode_Reward/reaching_object: 1.2309
    Episode_Reward/rotating_object: 97.2197
        Episode_Reward/action_rate: -0.1390
          Episode_Reward/joint_vel: -0.0633
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 4.10s
                      Time elapsed: 00:54:29
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 22915 steps/s (collection: 3.860s, learning 0.430s)
             Mean action noise std: 4.62
          Mean value_function loss: 112.0693
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 90.1027
                       Mean reward: 476.16
               Mean episode length: 212.61
    Episode_Reward/reaching_object: 1.2911
    Episode_Reward/rotating_object: 98.8195
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 4.29s
                      Time elapsed: 00:54:33
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 22328 steps/s (collection: 4.125s, learning 0.277s)
             Mean action noise std: 4.62
          Mean value_function loss: 120.7916
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 90.1190
                       Mean reward: 472.19
               Mean episode length: 206.79
    Episode_Reward/reaching_object: 1.2436
    Episode_Reward/rotating_object: 95.7713
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 4.40s
                      Time elapsed: 00:54:38
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 22999 steps/s (collection: 4.048s, learning 0.227s)
             Mean action noise std: 4.63
          Mean value_function loss: 127.6272
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 90.1407
                       Mean reward: 432.54
               Mean episode length: 204.57
    Episode_Reward/reaching_object: 1.2395
    Episode_Reward/rotating_object: 90.8350
        Episode_Reward/action_rate: -0.1396
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 4.27s
                      Time elapsed: 00:54:42
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 25205 steps/s (collection: 3.650s, learning 0.250s)
             Mean action noise std: 4.63
          Mean value_function loss: 124.8974
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 90.1644
                       Mean reward: 465.36
               Mean episode length: 211.39
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 90.3251
        Episode_Reward/action_rate: -0.1380
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 3.90s
                      Time elapsed: 00:54:46
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 26044 steps/s (collection: 3.514s, learning 0.261s)
             Mean action noise std: 4.63
          Mean value_function loss: 121.2125
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 90.1794
                       Mean reward: 486.88
               Mean episode length: 211.93
    Episode_Reward/reaching_object: 1.2278
    Episode_Reward/rotating_object: 94.9722
        Episode_Reward/action_rate: -0.1378
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 3.77s
                      Time elapsed: 00:54:50
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 24468 steps/s (collection: 3.738s, learning 0.280s)
             Mean action noise std: 4.63
          Mean value_function loss: 126.7516
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 90.1882
                       Mean reward: 519.34
               Mean episode length: 221.23
    Episode_Reward/reaching_object: 1.2475
    Episode_Reward/rotating_object: 96.8171
        Episode_Reward/action_rate: -0.1401
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 4.02s
                      Time elapsed: 00:54:54
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 22956 steps/s (collection: 4.001s, learning 0.282s)
             Mean action noise std: 4.64
          Mean value_function loss: 113.9348
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.1997
                       Mean reward: 516.77
               Mean episode length: 227.47
    Episode_Reward/reaching_object: 1.2623
    Episode_Reward/rotating_object: 98.3858
        Episode_Reward/action_rate: -0.1421
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 4.28s
                      Time elapsed: 00:54:58
                               ETA: 00:10:46

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 23197 steps/s (collection: 3.920s, learning 0.318s)
             Mean action noise std: 4.64
          Mean value_function loss: 119.3121
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 90.2214
                       Mean reward: 477.01
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 1.2553
    Episode_Reward/rotating_object: 90.4598
        Episode_Reward/action_rate: -0.1418
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 4.24s
                      Time elapsed: 00:55:02
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 24192 steps/s (collection: 3.747s, learning 0.316s)
             Mean action noise std: 4.64
          Mean value_function loss: 129.2203
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 90.2355
                       Mean reward: 482.12
               Mean episode length: 211.36
    Episode_Reward/reaching_object: 1.1867
    Episode_Reward/rotating_object: 92.5833
        Episode_Reward/action_rate: -0.1357
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 4.06s
                      Time elapsed: 00:55:06
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 24101 steps/s (collection: 3.735s, learning 0.344s)
             Mean action noise std: 4.65
          Mean value_function loss: 122.4553
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 90.2507
                       Mean reward: 493.53
               Mean episode length: 213.76
    Episode_Reward/reaching_object: 1.2701
    Episode_Reward/rotating_object: 100.6648
        Episode_Reward/action_rate: -0.1433
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 4.08s
                      Time elapsed: 00:55:10
                               ETA: 00:10:39

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 24825 steps/s (collection: 3.665s, learning 0.295s)
             Mean action noise std: 4.65
          Mean value_function loss: 114.8981
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 90.2714
                       Mean reward: 480.85
               Mean episode length: 210.32
    Episode_Reward/reaching_object: 1.2395
    Episode_Reward/rotating_object: 96.8186
        Episode_Reward/action_rate: -0.1404
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 3.96s
                      Time elapsed: 00:55:14
                               ETA: 00:10:37

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 26178 steps/s (collection: 3.508s, learning 0.248s)
             Mean action noise std: 4.65
          Mean value_function loss: 119.1874
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 90.2901
                       Mean reward: 473.77
               Mean episode length: 206.88
    Episode_Reward/reaching_object: 1.2282
    Episode_Reward/rotating_object: 96.1252
        Episode_Reward/action_rate: -0.1399
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 3.76s
                      Time elapsed: 00:55:18
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 26226 steps/s (collection: 3.490s, learning 0.259s)
             Mean action noise std: 4.66
          Mean value_function loss: 127.2485
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 90.3125
                       Mean reward: 482.56
               Mean episode length: 206.30
    Episode_Reward/reaching_object: 1.2275
    Episode_Reward/rotating_object: 95.7738
        Episode_Reward/action_rate: -0.1401
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 3.75s
                      Time elapsed: 00:55:22
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 24968 steps/s (collection: 3.650s, learning 0.287s)
             Mean action noise std: 4.66
          Mean value_function loss: 134.9128
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 90.3288
                       Mean reward: 420.37
               Mean episode length: 198.50
    Episode_Reward/reaching_object: 1.2097
    Episode_Reward/rotating_object: 94.1476
        Episode_Reward/action_rate: -0.1372
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 3.94s
                      Time elapsed: 00:55:26
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 24900 steps/s (collection: 3.687s, learning 0.261s)
             Mean action noise std: 4.66
          Mean value_function loss: 131.0210
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 90.3469
                       Mean reward: 457.54
               Mean episode length: 202.61
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 93.8553
        Episode_Reward/action_rate: -0.1383
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 3.95s
                      Time elapsed: 00:55:30
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 24957 steps/s (collection: 3.615s, learning 0.324s)
             Mean action noise std: 4.66
          Mean value_function loss: 114.5731
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 90.3607
                       Mean reward: 529.78
               Mean episode length: 220.91
    Episode_Reward/reaching_object: 1.2514
    Episode_Reward/rotating_object: 100.5078
        Episode_Reward/action_rate: -0.1426
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 3.94s
                      Time elapsed: 00:55:34
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 24086 steps/s (collection: 3.779s, learning 0.303s)
             Mean action noise std: 4.67
          Mean value_function loss: 117.0861
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 90.3731
                       Mean reward: 438.12
               Mean episode length: 201.31
    Episode_Reward/reaching_object: 1.2338
    Episode_Reward/rotating_object: 95.3763
        Episode_Reward/action_rate: -0.1410
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 4.08s
                      Time elapsed: 00:55:38
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 25155 steps/s (collection: 3.604s, learning 0.304s)
             Mean action noise std: 4.67
          Mean value_function loss: 133.8405
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 90.3878
                       Mean reward: 493.42
               Mean episode length: 219.15
    Episode_Reward/reaching_object: 1.2490
    Episode_Reward/rotating_object: 96.6233
        Episode_Reward/action_rate: -0.1426
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 3.91s
                      Time elapsed: 00:55:42
                               ETA: 00:10:20

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 25493 steps/s (collection: 3.570s, learning 0.286s)
             Mean action noise std: 4.67
          Mean value_function loss: 128.0321
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 90.4088
                       Mean reward: 474.55
               Mean episode length: 208.77
    Episode_Reward/reaching_object: 1.2389
    Episode_Reward/rotating_object: 94.9437
        Episode_Reward/action_rate: -0.1429
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 3.86s
                      Time elapsed: 00:55:45
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 25137 steps/s (collection: 3.636s, learning 0.274s)
             Mean action noise std: 4.67
          Mean value_function loss: 119.9155
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 90.4248
                       Mean reward: 472.80
               Mean episode length: 209.00
    Episode_Reward/reaching_object: 1.2414
    Episode_Reward/rotating_object: 94.6294
        Episode_Reward/action_rate: -0.1426
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 3.91s
                      Time elapsed: 00:55:49
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 25958 steps/s (collection: 3.520s, learning 0.267s)
             Mean action noise std: 4.68
          Mean value_function loss: 122.9385
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 90.4412
                       Mean reward: 518.11
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 1.2376
    Episode_Reward/rotating_object: 99.9693
        Episode_Reward/action_rate: -0.1436
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 3.79s
                      Time elapsed: 00:55:53
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 25621 steps/s (collection: 3.573s, learning 0.264s)
             Mean action noise std: 4.68
          Mean value_function loss: 118.5867
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 90.4586
                       Mean reward: 469.26
               Mean episode length: 208.19
    Episode_Reward/reaching_object: 1.2667
    Episode_Reward/rotating_object: 99.6513
        Episode_Reward/action_rate: -0.1443
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 3.84s
                      Time elapsed: 00:55:57
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 26147 steps/s (collection: 3.554s, learning 0.205s)
             Mean action noise std: 4.68
          Mean value_function loss: 117.3168
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 90.4721
                       Mean reward: 508.20
               Mean episode length: 215.60
    Episode_Reward/reaching_object: 1.2946
    Episode_Reward/rotating_object: 101.9881
        Episode_Reward/action_rate: -0.1484
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 3.76s
                      Time elapsed: 00:56:01
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 25288 steps/s (collection: 3.637s, learning 0.250s)
             Mean action noise std: 4.69
          Mean value_function loss: 117.3271
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 90.4877
                       Mean reward: 515.16
               Mean episode length: 219.79
    Episode_Reward/reaching_object: 1.2642
    Episode_Reward/rotating_object: 100.0155
        Episode_Reward/action_rate: -0.1452
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 3.89s
                      Time elapsed: 00:56:05
                               ETA: 00:10:05

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 25443 steps/s (collection: 3.567s, learning 0.297s)
             Mean action noise std: 4.69
          Mean value_function loss: 120.6560
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 90.4998
                       Mean reward: 478.39
               Mean episode length: 216.47
    Episode_Reward/reaching_object: 1.2319
    Episode_Reward/rotating_object: 93.2199
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 3.86s
                      Time elapsed: 00:56:08
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 25601 steps/s (collection: 3.578s, learning 0.262s)
             Mean action noise std: 4.69
          Mean value_function loss: 114.4304
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 90.5151
                       Mean reward: 468.12
               Mean episode length: 202.18
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 100.4057
        Episode_Reward/action_rate: -0.1439
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 3.84s
                      Time elapsed: 00:56:12
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 24845 steps/s (collection: 3.659s, learning 0.298s)
             Mean action noise std: 4.69
          Mean value_function loss: 125.8698
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.5297
                       Mean reward: 491.34
               Mean episode length: 215.59
    Episode_Reward/reaching_object: 1.2749
    Episode_Reward/rotating_object: 96.8312
        Episode_Reward/action_rate: -0.1480
          Episode_Reward/joint_vel: -0.0689
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 3.96s
                      Time elapsed: 00:56:16
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 25462 steps/s (collection: 3.577s, learning 0.284s)
             Mean action noise std: 4.70
          Mean value_function loss: 122.5898
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 90.5482
                       Mean reward: 514.44
               Mean episode length: 219.75
    Episode_Reward/reaching_object: 1.2786
    Episode_Reward/rotating_object: 102.7744
        Episode_Reward/action_rate: -0.1475
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 3.86s
                      Time elapsed: 00:56:20
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 25859 steps/s (collection: 3.506s, learning 0.295s)
             Mean action noise std: 4.70
          Mean value_function loss: 120.9999
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 90.5692
                       Mean reward: 475.36
               Mean episode length: 203.94
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 100.7231
        Episode_Reward/action_rate: -0.1456
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 3.80s
                      Time elapsed: 00:56:24
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 26271 steps/s (collection: 3.450s, learning 0.292s)
             Mean action noise std: 4.70
          Mean value_function loss: 125.1072
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.5855
                       Mean reward: 515.50
               Mean episode length: 220.86
    Episode_Reward/reaching_object: 1.2375
    Episode_Reward/rotating_object: 98.9399
        Episode_Reward/action_rate: -0.1437
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 3.74s
                      Time elapsed: 00:56:28
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 25098 steps/s (collection: 3.653s, learning 0.264s)
             Mean action noise std: 4.71
          Mean value_function loss: 125.6317
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 90.6040
                       Mean reward: 447.72
               Mean episode length: 206.74
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 99.5944
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 3.92s
                      Time elapsed: 00:56:32
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 25869 steps/s (collection: 3.558s, learning 0.242s)
             Mean action noise std: 4.71
          Mean value_function loss: 116.8458
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 90.6291
                       Mean reward: 475.92
               Mean episode length: 213.01
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 98.2295
        Episode_Reward/action_rate: -0.1445
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 3.80s
                      Time elapsed: 00:56:35
                               ETA: 00:09:46

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 27015 steps/s (collection: 3.363s, learning 0.276s)
             Mean action noise std: 4.71
          Mean value_function loss: 108.3954
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 90.6495
                       Mean reward: 446.55
               Mean episode length: 209.17
    Episode_Reward/reaching_object: 1.2517
    Episode_Reward/rotating_object: 100.1125
        Episode_Reward/action_rate: -0.1476
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 3.64s
                      Time elapsed: 00:56:39
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 25575 steps/s (collection: 3.544s, learning 0.300s)
             Mean action noise std: 4.72
          Mean value_function loss: 118.0381
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 90.6601
                       Mean reward: 465.87
               Mean episode length: 208.16
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 98.8229
        Episode_Reward/action_rate: -0.1449
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 3.84s
                      Time elapsed: 00:56:43
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 24159 steps/s (collection: 3.842s, learning 0.227s)
             Mean action noise std: 4.72
          Mean value_function loss: 112.0080
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 90.6682
                       Mean reward: 548.92
               Mean episode length: 217.08
    Episode_Reward/reaching_object: 1.2641
    Episode_Reward/rotating_object: 104.6008
        Episode_Reward/action_rate: -0.1482
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 4.07s
                      Time elapsed: 00:56:47
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 25970 steps/s (collection: 3.552s, learning 0.233s)
             Mean action noise std: 4.72
          Mean value_function loss: 111.2455
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 90.6808
                       Mean reward: 498.74
               Mean episode length: 210.68
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 100.4974
        Episode_Reward/action_rate: -0.1468
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 3.79s
                      Time elapsed: 00:56:51
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 24296 steps/s (collection: 3.732s, learning 0.314s)
             Mean action noise std: 4.72
          Mean value_function loss: 113.1138
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 90.6964
                       Mean reward: 491.59
               Mean episode length: 209.84
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 98.9292
        Episode_Reward/action_rate: -0.1451
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 4.05s
                      Time elapsed: 00:56:55
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 24732 steps/s (collection: 3.714s, learning 0.261s)
             Mean action noise std: 4.73
          Mean value_function loss: 122.5799
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 90.7144
                       Mean reward: 513.42
               Mean episode length: 216.20
    Episode_Reward/reaching_object: 1.2763
    Episode_Reward/rotating_object: 106.6857
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 3.97s
                      Time elapsed: 00:56:59
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 23989 steps/s (collection: 3.766s, learning 0.332s)
             Mean action noise std: 4.73
          Mean value_function loss: 119.8394
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.7276
                       Mean reward: 540.61
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 1.2517
    Episode_Reward/rotating_object: 103.8192
        Episode_Reward/action_rate: -0.1477
          Episode_Reward/joint_vel: -0.0631
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 4.10s
                      Time elapsed: 00:57:03
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 24135 steps/s (collection: 3.756s, learning 0.317s)
             Mean action noise std: 4.73
          Mean value_function loss: 116.2871
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 90.7461
                       Mean reward: 479.90
               Mean episode length: 211.84
    Episode_Reward/reaching_object: 1.2409
    Episode_Reward/rotating_object: 100.3566
        Episode_Reward/action_rate: -0.1468
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 4.07s
                      Time elapsed: 00:57:07
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 20946 steps/s (collection: 4.431s, learning 0.262s)
             Mean action noise std: 4.74
          Mean value_function loss: 128.4393
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 90.7693
                       Mean reward: 501.72
               Mean episode length: 209.94
    Episode_Reward/reaching_object: 1.2370
    Episode_Reward/rotating_object: 99.4100
        Episode_Reward/action_rate: -0.1467
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 4.69s
                      Time elapsed: 00:57:12
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 23791 steps/s (collection: 3.889s, learning 0.243s)
             Mean action noise std: 4.74
          Mean value_function loss: 132.7244
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.7971
                       Mean reward: 468.58
               Mean episode length: 204.12
    Episode_Reward/reaching_object: 1.2118
    Episode_Reward/rotating_object: 96.3913
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 4.13s
                      Time elapsed: 00:57:16
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 25016 steps/s (collection: 3.671s, learning 0.258s)
             Mean action noise std: 4.74
          Mean value_function loss: 115.8100
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 90.8141
                       Mean reward: 534.40
               Mean episode length: 215.16
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 101.5216
        Episode_Reward/action_rate: -0.1454
          Episode_Reward/joint_vel: -0.0625
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 3.93s
                      Time elapsed: 00:57:20
                               ETA: 00:09:19

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 24905 steps/s (collection: 3.727s, learning 0.220s)
             Mean action noise std: 4.75
          Mean value_function loss: 117.5272
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 90.8287
                       Mean reward: 475.02
               Mean episode length: 213.63
    Episode_Reward/reaching_object: 1.2372
    Episode_Reward/rotating_object: 99.0384
        Episode_Reward/action_rate: -0.1454
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 3.95s
                      Time elapsed: 00:57:24
                               ETA: 00:09:17

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 26088 steps/s (collection: 3.461s, learning 0.307s)
             Mean action noise std: 4.75
          Mean value_function loss: 124.7794
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 90.8453
                       Mean reward: 417.28
               Mean episode length: 203.99
    Episode_Reward/reaching_object: 1.2335
    Episode_Reward/rotating_object: 96.1088
        Episode_Reward/action_rate: -0.1445
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 3.77s
                      Time elapsed: 00:57:27
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 25319 steps/s (collection: 3.631s, learning 0.252s)
             Mean action noise std: 4.75
          Mean value_function loss: 109.7341
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 90.8677
                       Mean reward: 483.86
               Mean episode length: 208.25
    Episode_Reward/reaching_object: 1.2577
    Episode_Reward/rotating_object: 101.0601
        Episode_Reward/action_rate: -0.1481
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 3.88s
                      Time elapsed: 00:57:31
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 24442 steps/s (collection: 3.768s, learning 0.254s)
             Mean action noise std: 4.76
          Mean value_function loss: 119.4233
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 90.8881
                       Mean reward: 522.90
               Mean episode length: 222.19
    Episode_Reward/reaching_object: 1.2745
    Episode_Reward/rotating_object: 100.9848
        Episode_Reward/action_rate: -0.1496
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 4.02s
                      Time elapsed: 00:57:35
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 28731 steps/s (collection: 3.195s, learning 0.226s)
             Mean action noise std: 4.76
          Mean value_function loss: 111.8987
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 90.9018
                       Mean reward: 506.67
               Mean episode length: 218.91
    Episode_Reward/reaching_object: 1.2818
    Episode_Reward/rotating_object: 100.9465
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 3.42s
                      Time elapsed: 00:57:39
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 28669 steps/s (collection: 3.218s, learning 0.211s)
             Mean action noise std: 4.76
          Mean value_function loss: 114.5989
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 90.9090
                       Mean reward: 510.24
               Mean episode length: 220.31
    Episode_Reward/reaching_object: 1.2832
    Episode_Reward/rotating_object: 103.8831
        Episode_Reward/action_rate: -0.1514
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 3.43s
                      Time elapsed: 00:57:42
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 28611 steps/s (collection: 3.217s, learning 0.218s)
             Mean action noise std: 4.76
          Mean value_function loss: 122.2073
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 90.9172
                       Mean reward: 539.44
               Mean episode length: 223.08
    Episode_Reward/reaching_object: 1.2783
    Episode_Reward/rotating_object: 103.1068
        Episode_Reward/action_rate: -0.1518
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 3.44s
                      Time elapsed: 00:57:46
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 27548 steps/s (collection: 3.364s, learning 0.205s)
             Mean action noise std: 4.76
          Mean value_function loss: 120.9519
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 90.9272
                       Mean reward: 501.56
               Mean episode length: 209.55
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 101.8114
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 3.57s
                      Time elapsed: 00:57:49
                               ETA: 00:08:59

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 29091 steps/s (collection: 3.157s, learning 0.223s)
             Mean action noise std: 4.77
          Mean value_function loss: 109.6668
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 90.9473
                       Mean reward: 552.09
               Mean episode length: 227.31
    Episode_Reward/reaching_object: 1.2468
    Episode_Reward/rotating_object: 101.0618
        Episode_Reward/action_rate: -0.1493
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 3.38s
                      Time elapsed: 00:57:53
                               ETA: 00:08:56

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 30021 steps/s (collection: 3.063s, learning 0.211s)
             Mean action noise std: 4.77
          Mean value_function loss: 121.7112
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 90.9652
                       Mean reward: 552.72
               Mean episode length: 219.46
    Episode_Reward/reaching_object: 1.2438
    Episode_Reward/rotating_object: 103.5829
        Episode_Reward/action_rate: -0.1479
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 3.27s
                      Time elapsed: 00:57:56
                               ETA: 00:08:54

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 23589 steps/s (collection: 3.887s, learning 0.281s)
             Mean action noise std: 4.77
          Mean value_function loss: 109.5391
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 90.9852
                       Mean reward: 546.03
               Mean episode length: 215.55
    Episode_Reward/reaching_object: 1.2934
    Episode_Reward/rotating_object: 107.8557
        Episode_Reward/action_rate: -0.1549
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 4.17s
                      Time elapsed: 00:58:00
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 30015 steps/s (collection: 3.080s, learning 0.195s)
             Mean action noise std: 4.78
          Mean value_function loss: 114.4427
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 91.0058
                       Mean reward: 571.20
               Mean episode length: 227.47
    Episode_Reward/reaching_object: 1.2739
    Episode_Reward/rotating_object: 106.3848
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0635
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 3.28s
                      Time elapsed: 00:58:03
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 31994 steps/s (collection: 2.871s, learning 0.202s)
             Mean action noise std: 4.78
          Mean value_function loss: 118.5543
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 91.0300
                       Mean reward: 467.72
               Mean episode length: 208.98
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 99.9669
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 3.07s
                      Time elapsed: 00:58:06
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 31354 steps/s (collection: 2.876s, learning 0.259s)
             Mean action noise std: 4.78
          Mean value_function loss: 115.0731
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 91.0468
                       Mean reward: 509.61
               Mean episode length: 213.75
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 102.7723
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 3.14s
                      Time elapsed: 00:58:09
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 31451 steps/s (collection: 2.931s, learning 0.194s)
             Mean action noise std: 4.79
          Mean value_function loss: 113.3078
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 91.0608
                       Mean reward: 507.67
               Mean episode length: 213.55
    Episode_Reward/reaching_object: 1.2688
    Episode_Reward/rotating_object: 103.7120
        Episode_Reward/action_rate: -0.1534
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 3.13s
                      Time elapsed: 00:58:13
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 31300 steps/s (collection: 2.944s, learning 0.196s)
             Mean action noise std: 4.79
          Mean value_function loss: 123.2225
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 91.0715
                       Mean reward: 517.56
               Mean episode length: 217.25
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 96.7552
        Episode_Reward/action_rate: -0.1465
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 3.14s
                      Time elapsed: 00:58:16
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 24148 steps/s (collection: 3.872s, learning 0.199s)
             Mean action noise std: 4.79
          Mean value_function loss: 121.3570
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 91.0886
                       Mean reward: 557.55
               Mean episode length: 217.24
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 99.3173
        Episode_Reward/action_rate: -0.1484
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 4.07s
                      Time elapsed: 00:58:20
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 29448 steps/s (collection: 3.114s, learning 0.225s)
             Mean action noise std: 4.80
          Mean value_function loss: 115.2449
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 91.1187
                       Mean reward: 525.59
               Mean episode length: 221.86
    Episode_Reward/reaching_object: 1.2684
    Episode_Reward/rotating_object: 106.5808
        Episode_Reward/action_rate: -0.1539
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 3.34s
                      Time elapsed: 00:58:23
                               ETA: 00:08:33

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 29439 steps/s (collection: 3.128s, learning 0.211s)
             Mean action noise std: 4.80
          Mean value_function loss: 120.0749
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 91.1505
                       Mean reward: 519.41
               Mean episode length: 215.26
    Episode_Reward/reaching_object: 1.2694
    Episode_Reward/rotating_object: 102.8973
        Episode_Reward/action_rate: -0.1525
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 3.34s
                      Time elapsed: 00:58:26
                               ETA: 00:08:31

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 26453 steps/s (collection: 3.448s, learning 0.268s)
             Mean action noise std: 4.80
          Mean value_function loss: 130.4872
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 91.1660
                       Mean reward: 519.23
               Mean episode length: 215.90
    Episode_Reward/reaching_object: 1.2246
    Episode_Reward/rotating_object: 102.7833
        Episode_Reward/action_rate: -0.1485
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 3.72s
                      Time elapsed: 00:58:30
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 30575 steps/s (collection: 2.977s, learning 0.239s)
             Mean action noise std: 4.81
          Mean value_function loss: 123.8872
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 91.1716
                       Mean reward: 515.46
               Mean episode length: 211.45
    Episode_Reward/reaching_object: 1.2314
    Episode_Reward/rotating_object: 98.1776
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 3.22s
                      Time elapsed: 00:58:33
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 31658 steps/s (collection: 2.906s, learning 0.199s)
             Mean action noise std: 4.81
          Mean value_function loss: 119.4996
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 91.1863
                       Mean reward: 522.75
               Mean episode length: 223.20
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 102.2425
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 3.11s
                      Time elapsed: 00:58:36
                               ETA: 00:08:23

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 31930 steps/s (collection: 2.883s, learning 0.196s)
             Mean action noise std: 4.81
          Mean value_function loss: 110.3760
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 91.2050
                       Mean reward: 514.85
               Mean episode length: 219.43
    Episode_Reward/reaching_object: 1.2254
    Episode_Reward/rotating_object: 97.8719
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 3.08s
                      Time elapsed: 00:58:40
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 30109 steps/s (collection: 3.054s, learning 0.211s)
             Mean action noise std: 4.82
          Mean value_function loss: 119.2891
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 91.2284
                       Mean reward: 455.89
               Mean episode length: 197.74
    Episode_Reward/reaching_object: 1.2651
    Episode_Reward/rotating_object: 104.8031
        Episode_Reward/action_rate: -0.1524
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 3.26s
                      Time elapsed: 00:58:43
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 23438 steps/s (collection: 3.896s, learning 0.298s)
             Mean action noise std: 4.82
          Mean value_function loss: 113.6724
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 91.2516
                       Mean reward: 543.91
               Mean episode length: 217.39
    Episode_Reward/reaching_object: 1.2582
    Episode_Reward/rotating_object: 104.1190
        Episode_Reward/action_rate: -0.1518
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 4.19s
                      Time elapsed: 00:58:47
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 22799 steps/s (collection: 4.062s, learning 0.250s)
             Mean action noise std: 4.82
          Mean value_function loss: 112.0919
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 91.2751
                       Mean reward: 537.57
               Mean episode length: 222.62
    Episode_Reward/reaching_object: 1.2718
    Episode_Reward/rotating_object: 103.7573
        Episode_Reward/action_rate: -0.1537
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 4.31s
                      Time elapsed: 00:58:51
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 27515 steps/s (collection: 3.365s, learning 0.208s)
             Mean action noise std: 4.83
          Mean value_function loss: 120.2238
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 91.2887
                       Mean reward: 509.97
               Mean episode length: 207.72
    Episode_Reward/reaching_object: 1.2289
    Episode_Reward/rotating_object: 102.7147
        Episode_Reward/action_rate: -0.1497
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 3.57s
                      Time elapsed: 00:58:55
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 28658 steps/s (collection: 3.210s, learning 0.220s)
             Mean action noise std: 4.83
          Mean value_function loss: 113.9661
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 91.3066
                       Mean reward: 518.33
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.2835
    Episode_Reward/rotating_object: 106.1121
        Episode_Reward/action_rate: -0.1555
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 3.43s
                      Time elapsed: 00:58:58
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 26716 steps/s (collection: 3.306s, learning 0.373s)
             Mean action noise std: 4.83
          Mean value_function loss: 119.5228
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 91.3138
                       Mean reward: 509.14
               Mean episode length: 212.41
    Episode_Reward/reaching_object: 1.2512
    Episode_Reward/rotating_object: 103.0194
        Episode_Reward/action_rate: -0.1530
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 3.68s
                      Time elapsed: 00:59:02
                               ETA: 00:08:05

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 24248 steps/s (collection: 3.508s, learning 0.546s)
             Mean action noise std: 4.83
          Mean value_function loss: 125.1308
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 91.3280
                       Mean reward: 527.31
               Mean episode length: 209.24
    Episode_Reward/reaching_object: 1.2686
    Episode_Reward/rotating_object: 106.8344
        Episode_Reward/action_rate: -0.1538
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 4.05s
                      Time elapsed: 00:59:06
                               ETA: 00:08:03

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 26389 steps/s (collection: 3.484s, learning 0.241s)
             Mean action noise std: 4.84
          Mean value_function loss: 112.3755
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 91.3407
                       Mean reward: 514.39
               Mean episode length: 216.57
    Episode_Reward/reaching_object: 1.2445
    Episode_Reward/rotating_object: 97.9801
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 3.73s
                      Time elapsed: 00:59:10
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 24152 steps/s (collection: 3.764s, learning 0.306s)
             Mean action noise std: 4.84
          Mean value_function loss: 115.0776
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 91.3571
                       Mean reward: 561.30
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 1.2802
    Episode_Reward/rotating_object: 105.6847
        Episode_Reward/action_rate: -0.1571
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 4.07s
                      Time elapsed: 00:59:14
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 24573 steps/s (collection: 3.719s, learning 0.282s)
             Mean action noise std: 4.84
          Mean value_function loss: 116.8401
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 91.3782
                       Mean reward: 533.14
               Mean episode length: 220.16
    Episode_Reward/reaching_object: 1.2351
    Episode_Reward/rotating_object: 102.9650
        Episode_Reward/action_rate: -0.1521
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 4.00s
                      Time elapsed: 00:59:18
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 25845 steps/s (collection: 3.554s, learning 0.249s)
             Mean action noise std: 4.85
          Mean value_function loss: 119.3292
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 91.4070
                       Mean reward: 527.16
               Mean episode length: 213.96
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 100.9598
        Episode_Reward/action_rate: -0.1507
          Episode_Reward/joint_vel: -0.0630
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 3.80s
                      Time elapsed: 00:59:22
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 26719 steps/s (collection: 3.411s, learning 0.268s)
             Mean action noise std: 4.85
          Mean value_function loss: 115.2697
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 91.4345
                       Mean reward: 530.95
               Mean episode length: 216.47
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 102.7136
        Episode_Reward/action_rate: -0.1524
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 3.68s
                      Time elapsed: 00:59:25
                               ETA: 00:07:50

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 22395 steps/s (collection: 4.026s, learning 0.363s)
             Mean action noise std: 4.86
          Mean value_function loss: 114.6862
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 91.4600
                       Mean reward: 524.77
               Mean episode length: 220.55
    Episode_Reward/reaching_object: 1.2646
    Episode_Reward/rotating_object: 105.3341
        Episode_Reward/action_rate: -0.1564
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 4.39s
                      Time elapsed: 00:59:30
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 24046 steps/s (collection: 3.836s, learning 0.252s)
             Mean action noise std: 4.86
          Mean value_function loss: 121.9047
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 91.4890
                       Mean reward: 553.05
               Mean episode length: 216.21
    Episode_Reward/reaching_object: 1.2659
    Episode_Reward/rotating_object: 105.6035
        Episode_Reward/action_rate: -0.1561
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 4.09s
                      Time elapsed: 00:59:34
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 24361 steps/s (collection: 3.805s, learning 0.230s)
             Mean action noise std: 4.86
          Mean value_function loss: 111.8285
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 91.5087
                       Mean reward: 549.12
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 1.2850
    Episode_Reward/rotating_object: 108.4628
        Episode_Reward/action_rate: -0.1590
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 4.04s
                      Time elapsed: 00:59:38
                               ETA: 00:07:43

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 31124 steps/s (collection: 2.950s, learning 0.209s)
             Mean action noise std: 4.87
          Mean value_function loss: 123.0152
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 91.5195
                       Mean reward: 533.61
               Mean episode length: 223.10
    Episode_Reward/reaching_object: 1.2895
    Episode_Reward/rotating_object: 108.8687
        Episode_Reward/action_rate: -0.1589
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 3.16s
                      Time elapsed: 00:59:41
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 29076 steps/s (collection: 3.151s, learning 0.230s)
             Mean action noise std: 4.87
          Mean value_function loss: 118.5614
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 91.5357
                       Mean reward: 506.74
               Mean episode length: 214.09
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 102.0179
        Episode_Reward/action_rate: -0.1545
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 3.38s
                      Time elapsed: 00:59:44
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 26007 steps/s (collection: 3.483s, learning 0.297s)
             Mean action noise std: 4.87
          Mean value_function loss: 118.4198
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 91.5551
                       Mean reward: 588.01
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 1.2513
    Episode_Reward/rotating_object: 103.8081
        Episode_Reward/action_rate: -0.1551
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 3.78s
                      Time elapsed: 00:59:48
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 26779 steps/s (collection: 3.376s, learning 0.295s)
             Mean action noise std: 4.88
          Mean value_function loss: 118.0840
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 91.5785
                       Mean reward: 530.61
               Mean episode length: 216.90
    Episode_Reward/reaching_object: 1.2334
    Episode_Reward/rotating_object: 101.1175
        Episode_Reward/action_rate: -0.1533
          Episode_Reward/joint_vel: -0.0632
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 3.67s
                      Time elapsed: 00:59:52
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 7655 steps/s (collection: 12.381s, learning 0.460s)
             Mean action noise std: 4.88
          Mean value_function loss: 104.2589
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 91.5948
                       Mean reward: 540.78
               Mean episode length: 214.07
    Episode_Reward/reaching_object: 1.2693
    Episode_Reward/rotating_object: 107.3060
        Episode_Reward/action_rate: -0.1581
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 12.84s
                      Time elapsed: 01:00:05
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 6227 steps/s (collection: 15.300s, learning 0.485s)
             Mean action noise std: 4.88
          Mean value_function loss: 109.9957
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 91.6103
                       Mean reward: 539.91
               Mean episode length: 220.91
    Episode_Reward/reaching_object: 1.2551
    Episode_Reward/rotating_object: 105.7285
        Episode_Reward/action_rate: -0.1568
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 15.78s
                      Time elapsed: 01:00:20
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 6126 steps/s (collection: 15.525s, learning 0.520s)
             Mean action noise std: 4.89
          Mean value_function loss: 108.1471
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 91.6263
                       Mean reward: 515.26
               Mean episode length: 218.27
    Episode_Reward/reaching_object: 1.2685
    Episode_Reward/rotating_object: 105.0326
        Episode_Reward/action_rate: -0.1580
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 16.05s
                      Time elapsed: 01:00:37
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 6811 steps/s (collection: 14.071s, learning 0.361s)
             Mean action noise std: 4.89
          Mean value_function loss: 114.9482
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 91.6464
                       Mean reward: 596.49
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.2874
    Episode_Reward/rotating_object: 106.3020
        Episode_Reward/action_rate: -0.1597
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 14.43s
                      Time elapsed: 01:00:51
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 6299 steps/s (collection: 15.277s, learning 0.329s)
             Mean action noise std: 4.89
          Mean value_function loss: 122.7075
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 91.6666
                       Mean reward: 510.39
               Mean episode length: 212.89
    Episode_Reward/reaching_object: 1.2798
    Episode_Reward/rotating_object: 103.9196
        Episode_Reward/action_rate: -0.1601
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 15.61s
                      Time elapsed: 01:01:07
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 6203 steps/s (collection: 15.513s, learning 0.333s)
             Mean action noise std: 4.90
          Mean value_function loss: 107.7025
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 91.6855
                       Mean reward: 545.89
               Mean episode length: 223.48
    Episode_Reward/reaching_object: 1.2597
    Episode_Reward/rotating_object: 106.8381
        Episode_Reward/action_rate: -0.1579
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 15.85s
                      Time elapsed: 01:01:22
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 6519 steps/s (collection: 14.754s, learning 0.324s)
             Mean action noise std: 4.90
          Mean value_function loss: 120.7714
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 91.6994
                       Mean reward: 549.94
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.2792
    Episode_Reward/rotating_object: 103.8508
        Episode_Reward/action_rate: -0.1609
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 15.08s
                      Time elapsed: 01:01:37
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 6118 steps/s (collection: 15.735s, learning 0.332s)
             Mean action noise std: 4.90
          Mean value_function loss: 115.6083
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 91.7124
                       Mean reward: 495.86
               Mean episode length: 210.78
    Episode_Reward/reaching_object: 1.2641
    Episode_Reward/rotating_object: 104.7777
        Episode_Reward/action_rate: -0.1589
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 16.07s
                      Time elapsed: 01:01:54
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 5032 steps/s (collection: 19.091s, learning 0.443s)
             Mean action noise std: 4.91
          Mean value_function loss: 119.3728
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 91.7351
                       Mean reward: 535.07
               Mean episode length: 214.52
    Episode_Reward/reaching_object: 1.2669
    Episode_Reward/rotating_object: 107.9610
        Episode_Reward/action_rate: -0.1594
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 19.53s
                      Time elapsed: 01:02:13
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 21475 steps/s (collection: 4.260s, learning 0.318s)
             Mean action noise std: 4.91
          Mean value_function loss: 107.9894
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 91.7572
                       Mean reward: 505.85
               Mean episode length: 204.68
    Episode_Reward/reaching_object: 1.2312
    Episode_Reward/rotating_object: 103.6080
        Episode_Reward/action_rate: -0.1562
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 4.58s
                      Time elapsed: 01:02:18
                               ETA: 00:07:19

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 24136 steps/s (collection: 3.687s, learning 0.386s)
             Mean action noise std: 4.91
          Mean value_function loss: 115.5984
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 91.7762
                       Mean reward: 560.68
               Mean episode length: 226.03
    Episode_Reward/reaching_object: 1.2887
    Episode_Reward/rotating_object: 106.5661
        Episode_Reward/action_rate: -0.1638
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 4.07s
                      Time elapsed: 01:02:22
                               ETA: 00:07:17

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 22968 steps/s (collection: 3.957s, learning 0.323s)
             Mean action noise std: 4.92
          Mean value_function loss: 110.1295
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 91.7944
                       Mean reward: 568.64
               Mean episode length: 220.30
    Episode_Reward/reaching_object: 1.2532
    Episode_Reward/rotating_object: 108.5443
        Episode_Reward/action_rate: -0.1597
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 4.28s
                      Time elapsed: 01:02:26
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 24279 steps/s (collection: 3.807s, learning 0.242s)
             Mean action noise std: 4.92
          Mean value_function loss: 111.8629
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 91.8097
                       Mean reward: 545.64
               Mean episode length: 225.74
    Episode_Reward/reaching_object: 1.2863
    Episode_Reward/rotating_object: 106.6818
        Episode_Reward/action_rate: -0.1627
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 4.05s
                      Time elapsed: 01:02:30
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 25625 steps/s (collection: 3.529s, learning 0.308s)
             Mean action noise std: 4.92
          Mean value_function loss: 112.8118
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 91.8191
                       Mean reward: 512.12
               Mean episode length: 214.60
    Episode_Reward/reaching_object: 1.2415
    Episode_Reward/rotating_object: 108.7947
        Episode_Reward/action_rate: -0.1596
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 3.84s
                      Time elapsed: 01:02:34
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 47822 steps/s (collection: 1.960s, learning 0.096s)
             Mean action noise std: 4.92
          Mean value_function loss: 127.8271
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 91.8371
                       Mean reward: 508.01
               Mean episode length: 212.32
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 98.2925
        Episode_Reward/action_rate: -0.1580
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.06s
                      Time elapsed: 01:02:36
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 50305 steps/s (collection: 1.863s, learning 0.091s)
             Mean action noise std: 4.93
          Mean value_function loss: 107.3143
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 91.8539
                       Mean reward: 594.68
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.2626
    Episode_Reward/rotating_object: 108.8620
        Episode_Reward/action_rate: -0.1627
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.95s
                      Time elapsed: 01:02:38
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 49657 steps/s (collection: 1.869s, learning 0.111s)
             Mean action noise std: 4.93
          Mean value_function loss: 114.8791
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 91.8628
                       Mean reward: 530.41
               Mean episode length: 217.07
    Episode_Reward/reaching_object: 1.2802
    Episode_Reward/rotating_object: 111.3989
        Episode_Reward/action_rate: -0.1646
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.98s
                      Time elapsed: 01:02:40
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 50208 steps/s (collection: 1.860s, learning 0.098s)
             Mean action noise std: 4.93
          Mean value_function loss: 115.3348
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 91.8740
                       Mean reward: 498.92
               Mean episode length: 206.28
    Episode_Reward/reaching_object: 1.2603
    Episode_Reward/rotating_object: 105.2412
        Episode_Reward/action_rate: -0.1611
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.96s
                      Time elapsed: 01:02:42
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 50576 steps/s (collection: 1.847s, learning 0.097s)
             Mean action noise std: 4.93
          Mean value_function loss: 123.9074
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 91.8883
                       Mean reward: 509.40
               Mean episode length: 217.48
    Episode_Reward/reaching_object: 1.2811
    Episode_Reward/rotating_object: 110.6361
        Episode_Reward/action_rate: -0.1655
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.94s
                      Time elapsed: 01:02:44
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 51680 steps/s (collection: 1.801s, learning 0.101s)
             Mean action noise std: 4.94
          Mean value_function loss: 111.5591
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 91.9079
                       Mean reward: 521.24
               Mean episode length: 215.37
    Episode_Reward/reaching_object: 1.2217
    Episode_Reward/rotating_object: 101.5526
        Episode_Reward/action_rate: -0.1567
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.90s
                      Time elapsed: 01:02:46
                               ETA: 00:06:51

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 49315 steps/s (collection: 1.897s, learning 0.097s)
             Mean action noise std: 4.94
          Mean value_function loss: 111.7562
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 91.9231
                       Mean reward: 558.45
               Mean episode length: 218.02
    Episode_Reward/reaching_object: 1.2590
    Episode_Reward/rotating_object: 108.9482
        Episode_Reward/action_rate: -0.1617
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.99s
                      Time elapsed: 01:02:48
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 47086 steps/s (collection: 1.967s, learning 0.121s)
             Mean action noise std: 4.94
          Mean value_function loss: 112.8857
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 91.9313
                       Mean reward: 506.47
               Mean episode length: 216.60
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 103.1192
        Episode_Reward/action_rate: -0.1618
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.09s
                      Time elapsed: 01:02:50
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 46522 steps/s (collection: 2.017s, learning 0.096s)
             Mean action noise std: 4.94
          Mean value_function loss: 115.1130
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 91.9505
                       Mean reward: 532.37
               Mean episode length: 209.18
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 107.3529
        Episode_Reward/action_rate: -0.1590
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.11s
                      Time elapsed: 01:02:52
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 48788 steps/s (collection: 1.884s, learning 0.131s)
             Mean action noise std: 4.95
          Mean value_function loss: 119.9467
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 91.9689
                       Mean reward: 512.99
               Mean episode length: 210.44
    Episode_Reward/reaching_object: 1.2454
    Episode_Reward/rotating_object: 103.4582
        Episode_Reward/action_rate: -0.1618
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.01s
                      Time elapsed: 01:02:54
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 38856 steps/s (collection: 2.424s, learning 0.106s)
             Mean action noise std: 4.95
          Mean value_function loss: 112.1515
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 91.9784
                       Mean reward: 540.13
               Mean episode length: 216.78
    Episode_Reward/reaching_object: 1.2600
    Episode_Reward/rotating_object: 107.9437
        Episode_Reward/action_rate: -0.1611
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.53s
                      Time elapsed: 01:02:56
                               ETA: 00:06:37

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 44644 steps/s (collection: 2.079s, learning 0.123s)
             Mean action noise std: 4.95
          Mean value_function loss: 121.7203
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 91.9847
                       Mean reward: 555.40
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.2304
    Episode_Reward/rotating_object: 104.5527
        Episode_Reward/action_rate: -0.1595
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.20s
                      Time elapsed: 01:02:59
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 44116 steps/s (collection: 2.119s, learning 0.110s)
             Mean action noise std: 4.95
          Mean value_function loss: 123.3431
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 91.9965
                       Mean reward: 537.72
               Mean episode length: 207.39
    Episode_Reward/reaching_object: 1.2559
    Episode_Reward/rotating_object: 108.5707
        Episode_Reward/action_rate: -0.1612
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.23s
                      Time elapsed: 01:03:01
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 48215 steps/s (collection: 1.939s, learning 0.100s)
             Mean action noise std: 4.96
          Mean value_function loss: 120.5533
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 92.0139
                       Mean reward: 517.65
               Mean episode length: 208.30
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 108.2959
        Episode_Reward/action_rate: -0.1618
          Episode_Reward/joint_vel: -0.0630
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.04s
                      Time elapsed: 01:03:03
                               ETA: 00:06:29

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 46245 steps/s (collection: 1.983s, learning 0.143s)
             Mean action noise std: 4.96
          Mean value_function loss: 105.9172
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 92.0365
                       Mean reward: 515.64
               Mean episode length: 215.05
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 102.5013
        Episode_Reward/action_rate: -0.1576
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.13s
                      Time elapsed: 01:03:05
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 44406 steps/s (collection: 2.075s, learning 0.139s)
             Mean action noise std: 4.96
          Mean value_function loss: 109.5933
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 92.0503
                       Mean reward: 489.33
               Mean episode length: 207.49
    Episode_Reward/reaching_object: 1.2680
    Episode_Reward/rotating_object: 109.8176
        Episode_Reward/action_rate: -0.1634
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.21s
                      Time elapsed: 01:03:07
                               ETA: 00:06:23

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 41251 steps/s (collection: 2.244s, learning 0.139s)
             Mean action noise std: 4.97
          Mean value_function loss: 106.7277
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 92.0619
                       Mean reward: 526.25
               Mean episode length: 213.82
    Episode_Reward/reaching_object: 1.2683
    Episode_Reward/rotating_object: 108.8798
        Episode_Reward/action_rate: -0.1625
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.38s
                      Time elapsed: 01:03:10
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 39594 steps/s (collection: 2.326s, learning 0.157s)
             Mean action noise std: 4.97
          Mean value_function loss: 107.4439
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 92.0717
                       Mean reward: 562.06
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 1.3199
    Episode_Reward/rotating_object: 111.1601
        Episode_Reward/action_rate: -0.1678
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.48s
                      Time elapsed: 01:03:12
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 38906 steps/s (collection: 2.291s, learning 0.236s)
             Mean action noise std: 4.97
          Mean value_function loss: 111.8139
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 92.0831
                       Mean reward: 574.60
               Mean episode length: 221.96
    Episode_Reward/reaching_object: 1.3108
    Episode_Reward/rotating_object: 113.6910
        Episode_Reward/action_rate: -0.1674
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.53s
                      Time elapsed: 01:03:15
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 36245 steps/s (collection: 2.482s, learning 0.231s)
             Mean action noise std: 4.97
          Mean value_function loss: 109.2291
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 92.0915
                       Mean reward: 574.70
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 1.2935
    Episode_Reward/rotating_object: 112.4760
        Episode_Reward/action_rate: -0.1662
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.71s
                      Time elapsed: 01:03:17
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 38567 steps/s (collection: 2.362s, learning 0.187s)
             Mean action noise std: 4.98
          Mean value_function loss: 111.7793
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 92.1033
                       Mean reward: 569.45
               Mean episode length: 223.62
    Episode_Reward/reaching_object: 1.2798
    Episode_Reward/rotating_object: 112.0973
        Episode_Reward/action_rate: -0.1642
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.55s
                      Time elapsed: 01:03:20
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 41202 steps/s (collection: 2.227s, learning 0.159s)
             Mean action noise std: 4.98
          Mean value_function loss: 111.3557
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 92.1210
                       Mean reward: 515.12
               Mean episode length: 214.89
    Episode_Reward/reaching_object: 1.2692
    Episode_Reward/rotating_object: 105.0791
        Episode_Reward/action_rate: -0.1641
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.39s
                      Time elapsed: 01:03:22
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 41466 steps/s (collection: 2.221s, learning 0.150s)
             Mean action noise std: 4.98
          Mean value_function loss: 113.3505
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 92.1293
                       Mean reward: 566.78
               Mean episode length: 223.91
    Episode_Reward/reaching_object: 1.3100
    Episode_Reward/rotating_object: 109.0396
        Episode_Reward/action_rate: -0.1682
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.37s
                      Time elapsed: 01:03:25
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 41009 steps/s (collection: 2.242s, learning 0.155s)
             Mean action noise std: 4.98
          Mean value_function loss: 122.8617
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 92.1391
                       Mean reward: 583.92
               Mean episode length: 222.69
    Episode_Reward/reaching_object: 1.2808
    Episode_Reward/rotating_object: 111.2240
        Episode_Reward/action_rate: -0.1647
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.40s
                      Time elapsed: 01:03:27
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 37081 steps/s (collection: 2.368s, learning 0.283s)
             Mean action noise std: 4.99
          Mean value_function loss: 110.7623
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 92.1549
                       Mean reward: 556.74
               Mean episode length: 221.95
    Episode_Reward/reaching_object: 1.2701
    Episode_Reward/rotating_object: 109.7751
        Episode_Reward/action_rate: -0.1641
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.65s
                      Time elapsed: 01:03:30
                               ETA: 00:05:58

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 39905 steps/s (collection: 2.280s, learning 0.184s)
             Mean action noise std: 4.99
          Mean value_function loss: 105.0802
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 92.1713
                       Mean reward: 535.94
               Mean episode length: 220.23
    Episode_Reward/reaching_object: 1.2845
    Episode_Reward/rotating_object: 112.8462
        Episode_Reward/action_rate: -0.1663
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.46s
                      Time elapsed: 01:03:32
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 41418 steps/s (collection: 2.257s, learning 0.117s)
             Mean action noise std: 4.99
          Mean value_function loss: 112.9105
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 92.1794
                       Mean reward: 509.86
               Mean episode length: 214.94
    Episode_Reward/reaching_object: 1.2614
    Episode_Reward/rotating_object: 106.1952
        Episode_Reward/action_rate: -0.1636
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.37s
                      Time elapsed: 01:03:35
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 49154 steps/s (collection: 1.885s, learning 0.115s)
             Mean action noise std: 4.99
          Mean value_function loss: 111.2530
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 92.1882
                       Mean reward: 570.24
               Mean episode length: 220.70
    Episode_Reward/reaching_object: 1.2947
    Episode_Reward/rotating_object: 111.1199
        Episode_Reward/action_rate: -0.1681
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.00s
                      Time elapsed: 01:03:37
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 48142 steps/s (collection: 1.930s, learning 0.112s)
             Mean action noise std: 5.00
          Mean value_function loss: 104.3206
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 92.2024
                       Mean reward: 569.66
               Mean episode length: 220.46
    Episode_Reward/reaching_object: 1.2914
    Episode_Reward/rotating_object: 114.3235
        Episode_Reward/action_rate: -0.1681
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.04s
                      Time elapsed: 01:03:39
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 48875 steps/s (collection: 1.911s, learning 0.100s)
             Mean action noise std: 5.00
          Mean value_function loss: 102.3238
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 92.2192
                       Mean reward: 534.42
               Mean episode length: 219.22
    Episode_Reward/reaching_object: 1.3158
    Episode_Reward/rotating_object: 108.8961
        Episode_Reward/action_rate: -0.1699
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.01s
                      Time elapsed: 01:03:41
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 51348 steps/s (collection: 1.824s, learning 0.090s)
             Mean action noise std: 5.00
          Mean value_function loss: 104.8206
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 92.2329
                       Mean reward: 577.03
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 1.2980
    Episode_Reward/rotating_object: 111.0506
        Episode_Reward/action_rate: -0.1683
          Episode_Reward/joint_vel: -0.0689
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.91s
                      Time elapsed: 01:03:43
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 50050 steps/s (collection: 1.864s, learning 0.100s)
             Mean action noise std: 5.00
          Mean value_function loss: 109.4833
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 92.2471
                       Mean reward: 523.86
               Mean episode length: 213.43
    Episode_Reward/reaching_object: 1.2755
    Episode_Reward/rotating_object: 108.9770
        Episode_Reward/action_rate: -0.1666
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.96s
                      Time elapsed: 01:03:44
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 50495 steps/s (collection: 1.851s, learning 0.096s)
             Mean action noise std: 5.01
          Mean value_function loss: 115.3284
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 92.2644
                       Mean reward: 563.59
               Mean episode length: 214.72
    Episode_Reward/reaching_object: 1.2713
    Episode_Reward/rotating_object: 111.7881
        Episode_Reward/action_rate: -0.1650
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.95s
                      Time elapsed: 01:03:46
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 50223 steps/s (collection: 1.849s, learning 0.108s)
             Mean action noise std: 5.01
          Mean value_function loss: 110.3825
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 92.2923
                       Mean reward: 543.33
               Mean episode length: 208.76
    Episode_Reward/reaching_object: 1.2576
    Episode_Reward/rotating_object: 109.9724
        Episode_Reward/action_rate: -0.1631
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.96s
                      Time elapsed: 01:03:48
                               ETA: 00:05:32

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 50019 steps/s (collection: 1.855s, learning 0.110s)
             Mean action noise std: 5.01
          Mean value_function loss: 120.6726
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 92.3152
                       Mean reward: 537.36
               Mean episode length: 222.38
    Episode_Reward/reaching_object: 1.3274
    Episode_Reward/rotating_object: 112.0495
        Episode_Reward/action_rate: -0.1698
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.97s
                      Time elapsed: 01:03:50
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 50342 steps/s (collection: 1.826s, learning 0.127s)
             Mean action noise std: 5.02
          Mean value_function loss: 116.2352
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 92.3253
                       Mean reward: 536.18
               Mean episode length: 216.76
    Episode_Reward/reaching_object: 1.2491
    Episode_Reward/rotating_object: 103.2847
        Episode_Reward/action_rate: -0.1627
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.95s
                      Time elapsed: 01:03:52
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 50965 steps/s (collection: 1.835s, learning 0.094s)
             Mean action noise std: 5.02
          Mean value_function loss: 114.4975
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 92.3342
                       Mean reward: 546.57
               Mean episode length: 219.55
    Episode_Reward/reaching_object: 1.3152
    Episode_Reward/rotating_object: 113.5086
        Episode_Reward/action_rate: -0.1696
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.93s
                      Time elapsed: 01:03:54
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 49790 steps/s (collection: 1.876s, learning 0.098s)
             Mean action noise std: 5.02
          Mean value_function loss: 106.0546
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 92.3452
                       Mean reward: 544.22
               Mean episode length: 227.49
    Episode_Reward/reaching_object: 1.2944
    Episode_Reward/rotating_object: 109.3295
        Episode_Reward/action_rate: -0.1683
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.97s
                      Time elapsed: 01:03:56
                               ETA: 00:05:21

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 46487 steps/s (collection: 2.008s, learning 0.107s)
             Mean action noise std: 5.02
          Mean value_function loss: 104.1572
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 92.3595
                       Mean reward: 555.34
               Mean episode length: 220.99
    Episode_Reward/reaching_object: 1.3267
    Episode_Reward/rotating_object: 115.7805
        Episode_Reward/action_rate: -0.1710
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.11s
                      Time elapsed: 01:03:58
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 47694 steps/s (collection: 1.945s, learning 0.117s)
             Mean action noise std: 5.02
          Mean value_function loss: 110.5283
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 92.3646
                       Mean reward: 571.81
               Mean episode length: 218.99
    Episode_Reward/reaching_object: 1.2844
    Episode_Reward/rotating_object: 110.3651
        Episode_Reward/action_rate: -0.1660
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.06s
                      Time elapsed: 01:04:00
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 47246 steps/s (collection: 1.980s, learning 0.101s)
             Mean action noise std: 5.03
          Mean value_function loss: 110.9661
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 92.3752
                       Mean reward: 560.27
               Mean episode length: 218.60
    Episode_Reward/reaching_object: 1.2997
    Episode_Reward/rotating_object: 111.7310
        Episode_Reward/action_rate: -0.1688
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.08s
                      Time elapsed: 01:04:02
                               ETA: 00:05:12

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 51070 steps/s (collection: 1.820s, learning 0.105s)
             Mean action noise std: 5.03
          Mean value_function loss: 103.0247
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 92.3911
                       Mean reward: 589.18
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.3280
    Episode_Reward/rotating_object: 115.6412
        Episode_Reward/action_rate: -0.1728
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.92s
                      Time elapsed: 01:04:04
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 51008 steps/s (collection: 1.832s, learning 0.095s)
             Mean action noise std: 5.03
          Mean value_function loss: 109.0752
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 92.4110
                       Mean reward: 569.51
               Mean episode length: 217.36
    Episode_Reward/reaching_object: 1.3073
    Episode_Reward/rotating_object: 110.4340
        Episode_Reward/action_rate: -0.1689
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.93s
                      Time elapsed: 01:04:06
                               ETA: 00:05:07

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 44833 steps/s (collection: 2.101s, learning 0.092s)
             Mean action noise std: 5.04
          Mean value_function loss: 110.2408
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 92.4272
                       Mean reward: 555.85
               Mean episode length: 217.50
    Episode_Reward/reaching_object: 1.2933
    Episode_Reward/rotating_object: 112.7721
        Episode_Reward/action_rate: -0.1697
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.19s
                      Time elapsed: 01:04:08
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 45426 steps/s (collection: 2.067s, learning 0.098s)
             Mean action noise std: 5.04
          Mean value_function loss: 112.5647
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 92.4471
                       Mean reward: 574.99
               Mean episode length: 220.36
    Episode_Reward/reaching_object: 1.2886
    Episode_Reward/rotating_object: 112.1129
        Episode_Reward/action_rate: -0.1677
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.16s
                      Time elapsed: 01:04:11
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 50351 steps/s (collection: 1.857s, learning 0.095s)
             Mean action noise std: 5.05
          Mean value_function loss: 116.1949
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 92.4799
                       Mean reward: 591.56
               Mean episode length: 220.86
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 106.6057
        Episode_Reward/action_rate: -0.1650
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.95s
                      Time elapsed: 01:04:13
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 49642 steps/s (collection: 1.885s, learning 0.096s)
             Mean action noise std: 5.05
          Mean value_function loss: 117.9450
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 92.5059
                       Mean reward: 567.48
               Mean episode length: 223.43
    Episode_Reward/reaching_object: 1.2915
    Episode_Reward/rotating_object: 110.3521
        Episode_Reward/action_rate: -0.1695
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.98s
                      Time elapsed: 01:04:15
                               ETA: 00:04:55

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 50905 steps/s (collection: 1.828s, learning 0.104s)
             Mean action noise std: 5.05
          Mean value_function loss: 112.6331
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 92.5149
                       Mean reward: 539.74
               Mean episode length: 207.61
    Episode_Reward/reaching_object: 1.2579
    Episode_Reward/rotating_object: 109.9628
        Episode_Reward/action_rate: -0.1657
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.93s
                      Time elapsed: 01:04:17
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 46311 steps/s (collection: 2.001s, learning 0.122s)
             Mean action noise std: 5.05
          Mean value_function loss: 106.9155
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 92.5229
                       Mean reward: 537.58
               Mean episode length: 216.37
    Episode_Reward/reaching_object: 1.2532
    Episode_Reward/rotating_object: 106.6824
        Episode_Reward/action_rate: -0.1652
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.12s
                      Time elapsed: 01:04:19
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 46377 steps/s (collection: 2.006s, learning 0.114s)
             Mean action noise std: 5.06
          Mean value_function loss: 104.8477
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 92.5372
                       Mean reward: 595.04
               Mean episode length: 221.40
    Episode_Reward/reaching_object: 1.2927
    Episode_Reward/rotating_object: 113.1837
        Episode_Reward/action_rate: -0.1695
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.12s
                      Time elapsed: 01:04:21
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 49127 steps/s (collection: 1.904s, learning 0.097s)
             Mean action noise std: 5.06
          Mean value_function loss: 102.7363
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 92.5520
                       Mean reward: 541.64
               Mean episode length: 215.37
    Episode_Reward/reaching_object: 1.2914
    Episode_Reward/rotating_object: 111.5085
        Episode_Reward/action_rate: -0.1701
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.00s
                      Time elapsed: 01:04:23
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 49911 steps/s (collection: 1.868s, learning 0.101s)
             Mean action noise std: 5.06
          Mean value_function loss: 101.7160
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 92.5672
                       Mean reward: 552.59
               Mean episode length: 213.16
    Episode_Reward/reaching_object: 1.2708
    Episode_Reward/rotating_object: 110.8510
        Episode_Reward/action_rate: -0.1673
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.97s
                      Time elapsed: 01:04:25
                               ETA: 00:04:41

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 50848 steps/s (collection: 1.831s, learning 0.103s)
             Mean action noise std: 5.07
          Mean value_function loss: 110.7510
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 92.5869
                       Mean reward: 570.74
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.3026
    Episode_Reward/rotating_object: 110.9620
        Episode_Reward/action_rate: -0.1708
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.93s
                      Time elapsed: 01:04:27
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 51256 steps/s (collection: 1.823s, learning 0.095s)
             Mean action noise std: 5.07
          Mean value_function loss: 111.5447
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 92.6070
                       Mean reward: 530.34
               Mean episode length: 210.41
    Episode_Reward/reaching_object: 1.2955
    Episode_Reward/rotating_object: 113.6550
        Episode_Reward/action_rate: -0.1714
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.92s
                      Time elapsed: 01:04:29
                               ETA: 00:04:36

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 46175 steps/s (collection: 2.027s, learning 0.102s)
             Mean action noise std: 5.07
          Mean value_function loss: 107.6989
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 92.6272
                       Mean reward: 558.37
               Mean episode length: 214.91
    Episode_Reward/reaching_object: 1.2679
    Episode_Reward/rotating_object: 111.2447
        Episode_Reward/action_rate: -0.1683
          Episode_Reward/joint_vel: -0.0630
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.13s
                      Time elapsed: 01:04:31
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 49287 steps/s (collection: 1.891s, learning 0.103s)
             Mean action noise std: 5.08
          Mean value_function loss: 108.5422
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 92.6472
                       Mean reward: 522.49
               Mean episode length: 208.50
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 108.9316
        Episode_Reward/action_rate: -0.1675
          Episode_Reward/joint_vel: -0.0640
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.99s
                      Time elapsed: 01:04:33
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 50531 steps/s (collection: 1.846s, learning 0.099s)
             Mean action noise std: 5.08
          Mean value_function loss: 103.9345
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 92.6642
                       Mean reward: 562.00
               Mean episode length: 221.58
    Episode_Reward/reaching_object: 1.2833
    Episode_Reward/rotating_object: 110.7822
        Episode_Reward/action_rate: -0.1704
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.95s
                      Time elapsed: 01:04:35
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 49837 steps/s (collection: 1.856s, learning 0.117s)
             Mean action noise std: 5.08
          Mean value_function loss: 106.1740
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 92.6754
                       Mean reward: 569.47
               Mean episode length: 224.99
    Episode_Reward/reaching_object: 1.2776
    Episode_Reward/rotating_object: 111.8494
        Episode_Reward/action_rate: -0.1692
          Episode_Reward/joint_vel: -0.0610
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.97s
                      Time elapsed: 01:04:37
                               ETA: 00:04:24

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 49973 steps/s (collection: 1.857s, learning 0.111s)
             Mean action noise std: 5.08
          Mean value_function loss: 115.3741
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 92.6920
                       Mean reward: 536.96
               Mean episode length: 211.98
    Episode_Reward/reaching_object: 1.2527
    Episode_Reward/rotating_object: 110.1581
        Episode_Reward/action_rate: -0.1668
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.97s
                      Time elapsed: 01:04:39
                               ETA: 00:04:22

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 50861 steps/s (collection: 1.815s, learning 0.118s)
             Mean action noise std: 5.09
          Mean value_function loss: 107.9044
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 92.7180
                       Mean reward: 531.51
               Mean episode length: 212.21
    Episode_Reward/reaching_object: 1.2491
    Episode_Reward/rotating_object: 106.7262
        Episode_Reward/action_rate: -0.1677
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.93s
                      Time elapsed: 01:04:41
                               ETA: 00:04:19

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 50882 steps/s (collection: 1.832s, learning 0.100s)
             Mean action noise std: 5.09
          Mean value_function loss: 101.4563
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 92.7409
                       Mean reward: 590.81
               Mean episode length: 221.54
    Episode_Reward/reaching_object: 1.2687
    Episode_Reward/rotating_object: 109.7005
        Episode_Reward/action_rate: -0.1706
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.93s
                      Time elapsed: 01:04:42
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 50733 steps/s (collection: 1.832s, learning 0.106s)
             Mean action noise std: 5.09
          Mean value_function loss: 114.2490
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 92.7549
                       Mean reward: 611.00
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 1.3337
    Episode_Reward/rotating_object: 118.3300
        Episode_Reward/action_rate: -0.1761
          Episode_Reward/joint_vel: -0.0631
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.94s
                      Time elapsed: 01:04:44
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 51010 steps/s (collection: 1.827s, learning 0.100s)
             Mean action noise std: 5.10
          Mean value_function loss: 104.5324
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 92.7726
                       Mean reward: 587.88
               Mean episode length: 217.80
    Episode_Reward/reaching_object: 1.2928
    Episode_Reward/rotating_object: 114.6421
        Episode_Reward/action_rate: -0.1727
          Episode_Reward/joint_vel: -0.0629
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.93s
                      Time elapsed: 01:04:46
                               ETA: 00:04:10

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 49619 steps/s (collection: 1.867s, learning 0.114s)
             Mean action noise std: 5.10
          Mean value_function loss: 107.7566
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 92.7946
                       Mean reward: 567.35
               Mean episode length: 222.52
    Episode_Reward/reaching_object: 1.2659
    Episode_Reward/rotating_object: 108.7672
        Episode_Reward/action_rate: -0.1699
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.98s
                      Time elapsed: 01:04:48
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 50350 steps/s (collection: 1.840s, learning 0.113s)
             Mean action noise std: 5.11
          Mean value_function loss: 97.4193
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 92.8156
                       Mean reward: 528.48
               Mean episode length: 212.75
    Episode_Reward/reaching_object: 1.3067
    Episode_Reward/rotating_object: 111.4913
        Episode_Reward/action_rate: -0.1755
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.95s
                      Time elapsed: 01:04:50
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 50515 steps/s (collection: 1.830s, learning 0.116s)
             Mean action noise std: 5.11
          Mean value_function loss: 103.2468
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 92.8345
                       Mean reward: 562.55
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 1.3071
    Episode_Reward/rotating_object: 113.0854
        Episode_Reward/action_rate: -0.1749
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.95s
                      Time elapsed: 01:04:52
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 51028 steps/s (collection: 1.829s, learning 0.098s)
             Mean action noise std: 5.11
          Mean value_function loss: 102.4078
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 92.8452
                       Mean reward: 544.29
               Mean episode length: 212.17
    Episode_Reward/reaching_object: 1.2483
    Episode_Reward/rotating_object: 110.4659
        Episode_Reward/action_rate: -0.1683
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.93s
                      Time elapsed: 01:04:54
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 51284 steps/s (collection: 1.812s, learning 0.105s)
             Mean action noise std: 5.12
          Mean value_function loss: 98.9942
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 92.8571
                       Mean reward: 596.92
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.3045
    Episode_Reward/rotating_object: 115.3792
        Episode_Reward/action_rate: -0.1759
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.92s
                      Time elapsed: 01:04:56
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 50141 steps/s (collection: 1.854s, learning 0.107s)
             Mean action noise std: 5.12
          Mean value_function loss: 109.2724
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 92.8749
                       Mean reward: 554.68
               Mean episode length: 222.95
    Episode_Reward/reaching_object: 1.3033
    Episode_Reward/rotating_object: 112.9031
        Episode_Reward/action_rate: -0.1766
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.96s
                      Time elapsed: 01:04:58
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 51645 steps/s (collection: 1.800s, learning 0.104s)
             Mean action noise std: 5.12
          Mean value_function loss: 107.6652
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 92.8987
                       Mean reward: 563.22
               Mean episode length: 213.49
    Episode_Reward/reaching_object: 1.2865
    Episode_Reward/rotating_object: 115.9403
        Episode_Reward/action_rate: -0.1754
          Episode_Reward/joint_vel: -0.0617
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.90s
                      Time elapsed: 01:05:00
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 51337 steps/s (collection: 1.805s, learning 0.110s)
             Mean action noise std: 5.13
          Mean value_function loss: 107.1783
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 92.9208
                       Mean reward: 548.88
               Mean episode length: 219.20
    Episode_Reward/reaching_object: 1.2709
    Episode_Reward/rotating_object: 108.9897
        Episode_Reward/action_rate: -0.1748
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.91s
                      Time elapsed: 01:05:02
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 50704 steps/s (collection: 1.835s, learning 0.104s)
             Mean action noise std: 5.13
          Mean value_function loss: 103.7739
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 92.9406
                       Mean reward: 594.35
               Mean episode length: 230.78
    Episode_Reward/reaching_object: 1.3364
    Episode_Reward/rotating_object: 118.9705
        Episode_Reward/action_rate: -0.1819
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.94s
                      Time elapsed: 01:05:04
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 50476 steps/s (collection: 1.854s, learning 0.093s)
             Mean action noise std: 5.14
          Mean value_function loss: 104.6107
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 92.9635
                       Mean reward: 579.89
               Mean episode length: 224.18
    Episode_Reward/reaching_object: 1.2845
    Episode_Reward/rotating_object: 112.2733
        Episode_Reward/action_rate: -0.1767
          Episode_Reward/joint_vel: -0.0634
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.95s
                      Time elapsed: 01:05:06
                               ETA: 00:03:42

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 51529 steps/s (collection: 1.802s, learning 0.106s)
             Mean action noise std: 5.14
          Mean value_function loss: 94.7743
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 92.9786
                       Mean reward: 564.38
               Mean episode length: 220.48
    Episode_Reward/reaching_object: 1.3144
    Episode_Reward/rotating_object: 114.0765
        Episode_Reward/action_rate: -0.1803
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.91s
                      Time elapsed: 01:05:08
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 44102 steps/s (collection: 2.112s, learning 0.117s)
             Mean action noise std: 5.14
          Mean value_function loss: 97.6290
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 92.9880
                       Mean reward: 563.77
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.3017
    Episode_Reward/rotating_object: 115.8896
        Episode_Reward/action_rate: -0.1787
          Episode_Reward/joint_vel: -0.0611
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.23s
                      Time elapsed: 01:05:10
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 50686 steps/s (collection: 1.837s, learning 0.103s)
             Mean action noise std: 5.14
          Mean value_function loss: 100.1288
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 93.0083
                       Mean reward: 646.20
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 1.3198
    Episode_Reward/rotating_object: 121.3353
        Episode_Reward/action_rate: -0.1810
          Episode_Reward/joint_vel: -0.0613
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.94s
                      Time elapsed: 01:05:12
                               ETA: 00:03:34

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 49721 steps/s (collection: 1.884s, learning 0.094s)
             Mean action noise std: 5.15
          Mean value_function loss: 85.3472
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 93.0286
                       Mean reward: 575.23
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.3078
    Episode_Reward/rotating_object: 116.7062
        Episode_Reward/action_rate: -0.1803
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.98s
                      Time elapsed: 01:05:14
                               ETA: 00:03:31

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 50845 steps/s (collection: 1.836s, learning 0.097s)
             Mean action noise std: 5.15
          Mean value_function loss: 96.6788
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 93.0486
                       Mean reward: 595.63
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 1.3160
    Episode_Reward/rotating_object: 118.0155
        Episode_Reward/action_rate: -0.1831
          Episode_Reward/joint_vel: -0.0618
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.93s
                      Time elapsed: 01:05:16
                               ETA: 00:03:28

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 51786 steps/s (collection: 1.793s, learning 0.106s)
             Mean action noise std: 5.15
          Mean value_function loss: 98.3540
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 93.0663
                       Mean reward: 603.46
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 1.3325
    Episode_Reward/rotating_object: 118.8038
        Episode_Reward/action_rate: -0.1836
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.90s
                      Time elapsed: 01:05:18
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 49654 steps/s (collection: 1.872s, learning 0.108s)
             Mean action noise std: 5.16
          Mean value_function loss: 105.1879
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 93.0745
                       Mean reward: 581.91
               Mean episode length: 226.13
    Episode_Reward/reaching_object: 1.2912
    Episode_Reward/rotating_object: 116.1630
        Episode_Reward/action_rate: -0.1789
          Episode_Reward/joint_vel: -0.0594
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.98s
                      Time elapsed: 01:05:20
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 49228 steps/s (collection: 1.878s, learning 0.119s)
             Mean action noise std: 5.16
          Mean value_function loss: 101.4334
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 93.0832
                       Mean reward: 567.49
               Mean episode length: 218.64
    Episode_Reward/reaching_object: 1.2836
    Episode_Reward/rotating_object: 111.4667
        Episode_Reward/action_rate: -0.1773
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.00s
                      Time elapsed: 01:05:22
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 49651 steps/s (collection: 1.863s, learning 0.117s)
             Mean action noise std: 5.16
          Mean value_function loss: 95.4837
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 93.0961
                       Mean reward: 529.35
               Mean episode length: 215.23
    Episode_Reward/reaching_object: 1.3105
    Episode_Reward/rotating_object: 114.8452
        Episode_Reward/action_rate: -0.1810
          Episode_Reward/joint_vel: -0.0630
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.98s
                      Time elapsed: 01:05:24
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 50572 steps/s (collection: 1.846s, learning 0.098s)
             Mean action noise std: 5.16
          Mean value_function loss: 108.0058
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 93.1117
                       Mean reward: 603.00
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 1.2790
    Episode_Reward/rotating_object: 112.7294
        Episode_Reward/action_rate: -0.1764
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.94s
                      Time elapsed: 01:05:25
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 50224 steps/s (collection: 1.862s, learning 0.096s)
             Mean action noise std: 5.17
          Mean value_function loss: 97.6828
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 93.1306
                       Mean reward: 599.19
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.3150
    Episode_Reward/rotating_object: 112.9311
        Episode_Reward/action_rate: -0.1819
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.96s
                      Time elapsed: 01:05:27
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 51194 steps/s (collection: 1.827s, learning 0.094s)
             Mean action noise std: 5.17
          Mean value_function loss: 105.1789
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 93.1468
                       Mean reward: 537.62
               Mean episode length: 214.60
    Episode_Reward/reaching_object: 1.2982
    Episode_Reward/rotating_object: 113.4938
        Episode_Reward/action_rate: -0.1801
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.92s
                      Time elapsed: 01:05:29
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 50133 steps/s (collection: 1.862s, learning 0.099s)
             Mean action noise std: 5.17
          Mean value_function loss: 101.5155
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 93.1545
                       Mean reward: 571.95
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 1.2963
    Episode_Reward/rotating_object: 114.3991
        Episode_Reward/action_rate: -0.1804
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.96s
                      Time elapsed: 01:05:31
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 50348 steps/s (collection: 1.850s, learning 0.102s)
             Mean action noise std: 5.17
          Mean value_function loss: 98.2597
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 93.1679
                       Mean reward: 574.94
               Mean episode length: 214.27
    Episode_Reward/reaching_object: 1.2924
    Episode_Reward/rotating_object: 115.8046
        Episode_Reward/action_rate: -0.1792
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.95s
                      Time elapsed: 01:05:33
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 49952 steps/s (collection: 1.868s, learning 0.100s)
             Mean action noise std: 5.18
          Mean value_function loss: 105.3429
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.1773
                       Mean reward: 575.38
               Mean episode length: 217.54
    Episode_Reward/reaching_object: 1.2853
    Episode_Reward/rotating_object: 115.3976
        Episode_Reward/action_rate: -0.1788
          Episode_Reward/joint_vel: -0.0625
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.97s
                      Time elapsed: 01:05:35
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 50737 steps/s (collection: 1.837s, learning 0.101s)
             Mean action noise std: 5.18
          Mean value_function loss: 102.1830
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 93.1892
                       Mean reward: 583.98
               Mean episode length: 224.36
    Episode_Reward/reaching_object: 1.3113
    Episode_Reward/rotating_object: 117.4981
        Episode_Reward/action_rate: -0.1830
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.94s
                      Time elapsed: 01:05:37
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 50716 steps/s (collection: 1.837s, learning 0.101s)
             Mean action noise std: 5.18
          Mean value_function loss: 101.0205
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.2055
                       Mean reward: 611.22
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.3315
    Episode_Reward/rotating_object: 117.4605
        Episode_Reward/action_rate: -0.1839
          Episode_Reward/joint_vel: -0.0622
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.94s
                      Time elapsed: 01:05:39
                               ETA: 00:02:55

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 51442 steps/s (collection: 1.801s, learning 0.110s)
             Mean action noise std: 5.18
          Mean value_function loss: 110.0784
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 93.2174
                       Mean reward: 591.75
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 1.3009
    Episode_Reward/rotating_object: 117.8743
        Episode_Reward/action_rate: -0.1818
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.91s
                      Time elapsed: 01:05:41
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 48231 steps/s (collection: 1.925s, learning 0.114s)
             Mean action noise std: 5.19
          Mean value_function loss: 111.4572
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 93.2280
                       Mean reward: 563.57
               Mean episode length: 217.10
    Episode_Reward/reaching_object: 1.2879
    Episode_Reward/rotating_object: 114.7497
        Episode_Reward/action_rate: -0.1796
          Episode_Reward/joint_vel: -0.0629
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.04s
                      Time elapsed: 01:05:43
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 50584 steps/s (collection: 1.844s, learning 0.100s)
             Mean action noise std: 5.19
          Mean value_function loss: 98.5126
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 93.2403
                       Mean reward: 546.67
               Mean episode length: 222.28
    Episode_Reward/reaching_object: 1.2774
    Episode_Reward/rotating_object: 112.2675
        Episode_Reward/action_rate: -0.1805
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.94s
                      Time elapsed: 01:05:45
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 50509 steps/s (collection: 1.848s, learning 0.099s)
             Mean action noise std: 5.19
          Mean value_function loss: 99.2816
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 93.2539
                       Mean reward: 571.15
               Mean episode length: 221.78
    Episode_Reward/reaching_object: 1.2990
    Episode_Reward/rotating_object: 116.1415
        Episode_Reward/action_rate: -0.1816
          Episode_Reward/joint_vel: -0.0615
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.95s
                      Time elapsed: 01:05:47
                               ETA: 00:02:44

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 50551 steps/s (collection: 1.819s, learning 0.126s)
             Mean action noise std: 5.19
          Mean value_function loss: 98.1471
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 93.2741
                       Mean reward: 540.50
               Mean episode length: 224.88
    Episode_Reward/reaching_object: 1.3152
    Episode_Reward/rotating_object: 114.9546
        Episode_Reward/action_rate: -0.1821
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.94s
                      Time elapsed: 01:05:49
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 49983 steps/s (collection: 1.849s, learning 0.118s)
             Mean action noise std: 5.20
          Mean value_function loss: 107.0498
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 93.2944
                       Mean reward: 569.61
               Mean episode length: 223.79
    Episode_Reward/reaching_object: 1.3044
    Episode_Reward/rotating_object: 115.4294
        Episode_Reward/action_rate: -0.1828
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.97s
                      Time elapsed: 01:05:51
                               ETA: 00:02:38

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 49536 steps/s (collection: 1.861s, learning 0.123s)
             Mean action noise std: 5.20
          Mean value_function loss: 109.4082
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 93.3184
                       Mean reward: 521.10
               Mean episode length: 210.97
    Episode_Reward/reaching_object: 1.2630
    Episode_Reward/rotating_object: 113.1983
        Episode_Reward/action_rate: -0.1783
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.98s
                      Time elapsed: 01:05:53
                               ETA: 00:02:36

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 47333 steps/s (collection: 1.913s, learning 0.164s)
             Mean action noise std: 5.21
          Mean value_function loss: 102.6471
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 93.3398
                       Mean reward: 558.00
               Mean episode length: 218.27
    Episode_Reward/reaching_object: 1.2957
    Episode_Reward/rotating_object: 115.8640
        Episode_Reward/action_rate: -0.1830
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.08s
                      Time elapsed: 01:05:55
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 50082 steps/s (collection: 1.862s, learning 0.101s)
             Mean action noise std: 5.21
          Mean value_function loss: 101.9550
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 93.3604
                       Mean reward: 607.05
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 1.3046
    Episode_Reward/rotating_object: 115.7432
        Episode_Reward/action_rate: -0.1839
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.96s
                      Time elapsed: 01:05:57
                               ETA: 00:02:30

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 50503 steps/s (collection: 1.847s, learning 0.099s)
             Mean action noise std: 5.21
          Mean value_function loss: 109.3350
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 93.3743
                       Mean reward: 572.07
               Mean episode length: 215.65
    Episode_Reward/reaching_object: 1.2562
    Episode_Reward/rotating_object: 115.9485
        Episode_Reward/action_rate: -0.1771
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.95s
                      Time elapsed: 01:05:59
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 51028 steps/s (collection: 1.830s, learning 0.097s)
             Mean action noise std: 5.22
          Mean value_function loss: 102.4297
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 93.3867
                       Mean reward: 625.36
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.3323
    Episode_Reward/rotating_object: 120.5074
        Episode_Reward/action_rate: -0.1875
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.93s
                      Time elapsed: 01:06:01
                               ETA: 00:02:24

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 51470 steps/s (collection: 1.806s, learning 0.104s)
             Mean action noise std: 5.22
          Mean value_function loss: 102.9916
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 93.4042
                       Mean reward: 553.83
               Mean episode length: 210.76
    Episode_Reward/reaching_object: 1.2812
    Episode_Reward/rotating_object: 112.6154
        Episode_Reward/action_rate: -0.1808
          Episode_Reward/joint_vel: -0.0635
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.91s
                      Time elapsed: 01:06:03
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 46980 steps/s (collection: 1.969s, learning 0.123s)
             Mean action noise std: 5.22
          Mean value_function loss: 102.3491
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 93.4182
                       Mean reward: 604.56
               Mean episode length: 223.08
    Episode_Reward/reaching_object: 1.3036
    Episode_Reward/rotating_object: 116.1227
        Episode_Reward/action_rate: -0.1851
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.09s
                      Time elapsed: 01:06:05
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 48037 steps/s (collection: 1.928s, learning 0.119s)
             Mean action noise std: 5.22
          Mean value_function loss: 97.0521
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 93.4264
                       Mean reward: 604.01
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 1.2936
    Episode_Reward/rotating_object: 117.4931
        Episode_Reward/action_rate: -0.1841
          Episode_Reward/joint_vel: -0.0632
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.05s
                      Time elapsed: 01:06:07
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 46953 steps/s (collection: 1.995s, learning 0.099s)
             Mean action noise std: 5.23
          Mean value_function loss: 98.4608
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 93.4459
                       Mean reward: 580.24
               Mean episode length: 222.04
    Episode_Reward/reaching_object: 1.3019
    Episode_Reward/rotating_object: 117.1620
        Episode_Reward/action_rate: -0.1836
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.09s
                      Time elapsed: 01:06:09
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 51032 steps/s (collection: 1.805s, learning 0.121s)
             Mean action noise std: 5.23
          Mean value_function loss: 100.2244
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 93.4587
                       Mean reward: 593.94
               Mean episode length: 225.00
    Episode_Reward/reaching_object: 1.3033
    Episode_Reward/rotating_object: 118.0213
        Episode_Reward/action_rate: -0.1861
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.93s
                      Time elapsed: 01:06:11
                               ETA: 00:02:11

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 50164 steps/s (collection: 1.847s, learning 0.113s)
             Mean action noise std: 5.23
          Mean value_function loss: 109.3412
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 93.4696
                       Mean reward: 546.10
               Mean episode length: 209.43
    Episode_Reward/reaching_object: 1.2677
    Episode_Reward/rotating_object: 112.4045
        Episode_Reward/action_rate: -0.1810
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.96s
                      Time elapsed: 01:06:13
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 50251 steps/s (collection: 1.848s, learning 0.108s)
             Mean action noise std: 5.23
          Mean value_function loss: 102.7763
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 93.4832
                       Mean reward: 596.49
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 1.3139
    Episode_Reward/rotating_object: 116.5270
        Episode_Reward/action_rate: -0.1860
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.96s
                      Time elapsed: 01:06:15
                               ETA: 00:02:05

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 51335 steps/s (collection: 1.823s, learning 0.092s)
             Mean action noise std: 5.24
          Mean value_function loss: 94.2614
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 93.4959
                       Mean reward: 594.17
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.2944
    Episode_Reward/rotating_object: 113.1929
        Episode_Reward/action_rate: -0.1846
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.91s
                      Time elapsed: 01:06:17
                               ETA: 00:02:02

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 49623 steps/s (collection: 1.866s, learning 0.115s)
             Mean action noise std: 5.24
          Mean value_function loss: 100.9606
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.5100
                       Mean reward: 625.11
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 1.3184
    Episode_Reward/rotating_object: 120.7501
        Episode_Reward/action_rate: -0.1872
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.98s
                      Time elapsed: 01:06:19
                               ETA: 00:02:00

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 50284 steps/s (collection: 1.841s, learning 0.114s)
             Mean action noise std: 5.24
          Mean value_function loss: 99.6381
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 93.5229
                       Mean reward: 565.28
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 1.3118
    Episode_Reward/rotating_object: 117.3276
        Episode_Reward/action_rate: -0.1867
          Episode_Reward/joint_vel: -0.0635
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.95s
                      Time elapsed: 01:06:21
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 50137 steps/s (collection: 1.846s, learning 0.115s)
             Mean action noise std: 5.24
          Mean value_function loss: 95.0716
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 93.5413
                       Mean reward: 619.42
               Mean episode length: 221.37
    Episode_Reward/reaching_object: 1.3311
    Episode_Reward/rotating_object: 120.5883
        Episode_Reward/action_rate: -0.1875
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.96s
                      Time elapsed: 01:06:23
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 50587 steps/s (collection: 1.848s, learning 0.095s)
             Mean action noise std: 5.25
          Mean value_function loss: 93.3051
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 93.5613
                       Mean reward: 589.30
               Mean episode length: 218.01
    Episode_Reward/reaching_object: 1.3332
    Episode_Reward/rotating_object: 118.6746
        Episode_Reward/action_rate: -0.1883
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.94s
                      Time elapsed: 01:06:25
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 50641 steps/s (collection: 1.852s, learning 0.089s)
             Mean action noise std: 5.25
          Mean value_function loss: 97.9336
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 93.5786
                       Mean reward: 611.34
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.3200
    Episode_Reward/rotating_object: 116.0981
        Episode_Reward/action_rate: -0.1869
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.94s
                      Time elapsed: 01:06:26
                               ETA: 00:01:49

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 50547 steps/s (collection: 1.838s, learning 0.107s)
             Mean action noise std: 5.25
          Mean value_function loss: 99.2031
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 93.5914
                       Mean reward: 598.45
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 1.2996
    Episode_Reward/rotating_object: 120.5814
        Episode_Reward/action_rate: -0.1852
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.94s
                      Time elapsed: 01:06:28
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 49827 steps/s (collection: 1.867s, learning 0.106s)
             Mean action noise std: 5.25
          Mean value_function loss: 90.6305
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 93.5966
                       Mean reward: 598.89
               Mean episode length: 225.20
    Episode_Reward/reaching_object: 1.3317
    Episode_Reward/rotating_object: 121.3370
        Episode_Reward/action_rate: -0.1887
          Episode_Reward/joint_vel: -0.0625
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.97s
                      Time elapsed: 01:06:30
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 50699 steps/s (collection: 1.827s, learning 0.112s)
             Mean action noise std: 5.26
          Mean value_function loss: 107.4256
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 93.6075
                       Mean reward: 585.02
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 1.3343
    Episode_Reward/rotating_object: 117.8981
        Episode_Reward/action_rate: -0.1902
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.94s
                      Time elapsed: 01:06:32
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 49537 steps/s (collection: 1.889s, learning 0.095s)
             Mean action noise std: 5.26
          Mean value_function loss: 93.5678
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.6256
                       Mean reward: 587.76
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 1.2998
    Episode_Reward/rotating_object: 114.9776
        Episode_Reward/action_rate: -0.1847
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.98s
                      Time elapsed: 01:06:34
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 50246 steps/s (collection: 1.849s, learning 0.108s)
             Mean action noise std: 5.26
          Mean value_function loss: 101.7371
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.6438
                       Mean reward: 629.03
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 1.3397
    Episode_Reward/rotating_object: 122.8154
        Episode_Reward/action_rate: -0.1890
          Episode_Reward/joint_vel: -0.0611
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.96s
                      Time elapsed: 01:06:36
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 51237 steps/s (collection: 1.807s, learning 0.112s)
             Mean action noise std: 5.27
          Mean value_function loss: 97.2323
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 93.6589
                       Mean reward: 635.59
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.3624
    Episode_Reward/rotating_object: 123.0932
        Episode_Reward/action_rate: -0.1927
          Episode_Reward/joint_vel: -0.0618
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.92s
                      Time elapsed: 01:06:38
                               ETA: 00:01:32

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 51181 steps/s (collection: 1.822s, learning 0.099s)
             Mean action noise std: 5.27
          Mean value_function loss: 89.6820
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 93.6683
                       Mean reward: 590.50
               Mean episode length: 219.06
    Episode_Reward/reaching_object: 1.3049
    Episode_Reward/rotating_object: 119.6655
        Episode_Reward/action_rate: -0.1871
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.92s
                      Time elapsed: 01:06:40
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 50924 steps/s (collection: 1.830s, learning 0.100s)
             Mean action noise std: 5.27
          Mean value_function loss: 98.2542
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 93.6815
                       Mean reward: 616.41
               Mean episode length: 220.39
    Episode_Reward/reaching_object: 1.2785
    Episode_Reward/rotating_object: 119.6777
        Episode_Reward/action_rate: -0.1837
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.93s
                      Time elapsed: 01:06:42
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 51475 steps/s (collection: 1.811s, learning 0.098s)
             Mean action noise std: 5.28
          Mean value_function loss: 101.4550
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 93.6995
                       Mean reward: 614.98
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.3126
    Episode_Reward/rotating_object: 122.4429
        Episode_Reward/action_rate: -0.1881
          Episode_Reward/joint_vel: -0.0615
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.91s
                      Time elapsed: 01:06:44
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 50684 steps/s (collection: 1.839s, learning 0.101s)
             Mean action noise std: 5.28
          Mean value_function loss: 104.9011
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 93.7170
                       Mean reward: 628.52
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.3215
    Episode_Reward/rotating_object: 119.9055
        Episode_Reward/action_rate: -0.1890
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.94s
                      Time elapsed: 01:06:46
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 50829 steps/s (collection: 1.821s, learning 0.113s)
             Mean action noise std: 5.28
          Mean value_function loss: 96.6652
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 93.7260
                       Mean reward: 606.69
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 1.2769
    Episode_Reward/rotating_object: 113.9319
        Episode_Reward/action_rate: -0.1839
          Episode_Reward/joint_vel: -0.0613
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.93s
                      Time elapsed: 01:06:48
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 51134 steps/s (collection: 1.813s, learning 0.110s)
             Mean action noise std: 5.28
          Mean value_function loss: 91.2402
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 93.7331
                       Mean reward: 595.56
               Mean episode length: 228.99
    Episode_Reward/reaching_object: 1.3029
    Episode_Reward/rotating_object: 113.2364
        Episode_Reward/action_rate: -0.1871
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.92s
                      Time elapsed: 01:06:50
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 50447 steps/s (collection: 1.835s, learning 0.114s)
             Mean action noise std: 5.29
          Mean value_function loss: 85.2768
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 93.7439
                       Mean reward: 608.90
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.3612
    Episode_Reward/rotating_object: 122.3153
        Episode_Reward/action_rate: -0.1941
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.95s
                      Time elapsed: 01:06:52
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 49503 steps/s (collection: 1.871s, learning 0.115s)
             Mean action noise std: 5.29
          Mean value_function loss: 94.3671
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 93.7587
                       Mean reward: 599.81
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.3476
    Episode_Reward/rotating_object: 120.3891
        Episode_Reward/action_rate: -0.1920
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.99s
                      Time elapsed: 01:06:54
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 48664 steps/s (collection: 1.920s, learning 0.100s)
             Mean action noise std: 5.29
          Mean value_function loss: 101.2053
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 93.7726
                       Mean reward: 612.75
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 1.3277
    Episode_Reward/rotating_object: 117.8162
        Episode_Reward/action_rate: -0.1893
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.02s
                      Time elapsed: 01:06:56
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 50022 steps/s (collection: 1.866s, learning 0.100s)
             Mean action noise std: 5.29
          Mean value_function loss: 100.4161
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 93.7877
                       Mean reward: 616.51
               Mean episode length: 223.59
    Episode_Reward/reaching_object: 1.3030
    Episode_Reward/rotating_object: 119.1370
        Episode_Reward/action_rate: -0.1873
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.97s
                      Time elapsed: 01:06:58
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 48155 steps/s (collection: 1.948s, learning 0.094s)
             Mean action noise std: 5.30
          Mean value_function loss: 97.7163
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 93.8085
                       Mean reward: 588.69
               Mean episode length: 221.27
    Episode_Reward/reaching_object: 1.3176
    Episode_Reward/rotating_object: 121.5527
        Episode_Reward/action_rate: -0.1906
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.04s
                      Time elapsed: 01:07:00
                               ETA: 00:01:02

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 50954 steps/s (collection: 1.837s, learning 0.093s)
             Mean action noise std: 5.30
          Mean value_function loss: 87.5656
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 93.8199
                       Mean reward: 576.42
               Mean episode length: 216.06
    Episode_Reward/reaching_object: 1.3205
    Episode_Reward/rotating_object: 118.6354
        Episode_Reward/action_rate: -0.1922
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.93s
                      Time elapsed: 01:07:02
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 50773 steps/s (collection: 1.842s, learning 0.095s)
             Mean action noise std: 5.30
          Mean value_function loss: 94.4355
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 93.8283
                       Mean reward: 591.80
               Mean episode length: 225.00
    Episode_Reward/reaching_object: 1.3348
    Episode_Reward/rotating_object: 123.4567
        Episode_Reward/action_rate: -0.1924
          Episode_Reward/joint_vel: -0.0609
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.94s
                      Time elapsed: 01:07:04
                               ETA: 00:00:57

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 51099 steps/s (collection: 1.830s, learning 0.094s)
             Mean action noise std: 5.30
          Mean value_function loss: 95.1316
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.8405
                       Mean reward: 600.45
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 1.3265
    Episode_Reward/rotating_object: 120.5926
        Episode_Reward/action_rate: -0.1918
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.92s
                      Time elapsed: 01:07:05
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 48392 steps/s (collection: 1.933s, learning 0.098s)
             Mean action noise std: 5.31
          Mean value_function loss: 100.0868
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 93.8496
                       Mean reward: 589.11
               Mean episode length: 224.62
    Episode_Reward/reaching_object: 1.3348
    Episode_Reward/rotating_object: 117.5562
        Episode_Reward/action_rate: -0.1919
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.03s
                      Time elapsed: 01:07:08
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 50132 steps/s (collection: 1.848s, learning 0.112s)
             Mean action noise std: 5.31
          Mean value_function loss: 104.3535
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 93.8610
                       Mean reward: 617.47
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.3368
    Episode_Reward/rotating_object: 122.7619
        Episode_Reward/action_rate: -0.1920
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.96s
                      Time elapsed: 01:07:09
                               ETA: 00:00:48

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 50253 steps/s (collection: 1.846s, learning 0.110s)
             Mean action noise std: 5.31
          Mean value_function loss: 94.2480
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.8688
                       Mean reward: 597.17
               Mean episode length: 223.43
    Episode_Reward/reaching_object: 1.2999
    Episode_Reward/rotating_object: 118.2855
        Episode_Reward/action_rate: -0.1891
          Episode_Reward/joint_vel: -0.0635
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.96s
                      Time elapsed: 01:07:11
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 47479 steps/s (collection: 1.902s, learning 0.168s)
             Mean action noise std: 5.32
          Mean value_function loss: 96.6185
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 93.8909
                       Mean reward: 595.15
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 1.3626
    Episode_Reward/rotating_object: 124.3929
        Episode_Reward/action_rate: -0.1969
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.07s
                      Time elapsed: 01:07:14
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 50325 steps/s (collection: 1.844s, learning 0.110s)
             Mean action noise std: 5.32
          Mean value_function loss: 93.8566
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 93.9132
                       Mean reward: 635.30
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 1.3236
    Episode_Reward/rotating_object: 119.7957
        Episode_Reward/action_rate: -0.1917
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.95s
                      Time elapsed: 01:07:15
                               ETA: 00:00:40

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 50985 steps/s (collection: 1.814s, learning 0.114s)
             Mean action noise std: 5.32
          Mean value_function loss: 96.0091
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 93.9286
                       Mean reward: 597.73
               Mean episode length: 219.85
    Episode_Reward/reaching_object: 1.3093
    Episode_Reward/rotating_object: 122.3856
        Episode_Reward/action_rate: -0.1913
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.93s
                      Time elapsed: 01:07:17
                               ETA: 00:00:38

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 50332 steps/s (collection: 1.850s, learning 0.103s)
             Mean action noise std: 5.32
          Mean value_function loss: 97.2155
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 93.9462
                       Mean reward: 620.02
               Mean episode length: 224.98
    Episode_Reward/reaching_object: 1.2944
    Episode_Reward/rotating_object: 118.6047
        Episode_Reward/action_rate: -0.1894
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.95s
                      Time elapsed: 01:07:19
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 50417 steps/s (collection: 1.851s, learning 0.099s)
             Mean action noise std: 5.33
          Mean value_function loss: 104.5664
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 93.9686
                       Mean reward: 592.30
               Mean episode length: 214.29
    Episode_Reward/reaching_object: 1.2961
    Episode_Reward/rotating_object: 114.9822
        Episode_Reward/action_rate: -0.1889
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.95s
                      Time elapsed: 01:07:21
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 49563 steps/s (collection: 1.876s, learning 0.107s)
             Mean action noise std: 5.33
          Mean value_function loss: 95.7083
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 93.9934
                       Mean reward: 650.16
               Mean episode length: 231.11
    Episode_Reward/reaching_object: 1.3233
    Episode_Reward/rotating_object: 122.1806
        Episode_Reward/action_rate: -0.1942
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.98s
                      Time elapsed: 01:07:23
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 50690 steps/s (collection: 1.837s, learning 0.102s)
             Mean action noise std: 5.34
          Mean value_function loss: 98.0408
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 94.0170
                       Mean reward: 596.95
               Mean episode length: 221.63
    Episode_Reward/reaching_object: 1.3214
    Episode_Reward/rotating_object: 119.7185
        Episode_Reward/action_rate: -0.1934
          Episode_Reward/joint_vel: -0.0605
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.94s
                      Time elapsed: 01:07:25
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 50553 steps/s (collection: 1.835s, learning 0.109s)
             Mean action noise std: 5.34
          Mean value_function loss: 100.7998
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 94.0343
                       Mean reward: 621.81
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 1.3265
    Episode_Reward/rotating_object: 118.3453
        Episode_Reward/action_rate: -0.1952
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.94s
                      Time elapsed: 01:07:27
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 51067 steps/s (collection: 1.817s, learning 0.108s)
             Mean action noise std: 5.34
          Mean value_function loss: 101.2018
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 94.0508
                       Mean reward: 585.05
               Mean episode length: 218.68
    Episode_Reward/reaching_object: 1.2853
    Episode_Reward/rotating_object: 116.8259
        Episode_Reward/action_rate: -0.1897
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.92s
                      Time elapsed: 01:07:29
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 50966 steps/s (collection: 1.826s, learning 0.103s)
             Mean action noise std: 5.34
          Mean value_function loss: 93.9464
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 94.0648
                       Mean reward: 606.46
               Mean episode length: 225.28
    Episode_Reward/reaching_object: 1.3186
    Episode_Reward/rotating_object: 119.9137
        Episode_Reward/action_rate: -0.1931
          Episode_Reward/joint_vel: -0.0613
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.93s
                      Time elapsed: 01:07:31
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 49896 steps/s (collection: 1.857s, learning 0.113s)
             Mean action noise std: 5.35
          Mean value_function loss: 97.3383
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 94.0766
                       Mean reward: 605.94
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.3350
    Episode_Reward/rotating_object: 122.1147
        Episode_Reward/action_rate: -0.1965
          Episode_Reward/joint_vel: -0.0625
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.97s
                      Time elapsed: 01:07:33
                               ETA: 00:00:16

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 49980 steps/s (collection: 1.872s, learning 0.095s)
             Mean action noise std: 5.35
          Mean value_function loss: 94.3659
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 94.0872
                       Mean reward: 572.63
               Mean episode length: 223.29
    Episode_Reward/reaching_object: 1.3235
    Episode_Reward/rotating_object: 118.4237
        Episode_Reward/action_rate: -0.1934
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.97s
                      Time elapsed: 01:07:35
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 49585 steps/s (collection: 1.864s, learning 0.119s)
             Mean action noise std: 5.35
          Mean value_function loss: 100.6012
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 94.0996
                       Mean reward: 607.30
               Mean episode length: 223.33
    Episode_Reward/reaching_object: 1.2935
    Episode_Reward/rotating_object: 117.2308
        Episode_Reward/action_rate: -0.1916
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.98s
                      Time elapsed: 01:07:37
                               ETA: 00:00:10

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 50145 steps/s (collection: 1.857s, learning 0.104s)
             Mean action noise std: 5.36
          Mean value_function loss: 94.2759
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 94.1212
                       Mean reward: 579.52
               Mean episode length: 218.94
    Episode_Reward/reaching_object: 1.3033
    Episode_Reward/rotating_object: 117.4562
        Episode_Reward/action_rate: -0.1921
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.96s
                      Time elapsed: 01:07:39
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 50353 steps/s (collection: 1.861s, learning 0.092s)
             Mean action noise std: 5.36
          Mean value_function loss: 86.4598
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 94.1350
                       Mean reward: 616.67
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 1.2930
    Episode_Reward/rotating_object: 117.9995
        Episode_Reward/action_rate: -0.1928
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.95s
                      Time elapsed: 01:07:41
                               ETA: 00:00:05

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 50133 steps/s (collection: 1.869s, learning 0.092s)
             Mean action noise std: 5.36
          Mean value_function loss: 84.8862
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 94.1474
                       Mean reward: 638.11
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 1.3154
    Episode_Reward/rotating_object: 124.5040
        Episode_Reward/action_rate: -0.1961
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.96s
                      Time elapsed: 01:07:43
                               ETA: 00:00:02

