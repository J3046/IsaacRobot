################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 9340 steps/s (collection: 10.234s, learning 0.290s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0036
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.0293
                       Mean reward: 0.00
               Mean episode length: 21.31
    Episode_Reward/reaching_object: 0.0011
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0005
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 10.52s
                      Time elapsed: 00:00:10
                               ETA: 04:23:07

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 14509 steps/s (collection: 6.632s, learning 0.143s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.1649
                       Mean reward: 0.00
               Mean episode length: 45.35
    Episode_Reward/reaching_object: 0.0030
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.78s
                      Time elapsed: 00:00:17
                               ETA: 03:36:06

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14320 steps/s (collection: 6.671s, learning 0.193s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.2622
                       Mean reward: 0.01
               Mean episode length: 69.71
    Episode_Reward/reaching_object: 0.0048
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0023
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.86s
                      Time elapsed: 00:00:24
                               ETA: 03:21:06

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14430 steps/s (collection: 6.649s, learning 0.164s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.3195
                       Mean reward: 0.01
               Mean episode length: 93.33
    Episode_Reward/reaching_object: 0.0069
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0021
          Episode_Reward/joint_vel: -0.0032
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.81s
                      Time elapsed: 00:00:30
                               ETA: 03:13:12

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14005 steps/s (collection: 6.861s, learning 0.158s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.3584
                       Mean reward: 0.01
               Mean episode length: 117.98
    Episode_Reward/reaching_object: 0.0088
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0027
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 7.02s
                      Time elapsed: 00:00:37
                               ETA: 03:09:28

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 14123 steps/s (collection: 6.778s, learning 0.183s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.3976
                       Mean reward: 0.00
               Mean episode length: 141.18
    Episode_Reward/reaching_object: 0.0100
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.96s
                      Time elapsed: 00:00:44
                               ETA: 03:06:41

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 14282 steps/s (collection: 6.742s, learning 0.141s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 44.4205
                       Mean reward: 0.01
               Mean episode length: 165.30
    Episode_Reward/reaching_object: 0.0116
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.88s
                      Time elapsed: 00:00:51
                               ETA: 03:04:23

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14671 steps/s (collection: 6.546s, learning 0.155s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 44.4332
                       Mean reward: 0.01
               Mean episode length: 189.28
    Episode_Reward/reaching_object: 0.0135
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.70s
                      Time elapsed: 00:00:58
                               ETA: 03:02:04

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 14264 steps/s (collection: 6.767s, learning 0.124s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.4567
                       Mean reward: 0.02
               Mean episode length: 213.34
    Episode_Reward/reaching_object: 0.0157
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 6.89s
                      Time elapsed: 00:01:05
                               ETA: 03:00:46

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 45584 steps/s (collection: 1.974s, learning 0.182s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 44.4641
                       Mean reward: 0.01
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.0183
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 2.16s
                      Time elapsed: 00:01:07
                               ETA: 02:47:57

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 45170 steps/s (collection: 2.044s, learning 0.132s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 44.4473
                       Mean reward: 0.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0203
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 2.18s
                      Time elapsed: 00:01:09
                               ETA: 02:37:29

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 48953 steps/s (collection: 1.823s, learning 0.185s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 44.4504
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0216
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 2.01s
                      Time elapsed: 00:01:11
                               ETA: 02:28:25

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 50090 steps/s (collection: 1.840s, learning 0.123s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 44.4553
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0252
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.96s
                      Time elapsed: 00:01:13
                               ETA: 02:20:39

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 52209 steps/s (collection: 1.782s, learning 0.101s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 44.4883
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0284
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.88s
                      Time elapsed: 00:01:15
                               ETA: 02:13:51

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 45246 steps/s (collection: 2.022s, learning 0.151s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 44.5321
                       Mean reward: 0.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0326
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 2.17s
                      Time elapsed: 00:01:17
                               ETA: 02:08:26

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 50919 steps/s (collection: 1.765s, learning 0.166s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 44.6004
                       Mean reward: 0.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0388
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.93s
                      Time elapsed: 00:01:19
                               ETA: 02:03:19

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 54103 steps/s (collection: 1.723s, learning 0.094s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 44.6713
                       Mean reward: 0.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0488
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.82s
                      Time elapsed: 00:01:21
                               ETA: 01:58:37

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 55778 steps/s (collection: 1.581s, learning 0.181s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 44.7394
                       Mean reward: 0.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0621
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.76s
                      Time elapsed: 00:01:23
                               ETA: 01:54:22

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 56227 steps/s (collection: 1.631s, learning 0.117s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0009
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 44.7919
                       Mean reward: 0.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0884
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.75s
                      Time elapsed: 00:01:25
                               ETA: 01:50:33

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 56526 steps/s (collection: 1.642s, learning 0.097s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0014
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 44.8708
                       Mean reward: 0.62
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1150
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.74s
                      Time elapsed: 00:01:26
                               ETA: 01:47:06

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 54701 steps/s (collection: 1.701s, learning 0.096s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0024
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 44.9319
                       Mean reward: 0.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1473
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.80s
                      Time elapsed: 00:01:28
                               ETA: 01:44:03

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 54348 steps/s (collection: 1.688s, learning 0.121s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0036
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 45.0083
                       Mean reward: 1.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1937
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.81s
                      Time elapsed: 00:01:30
                               ETA: 01:41:16

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 51933 steps/s (collection: 1.771s, learning 0.122s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0051
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 45.1141
                       Mean reward: 1.23
               Mean episode length: 249.73
    Episode_Reward/reaching_object: 0.2380
    Episode_Reward/rotating_object: 0.0012
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.89s
                      Time elapsed: 00:01:32
                               ETA: 01:38:50

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 51024 steps/s (collection: 1.803s, learning 0.124s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0077
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 45.1904
                       Mean reward: 1.67
               Mean episode length: 248.74
    Episode_Reward/reaching_object: 0.3131
    Episode_Reward/rotating_object: 0.0014
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.93s
                      Time elapsed: 00:01:34
                               ETA: 01:36:37

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 51232 steps/s (collection: 1.814s, learning 0.105s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0111
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 45.2644
                       Mean reward: 1.81
               Mean episode length: 246.36
    Episode_Reward/reaching_object: 0.3458
    Episode_Reward/rotating_object: 0.0042
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.92s
                      Time elapsed: 00:01:36
                               ETA: 01:34:35

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 48824 steps/s (collection: 1.892s, learning 0.122s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0148
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 45.3470
                       Mean reward: 2.06
               Mean episode length: 239.06
    Episode_Reward/reaching_object: 0.4227
    Episode_Reward/rotating_object: 0.0139
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.01s
                      Time elapsed: 00:01:38
                               ETA: 01:32:47

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 47896 steps/s (collection: 1.934s, learning 0.119s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0177
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 45.4407
                       Mean reward: 2.64
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 0.4756
    Episode_Reward/rotating_object: 0.0114
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 10.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.05s
                      Time elapsed: 00:01:40
                               ETA: 01:31:10

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 48901 steps/s (collection: 1.887s, learning 0.123s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0266
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 45.5114
                       Mean reward: 2.60
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 0.5154
    Episode_Reward/rotating_object: 0.0224
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 8.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.01s
                      Time elapsed: 00:01:42
                               ETA: 01:29:36

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 49540 steps/s (collection: 1.879s, learning 0.105s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0432
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 45.6021
                       Mean reward: 2.79
               Mean episode length: 216.96
    Episode_Reward/reaching_object: 0.5199
    Episode_Reward/rotating_object: 0.0358
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 6.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 17.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.98s
                      Time elapsed: 00:01:44
                               ETA: 01:28:08

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 48230 steps/s (collection: 1.941s, learning 0.097s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.2198
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 45.7455
                       Mean reward: 2.80
               Mean episode length: 213.21
    Episode_Reward/reaching_object: 0.5471
    Episode_Reward/rotating_object: 0.0319
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 4.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 18.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.04s
                      Time elapsed: 00:01:46
                               ETA: 01:26:48

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 48916 steps/s (collection: 1.886s, learning 0.124s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0513
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.7874
                       Mean reward: 3.51
               Mean episode length: 205.07
    Episode_Reward/reaching_object: 0.5687
    Episode_Reward/rotating_object: 0.0554
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 2.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 18.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.01s
                      Time elapsed: 00:01:48
                               ETA: 01:25:32

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 49130 steps/s (collection: 1.877s, learning 0.124s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1023
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.8779
                       Mean reward: 3.69
               Mean episode length: 204.99
    Episode_Reward/reaching_object: 0.5917
    Episode_Reward/rotating_object: 0.0798
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 1.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.00s
                      Time elapsed: 00:01:50
                               ETA: 01:24:20

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 47420 steps/s (collection: 1.954s, learning 0.119s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0539
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 46.0579
                       Mean reward: 3.38
               Mean episode length: 199.24
    Episode_Reward/reaching_object: 0.6138
    Episode_Reward/rotating_object: 0.0701
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 1.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.07s
                      Time elapsed: 00:01:52
                               ETA: 01:23:16

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 47948 steps/s (collection: 1.927s, learning 0.123s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0478
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 46.1784
                       Mean reward: 3.49
               Mean episode length: 203.76
    Episode_Reward/reaching_object: 0.6716
    Episode_Reward/rotating_object: 0.0673
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 1.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.05s
                      Time elapsed: 00:01:54
                               ETA: 01:22:14

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 47115 steps/s (collection: 1.966s, learning 0.120s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0714
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 46.3333
                       Mean reward: 4.21
               Mean episode length: 206.51
    Episode_Reward/reaching_object: 0.7211
    Episode_Reward/rotating_object: 0.0862
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 2.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.09s
                      Time elapsed: 00:01:56
                               ETA: 01:21:17

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 46852 steps/s (collection: 1.983s, learning 0.116s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.1661
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.4819
                       Mean reward: 4.55
               Mean episode length: 213.24
    Episode_Reward/reaching_object: 0.7355
    Episode_Reward/rotating_object: 0.1292
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 2.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.2083
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.10s
                      Time elapsed: 00:01:58
                               ETA: 01:20:24

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 47434 steps/s (collection: 1.949s, learning 0.123s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.2164
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.5835
                       Mean reward: 5.28
               Mean episode length: 222.73
    Episode_Reward/reaching_object: 0.8162
    Episode_Reward/rotating_object: 0.1663
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 4.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.07s
                      Time elapsed: 00:02:00
                               ETA: 01:19:32

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 44392 steps/s (collection: 2.114s, learning 0.100s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.2233
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.7097
                       Mean reward: 5.78
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 0.8573
    Episode_Reward/rotating_object: 0.2608
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 6.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 8.7500
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.21s
                      Time elapsed: 00:02:02
                               ETA: 01:18:49

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 47774 steps/s (collection: 1.962s, learning 0.096s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.4434
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.9199
                       Mean reward: 5.83
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 0.8965
    Episode_Reward/rotating_object: 0.1731
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 10.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.06s
                      Time elapsed: 00:02:04
                               ETA: 01:18:01

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 47062 steps/s (collection: 1.973s, learning 0.116s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.5620
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 47.0397
                       Mean reward: 6.87
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.9630
    Episode_Reward/rotating_object: 0.3869
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.09s
                      Time elapsed: 00:02:06
                               ETA: 01:17:18

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 48119 steps/s (collection: 1.928s, learning 0.115s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.5508
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.1091
                       Mean reward: 5.95
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 0.9497
    Episode_Reward/rotating_object: 0.2195
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.04s
                      Time elapsed: 00:02:09
                               ETA: 01:16:34

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 48065 steps/s (collection: 1.932s, learning 0.113s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.5274
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.2927
                       Mean reward: 6.61
               Mean episode length: 247.23
    Episode_Reward/reaching_object: 0.9339
    Episode_Reward/rotating_object: 0.5543
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.05s
                      Time elapsed: 00:02:11
                               ETA: 01:15:53

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 47571 steps/s (collection: 1.956s, learning 0.111s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.4942
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.4710
                       Mean reward: 7.39
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 0.9695
    Episode_Reward/rotating_object: 0.4987
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.07s
                      Time elapsed: 00:02:13
                               ETA: 01:15:14

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 45342 steps/s (collection: 2.042s, learning 0.126s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.3984
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.6638
                       Mean reward: 6.78
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.9742
    Episode_Reward/rotating_object: 0.3752
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.17s
                      Time elapsed: 00:02:15
                               ETA: 01:14:40

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 42598 steps/s (collection: 2.188s, learning 0.120s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.4578
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.8205
                       Mean reward: 6.75
               Mean episode length: 245.08
    Episode_Reward/reaching_object: 0.9033
    Episode_Reward/rotating_object: 0.2764
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.31s
                      Time elapsed: 00:02:17
                               ETA: 01:14:12

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 46436 steps/s (collection: 2.002s, learning 0.115s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.6121
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.0025
                       Mean reward: 8.47
               Mean episode length: 246.83
    Episode_Reward/reaching_object: 0.9672
    Episode_Reward/rotating_object: 0.3804
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.12s
                      Time elapsed: 00:02:19
                               ETA: 01:13:39

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 46199 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.7565
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.1493
                       Mean reward: 7.82
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 0.9869
    Episode_Reward/rotating_object: 0.5268
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.13s
                      Time elapsed: 00:02:21
                               ETA: 01:13:08

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 46162 steps/s (collection: 2.004s, learning 0.126s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.7247
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.3272
                       Mean reward: 5.44
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 0.9540
    Episode_Reward/rotating_object: 0.5600
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.13s
                      Time elapsed: 00:02:23
                               ETA: 01:12:38

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 41514 steps/s (collection: 2.259s, learning 0.109s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.5705
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.4841
                       Mean reward: 10.08
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 1.0154
    Episode_Reward/rotating_object: 0.5311
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.37s
                      Time elapsed: 00:02:26
                               ETA: 01:12:16

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 45567 steps/s (collection: 2.039s, learning 0.118s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.6785
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.6574
                       Mean reward: 7.00
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 1.0261
    Episode_Reward/rotating_object: 0.5467
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.16s
                      Time elapsed: 00:02:28
                               ETA: 01:11:49

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 45986 steps/s (collection: 2.018s, learning 0.120s)
             Mean action noise std: 1.17
          Mean value_function loss: 0.8979
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.8241
                       Mean reward: 7.40
               Mean episode length: 246.45
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 0.5056
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.14s
                      Time elapsed: 00:02:30
                               ETA: 01:11:23

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 44730 steps/s (collection: 2.086s, learning 0.112s)
             Mean action noise std: 1.18
          Mean value_function loss: 0.6562
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.9335
                       Mean reward: 7.98
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 1.0493
    Episode_Reward/rotating_object: 0.6645
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.20s
                      Time elapsed: 00:02:32
                               ETA: 01:10:59

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 46587 steps/s (collection: 1.991s, learning 0.119s)
             Mean action noise std: 1.18
          Mean value_function loss: 0.5260
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.1163
                       Mean reward: 6.84
               Mean episode length: 247.05
    Episode_Reward/reaching_object: 1.0671
    Episode_Reward/rotating_object: 0.5430
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.11s
                      Time elapsed: 00:02:34
                               ETA: 01:10:33

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 43494 steps/s (collection: 2.140s, learning 0.121s)
             Mean action noise std: 1.19
          Mean value_function loss: 0.6398
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.2416
                       Mean reward: 8.22
               Mean episode length: 244.44
    Episode_Reward/reaching_object: 1.0764
    Episode_Reward/rotating_object: 0.4504
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.26s
                      Time elapsed: 00:02:37
                               ETA: 01:10:12

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 46686 steps/s (collection: 1.991s, learning 0.115s)
             Mean action noise std: 1.20
          Mean value_function loss: 0.5293
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.4372
                       Mean reward: 7.97
               Mean episode length: 247.07
    Episode_Reward/reaching_object: 1.1229
    Episode_Reward/rotating_object: 0.5377
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.11s
                      Time elapsed: 00:02:39
                               ETA: 01:09:48

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 46779 steps/s (collection: 1.976s, learning 0.126s)
             Mean action noise std: 1.20
          Mean value_function loss: 0.6776
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.5716
                       Mean reward: 10.76
               Mean episode length: 249.29
    Episode_Reward/reaching_object: 1.1456
    Episode_Reward/rotating_object: 0.9225
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.10s
                      Time elapsed: 00:02:41
                               ETA: 01:09:25

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 45852 steps/s (collection: 2.025s, learning 0.119s)
             Mean action noise std: 1.21
          Mean value_function loss: 0.6140
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.7247
                       Mean reward: 11.78
               Mean episode length: 247.27
    Episode_Reward/reaching_object: 1.1683
    Episode_Reward/rotating_object: 0.9296
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.14s
                      Time elapsed: 00:02:43
                               ETA: 01:09:03

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 47532 steps/s (collection: 1.949s, learning 0.120s)
             Mean action noise std: 1.21
          Mean value_function loss: 0.6375
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.8626
                       Mean reward: 8.90
               Mean episode length: 248.61
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 0.6250
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.07s
                      Time elapsed: 00:02:45
                               ETA: 01:08:40

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 46950 steps/s (collection: 1.960s, learning 0.134s)
             Mean action noise std: 1.22
          Mean value_function loss: 0.7845
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.9929
                       Mean reward: 9.22
               Mean episode length: 247.49
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 0.8243
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.09s
                      Time elapsed: 00:02:47
                               ETA: 01:08:19

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 46946 steps/s (collection: 1.977s, learning 0.117s)
             Mean action noise std: 1.22
          Mean value_function loss: 0.9621
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.0927
                       Mean reward: 8.69
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 1.1733
    Episode_Reward/rotating_object: 0.7263
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.09s
                      Time elapsed: 00:02:49
                               ETA: 01:07:58

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 47673 steps/s (collection: 1.949s, learning 0.113s)
             Mean action noise std: 1.23
          Mean value_function loss: 0.9389
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.2679
                       Mean reward: 9.74
               Mean episode length: 246.45
    Episode_Reward/reaching_object: 1.2274
    Episode_Reward/rotating_object: 0.9477
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.06s
                      Time elapsed: 00:02:51
                               ETA: 01:07:37

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 47459 steps/s (collection: 1.955s, learning 0.117s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.2914
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.4108
                       Mean reward: 11.44
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 1.0291
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.07s
                      Time elapsed: 00:02:53
                               ETA: 01:07:17

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 47446 steps/s (collection: 1.974s, learning 0.098s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.2580
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 50.4913
                       Mean reward: 10.84
               Mean episode length: 247.24
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 1.1354
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.07s
                      Time elapsed: 00:02:56
                               ETA: 01:06:57

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 47249 steps/s (collection: 1.971s, learning 0.110s)
             Mean action noise std: 1.24
          Mean value_function loss: 1.1494
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.5905
                       Mean reward: 9.07
               Mean episode length: 247.06
    Episode_Reward/reaching_object: 1.2410
    Episode_Reward/rotating_object: 0.9913
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.08s
                      Time elapsed: 00:02:58
                               ETA: 01:06:39

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 47508 steps/s (collection: 1.959s, learning 0.110s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.1346
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.7411
                       Mean reward: 9.27
               Mean episode length: 249.45
    Episode_Reward/reaching_object: 1.1995
    Episode_Reward/rotating_object: 0.7171
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.07s
                      Time elapsed: 00:03:00
                               ETA: 01:06:20

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 41744 steps/s (collection: 2.241s, learning 0.114s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.3199
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.8492
                       Mean reward: 9.61
               Mean episode length: 247.52
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 0.8975
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.35s
                      Time elapsed: 00:03:02
                               ETA: 01:06:08

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 46873 steps/s (collection: 1.976s, learning 0.121s)
             Mean action noise std: 1.25
          Mean value_function loss: 1.0727
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 50.9627
                       Mean reward: 18.41
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 1.7164
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.10s
                      Time elapsed: 00:03:04
                               ETA: 01:05:51

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 46422 steps/s (collection: 2.004s, learning 0.114s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.2056
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 51.0283
                       Mean reward: 11.38
               Mean episode length: 248.86
    Episode_Reward/reaching_object: 1.2427
    Episode_Reward/rotating_object: 1.0753
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.12s
                      Time elapsed: 00:03:06
                               ETA: 01:05:35

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 47024 steps/s (collection: 1.962s, learning 0.128s)
             Mean action noise std: 1.26
          Mean value_function loss: 1.0374
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.1160
                       Mean reward: 11.89
               Mean episode length: 248.92
    Episode_Reward/reaching_object: 1.2680
    Episode_Reward/rotating_object: 1.2745
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.09s
                      Time elapsed: 00:03:08
                               ETA: 01:05:19

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 44846 steps/s (collection: 2.078s, learning 0.114s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.2264
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.2532
                       Mean reward: 11.75
               Mean episode length: 246.24
    Episode_Reward/reaching_object: 1.2575
    Episode_Reward/rotating_object: 1.2566
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.19s
                      Time elapsed: 00:03:11
                               ETA: 01:05:05

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 45858 steps/s (collection: 2.021s, learning 0.123s)
             Mean action noise std: 1.27
          Mean value_function loss: 1.0654
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 51.4103
                       Mean reward: 13.91
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 1.2591
    Episode_Reward/rotating_object: 1.2199
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.14s
                      Time elapsed: 00:03:13
                               ETA: 01:04:50

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 43258 steps/s (collection: 2.155s, learning 0.118s)
             Mean action noise std: 1.28
          Mean value_function loss: 1.1759
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.5157
                       Mean reward: 11.45
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 1.2412
    Episode_Reward/rotating_object: 0.8885
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.27s
                      Time elapsed: 00:03:15
                               ETA: 01:04:39

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 46972 steps/s (collection: 1.968s, learning 0.125s)
             Mean action noise std: 1.28
          Mean value_function loss: 1.1737
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.6524
                       Mean reward: 12.19
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 1.2611
    Episode_Reward/rotating_object: 1.0533
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.09s
                      Time elapsed: 00:03:17
                               ETA: 01:04:24

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 46759 steps/s (collection: 1.979s, learning 0.123s)
             Mean action noise std: 1.29
          Mean value_function loss: 1.0742
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.7545
                       Mean reward: 15.63
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 1.2703
    Episode_Reward/rotating_object: 1.4424
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.10s
                      Time elapsed: 00:03:19
                               ETA: 01:04:09

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 45579 steps/s (collection: 2.046s, learning 0.111s)
             Mean action noise std: 1.29
          Mean value_function loss: 1.1473
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.8270
                       Mean reward: 12.05
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 1.2312
    Episode_Reward/rotating_object: 0.8977
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.16s
                      Time elapsed: 00:03:21
                               ETA: 01:03:56

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 46396 steps/s (collection: 1.996s, learning 0.123s)
             Mean action noise std: 1.30
          Mean value_function loss: 1.3327
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.9515
                       Mean reward: 11.23
               Mean episode length: 246.42
    Episode_Reward/reaching_object: 1.2698
    Episode_Reward/rotating_object: 0.9668
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.12s
                      Time elapsed: 00:03:23
                               ETA: 01:03:43

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 43718 steps/s (collection: 2.136s, learning 0.113s)
             Mean action noise std: 1.30
          Mean value_function loss: 1.5994
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.0642
                       Mean reward: 8.88
               Mean episode length: 247.50
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 1.1847
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.25s
                      Time elapsed: 00:03:26
                               ETA: 01:03:32

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 46369 steps/s (collection: 2.007s, learning 0.113s)
             Mean action noise std: 1.31
          Mean value_function loss: 1.8595
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.1650
                       Mean reward: 10.19
               Mean episode length: 247.22
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 1.2562
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.12s
                      Time elapsed: 00:03:28
                               ETA: 01:03:19

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 46792 steps/s (collection: 1.985s, learning 0.116s)
             Mean action noise std: 1.31
          Mean value_function loss: 1.6710
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.3152
                       Mean reward: 12.50
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.2845
    Episode_Reward/rotating_object: 1.4826
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.10s
                      Time elapsed: 00:03:30
                               ETA: 01:03:06

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 47072 steps/s (collection: 1.974s, learning 0.115s)
             Mean action noise std: 1.32
          Mean value_function loss: 1.5254
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.4218
                       Mean reward: 11.02
               Mean episode length: 239.79
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 1.7054
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.09s
                      Time elapsed: 00:03:32
                               ETA: 01:02:54

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 46570 steps/s (collection: 1.988s, learning 0.123s)
             Mean action noise std: 1.32
          Mean value_function loss: 1.2948
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 52.5357
                       Mean reward: 12.41
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 1.2388
    Episode_Reward/rotating_object: 1.3012
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.11s
                      Time elapsed: 00:03:34
                               ETA: 01:02:41

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 46253 steps/s (collection: 1.995s, learning 0.131s)
             Mean action noise std: 1.32
          Mean value_function loss: 1.1078
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 52.6391
                       Mean reward: 14.15
               Mean episode length: 249.43
    Episode_Reward/reaching_object: 1.2578
    Episode_Reward/rotating_object: 1.2929
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.13s
                      Time elapsed: 00:03:36
                               ETA: 01:02:30

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 46178 steps/s (collection: 2.003s, learning 0.126s)
             Mean action noise std: 1.33
          Mean value_function loss: 1.3709
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.7300
                       Mean reward: 11.85
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 1.1280
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.13s
                      Time elapsed: 00:03:38
                               ETA: 01:02:18

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 46394 steps/s (collection: 1.999s, learning 0.120s)
             Mean action noise std: 1.33
          Mean value_function loss: 1.4709
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.8514
                       Mean reward: 11.84
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 1.1307
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.12s
                      Time elapsed: 00:03:40
                               ETA: 01:02:07

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 46402 steps/s (collection: 2.004s, learning 0.114s)
             Mean action noise std: 1.34
          Mean value_function loss: 1.7713
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 52.9504
                       Mean reward: 14.73
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 1.2675
    Episode_Reward/rotating_object: 2.0343
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.12s
                      Time elapsed: 00:03:43
                               ETA: 01:01:56

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 46062 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 1.34
          Mean value_function loss: 1.8042
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.0729
                       Mean reward: 16.07
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 1.2693
    Episode_Reward/rotating_object: 1.5375
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.13s
                      Time elapsed: 00:03:45
                               ETA: 01:01:45

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 47237 steps/s (collection: 1.965s, learning 0.117s)
             Mean action noise std: 1.35
          Mean value_function loss: 1.8436
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 53.1711
                       Mean reward: 20.54
               Mean episode length: 244.97
    Episode_Reward/reaching_object: 1.2967
    Episode_Reward/rotating_object: 1.5749
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.08s
                      Time elapsed: 00:03:47
                               ETA: 01:01:34

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 46196 steps/s (collection: 2.006s, learning 0.122s)
             Mean action noise std: 1.35
          Mean value_function loss: 1.6498
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 53.2910
                       Mean reward: 12.68
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.2297
    Episode_Reward/rotating_object: 1.5762
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.13s
                      Time elapsed: 00:03:49
                               ETA: 01:01:23

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 47157 steps/s (collection: 1.973s, learning 0.112s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.2261
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.3652
                       Mean reward: 15.72
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.2648
    Episode_Reward/rotating_object: 1.6362
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.08s
                      Time elapsed: 00:03:51
                               ETA: 01:01:12

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 46916 steps/s (collection: 1.984s, learning 0.111s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.0547
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.4274
                       Mean reward: 15.96
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 1.2321
    Episode_Reward/rotating_object: 1.8781
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.10s
                      Time elapsed: 00:03:53
                               ETA: 01:01:02

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 47095 steps/s (collection: 1.975s, learning 0.113s)
             Mean action noise std: 1.36
          Mean value_function loss: 2.3133
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.4932
                       Mean reward: 15.59
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 1.2584
    Episode_Reward/rotating_object: 1.7257
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.09s
                      Time elapsed: 00:03:55
                               ETA: 01:00:51

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 46688 steps/s (collection: 2.001s, learning 0.105s)
             Mean action noise std: 1.37
          Mean value_function loss: 2.3623
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 53.5917
                       Mean reward: 15.12
               Mean episode length: 247.39
    Episode_Reward/reaching_object: 1.2838
    Episode_Reward/rotating_object: 1.8416
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.11s
                      Time elapsed: 00:03:57
                               ETA: 01:00:41

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 44600 steps/s (collection: 2.092s, learning 0.112s)
             Mean action noise std: 1.37
          Mean value_function loss: 2.3168
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.6640
                       Mean reward: 15.99
               Mean episode length: 248.68
    Episode_Reward/reaching_object: 1.2424
    Episode_Reward/rotating_object: 1.9195
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.20s
                      Time elapsed: 00:03:59
                               ETA: 01:00:33

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 44643 steps/s (collection: 2.086s, learning 0.116s)
             Mean action noise std: 1.37
          Mean value_function loss: 2.4657
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.7595
                       Mean reward: 13.87
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 1.2344
    Episode_Reward/rotating_object: 1.5014
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.20s
                      Time elapsed: 00:04:02
                               ETA: 01:00:25

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 45302 steps/s (collection: 2.052s, learning 0.118s)
             Mean action noise std: 1.38
          Mean value_function loss: 2.2879
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.8668
                       Mean reward: 13.02
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 1.9577
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.17s
                      Time elapsed: 00:04:04
                               ETA: 01:00:16

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 45572 steps/s (collection: 2.037s, learning 0.120s)
             Mean action noise std: 1.38
          Mean value_function loss: 1.9298
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.9392
                       Mean reward: 15.49
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 1.2312
    Episode_Reward/rotating_object: 1.9224
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.16s
                      Time elapsed: 00:04:06
                               ETA: 01:00:08

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 43535 steps/s (collection: 2.138s, learning 0.120s)
             Mean action noise std: 1.39
          Mean value_function loss: 2.2880
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.0414
                       Mean reward: 15.50
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 1.7240
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.26s
                      Time elapsed: 00:04:08
                               ETA: 01:00:00

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 46802 steps/s (collection: 1.985s, learning 0.116s)
             Mean action noise std: 1.39
          Mean value_function loss: 2.3408
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.1212
                       Mean reward: 18.66
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 1.7504
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.10s
                      Time elapsed: 00:04:10
                               ETA: 00:59:51

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 46629 steps/s (collection: 1.991s, learning 0.117s)
             Mean action noise std: 1.39
          Mean value_function loss: 2.4167
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.2134
                       Mean reward: 22.31
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 1.2186
    Episode_Reward/rotating_object: 2.2056
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.11s
                      Time elapsed: 00:04:12
                               ETA: 00:59:42

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 45494 steps/s (collection: 2.043s, learning 0.118s)
             Mean action noise std: 1.40
          Mean value_function loss: 2.4264
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.3049
                       Mean reward: 18.28
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.2185
    Episode_Reward/rotating_object: 2.1710
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.16s
                      Time elapsed: 00:04:15
                               ETA: 00:59:34

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 43949 steps/s (collection: 2.125s, learning 0.112s)
             Mean action noise std: 1.40
          Mean value_function loss: 2.7344
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.3940
                       Mean reward: 14.25
               Mean episode length: 248.68
    Episode_Reward/reaching_object: 1.2042
    Episode_Reward/rotating_object: 1.7662
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.24s
                      Time elapsed: 00:04:17
                               ETA: 00:59:27

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 46647 steps/s (collection: 2.009s, learning 0.099s)
             Mean action noise std: 1.41
          Mean value_function loss: 2.6652
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 54.4785
                       Mean reward: 17.23
               Mean episode length: 247.08
    Episode_Reward/reaching_object: 1.2028
    Episode_Reward/rotating_object: 2.5262
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.11s
                      Time elapsed: 00:04:19
                               ETA: 00:59:19

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 46574 steps/s (collection: 2.013s, learning 0.098s)
             Mean action noise std: 1.41
          Mean value_function loss: 2.6129
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.5634
                       Mean reward: 15.65
               Mean episode length: 242.75
    Episode_Reward/reaching_object: 1.1852
    Episode_Reward/rotating_object: 2.1080
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.11s
                      Time elapsed: 00:04:21
                               ETA: 00:59:10

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 45611 steps/s (collection: 2.055s, learning 0.100s)
             Mean action noise std: 1.41
          Mean value_function loss: 2.5745
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.6210
                       Mean reward: 10.75
               Mean episode length: 245.25
    Episode_Reward/reaching_object: 1.2197
    Episode_Reward/rotating_object: 2.0749
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.16s
                      Time elapsed: 00:04:23
                               ETA: 00:59:03

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 46241 steps/s (collection: 2.025s, learning 0.101s)
             Mean action noise std: 1.41
          Mean value_function loss: 2.2204
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.6799
                       Mean reward: 13.85
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 1.5090
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.13s
                      Time elapsed: 00:04:25
                               ETA: 00:58:55

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 47122 steps/s (collection: 1.989s, learning 0.097s)
             Mean action noise std: 1.42
          Mean value_function loss: 2.2955
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.7343
                       Mean reward: 12.74
               Mean episode length: 247.40
    Episode_Reward/reaching_object: 1.2170
    Episode_Reward/rotating_object: 1.6092
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.09s
                      Time elapsed: 00:04:27
                               ETA: 00:58:46

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 47020 steps/s (collection: 1.991s, learning 0.100s)
             Mean action noise std: 1.42
          Mean value_function loss: 2.9880
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.8307
                       Mean reward: 18.06
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 2.1279
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.09s
                      Time elapsed: 00:04:30
                               ETA: 00:58:38

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 46400 steps/s (collection: 2.015s, learning 0.104s)
             Mean action noise std: 1.43
          Mean value_function loss: 3.1660
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 54.9150
                       Mean reward: 15.01
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 1.7812
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.12s
                      Time elapsed: 00:04:32
                               ETA: 00:58:30

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 45503 steps/s (collection: 2.051s, learning 0.110s)
             Mean action noise std: 1.43
          Mean value_function loss: 2.7896
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 54.9960
                       Mean reward: 13.35
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 1.2454
    Episode_Reward/rotating_object: 2.1882
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.16s
                      Time elapsed: 00:04:34
                               ETA: 00:58:23

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 46237 steps/s (collection: 2.025s, learning 0.102s)
             Mean action noise std: 1.43
          Mean value_function loss: 2.6172
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 55.0901
                       Mean reward: 15.44
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.2256
    Episode_Reward/rotating_object: 1.9511
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.13s
                      Time elapsed: 00:04:36
                               ETA: 00:58:16

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 47390 steps/s (collection: 1.977s, learning 0.097s)
             Mean action noise std: 1.44
          Mean value_function loss: 2.9559
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 55.1795
                       Mean reward: 17.56
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 2.2661
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.07s
                      Time elapsed: 00:04:38
                               ETA: 00:58:08

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 46356 steps/s (collection: 2.001s, learning 0.120s)
             Mean action noise std: 1.44
          Mean value_function loss: 2.9627
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 55.2945
                       Mean reward: 14.09
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 2.2057
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.12s
                      Time elapsed: 00:04:40
                               ETA: 00:58:00

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 45815 steps/s (collection: 2.020s, learning 0.126s)
             Mean action noise std: 1.45
          Mean value_function loss: 3.0963
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 55.3749
                       Mean reward: 19.73
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.1805
    Episode_Reward/rotating_object: 2.1456
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.15s
                      Time elapsed: 00:04:42
                               ETA: 00:57:53

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 47247 steps/s (collection: 1.956s, learning 0.124s)
             Mean action noise std: 1.45
          Mean value_function loss: 2.8206
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.4636
                       Mean reward: 16.17
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 2.0643
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.08s
                      Time elapsed: 00:04:44
                               ETA: 00:57:46

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 43069 steps/s (collection: 2.159s, learning 0.123s)
             Mean action noise std: 1.46
          Mean value_function loss: 3.1175
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 55.5406
                       Mean reward: 14.31
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.2136
    Episode_Reward/rotating_object: 2.1917
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.28s
                      Time elapsed: 00:04:47
                               ETA: 00:57:41

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 45413 steps/s (collection: 2.043s, learning 0.122s)
             Mean action noise std: 1.46
          Mean value_function loss: 3.3258
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 55.6386
                       Mean reward: 18.21
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.2165
    Episode_Reward/rotating_object: 2.1716
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.16s
                      Time elapsed: 00:04:49
                               ETA: 00:57:34

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 46131 steps/s (collection: 2.035s, learning 0.096s)
             Mean action noise std: 1.46
          Mean value_function loss: 3.2342
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 55.7382
                       Mean reward: 17.94
               Mean episode length: 233.37
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 2.5260
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.13s
                      Time elapsed: 00:04:51
                               ETA: 00:57:27

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 45955 steps/s (collection: 2.022s, learning 0.117s)
             Mean action noise std: 1.47
          Mean value_function loss: 3.4693
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 55.8147
                       Mean reward: 17.51
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.2143
    Episode_Reward/rotating_object: 2.2841
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.14s
                      Time elapsed: 00:04:53
                               ETA: 00:57:21

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 47157 steps/s (collection: 1.971s, learning 0.114s)
             Mean action noise std: 1.47
          Mean value_function loss: 3.1520
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.9023
                       Mean reward: 19.87
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 2.3426
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.08s
                      Time elapsed: 00:04:55
                               ETA: 00:57:14

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 46618 steps/s (collection: 1.994s, learning 0.115s)
             Mean action noise std: 1.48
          Mean value_function loss: 3.3509
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 56.0086
                       Mean reward: 15.46
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.1771
    Episode_Reward/rotating_object: 1.9810
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.11s
                      Time elapsed: 00:04:57
                               ETA: 00:57:07

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 46921 steps/s (collection: 1.980s, learning 0.115s)
             Mean action noise std: 1.48
          Mean value_function loss: 3.6937
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.0765
                       Mean reward: 16.34
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.1894
    Episode_Reward/rotating_object: 1.8332
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.10s
                      Time elapsed: 00:04:59
                               ETA: 00:57:00

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 45974 steps/s (collection: 2.011s, learning 0.127s)
             Mean action noise std: 1.48
          Mean value_function loss: 3.6101
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.1320
                       Mean reward: 14.08
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.1754
    Episode_Reward/rotating_object: 2.3990
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.14s
                      Time elapsed: 00:05:02
                               ETA: 00:56:54

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 46648 steps/s (collection: 1.993s, learning 0.115s)
             Mean action noise std: 1.49
          Mean value_function loss: 3.6840
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 56.2083
                       Mean reward: 22.60
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 1.1891
    Episode_Reward/rotating_object: 2.0711
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.11s
                      Time elapsed: 00:05:04
                               ETA: 00:56:47

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 45174 steps/s (collection: 2.047s, learning 0.129s)
             Mean action noise std: 1.49
          Mean value_function loss: 3.7479
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.2749
                       Mean reward: 21.94
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 1.1719
    Episode_Reward/rotating_object: 2.2223
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.18s
                      Time elapsed: 00:05:06
                               ETA: 00:56:41

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 44793 steps/s (collection: 2.090s, learning 0.105s)
             Mean action noise std: 1.49
          Mean value_function loss: 3.7988
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.3318
                       Mean reward: 20.00
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.1717
    Episode_Reward/rotating_object: 2.3897
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.19s
                      Time elapsed: 00:05:08
                               ETA: 00:56:36

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 46046 steps/s (collection: 2.038s, learning 0.097s)
             Mean action noise std: 1.50
          Mean value_function loss: 3.0691
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 56.3898
                       Mean reward: 15.28
               Mean episode length: 230.08
    Episode_Reward/reaching_object: 1.1801
    Episode_Reward/rotating_object: 2.7601
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.13s
                      Time elapsed: 00:05:10
                               ETA: 00:56:30

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 45564 steps/s (collection: 2.039s, learning 0.118s)
             Mean action noise std: 1.50
          Mean value_function loss: 3.7675
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.4926
                       Mean reward: 18.42
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 2.4265
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.16s
                      Time elapsed: 00:05:12
                               ETA: 00:56:24

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 42144 steps/s (collection: 2.173s, learning 0.160s)
             Mean action noise std: 1.50
          Mean value_function loss: 3.7128
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 56.5882
                       Mean reward: 13.77
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.1607
    Episode_Reward/rotating_object: 2.2262
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.33s
                      Time elapsed: 00:05:15
                               ETA: 00:56:20

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 42565 steps/s (collection: 2.188s, learning 0.121s)
             Mean action noise std: 1.51
          Mean value_function loss: 3.5838
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 56.6592
                       Mean reward: 16.88
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 1.1766
    Episode_Reward/rotating_object: 2.0492
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.31s
                      Time elapsed: 00:05:17
                               ETA: 00:56:16

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 47758 steps/s (collection: 1.949s, learning 0.109s)
             Mean action noise std: 1.51
          Mean value_function loss: 3.4501
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 56.7545
                       Mean reward: 17.95
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.1830
    Episode_Reward/rotating_object: 2.1549
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.06s
                      Time elapsed: 00:05:19
                               ETA: 00:56:09

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 47407 steps/s (collection: 1.967s, learning 0.107s)
             Mean action noise std: 1.52
          Mean value_function loss: 4.4387
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.8367
                       Mean reward: 14.57
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.1843
    Episode_Reward/rotating_object: 2.2095
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.07s
                      Time elapsed: 00:05:21
                               ETA: 00:56:03

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 46457 steps/s (collection: 2.002s, learning 0.114s)
             Mean action noise std: 1.52
          Mean value_function loss: 4.1177
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 56.9214
                       Mean reward: 16.64
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 1.1706
    Episode_Reward/rotating_object: 2.7320
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.12s
                      Time elapsed: 00:05:23
                               ETA: 00:55:57

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 45348 steps/s (collection: 2.063s, learning 0.105s)
             Mean action noise std: 1.52
          Mean value_function loss: 4.1386
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 56.9910
                       Mean reward: 16.42
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 2.9100
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.17s
                      Time elapsed: 00:05:25
                               ETA: 00:55:51

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 44826 steps/s (collection: 2.071s, learning 0.122s)
             Mean action noise std: 1.53
          Mean value_function loss: 3.9940
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 57.0603
                       Mean reward: 13.57
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 2.8396
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.19s
                      Time elapsed: 00:05:28
                               ETA: 00:55:46

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 45531 steps/s (collection: 2.031s, learning 0.128s)
             Mean action noise std: 1.53
          Mean value_function loss: 4.5812
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 57.1559
                       Mean reward: 16.08
               Mean episode length: 240.43
    Episode_Reward/reaching_object: 1.2021
    Episode_Reward/rotating_object: 2.2876
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.16s
                      Time elapsed: 00:05:30
                               ETA: 00:55:41

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 46334 steps/s (collection: 2.010s, learning 0.112s)
             Mean action noise std: 1.53
          Mean value_function loss: 3.6709
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 57.2088
                       Mean reward: 15.70
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 1.1957
    Episode_Reward/rotating_object: 2.9316
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.12s
                      Time elapsed: 00:05:32
                               ETA: 00:55:35

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 41223 steps/s (collection: 2.265s, learning 0.120s)
             Mean action noise std: 1.54
          Mean value_function loss: 4.2426
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 57.2770
                       Mean reward: 20.41
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 2.5435
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.38s
                      Time elapsed: 00:05:34
                               ETA: 00:55:32

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 45906 steps/s (collection: 2.024s, learning 0.118s)
             Mean action noise std: 1.54
          Mean value_function loss: 4.9198
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.3618
                       Mean reward: 17.31
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 1.1896
    Episode_Reward/rotating_object: 2.1608
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.14s
                      Time elapsed: 00:05:36
                               ETA: 00:55:27

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 42837 steps/s (collection: 2.155s, learning 0.140s)
             Mean action noise std: 1.55
          Mean value_function loss: 4.9414
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.4216
                       Mean reward: 21.45
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.1836
    Episode_Reward/rotating_object: 2.5750
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.29s
                      Time elapsed: 00:05:39
                               ETA: 00:55:23

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 42502 steps/s (collection: 2.205s, learning 0.108s)
             Mean action noise std: 1.55
          Mean value_function loss: 5.0613
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 57.4786
                       Mean reward: 29.97
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.1813
    Episode_Reward/rotating_object: 3.3583
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.31s
                      Time elapsed: 00:05:41
                               ETA: 00:55:19

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 44101 steps/s (collection: 2.112s, learning 0.118s)
             Mean action noise std: 1.55
          Mean value_function loss: 5.4112
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 57.5634
                       Mean reward: 15.70
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 1.1791
    Episode_Reward/rotating_object: 2.3243
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.23s
                      Time elapsed: 00:05:43
                               ETA: 00:55:15

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 43216 steps/s (collection: 2.144s, learning 0.131s)
             Mean action noise std: 1.56
          Mean value_function loss: 5.0790
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 57.6514
                       Mean reward: 22.95
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 2.9465
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.27s
                      Time elapsed: 00:05:45
                               ETA: 00:55:11

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 41942 steps/s (collection: 2.203s, learning 0.141s)
             Mean action noise std: 1.56
          Mean value_function loss: 4.7970
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 57.7060
                       Mean reward: 25.18
               Mean episode length: 233.67
    Episode_Reward/reaching_object: 1.1917
    Episode_Reward/rotating_object: 3.1322
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.34s
                      Time elapsed: 00:05:48
                               ETA: 00:55:07

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 44681 steps/s (collection: 2.067s, learning 0.133s)
             Mean action noise std: 1.56
          Mean value_function loss: 4.4475
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.7531
                       Mean reward: 20.55
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.1914
    Episode_Reward/rotating_object: 2.6500
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.20s
                      Time elapsed: 00:05:50
                               ETA: 00:55:03

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 45331 steps/s (collection: 2.062s, learning 0.107s)
             Mean action noise std: 1.57
          Mean value_function loss: 5.0064
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 57.8302
                       Mean reward: 21.76
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 3.2684
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.17s
                      Time elapsed: 00:05:52
                               ETA: 00:54:58

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 46658 steps/s (collection: 1.996s, learning 0.111s)
             Mean action noise std: 1.57
          Mean value_function loss: 4.6251
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 57.9052
                       Mean reward: 24.92
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 1.1491
    Episode_Reward/rotating_object: 2.6793
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.11s
                      Time elapsed: 00:05:54
                               ETA: 00:54:52

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 47513 steps/s (collection: 1.968s, learning 0.101s)
             Mean action noise std: 1.57
          Mean value_function loss: 4.5431
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 57.9575
                       Mean reward: 21.89
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.1545
    Episode_Reward/rotating_object: 2.6062
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.07s
                      Time elapsed: 00:05:56
                               ETA: 00:54:47

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 46138 steps/s (collection: 2.021s, learning 0.110s)
             Mean action noise std: 1.58
          Mean value_function loss: 4.0754
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 58.0174
                       Mean reward: 20.57
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 2.7364
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.13s
                      Time elapsed: 00:05:58
                               ETA: 00:54:41

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 42696 steps/s (collection: 2.129s, learning 0.173s)
             Mean action noise std: 1.58
          Mean value_function loss: 4.0560
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 58.0837
                       Mean reward: 21.57
               Mean episode length: 238.57
    Episode_Reward/reaching_object: 1.1731
    Episode_Reward/rotating_object: 2.4942
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.30s
                      Time elapsed: 00:06:01
                               ETA: 00:54:38

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 42549 steps/s (collection: 2.158s, learning 0.153s)
             Mean action noise std: 1.58
          Mean value_function loss: 4.1999
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 58.1460
                       Mean reward: 22.62
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 1.1632
    Episode_Reward/rotating_object: 3.2015
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.31s
                      Time elapsed: 00:06:03
                               ETA: 00:54:34

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 41720 steps/s (collection: 2.232s, learning 0.125s)
             Mean action noise std: 1.59
          Mean value_function loss: 4.6531
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 58.2109
                       Mean reward: 15.52
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.1907
    Episode_Reward/rotating_object: 2.6479
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.36s
                      Time elapsed: 00:06:05
                               ETA: 00:54:31

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 46838 steps/s (collection: 1.996s, learning 0.103s)
             Mean action noise std: 1.59
          Mean value_function loss: 4.8071
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 58.2845
                       Mean reward: 20.88
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.1948
    Episode_Reward/rotating_object: 3.0862
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.10s
                      Time elapsed: 00:06:08
                               ETA: 00:54:26

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 46638 steps/s (collection: 1.999s, learning 0.109s)
             Mean action noise std: 1.59
          Mean value_function loss: 4.7664
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 58.3549
                       Mean reward: 12.08
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 2.4769
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.11s
                      Time elapsed: 00:06:10
                               ETA: 00:54:21

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 45940 steps/s (collection: 1.998s, learning 0.142s)
             Mean action noise std: 1.60
          Mean value_function loss: 4.9359
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 58.4214
                       Mean reward: 23.90
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 2.5360
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.14s
                      Time elapsed: 00:06:12
                               ETA: 00:54:16

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 44808 steps/s (collection: 2.074s, learning 0.120s)
             Mean action noise std: 1.60
          Mean value_function loss: 5.4059
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.4959
                       Mean reward: 23.04
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.1872
    Episode_Reward/rotating_object: 2.9290
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.19s
                      Time elapsed: 00:06:14
                               ETA: 00:54:12

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 46284 steps/s (collection: 2.005s, learning 0.119s)
             Mean action noise std: 1.60
          Mean value_function loss: 5.3902
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 58.5669
                       Mean reward: 14.21
               Mean episode length: 240.52
    Episode_Reward/reaching_object: 1.1264
    Episode_Reward/rotating_object: 2.6386
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.12s
                      Time elapsed: 00:06:16
                               ETA: 00:54:07

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 46349 steps/s (collection: 2.012s, learning 0.109s)
             Mean action noise std: 1.61
          Mean value_function loss: 5.5049
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 58.6260
                       Mean reward: 17.03
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 2.9700
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.12s
                      Time elapsed: 00:06:18
                               ETA: 00:54:02

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 44708 steps/s (collection: 2.086s, learning 0.113s)
             Mean action noise std: 1.61
          Mean value_function loss: 5.8456
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 58.6945
                       Mean reward: 23.35
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 1.1573
    Episode_Reward/rotating_object: 2.7841
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.20s
                      Time elapsed: 00:06:20
                               ETA: 00:53:58

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 47194 steps/s (collection: 1.972s, learning 0.111s)
             Mean action noise std: 1.61
          Mean value_function loss: 6.0857
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 58.7426
                       Mean reward: 20.81
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.1214
    Episode_Reward/rotating_object: 2.4960
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.08s
                      Time elapsed: 00:06:23
                               ETA: 00:53:52

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 44019 steps/s (collection: 2.108s, learning 0.126s)
             Mean action noise std: 1.62
          Mean value_function loss: 6.0685
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.8272
                       Mean reward: 24.29
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.1392
    Episode_Reward/rotating_object: 2.6980
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.23s
                      Time elapsed: 00:06:25
                               ETA: 00:53:48

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 45352 steps/s (collection: 2.034s, learning 0.134s)
             Mean action noise std: 1.62
          Mean value_function loss: 5.2069
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.8748
                       Mean reward: 23.53
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.1401
    Episode_Reward/rotating_object: 3.0310
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.17s
                      Time elapsed: 00:06:27
                               ETA: 00:53:44

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 42912 steps/s (collection: 2.111s, learning 0.180s)
             Mean action noise std: 1.62
          Mean value_function loss: 5.2389
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 58.9386
                       Mean reward: 14.00
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.1432
    Episode_Reward/rotating_object: 2.8819
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.29s
                      Time elapsed: 00:06:29
                               ETA: 00:53:41

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 42411 steps/s (collection: 2.217s, learning 0.101s)
             Mean action noise std: 1.63
          Mean value_function loss: 6.4715
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 59.0186
                       Mean reward: 16.66
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.1442
    Episode_Reward/rotating_object: 2.4908
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.32s
                      Time elapsed: 00:06:32
                               ETA: 00:53:38

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 43392 steps/s (collection: 2.084s, learning 0.182s)
             Mean action noise std: 1.63
          Mean value_function loss: 5.5973
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 59.0994
                       Mean reward: 23.59
               Mean episode length: 233.10
    Episode_Reward/reaching_object: 1.1055
    Episode_Reward/rotating_object: 3.1150
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.27s
                      Time elapsed: 00:06:34
                               ETA: 00:53:34

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 40092 steps/s (collection: 2.276s, learning 0.176s)
             Mean action noise std: 1.63
          Mean value_function loss: 6.1324
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 59.1542
                       Mean reward: 18.45
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 1.1293
    Episode_Reward/rotating_object: 2.8347
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.45s
                      Time elapsed: 00:06:36
                               ETA: 00:53:32

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 41066 steps/s (collection: 2.207s, learning 0.186s)
             Mean action noise std: 1.64
          Mean value_function loss: 6.9023
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 59.1991
                       Mean reward: 20.06
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.1502
    Episode_Reward/rotating_object: 3.0175
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.39s
                      Time elapsed: 00:06:39
                               ETA: 00:53:30

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 38786 steps/s (collection: 2.354s, learning 0.181s)
             Mean action noise std: 1.64
          Mean value_function loss: 7.5136
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 59.2515
                       Mean reward: 20.79
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.1696
    Episode_Reward/rotating_object: 2.9578
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.53s
                      Time elapsed: 00:06:41
                               ETA: 00:53:28

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 43144 steps/s (collection: 2.152s, learning 0.126s)
             Mean action noise std: 1.64
          Mean value_function loss: 7.0411
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.3037
                       Mean reward: 23.57
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.1366
    Episode_Reward/rotating_object: 3.9654
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.28s
                      Time elapsed: 00:06:43
                               ETA: 00:53:25

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 44219 steps/s (collection: 2.117s, learning 0.106s)
             Mean action noise std: 1.65
          Mean value_function loss: 6.7836
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 59.3528
                       Mean reward: 15.78
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.1350
    Episode_Reward/rotating_object: 3.3338
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.22s
                      Time elapsed: 00:06:46
                               ETA: 00:53:21

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 42907 steps/s (collection: 2.126s, learning 0.165s)
             Mean action noise std: 1.65
          Mean value_function loss: 7.2840
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 59.4101
                       Mean reward: 23.44
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 1.1406
    Episode_Reward/rotating_object: 3.6764
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.29s
                      Time elapsed: 00:06:48
                               ETA: 00:53:18

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 44527 steps/s (collection: 2.094s, learning 0.114s)
             Mean action noise std: 1.65
          Mean value_function loss: 5.5598
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 59.4626
                       Mean reward: 28.36
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 1.1180
    Episode_Reward/rotating_object: 3.9816
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.21s
                      Time elapsed: 00:06:50
                               ETA: 00:53:14

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 43042 steps/s (collection: 2.160s, learning 0.124s)
             Mean action noise std: 1.65
          Mean value_function loss: 6.1067
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 59.5207
                       Mean reward: 26.60
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 3.8673
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.28s
                      Time elapsed: 00:06:52
                               ETA: 00:53:10

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 38463 steps/s (collection: 2.338s, learning 0.218s)
             Mean action noise std: 1.66
          Mean value_function loss: 4.9444
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 59.6001
                       Mean reward: 16.90
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 1.1373
    Episode_Reward/rotating_object: 2.6239
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.56s
                      Time elapsed: 00:06:55
                               ETA: 00:53:09

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 43284 steps/s (collection: 2.139s, learning 0.132s)
             Mean action noise std: 1.66
          Mean value_function loss: 6.2530
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 59.6748
                       Mean reward: 21.83
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.1462
    Episode_Reward/rotating_object: 2.8550
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.27s
                      Time elapsed: 00:06:57
                               ETA: 00:53:06

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 40422 steps/s (collection: 2.266s, learning 0.166s)
             Mean action noise std: 1.67
          Mean value_function loss: 6.3272
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 59.7528
                       Mean reward: 26.24
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.1574
    Episode_Reward/rotating_object: 3.4809
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.43s
                      Time elapsed: 00:07:00
                               ETA: 00:53:04

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 38559 steps/s (collection: 2.359s, learning 0.190s)
             Mean action noise std: 1.67
          Mean value_function loss: 5.9147
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 59.8347
                       Mean reward: 19.80
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.1379
    Episode_Reward/rotating_object: 3.3894
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.55s
                      Time elapsed: 00:07:02
                               ETA: 00:53:02

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 40678 steps/s (collection: 2.250s, learning 0.167s)
             Mean action noise std: 1.68
          Mean value_function loss: 6.2896
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 59.9176
                       Mean reward: 14.97
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.1215
    Episode_Reward/rotating_object: 2.9414
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.42s
                      Time elapsed: 00:07:05
                               ETA: 00:53:00

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 41103 steps/s (collection: 2.215s, learning 0.177s)
             Mean action noise std: 1.68
          Mean value_function loss: 6.4972
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 59.9978
                       Mean reward: 27.01
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.1522
    Episode_Reward/rotating_object: 3.6855
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.39s
                      Time elapsed: 00:07:07
                               ETA: 00:52:58

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 43453 steps/s (collection: 2.130s, learning 0.132s)
             Mean action noise std: 1.68
          Mean value_function loss: 7.1852
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 60.0683
                       Mean reward: 19.61
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.1424
    Episode_Reward/rotating_object: 3.0826
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.26s
                      Time elapsed: 00:07:09
                               ETA: 00:52:54

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 45011 steps/s (collection: 2.060s, learning 0.124s)
             Mean action noise std: 1.69
          Mean value_function loss: 6.1031
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 60.1587
                       Mean reward: 19.16
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.1355
    Episode_Reward/rotating_object: 2.9935
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.18s
                      Time elapsed: 00:07:12
                               ETA: 00:52:50

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 41726 steps/s (collection: 2.212s, learning 0.144s)
             Mean action noise std: 1.69
          Mean value_function loss: 6.9845
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 60.2361
                       Mean reward: 23.05
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.1438
    Episode_Reward/rotating_object: 3.1792
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.36s
                      Time elapsed: 00:07:14
                               ETA: 00:52:47

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 38342 steps/s (collection: 2.411s, learning 0.153s)
             Mean action noise std: 1.70
          Mean value_function loss: 6.2182
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 60.3004
                       Mean reward: 23.69
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.1333
    Episode_Reward/rotating_object: 2.8735
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.56s
                      Time elapsed: 00:07:16
                               ETA: 00:52:46

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 44674 steps/s (collection: 2.085s, learning 0.116s)
             Mean action noise std: 1.70
          Mean value_function loss: 7.1594
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 60.3652
                       Mean reward: 21.26
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.1450
    Episode_Reward/rotating_object: 3.3590
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.20s
                      Time elapsed: 00:07:19
                               ETA: 00:52:42

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 47528 steps/s (collection: 1.949s, learning 0.120s)
             Mean action noise std: 1.70
          Mean value_function loss: 6.5478
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.4459
                       Mean reward: 19.52
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.1288
    Episode_Reward/rotating_object: 3.2987
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.07s
                      Time elapsed: 00:07:21
                               ETA: 00:52:38

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 43868 steps/s (collection: 2.096s, learning 0.145s)
             Mean action noise std: 1.71
          Mean value_function loss: 7.1661
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 60.4793
                       Mean reward: 19.43
               Mean episode length: 227.31
    Episode_Reward/reaching_object: 1.1263
    Episode_Reward/rotating_object: 3.3075
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.24s
                      Time elapsed: 00:07:23
                               ETA: 00:52:34

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 43857 steps/s (collection: 2.126s, learning 0.116s)
             Mean action noise std: 1.71
          Mean value_function loss: 7.4912
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 60.5495
                       Mean reward: 24.85
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.1418
    Episode_Reward/rotating_object: 3.7234
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.24s
                      Time elapsed: 00:07:25
                               ETA: 00:52:31

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 43975 steps/s (collection: 2.090s, learning 0.146s)
             Mean action noise std: 1.71
          Mean value_function loss: 7.0851
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 60.6161
                       Mean reward: 25.81
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.1450
    Episode_Reward/rotating_object: 3.6495
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.24s
                      Time elapsed: 00:07:27
                               ETA: 00:52:27

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 43720 steps/s (collection: 2.123s, learning 0.125s)
             Mean action noise std: 1.72
          Mean value_function loss: 8.6156
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 60.6840
                       Mean reward: 20.20
               Mean episode length: 230.06
    Episode_Reward/reaching_object: 1.1338
    Episode_Reward/rotating_object: 3.2948
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.25s
                      Time elapsed: 00:07:30
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 43857 steps/s (collection: 2.138s, learning 0.103s)
             Mean action noise std: 1.72
          Mean value_function loss: 8.1941
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 60.7543
                       Mean reward: 17.72
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.1341
    Episode_Reward/rotating_object: 3.4961
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.24s
                      Time elapsed: 00:07:32
                               ETA: 00:52:20

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 44067 steps/s (collection: 2.089s, learning 0.142s)
             Mean action noise std: 1.73
          Mean value_function loss: 7.9311
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 60.8181
                       Mean reward: 26.77
               Mean episode length: 230.04
    Episode_Reward/reaching_object: 1.0997
    Episode_Reward/rotating_object: 3.5516
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.23s
                      Time elapsed: 00:07:34
                               ETA: 00:52:17

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 42983 steps/s (collection: 2.163s, learning 0.124s)
             Mean action noise std: 1.73
          Mean value_function loss: 8.4269
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.8768
                       Mean reward: 27.91
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.1325
    Episode_Reward/rotating_object: 4.0781
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.29s
                      Time elapsed: 00:07:36
                               ETA: 00:52:14

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 43767 steps/s (collection: 2.085s, learning 0.161s)
             Mean action noise std: 1.73
          Mean value_function loss: 6.7820
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 60.9242
                       Mean reward: 29.62
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.1413
    Episode_Reward/rotating_object: 4.2191
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.25s
                      Time elapsed: 00:07:39
                               ETA: 00:52:10

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 42580 steps/s (collection: 2.185s, learning 0.124s)
             Mean action noise std: 1.73
          Mean value_function loss: 8.5461
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 60.9810
                       Mean reward: 23.60
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 1.1292
    Episode_Reward/rotating_object: 3.7570
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.31s
                      Time elapsed: 00:07:41
                               ETA: 00:52:07

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 42560 steps/s (collection: 2.153s, learning 0.157s)
             Mean action noise std: 1.74
          Mean value_function loss: 7.0194
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 61.0410
                       Mean reward: 16.86
               Mean episode length: 232.51
    Episode_Reward/reaching_object: 1.1365
    Episode_Reward/rotating_object: 3.3108
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.31s
                      Time elapsed: 00:07:43
                               ETA: 00:52:04

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 42583 steps/s (collection: 2.122s, learning 0.186s)
             Mean action noise std: 1.74
          Mean value_function loss: 8.0201
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 61.1098
                       Mean reward: 22.04
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.1001
    Episode_Reward/rotating_object: 3.5917
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.31s
                      Time elapsed: 00:07:46
                               ETA: 00:52:01

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 43106 steps/s (collection: 2.118s, learning 0.163s)
             Mean action noise std: 1.75
          Mean value_function loss: 7.7755
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 61.1843
                       Mean reward: 19.95
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 3.9227
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.28s
                      Time elapsed: 00:07:48
                               ETA: 00:51:58

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 43935 steps/s (collection: 2.091s, learning 0.147s)
             Mean action noise std: 1.75
          Mean value_function loss: 8.5651
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.2474
                       Mean reward: 27.84
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.1594
    Episode_Reward/rotating_object: 4.0543
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.24s
                      Time elapsed: 00:07:50
                               ETA: 00:51:55

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 43453 steps/s (collection: 2.118s, learning 0.144s)
             Mean action noise std: 1.75
          Mean value_function loss: 7.3272
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 61.3002
                       Mean reward: 22.05
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 1.1047
    Episode_Reward/rotating_object: 4.2228
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.26s
                      Time elapsed: 00:07:52
                               ETA: 00:51:52

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 44003 steps/s (collection: 2.134s, learning 0.100s)
             Mean action noise std: 1.76
          Mean value_function loss: 6.7744
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 61.3756
                       Mean reward: 27.02
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 1.1188
    Episode_Reward/rotating_object: 3.8372
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.23s
                      Time elapsed: 00:07:55
                               ETA: 00:51:48

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 43525 steps/s (collection: 2.091s, learning 0.168s)
             Mean action noise std: 1.76
          Mean value_function loss: 8.0762
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 61.4337
                       Mean reward: 16.18
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 1.0909
    Episode_Reward/rotating_object: 2.8953
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.26s
                      Time elapsed: 00:07:57
                               ETA: 00:51:45

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 44752 steps/s (collection: 2.042s, learning 0.155s)
             Mean action noise std: 1.76
          Mean value_function loss: 8.0703
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 61.4916
                       Mean reward: 25.20
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 1.1095
    Episode_Reward/rotating_object: 4.5605
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.20s
                      Time elapsed: 00:07:59
                               ETA: 00:51:41

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 43661 steps/s (collection: 2.134s, learning 0.118s)
             Mean action noise std: 1.77
          Mean value_function loss: 7.8869
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 61.5494
                       Mean reward: 23.21
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.0870
    Episode_Reward/rotating_object: 3.7267
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.25s
                      Time elapsed: 00:08:01
                               ETA: 00:51:38

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 44701 steps/s (collection: 2.072s, learning 0.128s)
             Mean action noise std: 1.77
          Mean value_function loss: 7.4662
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 61.6009
                       Mean reward: 23.13
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.0884
    Episode_Reward/rotating_object: 3.6152
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.20s
                      Time elapsed: 00:08:04
                               ETA: 00:51:34

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 42340 steps/s (collection: 2.182s, learning 0.140s)
             Mean action noise std: 1.77
          Mean value_function loss: 7.3700
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 61.6616
                       Mean reward: 18.56
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.1225
    Episode_Reward/rotating_object: 3.6808
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.32s
                      Time elapsed: 00:08:06
                               ETA: 00:51:32

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 44254 steps/s (collection: 2.055s, learning 0.166s)
             Mean action noise std: 1.78
          Mean value_function loss: 7.3311
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 61.7187
                       Mean reward: 20.29
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.1012
    Episode_Reward/rotating_object: 3.6167
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.22s
                      Time elapsed: 00:08:08
                               ETA: 00:51:28

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 44665 steps/s (collection: 2.011s, learning 0.190s)
             Mean action noise std: 1.78
          Mean value_function loss: 7.6324
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 61.7852
                       Mean reward: 26.08
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 1.0983
    Episode_Reward/rotating_object: 3.5862
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.20s
                      Time elapsed: 00:08:10
                               ETA: 00:51:25

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 43315 steps/s (collection: 2.177s, learning 0.093s)
             Mean action noise std: 1.78
          Mean value_function loss: 7.9287
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.8559
                       Mean reward: 21.00
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 3.5270
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.27s
                      Time elapsed: 00:08:13
                               ETA: 00:51:22

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 41344 steps/s (collection: 2.259s, learning 0.119s)
             Mean action noise std: 1.79
          Mean value_function loss: 7.5415
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 61.8939
                       Mean reward: 22.94
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 1.1124
    Episode_Reward/rotating_object: 3.6513
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.38s
                      Time elapsed: 00:08:15
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 43177 steps/s (collection: 2.121s, learning 0.156s)
             Mean action noise std: 1.79
          Mean value_function loss: 8.2031
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 61.9382
                       Mean reward: 24.37
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 1.0943
    Episode_Reward/rotating_object: 3.4397
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.28s
                      Time elapsed: 00:08:17
                               ETA: 00:51:16

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 44366 steps/s (collection: 2.069s, learning 0.147s)
             Mean action noise std: 1.79
          Mean value_function loss: 9.1556
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 61.9844
                       Mean reward: 14.06
               Mean episode length: 231.99
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 3.5396
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.22s
                      Time elapsed: 00:08:19
                               ETA: 00:51:13

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 44462 steps/s (collection: 2.052s, learning 0.159s)
             Mean action noise std: 1.79
          Mean value_function loss: 9.4965
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 62.0422
                       Mean reward: 27.24
               Mean episode length: 228.89
    Episode_Reward/reaching_object: 1.0560
    Episode_Reward/rotating_object: 4.1751
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.21s
                      Time elapsed: 00:08:22
                               ETA: 00:51:09

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 42927 steps/s (collection: 2.143s, learning 0.147s)
             Mean action noise std: 1.80
          Mean value_function loss: 9.2070
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 62.0920
                       Mean reward: 33.57
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 1.0798
    Episode_Reward/rotating_object: 4.2829
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.29s
                      Time elapsed: 00:08:24
                               ETA: 00:51:06

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 42625 steps/s (collection: 2.188s, learning 0.119s)
             Mean action noise std: 1.80
          Mean value_function loss: 7.4059
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 62.1304
                       Mean reward: 19.00
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 1.0514
    Episode_Reward/rotating_object: 4.1813
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.31s
                      Time elapsed: 00:08:26
                               ETA: 00:51:04

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 43311 steps/s (collection: 2.124s, learning 0.146s)
             Mean action noise std: 1.80
          Mean value_function loss: 8.2173
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 62.1883
                       Mean reward: 21.58
               Mean episode length: 222.90
    Episode_Reward/reaching_object: 1.0632
    Episode_Reward/rotating_object: 4.0534
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.27s
                      Time elapsed: 00:08:29
                               ETA: 00:51:01

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 43537 steps/s (collection: 2.134s, learning 0.124s)
             Mean action noise std: 1.81
          Mean value_function loss: 9.1691
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 62.2341
                       Mean reward: 25.28
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.0551
    Episode_Reward/rotating_object: 4.3450
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.26s
                      Time elapsed: 00:08:31
                               ETA: 00:50:58

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 43587 steps/s (collection: 2.104s, learning 0.151s)
             Mean action noise std: 1.81
          Mean value_function loss: 9.1795
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 62.2811
                       Mean reward: 18.70
               Mean episode length: 214.62
    Episode_Reward/reaching_object: 1.0457
    Episode_Reward/rotating_object: 4.0262
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.26s
                      Time elapsed: 00:08:33
                               ETA: 00:50:54

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 44543 steps/s (collection: 2.079s, learning 0.128s)
             Mean action noise std: 1.81
          Mean value_function loss: 9.5794
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 62.3393
                       Mean reward: 20.94
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.0522
    Episode_Reward/rotating_object: 3.5372
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.21s
                      Time elapsed: 00:08:35
                               ETA: 00:50:51

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 42840 steps/s (collection: 2.161s, learning 0.134s)
             Mean action noise std: 1.82
          Mean value_function loss: 8.5462
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 62.4089
                       Mean reward: 17.90
               Mean episode length: 222.72
    Episode_Reward/reaching_object: 1.0124
    Episode_Reward/rotating_object: 3.6837
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.29s
                      Time elapsed: 00:08:38
                               ETA: 00:50:48

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 43650 steps/s (collection: 2.111s, learning 0.142s)
             Mean action noise std: 1.82
          Mean value_function loss: 9.2007
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.4579
                       Mean reward: 21.64
               Mean episode length: 221.85
    Episode_Reward/reaching_object: 1.0533
    Episode_Reward/rotating_object: 3.8998
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.25s
                      Time elapsed: 00:08:40
                               ETA: 00:50:45

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 44410 steps/s (collection: 2.085s, learning 0.129s)
             Mean action noise std: 1.82
          Mean value_function loss: 9.0099
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.5188
                       Mean reward: 18.49
               Mean episode length: 228.89
    Episode_Reward/reaching_object: 1.0267
    Episode_Reward/rotating_object: 3.2360
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.21s
                      Time elapsed: 00:08:42
                               ETA: 00:50:42

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 44169 steps/s (collection: 2.087s, learning 0.139s)
             Mean action noise std: 1.82
          Mean value_function loss: 9.1238
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 62.5660
                       Mean reward: 29.92
               Mean episode length: 225.80
    Episode_Reward/reaching_object: 1.0468
    Episode_Reward/rotating_object: 4.5917
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.23s
                      Time elapsed: 00:08:44
                               ETA: 00:50:39

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 43794 steps/s (collection: 2.094s, learning 0.151s)
             Mean action noise std: 1.83
          Mean value_function loss: 8.6755
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 62.6021
                       Mean reward: 23.00
               Mean episode length: 215.59
    Episode_Reward/reaching_object: 1.0324
    Episode_Reward/rotating_object: 3.8847
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.24s
                      Time elapsed: 00:08:46
                               ETA: 00:50:35

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 43863 steps/s (collection: 2.110s, learning 0.132s)
             Mean action noise std: 1.83
          Mean value_function loss: 8.6531
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 62.6631
                       Mean reward: 22.76
               Mean episode length: 209.81
    Episode_Reward/reaching_object: 1.0045
    Episode_Reward/rotating_object: 4.0826
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.24s
                      Time elapsed: 00:08:49
                               ETA: 00:50:32

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 45578 steps/s (collection: 2.016s, learning 0.141s)
             Mean action noise std: 1.83
          Mean value_function loss: 8.9098
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 62.7152
                       Mean reward: 31.92
               Mean episode length: 228.25
    Episode_Reward/reaching_object: 1.0625
    Episode_Reward/rotating_object: 3.8589
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.16s
                      Time elapsed: 00:08:51
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 45383 steps/s (collection: 2.067s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 8.5247
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.7722
                       Mean reward: 20.17
               Mean episode length: 220.72
    Episode_Reward/reaching_object: 1.0077
    Episode_Reward/rotating_object: 3.6609
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 11.2083
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.17s
                      Time elapsed: 00:08:53
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 45486 steps/s (collection: 2.056s, learning 0.106s)
             Mean action noise std: 1.84
          Mean value_function loss: 8.9223
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.8093
                       Mean reward: 29.45
               Mean episode length: 221.62
    Episode_Reward/reaching_object: 1.0179
    Episode_Reward/rotating_object: 4.5251
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.16s
                      Time elapsed: 00:08:55
                               ETA: 00:50:22

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 45369 steps/s (collection: 2.000s, learning 0.167s)
             Mean action noise std: 1.84
          Mean value_function loss: 10.2309
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 62.8597
                       Mean reward: 30.86
               Mean episode length: 214.37
    Episode_Reward/reaching_object: 0.9829
    Episode_Reward/rotating_object: 3.7082
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.17s
                      Time elapsed: 00:08:57
                               ETA: 00:50:18

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 43521 steps/s (collection: 2.074s, learning 0.185s)
             Mean action noise std: 1.84
          Mean value_function loss: 10.1442
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 62.8900
                       Mean reward: 34.10
               Mean episode length: 224.58
    Episode_Reward/reaching_object: 1.0533
    Episode_Reward/rotating_object: 5.4123
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.26s
                      Time elapsed: 00:09:00
                               ETA: 00:50:15

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 44332 steps/s (collection: 2.097s, learning 0.120s)
             Mean action noise std: 1.85
          Mean value_function loss: 10.0898
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 62.9389
                       Mean reward: 19.78
               Mean episode length: 217.58
    Episode_Reward/reaching_object: 1.0399
    Episode_Reward/rotating_object: 3.8940
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.22s
                      Time elapsed: 00:09:02
                               ETA: 00:50:12

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 42419 steps/s (collection: 2.158s, learning 0.159s)
             Mean action noise std: 1.85
          Mean value_function loss: 9.6732
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 62.9824
                       Mean reward: 24.66
               Mean episode length: 220.73
    Episode_Reward/reaching_object: 1.0194
    Episode_Reward/rotating_object: 3.7157
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.32s
                      Time elapsed: 00:09:04
                               ETA: 00:50:09

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 43880 steps/s (collection: 2.093s, learning 0.148s)
             Mean action noise std: 1.85
          Mean value_function loss: 9.1133
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.0392
                       Mean reward: 23.40
               Mean episode length: 218.86
    Episode_Reward/reaching_object: 1.0529
    Episode_Reward/rotating_object: 4.1135
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.24s
                      Time elapsed: 00:09:06
                               ETA: 00:50:06

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 43845 steps/s (collection: 2.115s, learning 0.127s)
             Mean action noise std: 1.86
          Mean value_function loss: 10.1710
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 63.0982
                       Mean reward: 27.93
               Mean episode length: 224.26
    Episode_Reward/reaching_object: 0.9992
    Episode_Reward/rotating_object: 3.6815
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.24s
                      Time elapsed: 00:09:09
                               ETA: 00:50:03

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 44199 steps/s (collection: 2.067s, learning 0.157s)
             Mean action noise std: 1.86
          Mean value_function loss: 10.4589
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 63.1578
                       Mean reward: 35.10
               Mean episode length: 227.35
    Episode_Reward/reaching_object: 1.0188
    Episode_Reward/rotating_object: 4.1973
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.22s
                      Time elapsed: 00:09:11
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 44130 steps/s (collection: 2.110s, learning 0.117s)
             Mean action noise std: 1.86
          Mean value_function loss: 10.6430
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 63.2038
                       Mean reward: 28.48
               Mean episode length: 215.05
    Episode_Reward/reaching_object: 1.0295
    Episode_Reward/rotating_object: 5.4483
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.23s
                      Time elapsed: 00:09:13
                               ETA: 00:49:57

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 40922 steps/s (collection: 2.188s, learning 0.214s)
             Mean action noise std: 1.87
          Mean value_function loss: 8.8026
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 63.2487
                       Mean reward: 31.50
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.0864
    Episode_Reward/rotating_object: 4.8391
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.40s
                      Time elapsed: 00:09:15
                               ETA: 00:49:55

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 43332 steps/s (collection: 2.096s, learning 0.172s)
             Mean action noise std: 1.87
          Mean value_function loss: 8.7856
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 63.2806
                       Mean reward: 35.94
               Mean episode length: 220.86
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 4.1435
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.27s
                      Time elapsed: 00:09:18
                               ETA: 00:49:52

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 44574 steps/s (collection: 2.066s, learning 0.140s)
             Mean action noise std: 1.87
          Mean value_function loss: 9.1796
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.3220
                       Mean reward: 28.64
               Mean episode length: 215.81
    Episode_Reward/reaching_object: 1.0182
    Episode_Reward/rotating_object: 4.3314
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.21s
                      Time elapsed: 00:09:20
                               ETA: 00:49:49

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 44316 steps/s (collection: 2.100s, learning 0.119s)
             Mean action noise std: 1.87
          Mean value_function loss: 8.8861
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.3605
                       Mean reward: 25.69
               Mean episode length: 218.17
    Episode_Reward/reaching_object: 1.0580
    Episode_Reward/rotating_object: 4.1122
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.22s
                      Time elapsed: 00:09:22
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 45330 steps/s (collection: 2.048s, learning 0.121s)
             Mean action noise std: 1.88
          Mean value_function loss: 9.9301
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 63.4044
                       Mean reward: 29.92
               Mean episode length: 217.36
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 5.1957
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.17s
                      Time elapsed: 00:09:24
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 45202 steps/s (collection: 2.049s, learning 0.126s)
             Mean action noise std: 1.88
          Mean value_function loss: 9.6389
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 63.4559
                       Mean reward: 31.87
               Mean episode length: 216.29
    Episode_Reward/reaching_object: 1.0285
    Episode_Reward/rotating_object: 4.0666
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.17s
                      Time elapsed: 00:09:27
                               ETA: 00:49:39

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 44137 steps/s (collection: 2.092s, learning 0.135s)
             Mean action noise std: 1.88
          Mean value_function loss: 8.7572
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 63.5099
                       Mean reward: 31.47
               Mean episode length: 221.96
    Episode_Reward/reaching_object: 1.0975
    Episode_Reward/rotating_object: 4.8964
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.23s
                      Time elapsed: 00:09:29
                               ETA: 00:49:36

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 44312 steps/s (collection: 2.100s, learning 0.118s)
             Mean action noise std: 1.89
          Mean value_function loss: 9.2640
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 63.5639
                       Mean reward: 25.96
               Mean episode length: 226.51
    Episode_Reward/reaching_object: 1.0420
    Episode_Reward/rotating_object: 3.8909
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.22s
                      Time elapsed: 00:09:31
                               ETA: 00:49:32

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 43785 steps/s (collection: 2.129s, learning 0.117s)
             Mean action noise std: 1.89
          Mean value_function loss: 10.6276
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 63.6122
                       Mean reward: 22.23
               Mean episode length: 224.22
    Episode_Reward/reaching_object: 1.0722
    Episode_Reward/rotating_object: 4.1049
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.25s
                      Time elapsed: 00:09:33
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 44389 steps/s (collection: 2.092s, learning 0.123s)
             Mean action noise std: 1.89
          Mean value_function loss: 11.2267
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 63.6552
                       Mean reward: 21.90
               Mean episode length: 218.52
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 4.0341
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.21s
                      Time elapsed: 00:09:35
                               ETA: 00:49:26

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 41670 steps/s (collection: 2.158s, learning 0.201s)
             Mean action noise std: 1.89
          Mean value_function loss: 9.9814
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 63.6955
                       Mean reward: 18.94
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 5.0420
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.36s
                      Time elapsed: 00:09:38
                               ETA: 00:49:24

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 41980 steps/s (collection: 2.247s, learning 0.095s)
             Mean action noise std: 1.90
          Mean value_function loss: 9.5054
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 63.7440
                       Mean reward: 22.78
               Mean episode length: 202.27
    Episode_Reward/reaching_object: 1.0048
    Episode_Reward/rotating_object: 3.7787
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 10.8750
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.34s
                      Time elapsed: 00:09:40
                               ETA: 00:49:22

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 44181 steps/s (collection: 2.119s, learning 0.106s)
             Mean action noise std: 1.90
          Mean value_function loss: 10.5198
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.7995
                       Mean reward: 20.72
               Mean episode length: 220.32
    Episode_Reward/reaching_object: 1.0381
    Episode_Reward/rotating_object: 3.6903
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.23s
                      Time elapsed: 00:09:42
                               ETA: 00:49:19

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 44536 steps/s (collection: 2.066s, learning 0.142s)
             Mean action noise std: 1.90
          Mean value_function loss: 10.3861
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 63.8499
                       Mean reward: 30.58
               Mean episode length: 219.96
    Episode_Reward/reaching_object: 1.0424
    Episode_Reward/rotating_object: 4.6630
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.21s
                      Time elapsed: 00:09:45
                               ETA: 00:49:15

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 44321 steps/s (collection: 2.082s, learning 0.136s)
             Mean action noise std: 1.91
          Mean value_function loss: 9.9160
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 63.8931
                       Mean reward: 24.45
               Mean episode length: 225.16
    Episode_Reward/reaching_object: 1.0457
    Episode_Reward/rotating_object: 3.6140
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.22s
                      Time elapsed: 00:09:47
                               ETA: 00:49:12

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 40275 steps/s (collection: 2.319s, learning 0.122s)
             Mean action noise std: 1.91
          Mean value_function loss: 10.7068
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 63.9522
                       Mean reward: 26.20
               Mean episode length: 215.92
    Episode_Reward/reaching_object: 1.0436
    Episode_Reward/rotating_object: 4.6778
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 1.4583
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.44s
                      Time elapsed: 00:09:49
                               ETA: 00:49:10

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 41969 steps/s (collection: 2.114s, learning 0.228s)
             Mean action noise std: 1.91
          Mean value_function loss: 9.9392
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 64.0079
                       Mean reward: 31.95
               Mean episode length: 214.82
    Episode_Reward/reaching_object: 1.0308
    Episode_Reward/rotating_object: 4.1006
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.34s
                      Time elapsed: 00:09:52
                               ETA: 00:49:08

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 40266 steps/s (collection: 2.257s, learning 0.185s)
             Mean action noise std: 1.91
          Mean value_function loss: 11.1104
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 64.0531
                       Mean reward: 31.03
               Mean episode length: 214.92
    Episode_Reward/reaching_object: 1.0307
    Episode_Reward/rotating_object: 5.3422
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 1.2917
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.44s
                      Time elapsed: 00:09:54
                               ETA: 00:49:06

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 41668 steps/s (collection: 2.235s, learning 0.124s)
             Mean action noise std: 1.92
          Mean value_function loss: 11.0261
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.0812
                       Mean reward: 29.78
               Mean episode length: 218.30
    Episode_Reward/reaching_object: 1.0413
    Episode_Reward/rotating_object: 4.3405
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.36s
                      Time elapsed: 00:09:56
                               ETA: 00:49:04

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 39540 steps/s (collection: 2.319s, learning 0.168s)
             Mean action noise std: 1.92
          Mean value_function loss: 10.0138
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.1385
                       Mean reward: 35.14
               Mean episode length: 221.56
    Episode_Reward/reaching_object: 1.0324
    Episode_Reward/rotating_object: 3.8826
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.49s
                      Time elapsed: 00:09:59
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 42380 steps/s (collection: 2.200s, learning 0.120s)
             Mean action noise std: 1.93
          Mean value_function loss: 9.8721
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 64.2067
                       Mean reward: 27.65
               Mean episode length: 212.16
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 5.3890
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.32s
                      Time elapsed: 00:10:01
                               ETA: 00:48:59

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 41381 steps/s (collection: 2.183s, learning 0.193s)
             Mean action noise std: 1.93
          Mean value_function loss: 11.7431
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 64.2625
                       Mean reward: 25.45
               Mean episode length: 215.10
    Episode_Reward/reaching_object: 1.0080
    Episode_Reward/rotating_object: 3.9984
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.38s
                      Time elapsed: 00:10:04
                               ETA: 00:48:57

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 41738 steps/s (collection: 2.222s, learning 0.133s)
             Mean action noise std: 1.93
          Mean value_function loss: 11.8404
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 64.3074
                       Mean reward: 35.50
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 1.0426
    Episode_Reward/rotating_object: 5.2418
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.36s
                      Time elapsed: 00:10:06
                               ETA: 00:48:55

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 40982 steps/s (collection: 2.243s, learning 0.156s)
             Mean action noise std: 1.93
          Mean value_function loss: 10.2641
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.3568
                       Mean reward: 32.76
               Mean episode length: 225.77
    Episode_Reward/reaching_object: 1.0363
    Episode_Reward/rotating_object: 5.1434
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.40s
                      Time elapsed: 00:10:08
                               ETA: 00:48:53

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 40037 steps/s (collection: 2.277s, learning 0.179s)
             Mean action noise std: 1.94
          Mean value_function loss: 10.8520
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.4124
                       Mean reward: 30.84
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 1.0549
    Episode_Reward/rotating_object: 4.5424
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.46s
                      Time elapsed: 00:10:11
                               ETA: 00:48:51

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 37526 steps/s (collection: 2.455s, learning 0.165s)
             Mean action noise std: 1.94
          Mean value_function loss: 11.0084
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 64.4680
                       Mean reward: 33.97
               Mean episode length: 215.80
    Episode_Reward/reaching_object: 1.0286
    Episode_Reward/rotating_object: 4.2932
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.62s
                      Time elapsed: 00:10:13
                               ETA: 00:48:49

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 39227 steps/s (collection: 2.320s, learning 0.186s)
             Mean action noise std: 1.94
          Mean value_function loss: 12.4965
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 64.5199
                       Mean reward: 19.18
               Mean episode length: 214.40
    Episode_Reward/reaching_object: 0.9988
    Episode_Reward/rotating_object: 4.1381
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.51s
                      Time elapsed: 00:10:16
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 42708 steps/s (collection: 2.163s, learning 0.139s)
             Mean action noise std: 1.95
          Mean value_function loss: 13.4112
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 64.5791
                       Mean reward: 32.89
               Mean episode length: 217.82
    Episode_Reward/reaching_object: 1.0098
    Episode_Reward/rotating_object: 4.6113
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 1.7917
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.30s
                      Time elapsed: 00:10:18
                               ETA: 00:48:45

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 41765 steps/s (collection: 2.156s, learning 0.198s)
             Mean action noise std: 1.95
          Mean value_function loss: 11.5820
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 64.6228
                       Mean reward: 26.77
               Mean episode length: 226.04
    Episode_Reward/reaching_object: 1.0509
    Episode_Reward/rotating_object: 5.1800
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.35s
                      Time elapsed: 00:10:21
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 40692 steps/s (collection: 2.233s, learning 0.183s)
             Mean action noise std: 1.95
          Mean value_function loss: 12.9441
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.6672
                       Mean reward: 24.26
               Mean episode length: 225.55
    Episode_Reward/reaching_object: 1.0233
    Episode_Reward/rotating_object: 4.6997
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.42s
                      Time elapsed: 00:10:23
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 42975 steps/s (collection: 2.154s, learning 0.133s)
             Mean action noise std: 1.96
          Mean value_function loss: 12.0005
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 64.7102
                       Mean reward: 42.44
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 1.0247
    Episode_Reward/rotating_object: 5.6832
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.29s
                      Time elapsed: 00:10:25
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 43508 steps/s (collection: 2.110s, learning 0.149s)
             Mean action noise std: 1.96
          Mean value_function loss: 10.4296
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 64.7638
                       Mean reward: 38.89
               Mean episode length: 216.66
    Episode_Reward/reaching_object: 1.0337
    Episode_Reward/rotating_object: 6.0760
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.26s
                      Time elapsed: 00:10:27
                               ETA: 00:48:35

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 41464 steps/s (collection: 2.199s, learning 0.172s)
             Mean action noise std: 1.96
          Mean value_function loss: 11.9369
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 64.8186
                       Mean reward: 29.96
               Mean episode length: 219.44
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 4.9222
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.37s
                      Time elapsed: 00:10:30
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 41847 steps/s (collection: 2.203s, learning 0.146s)
             Mean action noise std: 1.97
          Mean value_function loss: 12.0090
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.8637
                       Mean reward: 28.32
               Mean episode length: 216.37
    Episode_Reward/reaching_object: 1.0296
    Episode_Reward/rotating_object: 5.5024
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.35s
                      Time elapsed: 00:10:32
                               ETA: 00:48:30

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 42225 steps/s (collection: 2.183s, learning 0.145s)
             Mean action noise std: 1.97
          Mean value_function loss: 11.2372
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 64.9096
                       Mean reward: 26.81
               Mean episode length: 216.14
    Episode_Reward/reaching_object: 1.0343
    Episode_Reward/rotating_object: 5.4636
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.33s
                      Time elapsed: 00:10:35
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 40681 steps/s (collection: 2.220s, learning 0.196s)
             Mean action noise std: 1.97
          Mean value_function loss: 12.4415
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 64.9726
                       Mean reward: 45.58
               Mean episode length: 226.14
    Episode_Reward/reaching_object: 1.0354
    Episode_Reward/rotating_object: 6.2485
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.42s
                      Time elapsed: 00:10:37
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 41288 steps/s (collection: 2.206s, learning 0.175s)
             Mean action noise std: 1.98
          Mean value_function loss: 11.6705
               Mean surrogate loss: -0.0112
                 Mean entropy loss: 65.0395
                       Mean reward: 33.22
               Mean episode length: 225.40
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 5.1869
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.38s
                      Time elapsed: 00:10:39
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 40891 steps/s (collection: 2.256s, learning 0.148s)
             Mean action noise std: 1.98
          Mean value_function loss: 11.3364
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 65.0920
                       Mean reward: 30.62
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 1.0532
    Episode_Reward/rotating_object: 4.9217
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.40s
                      Time elapsed: 00:10:42
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 42618 steps/s (collection: 2.114s, learning 0.192s)
             Mean action noise std: 1.98
          Mean value_function loss: 10.4557
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 65.1340
                       Mean reward: 35.99
               Mean episode length: 219.54
    Episode_Reward/reaching_object: 1.0348
    Episode_Reward/rotating_object: 4.5140
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.31s
                      Time elapsed: 00:10:44
                               ETA: 00:48:19

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 42998 steps/s (collection: 2.155s, learning 0.131s)
             Mean action noise std: 1.99
          Mean value_function loss: 11.1366
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 65.1855
                       Mean reward: 24.82
               Mean episode length: 225.93
    Episode_Reward/reaching_object: 1.0288
    Episode_Reward/rotating_object: 3.9976
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.29s
                      Time elapsed: 00:10:46
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 40180 steps/s (collection: 2.287s, learning 0.159s)
             Mean action noise std: 1.99
          Mean value_function loss: 11.6464
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.2307
                       Mean reward: 32.30
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.0832
    Episode_Reward/rotating_object: 4.4444
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.45s
                      Time elapsed: 00:10:49
                               ETA: 00:48:14

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 43471 steps/s (collection: 2.112s, learning 0.150s)
             Mean action noise std: 1.99
          Mean value_function loss: 10.4036
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 65.2824
                       Mean reward: 37.67
               Mean episode length: 221.12
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 5.7405
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.26s
                      Time elapsed: 00:10:51
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 42513 steps/s (collection: 2.137s, learning 0.176s)
             Mean action noise std: 2.00
          Mean value_function loss: 9.6002
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 65.3360
                       Mean reward: 28.97
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 1.0963
    Episode_Reward/rotating_object: 5.4014
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.31s
                      Time elapsed: 00:10:53
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 42303 steps/s (collection: 2.160s, learning 0.164s)
             Mean action noise std: 2.00
          Mean value_function loss: 10.3278
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 65.3837
                       Mean reward: 28.32
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.0584
    Episode_Reward/rotating_object: 4.4742
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.32s
                      Time elapsed: 00:10:56
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 42695 steps/s (collection: 2.127s, learning 0.175s)
             Mean action noise std: 2.00
          Mean value_function loss: 9.8347
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.4331
                       Mean reward: 44.61
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.0574
    Episode_Reward/rotating_object: 5.0655
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.30s
                      Time elapsed: 00:10:58
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 41333 steps/s (collection: 2.252s, learning 0.126s)
             Mean action noise std: 2.00
          Mean value_function loss: 10.1449
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.4721
                       Mean reward: 39.54
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.0562
    Episode_Reward/rotating_object: 5.8296
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.38s
                      Time elapsed: 00:11:00
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 41220 steps/s (collection: 2.181s, learning 0.204s)
             Mean action noise std: 2.01
          Mean value_function loss: 11.7358
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 65.5023
                       Mean reward: 22.67
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 4.4278
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.38s
                      Time elapsed: 00:11:03
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 43333 steps/s (collection: 2.139s, learning 0.129s)
             Mean action noise std: 2.01
          Mean value_function loss: 12.4211
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 65.5487
                       Mean reward: 21.58
               Mean episode length: 226.86
    Episode_Reward/reaching_object: 1.0576
    Episode_Reward/rotating_object: 4.5063
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.27s
                      Time elapsed: 00:11:05
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 44231 steps/s (collection: 2.088s, learning 0.134s)
             Mean action noise std: 2.01
          Mean value_function loss: 12.0417
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 65.5877
                       Mean reward: 24.05
               Mean episode length: 228.83
    Episode_Reward/reaching_object: 1.0507
    Episode_Reward/rotating_object: 4.6818
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.22s
                      Time elapsed: 00:11:07
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 42133 steps/s (collection: 2.160s, learning 0.173s)
             Mean action noise std: 2.02
          Mean value_function loss: 13.0191
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 65.6337
                       Mean reward: 24.49
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.0624
    Episode_Reward/rotating_object: 4.8607
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.33s
                      Time elapsed: 00:11:10
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 41138 steps/s (collection: 2.222s, learning 0.168s)
             Mean action noise std: 2.02
          Mean value_function loss: 13.3304
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 65.6828
                       Mean reward: 41.93
               Mean episode length: 228.45
    Episode_Reward/reaching_object: 1.0711
    Episode_Reward/rotating_object: 6.3778
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.39s
                      Time elapsed: 00:11:12
                               ETA: 00:47:49

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 40100 steps/s (collection: 2.294s, learning 0.157s)
             Mean action noise std: 2.02
          Mean value_function loss: 11.9245
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.7342
                       Mean reward: 32.02
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 1.1026
    Episode_Reward/rotating_object: 5.3397
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.45s
                      Time elapsed: 00:11:14
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 43192 steps/s (collection: 2.128s, learning 0.148s)
             Mean action noise std: 2.03
          Mean value_function loss: 11.2162
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.7847
                       Mean reward: 27.86
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.1204
    Episode_Reward/rotating_object: 5.5091
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.28s
                      Time elapsed: 00:11:17
                               ETA: 00:47:44

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 42758 steps/s (collection: 2.103s, learning 0.196s)
             Mean action noise std: 2.03
          Mean value_function loss: 11.0958
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.8336
                       Mean reward: 43.30
               Mean episode length: 218.59
    Episode_Reward/reaching_object: 1.0850
    Episode_Reward/rotating_object: 6.3333
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.30s
                      Time elapsed: 00:11:19
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 39909 steps/s (collection: 2.266s, learning 0.198s)
             Mean action noise std: 2.03
          Mean value_function loss: 11.9830
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 65.8694
                       Mean reward: 35.24
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 1.0707
    Episode_Reward/rotating_object: 5.6807
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.46s
                      Time elapsed: 00:11:21
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 43353 steps/s (collection: 2.139s, learning 0.129s)
             Mean action noise std: 2.04
          Mean value_function loss: 12.1956
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 65.9231
                       Mean reward: 26.03
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 1.0575
    Episode_Reward/rotating_object: 4.9398
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.27s
                      Time elapsed: 00:11:24
                               ETA: 00:47:37

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 42768 steps/s (collection: 2.179s, learning 0.120s)
             Mean action noise std: 2.04
          Mean value_function loss: 13.9846
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 65.9750
                       Mean reward: 28.56
               Mean episode length: 219.42
    Episode_Reward/reaching_object: 1.0162
    Episode_Reward/rotating_object: 4.9881
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.30s
                      Time elapsed: 00:11:26
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 43716 steps/s (collection: 2.084s, learning 0.165s)
             Mean action noise std: 2.04
          Mean value_function loss: 14.6135
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 66.0157
                       Mean reward: 28.28
               Mean episode length: 224.33
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 4.2498
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.25s
                      Time elapsed: 00:11:28
                               ETA: 00:47:31

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 41003 steps/s (collection: 2.232s, learning 0.166s)
             Mean action noise std: 2.04
          Mean value_function loss: 15.2654
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 66.0528
                       Mean reward: 28.75
               Mean episode length: 226.00
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 4.8063
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.40s
                      Time elapsed: 00:11:31
                               ETA: 00:47:29

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 42394 steps/s (collection: 2.215s, learning 0.104s)
             Mean action noise std: 2.05
          Mean value_function loss: 14.2273
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 66.0964
                       Mean reward: 37.98
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 1.1042
    Episode_Reward/rotating_object: 6.0871
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.32s
                      Time elapsed: 00:11:33
                               ETA: 00:47:26

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 42479 steps/s (collection: 2.199s, learning 0.115s)
             Mean action noise std: 2.05
          Mean value_function loss: 12.1201
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 66.1382
                       Mean reward: 29.36
               Mean episode length: 220.92
    Episode_Reward/reaching_object: 1.0709
    Episode_Reward/rotating_object: 5.5867
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.31s
                      Time elapsed: 00:11:35
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 41970 steps/s (collection: 2.200s, learning 0.142s)
             Mean action noise std: 2.05
          Mean value_function loss: 12.9938
               Mean surrogate loss: -0.0108
                 Mean entropy loss: 66.1933
                       Mean reward: 36.99
               Mean episode length: 228.52
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 5.7754
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.34s
                      Time elapsed: 00:11:38
                               ETA: 00:47:22

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 41140 steps/s (collection: 2.195s, learning 0.195s)
             Mean action noise std: 2.06
          Mean value_function loss: 14.7897
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 66.2416
                       Mean reward: 33.08
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.0892
    Episode_Reward/rotating_object: 5.7454
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.39s
                      Time elapsed: 00:11:40
                               ETA: 00:47:19

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 42833 steps/s (collection: 2.139s, learning 0.156s)
             Mean action noise std: 2.06
          Mean value_function loss: 15.5874
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 66.2772
                       Mean reward: 26.90
               Mean episode length: 215.84
    Episode_Reward/reaching_object: 1.0510
    Episode_Reward/rotating_object: 5.1946
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.30s
                      Time elapsed: 00:11:42
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 41516 steps/s (collection: 2.227s, learning 0.141s)
             Mean action noise std: 2.06
          Mean value_function loss: 13.9837
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 66.3281
                       Mean reward: 27.10
               Mean episode length: 226.73
    Episode_Reward/reaching_object: 1.0956
    Episode_Reward/rotating_object: 5.6421
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.37s
                      Time elapsed: 00:11:45
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 40023 steps/s (collection: 2.300s, learning 0.156s)
             Mean action noise std: 2.07
          Mean value_function loss: 15.4204
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 66.3837
                       Mean reward: 50.97
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 1.0839
    Episode_Reward/rotating_object: 6.5727
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.46s
                      Time elapsed: 00:11:47
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 43191 steps/s (collection: 2.127s, learning 0.149s)
             Mean action noise std: 2.07
          Mean value_function loss: 13.7131
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.4408
                       Mean reward: 35.34
               Mean episode length: 224.62
    Episode_Reward/reaching_object: 1.0536
    Episode_Reward/rotating_object: 6.2113
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.28s
                      Time elapsed: 00:11:49
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 40504 steps/s (collection: 2.267s, learning 0.160s)
             Mean action noise std: 2.07
          Mean value_function loss: 12.9574
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 66.4831
                       Mean reward: 29.61
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 5.3623
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.43s
                      Time elapsed: 00:11:52
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 40576 steps/s (collection: 2.276s, learning 0.147s)
             Mean action noise std: 2.07
          Mean value_function loss: 14.8712
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 66.5148
                       Mean reward: 38.85
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 5.3218
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.42s
                      Time elapsed: 00:11:54
                               ETA: 00:47:06

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 43624 steps/s (collection: 2.122s, learning 0.131s)
             Mean action noise std: 2.08
          Mean value_function loss: 14.7588
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 66.5447
                       Mean reward: 36.70
               Mean episode length: 220.60
    Episode_Reward/reaching_object: 1.0800
    Episode_Reward/rotating_object: 6.1397
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.25s
                      Time elapsed: 00:11:57
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 42778 steps/s (collection: 2.152s, learning 0.146s)
             Mean action noise std: 2.08
          Mean value_function loss: 15.3850
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 66.5855
                       Mean reward: 45.53
               Mean episode length: 212.76
    Episode_Reward/reaching_object: 1.0461
    Episode_Reward/rotating_object: 5.9956
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.30s
                      Time elapsed: 00:11:59
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 40539 steps/s (collection: 2.234s, learning 0.191s)
             Mean action noise std: 2.08
          Mean value_function loss: 16.7007
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 66.6359
                       Mean reward: 31.23
               Mean episode length: 209.11
    Episode_Reward/reaching_object: 1.0581
    Episode_Reward/rotating_object: 6.2088
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.42s
                      Time elapsed: 00:12:01
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 40585 steps/s (collection: 2.234s, learning 0.189s)
             Mean action noise std: 2.09
          Mean value_function loss: 16.5814
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.6873
                       Mean reward: 33.01
               Mean episode length: 218.66
    Episode_Reward/reaching_object: 1.0528
    Episode_Reward/rotating_object: 6.4031
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.42s
                      Time elapsed: 00:12:04
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 40343 steps/s (collection: 2.257s, learning 0.180s)
             Mean action noise std: 2.09
          Mean value_function loss: 15.1338
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 66.7273
                       Mean reward: 29.97
               Mean episode length: 212.97
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 6.4861
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.44s
                      Time elapsed: 00:12:06
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 41770 steps/s (collection: 2.176s, learning 0.177s)
             Mean action noise std: 2.09
          Mean value_function loss: 14.5939
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 66.7684
                       Mean reward: 34.20
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 5.8765
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.35s
                      Time elapsed: 00:12:08
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 41713 steps/s (collection: 2.153s, learning 0.204s)
             Mean action noise std: 2.09
          Mean value_function loss: 14.6598
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 66.8183
                       Mean reward: 40.12
               Mean episode length: 221.16
    Episode_Reward/reaching_object: 1.0521
    Episode_Reward/rotating_object: 6.5493
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.36s
                      Time elapsed: 00:12:11
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 41078 steps/s (collection: 2.212s, learning 0.181s)
             Mean action noise std: 2.10
          Mean value_function loss: 17.3901
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 66.8670
                       Mean reward: 34.45
               Mean episode length: 214.89
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 4.8436
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.39s
                      Time elapsed: 00:12:13
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 41000 steps/s (collection: 2.223s, learning 0.175s)
             Mean action noise std: 2.10
          Mean value_function loss: 16.0153
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 66.9054
                       Mean reward: 31.39
               Mean episode length: 222.96
    Episode_Reward/reaching_object: 1.0353
    Episode_Reward/rotating_object: 5.5623
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.40s
                      Time elapsed: 00:12:16
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 42171 steps/s (collection: 2.183s, learning 0.148s)
             Mean action noise std: 2.10
          Mean value_function loss: 13.5214
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 66.9415
                       Mean reward: 41.18
               Mean episode length: 219.39
    Episode_Reward/reaching_object: 1.0839
    Episode_Reward/rotating_object: 7.1891
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.33s
                      Time elapsed: 00:12:18
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 41044 steps/s (collection: 2.192s, learning 0.203s)
             Mean action noise std: 2.11
          Mean value_function loss: 14.2505
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 66.9781
                       Mean reward: 58.96
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 1.0926
    Episode_Reward/rotating_object: 7.5748
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.40s
                      Time elapsed: 00:12:20
                               ETA: 00:46:40

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 42946 steps/s (collection: 2.136s, learning 0.153s)
             Mean action noise std: 2.11
          Mean value_function loss: 14.8412
               Mean surrogate loss: -0.0110
                 Mean entropy loss: 67.0106
                       Mean reward: 33.26
               Mean episode length: 219.89
    Episode_Reward/reaching_object: 1.1048
    Episode_Reward/rotating_object: 7.4025
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.29s
                      Time elapsed: 00:12:23
                               ETA: 00:46:37

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 41896 steps/s (collection: 2.129s, learning 0.218s)
             Mean action noise std: 2.11
          Mean value_function loss: 15.0168
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 67.0521
                       Mean reward: 37.87
               Mean episode length: 222.92
    Episode_Reward/reaching_object: 1.1058
    Episode_Reward/rotating_object: 5.9144
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.35s
                      Time elapsed: 00:12:25
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 40651 steps/s (collection: 2.259s, learning 0.159s)
             Mean action noise std: 2.11
          Mean value_function loss: 18.3714
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 67.0954
                       Mean reward: 46.11
               Mean episode length: 224.84
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 6.9979
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.42s
                      Time elapsed: 00:12:27
                               ETA: 00:46:33

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 42515 steps/s (collection: 2.181s, learning 0.131s)
             Mean action noise std: 2.12
          Mean value_function loss: 19.0376
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 67.1360
                       Mean reward: 49.84
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.0819
    Episode_Reward/rotating_object: 7.0410
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.31s
                      Time elapsed: 00:12:30
                               ETA: 00:46:30

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 37865 steps/s (collection: 2.373s, learning 0.223s)
             Mean action noise std: 2.12
          Mean value_function loss: 20.0738
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.1794
                       Mean reward: 44.81
               Mean episode length: 223.29
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 7.3111
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.60s
                      Time elapsed: 00:12:32
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 40044 steps/s (collection: 2.266s, learning 0.189s)
             Mean action noise std: 2.12
          Mean value_function loss: 18.7384
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 67.2159
                       Mean reward: 41.36
               Mean episode length: 219.54
    Episode_Reward/reaching_object: 1.0819
    Episode_Reward/rotating_object: 8.4901
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.45s
                      Time elapsed: 00:12:35
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 42932 steps/s (collection: 2.105s, learning 0.185s)
             Mean action noise std: 2.13
          Mean value_function loss: 21.1471
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 67.2603
                       Mean reward: 21.29
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 1.1076
    Episode_Reward/rotating_object: 6.2867
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.29s
                      Time elapsed: 00:12:37
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 40083 steps/s (collection: 2.309s, learning 0.144s)
             Mean action noise std: 2.13
          Mean value_function loss: 19.7806
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 67.2985
                       Mean reward: 30.48
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.0754
    Episode_Reward/rotating_object: 5.9849
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.45s
                      Time elapsed: 00:12:39
                               ETA: 00:46:22

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 40052 steps/s (collection: 2.258s, learning 0.197s)
             Mean action noise std: 2.13
          Mean value_function loss: 16.9287
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 67.3298
                       Mean reward: 40.22
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 7.5373
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.45s
                      Time elapsed: 00:12:42
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 42338 steps/s (collection: 2.184s, learning 0.138s)
             Mean action noise std: 2.13
          Mean value_function loss: 19.3580
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 67.3734
                       Mean reward: 50.61
               Mean episode length: 226.65
    Episode_Reward/reaching_object: 1.0899
    Episode_Reward/rotating_object: 9.2323
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.32s
                      Time elapsed: 00:12:44
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 40418 steps/s (collection: 2.281s, learning 0.152s)
             Mean action noise std: 2.14
          Mean value_function loss: 17.2444
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 67.4191
                       Mean reward: 46.74
               Mean episode length: 217.78
    Episode_Reward/reaching_object: 1.0582
    Episode_Reward/rotating_object: 8.2697
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.43s
                      Time elapsed: 00:12:47
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 42123 steps/s (collection: 2.181s, learning 0.153s)
             Mean action noise std: 2.14
          Mean value_function loss: 20.7041
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 67.4605
                       Mean reward: 57.53
               Mean episode length: 217.60
    Episode_Reward/reaching_object: 1.0963
    Episode_Reward/rotating_object: 9.1508
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.33s
                      Time elapsed: 00:12:49
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 39680 steps/s (collection: 2.339s, learning 0.138s)
             Mean action noise std: 2.14
          Mean value_function loss: 21.4091
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 67.5005
                       Mean reward: 37.54
               Mean episode length: 220.92
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 7.3715
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.48s
                      Time elapsed: 00:12:51
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 39664 steps/s (collection: 2.305s, learning 0.173s)
             Mean action noise std: 2.14
          Mean value_function loss: 19.7567
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 67.5398
                       Mean reward: 49.44
               Mean episode length: 213.23
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 8.6009
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.48s
                      Time elapsed: 00:12:54
                               ETA: 00:46:09

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 41551 steps/s (collection: 2.232s, learning 0.134s)
             Mean action noise std: 2.15
          Mean value_function loss: 19.4879
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 67.5827
                       Mean reward: 53.99
               Mean episode length: 223.58
    Episode_Reward/reaching_object: 1.0746
    Episode_Reward/rotating_object: 8.0251
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.37s
                      Time elapsed: 00:12:56
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 39545 steps/s (collection: 2.290s, learning 0.196s)
             Mean action noise std: 2.15
          Mean value_function loss: 24.2484
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 67.6231
                       Mean reward: 49.02
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 8.3487
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.49s
                      Time elapsed: 00:12:59
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 39972 steps/s (collection: 2.301s, learning 0.158s)
             Mean action noise std: 2.15
          Mean value_function loss: 23.8348
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 67.6705
                       Mean reward: 42.14
               Mean episode length: 220.82
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 8.2683
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.46s
                      Time elapsed: 00:13:01
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 41082 steps/s (collection: 2.234s, learning 0.159s)
             Mean action noise std: 2.16
          Mean value_function loss: 24.0728
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 67.7151
                       Mean reward: 47.62
               Mean episode length: 225.73
    Episode_Reward/reaching_object: 1.0916
    Episode_Reward/rotating_object: 7.8350
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.39s
                      Time elapsed: 00:13:04
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 40179 steps/s (collection: 2.262s, learning 0.184s)
             Mean action noise std: 2.16
          Mean value_function loss: 22.5106
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 67.7561
                       Mean reward: 56.93
               Mean episode length: 218.55
    Episode_Reward/reaching_object: 1.0981
    Episode_Reward/rotating_object: 9.3430
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.45s
                      Time elapsed: 00:13:06
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 18870 steps/s (collection: 5.014s, learning 0.195s)
             Mean action noise std: 2.16
          Mean value_function loss: 21.0882
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 67.7957
                       Mean reward: 45.79
               Mean episode length: 218.56
    Episode_Reward/reaching_object: 1.0882
    Episode_Reward/rotating_object: 9.2841
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.21s
                      Time elapsed: 00:13:11
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14190 steps/s (collection: 6.790s, learning 0.137s)
             Mean action noise std: 2.16
          Mean value_function loss: 19.5229
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.8320
                       Mean reward: 57.32
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 1.1009
    Episode_Reward/rotating_object: 8.3355
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.93s
                      Time elapsed: 00:13:18
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 13855 steps/s (collection: 6.885s, learning 0.210s)
             Mean action noise std: 2.17
          Mean value_function loss: 20.5020
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.8613
                       Mean reward: 62.68
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.0962
    Episode_Reward/rotating_object: 10.2601
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 7.10s
                      Time elapsed: 00:13:25
                               ETA: 00:46:34

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14030 steps/s (collection: 6.822s, learning 0.185s)
             Mean action noise std: 2.17
          Mean value_function loss: 23.5621
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 67.9035
                       Mean reward: 42.69
               Mean episode length: 222.75
    Episode_Reward/reaching_object: 1.1114
    Episode_Reward/rotating_object: 8.8217
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0543
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 7.01s
                      Time elapsed: 00:13:32
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14489 steps/s (collection: 6.657s, learning 0.127s)
             Mean action noise std: 2.17
          Mean value_function loss: 21.7923
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 67.9334
                       Mean reward: 47.55
               Mean episode length: 227.73
    Episode_Reward/reaching_object: 1.0966
    Episode_Reward/rotating_object: 8.6382
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0539
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.78s
                      Time elapsed: 00:13:39
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14230 steps/s (collection: 6.764s, learning 0.144s)
             Mean action noise std: 2.17
          Mean value_function loss: 22.2064
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 67.9667
                       Mean reward: 50.66
               Mean episode length: 219.59
    Episode_Reward/reaching_object: 1.0968
    Episode_Reward/rotating_object: 8.9902
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.91s
                      Time elapsed: 00:13:46
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 14263 steps/s (collection: 6.742s, learning 0.150s)
             Mean action noise std: 2.18
          Mean value_function loss: 22.1801
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.0035
                       Mean reward: 58.71
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 1.0792
    Episode_Reward/rotating_object: 8.9942
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 1.2917
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.89s
                      Time elapsed: 00:13:53
                               ETA: 00:47:25

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14097 steps/s (collection: 6.827s, learning 0.146s)
             Mean action noise std: 2.18
          Mean value_function loss: 20.8543
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 68.0307
                       Mean reward: 54.80
               Mean episode length: 222.54
    Episode_Reward/reaching_object: 1.0935
    Episode_Reward/rotating_object: 8.0493
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.97s
                      Time elapsed: 00:14:00
                               ETA: 00:47:38

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 11890 steps/s (collection: 8.078s, learning 0.190s)
             Mean action noise std: 2.18
          Mean value_function loss: 21.1215
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 68.0714
                       Mean reward: 39.60
               Mean episode length: 209.38
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 8.2990
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 8.27s
                      Time elapsed: 00:14:08
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 38286 steps/s (collection: 2.382s, learning 0.185s)
             Mean action noise std: 2.18
          Mean value_function loss: 22.7451
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 68.1091
                       Mean reward: 46.56
               Mean episode length: 221.39
    Episode_Reward/reaching_object: 1.1078
    Episode_Reward/rotating_object: 9.7721
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.57s
                      Time elapsed: 00:14:11
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 40313 steps/s (collection: 2.289s, learning 0.150s)
             Mean action noise std: 2.19
          Mean value_function loss: 24.9815
               Mean surrogate loss: -0.0111
                 Mean entropy loss: 68.1509
                       Mean reward: 56.96
               Mean episode length: 214.69
    Episode_Reward/reaching_object: 1.1241
    Episode_Reward/rotating_object: 10.3897
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.44s
                      Time elapsed: 00:14:13
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 44158 steps/s (collection: 2.115s, learning 0.111s)
             Mean action noise std: 2.19
          Mean value_function loss: 27.2341
               Mean surrogate loss: -0.0109
                 Mean entropy loss: 68.1827
                       Mean reward: 40.15
               Mean episode length: 211.36
    Episode_Reward/reaching_object: 1.1114
    Episode_Reward/rotating_object: 10.5611
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.23s
                      Time elapsed: 00:14:15
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 45550 steps/s (collection: 2.065s, learning 0.093s)
             Mean action noise std: 2.19
          Mean value_function loss: 24.4213
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 68.2155
                       Mean reward: 42.82
               Mean episode length: 214.90
    Episode_Reward/reaching_object: 1.0884
    Episode_Reward/rotating_object: 9.6559
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.16s
                      Time elapsed: 00:14:18
                               ETA: 00:47:44

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 48824 steps/s (collection: 1.907s, learning 0.107s)
             Mean action noise std: 2.19
          Mean value_function loss: 25.2636
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 68.2437
                       Mean reward: 83.71
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.1351
    Episode_Reward/rotating_object: 11.0132
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.01s
                      Time elapsed: 00:14:20
                               ETA: 00:47:40

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 46482 steps/s (collection: 1.963s, learning 0.152s)
             Mean action noise std: 2.20
          Mean value_function loss: 24.9641
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 68.2778
                       Mean reward: 61.72
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 1.1409
    Episode_Reward/rotating_object: 11.3492
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.11s
                      Time elapsed: 00:14:22
                               ETA: 00:47:36

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 46280 steps/s (collection: 1.959s, learning 0.165s)
             Mean action noise std: 2.20
          Mean value_function loss: 24.6048
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.3121
                       Mean reward: 32.36
               Mean episode length: 214.24
    Episode_Reward/reaching_object: 1.1200
    Episode_Reward/rotating_object: 9.7439
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.12s
                      Time elapsed: 00:14:24
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 45210 steps/s (collection: 2.046s, learning 0.128s)
             Mean action noise std: 2.20
          Mean value_function loss: 30.5611
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.3445
                       Mean reward: 58.39
               Mean episode length: 218.84
    Episode_Reward/reaching_object: 1.1472
    Episode_Reward/rotating_object: 9.9373
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.17s
                      Time elapsed: 00:14:26
                               ETA: 00:47:29

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 44311 steps/s (collection: 2.081s, learning 0.138s)
             Mean action noise std: 2.20
          Mean value_function loss: 30.3289
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 68.3736
                       Mean reward: 60.49
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.1386
    Episode_Reward/rotating_object: 10.9226
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.22s
                      Time elapsed: 00:14:28
                               ETA: 00:47:26

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 44935 steps/s (collection: 2.038s, learning 0.149s)
             Mean action noise std: 2.20
          Mean value_function loss: 27.8243
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 68.4004
                       Mean reward: 72.58
               Mean episode length: 219.74
    Episode_Reward/reaching_object: 1.1368
    Episode_Reward/rotating_object: 12.2013
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.19s
                      Time elapsed: 00:14:30
                               ETA: 00:47:22

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 45334 steps/s (collection: 2.020s, learning 0.148s)
             Mean action noise std: 2.21
          Mean value_function loss: 25.0705
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 68.4244
                       Mean reward: 49.97
               Mean episode length: 212.35
    Episode_Reward/reaching_object: 1.1211
    Episode_Reward/rotating_object: 11.1741
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.17s
                      Time elapsed: 00:14:33
                               ETA: 00:47:19

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 43182 steps/s (collection: 2.154s, learning 0.123s)
             Mean action noise std: 2.21
          Mean value_function loss: 28.5432
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.4549
                       Mean reward: 69.03
               Mean episode length: 217.36
    Episode_Reward/reaching_object: 1.1106
    Episode_Reward/rotating_object: 9.9035
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.28s
                      Time elapsed: 00:14:35
                               ETA: 00:47:16

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 41076 steps/s (collection: 2.192s, learning 0.201s)
             Mean action noise std: 2.21
          Mean value_function loss: 26.9915
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 68.4874
                       Mean reward: 51.92
               Mean episode length: 218.52
    Episode_Reward/reaching_object: 1.1246
    Episode_Reward/rotating_object: 10.6922
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.39s
                      Time elapsed: 00:14:37
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 40914 steps/s (collection: 2.246s, learning 0.157s)
             Mean action noise std: 2.21
          Mean value_function loss: 31.3109
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 68.5217
                       Mean reward: 43.76
               Mean episode length: 218.47
    Episode_Reward/reaching_object: 1.1404
    Episode_Reward/rotating_object: 9.5265
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.40s
                      Time elapsed: 00:14:40
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 43212 steps/s (collection: 2.090s, learning 0.185s)
             Mean action noise std: 2.22
          Mean value_function loss: 27.6683
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 68.5542
                       Mean reward: 69.32
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.1672
    Episode_Reward/rotating_object: 10.6944
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0594
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.27s
                      Time elapsed: 00:14:42
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 42792 steps/s (collection: 2.107s, learning 0.191s)
             Mean action noise std: 2.22
          Mean value_function loss: 28.0042
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 68.5880
                       Mean reward: 66.44
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 1.1424
    Episode_Reward/rotating_object: 11.4325
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.30s
                      Time elapsed: 00:14:44
                               ETA: 00:47:04

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 43210 steps/s (collection: 2.174s, learning 0.101s)
             Mean action noise std: 2.22
          Mean value_function loss: 26.3360
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 68.6243
                       Mean reward: 58.63
               Mean episode length: 220.13
    Episode_Reward/reaching_object: 1.1623
    Episode_Reward/rotating_object: 11.0345
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.28s
                      Time elapsed: 00:14:47
                               ETA: 00:47:01

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 47453 steps/s (collection: 1.979s, learning 0.093s)
             Mean action noise std: 2.22
          Mean value_function loss: 31.9098
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 68.6610
                       Mean reward: 63.33
               Mean episode length: 216.96
    Episode_Reward/reaching_object: 1.1661
    Episode_Reward/rotating_object: 10.9515
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.07s
                      Time elapsed: 00:14:49
                               ETA: 00:46:57

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 43695 steps/s (collection: 2.127s, learning 0.123s)
             Mean action noise std: 2.23
          Mean value_function loss: 28.2098
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 68.6893
                       Mean reward: 49.14
               Mean episode length: 219.30
    Episode_Reward/reaching_object: 1.1606
    Episode_Reward/rotating_object: 13.0041
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.25s
                      Time elapsed: 00:14:51
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 45376 steps/s (collection: 2.041s, learning 0.125s)
             Mean action noise std: 2.23
          Mean value_function loss: 32.4130
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 68.7121
                       Mean reward: 78.62
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 12.6413
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0586
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.17s
                      Time elapsed: 00:14:53
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 45307 steps/s (collection: 2.027s, learning 0.143s)
             Mean action noise std: 2.23
          Mean value_function loss: 27.9880
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 68.7433
                       Mean reward: 83.86
               Mean episode length: 222.77
    Episode_Reward/reaching_object: 1.1704
    Episode_Reward/rotating_object: 14.9271
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0582
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.17s
                      Time elapsed: 00:14:55
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 45085 steps/s (collection: 2.081s, learning 0.100s)
             Mean action noise std: 2.23
          Mean value_function loss: 30.1887
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 68.7673
                       Mean reward: 66.36
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 1.1690
    Episode_Reward/rotating_object: 11.3194
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.18s
                      Time elapsed: 00:14:57
                               ETA: 00:46:44

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 42776 steps/s (collection: 2.122s, learning 0.176s)
             Mean action noise std: 2.23
          Mean value_function loss: 28.4125
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 68.7896
                       Mean reward: 71.49
               Mean episode length: 225.18
    Episode_Reward/reaching_object: 1.1625
    Episode_Reward/rotating_object: 12.0788
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 1.5833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.30s
                      Time elapsed: 00:15:00
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 44894 steps/s (collection: 1.983s, learning 0.207s)
             Mean action noise std: 2.23
          Mean value_function loss: 28.6254
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 68.8124
                       Mean reward: 81.68
               Mean episode length: 226.24
    Episode_Reward/reaching_object: 1.1442
    Episode_Reward/rotating_object: 13.8817
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.19s
                      Time elapsed: 00:15:02
                               ETA: 00:46:38

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 42534 steps/s (collection: 2.186s, learning 0.125s)
             Mean action noise std: 2.24
          Mean value_function loss: 32.9925
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 68.8474
                       Mean reward: 76.37
               Mean episode length: 225.46
    Episode_Reward/reaching_object: 1.1276
    Episode_Reward/rotating_object: 13.2838
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.31s
                      Time elapsed: 00:15:04
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 43892 steps/s (collection: 2.071s, learning 0.169s)
             Mean action noise std: 2.24
          Mean value_function loss: 32.0379
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 68.8827
                       Mean reward: 97.09
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 14.4599
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.24s
                      Time elapsed: 00:15:06
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 41636 steps/s (collection: 2.222s, learning 0.139s)
             Mean action noise std: 2.24
          Mean value_function loss: 30.4075
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 68.9064
                       Mean reward: 74.98
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 1.1570
    Episode_Reward/rotating_object: 14.7957
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0605
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.36s
                      Time elapsed: 00:15:09
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 40267 steps/s (collection: 2.259s, learning 0.182s)
             Mean action noise std: 2.24
          Mean value_function loss: 30.8556
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 68.9260
                       Mean reward: 82.09
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 1.1912
    Episode_Reward/rotating_object: 14.7347
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.44s
                      Time elapsed: 00:15:11
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 41163 steps/s (collection: 2.235s, learning 0.153s)
             Mean action noise std: 2.24
          Mean value_function loss: 28.2343
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 68.9525
                       Mean reward: 72.77
               Mean episode length: 219.86
    Episode_Reward/reaching_object: 1.1524
    Episode_Reward/rotating_object: 15.1839
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0593
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.39s
                      Time elapsed: 00:15:14
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 40858 steps/s (collection: 2.237s, learning 0.169s)
             Mean action noise std: 2.25
          Mean value_function loss: 29.0658
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 68.9743
                       Mean reward: 79.40
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.1500
    Episode_Reward/rotating_object: 15.5450
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.41s
                      Time elapsed: 00:15:16
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 44265 steps/s (collection: 2.080s, learning 0.141s)
             Mean action noise std: 2.25
          Mean value_function loss: 35.9919
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 68.9963
                       Mean reward: 73.35
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 1.1738
    Episode_Reward/rotating_object: 13.9496
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0596
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.22s
                      Time elapsed: 00:15:18
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 43456 steps/s (collection: 2.142s, learning 0.120s)
             Mean action noise std: 2.25
          Mean value_function loss: 35.5140
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 69.0170
                       Mean reward: 76.27
               Mean episode length: 222.18
    Episode_Reward/reaching_object: 1.1568
    Episode_Reward/rotating_object: 13.8177
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.26s
                      Time elapsed: 00:15:20
                               ETA: 00:46:15

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 41260 steps/s (collection: 2.227s, learning 0.156s)
             Mean action noise std: 2.25
          Mean value_function loss: 37.8880
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 69.0471
                       Mean reward: 99.46
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.2170
    Episode_Reward/rotating_object: 15.3588
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0622
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.38s
                      Time elapsed: 00:15:23
                               ETA: 00:46:12

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 42987 steps/s (collection: 2.155s, learning 0.132s)
             Mean action noise std: 2.25
          Mean value_function loss: 35.6110
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 69.0755
                       Mean reward: 106.35
               Mean episode length: 226.95
    Episode_Reward/reaching_object: 1.2054
    Episode_Reward/rotating_object: 16.2411
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.29s
                      Time elapsed: 00:15:25
                               ETA: 00:46:09

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 42736 steps/s (collection: 2.154s, learning 0.146s)
             Mean action noise std: 2.26
          Mean value_function loss: 41.1913
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 69.1036
                       Mean reward: 82.28
               Mean episode length: 223.32
    Episode_Reward/reaching_object: 1.1749
    Episode_Reward/rotating_object: 19.4646
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.30s
                      Time elapsed: 00:15:27
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 41777 steps/s (collection: 2.159s, learning 0.194s)
             Mean action noise std: 2.26
          Mean value_function loss: 36.2629
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.1231
                       Mean reward: 84.69
               Mean episode length: 222.91
    Episode_Reward/reaching_object: 1.1579
    Episode_Reward/rotating_object: 17.1615
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0588
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.35s
                      Time elapsed: 00:15:30
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 41560 steps/s (collection: 2.230s, learning 0.135s)
             Mean action noise std: 2.26
          Mean value_function loss: 38.0028
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 69.1430
                       Mean reward: 85.44
               Mean episode length: 223.26
    Episode_Reward/reaching_object: 1.1663
    Episode_Reward/rotating_object: 16.5325
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.37s
                      Time elapsed: 00:15:32
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 42870 steps/s (collection: 2.169s, learning 0.124s)
             Mean action noise std: 2.26
          Mean value_function loss: 41.9737
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 69.1634
                       Mean reward: 84.47
               Mean episode length: 231.99
    Episode_Reward/reaching_object: 1.1777
    Episode_Reward/rotating_object: 16.6397
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0611
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.29s
                      Time elapsed: 00:15:34
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 40778 steps/s (collection: 2.286s, learning 0.125s)
             Mean action noise std: 2.26
          Mean value_function loss: 43.5581
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 69.1892
                       Mean reward: 102.81
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.1744
    Episode_Reward/rotating_object: 15.6039
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0602
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 1.5417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.41s
                      Time elapsed: 00:15:37
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 40583 steps/s (collection: 2.262s, learning 0.161s)
             Mean action noise std: 2.26
          Mean value_function loss: 42.2245
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 69.2129
                       Mean reward: 87.03
               Mean episode length: 224.18
    Episode_Reward/reaching_object: 1.1598
    Episode_Reward/rotating_object: 18.7381
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 1.6667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.42s
                      Time elapsed: 00:15:39
                               ETA: 00:45:52

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 43358 steps/s (collection: 2.102s, learning 0.165s)
             Mean action noise std: 2.27
          Mean value_function loss: 42.8792
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.2409
                       Mean reward: 88.26
               Mean episode length: 214.30
    Episode_Reward/reaching_object: 1.1692
    Episode_Reward/rotating_object: 16.9298
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.27s
                      Time elapsed: 00:15:42
                               ETA: 00:45:49

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 40870 steps/s (collection: 2.210s, learning 0.196s)
             Mean action noise std: 2.27
          Mean value_function loss: 39.9459
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 69.2730
                       Mean reward: 96.18
               Mean episode length: 223.24
    Episode_Reward/reaching_object: 1.1522
    Episode_Reward/rotating_object: 16.6333
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0600
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 1.5417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.41s
                      Time elapsed: 00:15:44
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 41922 steps/s (collection: 2.184s, learning 0.161s)
             Mean action noise std: 2.27
          Mean value_function loss: 44.1911
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.3096
                       Mean reward: 104.99
               Mean episode length: 218.59
    Episode_Reward/reaching_object: 1.1877
    Episode_Reward/rotating_object: 14.9636
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0615
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.34s
                      Time elapsed: 00:15:46
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 41958 steps/s (collection: 2.197s, learning 0.146s)
             Mean action noise std: 2.27
          Mean value_function loss: 36.5977
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 69.3338
                       Mean reward: 92.20
               Mean episode length: 222.08
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 16.9995
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0621
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 1.5417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.34s
                      Time elapsed: 00:15:49
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 44381 steps/s (collection: 2.100s, learning 0.115s)
             Mean action noise std: 2.28
          Mean value_function loss: 41.7680
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 69.3608
                       Mean reward: 100.07
               Mean episode length: 219.60
    Episode_Reward/reaching_object: 1.1944
    Episode_Reward/rotating_object: 18.7988
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0629
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.21s
                      Time elapsed: 00:15:51
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 41551 steps/s (collection: 2.155s, learning 0.211s)
             Mean action noise std: 2.28
          Mean value_function loss: 42.7217
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 69.3871
                       Mean reward: 91.88
               Mean episode length: 222.36
    Episode_Reward/reaching_object: 1.1729
    Episode_Reward/rotating_object: 17.4646
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0605
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.37s
                      Time elapsed: 00:15:53
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 42379 steps/s (collection: 2.211s, learning 0.109s)
             Mean action noise std: 2.28
          Mean value_function loss: 39.5379
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.4127
                       Mean reward: 100.64
               Mean episode length: 220.76
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 17.1334
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.32s
                      Time elapsed: 00:15:56
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 43024 steps/s (collection: 2.172s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 37.5823
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 69.4314
                       Mean reward: 96.90
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 1.1701
    Episode_Reward/rotating_object: 18.4284
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0613
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 1.4167
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.28s
                      Time elapsed: 00:15:58
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 45762 steps/s (collection: 1.990s, learning 0.158s)
             Mean action noise std: 2.28
          Mean value_function loss: 39.1756
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 69.4462
                       Mean reward: 84.20
               Mean episode length: 215.64
    Episode_Reward/reaching_object: 1.1695
    Episode_Reward/rotating_object: 18.1148
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 1.6250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.15s
                      Time elapsed: 00:16:00
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 45412 steps/s (collection: 2.051s, learning 0.114s)
             Mean action noise std: 2.28
          Mean value_function loss: 41.9448
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.4672
                       Mean reward: 109.34
               Mean episode length: 215.13
    Episode_Reward/reaching_object: 1.1506
    Episode_Reward/rotating_object: 16.7120
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0604
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.16s
                      Time elapsed: 00:16:02
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 47283 steps/s (collection: 1.985s, learning 0.094s)
             Mean action noise std: 2.29
          Mean value_function loss: 36.7903
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 69.4938
                       Mean reward: 103.00
               Mean episode length: 223.48
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 17.4629
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 1.5833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.08s
                      Time elapsed: 00:16:04
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 47233 steps/s (collection: 1.975s, learning 0.106s)
             Mean action noise std: 2.29
          Mean value_function loss: 33.8568
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 69.5236
                       Mean reward: 79.24
               Mean episode length: 218.25
    Episode_Reward/reaching_object: 1.1856
    Episode_Reward/rotating_object: 16.3611
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 1.7917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.08s
                      Time elapsed: 00:16:06
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 47349 steps/s (collection: 1.976s, learning 0.100s)
             Mean action noise std: 2.29
          Mean value_function loss: 34.5706
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 69.5537
                       Mean reward: 82.76
               Mean episode length: 218.61
    Episode_Reward/reaching_object: 1.1678
    Episode_Reward/rotating_object: 15.4392
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0606
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.08s
                      Time elapsed: 00:16:08
                               ETA: 00:45:12

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 45951 steps/s (collection: 2.008s, learning 0.131s)
             Mean action noise std: 2.29
          Mean value_function loss: 40.1355
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 69.5805
                       Mean reward: 88.97
               Mean episode length: 212.63
    Episode_Reward/reaching_object: 1.1621
    Episode_Reward/rotating_object: 17.8390
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0614
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.14s
                      Time elapsed: 00:16:11
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 44920 steps/s (collection: 2.028s, learning 0.160s)
             Mean action noise std: 2.29
          Mean value_function loss: 36.1702
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 69.6007
                       Mean reward: 94.88
               Mean episode length: 220.30
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 19.8473
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.19s
                      Time elapsed: 00:16:13
                               ETA: 00:45:06

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 44869 steps/s (collection: 2.025s, learning 0.166s)
             Mean action noise std: 2.30
          Mean value_function loss: 41.5014
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 69.6215
                       Mean reward: 118.89
               Mean episode length: 223.33
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 19.7289
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.19s
                      Time elapsed: 00:16:15
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 42895 steps/s (collection: 2.127s, learning 0.165s)
             Mean action noise std: 2.30
          Mean value_function loss: 43.4001
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 69.6523
                       Mean reward: 110.16
               Mean episode length: 223.88
    Episode_Reward/reaching_object: 1.1864
    Episode_Reward/rotating_object: 20.3338
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 1.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.29s
                      Time elapsed: 00:16:17
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 43866 steps/s (collection: 2.046s, learning 0.195s)
             Mean action noise std: 2.30
          Mean value_function loss: 37.3971
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.6744
                       Mean reward: 121.21
               Mean episode length: 237.80
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 18.4080
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0640
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 1.5000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.24s
                      Time elapsed: 00:16:19
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 44988 steps/s (collection: 2.052s, learning 0.133s)
             Mean action noise std: 2.30
          Mean value_function loss: 38.7168
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 69.7036
                       Mean reward: 110.32
               Mean episode length: 222.52
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 19.8833
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.19s
                      Time elapsed: 00:16:22
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 43150 steps/s (collection: 2.104s, learning 0.175s)
             Mean action noise std: 2.30
          Mean value_function loss: 37.1367
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 69.7298
                       Mean reward: 90.78
               Mean episode length: 222.15
    Episode_Reward/reaching_object: 1.1693
    Episode_Reward/rotating_object: 17.8723
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0618
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.28s
                      Time elapsed: 00:16:24
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 45744 steps/s (collection: 2.008s, learning 0.141s)
             Mean action noise std: 2.31
          Mean value_function loss: 42.2770
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 69.7553
                       Mean reward: 97.24
               Mean episode length: 219.32
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 18.6352
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.15s
                      Time elapsed: 00:16:26
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 44768 steps/s (collection: 2.038s, learning 0.158s)
             Mean action noise std: 2.31
          Mean value_function loss: 34.5630
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 69.7853
                       Mean reward: 99.30
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 18.7126
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.20s
                      Time elapsed: 00:16:28
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 45267 steps/s (collection: 2.041s, learning 0.131s)
             Mean action noise std: 2.31
          Mean value_function loss: 35.2889
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 69.8099
                       Mean reward: 108.70
               Mean episode length: 222.55
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 20.1507
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0624
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.17s
                      Time elapsed: 00:16:30
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 46030 steps/s (collection: 2.007s, learning 0.129s)
             Mean action noise std: 2.31
          Mean value_function loss: 38.6148
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 69.8335
                       Mean reward: 101.07
               Mean episode length: 220.78
    Episode_Reward/reaching_object: 1.1673
    Episode_Reward/rotating_object: 21.1224
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0617
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.14s
                      Time elapsed: 00:16:33
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 41960 steps/s (collection: 2.233s, learning 0.110s)
             Mean action noise std: 2.31
          Mean value_function loss: 38.7790
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 69.8529
                       Mean reward: 117.93
               Mean episode length: 221.13
    Episode_Reward/reaching_object: 1.1808
    Episode_Reward/rotating_object: 20.2320
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0616
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.34s
                      Time elapsed: 00:16:35
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 44162 steps/s (collection: 2.048s, learning 0.178s)
             Mean action noise std: 2.31
          Mean value_function loss: 40.5350
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.8711
                       Mean reward: 110.18
               Mean episode length: 215.05
    Episode_Reward/reaching_object: 1.1805
    Episode_Reward/rotating_object: 20.3497
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0627
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 1.2917
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.23s
                      Time elapsed: 00:16:37
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 44543 steps/s (collection: 2.074s, learning 0.133s)
             Mean action noise std: 2.32
          Mean value_function loss: 42.0911
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 69.8885
                       Mean reward: 88.79
               Mean episode length: 215.77
    Episode_Reward/reaching_object: 1.2010
    Episode_Reward/rotating_object: 19.2270
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0618
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.21s
                      Time elapsed: 00:16:39
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 45741 steps/s (collection: 2.035s, learning 0.114s)
             Mean action noise std: 2.32
          Mean value_function loss: 44.7996
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 69.9152
                       Mean reward: 70.25
               Mean episode length: 207.55
    Episode_Reward/reaching_object: 1.1513
    Episode_Reward/rotating_object: 17.3389
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 1.9167
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.15s
                      Time elapsed: 00:16:41
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 45244 steps/s (collection: 2.011s, learning 0.162s)
             Mean action noise std: 2.32
          Mean value_function loss: 40.6112
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 69.9422
                       Mean reward: 96.72
               Mean episode length: 219.86
    Episode_Reward/reaching_object: 1.1880
    Episode_Reward/rotating_object: 19.2783
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0619
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.17s
                      Time elapsed: 00:16:44
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 47539 steps/s (collection: 1.961s, learning 0.107s)
             Mean action noise std: 2.32
          Mean value_function loss: 42.1412
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 69.9719
                       Mean reward: 86.58
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.2143
    Episode_Reward/rotating_object: 20.2336
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.07s
                      Time elapsed: 00:16:46
                               ETA: 00:44:19

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 39166 steps/s (collection: 2.378s, learning 0.132s)
             Mean action noise std: 2.32
          Mean value_function loss: 43.5605
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 69.9984
                       Mean reward: 87.87
               Mean episode length: 218.07
    Episode_Reward/reaching_object: 1.1836
    Episode_Reward/rotating_object: 19.8739
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0628
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.51s
                      Time elapsed: 00:16:48
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 45506 steps/s (collection: 2.015s, learning 0.145s)
             Mean action noise std: 2.33
          Mean value_function loss: 38.6786
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.0247
                       Mean reward: 102.92
               Mean episode length: 219.70
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 18.8784
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 1.4583
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.16s
                      Time elapsed: 00:16:50
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 45153 steps/s (collection: 2.035s, learning 0.142s)
             Mean action noise std: 2.33
          Mean value_function loss: 37.6031
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 70.0464
                       Mean reward: 117.41
               Mean episode length: 219.19
    Episode_Reward/reaching_object: 1.1711
    Episode_Reward/rotating_object: 20.4644
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0629
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 1.5417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.18s
                      Time elapsed: 00:16:53
                               ETA: 00:44:11

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 44015 steps/s (collection: 2.055s, learning 0.179s)
             Mean action noise std: 2.33
          Mean value_function loss: 37.1329
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 70.0612
                       Mean reward: 109.14
               Mean episode length: 223.70
    Episode_Reward/reaching_object: 1.1487
    Episode_Reward/rotating_object: 19.6977
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0626
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 1.4583
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.23s
                      Time elapsed: 00:16:55
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 46753 steps/s (collection: 2.000s, learning 0.102s)
             Mean action noise std: 2.33
          Mean value_function loss: 37.1581
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 70.0761
                       Mean reward: 106.43
               Mean episode length: 211.99
    Episode_Reward/reaching_object: 1.1589
    Episode_Reward/rotating_object: 18.1146
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0610
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.10s
                      Time elapsed: 00:16:57
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 45563 steps/s (collection: 2.048s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 36.1243
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.0909
                       Mean reward: 113.08
               Mean episode length: 224.64
    Episode_Reward/reaching_object: 1.1682
    Episode_Reward/rotating_object: 20.0493
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.16s
                      Time elapsed: 00:16:59
                               ETA: 00:44:01

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 45652 steps/s (collection: 2.016s, learning 0.137s)
             Mean action noise std: 2.33
          Mean value_function loss: 36.2087
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 70.1139
                       Mean reward: 100.36
               Mean episode length: 211.80
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 18.0023
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0640
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.15s
                      Time elapsed: 00:17:01
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 46173 steps/s (collection: 1.999s, learning 0.130s)
             Mean action noise std: 2.33
          Mean value_function loss: 39.2288
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 70.1362
                       Mean reward: 97.18
               Mean episode length: 225.00
    Episode_Reward/reaching_object: 1.1699
    Episode_Reward/rotating_object: 18.9204
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.13s
                      Time elapsed: 00:17:03
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 45185 steps/s (collection: 2.027s, learning 0.148s)
             Mean action noise std: 2.34
          Mean value_function loss: 37.6951
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 70.1591
                       Mean reward: 109.31
               Mean episode length: 222.03
    Episode_Reward/reaching_object: 1.1757
    Episode_Reward/rotating_object: 19.8818
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.18s
                      Time elapsed: 00:17:05
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 45169 steps/s (collection: 2.066s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 39.4448
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 70.1775
                       Mean reward: 102.90
               Mean episode length: 224.04
    Episode_Reward/reaching_object: 1.1701
    Episode_Reward/rotating_object: 19.7618
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0640
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.18s
                      Time elapsed: 00:17:08
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 46224 steps/s (collection: 1.968s, learning 0.159s)
             Mean action noise std: 2.34
          Mean value_function loss: 39.1167
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 70.1923
                       Mean reward: 106.56
               Mean episode length: 218.34
    Episode_Reward/reaching_object: 1.1488
    Episode_Reward/rotating_object: 20.1080
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0634
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 1.1667
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.13s
                      Time elapsed: 00:17:10
                               ETA: 00:43:45

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 45311 steps/s (collection: 2.045s, learning 0.125s)
             Mean action noise std: 2.34
          Mean value_function loss: 42.5775
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 70.2152
                       Mean reward: 113.08
               Mean episode length: 216.14
    Episode_Reward/reaching_object: 1.1822
    Episode_Reward/rotating_object: 18.9889
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.17s
                      Time elapsed: 00:17:12
                               ETA: 00:43:42

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 45694 steps/s (collection: 2.013s, learning 0.138s)
             Mean action noise std: 2.34
          Mean value_function loss: 37.2484
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 70.2389
                       Mean reward: 126.13
               Mean episode length: 221.90
    Episode_Reward/reaching_object: 1.1748
    Episode_Reward/rotating_object: 20.6790
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 1.5000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.15s
                      Time elapsed: 00:17:14
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 45429 steps/s (collection: 2.008s, learning 0.156s)
             Mean action noise std: 2.34
          Mean value_function loss: 37.8389
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 70.2613
                       Mean reward: 96.70
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 1.2029
    Episode_Reward/rotating_object: 20.7339
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 1.3750
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.16s
                      Time elapsed: 00:17:16
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 46081 steps/s (collection: 1.997s, learning 0.137s)
             Mean action noise std: 2.35
          Mean value_function loss: 45.3412
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 70.2804
                       Mean reward: 98.25
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.1935
    Episode_Reward/rotating_object: 22.3829
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.13s
                      Time elapsed: 00:17:18
                               ETA: 00:43:33

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 46668 steps/s (collection: 1.963s, learning 0.143s)
             Mean action noise std: 2.35
          Mean value_function loss: 39.1198
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 70.3033
                       Mean reward: 121.84
               Mean episode length: 222.31
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 20.4295
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.11s
                      Time elapsed: 00:17:21
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 46305 steps/s (collection: 1.970s, learning 0.153s)
             Mean action noise std: 2.35
          Mean value_function loss: 39.7843
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 70.3233
                       Mean reward: 99.42
               Mean episode length: 207.66
    Episode_Reward/reaching_object: 1.1696
    Episode_Reward/rotating_object: 23.5783
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.12s
                      Time elapsed: 00:17:23
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 44739 steps/s (collection: 2.021s, learning 0.176s)
             Mean action noise std: 2.35
          Mean value_function loss: 40.5223
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 70.3471
                       Mean reward: 126.74
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 21.4244
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 1.3333
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.20s
                      Time elapsed: 00:17:25
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 45364 steps/s (collection: 1.994s, learning 0.173s)
             Mean action noise std: 2.35
          Mean value_function loss: 40.4139
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 70.3693
                       Mean reward: 148.57
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 21.9210
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.17s
                      Time elapsed: 00:17:27
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 45683 steps/s (collection: 1.999s, learning 0.153s)
             Mean action noise std: 2.35
          Mean value_function loss: 41.3316
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 70.3867
                       Mean reward: 127.08
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 21.8670
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.15s
                      Time elapsed: 00:17:29
                               ETA: 00:43:17

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 44039 steps/s (collection: 2.072s, learning 0.160s)
             Mean action noise std: 2.36
          Mean value_function loss: 48.1731
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 70.4127
                       Mean reward: 104.20
               Mean episode length: 213.45
    Episode_Reward/reaching_object: 1.1912
    Episode_Reward/rotating_object: 23.7192
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.23s
                      Time elapsed: 00:17:31
                               ETA: 00:43:14

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 43647 steps/s (collection: 2.130s, learning 0.122s)
             Mean action noise std: 2.36
          Mean value_function loss: 42.2367
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 70.4368
                       Mean reward: 113.59
               Mean episode length: 216.42
    Episode_Reward/reaching_object: 1.1928
    Episode_Reward/rotating_object: 21.4461
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.25s
                      Time elapsed: 00:17:34
                               ETA: 00:43:11

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 44544 steps/s (collection: 2.087s, learning 0.120s)
             Mean action noise std: 2.36
          Mean value_function loss: 42.8877
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.4592
                       Mean reward: 110.27
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 1.1924
    Episode_Reward/rotating_object: 22.7328
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.21s
                      Time elapsed: 00:17:36
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 44046 steps/s (collection: 2.079s, learning 0.153s)
             Mean action noise std: 2.36
          Mean value_function loss: 45.2726
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 70.4799
                       Mean reward: 118.25
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.1934
    Episode_Reward/rotating_object: 23.9043
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.23s
                      Time elapsed: 00:17:38
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 45244 steps/s (collection: 2.027s, learning 0.145s)
             Mean action noise std: 2.36
          Mean value_function loss: 50.4130
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 70.4956
                       Mean reward: 118.81
               Mean episode length: 220.76
    Episode_Reward/reaching_object: 1.1554
    Episode_Reward/rotating_object: 23.6194
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.17s
                      Time elapsed: 00:17:40
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 47906 steps/s (collection: 1.902s, learning 0.150s)
             Mean action noise std: 2.36
          Mean value_function loss: 48.3745
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 70.5088
                       Mean reward: 130.66
               Mean episode length: 218.73
    Episode_Reward/reaching_object: 1.1541
    Episode_Reward/rotating_object: 23.9022
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.05s
                      Time elapsed: 00:17:42
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 46113 steps/s (collection: 2.006s, learning 0.126s)
             Mean action noise std: 2.36
          Mean value_function loss: 43.0218
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 70.5280
                       Mean reward: 102.63
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 1.1774
    Episode_Reward/rotating_object: 22.1874
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.13s
                      Time elapsed: 00:17:44
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 44003 steps/s (collection: 2.124s, learning 0.110s)
             Mean action noise std: 2.37
          Mean value_function loss: 36.7487
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 70.5454
                       Mean reward: 136.74
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 1.1758
    Episode_Reward/rotating_object: 24.6146
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.23s
                      Time elapsed: 00:17:47
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 43655 steps/s (collection: 2.099s, learning 0.152s)
             Mean action noise std: 2.37
          Mean value_function loss: 38.6075
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 70.5647
                       Mean reward: 130.44
               Mean episode length: 218.73
    Episode_Reward/reaching_object: 1.1658
    Episode_Reward/rotating_object: 23.0945
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.25s
                      Time elapsed: 00:17:49
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 47680 steps/s (collection: 1.911s, learning 0.151s)
             Mean action noise std: 2.37
          Mean value_function loss: 39.5847
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.5822
                       Mean reward: 138.19
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.1736
    Episode_Reward/rotating_object: 25.6311
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 1.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.06s
                      Time elapsed: 00:17:51
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 47060 steps/s (collection: 1.949s, learning 0.140s)
             Mean action noise std: 2.37
          Mean value_function loss: 39.1299
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 70.5926
                       Mean reward: 146.37
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 1.1811
    Episode_Reward/rotating_object: 26.3989
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.09s
                      Time elapsed: 00:17:53
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 47302 steps/s (collection: 1.931s, learning 0.147s)
             Mean action noise std: 2.37
          Mean value_function loss: 31.0729
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.6073
                       Mean reward: 170.35
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 1.1576
    Episode_Reward/rotating_object: 29.6056
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.08s
                      Time elapsed: 00:17:55
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 45402 steps/s (collection: 2.022s, learning 0.143s)
             Mean action noise std: 2.37
          Mean value_function loss: 37.3066
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.6266
                       Mean reward: 129.00
               Mean episode length: 221.52
    Episode_Reward/reaching_object: 1.1693
    Episode_Reward/rotating_object: 24.5036
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.17s
                      Time elapsed: 00:17:57
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 46216 steps/s (collection: 1.995s, learning 0.132s)
             Mean action noise std: 2.37
          Mean value_function loss: 36.4349
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 70.6424
                       Mean reward: 142.42
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.1659
    Episode_Reward/rotating_object: 26.3597
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.13s
                      Time elapsed: 00:17:59
                               ETA: 00:42:34

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 45198 steps/s (collection: 2.024s, learning 0.151s)
             Mean action noise std: 2.37
          Mean value_function loss: 45.0603
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.6565
                       Mean reward: 154.29
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 1.1765
    Episode_Reward/rotating_object: 26.9906
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.17s
                      Time elapsed: 00:18:02
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 45205 steps/s (collection: 2.020s, learning 0.155s)
             Mean action noise std: 2.38
          Mean value_function loss: 42.7043
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 70.6764
                       Mean reward: 160.35
               Mean episode length: 229.77
    Episode_Reward/reaching_object: 1.1817
    Episode_Reward/rotating_object: 27.7844
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.17s
                      Time elapsed: 00:18:04
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 47055 steps/s (collection: 1.953s, learning 0.137s)
             Mean action noise std: 2.38
          Mean value_function loss: 42.3519
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 70.6913
                       Mean reward: 121.95
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 28.7292
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.09s
                      Time elapsed: 00:18:06
                               ETA: 00:42:25

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 45206 steps/s (collection: 2.017s, learning 0.158s)
             Mean action noise std: 2.38
          Mean value_function loss: 42.7822
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.7078
                       Mean reward: 145.13
               Mean episode length: 220.81
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 26.2891
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.17s
                      Time elapsed: 00:18:08
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 44773 steps/s (collection: 2.039s, learning 0.157s)
             Mean action noise std: 2.38
          Mean value_function loss: 39.9804
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.7211
                       Mean reward: 133.98
               Mean episode length: 217.71
    Episode_Reward/reaching_object: 1.1687
    Episode_Reward/rotating_object: 25.1254
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0696
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.20s
                      Time elapsed: 00:18:10
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 47667 steps/s (collection: 1.915s, learning 0.147s)
             Mean action noise std: 2.38
          Mean value_function loss: 47.1662
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 70.7396
                       Mean reward: 123.68
               Mean episode length: 216.89
    Episode_Reward/reaching_object: 1.1697
    Episode_Reward/rotating_object: 27.4474
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.06s
                      Time elapsed: 00:18:12
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 44507 steps/s (collection: 2.058s, learning 0.151s)
             Mean action noise std: 2.38
          Mean value_function loss: 52.0816
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 70.7591
                       Mean reward: 113.93
               Mean episode length: 226.00
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 25.3432
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.21s
                      Time elapsed: 00:18:15
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 46368 steps/s (collection: 1.992s, learning 0.128s)
             Mean action noise std: 2.38
          Mean value_function loss: 52.1063
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 70.7801
                       Mean reward: 140.79
               Mean episode length: 217.18
    Episode_Reward/reaching_object: 1.1685
    Episode_Reward/rotating_object: 28.9098
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.12s
                      Time elapsed: 00:18:17
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 46973 steps/s (collection: 1.968s, learning 0.125s)
             Mean action noise std: 2.39
          Mean value_function loss: 63.9046
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 70.8059
                       Mean reward: 157.60
               Mean episode length: 217.54
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 30.2137
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.09s
                      Time elapsed: 00:18:19
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 46692 steps/s (collection: 1.967s, learning 0.139s)
             Mean action noise std: 2.39
          Mean value_function loss: 58.1629
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 70.8324
                       Mean reward: 131.94
               Mean episode length: 221.90
    Episode_Reward/reaching_object: 1.1762
    Episode_Reward/rotating_object: 27.0737
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.11s
                      Time elapsed: 00:18:21
                               ETA: 00:42:03

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 46269 steps/s (collection: 1.984s, learning 0.141s)
             Mean action noise std: 2.39
          Mean value_function loss: 48.6326
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 70.8533
                       Mean reward: 125.27
               Mean episode length: 211.64
    Episode_Reward/reaching_object: 1.1840
    Episode_Reward/rotating_object: 26.4399
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0696
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.12s
                      Time elapsed: 00:18:23
                               ETA: 00:42:00

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 45280 steps/s (collection: 2.024s, learning 0.147s)
             Mean action noise std: 2.39
          Mean value_function loss: 43.1955
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 70.8731
                       Mean reward: 124.09
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 1.1805
    Episode_Reward/rotating_object: 26.2973
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0690
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.17s
                      Time elapsed: 00:18:25
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 45680 steps/s (collection: 1.957s, learning 0.195s)
             Mean action noise std: 2.39
          Mean value_function loss: 46.0697
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.8890
                       Mean reward: 138.86
               Mean episode length: 216.90
    Episode_Reward/reaching_object: 1.1786
    Episode_Reward/rotating_object: 25.4576
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.15s
                      Time elapsed: 00:18:27
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 45798 steps/s (collection: 2.031s, learning 0.115s)
             Mean action noise std: 2.39
          Mean value_function loss: 41.9712
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 70.9046
                       Mean reward: 132.14
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 26.9925
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.15s
                      Time elapsed: 00:18:29
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 45113 steps/s (collection: 2.079s, learning 0.100s)
             Mean action noise std: 2.40
          Mean value_function loss: 48.0319
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 70.9227
                       Mean reward: 149.34
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 26.6576
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0704
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.18s
                      Time elapsed: 00:18:32
                               ETA: 00:41:48

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 45600 steps/s (collection: 2.011s, learning 0.145s)
             Mean action noise std: 2.40
          Mean value_function loss: 46.7113
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 70.9393
                       Mean reward: 150.13
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 31.6185
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 1.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.16s
                      Time elapsed: 00:18:34
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 45229 steps/s (collection: 2.058s, learning 0.115s)
             Mean action noise std: 2.40
          Mean value_function loss: 53.9131
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 70.9513
                       Mean reward: 130.28
               Mean episode length: 222.49
    Episode_Reward/reaching_object: 1.1991
    Episode_Reward/rotating_object: 27.5454
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0704
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 1.1250
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.17s
                      Time elapsed: 00:18:36
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 45925 steps/s (collection: 1.992s, learning 0.149s)
             Mean action noise std: 2.40
          Mean value_function loss: 57.3065
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 70.9656
                       Mean reward: 146.02
               Mean episode length: 224.19
    Episode_Reward/reaching_object: 1.1819
    Episode_Reward/rotating_object: 29.0613
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.14s
                      Time elapsed: 00:18:38
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 46982 steps/s (collection: 1.979s, learning 0.113s)
             Mean action noise std: 2.40
          Mean value_function loss: 54.9305
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 70.9790
                       Mean reward: 107.60
               Mean episode length: 203.55
    Episode_Reward/reaching_object: 1.1579
    Episode_Reward/rotating_object: 26.6569
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.09s
                      Time elapsed: 00:18:40
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 48012 steps/s (collection: 1.875s, learning 0.172s)
             Mean action noise std: 2.40
          Mean value_function loss: 47.6218
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 70.9959
                       Mean reward: 141.28
               Mean episode length: 228.06
    Episode_Reward/reaching_object: 1.1800
    Episode_Reward/rotating_object: 26.1430
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.05s
                      Time elapsed: 00:18:42
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 45465 steps/s (collection: 2.021s, learning 0.142s)
             Mean action noise std: 2.40
          Mean value_function loss: 46.7935
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.0169
                       Mean reward: 129.94
               Mean episode length: 218.85
    Episode_Reward/reaching_object: 1.1657
    Episode_Reward/rotating_object: 27.8287
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.16s
                      Time elapsed: 00:18:44
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 43199 steps/s (collection: 2.142s, learning 0.134s)
             Mean action noise std: 2.40
          Mean value_function loss: 52.1053
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 71.0356
                       Mean reward: 147.12
               Mean episode length: 218.71
    Episode_Reward/reaching_object: 1.1778
    Episode_Reward/rotating_object: 28.7839
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.28s
                      Time elapsed: 00:18:47
                               ETA: 00:41:27

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 46675 steps/s (collection: 1.974s, learning 0.132s)
             Mean action noise std: 2.41
          Mean value_function loss: 53.0917
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.0549
                       Mean reward: 121.76
               Mean episode length: 209.51
    Episode_Reward/reaching_object: 1.1430
    Episode_Reward/rotating_object: 26.7483
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0640
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.11s
                      Time elapsed: 00:18:49
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 45326 steps/s (collection: 2.034s, learning 0.135s)
             Mean action noise std: 2.41
          Mean value_function loss: 53.2659
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 71.0731
                       Mean reward: 161.37
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 1.1526
    Episode_Reward/rotating_object: 24.9655
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.17s
                      Time elapsed: 00:18:51
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 47361 steps/s (collection: 1.924s, learning 0.152s)
             Mean action noise std: 2.41
          Mean value_function loss: 50.1938
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 71.0905
                       Mean reward: 153.77
               Mean episode length: 219.31
    Episode_Reward/reaching_object: 1.1938
    Episode_Reward/rotating_object: 27.1027
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.08s
                      Time elapsed: 00:18:53
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 45767 steps/s (collection: 2.009s, learning 0.139s)
             Mean action noise std: 2.41
          Mean value_function loss: 50.0412
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 71.1071
                       Mean reward: 155.94
               Mean episode length: 224.04
    Episode_Reward/reaching_object: 1.1843
    Episode_Reward/rotating_object: 25.6731
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.15s
                      Time elapsed: 00:18:55
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 44134 steps/s (collection: 2.102s, learning 0.126s)
             Mean action noise std: 2.41
          Mean value_function loss: 54.3887
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 71.1221
                       Mean reward: 148.53
               Mean episode length: 222.97
    Episode_Reward/reaching_object: 1.1655
    Episode_Reward/rotating_object: 29.2373
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.23s
                      Time elapsed: 00:18:57
                               ETA: 00:41:13

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 46201 steps/s (collection: 1.985s, learning 0.143s)
             Mean action noise std: 2.41
          Mean value_function loss: 52.6892
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.1370
                       Mean reward: 145.68
               Mean episode length: 216.88
    Episode_Reward/reaching_object: 1.1582
    Episode_Reward/rotating_object: 26.7849
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.13s
                      Time elapsed: 00:19:00
                               ETA: 00:41:10

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 46893 steps/s (collection: 1.914s, learning 0.182s)
             Mean action noise std: 2.41
          Mean value_function loss: 51.9764
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 71.1497
                       Mean reward: 144.44
               Mean episode length: 222.10
    Episode_Reward/reaching_object: 1.1463
    Episode_Reward/rotating_object: 25.5487
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.10s
                      Time elapsed: 00:19:02
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 45784 steps/s (collection: 1.999s, learning 0.148s)
             Mean action noise std: 2.41
          Mean value_function loss: 54.7768
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.1662
                       Mean reward: 143.33
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.1488
    Episode_Reward/rotating_object: 26.0694
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0631
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.15s
                      Time elapsed: 00:19:04
                               ETA: 00:41:04

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 47107 steps/s (collection: 1.957s, learning 0.130s)
             Mean action noise std: 2.42
          Mean value_function loss: 44.4349
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 71.1830
                       Mean reward: 145.48
               Mean episode length: 224.31
    Episode_Reward/reaching_object: 1.1650
    Episode_Reward/rotating_object: 28.9651
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0648
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.09s
                      Time elapsed: 00:19:06
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 47312 steps/s (collection: 1.906s, learning 0.172s)
             Mean action noise std: 2.42
          Mean value_function loss: 43.5700
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 71.1989
                       Mean reward: 133.74
               Mean episode length: 219.69
    Episode_Reward/reaching_object: 1.1598
    Episode_Reward/rotating_object: 28.0310
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.08s
                      Time elapsed: 00:19:08
                               ETA: 00:40:57

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 46039 steps/s (collection: 2.026s, learning 0.110s)
             Mean action noise std: 2.42
          Mean value_function loss: 49.7558
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 71.2172
                       Mean reward: 167.68
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.1678
    Episode_Reward/rotating_object: 29.9607
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.14s
                      Time elapsed: 00:19:10
                               ETA: 00:40:54

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 49878 steps/s (collection: 1.844s, learning 0.127s)
             Mean action noise std: 2.42
          Mean value_function loss: 51.1691
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.2346
                       Mean reward: 159.56
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 1.1672
    Episode_Reward/rotating_object: 30.2282
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.97s
                      Time elapsed: 00:19:12
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 46164 steps/s (collection: 2.008s, learning 0.121s)
             Mean action noise std: 2.42
          Mean value_function loss: 44.6654
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 71.2566
                       Mean reward: 148.37
               Mean episode length: 221.95
    Episode_Reward/reaching_object: 1.1749
    Episode_Reward/rotating_object: 31.0840
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.13s
                      Time elapsed: 00:19:14
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 45611 steps/s (collection: 2.015s, learning 0.140s)
             Mean action noise std: 2.42
          Mean value_function loss: 50.0074
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 71.2780
                       Mean reward: 151.23
               Mean episode length: 219.11
    Episode_Reward/reaching_object: 1.1440
    Episode_Reward/rotating_object: 29.7009
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.16s
                      Time elapsed: 00:19:16
                               ETA: 00:40:45

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 46034 steps/s (collection: 1.989s, learning 0.146s)
             Mean action noise std: 2.43
          Mean value_function loss: 55.8938
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 71.2964
                       Mean reward: 162.98
               Mean episode length: 228.55
    Episode_Reward/reaching_object: 1.1481
    Episode_Reward/rotating_object: 27.8960
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.14s
                      Time elapsed: 00:19:18
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 46857 steps/s (collection: 1.943s, learning 0.155s)
             Mean action noise std: 2.43
          Mean value_function loss: 52.0465
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.3163
                       Mean reward: 143.36
               Mean episode length: 219.01
    Episode_Reward/reaching_object: 1.1541
    Episode_Reward/rotating_object: 27.8619
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.10s
                      Time elapsed: 00:19:21
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 46798 steps/s (collection: 1.980s, learning 0.120s)
             Mean action noise std: 2.43
          Mean value_function loss: 55.5793
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 71.3351
                       Mean reward: 140.84
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.1453
    Episode_Reward/rotating_object: 31.5839
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.10s
                      Time elapsed: 00:19:23
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 45966 steps/s (collection: 1.969s, learning 0.170s)
             Mean action noise std: 2.43
          Mean value_function loss: 53.7215
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 71.3509
                       Mean reward: 115.86
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 27.2098
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.14s
                      Time elapsed: 00:19:25
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 45824 steps/s (collection: 2.019s, learning 0.127s)
             Mean action noise std: 2.43
          Mean value_function loss: 52.7772
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 71.3726
                       Mean reward: 183.89
               Mean episode length: 225.88
    Episode_Reward/reaching_object: 1.1400
    Episode_Reward/rotating_object: 30.2860
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.15s
                      Time elapsed: 00:19:27
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 41739 steps/s (collection: 2.212s, learning 0.143s)
             Mean action noise std: 2.43
          Mean value_function loss: 45.8784
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.3923
                       Mean reward: 190.74
               Mean episode length: 223.19
    Episode_Reward/reaching_object: 1.1520
    Episode_Reward/rotating_object: 31.3079
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.36s
                      Time elapsed: 00:19:29
                               ETA: 00:40:28

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 46265 steps/s (collection: 2.019s, learning 0.105s)
             Mean action noise std: 2.44
          Mean value_function loss: 47.4595
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 71.4161
                       Mean reward: 168.73
               Mean episode length: 225.37
    Episode_Reward/reaching_object: 1.1267
    Episode_Reward/rotating_object: 30.5198
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.12s
                      Time elapsed: 00:19:31
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 46372 steps/s (collection: 1.982s, learning 0.138s)
             Mean action noise std: 2.44
          Mean value_function loss: 54.6685
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 71.4399
                       Mean reward: 154.18
               Mean episode length: 216.66
    Episode_Reward/reaching_object: 1.1587
    Episode_Reward/rotating_object: 33.5026
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.12s
                      Time elapsed: 00:19:34
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 45377 steps/s (collection: 2.046s, learning 0.121s)
             Mean action noise std: 2.44
          Mean value_function loss: 50.9870
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 71.4577
                       Mean reward: 163.36
               Mean episode length: 220.05
    Episode_Reward/reaching_object: 1.1482
    Episode_Reward/rotating_object: 28.0962
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.17s
                      Time elapsed: 00:19:36
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 46051 steps/s (collection: 2.030s, learning 0.105s)
             Mean action noise std: 2.44
          Mean value_function loss: 50.7373
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 71.4746
                       Mean reward: 182.96
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 1.1565
    Episode_Reward/rotating_object: 30.5938
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0686
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.13s
                      Time elapsed: 00:19:38
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 45379 steps/s (collection: 2.064s, learning 0.103s)
             Mean action noise std: 2.44
          Mean value_function loss: 49.6953
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 71.4869
                       Mean reward: 156.26
               Mean episode length: 221.75
    Episode_Reward/reaching_object: 1.1606
    Episode_Reward/rotating_object: 31.0780
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0690
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.17s
                      Time elapsed: 00:19:40
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 47450 steps/s (collection: 1.941s, learning 0.131s)
             Mean action noise std: 2.44
          Mean value_function loss: 49.7870
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 71.5009
                       Mean reward: 152.45
               Mean episode length: 214.01
    Episode_Reward/reaching_object: 1.1715
    Episode_Reward/rotating_object: 32.8001
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.07s
                      Time elapsed: 00:19:42
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 46121 steps/s (collection: 1.994s, learning 0.137s)
             Mean action noise std: 2.44
          Mean value_function loss: 51.7253
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 71.5185
                       Mean reward: 163.97
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 1.1302
    Episode_Reward/rotating_object: 32.1571
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.13s
                      Time elapsed: 00:19:44
                               ETA: 00:40:07

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 44523 steps/s (collection: 2.072s, learning 0.136s)
             Mean action noise std: 2.44
          Mean value_function loss: 47.4838
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 71.5328
                       Mean reward: 159.12
               Mean episode length: 222.57
    Episode_Reward/reaching_object: 1.1101
    Episode_Reward/rotating_object: 29.8020
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.21s
                      Time elapsed: 00:19:46
                               ETA: 00:40:04

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 46956 steps/s (collection: 1.930s, learning 0.164s)
             Mean action noise std: 2.45
          Mean value_function loss: 44.9904
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 71.5498
                       Mean reward: 169.45
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 1.1448
    Episode_Reward/rotating_object: 30.5217
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.09s
                      Time elapsed: 00:19:49
                               ETA: 00:40:01

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 47552 steps/s (collection: 1.947s, learning 0.121s)
             Mean action noise std: 2.45
          Mean value_function loss: 50.2962
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 71.5655
                       Mean reward: 137.88
               Mean episode length: 222.60
    Episode_Reward/reaching_object: 1.1349
    Episode_Reward/rotating_object: 32.1056
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.07s
                      Time elapsed: 00:19:51
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 47149 steps/s (collection: 1.930s, learning 0.155s)
             Mean action noise std: 2.45
          Mean value_function loss: 53.8865
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 71.5838
                       Mean reward: 151.09
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.1713
    Episode_Reward/rotating_object: 30.2558
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.08s
                      Time elapsed: 00:19:53
                               ETA: 00:39:55

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 47082 steps/s (collection: 1.954s, learning 0.134s)
             Mean action noise std: 2.45
          Mean value_function loss: 59.2861
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.5999
                       Mean reward: 189.02
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.1663
    Episode_Reward/rotating_object: 33.4145
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 1.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.09s
                      Time elapsed: 00:19:55
                               ETA: 00:39:52

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 45201 steps/s (collection: 1.985s, learning 0.190s)
             Mean action noise std: 2.45
          Mean value_function loss: 52.9047
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 71.6157
                       Mean reward: 182.97
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.1448
    Episode_Reward/rotating_object: 33.1964
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.17s
                      Time elapsed: 00:19:57
                               ETA: 00:39:50

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 44596 steps/s (collection: 2.067s, learning 0.137s)
             Mean action noise std: 2.45
          Mean value_function loss: 59.2762
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 71.6348
                       Mean reward: 166.54
               Mean episode length: 221.90
    Episode_Reward/reaching_object: 1.1339
    Episode_Reward/rotating_object: 30.7247
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.20s
                      Time elapsed: 00:19:59
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 44740 steps/s (collection: 2.053s, learning 0.145s)
             Mean action noise std: 2.45
          Mean value_function loss: 59.7245
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 71.6565
                       Mean reward: 150.00
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.1790
    Episode_Reward/rotating_object: 36.3855
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.20s
                      Time elapsed: 00:20:01
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 45726 steps/s (collection: 1.989s, learning 0.161s)
             Mean action noise std: 2.46
          Mean value_function loss: 54.3709
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 71.6739
                       Mean reward: 159.85
               Mean episode length: 218.75
    Episode_Reward/reaching_object: 1.1558
    Episode_Reward/rotating_object: 34.8961
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.15s
                      Time elapsed: 00:20:03
                               ETA: 00:39:41

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 44025 steps/s (collection: 2.077s, learning 0.156s)
             Mean action noise std: 2.46
          Mean value_function loss: 56.2857
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 71.6943
                       Mean reward: 151.86
               Mean episode length: 214.88
    Episode_Reward/reaching_object: 1.1277
    Episode_Reward/rotating_object: 32.2554
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.23s
                      Time elapsed: 00:20:06
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 46775 steps/s (collection: 2.003s, learning 0.098s)
             Mean action noise std: 2.46
          Mean value_function loss: 65.9936
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 71.7135
                       Mean reward: 140.22
               Mean episode length: 227.97
    Episode_Reward/reaching_object: 1.1546
    Episode_Reward/rotating_object: 31.5898
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.10s
                      Time elapsed: 00:20:08
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 45404 steps/s (collection: 2.057s, learning 0.108s)
             Mean action noise std: 2.46
          Mean value_function loss: 62.8983
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.7358
                       Mean reward: 198.29
               Mean episode length: 227.55
    Episode_Reward/reaching_object: 1.1531
    Episode_Reward/rotating_object: 33.1320
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.17s
                      Time elapsed: 00:20:10
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 47907 steps/s (collection: 1.913s, learning 0.139s)
             Mean action noise std: 2.46
          Mean value_function loss: 60.7611
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.7568
                       Mean reward: 180.48
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 1.1502
    Episode_Reward/rotating_object: 30.8505
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0632
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.05s
                      Time elapsed: 00:20:12
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 45814 steps/s (collection: 1.990s, learning 0.156s)
             Mean action noise std: 2.46
          Mean value_function loss: 53.9921
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.7742
                       Mean reward: 151.27
               Mean episode length: 222.83
    Episode_Reward/reaching_object: 1.1546
    Episode_Reward/rotating_object: 35.0498
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.15s
                      Time elapsed: 00:20:14
                               ETA: 00:39:27

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 43704 steps/s (collection: 2.066s, learning 0.184s)
             Mean action noise std: 2.47
          Mean value_function loss: 54.9974
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.8035
                       Mean reward: 169.60
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 1.1503
    Episode_Reward/rotating_object: 31.5168
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0634
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.25s
                      Time elapsed: 00:20:16
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 45180 steps/s (collection: 2.013s, learning 0.163s)
             Mean action noise std: 2.47
          Mean value_function loss: 48.4359
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.8314
                       Mean reward: 190.92
               Mean episode length: 228.38
    Episode_Reward/reaching_object: 1.1721
    Episode_Reward/rotating_object: 35.2398
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.18s
                      Time elapsed: 00:20:19
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 46774 steps/s (collection: 1.969s, learning 0.133s)
             Mean action noise std: 2.47
          Mean value_function loss: 51.3147
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 71.8538
                       Mean reward: 190.37
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 1.1426
    Episode_Reward/rotating_object: 33.9051
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.10s
                      Time elapsed: 00:20:21
                               ETA: 00:39:18

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 45870 steps/s (collection: 1.995s, learning 0.148s)
             Mean action noise std: 2.47
          Mean value_function loss: 47.8698
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 71.8726
                       Mean reward: 164.61
               Mean episode length: 218.33
    Episode_Reward/reaching_object: 1.1172
    Episode_Reward/rotating_object: 30.7894
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0617
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.14s
                      Time elapsed: 00:20:23
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 46644 steps/s (collection: 1.978s, learning 0.130s)
             Mean action noise std: 2.47
          Mean value_function loss: 50.9592
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 71.8912
                       Mean reward: 168.38
               Mean episode length: 228.50
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 30.9053
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.11s
                      Time elapsed: 00:20:25
                               ETA: 00:39:13

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 44999 steps/s (collection: 2.032s, learning 0.152s)
             Mean action noise std: 2.48
          Mean value_function loss: 58.0920
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.9115
                       Mean reward: 150.06
               Mean episode length: 218.12
    Episode_Reward/reaching_object: 1.1356
    Episode_Reward/rotating_object: 35.1291
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.18s
                      Time elapsed: 00:20:27
                               ETA: 00:39:10

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 46571 steps/s (collection: 1.982s, learning 0.129s)
             Mean action noise std: 2.48
          Mean value_function loss: 49.6841
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.9342
                       Mean reward: 159.48
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 1.1535
    Episode_Reward/rotating_object: 31.0332
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.11s
                      Time elapsed: 00:20:29
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 46500 steps/s (collection: 1.986s, learning 0.128s)
             Mean action noise std: 2.48
          Mean value_function loss: 63.4466
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 71.9566
                       Mean reward: 158.17
               Mean episode length: 221.91
    Episode_Reward/reaching_object: 1.0939
    Episode_Reward/rotating_object: 28.3047
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0612
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.11s
                      Time elapsed: 00:20:31
                               ETA: 00:39:04

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 44678 steps/s (collection: 2.010s, learning 0.190s)
             Mean action noise std: 2.48
          Mean value_function loss: 56.3971
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 71.9820
                       Mean reward: 190.01
               Mean episode length: 216.57
    Episode_Reward/reaching_object: 1.1416
    Episode_Reward/rotating_object: 35.2557
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.20s
                      Time elapsed: 00:20:34
                               ETA: 00:39:01

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 46431 steps/s (collection: 2.014s, learning 0.104s)
             Mean action noise std: 2.48
          Mean value_function loss: 57.6795
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 72.0033
                       Mean reward: 186.00
               Mean episode length: 231.21
    Episode_Reward/reaching_object: 1.1547
    Episode_Reward/rotating_object: 33.3546
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.12s
                      Time elapsed: 00:20:36
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 39668 steps/s (collection: 2.334s, learning 0.144s)
             Mean action noise std: 2.48
          Mean value_function loss: 58.6252
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 72.0263
                       Mean reward: 191.97
               Mean episode length: 217.53
    Episode_Reward/reaching_object: 1.1267
    Episode_Reward/rotating_object: 35.8597
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0633
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.48s
                      Time elapsed: 00:20:38
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 47161 steps/s (collection: 1.989s, learning 0.096s)
             Mean action noise std: 2.49
          Mean value_function loss: 63.5111
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 72.0477
                       Mean reward: 168.94
               Mean episode length: 223.15
    Episode_Reward/reaching_object: 1.1288
    Episode_Reward/rotating_object: 31.5918
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.08s
                      Time elapsed: 00:20:40
                               ETA: 00:38:53

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 46103 steps/s (collection: 2.002s, learning 0.131s)
             Mean action noise std: 2.49
          Mean value_function loss: 64.5288
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.0672
                       Mean reward: 183.56
               Mean episode length: 223.21
    Episode_Reward/reaching_object: 1.1449
    Episode_Reward/rotating_object: 34.7117
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.13s
                      Time elapsed: 00:20:42
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 44149 steps/s (collection: 2.025s, learning 0.202s)
             Mean action noise std: 2.49
          Mean value_function loss: 60.9910
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 72.0842
                       Mean reward: 212.66
               Mean episode length: 225.21
    Episode_Reward/reaching_object: 1.1273
    Episode_Reward/rotating_object: 34.0139
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0623
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.23s
                      Time elapsed: 00:20:45
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 43908 steps/s (collection: 2.061s, learning 0.178s)
             Mean action noise std: 2.49
          Mean value_function loss: 62.2519
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 72.1081
                       Mean reward: 147.90
               Mean episode length: 223.33
    Episode_Reward/reaching_object: 1.1418
    Episode_Reward/rotating_object: 32.6526
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0631
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.24s
                      Time elapsed: 00:20:47
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 46524 steps/s (collection: 2.007s, learning 0.106s)
             Mean action noise std: 2.49
          Mean value_function loss: 63.9016
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 72.1307
                       Mean reward: 164.53
               Mean episode length: 224.49
    Episode_Reward/reaching_object: 1.1693
    Episode_Reward/rotating_object: 34.5309
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.11s
                      Time elapsed: 00:20:49
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 47896 steps/s (collection: 1.911s, learning 0.141s)
             Mean action noise std: 2.49
          Mean value_function loss: 56.1371
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 72.1479
                       Mean reward: 159.59
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 35.7959
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.05s
                      Time elapsed: 00:20:51
                               ETA: 00:38:39

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 45591 steps/s (collection: 2.013s, learning 0.143s)
             Mean action noise std: 2.50
          Mean value_function loss: 58.4033
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.1702
                       Mean reward: 159.82
               Mean episode length: 222.52
    Episode_Reward/reaching_object: 1.1546
    Episode_Reward/rotating_object: 34.5535
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.16s
                      Time elapsed: 00:20:53
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 46990 steps/s (collection: 1.952s, learning 0.140s)
             Mean action noise std: 2.50
          Mean value_function loss: 55.8424
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.1943
                       Mean reward: 192.83
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.1798
    Episode_Reward/rotating_object: 33.4267
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.09s
                      Time elapsed: 00:20:55
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 45673 steps/s (collection: 1.985s, learning 0.167s)
             Mean action noise std: 2.50
          Mean value_function loss: 60.5959
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 72.2174
                       Mean reward: 175.74
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.1485
    Episode_Reward/rotating_object: 34.9595
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.15s
                      Time elapsed: 00:20:57
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 47693 steps/s (collection: 1.926s, learning 0.135s)
             Mean action noise std: 2.50
          Mean value_function loss: 68.1081
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 72.2359
                       Mean reward: 182.15
               Mean episode length: 233.53
    Episode_Reward/reaching_object: 1.1665
    Episode_Reward/rotating_object: 35.3715
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.06s
                      Time elapsed: 00:20:59
                               ETA: 00:38:28

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 46007 steps/s (collection: 1.951s, learning 0.186s)
             Mean action noise std: 2.50
          Mean value_function loss: 62.3576
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 72.2547
                       Mean reward: 181.92
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.1197
    Episode_Reward/rotating_object: 33.3059
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0643
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.14s
                      Time elapsed: 00:21:02
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 46227 steps/s (collection: 1.974s, learning 0.153s)
             Mean action noise std: 2.51
          Mean value_function loss: 60.1545
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 72.2781
                       Mean reward: 179.64
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.1586
    Episode_Reward/rotating_object: 34.3784
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.13s
                      Time elapsed: 00:21:04
                               ETA: 00:38:22

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 46767 steps/s (collection: 1.987s, learning 0.115s)
             Mean action noise std: 2.51
          Mean value_function loss: 50.8720
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 72.3034
                       Mean reward: 186.96
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.1679
    Episode_Reward/rotating_object: 34.3114
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.10s
                      Time elapsed: 00:21:06
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 46833 steps/s (collection: 1.977s, learning 0.122s)
             Mean action noise std: 2.51
          Mean value_function loss: 67.8147
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 72.3232
                       Mean reward: 189.41
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 1.1469
    Episode_Reward/rotating_object: 35.5083
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.10s
                      Time elapsed: 00:21:08
                               ETA: 00:38:16

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 48644 steps/s (collection: 1.919s, learning 0.102s)
             Mean action noise std: 2.51
          Mean value_function loss: 66.2832
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 72.3371
                       Mean reward: 175.50
               Mean episode length: 222.95
    Episode_Reward/reaching_object: 1.1686
    Episode_Reward/rotating_object: 33.1589
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.02s
                      Time elapsed: 00:21:10
                               ETA: 00:38:13

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 47931 steps/s (collection: 1.907s, learning 0.144s)
             Mean action noise std: 2.51
          Mean value_function loss: 62.6273
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 72.3514
                       Mean reward: 189.76
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.1770
    Episode_Reward/rotating_object: 36.6573
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.9583
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.05s
                      Time elapsed: 00:21:12
                               ETA: 00:38:10

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 47509 steps/s (collection: 1.952s, learning 0.117s)
             Mean action noise std: 2.51
          Mean value_function loss: 68.4772
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 72.3718
                       Mean reward: 185.49
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.1813
    Episode_Reward/rotating_object: 35.8606
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.07s
                      Time elapsed: 00:21:14
                               ETA: 00:38:08

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 46050 steps/s (collection: 1.999s, learning 0.136s)
             Mean action noise std: 2.51
          Mean value_function loss: 67.4118
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.3951
                       Mean reward: 196.35
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 36.4652
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.13s
                      Time elapsed: 00:21:16
                               ETA: 00:38:05

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 46414 steps/s (collection: 1.998s, learning 0.120s)
             Mean action noise std: 2.52
          Mean value_function loss: 59.5575
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 72.4153
                       Mean reward: 172.95
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.1568
    Episode_Reward/rotating_object: 31.6334
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.12s
                      Time elapsed: 00:21:18
                               ETA: 00:38:02

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 47028 steps/s (collection: 1.923s, learning 0.168s)
             Mean action noise std: 2.52
          Mean value_function loss: 58.3278
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 72.4379
                       Mean reward: 167.46
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.1763
    Episode_Reward/rotating_object: 37.8002
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.09s
                      Time elapsed: 00:21:20
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 47428 steps/s (collection: 1.937s, learning 0.135s)
             Mean action noise std: 2.52
          Mean value_function loss: 66.1508
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 72.4602
                       Mean reward: 196.80
               Mean episode length: 224.89
    Episode_Reward/reaching_object: 1.1583
    Episode_Reward/rotating_object: 31.4666
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.07s
                      Time elapsed: 00:21:22
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 47479 steps/s (collection: 1.955s, learning 0.115s)
             Mean action noise std: 2.52
          Mean value_function loss: 66.2673
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 72.4776
                       Mean reward: 162.40
               Mean episode length: 215.28
    Episode_Reward/reaching_object: 1.1565
    Episode_Reward/rotating_object: 31.8115
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0650
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.07s
                      Time elapsed: 00:21:25
                               ETA: 00:37:53

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 46100 steps/s (collection: 1.979s, learning 0.153s)
             Mean action noise std: 2.52
          Mean value_function loss: 67.3184
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 72.4944
                       Mean reward: 208.67
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 39.3740
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.13s
                      Time elapsed: 00:21:27
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 44395 steps/s (collection: 2.011s, learning 0.203s)
             Mean action noise std: 2.52
          Mean value_function loss: 60.2772
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.5145
                       Mean reward: 208.71
               Mean episode length: 223.49
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 38.2196
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.21s
                      Time elapsed: 00:21:29
                               ETA: 00:37:48

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 47001 steps/s (collection: 1.946s, learning 0.145s)
             Mean action noise std: 2.53
          Mean value_function loss: 61.4780
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 72.5379
                       Mean reward: 178.14
               Mean episode length: 218.00
    Episode_Reward/reaching_object: 1.1498
    Episode_Reward/rotating_object: 35.0637
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.09s
                      Time elapsed: 00:21:31
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 46208 steps/s (collection: 2.029s, learning 0.099s)
             Mean action noise std: 2.53
          Mean value_function loss: 60.1729
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 72.5555
                       Mean reward: 162.39
               Mean episode length: 207.38
    Episode_Reward/reaching_object: 1.1214
    Episode_Reward/rotating_object: 32.2643
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.13s
                      Time elapsed: 00:21:33
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 47748 steps/s (collection: 1.936s, learning 0.123s)
             Mean action noise std: 2.53
          Mean value_function loss: 61.6482
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 72.5776
                       Mean reward: 164.49
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 1.1640
    Episode_Reward/rotating_object: 37.3598
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.06s
                      Time elapsed: 00:21:35
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 47434 steps/s (collection: 1.959s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 67.9807
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 72.6041
                       Mean reward: 159.80
               Mean episode length: 215.07
    Episode_Reward/reaching_object: 1.1353
    Episode_Reward/rotating_object: 32.8029
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.07s
                      Time elapsed: 00:21:37
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 46241 steps/s (collection: 2.036s, learning 0.090s)
             Mean action noise std: 2.53
          Mean value_function loss: 65.8859
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 72.6250
                       Mean reward: 197.60
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.1096
    Episode_Reward/rotating_object: 33.0777
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.13s
                      Time elapsed: 00:21:39
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 47909 steps/s (collection: 1.883s, learning 0.169s)
             Mean action noise std: 2.54
          Mean value_function loss: 70.2218
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.6448
                       Mean reward: 167.89
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 36.1851
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.05s
                      Time elapsed: 00:21:41
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 45973 steps/s (collection: 1.996s, learning 0.143s)
             Mean action noise std: 2.54
          Mean value_function loss: 69.2030
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.6690
                       Mean reward: 154.83
               Mean episode length: 227.99
    Episode_Reward/reaching_object: 1.1309
    Episode_Reward/rotating_object: 35.7837
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.14s
                      Time elapsed: 00:21:44
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 42705 steps/s (collection: 2.117s, learning 0.185s)
             Mean action noise std: 2.54
          Mean value_function loss: 63.3558
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 72.6916
                       Mean reward: 174.94
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 1.1347
    Episode_Reward/rotating_object: 34.6454
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.30s
                      Time elapsed: 00:21:46
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 46798 steps/s (collection: 1.982s, learning 0.119s)
             Mean action noise std: 2.54
          Mean value_function loss: 64.5682
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 72.7128
                       Mean reward: 184.06
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 1.1461
    Episode_Reward/rotating_object: 37.3403
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.10s
                      Time elapsed: 00:21:48
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 47145 steps/s (collection: 1.955s, learning 0.131s)
             Mean action noise std: 2.54
          Mean value_function loss: 59.3795
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 72.7355
                       Mean reward: 185.50
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.1246
    Episode_Reward/rotating_object: 32.9758
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.09s
                      Time elapsed: 00:21:50
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 46937 steps/s (collection: 1.948s, learning 0.146s)
             Mean action noise std: 2.54
          Mean value_function loss: 63.2475
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 72.7573
                       Mean reward: 154.12
               Mean episode length: 224.91
    Episode_Reward/reaching_object: 1.1375
    Episode_Reward/rotating_object: 33.6624
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.09s
                      Time elapsed: 00:21:52
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 46638 steps/s (collection: 2.005s, learning 0.103s)
             Mean action noise std: 2.55
          Mean value_function loss: 58.3459
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 72.7701
                       Mean reward: 172.19
               Mean episode length: 220.30
    Episode_Reward/reaching_object: 1.1446
    Episode_Reward/rotating_object: 38.5404
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.11s
                      Time elapsed: 00:21:54
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 47753 steps/s (collection: 1.941s, learning 0.118s)
             Mean action noise std: 2.55
          Mean value_function loss: 66.6726
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 72.7853
                       Mean reward: 171.12
               Mean episode length: 215.07
    Episode_Reward/reaching_object: 1.1409
    Episode_Reward/rotating_object: 36.0533
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.06s
                      Time elapsed: 00:21:56
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 48353 steps/s (collection: 1.939s, learning 0.094s)
             Mean action noise std: 2.55
          Mean value_function loss: 63.9197
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 72.8032
                       Mean reward: 177.14
               Mean episode length: 222.61
    Episode_Reward/reaching_object: 1.1416
    Episode_Reward/rotating_object: 35.1338
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.03s
                      Time elapsed: 00:21:58
                               ETA: 00:37:08

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 46726 steps/s (collection: 1.985s, learning 0.119s)
             Mean action noise std: 2.55
          Mean value_function loss: 67.8314
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 72.8176
                       Mean reward: 175.84
               Mean episode length: 218.92
    Episode_Reward/reaching_object: 1.1135
    Episode_Reward/rotating_object: 33.7954
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.10s
                      Time elapsed: 00:22:00
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 48304 steps/s (collection: 1.911s, learning 0.125s)
             Mean action noise std: 2.55
          Mean value_function loss: 59.2977
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 72.8313
                       Mean reward: 212.61
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 1.1476
    Episode_Reward/rotating_object: 40.4446
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.04s
                      Time elapsed: 00:22:02
                               ETA: 00:37:03

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 46755 steps/s (collection: 1.971s, learning 0.131s)
             Mean action noise std: 2.55
          Mean value_function loss: 54.9592
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 72.8474
                       Mean reward: 176.24
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 1.1358
    Episode_Reward/rotating_object: 38.2010
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.10s
                      Time elapsed: 00:22:05
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 46512 steps/s (collection: 1.979s, learning 0.134s)
             Mean action noise std: 2.55
          Mean value_function loss: 58.1920
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 72.8662
                       Mean reward: 176.14
               Mean episode length: 219.33
    Episode_Reward/reaching_object: 1.1248
    Episode_Reward/rotating_object: 35.8222
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.11s
                      Time elapsed: 00:22:07
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 43725 steps/s (collection: 2.102s, learning 0.146s)
             Mean action noise std: 2.56
          Mean value_function loss: 69.1654
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 72.8893
                       Mean reward: 198.10
               Mean episode length: 221.78
    Episode_Reward/reaching_object: 1.1432
    Episode_Reward/rotating_object: 36.7991
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0690
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.25s
                      Time elapsed: 00:22:09
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 47332 steps/s (collection: 1.945s, learning 0.132s)
             Mean action noise std: 2.56
          Mean value_function loss: 65.1164
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 72.9126
                       Mean reward: 167.71
               Mean episode length: 215.52
    Episode_Reward/reaching_object: 1.1201
    Episode_Reward/rotating_object: 34.8404
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.08s
                      Time elapsed: 00:22:11
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 44996 steps/s (collection: 2.014s, learning 0.171s)
             Mean action noise std: 2.56
          Mean value_function loss: 62.9974
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 72.9284
                       Mean reward: 183.30
               Mean episode length: 223.63
    Episode_Reward/reaching_object: 1.1192
    Episode_Reward/rotating_object: 36.5023
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.18s
                      Time elapsed: 00:22:13
                               ETA: 00:36:49

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 45748 steps/s (collection: 2.003s, learning 0.146s)
             Mean action noise std: 2.56
          Mean value_function loss: 64.5591
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 72.9433
                       Mean reward: 169.63
               Mean episode length: 207.73
    Episode_Reward/reaching_object: 1.1267
    Episode_Reward/rotating_object: 37.1820
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.15s
                      Time elapsed: 00:22:15
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 48460 steps/s (collection: 1.880s, learning 0.149s)
             Mean action noise std: 2.56
          Mean value_function loss: 55.9902
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.9612
                       Mean reward: 172.82
               Mean episode length: 222.39
    Episode_Reward/reaching_object: 1.1576
    Episode_Reward/rotating_object: 37.1476
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.03s
                      Time elapsed: 00:22:17
                               ETA: 00:36:43

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 46070 steps/s (collection: 1.980s, learning 0.154s)
             Mean action noise std: 2.56
          Mean value_function loss: 53.0305
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 72.9853
                       Mean reward: 172.24
               Mean episode length: 223.63
    Episode_Reward/reaching_object: 1.1269
    Episode_Reward/rotating_object: 35.2348
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.13s
                      Time elapsed: 00:22:20
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 47441 steps/s (collection: 1.944s, learning 0.128s)
             Mean action noise std: 2.57
          Mean value_function loss: 59.6975
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 73.0105
                       Mean reward: 179.52
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.1315
    Episode_Reward/rotating_object: 39.4129
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.07s
                      Time elapsed: 00:22:22
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 45572 steps/s (collection: 2.027s, learning 0.130s)
             Mean action noise std: 2.57
          Mean value_function loss: 56.5214
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 73.0358
                       Mean reward: 194.17
               Mean episode length: 216.25
    Episode_Reward/reaching_object: 1.1380
    Episode_Reward/rotating_object: 37.3675
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.16s
                      Time elapsed: 00:22:24
                               ETA: 00:36:35

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 44380 steps/s (collection: 2.049s, learning 0.166s)
             Mean action noise std: 2.57
          Mean value_function loss: 56.6273
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 73.0558
                       Mean reward: 168.87
               Mean episode length: 222.15
    Episode_Reward/reaching_object: 1.1246
    Episode_Reward/rotating_object: 37.8343
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.22s
                      Time elapsed: 00:22:26
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 46890 steps/s (collection: 1.975s, learning 0.122s)
             Mean action noise std: 2.57
          Mean value_function loss: 62.0403
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 73.0762
                       Mean reward: 185.55
               Mean episode length: 219.07
    Episode_Reward/reaching_object: 1.1251
    Episode_Reward/rotating_object: 39.1696
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.10s
                      Time elapsed: 00:22:28
                               ETA: 00:36:30

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 44697 steps/s (collection: 2.012s, learning 0.188s)
             Mean action noise std: 2.57
          Mean value_function loss: 67.4726
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 73.1006
                       Mean reward: 204.05
               Mean episode length: 228.30
    Episode_Reward/reaching_object: 1.1227
    Episode_Reward/rotating_object: 36.4139
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.20s
                      Time elapsed: 00:22:30
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 47370 steps/s (collection: 1.967s, learning 0.108s)
             Mean action noise std: 2.58
          Mean value_function loss: 67.4869
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 73.1211
                       Mean reward: 194.76
               Mean episode length: 223.04
    Episode_Reward/reaching_object: 1.1201
    Episode_Reward/rotating_object: 38.3039
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 1.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.08s
                      Time elapsed: 00:22:32
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 45150 steps/s (collection: 2.058s, learning 0.119s)
             Mean action noise std: 2.58
          Mean value_function loss: 65.2992
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 73.1364
                       Mean reward: 201.05
               Mean episode length: 220.11
    Episode_Reward/reaching_object: 1.1496
    Episode_Reward/rotating_object: 39.4310
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.18s
                      Time elapsed: 00:22:35
                               ETA: 00:36:22

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 45588 steps/s (collection: 2.023s, learning 0.133s)
             Mean action noise std: 2.58
          Mean value_function loss: 66.9122
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 73.1602
                       Mean reward: 195.55
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 1.1338
    Episode_Reward/rotating_object: 41.0148
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.16s
                      Time elapsed: 00:22:37
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 45959 steps/s (collection: 1.974s, learning 0.165s)
             Mean action noise std: 2.58
          Mean value_function loss: 65.1376
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 73.1838
                       Mean reward: 191.03
               Mean episode length: 218.36
    Episode_Reward/reaching_object: 1.1281
    Episode_Reward/rotating_object: 38.8787
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.14s
                      Time elapsed: 00:22:39
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 47740 steps/s (collection: 1.906s, learning 0.153s)
             Mean action noise std: 2.58
          Mean value_function loss: 56.3298
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 73.2034
                       Mean reward: 201.03
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.1545
    Episode_Reward/rotating_object: 40.3449
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.06s
                      Time elapsed: 00:22:41
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 44266 steps/s (collection: 2.073s, learning 0.148s)
             Mean action noise std: 2.58
          Mean value_function loss: 74.7328
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 73.2211
                       Mean reward: 191.81
               Mean episode length: 224.61
    Episode_Reward/reaching_object: 1.1395
    Episode_Reward/rotating_object: 39.5558
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0686
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.22s
                      Time elapsed: 00:22:43
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 44682 steps/s (collection: 1.996s, learning 0.204s)
             Mean action noise std: 2.59
          Mean value_function loss: 80.7368
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 73.2418
                       Mean reward: 219.45
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.1319
    Episode_Reward/rotating_object: 36.1940
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.20s
                      Time elapsed: 00:22:45
                               ETA: 00:36:08

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 43381 steps/s (collection: 2.069s, learning 0.197s)
             Mean action noise std: 2.59
          Mean value_function loss: 70.4795
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 73.2577
                       Mean reward: 195.77
               Mean episode length: 214.63
    Episode_Reward/reaching_object: 1.1372
    Episode_Reward/rotating_object: 40.1645
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.27s
                      Time elapsed: 00:22:48
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 42961 steps/s (collection: 2.127s, learning 0.162s)
             Mean action noise std: 2.59
          Mean value_function loss: 68.5154
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 73.2750
                       Mean reward: 184.06
               Mean episode length: 227.23
    Episode_Reward/reaching_object: 1.1528
    Episode_Reward/rotating_object: 37.6151
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.29s
                      Time elapsed: 00:22:50
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 44970 steps/s (collection: 2.012s, learning 0.174s)
             Mean action noise std: 2.59
          Mean value_function loss: 64.0753
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 73.2995
                       Mean reward: 182.85
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 1.1341
    Episode_Reward/rotating_object: 36.6901
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0689
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.19s
                      Time elapsed: 00:22:52
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 46673 steps/s (collection: 1.963s, learning 0.143s)
             Mean action noise std: 2.59
          Mean value_function loss: 68.1733
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 73.3257
                       Mean reward: 232.07
               Mean episode length: 217.40
    Episode_Reward/reaching_object: 1.1541
    Episode_Reward/rotating_object: 43.0905
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0699
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.11s
                      Time elapsed: 00:22:54
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 42205 steps/s (collection: 2.182s, learning 0.147s)
             Mean action noise std: 2.59
          Mean value_function loss: 73.2070
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 73.3466
                       Mean reward: 200.83
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 1.1542
    Episode_Reward/rotating_object: 36.0843
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.33s
                      Time elapsed: 00:22:56
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 45276 steps/s (collection: 2.032s, learning 0.140s)
             Mean action noise std: 2.60
          Mean value_function loss: 63.9553
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 73.3652
                       Mean reward: 198.95
               Mean episode length: 219.12
    Episode_Reward/reaching_object: 1.1582
    Episode_Reward/rotating_object: 35.4862
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0699
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.17s
                      Time elapsed: 00:22:59
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 44185 steps/s (collection: 2.076s, learning 0.149s)
             Mean action noise std: 2.60
          Mean value_function loss: 67.1206
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 73.3835
                       Mean reward: 194.09
               Mean episode length: 224.60
    Episode_Reward/reaching_object: 1.1505
    Episode_Reward/rotating_object: 37.8555
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.22s
                      Time elapsed: 00:23:01
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 44512 steps/s (collection: 2.054s, learning 0.155s)
             Mean action noise std: 2.60
          Mean value_function loss: 64.8424
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 73.4060
                       Mean reward: 170.41
               Mean episode length: 213.45
    Episode_Reward/reaching_object: 1.1403
    Episode_Reward/rotating_object: 38.1726
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.21s
                      Time elapsed: 00:23:03
                               ETA: 00:35:48

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 45670 steps/s (collection: 2.021s, learning 0.131s)
             Mean action noise std: 2.60
          Mean value_function loss: 69.4011
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.4288
                       Mean reward: 201.47
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 1.1502
    Episode_Reward/rotating_object: 37.2992
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0686
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.15s
                      Time elapsed: 00:23:05
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 46436 steps/s (collection: 1.995s, learning 0.122s)
             Mean action noise std: 2.60
          Mean value_function loss: 62.3060
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 73.4490
                       Mean reward: 186.05
               Mean episode length: 218.64
    Episode_Reward/reaching_object: 1.1508
    Episode_Reward/rotating_object: 38.5335
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.12s
                      Time elapsed: 00:23:07
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 45256 steps/s (collection: 2.063s, learning 0.109s)
             Mean action noise std: 2.61
          Mean value_function loss: 76.2213
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 73.4709
                       Mean reward: 219.82
               Mean episode length: 217.00
    Episode_Reward/reaching_object: 1.1317
    Episode_Reward/rotating_object: 36.0685
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.17s
                      Time elapsed: 00:23:10
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 46027 steps/s (collection: 1.993s, learning 0.143s)
             Mean action noise std: 2.61
          Mean value_function loss: 75.0112
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 73.4970
                       Mean reward: 212.37
               Mean episode length: 228.52
    Episode_Reward/reaching_object: 1.1877
    Episode_Reward/rotating_object: 40.0880
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0686
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.14s
                      Time elapsed: 00:23:12
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 46111 steps/s (collection: 1.982s, learning 0.150s)
             Mean action noise std: 2.61
          Mean value_function loss: 65.8809
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 73.5279
                       Mean reward: 193.33
               Mean episode length: 225.91
    Episode_Reward/reaching_object: 1.1700
    Episode_Reward/rotating_object: 38.0038
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.13s
                      Time elapsed: 00:23:14
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 44524 steps/s (collection: 2.077s, learning 0.131s)
             Mean action noise std: 2.61
          Mean value_function loss: 69.6311
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 73.5541
                       Mean reward: 189.11
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.1732
    Episode_Reward/rotating_object: 35.9218
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.21s
                      Time elapsed: 00:23:16
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 44417 steps/s (collection: 2.082s, learning 0.131s)
             Mean action noise std: 2.61
          Mean value_function loss: 72.2320
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 73.5753
                       Mean reward: 214.94
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.1614
    Episode_Reward/rotating_object: 38.9978
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.21s
                      Time elapsed: 00:23:18
                               ETA: 00:35:29

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 44402 steps/s (collection: 2.055s, learning 0.159s)
             Mean action noise std: 2.62
          Mean value_function loss: 66.3484
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 73.5983
                       Mean reward: 213.75
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 40.9920
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.21s
                      Time elapsed: 00:23:20
                               ETA: 00:35:27

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 44862 steps/s (collection: 2.090s, learning 0.101s)
             Mean action noise std: 2.62
          Mean value_function loss: 61.3624
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 73.6268
                       Mean reward: 189.38
               Mean episode length: 220.69
    Episode_Reward/reaching_object: 1.1336
    Episode_Reward/rotating_object: 36.1960
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.19s
                      Time elapsed: 00:23:23
                               ETA: 00:35:24

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 44470 steps/s (collection: 2.061s, learning 0.150s)
             Mean action noise std: 2.62
          Mean value_function loss: 69.0423
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 73.6493
                       Mean reward: 219.24
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 1.1852
    Episode_Reward/rotating_object: 38.4131
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.21s
                      Time elapsed: 00:23:25
                               ETA: 00:35:22

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 45368 steps/s (collection: 2.026s, learning 0.141s)
             Mean action noise std: 2.62
          Mean value_function loss: 61.3300
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.6707
                       Mean reward: 192.71
               Mean episode length: 222.61
    Episode_Reward/reaching_object: 1.1603
    Episode_Reward/rotating_object: 37.6476
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.17s
                      Time elapsed: 00:23:27
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 45522 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 2.62
          Mean value_function loss: 67.4194
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 73.6948
                       Mean reward: 211.80
               Mean episode length: 223.99
    Episode_Reward/reaching_object: 1.1572
    Episode_Reward/rotating_object: 38.3824
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.16s
                      Time elapsed: 00:23:29
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 45529 steps/s (collection: 2.031s, learning 0.129s)
             Mean action noise std: 2.63
          Mean value_function loss: 62.7361
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.7163
                       Mean reward: 190.42
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.1733
    Episode_Reward/rotating_object: 40.5274
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.16s
                      Time elapsed: 00:23:31
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 45161 steps/s (collection: 2.041s, learning 0.136s)
             Mean action noise std: 2.63
          Mean value_function loss: 63.6254
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 73.7405
                       Mean reward: 203.47
               Mean episode length: 221.59
    Episode_Reward/reaching_object: 1.1454
    Episode_Reward/rotating_object: 37.7591
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.18s
                      Time elapsed: 00:23:33
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 43912 steps/s (collection: 2.111s, learning 0.128s)
             Mean action noise std: 2.63
          Mean value_function loss: 62.7594
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 73.7666
                       Mean reward: 213.24
               Mean episode length: 224.05
    Episode_Reward/reaching_object: 1.1845
    Episode_Reward/rotating_object: 40.8538
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0704
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.24s
                      Time elapsed: 00:23:36
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 44737 steps/s (collection: 2.060s, learning 0.138s)
             Mean action noise std: 2.63
          Mean value_function loss: 60.7115
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 73.7872
                       Mean reward: 229.15
               Mean episode length: 221.94
    Episode_Reward/reaching_object: 1.1631
    Episode_Reward/rotating_object: 41.5652
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0689
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.20s
                      Time elapsed: 00:23:38
                               ETA: 00:35:06

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 48068 steps/s (collection: 1.945s, learning 0.100s)
             Mean action noise std: 2.63
          Mean value_function loss: 61.6477
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 73.8094
                       Mean reward: 203.89
               Mean episode length: 230.54
    Episode_Reward/reaching_object: 1.1719
    Episode_Reward/rotating_object: 41.9581
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.05s
                      Time elapsed: 00:23:40
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 44686 steps/s (collection: 2.020s, learning 0.180s)
             Mean action noise std: 2.64
          Mean value_function loss: 61.5102
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 73.8349
                       Mean reward: 222.96
               Mean episode length: 222.39
    Episode_Reward/reaching_object: 1.1411
    Episode_Reward/rotating_object: 39.9273
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.20s
                      Time elapsed: 00:23:42
                               ETA: 00:35:01

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 44533 steps/s (collection: 2.043s, learning 0.165s)
             Mean action noise std: 2.64
          Mean value_function loss: 63.5760
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 73.8575
                       Mean reward: 181.79
               Mean episode length: 224.89
    Episode_Reward/reaching_object: 1.1404
    Episode_Reward/rotating_object: 35.2613
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 1.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.21s
                      Time elapsed: 00:23:44
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 44394 steps/s (collection: 2.089s, learning 0.126s)
             Mean action noise std: 2.64
          Mean value_function loss: 65.5121
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 73.8830
                       Mean reward: 177.46
               Mean episode length: 222.83
    Episode_Reward/reaching_object: 1.1414
    Episode_Reward/rotating_object: 39.1382
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.21s
                      Time elapsed: 00:23:47
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 45494 steps/s (collection: 2.012s, learning 0.149s)
             Mean action noise std: 2.64
          Mean value_function loss: 61.9704
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 73.9022
                       Mean reward: 209.21
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 1.1478
    Episode_Reward/rotating_object: 41.6252
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.16s
                      Time elapsed: 00:23:49
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 44962 steps/s (collection: 2.038s, learning 0.149s)
             Mean action noise std: 2.64
          Mean value_function loss: 68.6912
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 73.9250
                       Mean reward: 189.54
               Mean episode length: 224.87
    Episode_Reward/reaching_object: 1.1593
    Episode_Reward/rotating_object: 40.9671
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.19s
                      Time elapsed: 00:23:51
                               ETA: 00:34:50

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 45916 steps/s (collection: 2.023s, learning 0.118s)
             Mean action noise std: 2.65
          Mean value_function loss: 70.3699
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 73.9533
                       Mean reward: 227.04
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 42.3896
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.14s
                      Time elapsed: 00:23:53
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 43651 steps/s (collection: 2.116s, learning 0.136s)
             Mean action noise std: 2.65
          Mean value_function loss: 67.9193
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 73.9715
                       Mean reward: 237.25
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.1530
    Episode_Reward/rotating_object: 44.7322
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.25s
                      Time elapsed: 00:23:55
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 42788 steps/s (collection: 2.146s, learning 0.151s)
             Mean action noise std: 2.65
          Mean value_function loss: 69.8800
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 73.9932
                       Mean reward: 204.80
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 1.1655
    Episode_Reward/rotating_object: 40.3685
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.30s
                      Time elapsed: 00:23:58
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 44821 steps/s (collection: 1.996s, learning 0.197s)
             Mean action noise std: 2.65
          Mean value_function loss: 74.3195
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 74.0197
                       Mean reward: 239.76
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 1.1617
    Episode_Reward/rotating_object: 41.7371
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.19s
                      Time elapsed: 00:24:00
                               ETA: 00:34:40

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 46585 steps/s (collection: 1.984s, learning 0.127s)
             Mean action noise std: 2.66
          Mean value_function loss: 81.7304
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 74.0471
                       Mean reward: 206.18
               Mean episode length: 220.27
    Episode_Reward/reaching_object: 1.1520
    Episode_Reward/rotating_object: 38.1741
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.11s
                      Time elapsed: 00:24:02
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 44639 steps/s (collection: 2.064s, learning 0.139s)
             Mean action noise std: 2.66
          Mean value_function loss: 77.3955
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 74.0755
                       Mean reward: 231.36
               Mean episode length: 220.26
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 42.5093
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.20s
                      Time elapsed: 00:24:04
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 44064 steps/s (collection: 2.113s, learning 0.118s)
             Mean action noise std: 2.66
          Mean value_function loss: 72.5218
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 74.0969
                       Mean reward: 193.14
               Mean episode length: 227.65
    Episode_Reward/reaching_object: 1.1581
    Episode_Reward/rotating_object: 39.4251
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.23s
                      Time elapsed: 00:24:06
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 42813 steps/s (collection: 2.126s, learning 0.171s)
             Mean action noise std: 2.66
          Mean value_function loss: 77.2400
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 74.1110
                       Mean reward: 216.38
               Mean episode length: 225.38
    Episode_Reward/reaching_object: 1.1626
    Episode_Reward/rotating_object: 44.9139
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.30s
                      Time elapsed: 00:24:09
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 46024 steps/s (collection: 1.981s, learning 0.155s)
             Mean action noise std: 2.66
          Mean value_function loss: 370.6402
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 74.1197
                       Mean reward: 170.71
               Mean episode length: 208.91
    Episode_Reward/reaching_object: 1.1486
    Episode_Reward/rotating_object: 37.9246
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -1.1573
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.14s
                      Time elapsed: 00:24:11
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 44366 steps/s (collection: 2.071s, learning 0.145s)
             Mean action noise std: 2.66
          Mean value_function loss: 84.5115
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.1236
                       Mean reward: 200.91
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 1.1809
    Episode_Reward/rotating_object: 41.1821
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.22s
                      Time elapsed: 00:24:13
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 43426 steps/s (collection: 2.129s, learning 0.135s)
             Mean action noise std: 2.66
          Mean value_function loss: 80.2824
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.1361
                       Mean reward: 231.26
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.1617
    Episode_Reward/rotating_object: 39.9948
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.26s
                      Time elapsed: 00:24:15
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 45085 steps/s (collection: 2.026s, learning 0.154s)
             Mean action noise std: 2.66
          Mean value_function loss: 75.6837
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 74.1555
                       Mean reward: 218.56
               Mean episode length: 225.27
    Episode_Reward/reaching_object: 1.1318
    Episode_Reward/rotating_object: 40.1032
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.18s
                      Time elapsed: 00:24:17
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 44624 steps/s (collection: 2.022s, learning 0.181s)
             Mean action noise std: 2.67
          Mean value_function loss: 75.6960
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 74.1815
                       Mean reward: 205.41
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 1.1651
    Episode_Reward/rotating_object: 41.4885
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.20s
                      Time elapsed: 00:24:20
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 44967 steps/s (collection: 2.032s, learning 0.155s)
             Mean action noise std: 2.67
          Mean value_function loss: 79.0385
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 74.2070
                       Mean reward: 169.08
               Mean episode length: 222.68
    Episode_Reward/reaching_object: 1.1754
    Episode_Reward/rotating_object: 38.6163
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.19s
                      Time elapsed: 00:24:22
                               ETA: 00:34:15

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 44290 steps/s (collection: 2.084s, learning 0.136s)
             Mean action noise std: 2.67
          Mean value_function loss: 78.8957
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 74.2323
                       Mean reward: 169.75
               Mean episode length: 222.92
    Episode_Reward/reaching_object: 1.1352
    Episode_Reward/rotating_object: 37.4202
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.22s
                      Time elapsed: 00:24:24
                               ETA: 00:34:12

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 43045 steps/s (collection: 2.111s, learning 0.173s)
             Mean action noise std: 2.67
          Mean value_function loss: 64.2569
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 74.2585
                       Mean reward: 207.31
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.1590
    Episode_Reward/rotating_object: 39.9104
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.28s
                      Time elapsed: 00:24:26
                               ETA: 00:34:10

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 45522 steps/s (collection: 1.970s, learning 0.189s)
             Mean action noise std: 2.68
          Mean value_function loss: 71.8114
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 74.2848
                       Mean reward: 211.51
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 1.1713
    Episode_Reward/rotating_object: 40.6606
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.16s
                      Time elapsed: 00:24:29
                               ETA: 00:34:07

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 45475 steps/s (collection: 2.019s, learning 0.143s)
             Mean action noise std: 2.68
          Mean value_function loss: 62.7726
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 74.3102
                       Mean reward: 166.69
               Mean episode length: 221.75
    Episode_Reward/reaching_object: 1.1387
    Episode_Reward/rotating_object: 39.7944
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.16s
                      Time elapsed: 00:24:31
                               ETA: 00:34:05

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 45309 steps/s (collection: 2.057s, learning 0.112s)
             Mean action noise std: 2.68
          Mean value_function loss: 73.6361
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 74.3358
                       Mean reward: 179.50
               Mean episode length: 199.43
    Episode_Reward/reaching_object: 1.1375
    Episode_Reward/rotating_object: 39.8430
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.17s
                      Time elapsed: 00:24:33
                               ETA: 00:34:02

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 42858 steps/s (collection: 2.120s, learning 0.174s)
             Mean action noise std: 2.68
          Mean value_function loss: 74.4746
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 74.3607
                       Mean reward: 213.32
               Mean episode length: 229.93
    Episode_Reward/reaching_object: 1.1441
    Episode_Reward/rotating_object: 41.4255
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.29s
                      Time elapsed: 00:24:35
                               ETA: 00:34:00

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 43935 steps/s (collection: 2.051s, learning 0.186s)
             Mean action noise std: 2.68
          Mean value_function loss: 73.9248
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 74.3796
                       Mean reward: 217.24
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 1.1548
    Episode_Reward/rotating_object: 41.4941
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.24s
                      Time elapsed: 00:24:37
                               ETA: 00:33:57

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 45695 steps/s (collection: 2.008s, learning 0.144s)
             Mean action noise std: 2.69
          Mean value_function loss: 67.0103
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 74.3936
                       Mean reward: 242.00
               Mean episode length: 228.67
    Episode_Reward/reaching_object: 1.1818
    Episode_Reward/rotating_object: 44.3993
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.15s
                      Time elapsed: 00:24:40
                               ETA: 00:33:55

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 43957 steps/s (collection: 2.078s, learning 0.158s)
             Mean action noise std: 2.69
          Mean value_function loss: 73.7999
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 74.4174
                       Mean reward: 229.06
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 1.1678
    Episode_Reward/rotating_object: 41.0094
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.24s
                      Time elapsed: 00:24:42
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 46846 steps/s (collection: 1.981s, learning 0.118s)
             Mean action noise std: 2.69
          Mean value_function loss: 84.6042
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 74.4381
                       Mean reward: 201.79
               Mean episode length: 222.96
    Episode_Reward/reaching_object: 1.1478
    Episode_Reward/rotating_object: 43.3070
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.10s
                      Time elapsed: 00:24:44
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 44459 steps/s (collection: 2.103s, learning 0.108s)
             Mean action noise std: 2.69
          Mean value_function loss: 77.7134
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 74.4588
                       Mean reward: 218.70
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.1359
    Episode_Reward/rotating_object: 40.8758
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.21s
                      Time elapsed: 00:24:46
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 45162 steps/s (collection: 2.007s, learning 0.170s)
             Mean action noise std: 2.69
          Mean value_function loss: 82.4574
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 74.4855
                       Mean reward: 205.97
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 1.1421
    Episode_Reward/rotating_object: 42.5673
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.18s
                      Time elapsed: 00:24:48
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 45311 steps/s (collection: 2.034s, learning 0.136s)
             Mean action noise std: 2.70
          Mean value_function loss: 74.3867
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 74.5066
                       Mean reward: 191.50
               Mean episode length: 219.05
    Episode_Reward/reaching_object: 1.1668
    Episode_Reward/rotating_object: 40.4604
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.17s
                      Time elapsed: 00:24:50
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 45389 steps/s (collection: 2.004s, learning 0.162s)
             Mean action noise std: 2.70
          Mean value_function loss: 72.5686
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 74.5350
                       Mean reward: 213.06
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 1.1474
    Episode_Reward/rotating_object: 40.5808
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0641
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.17s
                      Time elapsed: 00:24:53
                               ETA: 00:33:39

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 40211 steps/s (collection: 2.282s, learning 0.163s)
             Mean action noise std: 2.70
          Mean value_function loss: 62.7660
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 74.5587
                       Mean reward: 207.59
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 41.5162
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.44s
                      Time elapsed: 00:24:55
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 39930 steps/s (collection: 2.295s, learning 0.167s)
             Mean action noise std: 2.70
          Mean value_function loss: 63.8869
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.5783
                       Mean reward: 203.23
               Mean episode length: 217.24
    Episode_Reward/reaching_object: 1.1522
    Episode_Reward/rotating_object: 42.5528
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0646
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.46s
                      Time elapsed: 00:24:57
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 41139 steps/s (collection: 2.231s, learning 0.159s)
             Mean action noise std: 2.70
          Mean value_function loss: 83.2248
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.5995
                       Mean reward: 202.67
               Mean episode length: 229.03
    Episode_Reward/reaching_object: 1.1408
    Episode_Reward/rotating_object: 38.0589
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0630
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.39s
                      Time elapsed: 00:25:00
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 40651 steps/s (collection: 2.252s, learning 0.167s)
             Mean action noise std: 2.71
          Mean value_function loss: 79.4765
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 74.6329
                       Mean reward: 221.20
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 1.1371
    Episode_Reward/rotating_object: 43.8068
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0629
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.42s
                      Time elapsed: 00:25:02
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 41923 steps/s (collection: 2.204s, learning 0.141s)
             Mean action noise std: 2.71
          Mean value_function loss: 71.1483
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 74.6685
                       Mean reward: 180.01
               Mean episode length: 215.89
    Episode_Reward/reaching_object: 1.1181
    Episode_Reward/rotating_object: 42.5115
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0620
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.34s
                      Time elapsed: 00:25:05
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 45382 steps/s (collection: 2.031s, learning 0.135s)
             Mean action noise std: 2.71
          Mean value_function loss: 74.8831
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 74.7020
                       Mean reward: 162.57
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 1.1356
    Episode_Reward/rotating_object: 40.8302
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.17s
                      Time elapsed: 00:25:07
                               ETA: 00:33:25

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 45397 steps/s (collection: 2.041s, learning 0.125s)
             Mean action noise std: 2.72
          Mean value_function loss: 72.6395
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 74.7304
                       Mean reward: 190.53
               Mean episode length: 219.62
    Episode_Reward/reaching_object: 1.1310
    Episode_Reward/rotating_object: 35.2638
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.17s
                      Time elapsed: 00:25:09
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 45584 steps/s (collection: 2.015s, learning 0.142s)
             Mean action noise std: 2.72
          Mean value_function loss: 72.6381
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 74.7614
                       Mean reward: 214.35
               Mean episode length: 212.02
    Episode_Reward/reaching_object: 1.1388
    Episode_Reward/rotating_object: 40.9958
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.16s
                      Time elapsed: 00:25:11
                               ETA: 00:33:20

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 43178 steps/s (collection: 2.120s, learning 0.157s)
             Mean action noise std: 2.72
          Mean value_function loss: 65.3629
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 74.7878
                       Mean reward: 174.51
               Mean episode length: 212.48
    Episode_Reward/reaching_object: 1.1235
    Episode_Reward/rotating_object: 41.3568
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0640
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.28s
                      Time elapsed: 00:25:13
                               ETA: 00:33:18

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 46312 steps/s (collection: 2.017s, learning 0.106s)
             Mean action noise std: 2.72
          Mean value_function loss: 71.2962
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 74.8088
                       Mean reward: 214.52
               Mean episode length: 215.58
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 42.0827
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.12s
                      Time elapsed: 00:25:16
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 44049 steps/s (collection: 2.104s, learning 0.128s)
             Mean action noise std: 2.73
          Mean value_function loss: 65.4745
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 74.8361
                       Mean reward: 191.56
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 1.1465
    Episode_Reward/rotating_object: 42.1634
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.23s
                      Time elapsed: 00:25:18
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 46403 steps/s (collection: 2.012s, learning 0.106s)
             Mean action noise std: 2.73
          Mean value_function loss: 72.6946
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 74.8590
                       Mean reward: 246.16
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 1.1326
    Episode_Reward/rotating_object: 41.0869
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.12s
                      Time elapsed: 00:25:20
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 43054 steps/s (collection: 2.116s, learning 0.167s)
             Mean action noise std: 2.73
          Mean value_function loss: 66.5621
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 74.8899
                       Mean reward: 224.28
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 1.1534
    Episode_Reward/rotating_object: 40.6847
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.28s
                      Time elapsed: 00:25:22
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 41523 steps/s (collection: 2.196s, learning 0.172s)
             Mean action noise std: 2.73
          Mean value_function loss: 69.4733
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.9178
                       Mean reward: 218.22
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.1516
    Episode_Reward/rotating_object: 40.5923
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.37s
                      Time elapsed: 00:25:25
                               ETA: 00:33:05

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 43862 steps/s (collection: 2.098s, learning 0.143s)
             Mean action noise std: 2.73
          Mean value_function loss: 66.5782
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 74.9382
                       Mean reward: 208.76
               Mean episode length: 226.28
    Episode_Reward/reaching_object: 1.1476
    Episode_Reward/rotating_object: 41.6296
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.24s
                      Time elapsed: 00:25:27
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 45245 steps/s (collection: 2.049s, learning 0.124s)
             Mean action noise std: 2.74
          Mean value_function loss: 64.4733
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 74.9689
                       Mean reward: 215.31
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 1.1686
    Episode_Reward/rotating_object: 43.4052
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.17s
                      Time elapsed: 00:25:29
                               ETA: 00:33:00

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 45164 steps/s (collection: 2.042s, learning 0.134s)
             Mean action noise std: 2.74
          Mean value_function loss: 77.2289
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 74.9966
                       Mean reward: 218.61
               Mean episode length: 219.57
    Episode_Reward/reaching_object: 1.1549
    Episode_Reward/rotating_object: 41.2614
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.18s
                      Time elapsed: 00:25:31
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 46170 steps/s (collection: 1.990s, learning 0.140s)
             Mean action noise std: 2.74
          Mean value_function loss: 80.7433
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 75.0236
                       Mean reward: 206.71
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 1.1292
    Episode_Reward/rotating_object: 39.6578
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.13s
                      Time elapsed: 00:25:33
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 44632 steps/s (collection: 2.010s, learning 0.193s)
             Mean action noise std: 2.74
          Mean value_function loss: 76.6919
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 75.0466
                       Mean reward: 208.32
               Mean episode length: 226.76
    Episode_Reward/reaching_object: 1.1401
    Episode_Reward/rotating_object: 41.4551
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.20s
                      Time elapsed: 00:25:35
                               ETA: 00:32:53

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 44461 steps/s (collection: 2.071s, learning 0.140s)
             Mean action noise std: 2.75
          Mean value_function loss: 71.2726
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 75.0717
                       Mean reward: 215.72
               Mean episode length: 224.71
    Episode_Reward/reaching_object: 1.1589
    Episode_Reward/rotating_object: 41.9515
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.21s
                      Time elapsed: 00:25:38
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 46988 steps/s (collection: 1.954s, learning 0.138s)
             Mean action noise std: 2.75
          Mean value_function loss: 74.0271
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 75.0980
                       Mean reward: 198.58
               Mean episode length: 217.24
    Episode_Reward/reaching_object: 1.1468
    Episode_Reward/rotating_object: 39.7692
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.09s
                      Time elapsed: 00:25:40
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 45477 steps/s (collection: 2.035s, learning 0.127s)
             Mean action noise std: 2.75
          Mean value_function loss: 71.1755
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 75.1229
                       Mean reward: 190.77
               Mean episode length: 211.06
    Episode_Reward/reaching_object: 1.1265
    Episode_Reward/rotating_object: 40.7749
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.16s
                      Time elapsed: 00:25:42
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 45655 steps/s (collection: 2.028s, learning 0.126s)
             Mean action noise std: 2.75
          Mean value_function loss: 73.3642
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 75.1468
                       Mean reward: 233.46
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 1.1659
    Episode_Reward/rotating_object: 43.1599
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.15s
                      Time elapsed: 00:25:44
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 44760 steps/s (collection: 2.077s, learning 0.119s)
             Mean action noise std: 2.76
          Mean value_function loss: 72.3802
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 75.1731
                       Mean reward: 220.95
               Mean episode length: 223.56
    Episode_Reward/reaching_object: 1.1664
    Episode_Reward/rotating_object: 45.4051
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.20s
                      Time elapsed: 00:25:46
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 43083 steps/s (collection: 2.104s, learning 0.178s)
             Mean action noise std: 2.76
          Mean value_function loss: 64.1523
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 75.2059
                       Mean reward: 255.13
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.1735
    Episode_Reward/rotating_object: 46.1491
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.28s
                      Time elapsed: 00:25:49
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 45553 steps/s (collection: 2.032s, learning 0.126s)
             Mean action noise std: 2.76
          Mean value_function loss: 68.5590
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 75.2236
                       Mean reward: 230.11
               Mean episode length: 214.15
    Episode_Reward/reaching_object: 1.1327
    Episode_Reward/rotating_object: 47.1483
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.16s
                      Time elapsed: 00:25:51
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 46811 steps/s (collection: 1.971s, learning 0.129s)
             Mean action noise std: 2.76
          Mean value_function loss: 68.2312
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 75.2433
                       Mean reward: 224.21
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.1754
    Episode_Reward/rotating_object: 46.4560
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0696
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.10s
                      Time elapsed: 00:25:53
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 46794 steps/s (collection: 1.964s, learning 0.137s)
             Mean action noise std: 2.76
          Mean value_function loss: 75.8760
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 75.2613
                       Mean reward: 257.86
               Mean episode length: 223.98
    Episode_Reward/reaching_object: 1.1255
    Episode_Reward/rotating_object: 47.2290
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.10s
                      Time elapsed: 00:25:55
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 28053 steps/s (collection: 3.393s, learning 0.112s)
             Mean action noise std: 2.77
          Mean value_function loss: 76.0439
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 75.2825
                       Mean reward: 217.00
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 1.1672
    Episode_Reward/rotating_object: 46.0973
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.50s
                      Time elapsed: 00:25:58
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14539 steps/s (collection: 6.636s, learning 0.126s)
             Mean action noise std: 2.77
          Mean value_function loss: 74.6902
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 75.3044
                       Mean reward: 225.14
               Mean episode length: 231.11
    Episode_Reward/reaching_object: 1.1534
    Episode_Reward/rotating_object: 44.7059
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.76s
                      Time elapsed: 00:26:05
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14565 steps/s (collection: 6.593s, learning 0.156s)
             Mean action noise std: 2.77
          Mean value_function loss: 62.4696
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 75.3259
                       Mean reward: 263.79
               Mean episode length: 229.07
    Episode_Reward/reaching_object: 1.1667
    Episode_Reward/rotating_object: 48.6418
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.75s
                      Time elapsed: 00:26:12
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14469 steps/s (collection: 6.651s, learning 0.143s)
             Mean action noise std: 2.77
          Mean value_function loss: 59.9536
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 75.3465
                       Mean reward: 239.38
               Mean episode length: 217.42
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 47.0500
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.79s
                      Time elapsed: 00:26:19
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14312 steps/s (collection: 6.709s, learning 0.160s)
             Mean action noise std: 2.77
          Mean value_function loss: 72.8462
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 75.3660
                       Mean reward: 226.27
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.1726
    Episode_Reward/rotating_object: 46.6082
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.87s
                      Time elapsed: 00:26:26
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14305 steps/s (collection: 6.724s, learning 0.148s)
             Mean action noise std: 2.77
          Mean value_function loss: 75.6458
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 75.3821
                       Mean reward: 252.33
               Mean episode length: 219.64
    Episode_Reward/reaching_object: 1.1121
    Episode_Reward/rotating_object: 43.8585
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0659
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.87s
                      Time elapsed: 00:26:32
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14759 steps/s (collection: 6.528s, learning 0.132s)
             Mean action noise std: 2.78
          Mean value_function loss: 74.2701
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 75.4029
                       Mean reward: 234.02
               Mean episode length: 222.25
    Episode_Reward/reaching_object: 1.1350
    Episode_Reward/rotating_object: 47.3516
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.66s
                      Time elapsed: 00:26:39
                               ETA: 00:32:48

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14076 steps/s (collection: 6.847s, learning 0.137s)
             Mean action noise std: 2.78
          Mean value_function loss: 73.6209
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 75.4199
                       Mean reward: 238.65
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 1.1664
    Episode_Reward/rotating_object: 46.2821
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.98s
                      Time elapsed: 00:26:46
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14209 steps/s (collection: 6.760s, learning 0.159s)
             Mean action noise std: 2.78
          Mean value_function loss: 75.3841
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 75.4390
                       Mean reward: 219.10
               Mean episode length: 218.94
    Episode_Reward/reaching_object: 1.1278
    Episode_Reward/rotating_object: 39.8787
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.92s
                      Time elapsed: 00:26:53
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 21835 steps/s (collection: 4.356s, learning 0.146s)
             Mean action noise std: 2.78
          Mean value_function loss: 75.2398
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.4578
                       Mean reward: 234.82
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1454
    Episode_Reward/rotating_object: 47.4492
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.50s
                      Time elapsed: 00:26:58
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 49133 steps/s (collection: 1.887s, learning 0.114s)
             Mean action noise std: 2.78
          Mean value_function loss: 68.7682
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 75.4803
                       Mean reward: 224.38
               Mean episode length: 221.67
    Episode_Reward/reaching_object: 1.1302
    Episode_Reward/rotating_object: 44.7450
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.00s
                      Time elapsed: 00:27:00
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 48568 steps/s (collection: 1.888s, learning 0.136s)
             Mean action noise std: 2.79
          Mean value_function loss: 76.6198
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 75.5148
                       Mean reward: 246.89
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.1102
    Episode_Reward/rotating_object: 43.7352
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.02s
                      Time elapsed: 00:27:02
                               ETA: 00:32:48

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 48545 steps/s (collection: 1.893s, learning 0.132s)
             Mean action noise std: 2.79
          Mean value_function loss: 77.8068
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 75.5425
                       Mean reward: 220.87
               Mean episode length: 220.39
    Episode_Reward/reaching_object: 1.1081
    Episode_Reward/rotating_object: 42.7484
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.02s
                      Time elapsed: 00:27:04
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 46944 steps/s (collection: 1.964s, learning 0.130s)
             Mean action noise std: 2.79
          Mean value_function loss: 79.1197
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 75.5710
                       Mean reward: 261.60
               Mean episode length: 221.18
    Episode_Reward/reaching_object: 1.1264
    Episode_Reward/rotating_object: 49.3873
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.09s
                      Time elapsed: 00:27:06
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 47194 steps/s (collection: 1.955s, learning 0.128s)
             Mean action noise std: 2.80
          Mean value_function loss: 73.6473
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 75.5974
                       Mean reward: 220.21
               Mean episode length: 225.01
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 46.0819
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.08s
                      Time elapsed: 00:27:08
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 49918 steps/s (collection: 1.858s, learning 0.112s)
             Mean action noise std: 2.80
          Mean value_function loss: 69.0477
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 75.6218
                       Mean reward: 255.62
               Mean episode length: 224.48
    Episode_Reward/reaching_object: 1.1569
    Episode_Reward/rotating_object: 48.1570
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.97s
                      Time elapsed: 00:27:10
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 48853 steps/s (collection: 1.888s, learning 0.125s)
             Mean action noise std: 2.80
          Mean value_function loss: 72.6204
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 75.6478
                       Mean reward: 235.82
               Mean episode length: 218.62
    Episode_Reward/reaching_object: 1.1195
    Episode_Reward/rotating_object: 43.5821
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.01s
                      Time elapsed: 00:27:12
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 47154 steps/s (collection: 1.953s, learning 0.132s)
             Mean action noise std: 2.80
          Mean value_function loss: 71.5398
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 75.6737
                       Mean reward: 284.45
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.1765
    Episode_Reward/rotating_object: 50.3486
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.08s
                      Time elapsed: 00:27:14
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 47461 steps/s (collection: 1.950s, learning 0.122s)
             Mean action noise std: 2.81
          Mean value_function loss: 66.3603
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 75.6994
                       Mean reward: 235.33
               Mean episode length: 224.05
    Episode_Reward/reaching_object: 1.1441
    Episode_Reward/rotating_object: 45.4746
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.07s
                      Time elapsed: 00:27:16
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 47150 steps/s (collection: 1.955s, learning 0.130s)
             Mean action noise std: 2.81
          Mean value_function loss: 74.9998
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 75.7276
                       Mean reward: 237.47
               Mean episode length: 222.05
    Episode_Reward/reaching_object: 1.1374
    Episode_Reward/rotating_object: 47.0926
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.08s
                      Time elapsed: 00:27:18
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 48124 steps/s (collection: 1.890s, learning 0.152s)
             Mean action noise std: 2.81
          Mean value_function loss: 67.7081
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 75.7526
                       Mean reward: 259.84
               Mean episode length: 222.40
    Episode_Reward/reaching_object: 1.1372
    Episode_Reward/rotating_object: 48.9455
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.04s
                      Time elapsed: 00:27:20
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 46967 steps/s (collection: 1.950s, learning 0.143s)
             Mean action noise std: 2.81
          Mean value_function loss: 67.7842
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 75.7872
                       Mean reward: 271.47
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 1.1360
    Episode_Reward/rotating_object: 48.5394
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.09s
                      Time elapsed: 00:27:22
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 47877 steps/s (collection: 1.904s, learning 0.149s)
             Mean action noise std: 2.82
          Mean value_function loss: 67.0020
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 75.8139
                       Mean reward: 230.03
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.1747
    Episode_Reward/rotating_object: 48.1772
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0710
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.05s
                      Time elapsed: 00:27:24
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 49116 steps/s (collection: 1.881s, learning 0.121s)
             Mean action noise std: 2.82
          Mean value_function loss: 80.1420
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 75.8416
                       Mean reward: 221.52
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.1465
    Episode_Reward/rotating_object: 46.6283
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.00s
                      Time elapsed: 00:27:26
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 47802 steps/s (collection: 1.956s, learning 0.100s)
             Mean action noise std: 2.82
          Mean value_function loss: 83.9262
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 75.8668
                       Mean reward: 215.87
               Mean episode length: 224.36
    Episode_Reward/reaching_object: 1.1564
    Episode_Reward/rotating_object: 45.5128
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.06s
                      Time elapsed: 00:27:28
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 47530 steps/s (collection: 1.930s, learning 0.139s)
             Mean action noise std: 2.82
          Mean value_function loss: 84.2664
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 75.8930
                       Mean reward: 247.30
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.1541
    Episode_Reward/rotating_object: 45.0236
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0710
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.07s
                      Time elapsed: 00:27:30
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 49521 steps/s (collection: 1.881s, learning 0.104s)
             Mean action noise std: 2.83
          Mean value_function loss: 85.2852
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 75.9232
                       Mean reward: 252.95
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.1493
    Episode_Reward/rotating_object: 47.9931
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.99s
                      Time elapsed: 00:27:32
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 49280 steps/s (collection: 1.887s, learning 0.108s)
             Mean action noise std: 2.83
          Mean value_function loss: 103.3788
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 75.9577
                       Mean reward: 246.11
               Mean episode length: 223.74
    Episode_Reward/reaching_object: 1.1491
    Episode_Reward/rotating_object: 45.9101
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.99s
                      Time elapsed: 00:27:34
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 48664 steps/s (collection: 1.876s, learning 0.144s)
             Mean action noise std: 2.83
          Mean value_function loss: 85.7726
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 75.9846
                       Mean reward: 198.70
               Mean episode length: 221.37
    Episode_Reward/reaching_object: 1.1420
    Episode_Reward/rotating_object: 45.4820
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.02s
                      Time elapsed: 00:27:36
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 48083 steps/s (collection: 1.922s, learning 0.122s)
             Mean action noise std: 2.83
          Mean value_function loss: 86.6394
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 76.0073
                       Mean reward: 209.52
               Mean episode length: 222.03
    Episode_Reward/reaching_object: 1.1615
    Episode_Reward/rotating_object: 42.8605
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.04s
                      Time elapsed: 00:27:38
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 47724 steps/s (collection: 1.936s, learning 0.124s)
             Mean action noise std: 2.84
          Mean value_function loss: 80.1754
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 76.0284
                       Mean reward: 220.21
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 1.1497
    Episode_Reward/rotating_object: 44.3414
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0699
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.06s
                      Time elapsed: 00:27:40
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 49145 steps/s (collection: 1.877s, learning 0.124s)
             Mean action noise std: 2.84
          Mean value_function loss: 78.8460
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 76.0496
                       Mean reward: 181.28
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 1.1587
    Episode_Reward/rotating_object: 44.1947
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.00s
                      Time elapsed: 00:27:42
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 45554 steps/s (collection: 2.007s, learning 0.151s)
             Mean action noise std: 2.84
          Mean value_function loss: 78.7661
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 76.0756
                       Mean reward: 238.04
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 1.1689
    Episode_Reward/rotating_object: 46.7996
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0699
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.16s
                      Time elapsed: 00:27:45
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 47209 steps/s (collection: 1.946s, learning 0.137s)
             Mean action noise std: 2.84
          Mean value_function loss: 80.3248
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 76.1052
                       Mean reward: 224.10
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 1.1575
    Episode_Reward/rotating_object: 41.2346
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.08s
                      Time elapsed: 00:27:47
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 47358 steps/s (collection: 1.918s, learning 0.158s)
             Mean action noise std: 2.85
          Mean value_function loss: 74.2138
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 76.1383
                       Mean reward: 240.31
               Mean episode length: 222.41
    Episode_Reward/reaching_object: 1.1442
    Episode_Reward/rotating_object: 48.2838
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.08s
                      Time elapsed: 00:27:49
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 45323 steps/s (collection: 1.988s, learning 0.180s)
             Mean action noise std: 2.85
          Mean value_function loss: 67.4207
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 76.1641
                       Mean reward: 200.79
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 1.1725
    Episode_Reward/rotating_object: 46.0715
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.17s
                      Time elapsed: 00:27:51
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 46332 steps/s (collection: 1.999s, learning 0.123s)
             Mean action noise std: 2.85
          Mean value_function loss: 62.9989
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 76.1944
                       Mean reward: 269.12
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.1899
    Episode_Reward/rotating_object: 48.0447
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0718
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.12s
                      Time elapsed: 00:27:53
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 47278 steps/s (collection: 1.945s, learning 0.134s)
             Mean action noise std: 2.86
          Mean value_function loss: 72.2931
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 76.2287
                       Mean reward: 232.36
               Mean episode length: 230.97
    Episode_Reward/reaching_object: 1.1278
    Episode_Reward/rotating_object: 42.4958
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.08s
                      Time elapsed: 00:27:55
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 48000 steps/s (collection: 1.948s, learning 0.100s)
             Mean action noise std: 2.86
          Mean value_function loss: 78.1186
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 76.2588
                       Mean reward: 240.74
               Mean episode length: 222.49
    Episode_Reward/reaching_object: 1.1514
    Episode_Reward/rotating_object: 44.8268
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.05s
                      Time elapsed: 00:27:57
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 45729 steps/s (collection: 1.967s, learning 0.183s)
             Mean action noise std: 2.86
          Mean value_function loss: 77.9056
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 76.2801
                       Mean reward: 223.78
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.1449
    Episode_Reward/rotating_object: 45.0130
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.15s
                      Time elapsed: 00:27:59
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 48079 steps/s (collection: 1.932s, learning 0.113s)
             Mean action noise std: 2.86
          Mean value_function loss: 67.7940
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 76.3008
                       Mean reward: 259.88
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.1844
    Episode_Reward/rotating_object: 51.0397
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.04s
                      Time elapsed: 00:28:01
                               ETA: 00:31:28

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 46664 steps/s (collection: 1.950s, learning 0.156s)
             Mean action noise std: 2.86
          Mean value_function loss: 71.8506
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 76.3194
                       Mean reward: 238.18
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.1668
    Episode_Reward/rotating_object: 44.7959
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.11s
                      Time elapsed: 00:28:03
                               ETA: 00:31:26

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 45782 steps/s (collection: 2.010s, learning 0.138s)
             Mean action noise std: 2.87
          Mean value_function loss: 71.6777
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 76.3456
                       Mean reward: 258.14
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.1624
    Episode_Reward/rotating_object: 46.4820
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.15s
                      Time elapsed: 00:28:06
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 46354 steps/s (collection: 2.001s, learning 0.120s)
             Mean action noise std: 2.87
          Mean value_function loss: 73.3149
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 76.3793
                       Mean reward: 269.43
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.1492
    Episode_Reward/rotating_object: 44.2690
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.12s
                      Time elapsed: 00:28:08
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 50489 steps/s (collection: 1.805s, learning 0.143s)
             Mean action noise std: 2.87
          Mean value_function loss: 68.9899
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 76.4081
                       Mean reward: 205.85
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.1568
    Episode_Reward/rotating_object: 44.6698
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0699
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.95s
                      Time elapsed: 00:28:10
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 46783 steps/s (collection: 1.929s, learning 0.172s)
             Mean action noise std: 2.87
          Mean value_function loss: 78.5748
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 76.4337
                       Mean reward: 223.58
               Mean episode length: 219.91
    Episode_Reward/reaching_object: 1.1304
    Episode_Reward/rotating_object: 42.8888
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.10s
                      Time elapsed: 00:28:12
                               ETA: 00:31:15

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 46798 steps/s (collection: 1.975s, learning 0.125s)
             Mean action noise std: 2.88
          Mean value_function loss: 77.5329
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 76.4601
                       Mean reward: 243.01
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 43.9399
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.10s
                      Time elapsed: 00:28:14
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 48121 steps/s (collection: 1.918s, learning 0.125s)
             Mean action noise std: 2.88
          Mean value_function loss: 78.7993
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 76.4824
                       Mean reward: 263.26
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.1523
    Episode_Reward/rotating_object: 47.3766
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.04s
                      Time elapsed: 00:28:16
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 45900 steps/s (collection: 1.986s, learning 0.156s)
             Mean action noise std: 2.88
          Mean value_function loss: 79.7834
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 76.5098
                       Mean reward: 242.49
               Mean episode length: 225.41
    Episode_Reward/reaching_object: 1.1459
    Episode_Reward/rotating_object: 44.9622
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.14s
                      Time elapsed: 00:28:18
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 47616 steps/s (collection: 1.908s, learning 0.157s)
             Mean action noise std: 2.88
          Mean value_function loss: 84.8677
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 76.5402
                       Mean reward: 222.89
               Mean episode length: 224.00
    Episode_Reward/reaching_object: 1.1677
    Episode_Reward/rotating_object: 46.0799
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.06s
                      Time elapsed: 00:28:20
                               ETA: 00:31:04

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 48495 steps/s (collection: 1.861s, learning 0.166s)
             Mean action noise std: 2.89
          Mean value_function loss: 76.3478
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.5643
                       Mean reward: 209.22
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 45.1650
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.03s
                      Time elapsed: 00:28:22
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 45840 steps/s (collection: 1.969s, learning 0.175s)
             Mean action noise std: 2.89
          Mean value_function loss: 81.2062
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 76.5844
                       Mean reward: 250.97
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 49.3617
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.14s
                      Time elapsed: 00:28:24
                               ETA: 00:30:59

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 47500 steps/s (collection: 1.918s, learning 0.152s)
             Mean action noise std: 2.89
          Mean value_function loss: 74.8766
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 76.6106
                       Mean reward: 209.67
               Mean episode length: 219.73
    Episode_Reward/reaching_object: 1.1602
    Episode_Reward/rotating_object: 45.1694
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.07s
                      Time elapsed: 00:28:26
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 46258 steps/s (collection: 1.939s, learning 0.186s)
             Mean action noise std: 2.89
          Mean value_function loss: 75.1309
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 76.6438
                       Mean reward: 210.71
               Mean episode length: 219.44
    Episode_Reward/reaching_object: 1.1287
    Episode_Reward/rotating_object: 44.0421
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.13s
                      Time elapsed: 00:28:28
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 47694 steps/s (collection: 1.899s, learning 0.162s)
             Mean action noise std: 2.90
          Mean value_function loss: 76.8030
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 76.6747
                       Mean reward: 234.18
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 46.9128
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.06s
                      Time elapsed: 00:28:31
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 47749 steps/s (collection: 1.936s, learning 0.123s)
             Mean action noise std: 2.90
          Mean value_function loss: 68.2499
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 76.7061
                       Mean reward: 273.12
               Mean episode length: 228.84
    Episode_Reward/reaching_object: 1.1523
    Episode_Reward/rotating_object: 49.5712
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.06s
                      Time elapsed: 00:28:33
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 48122 steps/s (collection: 1.890s, learning 0.153s)
             Mean action noise std: 2.90
          Mean value_function loss: 67.9592
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 76.7383
                       Mean reward: 240.37
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.1682
    Episode_Reward/rotating_object: 48.6868
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0704
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.04s
                      Time elapsed: 00:28:35
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 48613 steps/s (collection: 1.910s, learning 0.112s)
             Mean action noise std: 2.91
          Mean value_function loss: 74.6221
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 76.7725
                       Mean reward: 264.96
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 49.1881
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0726
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.02s
                      Time elapsed: 00:28:37
                               ETA: 00:30:42

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 49633 steps/s (collection: 1.853s, learning 0.128s)
             Mean action noise std: 2.91
          Mean value_function loss: 76.9192
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 76.7947
                       Mean reward: 240.64
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 45.6599
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.98s
                      Time elapsed: 00:28:39
                               ETA: 00:30:40

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 47928 steps/s (collection: 1.916s, learning 0.135s)
             Mean action noise std: 2.91
          Mean value_function loss: 78.3661
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 76.8212
                       Mean reward: 239.13
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 1.1391
    Episode_Reward/rotating_object: 45.5069
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.05s
                      Time elapsed: 00:28:41
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 48413 steps/s (collection: 1.906s, learning 0.124s)
             Mean action noise std: 2.91
          Mean value_function loss: 69.0968
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 76.8426
                       Mean reward: 226.47
               Mean episode length: 215.67
    Episode_Reward/reaching_object: 1.1437
    Episode_Reward/rotating_object: 45.7731
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.03s
                      Time elapsed: 00:28:43
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 45088 steps/s (collection: 2.036s, learning 0.144s)
             Mean action noise std: 2.92
          Mean value_function loss: 76.4309
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 76.8698
                       Mean reward: 205.89
               Mean episode length: 221.19
    Episode_Reward/reaching_object: 1.1510
    Episode_Reward/rotating_object: 46.7923
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.18s
                      Time elapsed: 00:28:45
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 48112 steps/s (collection: 1.908s, learning 0.136s)
             Mean action noise std: 2.92
          Mean value_function loss: 76.4852
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 76.9053
                       Mean reward: 237.20
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 1.1863
    Episode_Reward/rotating_object: 47.7783
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.04s
                      Time elapsed: 00:28:47
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 47907 steps/s (collection: 1.911s, learning 0.141s)
             Mean action noise std: 2.92
          Mean value_function loss: 68.3931
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 76.9385
                       Mean reward: 214.29
               Mean episode length: 228.13
    Episode_Reward/reaching_object: 1.1468
    Episode_Reward/rotating_object: 45.3679
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.05s
                      Time elapsed: 00:28:49
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 45733 steps/s (collection: 1.980s, learning 0.170s)
             Mean action noise std: 2.93
          Mean value_function loss: 80.7025
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 76.9624
                       Mean reward: 247.95
               Mean episode length: 228.11
    Episode_Reward/reaching_object: 1.1377
    Episode_Reward/rotating_object: 44.9901
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.15s
                      Time elapsed: 00:28:51
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 47694 steps/s (collection: 1.899s, learning 0.163s)
             Mean action noise std: 2.93
          Mean value_function loss: 79.8146
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 76.9951
                       Mean reward: 270.25
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 1.1361
    Episode_Reward/rotating_object: 46.3172
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.06s
                      Time elapsed: 00:28:53
                               ETA: 00:30:21

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 43952 steps/s (collection: 2.081s, learning 0.155s)
             Mean action noise std: 2.93
          Mean value_function loss: 93.8532
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 77.0293
                       Mean reward: 193.48
               Mean episode length: 226.33
    Episode_Reward/reaching_object: 1.1441
    Episode_Reward/rotating_object: 42.7813
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.24s
                      Time elapsed: 00:28:55
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 46422 steps/s (collection: 1.978s, learning 0.140s)
             Mean action noise std: 2.93
          Mean value_function loss: 85.3678
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 77.0563
                       Mean reward: 251.77
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 46.4048
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.12s
                      Time elapsed: 00:28:58
                               ETA: 00:30:16

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 44119 steps/s (collection: 2.073s, learning 0.155s)
             Mean action noise std: 2.94
          Mean value_function loss: 83.1217
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 77.0865
                       Mean reward: 260.93
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.1537
    Episode_Reward/rotating_object: 43.3205
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.23s
                      Time elapsed: 00:29:00
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 47162 steps/s (collection: 1.942s, learning 0.142s)
             Mean action noise std: 2.94
          Mean value_function loss: 80.0599
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 77.1091
                       Mean reward: 229.97
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 1.1328
    Episode_Reward/rotating_object: 42.6590
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.08s
                      Time elapsed: 00:29:02
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 45733 steps/s (collection: 2.022s, learning 0.127s)
             Mean action noise std: 2.94
          Mean value_function loss: 74.8587
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 77.1295
                       Mean reward: 235.81
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.1698
    Episode_Reward/rotating_object: 47.0391
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0699
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.15s
                      Time elapsed: 00:29:04
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 48093 steps/s (collection: 1.934s, learning 0.110s)
             Mean action noise std: 2.94
          Mean value_function loss: 76.8781
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 77.1487
                       Mean reward: 214.09
               Mean episode length: 221.08
    Episode_Reward/reaching_object: 1.1561
    Episode_Reward/rotating_object: 45.6372
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.04s
                      Time elapsed: 00:29:06
                               ETA: 00:30:05

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 46163 steps/s (collection: 2.030s, learning 0.099s)
             Mean action noise std: 2.95
          Mean value_function loss: 65.8142
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 77.1869
                       Mean reward: 255.67
               Mean episode length: 226.74
    Episode_Reward/reaching_object: 1.1708
    Episode_Reward/rotating_object: 46.6800
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.13s
                      Time elapsed: 00:29:08
                               ETA: 00:30:03

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 47057 steps/s (collection: 1.916s, learning 0.173s)
             Mean action noise std: 2.95
          Mean value_function loss: 65.4894
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 77.2189
                       Mean reward: 230.69
               Mean episode length: 223.59
    Episode_Reward/reaching_object: 1.1659
    Episode_Reward/rotating_object: 45.2063
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0712
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.09s
                      Time elapsed: 00:29:10
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 45629 steps/s (collection: 1.977s, learning 0.177s)
             Mean action noise std: 2.95
          Mean value_function loss: 70.5076
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 77.2442
                       Mean reward: 231.38
               Mean episode length: 232.64
    Episode_Reward/reaching_object: 1.1725
    Episode_Reward/rotating_object: 45.3907
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.15s
                      Time elapsed: 00:29:12
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 48133 steps/s (collection: 1.872s, learning 0.170s)
             Mean action noise std: 2.96
          Mean value_function loss: 68.0685
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 77.2748
                       Mean reward: 213.96
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 1.1505
    Episode_Reward/rotating_object: 41.9190
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.04s
                      Time elapsed: 00:29:14
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 47522 steps/s (collection: 1.918s, learning 0.151s)
             Mean action noise std: 2.96
          Mean value_function loss: 72.8223
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 77.3083
                       Mean reward: 236.32
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.1738
    Episode_Reward/rotating_object: 46.7795
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.07s
                      Time elapsed: 00:29:17
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 47999 steps/s (collection: 1.916s, learning 0.132s)
             Mean action noise std: 2.96
          Mean value_function loss: 71.7532
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 77.3448
                       Mean reward: 250.63
               Mean episode length: 222.75
    Episode_Reward/reaching_object: 1.1574
    Episode_Reward/rotating_object: 48.1895
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.05s
                      Time elapsed: 00:29:19
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 47162 steps/s (collection: 1.945s, learning 0.140s)
             Mean action noise std: 2.97
          Mean value_function loss: 69.7767
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 77.3823
                       Mean reward: 230.87
               Mean episode length: 227.67
    Episode_Reward/reaching_object: 1.1692
    Episode_Reward/rotating_object: 46.5495
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0744
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.08s
                      Time elapsed: 00:29:21
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 48442 steps/s (collection: 1.935s, learning 0.094s)
             Mean action noise std: 2.97
          Mean value_function loss: 73.3110
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 77.4127
                       Mean reward: 243.72
               Mean episode length: 223.08
    Episode_Reward/reaching_object: 1.1454
    Episode_Reward/rotating_object: 42.4827
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.03s
                      Time elapsed: 00:29:23
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 48462 steps/s (collection: 1.924s, learning 0.104s)
             Mean action noise std: 2.97
          Mean value_function loss: 80.0562
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 77.4396
                       Mean reward: 208.38
               Mean episode length: 218.68
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 45.1168
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0747
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.03s
                      Time elapsed: 00:29:25
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 47171 steps/s (collection: 1.914s, learning 0.170s)
             Mean action noise std: 2.98
          Mean value_function loss: 68.1780
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 77.4721
                       Mean reward: 235.97
               Mean episode length: 225.28
    Episode_Reward/reaching_object: 1.1737
    Episode_Reward/rotating_object: 47.3678
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.08s
                      Time elapsed: 00:29:27
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 47722 steps/s (collection: 1.948s, learning 0.112s)
             Mean action noise std: 2.98
          Mean value_function loss: 78.0521
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 77.5020
                       Mean reward: 201.42
               Mean episode length: 226.07
    Episode_Reward/reaching_object: 1.1662
    Episode_Reward/rotating_object: 42.0481
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0731
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.06s
                      Time elapsed: 00:29:29
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 48145 steps/s (collection: 1.911s, learning 0.131s)
             Mean action noise std: 2.98
          Mean value_function loss: 65.5755
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 77.5284
                       Mean reward: 225.12
               Mean episode length: 220.36
    Episode_Reward/reaching_object: 1.1507
    Episode_Reward/rotating_object: 44.3505
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.04s
                      Time elapsed: 00:29:31
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 47329 steps/s (collection: 1.929s, learning 0.148s)
             Mean action noise std: 2.98
          Mean value_function loss: 78.3371
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 77.5526
                       Mean reward: 258.11
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 1.1706
    Episode_Reward/rotating_object: 48.4242
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.08s
                      Time elapsed: 00:29:33
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 46884 steps/s (collection: 1.935s, learning 0.162s)
             Mean action noise std: 2.99
          Mean value_function loss: 77.7321
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 77.5872
                       Mean reward: 255.22
               Mean episode length: 217.70
    Episode_Reward/reaching_object: 1.1691
    Episode_Reward/rotating_object: 47.1268
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0729
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.10s
                      Time elapsed: 00:29:35
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 46031 steps/s (collection: 2.023s, learning 0.113s)
             Mean action noise std: 2.99
          Mean value_function loss: 80.0449
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 77.6125
                       Mean reward: 249.68
               Mean episode length: 224.87
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 52.5871
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.14s
                      Time elapsed: 00:29:37
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 49264 steps/s (collection: 1.871s, learning 0.124s)
             Mean action noise std: 2.99
          Mean value_function loss: 70.3219
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 77.6359
                       Mean reward: 233.39
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 44.9697
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.00s
                      Time elapsed: 00:29:39
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 45269 steps/s (collection: 1.951s, learning 0.221s)
             Mean action noise std: 2.99
          Mean value_function loss: 65.9949
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 77.6714
                       Mean reward: 236.50
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.1642
    Episode_Reward/rotating_object: 45.4373
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.17s
                      Time elapsed: 00:29:41
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 46881 steps/s (collection: 1.944s, learning 0.153s)
             Mean action noise std: 3.00
          Mean value_function loss: 78.7076
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 77.7039
                       Mean reward: 231.40
               Mean episode length: 229.09
    Episode_Reward/reaching_object: 1.1915
    Episode_Reward/rotating_object: 46.0242
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.10s
                      Time elapsed: 00:29:43
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 46369 steps/s (collection: 1.995s, learning 0.125s)
             Mean action noise std: 3.00
          Mean value_function loss: 76.6470
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 77.7291
                       Mean reward: 231.76
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 1.1428
    Episode_Reward/rotating_object: 42.8720
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.12s
                      Time elapsed: 00:29:46
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 47114 steps/s (collection: 1.972s, learning 0.115s)
             Mean action noise std: 3.00
          Mean value_function loss: 70.9476
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 77.7454
                       Mean reward: 223.76
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 1.2081
    Episode_Reward/rotating_object: 48.6660
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.09s
                      Time elapsed: 00:29:48
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 47565 steps/s (collection: 1.910s, learning 0.157s)
             Mean action noise std: 3.00
          Mean value_function loss: 76.8265
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 77.7665
                       Mean reward: 203.36
               Mean episode length: 221.39
    Episode_Reward/reaching_object: 1.1520
    Episode_Reward/rotating_object: 43.8668
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0712
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.07s
                      Time elapsed: 00:29:50
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 49886 steps/s (collection: 1.872s, learning 0.099s)
             Mean action noise std: 3.01
          Mean value_function loss: 70.2644
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 77.7993
                       Mean reward: 213.70
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 1.1711
    Episode_Reward/rotating_object: 49.8751
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0733
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.97s
                      Time elapsed: 00:29:52
                               ETA: 00:29:07

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 47766 steps/s (collection: 1.950s, learning 0.108s)
             Mean action noise std: 3.01
          Mean value_function loss: 62.7441
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 77.8356
                       Mean reward: 230.30
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.1605
    Episode_Reward/rotating_object: 44.1936
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0716
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.06s
                      Time elapsed: 00:29:54
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 47584 steps/s (collection: 1.956s, learning 0.110s)
             Mean action noise std: 3.01
          Mean value_function loss: 77.1536
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 77.8691
                       Mean reward: 244.29
               Mean episode length: 228.34
    Episode_Reward/reaching_object: 1.1614
    Episode_Reward/rotating_object: 44.9446
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.07s
                      Time elapsed: 00:29:56
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 47542 steps/s (collection: 1.958s, learning 0.110s)
             Mean action noise std: 3.02
          Mean value_function loss: 74.6297
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 77.8915
                       Mean reward: 235.73
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 1.1897
    Episode_Reward/rotating_object: 46.9034
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0747
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.07s
                      Time elapsed: 00:29:58
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 48507 steps/s (collection: 1.911s, learning 0.115s)
             Mean action noise std: 3.02
          Mean value_function loss: 80.2300
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 77.9276
                       Mean reward: 234.26
               Mean episode length: 223.60
    Episode_Reward/reaching_object: 1.1554
    Episode_Reward/rotating_object: 46.2092
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.03s
                      Time elapsed: 00:30:00
                               ETA: 00:28:56

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 48354 steps/s (collection: 1.922s, learning 0.111s)
             Mean action noise std: 3.02
          Mean value_function loss: 79.5073
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 77.9623
                       Mean reward: 238.61
               Mean episode length: 224.69
    Episode_Reward/reaching_object: 1.1659
    Episode_Reward/rotating_object: 47.7949
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.03s
                      Time elapsed: 00:30:02
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 47656 steps/s (collection: 1.915s, learning 0.148s)
             Mean action noise std: 3.03
          Mean value_function loss: 76.9610
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.0035
                       Mean reward: 249.04
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 1.1671
    Episode_Reward/rotating_object: 45.7749
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.06s
                      Time elapsed: 00:30:04
                               ETA: 00:28:51

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 45996 steps/s (collection: 2.000s, learning 0.138s)
             Mean action noise std: 3.03
          Mean value_function loss: 79.2152
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 78.0359
                       Mean reward: 246.54
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.1770
    Episode_Reward/rotating_object: 48.1818
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.14s
                      Time elapsed: 00:30:06
                               ETA: 00:28:48

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 48369 steps/s (collection: 1.918s, learning 0.115s)
             Mean action noise std: 3.03
          Mean value_function loss: 71.2906
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 78.0620
                       Mean reward: 240.94
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 51.3976
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0729
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.03s
                      Time elapsed: 00:30:08
                               ETA: 00:28:46

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 49026 steps/s (collection: 1.872s, learning 0.133s)
             Mean action noise std: 3.04
          Mean value_function loss: 82.0283
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 78.0772
                       Mean reward: 247.56
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 1.1773
    Episode_Reward/rotating_object: 48.3446
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.01s
                      Time elapsed: 00:30:10
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 43841 steps/s (collection: 2.060s, learning 0.182s)
             Mean action noise std: 3.04
          Mean value_function loss: 76.6828
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 78.0963
                       Mean reward: 256.57
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 48.7719
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.24s
                      Time elapsed: 00:30:12
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 48783 steps/s (collection: 1.914s, learning 0.101s)
             Mean action noise std: 3.04
          Mean value_function loss: 69.2472
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 78.1198
                       Mean reward: 215.93
               Mean episode length: 223.12
    Episode_Reward/reaching_object: 1.1654
    Episode_Reward/rotating_object: 47.3643
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0716
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.02s
                      Time elapsed: 00:30:14
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 48560 steps/s (collection: 1.897s, learning 0.127s)
             Mean action noise std: 3.04
          Mean value_function loss: 77.5858
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 78.1515
                       Mean reward: 207.57
               Mean episode length: 225.60
    Episode_Reward/reaching_object: 1.1846
    Episode_Reward/rotating_object: 43.8703
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.02s
                      Time elapsed: 00:30:16
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 49085 steps/s (collection: 1.903s, learning 0.100s)
             Mean action noise std: 3.05
          Mean value_function loss: 79.4963
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 78.1866
                       Mean reward: 249.76
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 1.1858
    Episode_Reward/rotating_object: 47.5632
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0730
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.00s
                      Time elapsed: 00:30:18
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 49230 steps/s (collection: 1.903s, learning 0.094s)
             Mean action noise std: 3.05
          Mean value_function loss: 84.9245
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 78.2160
                       Mean reward: 193.72
               Mean episode length: 221.05
    Episode_Reward/reaching_object: 1.1782
    Episode_Reward/rotating_object: 44.3752
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.00s
                      Time elapsed: 00:30:20
                               ETA: 00:28:30

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 48239 steps/s (collection: 1.926s, learning 0.112s)
             Mean action noise std: 3.05
          Mean value_function loss: 84.1368
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 78.2521
                       Mean reward: 224.80
               Mean episode length: 227.43
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 46.2362
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0726
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.04s
                      Time elapsed: 00:30:23
                               ETA: 00:28:27

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 47733 steps/s (collection: 1.931s, learning 0.128s)
             Mean action noise std: 3.06
          Mean value_function loss: 86.1987
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 78.2815
                       Mean reward: 239.11
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 47.5248
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.06s
                      Time elapsed: 00:30:25
                               ETA: 00:28:25

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 48655 steps/s (collection: 1.870s, learning 0.151s)
             Mean action noise std: 3.06
          Mean value_function loss: 77.2307
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 78.3023
                       Mean reward: 249.82
               Mean episode length: 221.62
    Episode_Reward/reaching_object: 1.1538
    Episode_Reward/rotating_object: 42.6284
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.02s
                      Time elapsed: 00:30:27
                               ETA: 00:28:22

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 47794 steps/s (collection: 1.952s, learning 0.105s)
             Mean action noise std: 3.06
          Mean value_function loss: 88.8873
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 78.3258
                       Mean reward: 235.43
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.1927
    Episode_Reward/rotating_object: 48.2977
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.06s
                      Time elapsed: 00:30:29
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 47784 steps/s (collection: 1.920s, learning 0.138s)
             Mean action noise std: 3.06
          Mean value_function loss: 71.2510
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 78.3441
                       Mean reward: 195.25
               Mean episode length: 225.66
    Episode_Reward/reaching_object: 1.1722
    Episode_Reward/rotating_object: 46.5140
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.06s
                      Time elapsed: 00:30:31
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 47961 steps/s (collection: 1.906s, learning 0.144s)
             Mean action noise std: 3.07
          Mean value_function loss: 74.0792
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 78.3682
                       Mean reward: 233.44
               Mean episode length: 224.67
    Episode_Reward/reaching_object: 1.1661
    Episode_Reward/rotating_object: 45.7096
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.05s
                      Time elapsed: 00:30:33
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 46167 steps/s (collection: 1.972s, learning 0.158s)
             Mean action noise std: 3.07
          Mean value_function loss: 80.1245
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 78.4054
                       Mean reward: 225.15
               Mean episode length: 226.14
    Episode_Reward/reaching_object: 1.1607
    Episode_Reward/rotating_object: 44.4537
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.13s
                      Time elapsed: 00:30:35
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 48798 steps/s (collection: 1.922s, learning 0.093s)
             Mean action noise std: 3.07
          Mean value_function loss: 81.5134
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 78.4437
                       Mean reward: 230.15
               Mean episode length: 227.31
    Episode_Reward/reaching_object: 1.1600
    Episode_Reward/rotating_object: 46.2345
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.01s
                      Time elapsed: 00:30:37
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 49942 steps/s (collection: 1.857s, learning 0.111s)
             Mean action noise std: 3.08
          Mean value_function loss: 85.1693
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 78.4718
                       Mean reward: 251.98
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 1.1651
    Episode_Reward/rotating_object: 45.6175
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0712
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.97s
                      Time elapsed: 00:30:39
                               ETA: 00:28:06

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 47518 steps/s (collection: 1.942s, learning 0.127s)
             Mean action noise std: 3.08
          Mean value_function loss: 75.5111
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 78.5070
                       Mean reward: 237.32
               Mean episode length: 219.64
    Episode_Reward/reaching_object: 1.1416
    Episode_Reward/rotating_object: 43.2127
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.07s
                      Time elapsed: 00:30:41
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 49263 steps/s (collection: 1.863s, learning 0.133s)
             Mean action noise std: 3.08
          Mean value_function loss: 72.2252
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 78.5360
                       Mean reward: 224.42
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.1390
    Episode_Reward/rotating_object: 45.0017
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0701
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.00s
                      Time elapsed: 00:30:43
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 45975 steps/s (collection: 2.010s, learning 0.128s)
             Mean action noise std: 3.08
          Mean value_function loss: 81.1716
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 78.5619
                       Mean reward: 247.60
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 46.6601
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0736
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.14s
                      Time elapsed: 00:30:45
                               ETA: 00:27:58

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 48834 steps/s (collection: 1.886s, learning 0.127s)
             Mean action noise std: 3.09
          Mean value_function loss: 77.5369
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 78.5882
                       Mean reward: 241.39
               Mean episode length: 220.10
    Episode_Reward/reaching_object: 1.1541
    Episode_Reward/rotating_object: 46.9769
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.01s
                      Time elapsed: 00:30:47
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 49179 steps/s (collection: 1.903s, learning 0.096s)
             Mean action noise std: 3.09
          Mean value_function loss: 78.9629
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 78.6154
                       Mean reward: 221.37
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 1.1498
    Episode_Reward/rotating_object: 47.0305
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0712
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.00s
                      Time elapsed: 00:30:49
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 48409 steps/s (collection: 1.913s, learning 0.118s)
             Mean action noise std: 3.09
          Mean value_function loss: 83.4110
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 78.6383
                       Mean reward: 219.63
               Mean episode length: 221.78
    Episode_Reward/reaching_object: 1.1606
    Episode_Reward/rotating_object: 45.5572
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.03s
                      Time elapsed: 00:30:51
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 48153 steps/s (collection: 1.909s, learning 0.133s)
             Mean action noise std: 3.10
          Mean value_function loss: 73.1080
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 78.6741
                       Mean reward: 231.39
               Mean episode length: 228.26
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 49.1202
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0733
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.04s
                      Time elapsed: 00:30:53
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 47153 steps/s (collection: 1.979s, learning 0.106s)
             Mean action noise std: 3.10
          Mean value_function loss: 83.4229
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 78.7057
                       Mean reward: 226.86
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 1.1825
    Episode_Reward/rotating_object: 47.5447
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0717
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.08s
                      Time elapsed: 00:30:55
                               ETA: 00:27:45

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 48017 steps/s (collection: 1.946s, learning 0.101s)
             Mean action noise std: 3.10
          Mean value_function loss: 75.1683
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 78.7349
                       Mean reward: 223.64
               Mean episode length: 226.66
    Episode_Reward/reaching_object: 1.1813
    Episode_Reward/rotating_object: 46.4268
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.05s
                      Time elapsed: 00:30:57
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 48281 steps/s (collection: 1.912s, learning 0.124s)
             Mean action noise std: 3.11
          Mean value_function loss: 92.4212
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 78.7826
                       Mean reward: 240.67
               Mean episode length: 225.99
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 47.6257
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.04s
                      Time elapsed: 00:30:59
                               ETA: 00:27:40

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 46483 steps/s (collection: 1.969s, learning 0.146s)
             Mean action noise std: 3.11
          Mean value_function loss: 78.3227
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.8215
                       Mean reward: 258.25
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 46.8355
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0731
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.11s
                      Time elapsed: 00:31:01
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 46877 steps/s (collection: 1.976s, learning 0.121s)
             Mean action noise std: 3.12
          Mean value_function loss: 77.9429
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 78.8570
                       Mean reward: 208.76
               Mean episode length: 215.40
    Episode_Reward/reaching_object: 1.1498
    Episode_Reward/rotating_object: 46.5213
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0716
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.10s
                      Time elapsed: 00:31:04
                               ETA: 00:27:35

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 48966 steps/s (collection: 1.888s, learning 0.120s)
             Mean action noise std: 3.12
          Mean value_function loss: 78.6429
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 78.8834
                       Mean reward: 299.31
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 1.1568
    Episode_Reward/rotating_object: 46.9806
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.01s
                      Time elapsed: 00:31:06
                               ETA: 00:27:32

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 49012 steps/s (collection: 1.912s, learning 0.094s)
             Mean action noise std: 3.12
          Mean value_function loss: 73.4356
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 78.9183
                       Mean reward: 229.15
               Mean episode length: 225.73
    Episode_Reward/reaching_object: 1.1558
    Episode_Reward/rotating_object: 45.3985
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0717
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.01s
                      Time elapsed: 00:31:08
                               ETA: 00:27:30

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 45983 steps/s (collection: 1.925s, learning 0.213s)
             Mean action noise std: 3.13
          Mean value_function loss: 71.4579
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 78.9573
                       Mean reward: 220.10
               Mean episode length: 221.52
    Episode_Reward/reaching_object: 1.1544
    Episode_Reward/rotating_object: 44.6252
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0726
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.14s
                      Time elapsed: 00:31:10
                               ETA: 00:27:27

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 45091 steps/s (collection: 2.015s, learning 0.165s)
             Mean action noise std: 3.13
          Mean value_function loss: 70.4525
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 78.9957
                       Mean reward: 207.10
               Mean episode length: 219.18
    Episode_Reward/reaching_object: 1.1115
    Episode_Reward/rotating_object: 45.7741
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0713
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.18s
                      Time elapsed: 00:31:12
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 46853 steps/s (collection: 1.919s, learning 0.179s)
             Mean action noise std: 3.13
          Mean value_function loss: 74.7649
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 79.0273
                       Mean reward: 292.71
               Mean episode length: 236.26
    Episode_Reward/reaching_object: 1.1428
    Episode_Reward/rotating_object: 50.2410
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0714
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.10s
                      Time elapsed: 00:31:14
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 49135 steps/s (collection: 1.905s, learning 0.096s)
             Mean action noise std: 3.13
          Mean value_function loss: 77.4947
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 79.0424
                       Mean reward: 257.13
               Mean episode length: 226.72
    Episode_Reward/reaching_object: 1.1485
    Episode_Reward/rotating_object: 48.7369
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.00s
                      Time elapsed: 00:31:16
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 46232 steps/s (collection: 1.999s, learning 0.127s)
             Mean action noise std: 3.14
          Mean value_function loss: 71.9926
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 79.0635
                       Mean reward: 238.43
               Mean episode length: 230.51
    Episode_Reward/reaching_object: 1.1651
    Episode_Reward/rotating_object: 47.8025
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.13s
                      Time elapsed: 00:31:18
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 47442 steps/s (collection: 1.946s, learning 0.127s)
             Mean action noise std: 3.14
          Mean value_function loss: 79.2530
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 79.0924
                       Mean reward: 225.65
               Mean episode length: 215.22
    Episode_Reward/reaching_object: 1.1229
    Episode_Reward/rotating_object: 45.5154
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.07s
                      Time elapsed: 00:31:20
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 47724 steps/s (collection: 1.936s, learning 0.124s)
             Mean action noise std: 3.14
          Mean value_function loss: 660.7965
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 79.1100
                       Mean reward: 241.20
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 1.1781
    Episode_Reward/rotating_object: 47.0867
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.06s
                      Time elapsed: 00:31:22
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 48396 steps/s (collection: 1.917s, learning 0.114s)
             Mean action noise std: 3.14
          Mean value_function loss: 483554140094464.0000
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 79.1128
                       Mean reward: 251.97
               Mean episode length: 223.65
    Episode_Reward/reaching_object: 1.1458
    Episode_Reward/rotating_object: 44.2595
        Episode_Reward/action_rate: -4340.9468
          Episode_Reward/joint_vel: -2095459.8750
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.03s
                      Time elapsed: 00:31:24
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 48516 steps/s (collection: 1.913s, learning 0.113s)
             Mean action noise std: 3.14
          Mean value_function loss: 70.1836
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 79.1214
                       Mean reward: 241.59
               Mean episode length: 201.09
    Episode_Reward/reaching_object: 1.1316
    Episode_Reward/rotating_object: 46.8713
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.03s
                      Time elapsed: 00:31:26
                               ETA: 00:27:06

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 48891 steps/s (collection: 1.906s, learning 0.105s)
             Mean action noise std: 3.15
          Mean value_function loss: 77.3592
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 79.1447
                       Mean reward: 256.57
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 1.1598
    Episode_Reward/rotating_object: 46.6561
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.01s
                      Time elapsed: 00:31:28
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 47408 steps/s (collection: 1.924s, learning 0.150s)
             Mean action noise std: 3.15
          Mean value_function loss: 68.1437
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 79.1783
                       Mean reward: 307.85
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.1699
    Episode_Reward/rotating_object: 50.1784
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.07s
                      Time elapsed: 00:31:30
                               ETA: 00:27:01

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 47954 steps/s (collection: 1.927s, learning 0.123s)
             Mean action noise std: 3.15
          Mean value_function loss: 79.6880
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 79.2104
                       Mean reward: 237.16
               Mean episode length: 222.89
    Episode_Reward/reaching_object: 1.1601
    Episode_Reward/rotating_object: 49.4568
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.05s
                      Time elapsed: 00:31:32
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 48355 steps/s (collection: 1.901s, learning 0.132s)
             Mean action noise std: 3.15
          Mean value_function loss: 81.1452
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 79.2327
                       Mean reward: 233.48
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.1858
    Episode_Reward/rotating_object: 48.8878
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.03s
                      Time elapsed: 00:31:34
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 46818 steps/s (collection: 1.984s, learning 0.116s)
             Mean action noise std: 3.16
          Mean value_function loss: 73.8847
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 79.2646
                       Mean reward: 245.93
               Mean episode length: 217.94
    Episode_Reward/reaching_object: 1.1440
    Episode_Reward/rotating_object: 48.2579
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0760
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.10s
                      Time elapsed: 00:31:37
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 48813 steps/s (collection: 1.868s, learning 0.146s)
             Mean action noise std: 3.16
          Mean value_function loss: 72.3559
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 79.3018
                       Mean reward: 261.91
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.1772
    Episode_Reward/rotating_object: 51.2209
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.01s
                      Time elapsed: 00:31:39
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 47569 steps/s (collection: 1.940s, learning 0.127s)
             Mean action noise std: 3.16
          Mean value_function loss: 79.8890
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 79.3235
                       Mean reward: 250.24
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.1650
    Episode_Reward/rotating_object: 48.2585
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0752
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.07s
                      Time elapsed: 00:31:41
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 45594 steps/s (collection: 2.012s, learning 0.144s)
             Mean action noise std: 3.17
          Mean value_function loss: 73.4924
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 79.3520
                       Mean reward: 233.71
               Mean episode length: 228.21
    Episode_Reward/reaching_object: 1.1683
    Episode_Reward/rotating_object: 45.8473
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0740
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.16s
                      Time elapsed: 00:31:43
                               ETA: 00:26:46

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 42090 steps/s (collection: 2.216s, learning 0.120s)
             Mean action noise std: 3.17
          Mean value_function loss: 75.8344
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.3804
                       Mean reward: 222.01
               Mean episode length: 217.93
    Episode_Reward/reaching_object: 1.1483
    Episode_Reward/rotating_object: 48.8931
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.34s
                      Time elapsed: 00:31:45
                               ETA: 00:26:44

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 40482 steps/s (collection: 2.296s, learning 0.132s)
             Mean action noise std: 3.17
          Mean value_function loss: 76.2642
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 79.4060
                       Mean reward: 258.08
               Mean episode length: 219.38
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 51.5808
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.43s
                      Time elapsed: 00:31:48
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 45151 steps/s (collection: 1.999s, learning 0.179s)
             Mean action noise std: 3.18
          Mean value_function loss: 74.3800
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 79.4337
                       Mean reward: 260.12
               Mean episode length: 211.33
    Episode_Reward/reaching_object: 1.1617
    Episode_Reward/rotating_object: 49.4338
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0733
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.18s
                      Time elapsed: 00:31:50
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 49031 steps/s (collection: 1.898s, learning 0.107s)
             Mean action noise std: 3.18
          Mean value_function loss: 68.1267
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 79.4631
                       Mean reward: 247.67
               Mean episode length: 218.23
    Episode_Reward/reaching_object: 1.1616
    Episode_Reward/rotating_object: 50.9515
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.00s
                      Time elapsed: 00:31:52
                               ETA: 00:26:36

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 46206 steps/s (collection: 1.994s, learning 0.134s)
             Mean action noise std: 3.18
          Mean value_function loss: 68.0562
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 79.4922
                       Mean reward: 230.44
               Mean episode length: 226.13
    Episode_Reward/reaching_object: 1.1537
    Episode_Reward/rotating_object: 49.3886
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0738
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.13s
                      Time elapsed: 00:31:54
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 47922 steps/s (collection: 1.904s, learning 0.148s)
             Mean action noise std: 3.19
          Mean value_function loss: 64.8488
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 79.5164
                       Mean reward: 236.26
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.1567
    Episode_Reward/rotating_object: 51.3796
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0737
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.05s
                      Time elapsed: 00:31:56
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 48144 steps/s (collection: 1.899s, learning 0.143s)
             Mean action noise std: 3.19
          Mean value_function loss: 69.5992
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 79.5543
                       Mean reward: 291.36
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.1757
    Episode_Reward/rotating_object: 52.1269
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.04s
                      Time elapsed: 00:31:58
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 45205 steps/s (collection: 2.009s, learning 0.166s)
             Mean action noise std: 3.19
          Mean value_function loss: 78.3349
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 79.5837
                       Mean reward: 255.25
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.1881
    Episode_Reward/rotating_object: 51.8755
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0784
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.17s
                      Time elapsed: 00:32:00
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 47494 steps/s (collection: 1.923s, learning 0.147s)
             Mean action noise std: 3.20
          Mean value_function loss: 72.4002
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 79.6120
                       Mean reward: 208.40
               Mean episode length: 217.25
    Episode_Reward/reaching_object: 1.1321
    Episode_Reward/rotating_object: 45.5077
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0742
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.07s
                      Time elapsed: 00:32:02
                               ETA: 00:26:23

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 48163 steps/s (collection: 1.928s, learning 0.113s)
             Mean action noise std: 3.20
          Mean value_function loss: 82.8585
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 79.6398
                       Mean reward: 212.52
               Mean episode length: 214.31
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 47.6134
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0742
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.04s
                      Time elapsed: 00:32:04
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 45375 steps/s (collection: 2.053s, learning 0.113s)
             Mean action noise std: 3.20
          Mean value_function loss: 78.4069
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 79.6599
                       Mean reward: 283.30
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 1.1755
    Episode_Reward/rotating_object: 50.1814
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0784
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.17s
                      Time elapsed: 00:32:06
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 49189 steps/s (collection: 1.881s, learning 0.118s)
             Mean action noise std: 3.20
          Mean value_function loss: 82.0542
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 79.6794
                       Mean reward: 248.91
               Mean episode length: 214.93
    Episode_Reward/reaching_object: 1.1584
    Episode_Reward/rotating_object: 50.7082
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.00s
                      Time elapsed: 00:32:08
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 46326 steps/s (collection: 1.993s, learning 0.129s)
             Mean action noise std: 3.20
          Mean value_function loss: 71.5618
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 79.7014
                       Mean reward: 246.21
               Mean episode length: 225.67
    Episode_Reward/reaching_object: 1.1869
    Episode_Reward/rotating_object: 50.5947
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0796
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.12s
                      Time elapsed: 00:32:11
                               ETA: 00:26:13

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 45807 steps/s (collection: 1.982s, learning 0.164s)
             Mean action noise std: 3.21
          Mean value_function loss: 78.1100
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 79.7237
                       Mean reward: 279.70
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 50.0044
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0804
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.15s
                      Time elapsed: 00:32:13
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 47499 steps/s (collection: 1.951s, learning 0.119s)
             Mean action noise std: 3.21
          Mean value_function loss: 78.7093
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 79.7683
                       Mean reward: 286.41
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 49.0029
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0820
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.07s
                      Time elapsed: 00:32:15
                               ETA: 00:26:08

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 46105 steps/s (collection: 1.985s, learning 0.148s)
             Mean action noise std: 3.22
          Mean value_function loss: 72.2590
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 79.8017
                       Mean reward: 264.89
               Mean episode length: 218.67
    Episode_Reward/reaching_object: 1.1557
    Episode_Reward/rotating_object: 49.6461
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.13s
                      Time elapsed: 00:32:17
                               ETA: 00:26:06

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 46305 steps/s (collection: 1.967s, learning 0.156s)
             Mean action noise std: 3.22
          Mean value_function loss: 78.0587
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 79.8269
                       Mean reward: 250.48
               Mean episode length: 221.61
    Episode_Reward/reaching_object: 1.1800
    Episode_Reward/rotating_object: 51.4432
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0801
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.12s
                      Time elapsed: 00:32:19
                               ETA: 00:26:03

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 47953 steps/s (collection: 1.934s, learning 0.116s)
             Mean action noise std: 3.22
          Mean value_function loss: 87.1434
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 79.8385
                       Mean reward: 248.40
               Mean episode length: 218.31
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 53.2161
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.05s
                      Time elapsed: 00:32:21
                               ETA: 00:26:01

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 44344 steps/s (collection: 2.073s, learning 0.144s)
             Mean action noise std: 3.22
          Mean value_function loss: 84.9772
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 79.8598
                       Mean reward: 275.09
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 52.2312
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0809
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.22s
                      Time elapsed: 00:32:23
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 46825 steps/s (collection: 1.973s, learning 0.126s)
             Mean action noise std: 3.22
          Mean value_function loss: 92.3272
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 79.8804
                       Mean reward: 246.28
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.2041
    Episode_Reward/rotating_object: 50.1703
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0816
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.10s
                      Time elapsed: 00:32:25
                               ETA: 00:25:56

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 46807 steps/s (collection: 1.975s, learning 0.125s)
             Mean action noise std: 3.23
          Mean value_function loss: 89.0857
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.9066
                       Mean reward: 257.95
               Mean episode length: 222.00
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 51.8221
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.10s
                      Time elapsed: 00:32:27
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 48024 steps/s (collection: 1.939s, learning 0.108s)
             Mean action noise std: 3.23
          Mean value_function loss: 95.1464
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.9366
                       Mean reward: 255.11
               Mean episode length: 226.94
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 49.3064
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.05s
                      Time elapsed: 00:32:30
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 46474 steps/s (collection: 1.989s, learning 0.126s)
             Mean action noise std: 3.23
          Mean value_function loss: 97.3567
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.9621
                       Mean reward: 243.99
               Mean episode length: 225.87
    Episode_Reward/reaching_object: 1.1814
    Episode_Reward/rotating_object: 50.3339
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.12s
                      Time elapsed: 00:32:32
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 46410 steps/s (collection: 1.980s, learning 0.138s)
             Mean action noise std: 3.23
          Mean value_function loss: 77.8024
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 79.9791
                       Mean reward: 272.85
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.2071
    Episode_Reward/rotating_object: 52.9167
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0810
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.12s
                      Time elapsed: 00:32:34
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 46953 steps/s (collection: 1.973s, learning 0.121s)
             Mean action noise std: 3.24
          Mean value_function loss: 75.5439
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 79.9964
                       Mean reward: 257.00
               Mean episode length: 223.05
    Episode_Reward/reaching_object: 1.1916
    Episode_Reward/rotating_object: 50.3133
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0795
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.09s
                      Time elapsed: 00:32:36
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 47205 steps/s (collection: 1.911s, learning 0.171s)
             Mean action noise std: 3.24
          Mean value_function loss: 81.5510
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 80.0227
                       Mean reward: 243.29
               Mean episode length: 224.25
    Episode_Reward/reaching_object: 1.1848
    Episode_Reward/rotating_object: 49.5996
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0814
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.08s
                      Time elapsed: 00:32:38
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 47658 steps/s (collection: 1.941s, learning 0.122s)
             Mean action noise std: 3.24
          Mean value_function loss: 82.7750
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 80.0492
                       Mean reward: 274.86
               Mean episode length: 223.67
    Episode_Reward/reaching_object: 1.1690
    Episode_Reward/rotating_object: 50.2023
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0826
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.06s
                      Time elapsed: 00:32:40
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 45893 steps/s (collection: 1.957s, learning 0.185s)
             Mean action noise std: 3.25
          Mean value_function loss: 86.0376
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 80.0771
                       Mean reward: 253.25
               Mean episode length: 222.46
    Episode_Reward/reaching_object: 1.1710
    Episode_Reward/rotating_object: 49.5284
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0805
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.14s
                      Time elapsed: 00:32:42
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 46990 steps/s (collection: 1.963s, learning 0.129s)
             Mean action noise std: 3.25
          Mean value_function loss: 77.6525
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 80.1024
                       Mean reward: 275.56
               Mean episode length: 227.44
    Episode_Reward/reaching_object: 1.1807
    Episode_Reward/rotating_object: 50.3187
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.09s
                      Time elapsed: 00:32:44
                               ETA: 00:25:33

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 47465 steps/s (collection: 1.918s, learning 0.153s)
             Mean action noise std: 3.25
          Mean value_function loss: 80.8836
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 80.1289
                       Mean reward: 278.46
               Mean episode length: 224.31
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 52.2995
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0796
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.07s
                      Time elapsed: 00:32:46
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 46307 steps/s (collection: 2.017s, learning 0.106s)
             Mean action noise std: 3.25
          Mean value_function loss: 73.9251
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 80.1514
                       Mean reward: 253.55
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 48.4053
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0796
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.12s
                      Time elapsed: 00:32:48
                               ETA: 00:25:28

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 48154 steps/s (collection: 1.940s, learning 0.102s)
             Mean action noise std: 3.26
          Mean value_function loss: 79.7005
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 80.1743
                       Mean reward: 225.57
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.1910
    Episode_Reward/rotating_object: 52.7289
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0806
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.04s
                      Time elapsed: 00:32:50
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 49343 steps/s (collection: 1.898s, learning 0.095s)
             Mean action noise std: 3.26
          Mean value_function loss: 84.5160
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 80.2028
                       Mean reward: 205.66
               Mean episode length: 219.83
    Episode_Reward/reaching_object: 1.1552
    Episode_Reward/rotating_object: 49.0981
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.99s
                      Time elapsed: 00:32:52
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 48085 steps/s (collection: 1.930s, learning 0.114s)
             Mean action noise std: 3.26
          Mean value_function loss: 85.7680
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 80.2320
                       Mean reward: 272.49
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 53.6186
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.04s
                      Time elapsed: 00:32:54
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 47820 steps/s (collection: 1.952s, learning 0.104s)
             Mean action noise std: 3.27
          Mean value_function loss: 86.6655
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 80.2619
                       Mean reward: 245.42
               Mean episode length: 219.77
    Episode_Reward/reaching_object: 1.1351
    Episode_Reward/rotating_object: 50.0088
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.06s
                      Time elapsed: 00:32:57
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 49674 steps/s (collection: 1.879s, learning 0.100s)
             Mean action noise std: 3.27
          Mean value_function loss: 80.6085
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 80.2826
                       Mean reward: 248.25
               Mean episode length: 215.65
    Episode_Reward/reaching_object: 1.1553
    Episode_Reward/rotating_object: 49.8693
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.98s
                      Time elapsed: 00:32:59
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 47091 steps/s (collection: 1.956s, learning 0.131s)
             Mean action noise std: 3.27
          Mean value_function loss: 77.3733
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 80.3011
                       Mean reward: 258.70
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 1.1769
    Episode_Reward/rotating_object: 51.2512
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0773
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.09s
                      Time elapsed: 00:33:01
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 48444 steps/s (collection: 1.931s, learning 0.098s)
             Mean action noise std: 3.27
          Mean value_function loss: 76.2040
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 80.3307
                       Mean reward: 280.84
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 1.1993
    Episode_Reward/rotating_object: 51.4207
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0788
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.03s
                      Time elapsed: 00:33:03
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 46422 steps/s (collection: 2.023s, learning 0.095s)
             Mean action noise std: 3.28
          Mean value_function loss: 78.4904
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 80.3593
                       Mean reward: 229.66
               Mean episode length: 227.20
    Episode_Reward/reaching_object: 1.1845
    Episode_Reward/rotating_object: 49.8291
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.12s
                      Time elapsed: 00:33:05
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 46834 steps/s (collection: 2.000s, learning 0.099s)
             Mean action noise std: 3.28
          Mean value_function loss: 74.8907
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 80.3862
                       Mean reward: 236.13
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.1741
    Episode_Reward/rotating_object: 47.3542
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.10s
                      Time elapsed: 00:33:07
                               ETA: 00:25:05

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 47706 steps/s (collection: 1.945s, learning 0.116s)
             Mean action noise std: 3.28
          Mean value_function loss: 71.7791
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 80.4127
                       Mean reward: 290.93
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.1551
    Episode_Reward/rotating_object: 46.5033
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0770
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.06s
                      Time elapsed: 00:33:09
                               ETA: 00:25:03

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 47222 steps/s (collection: 1.944s, learning 0.138s)
             Mean action noise std: 3.29
          Mean value_function loss: 81.2658
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 80.4424
                       Mean reward: 267.67
               Mean episode length: 224.79
    Episode_Reward/reaching_object: 1.1770
    Episode_Reward/rotating_object: 53.3389
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0764
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.08s
                      Time elapsed: 00:33:11
                               ETA: 00:25:00

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 47427 steps/s (collection: 1.928s, learning 0.145s)
             Mean action noise std: 3.29
          Mean value_function loss: 95.0728
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 80.4670
                       Mean reward: 241.19
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 1.1687
    Episode_Reward/rotating_object: 48.0724
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0761
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.07s
                      Time elapsed: 00:33:13
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 48502 steps/s (collection: 1.898s, learning 0.129s)
             Mean action noise std: 3.29
          Mean value_function loss: 88.4620
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 80.4938
                       Mean reward: 246.93
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 1.1737
    Episode_Reward/rotating_object: 48.5529
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.03s
                      Time elapsed: 00:33:15
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 46573 steps/s (collection: 1.932s, learning 0.178s)
             Mean action noise std: 3.29
          Mean value_function loss: 87.1750
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 80.5171
                       Mean reward: 216.06
               Mean episode length: 218.49
    Episode_Reward/reaching_object: 1.1663
    Episode_Reward/rotating_object: 46.3517
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.11s
                      Time elapsed: 00:33:17
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 45441 steps/s (collection: 1.995s, learning 0.169s)
             Mean action noise std: 3.30
          Mean value_function loss: 81.1003
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 80.5315
                       Mean reward: 281.66
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 50.4939
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.16s
                      Time elapsed: 00:33:19
                               ETA: 00:24:50

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 46610 steps/s (collection: 1.996s, learning 0.113s)
             Mean action noise std: 3.30
          Mean value_function loss: 75.6154
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 80.5614
                       Mean reward: 243.99
               Mean episode length: 222.90
    Episode_Reward/reaching_object: 1.1955
    Episode_Reward/rotating_object: 51.1388
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.11s
                      Time elapsed: 00:33:21
                               ETA: 00:24:48

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 45737 steps/s (collection: 1.997s, learning 0.153s)
             Mean action noise std: 3.30
          Mean value_function loss: 85.1023
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 80.5863
                       Mean reward: 272.00
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 49.1193
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0780
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.15s
                      Time elapsed: 00:33:24
                               ETA: 00:24:45

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 47035 steps/s (collection: 1.950s, learning 0.140s)
             Mean action noise std: 3.31
          Mean value_function loss: 76.5968
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 80.6110
                       Mean reward: 258.14
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 1.1688
    Episode_Reward/rotating_object: 47.1231
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.09s
                      Time elapsed: 00:33:26
                               ETA: 00:24:43

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 47690 steps/s (collection: 1.935s, learning 0.126s)
             Mean action noise std: 3.31
          Mean value_function loss: 74.2032
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 80.6385
                       Mean reward: 250.41
               Mean episode length: 222.72
    Episode_Reward/reaching_object: 1.1832
    Episode_Reward/rotating_object: 49.7083
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.06s
                      Time elapsed: 00:33:28
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 47507 steps/s (collection: 1.954s, learning 0.115s)
             Mean action noise std: 3.31
          Mean value_function loss: 68.0464
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 80.6520
                       Mean reward: 248.50
               Mean episode length: 230.92
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 51.7169
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.07s
                      Time elapsed: 00:33:30
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 47673 steps/s (collection: 1.927s, learning 0.135s)
             Mean action noise std: 3.31
          Mean value_function loss: 69.0174
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 80.6727
                       Mean reward: 302.18
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.1698
    Episode_Reward/rotating_object: 50.8605
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.06s
                      Time elapsed: 00:33:32
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 46640 steps/s (collection: 1.964s, learning 0.144s)
             Mean action noise std: 3.31
          Mean value_function loss: 80.4383
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 80.6992
                       Mean reward: 290.66
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 1.1755
    Episode_Reward/rotating_object: 48.6399
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.11s
                      Time elapsed: 00:33:34
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 48923 steps/s (collection: 1.913s, learning 0.097s)
             Mean action noise std: 3.32
          Mean value_function loss: 83.4594
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 80.7247
                       Mean reward: 241.74
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.1775
    Episode_Reward/rotating_object: 51.0753
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0788
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.01s
                      Time elapsed: 00:33:36
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 49703 steps/s (collection: 1.855s, learning 0.123s)
             Mean action noise std: 3.32
          Mean value_function loss: 80.6495
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 80.7639
                       Mean reward: 255.46
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 49.8600
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.98s
                      Time elapsed: 00:33:38
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 46074 steps/s (collection: 1.984s, learning 0.150s)
             Mean action noise std: 3.33
          Mean value_function loss: 89.4737
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 80.7936
                       Mean reward: 228.79
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.1699
    Episode_Reward/rotating_object: 45.0134
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0786
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.13s
                      Time elapsed: 00:33:40
                               ETA: 00:24:25

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 45932 steps/s (collection: 1.995s, learning 0.146s)
             Mean action noise std: 3.33
          Mean value_function loss: 84.0712
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 80.8295
                       Mean reward: 271.92
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 50.2276
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.14s
                      Time elapsed: 00:33:42
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 48223 steps/s (collection: 1.936s, learning 0.103s)
             Mean action noise std: 3.33
          Mean value_function loss: 85.3666
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 80.8569
                       Mean reward: 253.49
               Mean episode length: 221.62
    Episode_Reward/reaching_object: 1.1753
    Episode_Reward/rotating_object: 47.6180
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0786
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.04s
                      Time elapsed: 00:33:44
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 46743 steps/s (collection: 1.956s, learning 0.147s)
             Mean action noise std: 3.34
          Mean value_function loss: 93.6697
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 80.8918
                       Mean reward: 239.25
               Mean episode length: 214.62
    Episode_Reward/reaching_object: 1.1586
    Episode_Reward/rotating_object: 48.2895
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.10s
                      Time elapsed: 00:33:46
                               ETA: 00:24:18

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 47933 steps/s (collection: 1.872s, learning 0.179s)
             Mean action noise std: 3.34
          Mean value_function loss: 85.2017
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 80.9362
                       Mean reward: 271.02
               Mean episode length: 226.46
    Episode_Reward/reaching_object: 1.2130
    Episode_Reward/rotating_object: 54.9718
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.05s
                      Time elapsed: 00:33:48
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 47336 steps/s (collection: 1.956s, learning 0.121s)
             Mean action noise std: 3.34
          Mean value_function loss: 99.2682
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 80.9660
                       Mean reward: 273.44
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 52.5005
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0827
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.08s
                      Time elapsed: 00:33:51
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 45918 steps/s (collection: 2.013s, learning 0.128s)
             Mean action noise std: 3.35
          Mean value_function loss: 89.9210
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 80.9875
                       Mean reward: 282.44
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 1.1928
    Episode_Reward/rotating_object: 52.0131
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0809
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.14s
                      Time elapsed: 00:33:53
                               ETA: 00:24:10

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 46662 steps/s (collection: 1.983s, learning 0.124s)
             Mean action noise std: 3.35
          Mean value_function loss: 85.4663
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 81.0041
                       Mean reward: 254.06
               Mean episode length: 222.05
    Episode_Reward/reaching_object: 1.1555
    Episode_Reward/rotating_object: 49.5717
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0796
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.11s
                      Time elapsed: 00:33:55
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 48522 steps/s (collection: 1.932s, learning 0.094s)
             Mean action noise std: 3.35
          Mean value_function loss: 86.1285
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 81.0343
                       Mean reward: 247.12
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.1468
    Episode_Reward/rotating_object: 46.2928
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.03s
                      Time elapsed: 00:33:57
                               ETA: 00:24:05

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 48701 steps/s (collection: 1.908s, learning 0.110s)
             Mean action noise std: 3.35
          Mean value_function loss: 91.9206
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 81.0548
                       Mean reward: 260.44
               Mean episode length: 221.97
    Episode_Reward/reaching_object: 1.1534
    Episode_Reward/rotating_object: 49.4464
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0795
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.02s
                      Time elapsed: 00:33:59
                               ETA: 00:24:03

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 48241 steps/s (collection: 1.911s, learning 0.127s)
             Mean action noise std: 3.36
          Mean value_function loss: 74.8909
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 81.0802
                       Mean reward: 282.80
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 50.3411
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.04s
                      Time elapsed: 00:34:01
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 48360 steps/s (collection: 1.938s, learning 0.095s)
             Mean action noise std: 3.36
          Mean value_function loss: 73.7336
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 81.1142
                       Mean reward: 284.08
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.1903
    Episode_Reward/rotating_object: 54.8883
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0814
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.03s
                      Time elapsed: 00:34:03
                               ETA: 00:23:58

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 48294 steps/s (collection: 1.895s, learning 0.141s)
             Mean action noise std: 3.36
          Mean value_function loss: 78.5502
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 81.1456
                       Mean reward: 222.48
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 51.0735
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0811
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.04s
                      Time elapsed: 00:34:05
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 48519 steps/s (collection: 1.925s, learning 0.101s)
             Mean action noise std: 3.37
          Mean value_function loss: 71.6201
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 81.1736
                       Mean reward: 247.56
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 1.1546
    Episode_Reward/rotating_object: 50.1761
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0789
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.03s
                      Time elapsed: 00:34:07
                               ETA: 00:23:53

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 47933 steps/s (collection: 1.930s, learning 0.121s)
             Mean action noise std: 3.37
          Mean value_function loss: 75.0779
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 81.2025
                       Mean reward: 239.05
               Mean episode length: 221.03
    Episode_Reward/reaching_object: 1.1630
    Episode_Reward/rotating_object: 48.5755
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0806
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.05s
                      Time elapsed: 00:34:09
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 45689 steps/s (collection: 2.034s, learning 0.118s)
             Mean action noise std: 3.37
          Mean value_function loss: 80.6411
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 81.2291
                       Mean reward: 249.54
               Mean episode length: 225.29
    Episode_Reward/reaching_object: 1.1528
    Episode_Reward/rotating_object: 48.1895
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.15s
                      Time elapsed: 00:34:11
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 44660 steps/s (collection: 2.021s, learning 0.180s)
             Mean action noise std: 3.38
          Mean value_function loss: 74.5989
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 81.2633
                       Mean reward: 280.98
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.1741
    Episode_Reward/rotating_object: 54.9873
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.20s
                      Time elapsed: 00:34:13
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 44976 steps/s (collection: 2.058s, learning 0.128s)
             Mean action noise std: 3.38
          Mean value_function loss: 84.5302
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 81.2862
                       Mean reward: 248.54
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 1.1698
    Episode_Reward/rotating_object: 49.6015
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0814
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.19s
                      Time elapsed: 00:34:16
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 45888 steps/s (collection: 2.040s, learning 0.103s)
             Mean action noise std: 3.38
          Mean value_function loss: 81.8009
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 81.3040
                       Mean reward: 249.29
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.1779
    Episode_Reward/rotating_object: 53.8264
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0819
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.14s
                      Time elapsed: 00:34:18
                               ETA: 00:23:40

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 46379 steps/s (collection: 2.006s, learning 0.114s)
             Mean action noise std: 3.39
          Mean value_function loss: 81.6130
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 81.3269
                       Mean reward: 245.59
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 50.5619
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0809
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.12s
                      Time elapsed: 00:34:20
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 46944 steps/s (collection: 1.981s, learning 0.113s)
             Mean action noise std: 3.39
          Mean value_function loss: 73.8086
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 81.3497
                       Mean reward: 303.58
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.1620
    Episode_Reward/rotating_object: 53.1599
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0799
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.09s
                      Time elapsed: 00:34:22
                               ETA: 00:23:35

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 45204 steps/s (collection: 2.024s, learning 0.150s)
             Mean action noise std: 3.39
          Mean value_function loss: 88.7426
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 81.3726
                       Mean reward: 265.56
               Mean episode length: 222.16
    Episode_Reward/reaching_object: 1.1236
    Episode_Reward/rotating_object: 52.1261
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.17s
                      Time elapsed: 00:34:24
                               ETA: 00:23:33

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 44099 steps/s (collection: 2.053s, learning 0.176s)
             Mean action noise std: 3.39
          Mean value_function loss: 90.1401
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 81.3956
                       Mean reward: 229.06
               Mean episode length: 220.88
    Episode_Reward/reaching_object: 1.1637
    Episode_Reward/rotating_object: 50.0785
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0799
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.23s
                      Time elapsed: 00:34:26
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 43535 steps/s (collection: 2.105s, learning 0.153s)
             Mean action noise std: 3.39
          Mean value_function loss: 79.7775
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 81.4125
                       Mean reward: 292.95
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 1.1747
    Episode_Reward/rotating_object: 51.3420
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0816
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.26s
                      Time elapsed: 00:34:29
                               ETA: 00:23:28

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 42759 steps/s (collection: 2.124s, learning 0.175s)
             Mean action noise std: 3.40
          Mean value_function loss: 86.8048
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 81.4315
                       Mean reward: 258.70
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 1.1843
    Episode_Reward/rotating_object: 51.4029
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.30s
                      Time elapsed: 00:34:31
                               ETA: 00:23:26

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 47387 steps/s (collection: 1.976s, learning 0.099s)
             Mean action noise std: 3.40
          Mean value_function loss: 79.8658
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 81.4516
                       Mean reward: 274.18
               Mean episode length: 227.31
    Episode_Reward/reaching_object: 1.1666
    Episode_Reward/rotating_object: 49.9506
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0800
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.07s
                      Time elapsed: 00:34:33
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 47416 steps/s (collection: 1.978s, learning 0.095s)
             Mean action noise std: 3.40
          Mean value_function loss: 74.9908
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 81.4686
                       Mean reward: 258.21
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.1855
    Episode_Reward/rotating_object: 51.9018
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.07s
                      Time elapsed: 00:34:35
                               ETA: 00:23:21

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 48181 steps/s (collection: 1.920s, learning 0.121s)
             Mean action noise std: 3.40
          Mean value_function loss: 79.3906
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 81.4857
                       Mean reward: 258.22
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 1.1778
    Episode_Reward/rotating_object: 51.8407
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0800
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.04s
                      Time elapsed: 00:34:37
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 43113 steps/s (collection: 2.089s, learning 0.192s)
             Mean action noise std: 3.41
          Mean value_function loss: 84.4736
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 81.5055
                       Mean reward: 240.80
               Mean episode length: 214.35
    Episode_Reward/reaching_object: 1.1845
    Episode_Reward/rotating_object: 51.2817
        Episode_Reward/action_rate: -0.0811
          Episode_Reward/joint_vel: -0.0799
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.28s
                      Time elapsed: 00:34:39
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 45810 steps/s (collection: 2.020s, learning 0.126s)
             Mean action noise std: 3.41
          Mean value_function loss: 84.6235
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 81.5267
                       Mean reward: 209.67
               Mean episode length: 220.13
    Episode_Reward/reaching_object: 1.1677
    Episode_Reward/rotating_object: 49.9370
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0785
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.15s
                      Time elapsed: 00:34:42
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 43973 steps/s (collection: 2.087s, learning 0.149s)
             Mean action noise std: 3.41
          Mean value_function loss: 83.2395
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 81.5451
                       Mean reward: 281.37
               Mean episode length: 229.49
    Episode_Reward/reaching_object: 1.1700
    Episode_Reward/rotating_object: 52.0040
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0798
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.24s
                      Time elapsed: 00:34:44
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 48120 steps/s (collection: 1.944s, learning 0.099s)
             Mean action noise std: 3.41
          Mean value_function loss: 83.3259
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 81.5693
                       Mean reward: 253.56
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 52.0805
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.04s
                      Time elapsed: 00:34:46
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 44114 steps/s (collection: 2.077s, learning 0.152s)
             Mean action noise std: 3.42
          Mean value_function loss: 89.0086
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 81.5922
                       Mean reward: 266.74
               Mean episode length: 226.06
    Episode_Reward/reaching_object: 1.1774
    Episode_Reward/rotating_object: 49.5002
        Episode_Reward/action_rate: -0.0806
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.23s
                      Time elapsed: 00:34:48
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 44966 steps/s (collection: 2.003s, learning 0.184s)
             Mean action noise std: 3.42
          Mean value_function loss: 85.6979
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 81.6158
                       Mean reward: 248.07
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 1.1670
    Episode_Reward/rotating_object: 50.5955
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.19s
                      Time elapsed: 00:34:50
                               ETA: 00:23:04

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 46411 steps/s (collection: 1.979s, learning 0.139s)
             Mean action noise std: 3.42
          Mean value_function loss: 77.4825
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 81.6389
                       Mean reward: 259.17
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 52.4519
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0776
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.12s
                      Time elapsed: 00:34:52
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 45263 steps/s (collection: 2.006s, learning 0.166s)
             Mean action noise std: 3.42
          Mean value_function loss: 75.4963
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 81.6563
                       Mean reward: 268.05
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 52.7233
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.17s
                      Time elapsed: 00:34:54
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 44797 steps/s (collection: 2.005s, learning 0.189s)
             Mean action noise std: 3.43
          Mean value_function loss: 85.7726
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 81.6770
                       Mean reward: 302.67
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.1903
    Episode_Reward/rotating_object: 54.0417
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0788
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.19s
                      Time elapsed: 00:34:57
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 45916 steps/s (collection: 2.016s, learning 0.125s)
             Mean action noise std: 3.43
          Mean value_function loss: 89.2589
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 81.6997
                       Mean reward: 266.53
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.1572
    Episode_Reward/rotating_object: 48.9252
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.14s
                      Time elapsed: 00:34:59
                               ETA: 00:22:54

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 46931 steps/s (collection: 1.964s, learning 0.131s)
             Mean action noise std: 3.43
          Mean value_function loss: 81.7572
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 81.7161
                       Mean reward: 235.89
               Mean episode length: 221.72
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 54.1456
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0776
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.09s
                      Time elapsed: 00:35:01
                               ETA: 00:22:52

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 45846 steps/s (collection: 2.024s, learning 0.121s)
             Mean action noise std: 3.43
          Mean value_function loss: 76.1005
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 81.7380
                       Mean reward: 245.15
               Mean episode length: 220.11
    Episode_Reward/reaching_object: 1.1387
    Episode_Reward/rotating_object: 48.2663
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0744
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.14s
                      Time elapsed: 00:35:03
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 42721 steps/s (collection: 2.116s, learning 0.185s)
             Mean action noise std: 3.43
          Mean value_function loss: 72.4070
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 81.7559
                       Mean reward: 244.93
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 1.1904
    Episode_Reward/rotating_object: 52.1724
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.30s
                      Time elapsed: 00:35:05
                               ETA: 00:22:47

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 45301 steps/s (collection: 2.013s, learning 0.157s)
             Mean action noise std: 3.44
          Mean value_function loss: 69.8810
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 81.7734
                       Mean reward: 267.98
               Mean episode length: 228.24
    Episode_Reward/reaching_object: 1.2042
    Episode_Reward/rotating_object: 54.4699
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.17s
                      Time elapsed: 00:35:08
                               ETA: 00:22:45

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 47846 steps/s (collection: 1.897s, learning 0.158s)
             Mean action noise std: 3.44
          Mean value_function loss: 76.8692
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 81.7972
                       Mean reward: 292.88
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 54.8455
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.05s
                      Time elapsed: 00:35:10
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 45788 steps/s (collection: 1.977s, learning 0.170s)
             Mean action noise std: 3.44
          Mean value_function loss: 82.7918
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 81.8152
                       Mean reward: 273.02
               Mean episode length: 227.15
    Episode_Reward/reaching_object: 1.1841
    Episode_Reward/rotating_object: 52.2808
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.15s
                      Time elapsed: 00:35:12
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 45051 steps/s (collection: 2.061s, learning 0.121s)
             Mean action noise std: 3.44
          Mean value_function loss: 73.3423
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 81.8376
                       Mean reward: 291.41
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.1833
    Episode_Reward/rotating_object: 54.1828
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.18s
                      Time elapsed: 00:35:14
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 47289 steps/s (collection: 1.933s, learning 0.145s)
             Mean action noise std: 3.45
          Mean value_function loss: 87.9914
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 81.8655
                       Mean reward: 242.87
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 1.1517
    Episode_Reward/rotating_object: 51.3773
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.08s
                      Time elapsed: 00:35:16
                               ETA: 00:22:35

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 46357 steps/s (collection: 2.007s, learning 0.114s)
             Mean action noise std: 3.45
          Mean value_function loss: 82.7795
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 81.8902
                       Mean reward: 285.30
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 56.0801
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0786
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.12s
                      Time elapsed: 00:35:18
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 46461 steps/s (collection: 1.991s, learning 0.125s)
             Mean action noise std: 3.45
          Mean value_function loss: 73.9811
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 81.9131
                       Mean reward: 286.50
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 56.6712
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0780
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.12s
                      Time elapsed: 00:35:20
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 47282 steps/s (collection: 1.921s, learning 0.158s)
             Mean action noise std: 3.46
          Mean value_function loss: 69.6952
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 81.9328
                       Mean reward: 243.88
               Mean episode length: 224.85
    Episode_Reward/reaching_object: 1.1821
    Episode_Reward/rotating_object: 53.2511
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0765
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.08s
                      Time elapsed: 00:35:22
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 47486 steps/s (collection: 1.938s, learning 0.132s)
             Mean action noise std: 3.46
          Mean value_function loss: 84.2564
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 81.9450
                       Mean reward: 267.97
               Mean episode length: 222.65
    Episode_Reward/reaching_object: 1.1814
    Episode_Reward/rotating_object: 51.5263
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0766
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.07s
                      Time elapsed: 00:35:24
                               ETA: 00:22:25

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 46472 steps/s (collection: 1.970s, learning 0.146s)
             Mean action noise std: 3.46
          Mean value_function loss: 78.5633
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 81.9683
                       Mean reward: 285.28
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 53.4094
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.12s
                      Time elapsed: 00:35:26
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 46368 steps/s (collection: 1.982s, learning 0.138s)
             Mean action noise std: 3.46
          Mean value_function loss: 87.7345
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 81.9892
                       Mean reward: 244.74
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 56.7599
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.12s
                      Time elapsed: 00:35:29
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 45219 steps/s (collection: 2.023s, learning 0.151s)
             Mean action noise std: 3.47
          Mean value_function loss: 86.2079
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 82.0086
                       Mean reward: 269.55
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 1.1834
    Episode_Reward/rotating_object: 56.1981
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0769
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.17s
                      Time elapsed: 00:35:31
                               ETA: 00:22:18

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 40853 steps/s (collection: 2.276s, learning 0.130s)
             Mean action noise std: 3.47
          Mean value_function loss: 79.9249
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 82.0312
                       Mean reward: 262.75
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 54.8865
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0766
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.41s
                      Time elapsed: 00:35:33
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 48443 steps/s (collection: 1.912s, learning 0.118s)
             Mean action noise std: 3.47
          Mean value_function loss: 81.1646
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 82.0641
                       Mean reward: 290.02
               Mean episode length: 226.84
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 57.0225
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.03s
                      Time elapsed: 00:35:35
                               ETA: 00:22:13

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 49684 steps/s (collection: 1.869s, learning 0.110s)
             Mean action noise std: 3.47
          Mean value_function loss: 84.3921
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 82.0934
                       Mean reward: 287.77
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 53.5283
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.98s
                      Time elapsed: 00:35:37
                               ETA: 00:22:11

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 45019 steps/s (collection: 2.021s, learning 0.163s)
             Mean action noise std: 3.48
          Mean value_function loss: 82.6136
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 82.1183
                       Mean reward: 273.42
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.1735
    Episode_Reward/rotating_object: 53.3550
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.18s
                      Time elapsed: 00:35:39
                               ETA: 00:22:08

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 47798 steps/s (collection: 1.912s, learning 0.144s)
             Mean action noise std: 3.48
          Mean value_function loss: 85.8376
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 82.1519
                       Mean reward: 272.68
               Mean episode length: 224.69
    Episode_Reward/reaching_object: 1.1782
    Episode_Reward/rotating_object: 55.2083
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.06s
                      Time elapsed: 00:35:41
                               ETA: 00:22:06

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 43581 steps/s (collection: 2.115s, learning 0.141s)
             Mean action noise std: 3.49
          Mean value_function loss: 92.7959
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 82.1881
                       Mean reward: 289.29
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 1.1724
    Episode_Reward/rotating_object: 58.4336
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.26s
                      Time elapsed: 00:35:44
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 46400 steps/s (collection: 1.980s, learning 0.139s)
             Mean action noise std: 3.49
          Mean value_function loss: 92.3253
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 82.2137
                       Mean reward: 276.63
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.1689
    Episode_Reward/rotating_object: 52.9971
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.12s
                      Time elapsed: 00:35:46
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 46432 steps/s (collection: 1.994s, learning 0.123s)
             Mean action noise std: 3.49
          Mean value_function loss: 87.4142
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 82.2285
                       Mean reward: 301.89
               Mean episode length: 226.86
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 56.6682
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0785
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.12s
                      Time elapsed: 00:35:48
                               ETA: 00:21:59

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 46048 steps/s (collection: 2.001s, learning 0.134s)
             Mean action noise std: 3.49
          Mean value_function loss: 77.4742
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 82.2410
                       Mean reward: 296.41
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 55.5248
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.13s
                      Time elapsed: 00:35:50
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 47733 steps/s (collection: 1.939s, learning 0.120s)
             Mean action noise std: 3.49
          Mean value_function loss: 70.8862
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 82.2606
                       Mean reward: 285.19
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.2103
    Episode_Reward/rotating_object: 56.0484
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0801
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.06s
                      Time elapsed: 00:35:52
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 47386 steps/s (collection: 1.969s, learning 0.106s)
             Mean action noise std: 3.50
          Mean value_function loss: 72.4036
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 82.2814
                       Mean reward: 302.14
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 1.1977
    Episode_Reward/rotating_object: 58.3206
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0785
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.07s
                      Time elapsed: 00:35:54
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 47249 steps/s (collection: 1.961s, learning 0.119s)
             Mean action noise std: 3.50
          Mean value_function loss: 82.8534
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 82.3054
                       Mean reward: 300.94
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.1997
    Episode_Reward/rotating_object: 58.7300
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.08s
                      Time elapsed: 00:35:56
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 48162 steps/s (collection: 1.948s, learning 0.094s)
             Mean action noise std: 3.50
          Mean value_function loss: 84.2783
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 82.3333
                       Mean reward: 253.34
               Mean episode length: 220.07
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 53.1887
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0770
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.04s
                      Time elapsed: 00:35:58
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 47887 steps/s (collection: 1.915s, learning 0.138s)
             Mean action noise std: 3.51
          Mean value_function loss: 84.3139
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 82.3669
                       Mean reward: 313.02
               Mean episode length: 233.25
    Episode_Reward/reaching_object: 1.1961
    Episode_Reward/rotating_object: 58.9740
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.05s
                      Time elapsed: 00:36:00
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 46631 steps/s (collection: 1.988s, learning 0.120s)
             Mean action noise std: 3.51
          Mean value_function loss: 90.9712
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 82.3955
                       Mean reward: 284.30
               Mean episode length: 221.41
    Episode_Reward/reaching_object: 1.1707
    Episode_Reward/rotating_object: 59.2001
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.11s
                      Time elapsed: 00:36:02
                               ETA: 00:21:41

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 46314 steps/s (collection: 1.958s, learning 0.165s)
             Mean action noise std: 3.51
          Mean value_function loss: 81.3146
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 82.4182
                       Mean reward: 262.61
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 1.1666
    Episode_Reward/rotating_object: 52.0717
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.12s
                      Time elapsed: 00:36:05
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 47196 steps/s (collection: 1.963s, learning 0.120s)
             Mean action noise std: 3.52
          Mean value_function loss: 79.4464
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 82.4398
                       Mean reward: 302.66
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.1819
    Episode_Reward/rotating_object: 56.7665
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0765
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.08s
                      Time elapsed: 00:36:07
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 48053 steps/s (collection: 1.910s, learning 0.136s)
             Mean action noise std: 3.52
          Mean value_function loss: 95.7103
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 82.4532
                       Mean reward: 259.74
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.1897
    Episode_Reward/rotating_object: 56.4648
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0784
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.05s
                      Time elapsed: 00:36:09
                               ETA: 00:21:34

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 44526 steps/s (collection: 2.020s, learning 0.188s)
             Mean action noise std: 3.52
          Mean value_function loss: 84.3729
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 82.4726
                       Mean reward: 289.39
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 1.1556
    Episode_Reward/rotating_object: 53.8522
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.21s
                      Time elapsed: 00:36:11
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 46787 steps/s (collection: 1.951s, learning 0.150s)
             Mean action noise std: 3.52
          Mean value_function loss: 86.7189
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 82.4989
                       Mean reward: 254.95
               Mean episode length: 227.06
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 52.9117
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0800
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.10s
                      Time elapsed: 00:36:13
                               ETA: 00:21:29

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 46140 steps/s (collection: 1.987s, learning 0.144s)
             Mean action noise std: 3.53
          Mean value_function loss: 92.1591
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 82.5289
                       Mean reward: 271.93
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 56.0352
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0800
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.13s
                      Time elapsed: 00:36:15
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 46865 steps/s (collection: 1.977s, learning 0.121s)
             Mean action noise std: 3.53
          Mean value_function loss: 72.7132
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 82.5583
                       Mean reward: 287.06
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.1770
    Episode_Reward/rotating_object: 53.5275
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.10s
                      Time elapsed: 00:36:17
                               ETA: 00:21:24

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 45737 steps/s (collection: 1.985s, learning 0.165s)
             Mean action noise std: 3.53
          Mean value_function loss: 73.4629
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 82.5926
                       Mean reward: 226.84
               Mean episode length: 218.23
    Episode_Reward/reaching_object: 1.1603
    Episode_Reward/rotating_object: 50.7873
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.15s
                      Time elapsed: 00:36:19
                               ETA: 00:21:22

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 41711 steps/s (collection: 2.132s, learning 0.225s)
             Mean action noise std: 3.54
          Mean value_function loss: 79.5247
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 82.6118
                       Mean reward: 280.68
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.1958
    Episode_Reward/rotating_object: 55.7945
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0785
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.36s
                      Time elapsed: 00:36:22
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 44722 steps/s (collection: 2.034s, learning 0.164s)
             Mean action noise std: 3.54
          Mean value_function loss: 93.8465
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 82.6343
                       Mean reward: 289.69
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.1744
    Episode_Reward/rotating_object: 52.7221
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.20s
                      Time elapsed: 00:36:24
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 41158 steps/s (collection: 2.213s, learning 0.176s)
             Mean action noise std: 3.54
          Mean value_function loss: 77.1826
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 82.6527
                       Mean reward: 308.19
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 1.1931
    Episode_Reward/rotating_object: 59.6470
        Episode_Reward/action_rate: -0.0889
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.39s
                      Time elapsed: 00:36:26
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 44392 steps/s (collection: 2.105s, learning 0.109s)
             Mean action noise std: 3.54
          Mean value_function loss: 75.0137
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 82.6730
                       Mean reward: 299.34
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 54.5841
        Episode_Reward/action_rate: -0.0893
          Episode_Reward/joint_vel: -0.0813
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.21s
                      Time elapsed: 00:36:29
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 45801 steps/s (collection: 2.014s, learning 0.132s)
             Mean action noise std: 3.55
          Mean value_function loss: 80.3900
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 82.6939
                       Mean reward: 272.72
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 58.4296
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0793
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.15s
                      Time elapsed: 00:36:31
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 44652 steps/s (collection: 2.051s, learning 0.151s)
             Mean action noise std: 3.55
          Mean value_function loss: 81.4305
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 82.7184
                       Mean reward: 305.16
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 57.2780
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0803
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.20s
                      Time elapsed: 00:36:33
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 45299 steps/s (collection: 2.070s, learning 0.101s)
             Mean action noise std: 3.55
          Mean value_function loss: 84.5719
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 82.7411
                       Mean reward: 248.26
               Mean episode length: 225.47
    Episode_Reward/reaching_object: 1.1843
    Episode_Reward/rotating_object: 53.8624
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0807
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.17s
                      Time elapsed: 00:36:35
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 43734 steps/s (collection: 2.117s, learning 0.131s)
             Mean action noise std: 3.55
          Mean value_function loss: 92.5380
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 82.7554
                       Mean reward: 268.79
               Mean episode length: 219.47
    Episode_Reward/reaching_object: 1.1880
    Episode_Reward/rotating_object: 57.9642
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.25s
                      Time elapsed: 00:36:37
                               ETA: 00:21:03

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 44704 steps/s (collection: 2.004s, learning 0.195s)
             Mean action noise std: 3.56
          Mean value_function loss: 77.4863
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 82.7771
                       Mean reward: 289.16
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.1804
    Episode_Reward/rotating_object: 55.7910
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0800
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.20s
                      Time elapsed: 00:36:40
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 44653 steps/s (collection: 2.019s, learning 0.183s)
             Mean action noise std: 3.56
          Mean value_function loss: 81.0292
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 82.7983
                       Mean reward: 305.01
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.1696
    Episode_Reward/rotating_object: 53.2718
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0807
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.20s
                      Time elapsed: 00:36:42
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 46257 steps/s (collection: 1.998s, learning 0.128s)
             Mean action noise std: 3.56
          Mean value_function loss: 83.9223
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 82.8149
                       Mean reward: 235.73
               Mean episode length: 208.15
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 51.4438
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0795
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.13s
                      Time elapsed: 00:36:44
                               ETA: 00:20:56

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 46074 steps/s (collection: 2.004s, learning 0.130s)
             Mean action noise std: 3.56
          Mean value_function loss: 86.4262
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 82.8423
                       Mean reward: 257.04
               Mean episode length: 225.24
    Episode_Reward/reaching_object: 1.1546
    Episode_Reward/rotating_object: 50.1303
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0792
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.13s
                      Time elapsed: 00:36:46
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 46789 steps/s (collection: 1.984s, learning 0.117s)
             Mean action noise std: 3.57
          Mean value_function loss: 92.2266
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 82.8589
                       Mean reward: 230.44
               Mean episode length: 228.25
    Episode_Reward/reaching_object: 1.1575
    Episode_Reward/rotating_object: 52.2957
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.10s
                      Time elapsed: 00:36:48
                               ETA: 00:20:51

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 47356 steps/s (collection: 1.947s, learning 0.129s)
             Mean action noise std: 3.57
          Mean value_function loss: 76.6043
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 82.8781
                       Mean reward: 297.40
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.1643
    Episode_Reward/rotating_object: 55.4912
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0785
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.08s
                      Time elapsed: 00:36:50
                               ETA: 00:20:49

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 45561 steps/s (collection: 2.007s, learning 0.151s)
             Mean action noise std: 3.57
          Mean value_function loss: 82.0839
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 82.9077
                       Mean reward: 251.26
               Mean episode length: 222.27
    Episode_Reward/reaching_object: 1.1682
    Episode_Reward/rotating_object: 53.7302
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.16s
                      Time elapsed: 00:36:52
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 46131 steps/s (collection: 2.002s, learning 0.129s)
             Mean action noise std: 3.58
          Mean value_function loss: 76.2687
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 82.9390
                       Mean reward: 328.73
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 56.4631
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.13s
                      Time elapsed: 00:36:54
                               ETA: 00:20:44

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 45365 steps/s (collection: 2.035s, learning 0.132s)
             Mean action noise std: 3.58
          Mean value_function loss: 82.5055
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 82.9642
                       Mean reward: 259.79
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.2085
    Episode_Reward/rotating_object: 57.5378
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.17s
                      Time elapsed: 00:36:57
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 46467 steps/s (collection: 1.981s, learning 0.134s)
             Mean action noise std: 3.58
          Mean value_function loss: 86.7467
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 82.9831
                       Mean reward: 296.85
               Mean episode length: 223.02
    Episode_Reward/reaching_object: 1.1511
    Episode_Reward/rotating_object: 52.3814
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.12s
                      Time elapsed: 00:36:59
                               ETA: 00:20:39

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 44621 steps/s (collection: 2.022s, learning 0.181s)
             Mean action noise std: 3.58
          Mean value_function loss: 82.8544
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.0051
                       Mean reward: 259.87
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.1873
    Episode_Reward/rotating_object: 55.7496
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.20s
                      Time elapsed: 00:37:01
                               ETA: 00:20:37

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 44287 steps/s (collection: 2.087s, learning 0.132s)
             Mean action noise std: 3.59
          Mean value_function loss: 78.1460
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 83.0321
                       Mean reward: 305.66
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.1754
    Episode_Reward/rotating_object: 55.7476
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0795
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.22s
                      Time elapsed: 00:37:03
                               ETA: 00:20:35

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 45294 steps/s (collection: 2.068s, learning 0.102s)
             Mean action noise std: 3.59
          Mean value_function loss: 90.5395
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.0583
                       Mean reward: 298.48
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.2025
    Episode_Reward/rotating_object: 53.3272
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0816
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.17s
                      Time elapsed: 00:37:05
                               ETA: 00:20:32

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 45172 steps/s (collection: 2.025s, learning 0.151s)
             Mean action noise std: 3.59
          Mean value_function loss: 83.3629
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 83.0751
                       Mean reward: 277.54
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 1.1637
    Episode_Reward/rotating_object: 53.4417
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0789
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.18s
                      Time elapsed: 00:37:08
                               ETA: 00:20:30

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 45469 steps/s (collection: 2.038s, learning 0.124s)
             Mean action noise std: 3.59
          Mean value_function loss: 84.7347
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 83.0847
                       Mean reward: 220.18
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 1.1637
    Episode_Reward/rotating_object: 51.9180
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.16s
                      Time elapsed: 00:37:10
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 42065 steps/s (collection: 2.169s, learning 0.168s)
             Mean action noise std: 3.60
          Mean value_function loss: 87.6094
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 83.1080
                       Mean reward: 297.47
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 57.3342
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0827
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.34s
                      Time elapsed: 00:37:12
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 44152 steps/s (collection: 2.101s, learning 0.125s)
             Mean action noise std: 3.60
          Mean value_function loss: 102.1348
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 83.1400
                       Mean reward: 274.46
               Mean episode length: 230.31
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 53.3810
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0810
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.23s
                      Time elapsed: 00:37:14
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 42187 steps/s (collection: 2.173s, learning 0.157s)
             Mean action noise std: 3.60
          Mean value_function loss: 88.5126
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 83.1654
                       Mean reward: 237.94
               Mean episode length: 231.74
    Episode_Reward/reaching_object: 1.1864
    Episode_Reward/rotating_object: 53.9328
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0825
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.33s
                      Time elapsed: 00:37:17
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 43489 steps/s (collection: 2.098s, learning 0.162s)
             Mean action noise std: 3.61
          Mean value_function loss: 90.6495
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.1799
                       Mean reward: 236.04
               Mean episode length: 232.32
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 54.3782
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0836
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.26s
                      Time elapsed: 00:37:19
                               ETA: 00:20:18

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 46069 steps/s (collection: 2.016s, learning 0.118s)
             Mean action noise std: 3.61
          Mean value_function loss: 96.0132
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.1969
                       Mean reward: 290.74
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 54.4339
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0818
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.13s
                      Time elapsed: 00:37:21
                               ETA: 00:20:16

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 46026 steps/s (collection: 1.967s, learning 0.169s)
             Mean action noise std: 3.61
          Mean value_function loss: 80.5569
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 83.2127
                       Mean reward: 298.85
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 1.2105
    Episode_Reward/rotating_object: 56.3115
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0840
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.14s
                      Time elapsed: 00:37:23
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 43283 steps/s (collection: 2.150s, learning 0.122s)
             Mean action noise std: 3.61
          Mean value_function loss: 73.2934
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.2350
                       Mean reward: 288.98
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.2091
    Episode_Reward/rotating_object: 55.9996
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0829
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.27s
                      Time elapsed: 00:37:25
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 45650 steps/s (collection: 2.023s, learning 0.130s)
             Mean action noise std: 3.62
          Mean value_function loss: 91.9628
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 83.2578
                       Mean reward: 266.41
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.1989
    Episode_Reward/rotating_object: 52.0893
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0819
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.15s
                      Time elapsed: 00:37:28
                               ETA: 00:20:09

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 42459 steps/s (collection: 2.141s, learning 0.175s)
             Mean action noise std: 3.62
          Mean value_function loss: 82.4434
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 83.2782
                       Mean reward: 280.10
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 52.6298
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0812
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.32s
                      Time elapsed: 00:37:30
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 45084 steps/s (collection: 2.054s, learning 0.126s)
             Mean action noise std: 3.62
          Mean value_function loss: 81.1007
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 83.2965
                       Mean reward: 262.95
               Mean episode length: 217.51
    Episode_Reward/reaching_object: 1.1880
    Episode_Reward/rotating_object: 56.5544
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0827
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.18s
                      Time elapsed: 00:37:32
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 48012 steps/s (collection: 1.932s, learning 0.115s)
             Mean action noise std: 3.62
          Mean value_function loss: 92.6836
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 83.3226
                       Mean reward: 292.49
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.1997
    Episode_Reward/rotating_object: 54.1717
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0813
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.05s
                      Time elapsed: 00:37:34
                               ETA: 00:20:02

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 48202 steps/s (collection: 1.933s, learning 0.107s)
             Mean action noise std: 3.63
          Mean value_function loss: 94.1599
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 83.3501
                       Mean reward: 260.20
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 1.1785
    Episode_Reward/rotating_object: 54.1972
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0805
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.04s
                      Time elapsed: 00:37:36
                               ETA: 00:19:59

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 46622 steps/s (collection: 1.967s, learning 0.142s)
             Mean action noise std: 3.63
          Mean value_function loss: 83.2014
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 83.3720
                       Mean reward: 297.30
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.1827
    Episode_Reward/rotating_object: 53.1183
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0820
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.11s
                      Time elapsed: 00:37:38
                               ETA: 00:19:57

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 41416 steps/s (collection: 2.201s, learning 0.173s)
             Mean action noise std: 3.63
          Mean value_function loss: 88.7429
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 83.3880
                       Mean reward: 254.91
               Mean episode length: 219.48
    Episode_Reward/reaching_object: 1.1548
    Episode_Reward/rotating_object: 49.6567
        Episode_Reward/action_rate: -0.0896
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.37s
                      Time elapsed: 00:37:41
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 44190 steps/s (collection: 2.070s, learning 0.154s)
             Mean action noise std: 3.63
          Mean value_function loss: 73.1555
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 83.4110
                       Mean reward: 250.36
               Mean episode length: 225.20
    Episode_Reward/reaching_object: 1.1902
    Episode_Reward/rotating_object: 56.7206
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0829
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.22s
                      Time elapsed: 00:37:43
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 41381 steps/s (collection: 2.217s, learning 0.158s)
             Mean action noise std: 3.64
          Mean value_function loss: 84.7640
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.4342
                       Mean reward: 277.01
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.1716
    Episode_Reward/rotating_object: 53.2547
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0808
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.38s
                      Time elapsed: 00:37:45
                               ETA: 00:19:50

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 46713 steps/s (collection: 1.999s, learning 0.105s)
             Mean action noise std: 3.64
          Mean value_function loss: 81.0688
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.4583
                       Mean reward: 330.00
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.2005
    Episode_Reward/rotating_object: 60.5456
        Episode_Reward/action_rate: -0.0921
          Episode_Reward/joint_vel: -0.0807
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.10s
                      Time elapsed: 00:37:47
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 45298 steps/s (collection: 1.989s, learning 0.182s)
             Mean action noise std: 3.64
          Mean value_function loss: 85.4695
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 83.4793
                       Mean reward: 297.45
               Mean episode length: 212.40
    Episode_Reward/reaching_object: 1.1767
    Episode_Reward/rotating_object: 57.8781
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0792
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.17s
                      Time elapsed: 00:37:49
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 44581 steps/s (collection: 2.049s, learning 0.156s)
             Mean action noise std: 3.64
          Mean value_function loss: 93.7157
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 83.4948
                       Mean reward: 303.83
               Mean episode length: 227.35
    Episode_Reward/reaching_object: 1.1806
    Episode_Reward/rotating_object: 53.8545
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0814
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.21s
                      Time elapsed: 00:37:52
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 45506 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 3.65
          Mean value_function loss: 90.6528
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.5130
                       Mean reward: 283.67
               Mean episode length: 227.57
    Episode_Reward/reaching_object: 1.1947
    Episode_Reward/rotating_object: 55.8221
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0823
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.16s
                      Time elapsed: 00:37:54
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 43797 steps/s (collection: 2.069s, learning 0.176s)
             Mean action noise std: 3.65
          Mean value_function loss: 84.5689
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 83.5400
                       Mean reward: 276.21
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 1.1827
    Episode_Reward/rotating_object: 56.7424
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0802
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.24s
                      Time elapsed: 00:37:56
                               ETA: 00:19:38

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 45693 steps/s (collection: 2.013s, learning 0.138s)
             Mean action noise std: 3.65
          Mean value_function loss: 75.8184
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.5661
                       Mean reward: 295.76
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.1998
    Episode_Reward/rotating_object: 54.4991
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0821
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.15s
                      Time elapsed: 00:37:58
                               ETA: 00:19:36

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 43752 steps/s (collection: 2.139s, learning 0.107s)
             Mean action noise std: 3.66
          Mean value_function loss: 88.2968
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.5877
                       Mean reward: 258.11
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 53.3282
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0789
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.25s
                      Time elapsed: 00:38:00
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 47085 steps/s (collection: 1.986s, learning 0.102s)
             Mean action noise std: 3.66
          Mean value_function loss: 103.2995
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 83.6099
                       Mean reward: 282.51
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.1709
    Episode_Reward/rotating_object: 53.0609
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0794
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.09s
                      Time elapsed: 00:38:03
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 42093 steps/s (collection: 2.177s, learning 0.159s)
             Mean action noise std: 3.66
          Mean value_function loss: 109.5074
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.6242
                       Mean reward: 299.23
               Mean episode length: 225.31
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 56.8638
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.34s
                      Time elapsed: 00:38:05
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 45944 steps/s (collection: 1.950s, learning 0.190s)
             Mean action noise std: 3.66
          Mean value_function loss: 92.9030
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 83.6367
                       Mean reward: 290.87
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 1.1974
    Episode_Reward/rotating_object: 56.5154
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0816
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.14s
                      Time elapsed: 00:38:07
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 45670 steps/s (collection: 1.977s, learning 0.175s)
             Mean action noise std: 3.66
          Mean value_function loss: 80.7644
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 83.6479
                       Mean reward: 315.79
               Mean episode length: 233.71
    Episode_Reward/reaching_object: 1.1605
    Episode_Reward/rotating_object: 53.4915
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.15s
                      Time elapsed: 00:38:09
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 46021 steps/s (collection: 1.958s, learning 0.178s)
             Mean action noise std: 3.67
          Mean value_function loss: 72.7009
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 83.6703
                       Mean reward: 309.10
               Mean episode length: 226.15
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 54.2958
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0830
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.14s
                      Time elapsed: 00:38:11
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 45743 steps/s (collection: 2.002s, learning 0.147s)
             Mean action noise std: 3.67
          Mean value_function loss: 70.3799
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.7000
                       Mean reward: 273.83
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.1775
    Episode_Reward/rotating_object: 54.8288
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0816
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.15s
                      Time elapsed: 00:38:13
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 46512 steps/s (collection: 1.988s, learning 0.125s)
             Mean action noise std: 3.67
          Mean value_function loss: 76.1252
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.7244
                       Mean reward: 273.34
               Mean episode length: 228.21
    Episode_Reward/reaching_object: 1.1584
    Episode_Reward/rotating_object: 52.4652
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0793
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.11s
                      Time elapsed: 00:38:16
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 46989 steps/s (collection: 1.956s, learning 0.136s)
             Mean action noise std: 3.68
          Mean value_function loss: 71.3036
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 83.7481
                       Mean reward: 284.75
               Mean episode length: 220.30
    Episode_Reward/reaching_object: 1.1842
    Episode_Reward/rotating_object: 54.1371
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0811
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.09s
                      Time elapsed: 00:38:18
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 41848 steps/s (collection: 2.084s, learning 0.265s)
             Mean action noise std: 3.68
          Mean value_function loss: 72.8629
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 83.7701
                       Mean reward: 267.00
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.2232
    Episode_Reward/rotating_object: 55.5366
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0839
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.35s
                      Time elapsed: 00:38:20
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14704 steps/s (collection: 6.536s, learning 0.150s)
             Mean action noise std: 3.68
          Mean value_function loss: 78.6101
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 83.7877
                       Mean reward: 298.46
               Mean episode length: 228.99
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 54.0506
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0821
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.69s
                      Time elapsed: 00:38:27
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14715 steps/s (collection: 6.506s, learning 0.174s)
             Mean action noise std: 3.68
          Mean value_function loss: 86.9740
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 83.8024
                       Mean reward: 284.14
               Mean episode length: 222.48
    Episode_Reward/reaching_object: 1.1930
    Episode_Reward/rotating_object: 56.6437
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0822
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.68s
                      Time elapsed: 00:38:33
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14861 steps/s (collection: 6.474s, learning 0.140s)
             Mean action noise std: 3.69
          Mean value_function loss: 81.5141
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.8228
                       Mean reward: 280.11
               Mean episode length: 218.92
    Episode_Reward/reaching_object: 1.1519
    Episode_Reward/rotating_object: 53.6281
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.61s
                      Time elapsed: 00:38:40
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14495 steps/s (collection: 6.657s, learning 0.124s)
             Mean action noise std: 3.69
          Mean value_function loss: 82.4685
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.8490
                       Mean reward: 347.43
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.2243
    Episode_Reward/rotating_object: 59.2333
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0820
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.78s
                      Time elapsed: 00:38:47
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14000 steps/s (collection: 6.859s, learning 0.163s)
             Mean action noise std: 3.69
          Mean value_function loss: 73.7165
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 83.8753
                       Mean reward: 299.91
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 55.5438
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0807
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 7.02s
                      Time elapsed: 00:38:54
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14426 steps/s (collection: 6.688s, learning 0.126s)
             Mean action noise std: 3.69
          Mean value_function loss: 78.0470
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 83.8888
                       Mean reward: 297.81
               Mean episode length: 220.77
    Episode_Reward/reaching_object: 1.1726
    Episode_Reward/rotating_object: 58.7803
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0798
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.81s
                      Time elapsed: 00:39:01
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 14797 steps/s (collection: 6.516s, learning 0.127s)
             Mean action noise std: 3.70
          Mean value_function loss: 70.7827
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 83.9098
                       Mean reward: 313.71
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.2146
    Episode_Reward/rotating_object: 61.1835
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0807
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.64s
                      Time elapsed: 00:39:07
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14873 steps/s (collection: 6.479s, learning 0.130s)
             Mean action noise std: 3.70
          Mean value_function loss: 82.5109
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 83.9351
                       Mean reward: 319.28
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.2168
    Episode_Reward/rotating_object: 60.9065
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0816
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.61s
                      Time elapsed: 00:39:14
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 15960 steps/s (collection: 6.008s, learning 0.151s)
             Mean action noise std: 3.70
          Mean value_function loss: 74.9798
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 83.9579
                       Mean reward: 336.12
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 59.3122
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0794
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 6.16s
                      Time elapsed: 00:39:20
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 45265 steps/s (collection: 2.059s, learning 0.113s)
             Mean action noise std: 3.70
          Mean value_function loss: 74.8310
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 83.9762
                       Mean reward: 290.92
               Mean episode length: 226.42
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 54.8913
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.17s
                      Time elapsed: 00:39:22
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 48871 steps/s (collection: 1.889s, learning 0.122s)
             Mean action noise std: 3.71
          Mean value_function loss: 89.0256
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 83.9880
                       Mean reward: 282.44
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 60.5991
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0799
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.01s
                      Time elapsed: 00:39:24
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 48516 steps/s (collection: 1.876s, learning 0.150s)
             Mean action noise std: 3.71
          Mean value_function loss: 81.8894
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 84.0042
                       Mean reward: 307.03
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 54.1590
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.03s
                      Time elapsed: 00:39:26
                               ETA: 00:19:03

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 49168 steps/s (collection: 1.884s, learning 0.116s)
             Mean action noise std: 3.71
          Mean value_function loss: 80.3058
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 84.0228
                       Mean reward: 295.22
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.2205
    Episode_Reward/rotating_object: 62.7727
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.00s
                      Time elapsed: 00:39:28
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 46833 steps/s (collection: 1.944s, learning 0.155s)
             Mean action noise std: 3.71
          Mean value_function loss: 86.3209
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 84.0435
                       Mean reward: 327.91
               Mean episode length: 236.16
    Episode_Reward/reaching_object: 1.2148
    Episode_Reward/rotating_object: 61.5785
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0796
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.10s
                      Time elapsed: 00:39:30
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 42738 steps/s (collection: 2.130s, learning 0.170s)
             Mean action noise std: 3.71
          Mean value_function loss: 92.3224
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 84.0571
                       Mean reward: 290.28
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 56.9601
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.30s
                      Time elapsed: 00:39:33
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 46867 steps/s (collection: 1.980s, learning 0.118s)
             Mean action noise std: 3.72
          Mean value_function loss: 82.6543
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 84.0765
                       Mean reward: 285.14
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 1.1671
    Episode_Reward/rotating_object: 54.9510
        Episode_Reward/action_rate: -0.0935
          Episode_Reward/joint_vel: -0.0763
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.10s
                      Time elapsed: 00:39:35
                               ETA: 00:18:53

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 51103 steps/s (collection: 1.766s, learning 0.158s)
             Mean action noise std: 3.72
          Mean value_function loss: 83.8365
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 84.0912
                       Mean reward: 254.96
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 56.8598
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.92s
                      Time elapsed: 00:39:37
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 48328 steps/s (collection: 1.893s, learning 0.141s)
             Mean action noise std: 3.72
          Mean value_function loss: 77.8210
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 84.1156
                       Mean reward: 293.29
               Mean episode length: 229.45
    Episode_Reward/reaching_object: 1.1968
    Episode_Reward/rotating_object: 58.7731
        Episode_Reward/action_rate: -0.0958
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.03s
                      Time elapsed: 00:39:39
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 48179 steps/s (collection: 1.916s, learning 0.124s)
             Mean action noise std: 3.73
          Mean value_function loss: 76.0408
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 84.1463
                       Mean reward: 293.06
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 57.2329
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0788
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.04s
                      Time elapsed: 00:39:41
                               ETA: 00:18:46

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 46713 steps/s (collection: 1.956s, learning 0.149s)
             Mean action noise std: 3.73
          Mean value_function loss: 83.5653
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 84.1639
                       Mean reward: 327.65
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 59.3551
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0805
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.10s
                      Time elapsed: 00:39:43
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 46206 steps/s (collection: 1.992s, learning 0.136s)
             Mean action noise std: 3.73
          Mean value_function loss: 89.1250
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 84.1819
                       Mean reward: 312.30
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 56.7809
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0780
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.13s
                      Time elapsed: 00:39:45
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 46629 steps/s (collection: 1.979s, learning 0.130s)
             Mean action noise std: 3.73
          Mean value_function loss: 83.8532
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 84.1998
                       Mean reward: 352.74
               Mean episode length: 246.78
    Episode_Reward/reaching_object: 1.2355
    Episode_Reward/rotating_object: 63.3982
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0818
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.11s
                      Time elapsed: 00:39:47
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 47854 steps/s (collection: 1.921s, learning 0.133s)
             Mean action noise std: 3.74
          Mean value_function loss: 82.1050
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 84.2151
                       Mean reward: 313.34
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.2108
    Episode_Reward/rotating_object: 59.0037
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.05s
                      Time elapsed: 00:39:49
                               ETA: 00:18:36

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 48871 steps/s (collection: 1.908s, learning 0.104s)
             Mean action noise std: 3.74
          Mean value_function loss: 88.2516
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 84.2359
                       Mean reward: 275.51
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 1.2036
    Episode_Reward/rotating_object: 59.6398
        Episode_Reward/action_rate: -0.0979
          Episode_Reward/joint_vel: -0.0801
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.01s
                      Time elapsed: 00:39:51
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 46748 steps/s (collection: 1.966s, learning 0.137s)
             Mean action noise std: 3.74
          Mean value_function loss: 83.9042
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 84.2493
                       Mean reward: 286.76
               Mean episode length: 224.98
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 57.7822
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0813
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.10s
                      Time elapsed: 00:39:53
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 47179 steps/s (collection: 1.941s, learning 0.143s)
             Mean action noise std: 3.74
          Mean value_function loss: 89.3364
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 84.2570
                       Mean reward: 305.62
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 61.2945
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0822
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.08s
                      Time elapsed: 00:39:55
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 47794 steps/s (collection: 1.941s, learning 0.116s)
             Mean action noise std: 3.74
          Mean value_function loss: 82.1957
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 84.2721
                       Mean reward: 285.21
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 61.4612
        Episode_Reward/action_rate: -0.0986
          Episode_Reward/joint_vel: -0.0808
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.06s
                      Time elapsed: 00:39:57
                               ETA: 00:18:26

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 50475 steps/s (collection: 1.828s, learning 0.119s)
             Mean action noise std: 3.74
          Mean value_function loss: 79.3164
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 84.2919
                       Mean reward: 298.42
               Mean episode length: 231.51
    Episode_Reward/reaching_object: 1.2096
    Episode_Reward/rotating_object: 60.9001
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0830
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.95s
                      Time elapsed: 00:39:59
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 45380 steps/s (collection: 2.029s, learning 0.137s)
             Mean action noise std: 3.75
          Mean value_function loss: 76.4617
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 84.3114
                       Mean reward: 313.27
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.1994
    Episode_Reward/rotating_object: 60.1817
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0832
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.17s
                      Time elapsed: 00:40:02
                               ETA: 00:18:21

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 48394 steps/s (collection: 1.858s, learning 0.174s)
             Mean action noise std: 3.75
          Mean value_function loss: 72.3322
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 84.3361
                       Mean reward: 295.22
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 1.2036
    Episode_Reward/rotating_object: 60.3916
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0824
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.03s
                      Time elapsed: 00:40:04
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 44864 steps/s (collection: 2.093s, learning 0.098s)
             Mean action noise std: 3.75
          Mean value_function loss: 69.2152
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.3572
                       Mean reward: 260.79
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.1908
    Episode_Reward/rotating_object: 59.1824
        Episode_Reward/action_rate: -0.0986
          Episode_Reward/joint_vel: -0.0814
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.19s
                      Time elapsed: 00:40:06
                               ETA: 00:18:16

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 47249 steps/s (collection: 1.932s, learning 0.149s)
             Mean action noise std: 3.76
          Mean value_function loss: 75.2674
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 84.3744
                       Mean reward: 279.61
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 58.6176
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0811
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.08s
                      Time elapsed: 00:40:08
                               ETA: 00:18:14

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 48884 steps/s (collection: 1.873s, learning 0.138s)
             Mean action noise std: 3.76
          Mean value_function loss: 66.7176
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 84.3983
                       Mean reward: 310.73
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.1998
    Episode_Reward/rotating_object: 66.5215
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0823
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.01s
                      Time elapsed: 00:40:10
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 43993 steps/s (collection: 2.056s, learning 0.178s)
             Mean action noise std: 3.76
          Mean value_function loss: 76.0419
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 84.4221
                       Mean reward: 302.53
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.1879
    Episode_Reward/rotating_object: 60.2103
        Episode_Reward/action_rate: -0.1006
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.23s
                      Time elapsed: 00:40:12
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 47966 steps/s (collection: 1.929s, learning 0.120s)
             Mean action noise std: 3.76
          Mean value_function loss: 76.2371
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 84.4428
                       Mean reward: 308.97
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.1919
    Episode_Reward/rotating_object: 60.3542
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0821
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.05s
                      Time elapsed: 00:40:14
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 47774 steps/s (collection: 1.927s, learning 0.131s)
             Mean action noise std: 3.77
          Mean value_function loss: 82.1554
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 84.4622
                       Mean reward: 331.67
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 1.1901
    Episode_Reward/rotating_object: 61.0777
        Episode_Reward/action_rate: -0.0998
          Episode_Reward/joint_vel: -0.0824
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.06s
                      Time elapsed: 00:40:16
                               ETA: 00:18:04

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 48235 steps/s (collection: 1.929s, learning 0.109s)
             Mean action noise std: 3.77
          Mean value_function loss: 75.3125
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 84.4952
                       Mean reward: 309.14
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 1.1712
    Episode_Reward/rotating_object: 60.5909
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0822
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.04s
                      Time elapsed: 00:40:18
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 46630 steps/s (collection: 1.986s, learning 0.123s)
             Mean action noise std: 3.77
          Mean value_function loss: 71.4820
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 84.5186
                       Mean reward: 240.01
               Mean episode length: 219.17
    Episode_Reward/reaching_object: 1.1695
    Episode_Reward/rotating_object: 55.7399
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0829
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.11s
                      Time elapsed: 00:40:20
                               ETA: 00:17:59

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 47389 steps/s (collection: 1.929s, learning 0.146s)
             Mean action noise std: 3.78
          Mean value_function loss: 77.3614
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 84.5381
                       Mean reward: 323.14
               Mean episode length: 236.54
    Episode_Reward/reaching_object: 1.1826
    Episode_Reward/rotating_object: 60.2630
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0828
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.07s
                      Time elapsed: 00:40:22
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 48642 steps/s (collection: 1.899s, learning 0.122s)
             Mean action noise std: 3.78
          Mean value_function loss: 74.7000
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 84.5532
                       Mean reward: 308.28
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.1758
    Episode_Reward/rotating_object: 58.7407
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0823
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.02s
                      Time elapsed: 00:40:24
                               ETA: 00:17:54

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 42785 steps/s (collection: 2.114s, learning 0.184s)
             Mean action noise std: 3.78
          Mean value_function loss: 73.2152
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.5720
                       Mean reward: 304.46
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 60.2063
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0862
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.30s
                      Time elapsed: 00:40:27
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 47630 steps/s (collection: 1.936s, learning 0.128s)
             Mean action noise std: 3.78
          Mean value_function loss: 79.8195
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 84.5900
                       Mean reward: 333.71
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.1741
    Episode_Reward/rotating_object: 62.5961
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0829
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.06s
                      Time elapsed: 00:40:29
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 44071 steps/s (collection: 2.123s, learning 0.107s)
             Mean action noise std: 3.79
          Mean value_function loss: 75.8277
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 84.6095
                       Mean reward: 288.04
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 59.3761
        Episode_Reward/action_rate: -0.0989
          Episode_Reward/joint_vel: -0.0819
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.23s
                      Time elapsed: 00:40:31
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 47545 steps/s (collection: 1.960s, learning 0.108s)
             Mean action noise std: 3.79
          Mean value_function loss: 73.3953
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 84.6368
                       Mean reward: 302.03
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 1.1851
    Episode_Reward/rotating_object: 59.9792
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0838
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.07s
                      Time elapsed: 00:40:33
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 48003 steps/s (collection: 1.951s, learning 0.097s)
             Mean action noise std: 3.79
          Mean value_function loss: 85.1085
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 84.6582
                       Mean reward: 292.10
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.1851
    Episode_Reward/rotating_object: 55.6095
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0861
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.05s
                      Time elapsed: 00:40:35
                               ETA: 00:17:42

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 48004 steps/s (collection: 1.883s, learning 0.165s)
             Mean action noise std: 3.79
          Mean value_function loss: 80.2712
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 84.6780
                       Mean reward: 283.60
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.2098
    Episode_Reward/rotating_object: 59.4415
        Episode_Reward/action_rate: -0.1041
          Episode_Reward/joint_vel: -0.0869
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.05s
                      Time elapsed: 00:40:37
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 41293 steps/s (collection: 2.282s, learning 0.099s)
             Mean action noise std: 3.80
          Mean value_function loss: 85.1330
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 84.7053
                       Mean reward: 315.03
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.1963
    Episode_Reward/rotating_object: 63.0222
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0858
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.38s
                      Time elapsed: 00:40:40
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 46767 steps/s (collection: 1.935s, learning 0.167s)
             Mean action noise std: 3.80
          Mean value_function loss: 80.7156
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 84.7373
                       Mean reward: 292.19
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.1924
    Episode_Reward/rotating_object: 57.4840
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0862
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.10s
                      Time elapsed: 00:40:42
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 46902 steps/s (collection: 1.941s, learning 0.155s)
             Mean action noise std: 3.81
          Mean value_function loss: 72.2122
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 84.7689
                       Mean reward: 301.61
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 65.5801
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0863
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.10s
                      Time elapsed: 00:40:44
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 47661 steps/s (collection: 1.921s, learning 0.141s)
             Mean action noise std: 3.81
          Mean value_function loss: 81.7878
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.7897
                       Mean reward: 291.09
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 61.5053
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0869
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.06s
                      Time elapsed: 00:40:46
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 47444 steps/s (collection: 1.937s, learning 0.135s)
             Mean action noise std: 3.81
          Mean value_function loss: 92.7289
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 84.8054
                       Mean reward: 288.13
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.1906
    Episode_Reward/rotating_object: 61.5740
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0867
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.07s
                      Time elapsed: 00:40:48
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 47721 steps/s (collection: 1.925s, learning 0.135s)
             Mean action noise std: 3.81
          Mean value_function loss: 83.2172
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 84.8249
                       Mean reward: 345.71
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.2077
    Episode_Reward/rotating_object: 60.7971
        Episode_Reward/action_rate: -0.1038
          Episode_Reward/joint_vel: -0.0867
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.06s
                      Time elapsed: 00:40:50
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 46783 steps/s (collection: 1.963s, learning 0.138s)
             Mean action noise std: 3.82
          Mean value_function loss: 81.2772
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 84.8505
                       Mean reward: 299.03
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.1916
    Episode_Reward/rotating_object: 61.9426
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0856
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.10s
                      Time elapsed: 00:40:52
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 48427 steps/s (collection: 1.877s, learning 0.153s)
             Mean action noise std: 3.82
          Mean value_function loss: 82.3049
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 84.8686
                       Mean reward: 303.40
               Mean episode length: 227.90
    Episode_Reward/reaching_object: 1.1840
    Episode_Reward/rotating_object: 63.6507
        Episode_Reward/action_rate: -0.1016
          Episode_Reward/joint_vel: -0.0865
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.03s
                      Time elapsed: 00:40:54
                               ETA: 00:17:20

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 46035 steps/s (collection: 1.995s, learning 0.141s)
             Mean action noise std: 3.82
          Mean value_function loss: 84.1028
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 84.8865
                       Mean reward: 318.42
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 57.8974
        Episode_Reward/action_rate: -0.1044
          Episode_Reward/joint_vel: -0.0855
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.14s
                      Time elapsed: 00:40:56
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 46867 steps/s (collection: 1.982s, learning 0.115s)
             Mean action noise std: 3.82
          Mean value_function loss: 81.6315
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 84.9039
                       Mean reward: 343.25
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 1.2021
    Episode_Reward/rotating_object: 63.1442
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0855
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.10s
                      Time elapsed: 00:40:58
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 46793 steps/s (collection: 1.973s, learning 0.128s)
             Mean action noise std: 3.83
          Mean value_function loss: 79.9762
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 84.9203
                       Mean reward: 313.38
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.2012
    Episode_Reward/rotating_object: 62.7501
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0848
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.10s
                      Time elapsed: 00:41:00
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 45770 steps/s (collection: 2.016s, learning 0.132s)
             Mean action noise std: 3.83
          Mean value_function loss: 84.9208
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 84.9376
                       Mean reward: 297.29
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.1952
    Episode_Reward/rotating_object: 56.9000
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0846
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.15s
                      Time elapsed: 00:41:03
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 43610 steps/s (collection: 2.128s, learning 0.127s)
             Mean action noise std: 3.83
          Mean value_function loss: 85.1434
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 84.9568
                       Mean reward: 261.90
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.1927
    Episode_Reward/rotating_object: 59.3012
        Episode_Reward/action_rate: -0.1038
          Episode_Reward/joint_vel: -0.0831
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.25s
                      Time elapsed: 00:41:05
                               ETA: 00:17:08

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 49179 steps/s (collection: 1.852s, learning 0.147s)
             Mean action noise std: 3.83
          Mean value_function loss: 85.2288
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 84.9760
                       Mean reward: 339.01
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 62.9930
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0821
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.00s
                      Time elapsed: 00:41:07
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 49207 steps/s (collection: 1.884s, learning 0.114s)
             Mean action noise std: 3.84
          Mean value_function loss: 90.4920
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 84.9969
                       Mean reward: 323.33
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 62.9368
        Episode_Reward/action_rate: -0.1043
          Episode_Reward/joint_vel: -0.0830
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.00s
                      Time elapsed: 00:41:09
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 48625 steps/s (collection: 1.880s, learning 0.142s)
             Mean action noise std: 3.84
          Mean value_function loss: 81.7917
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 85.0135
                       Mean reward: 313.95
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 65.5083
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0833
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.02s
                      Time elapsed: 00:41:11
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 47100 steps/s (collection: 1.932s, learning 0.155s)
             Mean action noise std: 3.84
          Mean value_function loss: 83.4679
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 85.0314
                       Mean reward: 255.87
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 57.7572
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0800
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.09s
                      Time elapsed: 00:41:13
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 48113 steps/s (collection: 1.866s, learning 0.177s)
             Mean action noise std: 3.84
          Mean value_function loss: 88.5882
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 85.0572
                       Mean reward: 323.13
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 57.3174
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0806
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.04s
                      Time elapsed: 00:41:15
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 48405 steps/s (collection: 1.862s, learning 0.169s)
             Mean action noise std: 3.84
          Mean value_function loss: 82.7499
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 85.0732
                       Mean reward: 322.09
               Mean episode length: 227.52
    Episode_Reward/reaching_object: 1.1818
    Episode_Reward/rotating_object: 62.7700
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0811
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.03s
                      Time elapsed: 00:41:17
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 44047 steps/s (collection: 2.079s, learning 0.153s)
             Mean action noise std: 3.85
          Mean value_function loss: 83.7076
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 85.0973
                       Mean reward: 318.61
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 1.1859
    Episode_Reward/rotating_object: 61.3775
        Episode_Reward/action_rate: -0.1041
          Episode_Reward/joint_vel: -0.0819
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.23s
                      Time elapsed: 00:41:19
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 41737 steps/s (collection: 2.226s, learning 0.129s)
             Mean action noise std: 3.85
          Mean value_function loss: 88.7872
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 85.1256
                       Mean reward: 326.96
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 63.6450
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0814
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.36s
                      Time elapsed: 00:41:22
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 47739 steps/s (collection: 1.923s, learning 0.137s)
             Mean action noise std: 3.85
          Mean value_function loss: 82.7567
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 85.1416
                       Mean reward: 301.30
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 63.9504
        Episode_Reward/action_rate: -0.1058
          Episode_Reward/joint_vel: -0.0847
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.06s
                      Time elapsed: 00:41:24
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 42940 steps/s (collection: 2.174s, learning 0.115s)
             Mean action noise std: 3.85
          Mean value_function loss: 84.7320
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 85.1539
                       Mean reward: 282.02
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 65.1793
        Episode_Reward/action_rate: -0.1052
          Episode_Reward/joint_vel: -0.0835
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.29s
                      Time elapsed: 00:41:26
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 47829 steps/s (collection: 1.922s, learning 0.133s)
             Mean action noise std: 3.86
          Mean value_function loss: 77.9983
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 85.1700
                       Mean reward: 337.72
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.1739
    Episode_Reward/rotating_object: 60.6685
        Episode_Reward/action_rate: -0.1047
          Episode_Reward/joint_vel: -0.0845
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.06s
                      Time elapsed: 00:41:28
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 47869 steps/s (collection: 1.880s, learning 0.173s)
             Mean action noise std: 3.86
          Mean value_function loss: 80.3960
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 85.1914
                       Mean reward: 281.30
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 1.1829
    Episode_Reward/rotating_object: 61.0300
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0845
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.05s
                      Time elapsed: 00:41:30
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 47466 steps/s (collection: 1.899s, learning 0.172s)
             Mean action noise std: 3.86
          Mean value_function loss: 82.0278
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 85.2186
                       Mean reward: 312.99
               Mean episode length: 226.93
    Episode_Reward/reaching_object: 1.1875
    Episode_Reward/rotating_object: 60.4108
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0870
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.07s
                      Time elapsed: 00:41:32
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 48404 steps/s (collection: 1.898s, learning 0.133s)
             Mean action noise std: 3.87
          Mean value_function loss: 85.0272
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 85.2424
                       Mean reward: 312.34
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 1.1989
    Episode_Reward/rotating_object: 62.7289
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0868
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.03s
                      Time elapsed: 00:41:34
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 50466 steps/s (collection: 1.784s, learning 0.164s)
             Mean action noise std: 3.87
          Mean value_function loss: 81.5640
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 85.2611
                       Mean reward: 308.42
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 1.1669
    Episode_Reward/rotating_object: 58.7720
        Episode_Reward/action_rate: -0.1040
          Episode_Reward/joint_vel: -0.0850
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.95s
                      Time elapsed: 00:41:36
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 46901 steps/s (collection: 1.966s, learning 0.130s)
             Mean action noise std: 3.87
          Mean value_function loss: 84.4430
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 85.2817
                       Mean reward: 307.48
               Mean episode length: 224.75
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 59.5878
        Episode_Reward/action_rate: -0.1062
          Episode_Reward/joint_vel: -0.0856
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.10s
                      Time elapsed: 00:41:38
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 49115 steps/s (collection: 1.871s, learning 0.131s)
             Mean action noise std: 3.87
          Mean value_function loss: 84.9095
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 85.2955
                       Mean reward: 324.87
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 61.4017
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0897
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.00s
                      Time elapsed: 00:41:40
                               ETA: 00:16:27

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 48907 steps/s (collection: 1.871s, learning 0.139s)
             Mean action noise std: 3.88
          Mean value_function loss: 78.1363
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 85.3107
                       Mean reward: 302.24
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.1961
    Episode_Reward/rotating_object: 62.7619
        Episode_Reward/action_rate: -0.1065
          Episode_Reward/joint_vel: -0.0880
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.01s
                      Time elapsed: 00:41:42
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 48152 steps/s (collection: 1.917s, learning 0.125s)
             Mean action noise std: 3.88
          Mean value_function loss: 80.0823
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 85.3335
                       Mean reward: 297.14
               Mean episode length: 227.04
    Episode_Reward/reaching_object: 1.1820
    Episode_Reward/rotating_object: 61.3983
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0858
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.04s
                      Time elapsed: 00:41:44
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 47060 steps/s (collection: 1.963s, learning 0.126s)
             Mean action noise std: 3.88
          Mean value_function loss: 80.2413
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 85.3475
                       Mean reward: 319.50
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 60.0204
        Episode_Reward/action_rate: -0.1067
          Episode_Reward/joint_vel: -0.0870
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.09s
                      Time elapsed: 00:41:46
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 47017 steps/s (collection: 1.960s, learning 0.131s)
             Mean action noise std: 3.88
          Mean value_function loss: 87.3552
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 85.3612
                       Mean reward: 262.23
               Mean episode length: 225.70
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 60.2139
        Episode_Reward/action_rate: -0.1068
          Episode_Reward/joint_vel: -0.0860
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.09s
                      Time elapsed: 00:41:48
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 44564 steps/s (collection: 2.066s, learning 0.139s)
             Mean action noise std: 3.89
          Mean value_function loss: 86.9273
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 85.3805
                       Mean reward: 325.90
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 1.1841
    Episode_Reward/rotating_object: 64.0486
        Episode_Reward/action_rate: -0.1058
          Episode_Reward/joint_vel: -0.0863
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.21s
                      Time elapsed: 00:41:51
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 45573 steps/s (collection: 2.036s, learning 0.121s)
             Mean action noise std: 3.89
          Mean value_function loss: 90.1604
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 85.3948
                       Mean reward: 291.45
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.1842
    Episode_Reward/rotating_object: 63.1134
        Episode_Reward/action_rate: -0.1062
          Episode_Reward/joint_vel: -0.0858
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.16s
                      Time elapsed: 00:41:53
                               ETA: 00:16:13

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 45142 steps/s (collection: 2.002s, learning 0.176s)
             Mean action noise std: 3.89
          Mean value_function loss: 81.8446
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 85.4130
                       Mean reward: 296.16
               Mean episode length: 226.74
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 59.8038
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0848
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.18s
                      Time elapsed: 00:41:55
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 46040 steps/s (collection: 2.019s, learning 0.116s)
             Mean action noise std: 3.89
          Mean value_function loss: 80.2117
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 85.4315
                       Mean reward: 327.99
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 1.1495
    Episode_Reward/rotating_object: 60.4050
        Episode_Reward/action_rate: -0.1041
          Episode_Reward/joint_vel: -0.0833
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.14s
                      Time elapsed: 00:41:57
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 44287 steps/s (collection: 2.013s, learning 0.207s)
             Mean action noise std: 3.89
          Mean value_function loss: 79.0866
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 85.4461
                       Mean reward: 331.35
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 1.2114
    Episode_Reward/rotating_object: 62.5581
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0870
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.22s
                      Time elapsed: 00:41:59
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 43785 steps/s (collection: 2.111s, learning 0.135s)
             Mean action noise std: 3.90
          Mean value_function loss: 79.8121
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 85.4691
                       Mean reward: 318.90
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 1.1677
    Episode_Reward/rotating_object: 63.6974
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0829
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.25s
                      Time elapsed: 00:42:02
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 45971 steps/s (collection: 2.009s, learning 0.129s)
             Mean action noise std: 3.90
          Mean value_function loss: 80.7399
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 85.4922
                       Mean reward: 313.50
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 1.1621
    Episode_Reward/rotating_object: 61.4088
        Episode_Reward/action_rate: -0.1052
          Episode_Reward/joint_vel: -0.0824
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.14s
                      Time elapsed: 00:42:04
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 46880 steps/s (collection: 1.975s, learning 0.122s)
             Mean action noise std: 3.90
          Mean value_function loss: 81.7349
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 85.5061
                       Mean reward: 327.58
               Mean episode length: 229.42
    Episode_Reward/reaching_object: 1.1819
    Episode_Reward/rotating_object: 62.7165
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0844
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.10s
                      Time elapsed: 00:42:06
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 45198 steps/s (collection: 2.009s, learning 0.166s)
             Mean action noise std: 3.90
          Mean value_function loss: 85.0031
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 85.5247
                       Mean reward: 340.49
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 1.1879
    Episode_Reward/rotating_object: 61.4950
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0856
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.17s
                      Time elapsed: 00:42:08
                               ETA: 00:15:56

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 46089 steps/s (collection: 1.964s, learning 0.169s)
             Mean action noise std: 3.91
          Mean value_function loss: 80.7184
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 85.5452
                       Mean reward: 300.23
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.1681
    Episode_Reward/rotating_object: 59.6932
        Episode_Reward/action_rate: -0.1072
          Episode_Reward/joint_vel: -0.0846
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.13s
                      Time elapsed: 00:42:10
                               ETA: 00:15:54

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 47107 steps/s (collection: 1.947s, learning 0.140s)
             Mean action noise std: 3.91
          Mean value_function loss: 88.2900
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 85.5611
                       Mean reward: 302.78
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 63.4212
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0864
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.09s
                      Time elapsed: 00:42:12
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 46170 steps/s (collection: 1.962s, learning 0.167s)
             Mean action noise std: 3.91
          Mean value_function loss: 83.0149
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 85.5779
                       Mean reward: 305.35
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 60.0583
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0858
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.13s
                      Time elapsed: 00:42:14
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 47541 steps/s (collection: 1.960s, learning 0.108s)
             Mean action noise std: 3.91
          Mean value_function loss: 89.0983
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 85.5978
                       Mean reward: 274.02
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.1905
    Episode_Reward/rotating_object: 62.4578
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0850
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.07s
                      Time elapsed: 00:42:16
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 48295 steps/s (collection: 1.908s, learning 0.127s)
             Mean action noise std: 3.92
          Mean value_function loss: 96.3595
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 85.6168
                       Mean reward: 258.56
               Mean episode length: 219.87
    Episode_Reward/reaching_object: 1.1576
    Episode_Reward/rotating_object: 58.3831
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0834
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.04s
                      Time elapsed: 00:42:18
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 47779 steps/s (collection: 1.913s, learning 0.145s)
             Mean action noise std: 3.92
          Mean value_function loss: 106.1189
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 85.6358
                       Mean reward: 332.19
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.2072
    Episode_Reward/rotating_object: 63.3276
        Episode_Reward/action_rate: -0.1099
          Episode_Reward/joint_vel: -0.0852
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.06s
                      Time elapsed: 00:42:20
                               ETA: 00:15:42

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 47093 steps/s (collection: 1.969s, learning 0.119s)
             Mean action noise std: 3.92
          Mean value_function loss: 88.4550
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 85.6521
                       Mean reward: 317.29
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 64.4030
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0843
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.09s
                      Time elapsed: 00:42:23
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 44518 steps/s (collection: 2.071s, learning 0.137s)
             Mean action noise std: 3.93
          Mean value_function loss: 91.2226
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 85.6698
                       Mean reward: 295.66
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 61.3420
        Episode_Reward/action_rate: -0.1096
          Episode_Reward/joint_vel: -0.0850
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.21s
                      Time elapsed: 00:42:25
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 46407 steps/s (collection: 2.012s, learning 0.106s)
             Mean action noise std: 3.93
          Mean value_function loss: 77.8652
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 85.6868
                       Mean reward: 299.12
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.1917
    Episode_Reward/rotating_object: 63.4493
        Episode_Reward/action_rate: -0.1084
          Episode_Reward/joint_vel: -0.0833
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.12s
                      Time elapsed: 00:42:27
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 45797 steps/s (collection: 1.910s, learning 0.236s)
             Mean action noise std: 3.93
          Mean value_function loss: 87.8602
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 85.6951
                       Mean reward: 313.28
               Mean episode length: 224.53
    Episode_Reward/reaching_object: 1.1694
    Episode_Reward/rotating_object: 62.5355
        Episode_Reward/action_rate: -0.1065
          Episode_Reward/joint_vel: -0.0808
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.15s
                      Time elapsed: 00:42:29
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 44941 steps/s (collection: 2.031s, learning 0.156s)
             Mean action noise std: 3.93
          Mean value_function loss: 80.0106
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 85.7076
                       Mean reward: 310.79
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 65.6041
        Episode_Reward/action_rate: -0.1099
          Episode_Reward/joint_vel: -0.0842
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.19s
                      Time elapsed: 00:42:31
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 46325 steps/s (collection: 1.957s, learning 0.165s)
             Mean action noise std: 3.93
          Mean value_function loss: 68.0964
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 85.7248
                       Mean reward: 317.50
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.1668
    Episode_Reward/rotating_object: 61.3799
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0822
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.12s
                      Time elapsed: 00:42:33
                               ETA: 00:15:27

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 48083 steps/s (collection: 1.924s, learning 0.120s)
             Mean action noise std: 3.94
          Mean value_function loss: 78.8146
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 85.7408
                       Mean reward: 341.61
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 64.1623
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0825
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.04s
                      Time elapsed: 00:42:35
                               ETA: 00:15:25

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 48787 steps/s (collection: 1.878s, learning 0.137s)
             Mean action noise std: 3.94
          Mean value_function loss: 82.3730
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 85.7661
                       Mean reward: 393.26
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 1.1993
    Episode_Reward/rotating_object: 64.2735
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0833
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.01s
                      Time elapsed: 00:42:37
                               ETA: 00:15:22

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 49262 steps/s (collection: 1.891s, learning 0.104s)
             Mean action noise std: 3.94
          Mean value_function loss: 81.7900
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 85.7896
                       Mean reward: 357.93
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 62.3535
        Episode_Reward/action_rate: -0.1099
          Episode_Reward/joint_vel: -0.0832
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.00s
                      Time elapsed: 00:42:39
                               ETA: 00:15:20

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 48792 steps/s (collection: 1.882s, learning 0.133s)
             Mean action noise std: 3.94
          Mean value_function loss: 86.5559
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 85.8109
                       Mean reward: 353.62
               Mean episode length: 238.57
    Episode_Reward/reaching_object: 1.1765
    Episode_Reward/rotating_object: 60.2558
        Episode_Reward/action_rate: -0.1095
          Episode_Reward/joint_vel: -0.0829
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.01s
                      Time elapsed: 00:42:41
                               ETA: 00:15:18

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 47162 steps/s (collection: 1.967s, learning 0.118s)
             Mean action noise std: 3.95
          Mean value_function loss: 86.9855
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 85.8275
                       Mean reward: 344.31
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.2081
    Episode_Reward/rotating_object: 67.3125
        Episode_Reward/action_rate: -0.1111
          Episode_Reward/joint_vel: -0.0853
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.08s
                      Time elapsed: 00:42:43
                               ETA: 00:15:15

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 43272 steps/s (collection: 2.142s, learning 0.130s)
             Mean action noise std: 3.95
          Mean value_function loss: 87.8647
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 85.8371
                       Mean reward: 310.09
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.1488
    Episode_Reward/rotating_object: 59.0663
        Episode_Reward/action_rate: -0.1063
          Episode_Reward/joint_vel: -0.0809
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.27s
                      Time elapsed: 00:42:46
                               ETA: 00:15:13

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 49891 steps/s (collection: 1.869s, learning 0.102s)
             Mean action noise std: 3.95
          Mean value_function loss: 72.8479
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 85.8499
                       Mean reward: 316.43
               Mean episode length: 235.54
    Episode_Reward/reaching_object: 1.2030
    Episode_Reward/rotating_object: 66.6097
        Episode_Reward/action_rate: -0.1111
          Episode_Reward/joint_vel: -0.0861
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.97s
                      Time elapsed: 00:42:48
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 44329 steps/s (collection: 2.038s, learning 0.179s)
             Mean action noise std: 3.95
          Mean value_function loss: 73.2751
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 85.8703
                       Mean reward: 303.95
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.2019
    Episode_Reward/rotating_object: 62.6398
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0853
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.22s
                      Time elapsed: 00:42:50
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 46737 steps/s (collection: 1.987s, learning 0.117s)
             Mean action noise std: 3.96
          Mean value_function loss: 79.1794
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 85.8991
                       Mean reward: 332.57
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 65.9520
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0858
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.10s
                      Time elapsed: 00:42:52
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 47249 steps/s (collection: 1.942s, learning 0.138s)
             Mean action noise std: 3.96
          Mean value_function loss: 77.2375
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 85.9182
                       Mean reward: 273.18
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.1876
    Episode_Reward/rotating_object: 59.9782
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0852
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.08s
                      Time elapsed: 00:42:54
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 46941 steps/s (collection: 1.911s, learning 0.183s)
             Mean action noise std: 3.96
          Mean value_function loss: 84.3347
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 85.9315
                       Mean reward: 302.32
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.1589
    Episode_Reward/rotating_object: 59.2671
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0831
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.09s
                      Time elapsed: 00:42:56
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 47692 steps/s (collection: 1.916s, learning 0.146s)
             Mean action noise std: 3.96
          Mean value_function loss: 86.1950
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 85.9439
                       Mean reward: 297.75
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 65.1072
        Episode_Reward/action_rate: -0.1099
          Episode_Reward/joint_vel: -0.0845
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.06s
                      Time elapsed: 00:42:58
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 46670 steps/s (collection: 1.938s, learning 0.168s)
             Mean action noise std: 3.96
          Mean value_function loss: 94.7473
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 85.9545
                       Mean reward: 353.63
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 66.4224
        Episode_Reward/action_rate: -0.1093
          Episode_Reward/joint_vel: -0.0847
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.11s
                      Time elapsed: 00:43:00
                               ETA: 00:14:56

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 48108 steps/s (collection: 1.877s, learning 0.167s)
             Mean action noise std: 3.97
          Mean value_function loss: 107.5723
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 85.9722
                       Mean reward: 337.78
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 65.3017
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0855
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.04s
                      Time elapsed: 00:43:02
                               ETA: 00:14:54

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 49373 steps/s (collection: 1.883s, learning 0.108s)
             Mean action noise std: 3.97
          Mean value_function loss: 95.2594
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 85.9904
                       Mean reward: 343.97
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 64.9339
        Episode_Reward/action_rate: -0.1107
          Episode_Reward/joint_vel: -0.0848
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.99s
                      Time elapsed: 00:43:04
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 49973 steps/s (collection: 1.851s, learning 0.116s)
             Mean action noise std: 3.97
          Mean value_function loss: 94.1895
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.0103
                       Mean reward: 328.24
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 62.1324
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0836
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.97s
                      Time elapsed: 00:43:06
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 48610 steps/s (collection: 1.903s, learning 0.119s)
             Mean action noise std: 3.97
          Mean value_function loss: 104.1330
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 86.0303
                       Mean reward: 352.45
               Mean episode length: 226.36
    Episode_Reward/reaching_object: 1.1791
    Episode_Reward/rotating_object: 62.7582
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0819
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.02s
                      Time elapsed: 00:43:08
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 46458 steps/s (collection: 1.983s, learning 0.133s)
             Mean action noise std: 3.98
          Mean value_function loss: 106.7906
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 86.0503
                       Mean reward: 316.19
               Mean episode length: 218.01
    Episode_Reward/reaching_object: 1.1750
    Episode_Reward/rotating_object: 62.2823
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0806
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.12s
                      Time elapsed: 00:43:11
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 46469 steps/s (collection: 1.992s, learning 0.123s)
             Mean action noise std: 3.98
          Mean value_function loss: 112.8804
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 86.0692
                       Mean reward: 297.40
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 1.1681
    Episode_Reward/rotating_object: 60.1436
        Episode_Reward/action_rate: -0.1087
          Episode_Reward/joint_vel: -0.0812
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.12s
                      Time elapsed: 00:43:13
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 49310 steps/s (collection: 1.877s, learning 0.116s)
             Mean action noise std: 3.98
          Mean value_function loss: 98.9516
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 86.0835
                       Mean reward: 349.68
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 64.4131
        Episode_Reward/action_rate: -0.1113
          Episode_Reward/joint_vel: -0.0826
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.99s
                      Time elapsed: 00:43:15
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 47937 steps/s (collection: 1.932s, learning 0.119s)
             Mean action noise std: 3.98
          Mean value_function loss: 88.8575
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 86.0939
                       Mean reward: 296.47
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 62.4875
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0818
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.05s
                      Time elapsed: 00:43:17
                               ETA: 00:14:37

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 49792 steps/s (collection: 1.883s, learning 0.091s)
             Mean action noise std: 3.98
          Mean value_function loss: 114.2183
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.1099
                       Mean reward: 332.22
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.1793
    Episode_Reward/rotating_object: 61.8830
        Episode_Reward/action_rate: -0.1088
          Episode_Reward/joint_vel: -0.0801
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.97s
                      Time elapsed: 00:43:19
                               ETA: 00:14:34

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 47290 steps/s (collection: 1.961s, learning 0.118s)
             Mean action noise std: 3.99
          Mean value_function loss: 100.4970
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 86.1174
                       Mean reward: 337.36
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 63.1771
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0819
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.08s
                      Time elapsed: 00:43:21
                               ETA: 00:14:32

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 46266 steps/s (collection: 1.957s, learning 0.168s)
             Mean action noise std: 3.99
          Mean value_function loss: 88.5824
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.1221
                       Mean reward: 364.60
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 68.9281
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0818
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.12s
                      Time elapsed: 00:43:23
                               ETA: 00:14:30

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 45570 steps/s (collection: 2.015s, learning 0.143s)
             Mean action noise std: 3.99
          Mean value_function loss: 95.8862
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 86.1321
                       Mean reward: 313.13
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.1723
    Episode_Reward/rotating_object: 60.3097
        Episode_Reward/action_rate: -0.1087
          Episode_Reward/joint_vel: -0.0798
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.16s
                      Time elapsed: 00:43:25
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 48067 steps/s (collection: 1.908s, learning 0.137s)
             Mean action noise std: 3.99
          Mean value_function loss: 80.5648
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 86.1411
                       Mean reward: 335.92
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 1.1855
    Episode_Reward/rotating_object: 62.5951
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0812
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.05s
                      Time elapsed: 00:43:27
                               ETA: 00:14:25

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 49066 steps/s (collection: 1.879s, learning 0.124s)
             Mean action noise std: 3.99
          Mean value_function loss: 87.5822
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.1514
                       Mean reward: 336.71
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.1727
    Episode_Reward/rotating_object: 62.7941
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0793
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.00s
                      Time elapsed: 00:43:29
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 49324 steps/s (collection: 1.859s, learning 0.134s)
             Mean action noise std: 3.99
          Mean value_function loss: 95.5606
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 86.1671
                       Mean reward: 324.54
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 1.1789
    Episode_Reward/rotating_object: 64.9349
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0801
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.99s
                      Time elapsed: 00:43:31
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 46852 steps/s (collection: 1.905s, learning 0.193s)
             Mean action noise std: 4.00
          Mean value_function loss: 88.1567
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 86.1857
                       Mean reward: 318.02
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 61.0711
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0816
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.10s
                      Time elapsed: 00:43:33
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 50794 steps/s (collection: 1.831s, learning 0.104s)
             Mean action noise std: 4.00
          Mean value_function loss: 75.3699
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 86.2043
                       Mean reward: 321.35
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.1930
    Episode_Reward/rotating_object: 64.0329
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0808
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.94s
                      Time elapsed: 00:43:35
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 47117 steps/s (collection: 1.952s, learning 0.135s)
             Mean action noise std: 4.00
          Mean value_function loss: 92.3936
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 86.2170
                       Mean reward: 300.11
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 65.3382
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.09s
                      Time elapsed: 00:43:37
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 46730 steps/s (collection: 1.941s, learning 0.163s)
             Mean action noise std: 4.00
          Mean value_function loss: 91.9242
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 86.2311
                       Mean reward: 321.93
               Mean episode length: 229.00
    Episode_Reward/reaching_object: 1.1746
    Episode_Reward/rotating_object: 62.9913
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.10s
                      Time elapsed: 00:43:39
                               ETA: 00:14:10

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 44657 steps/s (collection: 2.025s, learning 0.176s)
             Mean action noise std: 4.00
          Mean value_function loss: 92.1585
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 86.2400
                       Mean reward: 305.86
               Mean episode length: 228.38
    Episode_Reward/reaching_object: 1.1807
    Episode_Reward/rotating_object: 62.4754
        Episode_Reward/action_rate: -0.1111
          Episode_Reward/joint_vel: -0.0798
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.20s
                      Time elapsed: 00:43:41
                               ETA: 00:14:08

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 46609 steps/s (collection: 1.900s, learning 0.209s)
             Mean action noise std: 4.00
          Mean value_function loss: 93.3831
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 86.2485
                       Mean reward: 330.06
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.1612
    Episode_Reward/rotating_object: 61.6046
        Episode_Reward/action_rate: -0.1103
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.11s
                      Time elapsed: 00:43:44
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 46497 steps/s (collection: 1.998s, learning 0.116s)
             Mean action noise std: 4.01
          Mean value_function loss: 102.0306
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 86.2645
                       Mean reward: 288.20
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.1744
    Episode_Reward/rotating_object: 60.7689
        Episode_Reward/action_rate: -0.1104
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.11s
                      Time elapsed: 00:43:46
                               ETA: 00:14:03

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 47283 steps/s (collection: 1.920s, learning 0.159s)
             Mean action noise std: 4.01
          Mean value_function loss: 95.6642
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.2909
                       Mean reward: 333.46
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 1.1668
    Episode_Reward/rotating_object: 59.8388
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0781
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.08s
                      Time elapsed: 00:43:48
                               ETA: 00:14:01

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 44901 steps/s (collection: 2.048s, learning 0.141s)
             Mean action noise std: 4.01
          Mean value_function loss: 102.8100
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 86.3164
                       Mean reward: 316.80
               Mean episode length: 223.57
    Episode_Reward/reaching_object: 1.1473
    Episode_Reward/rotating_object: 59.7860
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.19s
                      Time elapsed: 00:43:50
                               ETA: 00:13:59

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 47037 steps/s (collection: 1.961s, learning 0.129s)
             Mean action noise std: 4.02
          Mean value_function loss: 90.1661
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 86.3416
                       Mean reward: 338.11
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.1618
    Episode_Reward/rotating_object: 61.5167
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.09s
                      Time elapsed: 00:43:52
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 47499 steps/s (collection: 1.940s, learning 0.130s)
             Mean action noise std: 4.02
          Mean value_function loss: 103.3797
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 86.3568
                       Mean reward: 308.67
               Mean episode length: 233.71
    Episode_Reward/reaching_object: 1.1680
    Episode_Reward/rotating_object: 59.2939
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0792
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.07s
                      Time elapsed: 00:43:54
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 48671 steps/s (collection: 1.914s, learning 0.106s)
             Mean action noise std: 4.02
          Mean value_function loss: 84.3443
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 86.3701
                       Mean reward: 305.65
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 1.1731
    Episode_Reward/rotating_object: 58.3255
        Episode_Reward/action_rate: -0.1113
          Episode_Reward/joint_vel: -0.0776
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.02s
                      Time elapsed: 00:43:56
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 48003 steps/s (collection: 1.931s, learning 0.117s)
             Mean action noise std: 4.02
          Mean value_function loss: 91.1057
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 86.3846
                       Mean reward: 301.42
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 60.8306
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.05s
                      Time elapsed: 00:43:58
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 49144 steps/s (collection: 1.880s, learning 0.121s)
             Mean action noise std: 4.03
          Mean value_function loss: 95.9038
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.4025
                       Mean reward: 345.74
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 1.1961
    Episode_Reward/rotating_object: 62.5945
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0795
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.00s
                      Time elapsed: 00:44:00
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 48506 steps/s (collection: 1.872s, learning 0.155s)
             Mean action noise std: 4.03
          Mean value_function loss: 93.8882
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 86.4168
                       Mean reward: 298.19
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 1.1634
    Episode_Reward/rotating_object: 60.6150
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.03s
                      Time elapsed: 00:44:02
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 47889 steps/s (collection: 1.957s, learning 0.096s)
             Mean action noise std: 4.03
          Mean value_function loss: 92.9008
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 86.4313
                       Mean reward: 293.97
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.1758
    Episode_Reward/rotating_object: 61.0209
        Episode_Reward/action_rate: -0.1116
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.05s
                      Time elapsed: 00:44:04
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 49203 steps/s (collection: 1.844s, learning 0.154s)
             Mean action noise std: 4.03
          Mean value_function loss: 90.9866
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.4459
                       Mean reward: 340.46
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 62.3929
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.00s
                      Time elapsed: 00:44:06
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 47139 steps/s (collection: 1.961s, learning 0.124s)
             Mean action noise std: 4.03
          Mean value_function loss: 99.7535
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 86.4621
                       Mean reward: 260.26
               Mean episode length: 228.29
    Episode_Reward/reaching_object: 1.1606
    Episode_Reward/rotating_object: 57.8904
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.09s
                      Time elapsed: 00:44:08
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 50384 steps/s (collection: 1.826s, learning 0.125s)
             Mean action noise std: 4.04
          Mean value_function loss: 101.2942
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 86.4840
                       Mean reward: 368.73
               Mean episode length: 234.15
    Episode_Reward/reaching_object: 1.1779
    Episode_Reward/rotating_object: 65.6724
        Episode_Reward/action_rate: -0.1115
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.95s
                      Time elapsed: 00:44:10
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 50385 steps/s (collection: 1.830s, learning 0.121s)
             Mean action noise std: 4.04
          Mean value_function loss: 89.6448
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 86.4971
                       Mean reward: 314.28
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.1655
    Episode_Reward/rotating_object: 60.4243
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0764
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.95s
                      Time elapsed: 00:44:12
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 50521 steps/s (collection: 1.825s, learning 0.121s)
             Mean action noise std: 4.04
          Mean value_function loss: 88.8059
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 86.5083
                       Mean reward: 296.23
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 1.1775
    Episode_Reward/rotating_object: 62.2699
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.95s
                      Time elapsed: 00:44:14
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 48326 steps/s (collection: 1.918s, learning 0.117s)
             Mean action noise std: 4.04
          Mean value_function loss: 88.8212
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.5230
                       Mean reward: 314.62
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 61.7182
        Episode_Reward/action_rate: -0.1133
          Episode_Reward/joint_vel: -0.0767
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.03s
                      Time elapsed: 00:44:16
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 50946 steps/s (collection: 1.809s, learning 0.121s)
             Mean action noise std: 4.04
          Mean value_function loss: 82.8809
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 86.5410
                       Mean reward: 308.27
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.1749
    Episode_Reward/rotating_object: 59.8680
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.93s
                      Time elapsed: 00:44:18
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 51172 steps/s (collection: 1.803s, learning 0.118s)
             Mean action noise std: 4.05
          Mean value_function loss: 88.8575
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.5533
                       Mean reward: 304.44
               Mean episode length: 234.89
    Episode_Reward/reaching_object: 1.1841
    Episode_Reward/rotating_object: 60.3155
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0770
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.92s
                      Time elapsed: 00:44:20
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 51501 steps/s (collection: 1.789s, learning 0.120s)
             Mean action noise std: 4.05
          Mean value_function loss: 81.0986
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 86.5670
                       Mean reward: 310.09
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.1771
    Episode_Reward/rotating_object: 60.8932
        Episode_Reward/action_rate: -0.1150
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.91s
                      Time elapsed: 00:44:22
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 46900 steps/s (collection: 1.961s, learning 0.135s)
             Mean action noise std: 4.05
          Mean value_function loss: 87.1732
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 86.5837
                       Mean reward: 320.81
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 62.6143
        Episode_Reward/action_rate: -0.1149
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.10s
                      Time elapsed: 00:44:24
                               ETA: 00:13:18

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 47024 steps/s (collection: 1.971s, learning 0.120s)
             Mean action noise std: 4.05
          Mean value_function loss: 77.2626
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 86.5923
                       Mean reward: 296.15
               Mean episode length: 228.98
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 61.1578
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.09s
                      Time elapsed: 00:44:26
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 50765 steps/s (collection: 1.822s, learning 0.115s)
             Mean action noise std: 4.05
          Mean value_function loss: 90.0605
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 86.6003
                       Mean reward: 337.55
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 65.0040
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.94s
                      Time elapsed: 00:44:28
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 41301 steps/s (collection: 2.191s, learning 0.190s)
             Mean action noise std: 4.05
          Mean value_function loss: 80.9587
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 86.6079
                       Mean reward: 299.95
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 61.5882
        Episode_Reward/action_rate: -0.1146
          Episode_Reward/joint_vel: -0.0772
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.38s
                      Time elapsed: 00:44:31
                               ETA: 00:13:11

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 42713 steps/s (collection: 2.065s, learning 0.237s)
             Mean action noise std: 4.05
          Mean value_function loss: 90.6933
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 86.6148
                       Mean reward: 344.72
               Mean episode length: 223.38
    Episode_Reward/reaching_object: 1.1540
    Episode_Reward/rotating_object: 64.6853
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.30s
                      Time elapsed: 00:44:33
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 49972 steps/s (collection: 1.857s, learning 0.110s)
             Mean action noise std: 4.06
          Mean value_function loss: 86.7062
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.6221
                       Mean reward: 345.13
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 1.1826
    Episode_Reward/rotating_object: 63.2001
        Episode_Reward/action_rate: -0.1144
          Episode_Reward/joint_vel: -0.0761
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.97s
                      Time elapsed: 00:44:35
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 46488 steps/s (collection: 1.986s, learning 0.129s)
             Mean action noise std: 4.06
          Mean value_function loss: 92.0460
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 86.6324
                       Mean reward: 340.86
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.1695
    Episode_Reward/rotating_object: 63.3865
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0760
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.11s
                      Time elapsed: 00:44:37
                               ETA: 00:13:04

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 45787 steps/s (collection: 2.023s, learning 0.124s)
             Mean action noise std: 4.06
          Mean value_function loss: 86.4349
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 86.6466
                       Mean reward: 316.55
               Mean episode length: 224.17
    Episode_Reward/reaching_object: 1.1605
    Episode_Reward/rotating_object: 63.1153
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0748
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.15s
                      Time elapsed: 00:44:39
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 46071 steps/s (collection: 2.036s, learning 0.098s)
             Mean action noise std: 4.06
          Mean value_function loss: 90.9695
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.6678
                       Mean reward: 343.39
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 1.2053
    Episode_Reward/rotating_object: 63.8410
        Episode_Reward/action_rate: -0.1169
          Episode_Reward/joint_vel: -0.0786
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.13s
                      Time elapsed: 00:44:41
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 47188 steps/s (collection: 1.935s, learning 0.148s)
             Mean action noise std: 4.07
          Mean value_function loss: 79.0580
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 86.6841
                       Mean reward: 384.34
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 1.1594
    Episode_Reward/rotating_object: 66.7502
        Episode_Reward/action_rate: -0.1121
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.08s
                      Time elapsed: 00:44:43
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 45468 steps/s (collection: 2.031s, learning 0.131s)
             Mean action noise std: 4.07
          Mean value_function loss: 74.2875
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 86.7029
                       Mean reward: 300.32
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 64.1273
        Episode_Reward/action_rate: -0.1136
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.16s
                      Time elapsed: 00:44:45
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 48244 steps/s (collection: 1.925s, learning 0.113s)
             Mean action noise std: 4.07
          Mean value_function loss: 76.2664
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 86.7237
                       Mean reward: 270.50
               Mean episode length: 220.70
    Episode_Reward/reaching_object: 1.1723
    Episode_Reward/rotating_object: 61.8784
        Episode_Reward/action_rate: -0.1135
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.04s
                      Time elapsed: 00:44:47
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 41988 steps/s (collection: 2.219s, learning 0.122s)
             Mean action noise std: 4.08
          Mean value_function loss: 89.2725
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.7465
                       Mean reward: 335.42
               Mean episode length: 231.78
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 64.8842
        Episode_Reward/action_rate: -0.1140
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.34s
                      Time elapsed: 00:44:50
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 47853 steps/s (collection: 1.895s, learning 0.159s)
             Mean action noise std: 4.08
          Mean value_function loss: 101.2915
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.7716
                       Mean reward: 324.65
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.1911
    Episode_Reward/rotating_object: 65.9791
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0775
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.05s
                      Time elapsed: 00:44:52
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 45655 steps/s (collection: 2.026s, learning 0.128s)
             Mean action noise std: 4.08
          Mean value_function loss: 100.3390
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 86.7908
                       Mean reward: 364.00
               Mean episode length: 232.04
    Episode_Reward/reaching_object: 1.1533
    Episode_Reward/rotating_object: 62.2341
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0757
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.15s
                      Time elapsed: 00:44:54
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 46416 steps/s (collection: 1.978s, learning 0.140s)
             Mean action noise std: 4.08
          Mean value_function loss: 96.6328
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.8076
                       Mean reward: 301.84
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.1695
    Episode_Reward/rotating_object: 61.2292
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.12s
                      Time elapsed: 00:44:56
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 47610 steps/s (collection: 1.944s, learning 0.121s)
             Mean action noise std: 4.08
          Mean value_function loss: 88.9745
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 86.8232
                       Mean reward: 332.38
               Mean episode length: 224.34
    Episode_Reward/reaching_object: 1.1552
    Episode_Reward/rotating_object: 62.2524
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.06s
                      Time elapsed: 00:44:58
                               ETA: 00:12:40

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 46776 steps/s (collection: 1.972s, learning 0.130s)
             Mean action noise std: 4.09
          Mean value_function loss: 86.8557
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 86.8341
                       Mean reward: 327.42
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 64.8272
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0798
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.10s
                      Time elapsed: 00:45:00
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 43583 steps/s (collection: 2.132s, learning 0.123s)
             Mean action noise std: 4.09
          Mean value_function loss: 83.0692
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 86.8442
                       Mean reward: 334.11
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.2010
    Episode_Reward/rotating_object: 62.5030
        Episode_Reward/action_rate: -0.1167
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.26s
                      Time elapsed: 00:45:03
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 46928 steps/s (collection: 1.984s, learning 0.111s)
             Mean action noise std: 4.09
          Mean value_function loss: 92.1524
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 86.8633
                       Mean reward: 319.49
               Mean episode length: 227.55
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 63.9924
        Episode_Reward/action_rate: -0.1168
          Episode_Reward/joint_vel: -0.0779
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.09s
                      Time elapsed: 00:45:05
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 44928 steps/s (collection: 2.065s, learning 0.123s)
             Mean action noise std: 4.09
          Mean value_function loss: 82.2441
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 86.8789
                       Mean reward: 266.35
               Mean episode length: 213.30
    Episode_Reward/reaching_object: 1.1744
    Episode_Reward/rotating_object: 59.9069
        Episode_Reward/action_rate: -0.1140
          Episode_Reward/joint_vel: -0.0761
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.19s
                      Time elapsed: 00:45:07
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 41338 steps/s (collection: 2.211s, learning 0.167s)
             Mean action noise std: 4.09
          Mean value_function loss: 78.2982
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.8919
                       Mean reward: 353.70
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 65.6766
        Episode_Reward/action_rate: -0.1166
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.38s
                      Time elapsed: 00:45:09
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 40284 steps/s (collection: 2.300s, learning 0.141s)
             Mean action noise std: 4.10
          Mean value_function loss: 72.1604
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 86.9078
                       Mean reward: 311.28
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 1.2190
    Episode_Reward/rotating_object: 65.3762
        Episode_Reward/action_rate: -0.1190
          Episode_Reward/joint_vel: -0.0805
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.44s
                      Time elapsed: 00:45:12
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 44015 steps/s (collection: 2.066s, learning 0.167s)
             Mean action noise std: 4.10
          Mean value_function loss: 80.5740
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 86.9166
                       Mean reward: 333.68
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 64.2580
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0796
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.23s
                      Time elapsed: 00:45:14
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 49044 steps/s (collection: 1.883s, learning 0.121s)
             Mean action noise std: 4.10
          Mean value_function loss: 71.0704
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 86.9298
                       Mean reward: 280.36
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.1950
    Episode_Reward/rotating_object: 62.1357
        Episode_Reward/action_rate: -0.1179
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.00s
                      Time elapsed: 00:45:16
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 50012 steps/s (collection: 1.853s, learning 0.113s)
             Mean action noise std: 4.10
          Mean value_function loss: 75.7575
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.9536
                       Mean reward: 314.18
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 62.9193
        Episode_Reward/action_rate: -0.1174
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.97s
                      Time elapsed: 00:45:18
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 42297 steps/s (collection: 2.104s, learning 0.220s)
             Mean action noise std: 4.11
          Mean value_function loss: 80.5326
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.9677
                       Mean reward: 338.72
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 1.1753
    Episode_Reward/rotating_object: 64.3271
        Episode_Reward/action_rate: -0.1161
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.32s
                      Time elapsed: 00:45:20
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 45273 steps/s (collection: 2.044s, learning 0.127s)
             Mean action noise std: 4.11
          Mean value_function loss: 79.6532
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.9781
                       Mean reward: 352.96
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 1.1881
    Episode_Reward/rotating_object: 67.6801
        Episode_Reward/action_rate: -0.1179
          Episode_Reward/joint_vel: -0.0764
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.17s
                      Time elapsed: 00:45:22
                               ETA: 00:12:14

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 43744 steps/s (collection: 2.074s, learning 0.174s)
             Mean action noise std: 4.11
          Mean value_function loss: 75.9544
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 86.9914
                       Mean reward: 321.09
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.1977
    Episode_Reward/rotating_object: 64.5440
        Episode_Reward/action_rate: -0.1191
          Episode_Reward/joint_vel: -0.0777
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.25s
                      Time elapsed: 00:45:25
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 48340 steps/s (collection: 1.936s, learning 0.098s)
             Mean action noise std: 4.11
          Mean value_function loss: 85.6731
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 87.0053
                       Mean reward: 357.74
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 65.7102
        Episode_Reward/action_rate: -0.1187
          Episode_Reward/joint_vel: -0.0769
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.03s
                      Time elapsed: 00:45:27
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 48725 steps/s (collection: 1.886s, learning 0.132s)
             Mean action noise std: 4.11
          Mean value_function loss: 96.2602
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 87.0165
                       Mean reward: 349.70
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 1.1839
    Episode_Reward/rotating_object: 67.4512
        Episode_Reward/action_rate: -0.1176
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.02s
                      Time elapsed: 00:45:29
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 45508 steps/s (collection: 2.040s, learning 0.121s)
             Mean action noise std: 4.11
          Mean value_function loss: 92.4635
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 87.0275
                       Mean reward: 291.22
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 63.1481
        Episode_Reward/action_rate: -0.1195
          Episode_Reward/joint_vel: -0.0786
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.16s
                      Time elapsed: 00:45:31
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 43957 steps/s (collection: 2.090s, learning 0.147s)
             Mean action noise std: 4.11
          Mean value_function loss: 100.9920
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 87.0338
                       Mean reward: 343.16
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 67.3333
        Episode_Reward/action_rate: -0.1195
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.24s
                      Time elapsed: 00:45:33
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 48613 steps/s (collection: 1.909s, learning 0.113s)
             Mean action noise std: 4.12
          Mean value_function loss: 110.1121
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 87.0426
                       Mean reward: 313.26
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 66.4748
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.02s
                      Time elapsed: 00:45:35
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 47640 steps/s (collection: 1.963s, learning 0.100s)
             Mean action noise std: 4.12
          Mean value_function loss: 84.3156
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 87.0559
                       Mean reward: 355.23
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.2020
    Episode_Reward/rotating_object: 68.2034
        Episode_Reward/action_rate: -0.1164
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.06s
                      Time elapsed: 00:45:37
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 45122 steps/s (collection: 2.061s, learning 0.118s)
             Mean action noise std: 4.12
          Mean value_function loss: 96.1521
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 87.0705
                       Mean reward: 369.61
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.2005
    Episode_Reward/rotating_object: 67.0359
        Episode_Reward/action_rate: -0.1169
          Episode_Reward/joint_vel: -0.0766
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.18s
                      Time elapsed: 00:45:39
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 47524 steps/s (collection: 1.963s, learning 0.106s)
             Mean action noise std: 4.12
          Mean value_function loss: 91.3538
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 87.0889
                       Mean reward: 327.92
               Mean episode length: 228.84
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 66.8095
        Episode_Reward/action_rate: -0.1168
          Episode_Reward/joint_vel: -0.0780
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.07s
                      Time elapsed: 00:45:41
                               ETA: 00:11:53

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 47875 steps/s (collection: 1.954s, learning 0.100s)
             Mean action noise std: 4.12
          Mean value_function loss: 83.6228
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 87.0957
                       Mean reward: 319.57
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 66.5025
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.05s
                      Time elapsed: 00:45:43
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 43072 steps/s (collection: 2.054s, learning 0.228s)
             Mean action noise std: 4.12
          Mean value_function loss: 77.6320
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 87.1027
                       Mean reward: 386.75
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.2239
    Episode_Reward/rotating_object: 65.0918
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0811
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.28s
                      Time elapsed: 00:45:46
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 44261 steps/s (collection: 1.991s, learning 0.230s)
             Mean action noise std: 4.13
          Mean value_function loss: 83.2581
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 87.1128
                       Mean reward: 331.57
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 66.4471
        Episode_Reward/action_rate: -0.1170
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.22s
                      Time elapsed: 00:45:48
                               ETA: 00:11:46

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 44869 steps/s (collection: 2.061s, learning 0.130s)
             Mean action noise std: 4.13
          Mean value_function loss: 79.4040
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 87.1285
                       Mean reward: 309.89
               Mean episode length: 229.70
    Episode_Reward/reaching_object: 1.1866
    Episode_Reward/rotating_object: 65.4110
        Episode_Reward/action_rate: -0.1175
          Episode_Reward/joint_vel: -0.0780
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.19s
                      Time elapsed: 00:45:50
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 46746 steps/s (collection: 1.919s, learning 0.184s)
             Mean action noise std: 4.13
          Mean value_function loss: 80.2932
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 87.1464
                       Mean reward: 333.53
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.1536
    Episode_Reward/rotating_object: 64.0681
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.10s
                      Time elapsed: 00:45:52
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 46393 steps/s (collection: 1.959s, learning 0.160s)
             Mean action noise std: 4.14
          Mean value_function loss: 75.5615
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 87.1686
                       Mean reward: 373.76
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 66.4639
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0796
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.12s
                      Time elapsed: 00:45:54
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 47512 steps/s (collection: 1.945s, learning 0.124s)
             Mean action noise std: 4.14
          Mean value_function loss: 78.1616
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 87.1889
                       Mean reward: 344.70
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 1.1827
    Episode_Reward/rotating_object: 65.1921
        Episode_Reward/action_rate: -0.1184
          Episode_Reward/joint_vel: -0.0785
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.07s
                      Time elapsed: 00:45:56
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 39733 steps/s (collection: 2.179s, learning 0.295s)
             Mean action noise std: 4.14
          Mean value_function loss: 82.4630
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 87.2071
                       Mean reward: 315.28
               Mean episode length: 227.00
    Episode_Reward/reaching_object: 1.1706
    Episode_Reward/rotating_object: 65.9414
        Episode_Reward/action_rate: -0.1179
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.47s
                      Time elapsed: 00:45:59
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 44307 steps/s (collection: 2.066s, learning 0.153s)
             Mean action noise std: 4.15
          Mean value_function loss: 75.8943
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 87.2368
                       Mean reward: 331.23
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.1906
    Episode_Reward/rotating_object: 66.6021
        Episode_Reward/action_rate: -0.1195
          Episode_Reward/joint_vel: -0.0791
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.22s
                      Time elapsed: 00:46:01
                               ETA: 00:11:32

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 45729 steps/s (collection: 2.041s, learning 0.109s)
             Mean action noise std: 4.15
          Mean value_function loss: 85.6684
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 87.2586
                       Mean reward: 305.83
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 68.1268
        Episode_Reward/action_rate: -0.1189
          Episode_Reward/joint_vel: -0.0787
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.15s
                      Time elapsed: 00:46:03
                               ETA: 00:11:30

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 49924 steps/s (collection: 1.868s, learning 0.102s)
             Mean action noise std: 4.15
          Mean value_function loss: 80.2913
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 87.2698
                       Mean reward: 319.54
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.1573
    Episode_Reward/rotating_object: 64.2052
        Episode_Reward/action_rate: -0.1189
          Episode_Reward/joint_vel: -0.0783
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.97s
                      Time elapsed: 00:46:05
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 48943 steps/s (collection: 1.898s, learning 0.111s)
             Mean action noise std: 4.15
          Mean value_function loss: 74.2355
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 87.2920
                       Mean reward: 381.64
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.2027
    Episode_Reward/rotating_object: 70.2464
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0805
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.01s
                      Time elapsed: 00:46:07
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 46824 steps/s (collection: 1.981s, learning 0.119s)
             Mean action noise std: 4.15
          Mean value_function loss: 75.3143
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 87.3126
                       Mean reward: 318.95
               Mean episode length: 234.19
    Episode_Reward/reaching_object: 1.1888
    Episode_Reward/rotating_object: 66.8044
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0800
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.10s
                      Time elapsed: 00:46:09
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 48478 steps/s (collection: 1.921s, learning 0.107s)
             Mean action noise std: 4.16
          Mean value_function loss: 79.7025
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 87.3264
                       Mean reward: 341.88
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.1584
    Episode_Reward/rotating_object: 69.3021
        Episode_Reward/action_rate: -0.1194
          Episode_Reward/joint_vel: -0.0774
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.03s
                      Time elapsed: 00:46:11
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 50121 steps/s (collection: 1.854s, learning 0.108s)
             Mean action noise std: 4.16
          Mean value_function loss: 79.0297
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.3510
                       Mean reward: 356.90
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.1831
    Episode_Reward/rotating_object: 69.2413
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0818
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.96s
                      Time elapsed: 00:46:13
                               ETA: 00:11:18

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 49704 steps/s (collection: 1.883s, learning 0.095s)
             Mean action noise std: 4.17
          Mean value_function loss: 81.6937
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 87.3779
                       Mean reward: 334.32
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 1.1508
    Episode_Reward/rotating_object: 67.0553
        Episode_Reward/action_rate: -0.1190
          Episode_Reward/joint_vel: -0.0784
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.98s
                      Time elapsed: 00:46:15
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 47463 steps/s (collection: 1.953s, learning 0.119s)
             Mean action noise std: 4.17
          Mean value_function loss: 84.4903
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 87.4029
                       Mean reward: 322.70
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 1.1590
    Episode_Reward/rotating_object: 69.8784
        Episode_Reward/action_rate: -0.1205
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.07s
                      Time elapsed: 00:46:17
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 43455 steps/s (collection: 2.161s, learning 0.101s)
             Mean action noise std: 4.17
          Mean value_function loss: 77.4259
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 87.4272
                       Mean reward: 387.09
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 1.1528
    Episode_Reward/rotating_object: 70.4416
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0769
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.26s
                      Time elapsed: 00:46:20
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 48907 steps/s (collection: 1.900s, learning 0.110s)
             Mean action noise std: 4.18
          Mean value_function loss: 76.1246
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 87.4481
                       Mean reward: 402.54
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 1.1795
    Episode_Reward/rotating_object: 69.3066
        Episode_Reward/action_rate: -0.1231
          Episode_Reward/joint_vel: -0.0804
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.01s
                      Time elapsed: 00:46:22
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 44688 steps/s (collection: 2.073s, learning 0.127s)
             Mean action noise std: 4.18
          Mean value_function loss: 81.2907
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 87.4669
                       Mean reward: 338.28
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 1.1746
    Episode_Reward/rotating_object: 68.8131
        Episode_Reward/action_rate: -0.1231
          Episode_Reward/joint_vel: -0.0803
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.20s
                      Time elapsed: 00:46:24
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 47005 steps/s (collection: 1.980s, learning 0.111s)
             Mean action noise std: 4.18
          Mean value_function loss: 92.0928
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 87.4828
                       Mean reward: 341.59
               Mean episode length: 228.55
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 69.8227
        Episode_Reward/action_rate: -0.1200
          Episode_Reward/joint_vel: -0.0792
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.09s
                      Time elapsed: 00:46:26
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 45039 steps/s (collection: 1.929s, learning 0.254s)
             Mean action noise std: 4.18
          Mean value_function loss: 82.6853
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.5021
                       Mean reward: 342.93
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.1552
    Episode_Reward/rotating_object: 70.1406
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.18s
                      Time elapsed: 00:46:28
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 43092 steps/s (collection: 2.179s, learning 0.102s)
             Mean action noise std: 4.19
          Mean value_function loss: 76.3218
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.5211
                       Mean reward: 361.52
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 1.1665
    Episode_Reward/rotating_object: 68.3422
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0794
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.28s
                      Time elapsed: 00:46:30
                               ETA: 00:10:59

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 45571 steps/s (collection: 2.007s, learning 0.151s)
             Mean action noise std: 4.19
          Mean value_function loss: 92.9410
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 87.5342
                       Mean reward: 344.67
               Mean episode length: 234.14
    Episode_Reward/reaching_object: 1.1660
    Episode_Reward/rotating_object: 69.0533
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0782
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.16s
                      Time elapsed: 00:46:33
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 43690 steps/s (collection: 2.014s, learning 0.236s)
             Mean action noise std: 4.19
          Mean value_function loss: 92.7517
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 87.5507
                       Mean reward: 301.36
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.1575
    Episode_Reward/rotating_object: 65.9295
        Episode_Reward/action_rate: -0.1219
          Episode_Reward/joint_vel: -0.0793
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.25s
                      Time elapsed: 00:46:35
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 37323 steps/s (collection: 2.367s, learning 0.267s)
             Mean action noise std: 4.19
          Mean value_function loss: 82.3566
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.5713
                       Mean reward: 336.16
               Mean episode length: 221.83
    Episode_Reward/reaching_object: 1.1853
    Episode_Reward/rotating_object: 69.5335
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.63s
                      Time elapsed: 00:46:37
                               ETA: 00:10:52

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 43459 steps/s (collection: 2.085s, learning 0.177s)
             Mean action noise std: 4.20
          Mean value_function loss: 85.9360
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 87.5922
                       Mean reward: 343.13
               Mean episode length: 230.83
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 70.5974
        Episode_Reward/action_rate: -0.1217
          Episode_Reward/joint_vel: -0.0805
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.26s
                      Time elapsed: 00:46:40
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 46153 steps/s (collection: 1.999s, learning 0.131s)
             Mean action noise std: 4.20
          Mean value_function loss: 80.5438
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 87.6173
                       Mean reward: 364.47
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.1462
    Episode_Reward/rotating_object: 66.9316
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0799
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.13s
                      Time elapsed: 00:46:42
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 45881 steps/s (collection: 2.005s, learning 0.138s)
             Mean action noise std: 4.20
          Mean value_function loss: 78.4859
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 87.6386
                       Mean reward: 348.69
               Mean episode length: 230.79
    Episode_Reward/reaching_object: 1.1597
    Episode_Reward/rotating_object: 70.0130
        Episode_Reward/action_rate: -0.1219
          Episode_Reward/joint_vel: -0.0809
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.14s
                      Time elapsed: 00:46:44
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 50066 steps/s (collection: 1.849s, learning 0.115s)
             Mean action noise std: 4.21
          Mean value_function loss: 95.8985
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 87.6607
                       Mean reward: 357.84
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 71.3932
        Episode_Reward/action_rate: -0.1225
          Episode_Reward/joint_vel: -0.0820
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.96s
                      Time elapsed: 00:46:46
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 50406 steps/s (collection: 1.828s, learning 0.122s)
             Mean action noise std: 4.21
          Mean value_function loss: 80.0158
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 87.6736
                       Mean reward: 376.16
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 1.1768
    Episode_Reward/rotating_object: 68.2716
        Episode_Reward/action_rate: -0.1239
          Episode_Reward/joint_vel: -0.0825
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.95s
                      Time elapsed: 00:46:48
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 47824 steps/s (collection: 1.931s, learning 0.124s)
             Mean action noise std: 4.21
          Mean value_function loss: 94.0738
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.6872
                       Mean reward: 330.78
               Mean episode length: 219.36
    Episode_Reward/reaching_object: 1.1615
    Episode_Reward/rotating_object: 69.7204
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0810
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.06s
                      Time elapsed: 00:46:50
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 47862 steps/s (collection: 1.948s, learning 0.106s)
             Mean action noise std: 4.21
          Mean value_function loss: 75.4603
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 87.7099
                       Mean reward: 351.46
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.1520
    Episode_Reward/rotating_object: 63.5334
        Episode_Reward/action_rate: -0.1215
          Episode_Reward/joint_vel: -0.0826
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.05s
                      Time elapsed: 00:46:52
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 47831 steps/s (collection: 1.931s, learning 0.124s)
             Mean action noise std: 4.22
          Mean value_function loss: 77.6538
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.7299
                       Mean reward: 386.87
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 72.6872
        Episode_Reward/action_rate: -0.1265
          Episode_Reward/joint_vel: -0.0856
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.06s
                      Time elapsed: 00:46:54
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 48229 steps/s (collection: 1.913s, learning 0.126s)
             Mean action noise std: 4.22
          Mean value_function loss: 74.0205
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 87.7426
                       Mean reward: 357.23
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 1.1588
    Episode_Reward/rotating_object: 67.9733
        Episode_Reward/action_rate: -0.1236
          Episode_Reward/joint_vel: -0.0825
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.04s
                      Time elapsed: 00:46:56
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 48685 steps/s (collection: 1.893s, learning 0.126s)
             Mean action noise std: 4.22
          Mean value_function loss: 66.1052
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 87.7552
                       Mean reward: 358.71
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.1347
    Episode_Reward/rotating_object: 66.2148
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0827
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.02s
                      Time elapsed: 00:46:58
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 49711 steps/s (collection: 1.845s, learning 0.132s)
             Mean action noise std: 4.22
          Mean value_function loss: 77.7066
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 87.7758
                       Mean reward: 350.27
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 1.1679
    Episode_Reward/rotating_object: 68.2845
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0839
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.98s
                      Time elapsed: 00:47:00
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 47952 steps/s (collection: 1.908s, learning 0.142s)
             Mean action noise std: 4.23
          Mean value_function loss: 72.9976
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 87.7973
                       Mean reward: 342.07
               Mean episode length: 231.74
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 70.9162
        Episode_Reward/action_rate: -0.1247
          Episode_Reward/joint_vel: -0.0835
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.05s
                      Time elapsed: 00:47:02
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 45938 steps/s (collection: 2.003s, learning 0.137s)
             Mean action noise std: 4.23
          Mean value_function loss: 82.9862
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 87.8196
                       Mean reward: 399.05
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.1698
    Episode_Reward/rotating_object: 68.1116
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0831
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.14s
                      Time elapsed: 00:47:04
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 49106 steps/s (collection: 1.868s, learning 0.133s)
             Mean action noise std: 4.23
          Mean value_function loss: 80.6580
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 87.8387
                       Mean reward: 349.94
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 1.1610
    Episode_Reward/rotating_object: 69.6397
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0818
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.00s
                      Time elapsed: 00:47:06
                               ETA: 00:10:20

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 47478 steps/s (collection: 1.921s, learning 0.150s)
             Mean action noise std: 4.23
          Mean value_function loss: 83.9316
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 87.8549
                       Mean reward: 383.98
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.1449
    Episode_Reward/rotating_object: 67.6489
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0799
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.07s
                      Time elapsed: 00:47:08
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 45114 steps/s (collection: 2.022s, learning 0.157s)
             Mean action noise std: 4.24
          Mean value_function loss: 77.8415
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 87.8700
                       Mean reward: 354.50
               Mean episode length: 227.52
    Episode_Reward/reaching_object: 1.1516
    Episode_Reward/rotating_object: 69.7346
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.18s
                      Time elapsed: 00:47:11
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 45715 steps/s (collection: 2.020s, learning 0.131s)
             Mean action noise std: 4.24
          Mean value_function loss: 83.1185
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.8842
                       Mean reward: 337.69
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 70.3428
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0817
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.15s
                      Time elapsed: 00:47:13
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 43264 steps/s (collection: 2.042s, learning 0.230s)
             Mean action noise std: 4.24
          Mean value_function loss: 82.8039
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 87.8963
                       Mean reward: 324.48
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 70.3566
        Episode_Reward/action_rate: -0.1259
          Episode_Reward/joint_vel: -0.0822
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.27s
                      Time elapsed: 00:47:15
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 35785 steps/s (collection: 2.550s, learning 0.197s)
             Mean action noise std: 4.24
          Mean value_function loss: 77.2380
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 87.9108
                       Mean reward: 314.77
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.1346
    Episode_Reward/rotating_object: 63.5869
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0795
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.75s
                      Time elapsed: 00:47:18
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 43664 steps/s (collection: 2.149s, learning 0.102s)
             Mean action noise std: 4.24
          Mean value_function loss: 84.8008
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 87.9248
                       Mean reward: 359.15
               Mean episode length: 227.79
    Episode_Reward/reaching_object: 1.1658
    Episode_Reward/rotating_object: 72.3008
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0811
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.25s
                      Time elapsed: 00:47:20
                               ETA: 00:10:06

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 48825 steps/s (collection: 1.872s, learning 0.142s)
             Mean action noise std: 4.25
          Mean value_function loss: 80.5804
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.9417
                       Mean reward: 367.44
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 71.3413
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0822
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.01s
                      Time elapsed: 00:47:22
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 48681 steps/s (collection: 1.880s, learning 0.140s)
             Mean action noise std: 4.25
          Mean value_function loss: 83.4533
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 87.9577
                       Mean reward: 385.41
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.1601
    Episode_Reward/rotating_object: 71.8231
        Episode_Reward/action_rate: -0.1233
          Episode_Reward/joint_vel: -0.0790
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.02s
                      Time elapsed: 00:47:24
                               ETA: 00:10:01

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 49065 steps/s (collection: 1.864s, learning 0.139s)
             Mean action noise std: 4.25
          Mean value_function loss: 85.8907
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 87.9620
                       Mean reward: 382.36
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 70.6295
        Episode_Reward/action_rate: -0.1269
          Episode_Reward/joint_vel: -0.0809
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.00s
                      Time elapsed: 00:47:26
                               ETA: 00:09:59

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 48659 steps/s (collection: 1.884s, learning 0.136s)
             Mean action noise std: 4.25
          Mean value_function loss: 87.0909
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 87.9730
                       Mean reward: 318.82
               Mean episode length: 224.34
    Episode_Reward/reaching_object: 1.1690
    Episode_Reward/rotating_object: 69.8021
        Episode_Reward/action_rate: -0.1245
          Episode_Reward/joint_vel: -0.0778
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.02s
                      Time elapsed: 00:47:28
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 46697 steps/s (collection: 1.986s, learning 0.119s)
             Mean action noise std: 4.25
          Mean value_function loss: 81.4144
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 87.9915
                       Mean reward: 349.32
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.1910
    Episode_Reward/rotating_object: 71.2451
        Episode_Reward/action_rate: -0.1270
          Episode_Reward/joint_vel: -0.0797
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.11s
                      Time elapsed: 00:47:30
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 47144 steps/s (collection: 1.948s, learning 0.137s)
             Mean action noise std: 4.26
          Mean value_function loss: 80.1634
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 88.0024
                       Mean reward: 356.33
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.2013
    Episode_Reward/rotating_object: 72.8224
        Episode_Reward/action_rate: -0.1274
          Episode_Reward/joint_vel: -0.0806
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.09s
                      Time elapsed: 00:47:32
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 42638 steps/s (collection: 2.141s, learning 0.164s)
             Mean action noise std: 4.26
          Mean value_function loss: 76.8565
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 88.0190
                       Mean reward: 389.52
               Mean episode length: 227.63
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 73.4534
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0780
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.31s
                      Time elapsed: 00:47:35
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 46341 steps/s (collection: 1.989s, learning 0.132s)
             Mean action noise std: 4.26
          Mean value_function loss: 88.0724
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.0317
                       Mean reward: 382.78
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.1869
    Episode_Reward/rotating_object: 70.6175
        Episode_Reward/action_rate: -0.1257
          Episode_Reward/joint_vel: -0.0770
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.12s
                      Time elapsed: 00:47:37
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 45137 steps/s (collection: 1.981s, learning 0.197s)
             Mean action noise std: 4.26
          Mean value_function loss: 84.2685
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 88.0478
                       Mean reward: 325.86
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.1715
    Episode_Reward/rotating_object: 68.0749
        Episode_Reward/action_rate: -0.1244
          Episode_Reward/joint_vel: -0.0758
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.18s
                      Time elapsed: 00:47:39
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 46353 steps/s (collection: 2.010s, learning 0.111s)
             Mean action noise std: 4.26
          Mean value_function loss: 88.0743
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.0627
                       Mean reward: 360.88
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 1.1863
    Episode_Reward/rotating_object: 71.1786
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.12s
                      Time elapsed: 00:47:41
                               ETA: 00:09:42

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 42877 steps/s (collection: 2.076s, learning 0.217s)
             Mean action noise std: 4.27
          Mean value_function loss: 87.6159
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 88.0773
                       Mean reward: 361.41
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 1.1980
    Episode_Reward/rotating_object: 74.3576
        Episode_Reward/action_rate: -0.1273
          Episode_Reward/joint_vel: -0.0756
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.29s
                      Time elapsed: 00:47:43
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 42660 steps/s (collection: 2.138s, learning 0.167s)
             Mean action noise std: 4.27
          Mean value_function loss: 85.0970
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.0987
                       Mean reward: 374.73
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.1843
    Episode_Reward/rotating_object: 70.4621
        Episode_Reward/action_rate: -0.1264
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.30s
                      Time elapsed: 00:47:46
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 39670 steps/s (collection: 2.286s, learning 0.192s)
             Mean action noise std: 4.27
          Mean value_function loss: 89.4181
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 88.1153
                       Mean reward: 346.99
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 1.1791
    Episode_Reward/rotating_object: 66.4821
        Episode_Reward/action_rate: -0.1265
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.48s
                      Time elapsed: 00:47:48
                               ETA: 00:09:35

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 41609 steps/s (collection: 2.252s, learning 0.110s)
             Mean action noise std: 4.27
          Mean value_function loss: 92.2091
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 88.1283
                       Mean reward: 356.08
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 68.7043
        Episode_Reward/action_rate: -0.1264
          Episode_Reward/joint_vel: -0.0766
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.36s
                      Time elapsed: 00:47:50
                               ETA: 00:09:33

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 44877 steps/s (collection: 2.047s, learning 0.144s)
             Mean action noise std: 4.28
          Mean value_function loss: 86.2155
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.1383
                       Mean reward: 361.15
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.2093
    Episode_Reward/rotating_object: 73.0392
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0768
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.19s
                      Time elapsed: 00:47:53
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 44774 steps/s (collection: 2.059s, learning 0.136s)
             Mean action noise std: 4.28
          Mean value_function loss: 75.4068
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.1487
                       Mean reward: 382.62
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 73.8725
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0757
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.20s
                      Time elapsed: 00:47:55
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 47645 steps/s (collection: 1.917s, learning 0.146s)
             Mean action noise std: 4.28
          Mean value_function loss: 75.5166
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.1598
                       Mean reward: 333.55
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 70.7857
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0749
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.06s
                      Time elapsed: 00:47:57
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 42902 steps/s (collection: 2.096s, learning 0.195s)
             Mean action noise std: 4.28
          Mean value_function loss: 80.8408
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.1772
                       Mean reward: 309.67
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.1765
    Episode_Reward/rotating_object: 67.6844
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.29s
                      Time elapsed: 00:47:59
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 46626 steps/s (collection: 1.942s, learning 0.166s)
             Mean action noise std: 4.28
          Mean value_function loss: 84.6903
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.1917
                       Mean reward: 378.83
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.2113
    Episode_Reward/rotating_object: 73.8599
        Episode_Reward/action_rate: -0.1280
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.11s
                      Time elapsed: 00:48:01
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 45583 steps/s (collection: 2.025s, learning 0.131s)
             Mean action noise std: 4.29
          Mean value_function loss: 85.9814
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.2061
                       Mean reward: 354.17
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 70.8203
        Episode_Reward/action_rate: -0.1283
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.16s
                      Time elapsed: 00:48:03
                               ETA: 00:09:19

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 46970 steps/s (collection: 1.904s, learning 0.189s)
             Mean action noise std: 4.29
          Mean value_function loss: 79.2628
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 88.2173
                       Mean reward: 375.74
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 79.5218
        Episode_Reward/action_rate: -0.1305
          Episode_Reward/joint_vel: -0.0754
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.09s
                      Time elapsed: 00:48:05
                               ETA: 00:09:17

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 48502 steps/s (collection: 1.902s, learning 0.125s)
             Mean action noise std: 4.29
          Mean value_function loss: 84.7056
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.2280
                       Mean reward: 423.68
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.1824
    Episode_Reward/rotating_object: 73.6720
        Episode_Reward/action_rate: -0.1279
          Episode_Reward/joint_vel: -0.0749
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.03s
                      Time elapsed: 00:48:07
                               ETA: 00:09:15

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 46470 steps/s (collection: 1.956s, learning 0.160s)
             Mean action noise std: 4.29
          Mean value_function loss: 85.0798
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 88.2447
                       Mean reward: 350.86
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.1509
    Episode_Reward/rotating_object: 67.0621
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.12s
                      Time elapsed: 00:48:10
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 46723 steps/s (collection: 1.961s, learning 0.143s)
             Mean action noise std: 4.29
          Mean value_function loss: 74.8062
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 88.2614
                       Mean reward: 342.26
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 1.1581
    Episode_Reward/rotating_object: 68.8849
        Episode_Reward/action_rate: -0.1259
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.10s
                      Time elapsed: 00:48:12
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 48283 steps/s (collection: 1.930s, learning 0.106s)
             Mean action noise std: 4.30
          Mean value_function loss: 73.7809
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 88.2784
                       Mean reward: 367.16
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 1.1863
    Episode_Reward/rotating_object: 71.4227
        Episode_Reward/action_rate: -0.1286
          Episode_Reward/joint_vel: -0.0753
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.04s
                      Time elapsed: 00:48:14
                               ETA: 00:09:08

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 47752 steps/s (collection: 1.952s, learning 0.107s)
             Mean action noise std: 4.30
          Mean value_function loss: 90.5908
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.3008
                       Mean reward: 354.64
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 73.1411
        Episode_Reward/action_rate: -0.1297
          Episode_Reward/joint_vel: -0.0769
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.06s
                      Time elapsed: 00:48:16
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 46186 steps/s (collection: 2.004s, learning 0.124s)
             Mean action noise std: 4.30
          Mean value_function loss: 78.4243
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 88.3077
                       Mean reward: 401.33
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.1780
    Episode_Reward/rotating_object: 73.0939
        Episode_Reward/action_rate: -0.1279
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.13s
                      Time elapsed: 00:48:18
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 43227 steps/s (collection: 2.071s, learning 0.204s)
             Mean action noise std: 4.30
          Mean value_function loss: 76.1930
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 88.3169
                       Mean reward: 384.02
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.1795
    Episode_Reward/rotating_object: 73.8714
        Episode_Reward/action_rate: -0.1286
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.27s
                      Time elapsed: 00:48:20
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 39729 steps/s (collection: 2.322s, learning 0.152s)
             Mean action noise std: 4.31
          Mean value_function loss: 67.4255
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.3316
                       Mean reward: 348.33
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 71.8182
        Episode_Reward/action_rate: -0.1294
          Episode_Reward/joint_vel: -0.0763
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.47s
                      Time elapsed: 00:48:23
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 45378 steps/s (collection: 2.053s, learning 0.113s)
             Mean action noise std: 4.31
          Mean value_function loss: 78.8538
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.3489
                       Mean reward: 392.04
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 71.2036
        Episode_Reward/action_rate: -0.1306
          Episode_Reward/joint_vel: -0.0747
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.17s
                      Time elapsed: 00:48:25
                               ETA: 00:08:56

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 46139 steps/s (collection: 2.006s, learning 0.125s)
             Mean action noise std: 4.31
          Mean value_function loss: 79.8043
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 88.3634
                       Mean reward: 379.88
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.2028
    Episode_Reward/rotating_object: 76.2735
        Episode_Reward/action_rate: -0.1306
          Episode_Reward/joint_vel: -0.0751
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.13s
                      Time elapsed: 00:48:27
                               ETA: 00:08:54

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 47922 steps/s (collection: 1.939s, learning 0.112s)
             Mean action noise std: 4.31
          Mean value_function loss: 91.2890
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 88.3721
                       Mean reward: 377.01
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 72.6892
        Episode_Reward/action_rate: -0.1319
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.05s
                      Time elapsed: 00:48:29
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 49023 steps/s (collection: 1.875s, learning 0.131s)
             Mean action noise std: 4.31
          Mean value_function loss: 72.8180
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 88.3875
                       Mean reward: 380.34
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 74.1050
        Episode_Reward/action_rate: -0.1314
          Episode_Reward/joint_vel: -0.0759
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.01s
                      Time elapsed: 00:48:31
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 49859 steps/s (collection: 1.843s, learning 0.129s)
             Mean action noise std: 4.31
          Mean value_function loss: 94.2803
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 88.3946
                       Mean reward: 348.36
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 72.1059
        Episode_Reward/action_rate: -0.1306
          Episode_Reward/joint_vel: -0.0771
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.97s
                      Time elapsed: 00:48:33
                               ETA: 00:08:47

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 47017 steps/s (collection: 1.954s, learning 0.137s)
             Mean action noise std: 4.32
          Mean value_function loss: 90.8540
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.4088
                       Mean reward: 372.11
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 72.3574
        Episode_Reward/action_rate: -0.1333
          Episode_Reward/joint_vel: -0.0762
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.09s
                      Time elapsed: 00:48:35
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 48499 steps/s (collection: 1.891s, learning 0.136s)
             Mean action noise std: 4.32
          Mean value_function loss: 91.1085
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 88.4260
                       Mean reward: 394.93
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.1818
    Episode_Reward/rotating_object: 70.7682
        Episode_Reward/action_rate: -0.1281
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.03s
                      Time elapsed: 00:48:37
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 48785 steps/s (collection: 1.880s, learning 0.135s)
             Mean action noise std: 4.32
          Mean value_function loss: 100.3263
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 88.4369
                       Mean reward: 327.96
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 75.9707
        Episode_Reward/action_rate: -0.1303
          Episode_Reward/joint_vel: -0.0746
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.02s
                      Time elapsed: 00:48:39
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 46592 steps/s (collection: 1.954s, learning 0.156s)
             Mean action noise std: 4.32
          Mean value_function loss: 101.3442
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.4518
                       Mean reward: 355.75
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 71.5979
        Episode_Reward/action_rate: -0.1290
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.11s
                      Time elapsed: 00:48:41
                               ETA: 00:08:37

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 46785 steps/s (collection: 1.971s, learning 0.131s)
             Mean action noise std: 4.33
          Mean value_function loss: 91.2085
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.4681
                       Mean reward: 367.51
               Mean episode length: 236.87
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 70.9012
        Episode_Reward/action_rate: -0.1299
          Episode_Reward/joint_vel: -0.0755
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.10s
                      Time elapsed: 00:48:43
                               ETA: 00:08:35

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 48919 steps/s (collection: 1.875s, learning 0.134s)
             Mean action noise std: 4.33
          Mean value_function loss: 86.0650
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 88.4779
                       Mean reward: 357.33
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 1.1908
    Episode_Reward/rotating_object: 70.6436
        Episode_Reward/action_rate: -0.1291
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.01s
                      Time elapsed: 00:48:45
                               ETA: 00:08:33

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 43505 steps/s (collection: 2.083s, learning 0.177s)
             Mean action noise std: 4.33
          Mean value_function loss: 79.6594
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 88.4855
                       Mean reward: 381.36
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 72.8867
        Episode_Reward/action_rate: -0.1290
          Episode_Reward/joint_vel: -0.0731
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.26s
                      Time elapsed: 00:48:48
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 47930 steps/s (collection: 1.924s, learning 0.127s)
             Mean action noise std: 4.33
          Mean value_function loss: 80.1054
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 88.4937
                       Mean reward: 323.67
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.1818
    Episode_Reward/rotating_object: 66.8850
        Episode_Reward/action_rate: -0.1284
          Episode_Reward/joint_vel: -0.0730
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.05s
                      Time elapsed: 00:48:50
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 41912 steps/s (collection: 2.142s, learning 0.203s)
             Mean action noise std: 4.33
          Mean value_function loss: 93.3779
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 88.5071
                       Mean reward: 349.11
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.1997
    Episode_Reward/rotating_object: 68.9950
        Episode_Reward/action_rate: -0.1298
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.35s
                      Time elapsed: 00:48:52
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 42618 steps/s (collection: 2.187s, learning 0.120s)
             Mean action noise std: 4.33
          Mean value_function loss: 83.0470
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.5199
                       Mean reward: 396.01
               Mean episode length: 237.39
    Episode_Reward/reaching_object: 1.2214
    Episode_Reward/rotating_object: 75.2039
        Episode_Reward/action_rate: -0.1306
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.31s
                      Time elapsed: 00:48:54
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 44676 steps/s (collection: 2.047s, learning 0.154s)
             Mean action noise std: 4.33
          Mean value_function loss: 83.6016
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.5316
                       Mean reward: 368.88
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.2035
    Episode_Reward/rotating_object: 72.8864
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0729
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.20s
                      Time elapsed: 00:48:57
                               ETA: 00:08:21

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 42514 steps/s (collection: 2.190s, learning 0.123s)
             Mean action noise std: 4.34
          Mean value_function loss: 79.6940
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.5405
                       Mean reward: 366.96
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 74.3642
        Episode_Reward/action_rate: -0.1318
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.31s
                      Time elapsed: 00:48:59
                               ETA: 00:08:19

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 47448 steps/s (collection: 1.928s, learning 0.143s)
             Mean action noise std: 4.34
          Mean value_function loss: 95.5895
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.5547
                       Mean reward: 384.72
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 1.2271
    Episode_Reward/rotating_object: 75.9450
        Episode_Reward/action_rate: -0.1335
          Episode_Reward/joint_vel: -0.0735
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.07s
                      Time elapsed: 00:49:01
                               ETA: 00:08:17

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 40652 steps/s (collection: 2.265s, learning 0.153s)
             Mean action noise std: 4.34
          Mean value_function loss: 92.7395
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 88.5701
                       Mean reward: 366.25
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 75.9468
        Episode_Reward/action_rate: -0.1314
          Episode_Reward/joint_vel: -0.0727
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.42s
                      Time elapsed: 00:49:03
                               ETA: 00:08:14

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 40137 steps/s (collection: 2.275s, learning 0.174s)
             Mean action noise std: 4.34
          Mean value_function loss: 83.6020
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 88.5811
                       Mean reward: 360.02
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.2054
    Episode_Reward/rotating_object: 71.3099
        Episode_Reward/action_rate: -0.1309
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.45s
                      Time elapsed: 00:49:06
                               ETA: 00:08:12

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 36036 steps/s (collection: 2.481s, learning 0.247s)
             Mean action noise std: 4.34
          Mean value_function loss: 98.2489
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 88.5910
                       Mean reward: 394.71
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 1.2470
    Episode_Reward/rotating_object: 76.9793
        Episode_Reward/action_rate: -0.1345
          Episode_Reward/joint_vel: -0.0752
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.73s
                      Time elapsed: 00:49:09
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 27560 steps/s (collection: 3.294s, learning 0.273s)
             Mean action noise std: 4.35
          Mean value_function loss: 89.3963
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.6046
                       Mean reward: 357.79
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 71.0666
        Episode_Reward/action_rate: -0.1322
          Episode_Reward/joint_vel: -0.0743
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 3.57s
                      Time elapsed: 00:49:12
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 26889 steps/s (collection: 3.401s, learning 0.255s)
             Mean action noise std: 4.35
          Mean value_function loss: 105.5491
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 88.6142
                       Mean reward: 368.59
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 70.7053
        Episode_Reward/action_rate: -0.1309
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 3.66s
                      Time elapsed: 00:49:16
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 21997 steps/s (collection: 4.030s, learning 0.439s)
             Mean action noise std: 4.35
          Mean value_function loss: 82.6050
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 88.6246
                       Mean reward: 364.47
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.2004
    Episode_Reward/rotating_object: 70.6087
        Episode_Reward/action_rate: -0.1301
          Episode_Reward/joint_vel: -0.0749
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 4.47s
                      Time elapsed: 00:49:20
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 22555 steps/s (collection: 4.094s, learning 0.265s)
             Mean action noise std: 4.35
          Mean value_function loss: 79.8939
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 88.6329
                       Mean reward: 380.76
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 74.3451
        Episode_Reward/action_rate: -0.1317
          Episode_Reward/joint_vel: -0.0745
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 4.36s
                      Time elapsed: 00:49:25
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 23630 steps/s (collection: 3.720s, learning 0.440s)
             Mean action noise std: 4.35
          Mean value_function loss: 87.0148
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.6483
                       Mean reward: 322.88
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 66.6390
        Episode_Reward/action_rate: -0.1311
          Episode_Reward/joint_vel: -0.0734
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 4.16s
                      Time elapsed: 00:49:29
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 27830 steps/s (collection: 3.424s, learning 0.108s)
             Mean action noise std: 4.36
          Mean value_function loss: 77.7171
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 88.6656
                       Mean reward: 403.53
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 73.4503
        Episode_Reward/action_rate: -0.1321
          Episode_Reward/joint_vel: -0.0724
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 3.53s
                      Time elapsed: 00:49:32
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 51866 steps/s (collection: 1.801s, learning 0.094s)
             Mean action noise std: 4.36
          Mean value_function loss: 81.9028
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 88.6873
                       Mean reward: 371.79
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.1933
    Episode_Reward/rotating_object: 70.9153
        Episode_Reward/action_rate: -0.1305
          Episode_Reward/joint_vel: -0.0715
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 1.90s
                      Time elapsed: 00:49:34
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 48528 steps/s (collection: 1.917s, learning 0.109s)
             Mean action noise std: 4.36
          Mean value_function loss: 79.0136
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 88.7040
                       Mean reward: 396.68
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.2161
    Episode_Reward/rotating_object: 74.5888
        Episode_Reward/action_rate: -0.1329
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.03s
                      Time elapsed: 00:49:36
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 44854 steps/s (collection: 2.051s, learning 0.141s)
             Mean action noise std: 4.36
          Mean value_function loss: 72.3077
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.7204
                       Mean reward: 405.12
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 72.0797
        Episode_Reward/action_rate: -0.1319
          Episode_Reward/joint_vel: -0.0735
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.19s
                      Time elapsed: 00:49:38
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 47197 steps/s (collection: 1.944s, learning 0.139s)
             Mean action noise std: 4.37
          Mean value_function loss: 60.8148
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 88.7328
                       Mean reward: 380.25
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 1.2107
    Episode_Reward/rotating_object: 74.3089
        Episode_Reward/action_rate: -0.1323
          Episode_Reward/joint_vel: -0.0712
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.08s
                      Time elapsed: 00:49:40
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 47079 steps/s (collection: 1.959s, learning 0.129s)
             Mean action noise std: 4.37
          Mean value_function loss: 71.9843
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.7417
                       Mean reward: 350.03
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 1.2077
    Episode_Reward/rotating_object: 70.9145
        Episode_Reward/action_rate: -0.1324
          Episode_Reward/joint_vel: -0.0729
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.09s
                      Time elapsed: 00:49:43
                               ETA: 00:07:46

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 41249 steps/s (collection: 2.245s, learning 0.139s)
             Mean action noise std: 4.37
          Mean value_function loss: 80.0030
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 88.7523
                       Mean reward: 366.74
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 1.2122
    Episode_Reward/rotating_object: 74.5850
        Episode_Reward/action_rate: -0.1349
          Episode_Reward/joint_vel: -0.0730
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.38s
                      Time elapsed: 00:49:45
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 38559 steps/s (collection: 2.305s, learning 0.245s)
             Mean action noise std: 4.37
          Mean value_function loss: 72.1296
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 88.7673
                       Mean reward: 363.43
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 74.9051
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.55s
                      Time elapsed: 00:49:47
                               ETA: 00:07:41

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 42326 steps/s (collection: 2.124s, learning 0.198s)
             Mean action noise std: 4.37
          Mean value_function loss: 75.8665
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 88.7791
                       Mean reward: 375.72
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 75.6964
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0728
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.32s
                      Time elapsed: 00:49:50
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 40964 steps/s (collection: 2.230s, learning 0.170s)
             Mean action noise std: 4.38
          Mean value_function loss: 98.0299
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.7934
                       Mean reward: 356.38
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 1.1739
    Episode_Reward/rotating_object: 68.6295
        Episode_Reward/action_rate: -0.1314
          Episode_Reward/joint_vel: -0.0713
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.40s
                      Time elapsed: 00:49:52
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 45504 steps/s (collection: 2.039s, learning 0.121s)
             Mean action noise std: 4.38
          Mean value_function loss: 77.1725
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 88.8049
                       Mean reward: 347.02
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 72.0930
        Episode_Reward/action_rate: -0.1335
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.16s
                      Time elapsed: 00:49:54
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 46199 steps/s (collection: 1.955s, learning 0.172s)
             Mean action noise std: 4.38
          Mean value_function loss: 70.8881
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 88.8093
                       Mean reward: 365.87
               Mean episode length: 236.01
    Episode_Reward/reaching_object: 1.1957
    Episode_Reward/rotating_object: 69.2880
        Episode_Reward/action_rate: -0.1335
          Episode_Reward/joint_vel: -0.0716
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.13s
                      Time elapsed: 00:49:56
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 40377 steps/s (collection: 2.294s, learning 0.141s)
             Mean action noise std: 4.38
          Mean value_function loss: 82.2713
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 88.8118
                       Mean reward: 364.24
               Mean episode length: 229.98
    Episode_Reward/reaching_object: 1.1781
    Episode_Reward/rotating_object: 71.1027
        Episode_Reward/action_rate: -0.1309
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.43s
                      Time elapsed: 00:49:59
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 45718 steps/s (collection: 1.955s, learning 0.195s)
             Mean action noise std: 4.38
          Mean value_function loss: 77.8121
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.8202
                       Mean reward: 374.15
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 74.2963
        Episode_Reward/action_rate: -0.1349
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.15s
                      Time elapsed: 00:50:01
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 49613 steps/s (collection: 1.881s, learning 0.100s)
             Mean action noise std: 4.38
          Mean value_function loss: 78.9969
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 88.8370
                       Mean reward: 397.51
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.1901
    Episode_Reward/rotating_object: 74.8427
        Episode_Reward/action_rate: -0.1324
          Episode_Reward/joint_vel: -0.0711
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 1.98s
                      Time elapsed: 00:50:03
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 45156 steps/s (collection: 2.067s, learning 0.110s)
             Mean action noise std: 4.39
          Mean value_function loss: 71.7909
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.8554
                       Mean reward: 401.70
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 1.2431
    Episode_Reward/rotating_object: 78.8983
        Episode_Reward/action_rate: -0.1366
          Episode_Reward/joint_vel: -0.0732
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.18s
                      Time elapsed: 00:50:05
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 41700 steps/s (collection: 2.163s, learning 0.195s)
             Mean action noise std: 4.39
          Mean value_function loss: 70.8572
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 88.8674
                       Mean reward: 382.84
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 74.9805
        Episode_Reward/action_rate: -0.1347
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.36s
                      Time elapsed: 00:50:08
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 46950 steps/s (collection: 1.967s, learning 0.127s)
             Mean action noise std: 4.39
          Mean value_function loss: 69.9158
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.8752
                       Mean reward: 400.24
               Mean episode length: 231.36
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 76.8429
        Episode_Reward/action_rate: -0.1346
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.09s
                      Time elapsed: 00:50:10
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 49322 steps/s (collection: 1.873s, learning 0.121s)
             Mean action noise std: 4.39
          Mean value_function loss: 71.3040
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 88.8865
                       Mean reward: 367.98
               Mean episode length: 247.02
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 73.8797
        Episode_Reward/action_rate: -0.1350
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.99s
                      Time elapsed: 00:50:12
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 50069 steps/s (collection: 1.839s, learning 0.124s)
             Mean action noise std: 4.39
          Mean value_function loss: 78.6097
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 88.8986
                       Mean reward: 402.15
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.2128
    Episode_Reward/rotating_object: 74.6302
        Episode_Reward/action_rate: -0.1363
          Episode_Reward/joint_vel: -0.0718
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 1.96s
                      Time elapsed: 00:50:14
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 49047 steps/s (collection: 1.879s, learning 0.125s)
             Mean action noise std: 4.40
          Mean value_function loss: 72.4017
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 88.9139
                       Mean reward: 435.86
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.2089
    Episode_Reward/rotating_object: 79.9964
        Episode_Reward/action_rate: -0.1355
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.00s
                      Time elapsed: 00:50:16
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 50758 steps/s (collection: 1.811s, learning 0.126s)
             Mean action noise std: 4.40
          Mean value_function loss: 80.3301
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 88.9280
                       Mean reward: 357.34
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 75.9636
        Episode_Reward/action_rate: -0.1367
          Episode_Reward/joint_vel: -0.0739
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.94s
                      Time elapsed: 00:50:18
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 50430 steps/s (collection: 1.819s, learning 0.130s)
             Mean action noise std: 4.40
          Mean value_function loss: 70.7773
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 88.9361
                       Mean reward: 411.62
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 78.0268
        Episode_Reward/action_rate: -0.1369
          Episode_Reward/joint_vel: -0.0733
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.95s
                      Time elapsed: 00:50:20
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 48687 steps/s (collection: 1.880s, learning 0.139s)
             Mean action noise std: 4.40
          Mean value_function loss: 82.9461
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.9481
                       Mean reward: 359.82
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.1830
    Episode_Reward/rotating_object: 75.9630
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0720
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.02s
                      Time elapsed: 00:50:22
                               ETA: 00:07:04

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 47688 steps/s (collection: 1.934s, learning 0.128s)
             Mean action noise std: 4.40
          Mean value_function loss: 96.3645
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 88.9587
                       Mean reward: 360.15
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 76.9791
        Episode_Reward/action_rate: -0.1365
          Episode_Reward/joint_vel: -0.0741
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.06s
                      Time elapsed: 00:50:24
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 51306 steps/s (collection: 1.791s, learning 0.125s)
             Mean action noise std: 4.40
          Mean value_function loss: 79.8091
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 88.9682
                       Mean reward: 415.06
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 1.1936
    Episode_Reward/rotating_object: 74.7159
        Episode_Reward/action_rate: -0.1353
          Episode_Reward/joint_vel: -0.0723
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.92s
                      Time elapsed: 00:50:26
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 52113 steps/s (collection: 1.773s, learning 0.113s)
             Mean action noise std: 4.41
          Mean value_function loss: 85.7331
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 88.9821
                       Mean reward: 375.33
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 1.2113
    Episode_Reward/rotating_object: 76.1981
        Episode_Reward/action_rate: -0.1371
          Episode_Reward/joint_vel: -0.0733
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.89s
                      Time elapsed: 00:50:27
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 47485 steps/s (collection: 1.946s, learning 0.124s)
             Mean action noise std: 4.41
          Mean value_function loss: 82.8853
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.9928
                       Mean reward: 351.00
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 72.6382
        Episode_Reward/action_rate: -0.1344
          Episode_Reward/joint_vel: -0.0715
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.07s
                      Time elapsed: 00:50:29
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 46719 steps/s (collection: 1.987s, learning 0.118s)
             Mean action noise std: 4.41
          Mean value_function loss: 79.8782
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.0056
                       Mean reward: 424.23
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.2089
    Episode_Reward/rotating_object: 77.5229
        Episode_Reward/action_rate: -0.1360
          Episode_Reward/joint_vel: -0.0717
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.10s
                      Time elapsed: 00:50:32
                               ETA: 00:06:53

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 53464 steps/s (collection: 1.739s, learning 0.100s)
             Mean action noise std: 4.41
          Mean value_function loss: 85.1666
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 89.0190
                       Mean reward: 395.98
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 77.8530
        Episode_Reward/action_rate: -0.1369
          Episode_Reward/joint_vel: -0.0726
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 1.84s
                      Time elapsed: 00:50:33
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 49022 steps/s (collection: 1.888s, learning 0.118s)
             Mean action noise std: 4.41
          Mean value_function loss: 82.0903
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 89.0292
                       Mean reward: 385.37
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 73.2199
        Episode_Reward/action_rate: -0.1358
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.01s
                      Time elapsed: 00:50:35
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 52134 steps/s (collection: 1.779s, learning 0.107s)
             Mean action noise std: 4.42
          Mean value_function loss: 82.0038
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.0440
                       Mean reward: 382.96
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.2041
    Episode_Reward/rotating_object: 76.5710
        Episode_Reward/action_rate: -0.1348
          Episode_Reward/joint_vel: -0.0719
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 1.89s
                      Time elapsed: 00:50:37
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 49849 steps/s (collection: 1.830s, learning 0.142s)
             Mean action noise std: 4.42
          Mean value_function loss: 83.2919
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 89.0577
                       Mean reward: 398.58
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 74.5869
        Episode_Reward/action_rate: -0.1348
          Episode_Reward/joint_vel: -0.0702
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 1.97s
                      Time elapsed: 00:50:39
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 47880 steps/s (collection: 1.943s, learning 0.110s)
             Mean action noise std: 4.42
          Mean value_function loss: 94.6488
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 89.0606
                       Mean reward: 390.16
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.2280
    Episode_Reward/rotating_object: 79.4041
        Episode_Reward/action_rate: -0.1379
          Episode_Reward/joint_vel: -0.0722
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.05s
                      Time elapsed: 00:50:41
                               ETA: 00:06:41

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 52021 steps/s (collection: 1.779s, learning 0.111s)
             Mean action noise std: 4.42
          Mean value_function loss: 80.4784
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 89.0672
                       Mean reward: 395.55
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 73.2863
        Episode_Reward/action_rate: -0.1354
          Episode_Reward/joint_vel: -0.0716
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 1.89s
                      Time elapsed: 00:50:43
                               ETA: 00:06:39

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 52816 steps/s (collection: 1.742s, learning 0.119s)
             Mean action noise std: 4.42
          Mean value_function loss: 89.1778
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 89.0774
                       Mean reward: 389.49
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 79.6302
        Episode_Reward/action_rate: -0.1352
          Episode_Reward/joint_vel: -0.0709
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 1.86s
                      Time elapsed: 00:50:45
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 53172 steps/s (collection: 1.747s, learning 0.102s)
             Mean action noise std: 4.42
          Mean value_function loss: 71.0408
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 89.0845
                       Mean reward: 370.07
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 77.1584
        Episode_Reward/action_rate: -0.1361
          Episode_Reward/joint_vel: -0.0718
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 1.85s
                      Time elapsed: 00:50:47
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 51765 steps/s (collection: 1.785s, learning 0.114s)
             Mean action noise std: 4.42
          Mean value_function loss: 83.3203
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.0941
                       Mean reward: 396.59
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 77.8870
        Episode_Reward/action_rate: -0.1359
          Episode_Reward/joint_vel: -0.0706
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.90s
                      Time elapsed: 00:50:49
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 52259 steps/s (collection: 1.762s, learning 0.119s)
             Mean action noise std: 4.43
          Mean value_function loss: 71.3883
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 89.1040
                       Mean reward: 416.16
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 78.3991
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0721
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.88s
                      Time elapsed: 00:50:51
                               ETA: 00:06:29

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 51274 steps/s (collection: 1.793s, learning 0.125s)
             Mean action noise std: 4.43
          Mean value_function loss: 79.3206
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 89.1199
                       Mean reward: 395.38
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 78.0672
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0725
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 1.92s
                      Time elapsed: 00:50:53
                               ETA: 00:06:27

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 52551 steps/s (collection: 1.755s, learning 0.116s)
             Mean action noise std: 4.43
          Mean value_function loss: 75.5879
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 89.1293
                       Mean reward: 395.91
               Mean episode length: 224.15
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 78.8192
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 1.87s
                      Time elapsed: 00:50:54
                               ETA: 00:06:25

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 19716 steps/s (collection: 4.854s, learning 0.132s)
             Mean action noise std: 4.43
          Mean value_function loss: 66.7769
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 89.1380
                       Mean reward: 366.06
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 77.4812
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 4.99s
                      Time elapsed: 00:50:59
                               ETA: 00:06:23

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14939 steps/s (collection: 6.444s, learning 0.137s)
             Mean action noise std: 4.43
          Mean value_function loss: 79.3500
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 89.1542
                       Mean reward: 386.70
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.1733
    Episode_Reward/rotating_object: 76.8565
        Episode_Reward/action_rate: -0.1353
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.58s
                      Time elapsed: 00:51:06
                               ETA: 00:06:21

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14657 steps/s (collection: 6.552s, learning 0.155s)
             Mean action noise std: 4.44
          Mean value_function loss: 78.8213
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.1683
                       Mean reward: 373.86
               Mean episode length: 244.81
    Episode_Reward/reaching_object: 1.1915
    Episode_Reward/rotating_object: 75.4493
        Episode_Reward/action_rate: -0.1381
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.71s
                      Time elapsed: 00:51:13
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14660 steps/s (collection: 6.567s, learning 0.139s)
             Mean action noise std: 4.44
          Mean value_function loss: 88.3278
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 89.1772
                       Mean reward: 376.77
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.1676
    Episode_Reward/rotating_object: 74.1317
        Episode_Reward/action_rate: -0.1358
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.71s
                      Time elapsed: 00:51:19
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 13777 steps/s (collection: 6.933s, learning 0.202s)
             Mean action noise std: 4.44
          Mean value_function loss: 83.7860
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 89.1876
                       Mean reward: 345.63
               Mean episode length: 236.66
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 76.9866
        Episode_Reward/action_rate: -0.1384
          Episode_Reward/joint_vel: -0.0689
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 7.13s
                      Time elapsed: 00:51:27
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 13503 steps/s (collection: 7.085s, learning 0.195s)
             Mean action noise std: 4.44
          Mean value_function loss: 82.2387
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 89.2049
                       Mean reward: 366.81
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 1.2130
    Episode_Reward/rotating_object: 79.2889
        Episode_Reward/action_rate: -0.1394
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 7.28s
                      Time elapsed: 00:51:34
                               ETA: 00:06:14

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14099 steps/s (collection: 6.824s, learning 0.148s)
             Mean action noise std: 4.44
          Mean value_function loss: 103.6865
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 89.2187
                       Mean reward: 386.66
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.2061
    Episode_Reward/rotating_object: 80.2207
        Episode_Reward/action_rate: -0.1386
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.97s
                      Time elapsed: 00:51:41
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14289 steps/s (collection: 6.742s, learning 0.138s)
             Mean action noise std: 4.44
          Mean value_function loss: 103.4169
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 89.2299
                       Mean reward: 369.92
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 76.8445
        Episode_Reward/action_rate: -0.1383
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.88s
                      Time elapsed: 00:51:48
                               ETA: 00:06:10

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 13739 steps/s (collection: 7.024s, learning 0.131s)
             Mean action noise std: 4.45
          Mean value_function loss: 94.2716
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 89.2401
                       Mean reward: 402.72
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.1994
    Episode_Reward/rotating_object: 75.4288
        Episode_Reward/action_rate: -0.1375
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.15s
                      Time elapsed: 00:51:55
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 48862 steps/s (collection: 1.887s, learning 0.125s)
             Mean action noise std: 4.45
          Mean value_function loss: 77.0294
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.2482
                       Mean reward: 389.20
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 79.5722
        Episode_Reward/action_rate: -0.1378
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.01s
                      Time elapsed: 00:51:57
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 49537 steps/s (collection: 1.860s, learning 0.125s)
             Mean action noise std: 4.45
          Mean value_function loss: 82.2151
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 89.2616
                       Mean reward: 397.43
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.1838
    Episode_Reward/rotating_object: 75.0630
        Episode_Reward/action_rate: -0.1364
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.98s
                      Time elapsed: 00:51:59
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 45530 steps/s (collection: 2.025s, learning 0.134s)
             Mean action noise std: 4.45
          Mean value_function loss: 69.5230
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.2725
                       Mean reward: 349.19
               Mean episode length: 226.81
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 78.6547
        Episode_Reward/action_rate: -0.1370
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.16s
                      Time elapsed: 00:52:01
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 50015 steps/s (collection: 1.845s, learning 0.120s)
             Mean action noise std: 4.45
          Mean value_function loss: 78.4860
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 89.2799
                       Mean reward: 420.29
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.1989
    Episode_Reward/rotating_object: 77.3210
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.97s
                      Time elapsed: 00:52:03
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 50137 steps/s (collection: 1.786s, learning 0.175s)
             Mean action noise std: 4.45
          Mean value_function loss: 75.0643
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 89.2879
                       Mean reward: 396.42
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.1875
    Episode_Reward/rotating_object: 76.6555
        Episode_Reward/action_rate: -0.1380
          Episode_Reward/joint_vel: -0.0697
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.96s
                      Time elapsed: 00:52:05
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 35926 steps/s (collection: 2.519s, learning 0.217s)
             Mean action noise std: 4.46
          Mean value_function loss: 80.4456
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 89.3027
                       Mean reward: 386.76
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.2115
    Episode_Reward/rotating_object: 76.0736
        Episode_Reward/action_rate: -0.1399
          Episode_Reward/joint_vel: -0.0707
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.74s
                      Time elapsed: 00:52:08
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 43087 steps/s (collection: 2.110s, learning 0.171s)
             Mean action noise std: 4.46
          Mean value_function loss: 76.1965
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 89.3214
                       Mean reward: 361.97
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 74.9443
        Episode_Reward/action_rate: -0.1392
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.28s
                      Time elapsed: 00:52:10
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 36547 steps/s (collection: 2.475s, learning 0.215s)
             Mean action noise std: 4.46
          Mean value_function loss: 77.7179
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 89.3327
                       Mean reward: 388.83
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 78.9007
        Episode_Reward/action_rate: -0.1393
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.69s
                      Time elapsed: 00:52:13
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 42534 steps/s (collection: 2.152s, learning 0.159s)
             Mean action noise std: 4.46
          Mean value_function loss: 80.0478
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 89.3472
                       Mean reward: 383.46
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.1906
    Episode_Reward/rotating_object: 76.0986
        Episode_Reward/action_rate: -0.1386
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.31s
                      Time elapsed: 00:52:15
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 40773 steps/s (collection: 2.236s, learning 0.175s)
             Mean action noise std: 4.47
          Mean value_function loss: 83.2754
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.3620
                       Mean reward: 397.21
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 1.2122
    Episode_Reward/rotating_object: 76.9962
        Episode_Reward/action_rate: -0.1393
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.41s
                      Time elapsed: 00:52:17
                               ETA: 00:05:45

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 43713 steps/s (collection: 2.086s, learning 0.163s)
             Mean action noise std: 4.47
          Mean value_function loss: 79.4471
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 89.3786
                       Mean reward: 409.59
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 78.0121
        Episode_Reward/action_rate: -0.1392
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.25s
                      Time elapsed: 00:52:20
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 45166 steps/s (collection: 2.015s, learning 0.162s)
             Mean action noise std: 4.47
          Mean value_function loss: 74.9140
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 89.3953
                       Mean reward: 426.62
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 79.2242
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.18s
                      Time elapsed: 00:52:22
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 45514 steps/s (collection: 1.978s, learning 0.182s)
             Mean action noise std: 4.47
          Mean value_function loss: 80.1864
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 89.4127
                       Mean reward: 400.92
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 74.4791
        Episode_Reward/action_rate: -0.1396
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.16s
                      Time elapsed: 00:52:24
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 45883 steps/s (collection: 2.030s, learning 0.112s)
             Mean action noise std: 4.48
          Mean value_function loss: 75.0848
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 89.4262
                       Mean reward: 390.11
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 75.4662
        Episode_Reward/action_rate: -0.1366
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.14s
                      Time elapsed: 00:52:26
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 46252 steps/s (collection: 1.936s, learning 0.190s)
             Mean action noise std: 4.48
          Mean value_function loss: 86.9512
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 89.4340
                       Mean reward: 416.58
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 75.0598
        Episode_Reward/action_rate: -0.1405
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.13s
                      Time elapsed: 00:52:28
                               ETA: 00:05:34

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 44527 steps/s (collection: 2.020s, learning 0.188s)
             Mean action noise std: 4.48
          Mean value_function loss: 87.6246
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 89.4489
                       Mean reward: 380.16
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.2194
    Episode_Reward/rotating_object: 77.6050
        Episode_Reward/action_rate: -0.1403
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.21s
                      Time elapsed: 00:52:30
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 41295 steps/s (collection: 2.229s, learning 0.151s)
             Mean action noise std: 4.48
          Mean value_function loss: 82.1759
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 89.4681
                       Mean reward: 412.56
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.2095
    Episode_Reward/rotating_object: 77.3992
        Episode_Reward/action_rate: -0.1395
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.38s
                      Time elapsed: 00:52:33
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 37772 steps/s (collection: 2.336s, learning 0.266s)
             Mean action noise std: 4.48
          Mean value_function loss: 86.9953
               Mean surrogate loss: 0.0026
                 Mean entropy loss: 89.4855
                       Mean reward: 405.61
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 82.4822
        Episode_Reward/action_rate: -0.1403
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.60s
                      Time elapsed: 00:52:35
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 38392 steps/s (collection: 2.341s, learning 0.219s)
             Mean action noise std: 4.48
          Mean value_function loss: 81.5666
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 89.4880
                       Mean reward: 413.26
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 1.2041
    Episode_Reward/rotating_object: 77.8543
        Episode_Reward/action_rate: -0.1386
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.56s
                      Time elapsed: 00:52:38
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 46932 steps/s (collection: 1.968s, learning 0.127s)
             Mean action noise std: 4.49
          Mean value_function loss: 80.0022
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 89.4894
                       Mean reward: 381.61
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 1.2103
    Episode_Reward/rotating_object: 78.5706
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.09s
                      Time elapsed: 00:52:40
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 53142 steps/s (collection: 1.737s, learning 0.113s)
             Mean action noise std: 4.49
          Mean value_function loss: 73.6428
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 89.4949
                       Mean reward: 405.63
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 79.7227
        Episode_Reward/action_rate: -0.1430
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.85s
                      Time elapsed: 00:52:42
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 51193 steps/s (collection: 1.800s, learning 0.120s)
             Mean action noise std: 4.49
          Mean value_function loss: 83.9719
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 89.5116
                       Mean reward: 435.40
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 1.2294
    Episode_Reward/rotating_object: 79.5756
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.92s
                      Time elapsed: 00:52:44
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 52157 steps/s (collection: 1.771s, learning 0.114s)
             Mean action noise std: 4.49
          Mean value_function loss: 83.8129
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 89.5261
                       Mean reward: 391.20
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 76.8412
        Episode_Reward/action_rate: -0.1428
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.88s
                      Time elapsed: 00:52:46
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 46588 steps/s (collection: 1.996s, learning 0.115s)
             Mean action noise std: 4.49
          Mean value_function loss: 87.6201
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 89.5344
                       Mean reward: 380.42
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.2253
    Episode_Reward/rotating_object: 77.0083
        Episode_Reward/action_rate: -0.1424
          Episode_Reward/joint_vel: -0.0690
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.11s
                      Time elapsed: 00:52:48
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 51506 steps/s (collection: 1.796s, learning 0.112s)
             Mean action noise std: 4.49
          Mean value_function loss: 86.5711
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 89.5460
                       Mean reward: 424.43
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 1.2436
    Episode_Reward/rotating_object: 83.2044
        Episode_Reward/action_rate: -0.1433
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.91s
                      Time elapsed: 00:52:50
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 51216 steps/s (collection: 1.805s, learning 0.114s)
             Mean action noise std: 4.50
          Mean value_function loss: 106.8133
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 89.5551
                       Mean reward: 393.01
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 78.4963
        Episode_Reward/action_rate: -0.1421
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.92s
                      Time elapsed: 00:52:52
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 50910 steps/s (collection: 1.813s, learning 0.118s)
             Mean action noise std: 4.50
          Mean value_function loss: 105.7721
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 89.5589
                       Mean reward: 433.25
               Mean episode length: 245.34
    Episode_Reward/reaching_object: 1.2328
    Episode_Reward/rotating_object: 83.4029
        Episode_Reward/action_rate: -0.1427
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.93s
                      Time elapsed: 00:52:54
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 52822 steps/s (collection: 1.768s, learning 0.093s)
             Mean action noise std: 4.50
          Mean value_function loss: 100.4901
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 89.5610
                       Mean reward: 377.11
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 74.8042
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0679
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.86s
                      Time elapsed: 00:52:55
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 53840 steps/s (collection: 1.725s, learning 0.101s)
             Mean action noise std: 4.50
          Mean value_function loss: 95.3180
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 89.5623
                       Mean reward: 397.15
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 1.2225
    Episode_Reward/rotating_object: 77.8282
        Episode_Reward/action_rate: -0.1415
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.83s
                      Time elapsed: 00:52:57
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 52308 steps/s (collection: 1.759s, learning 0.121s)
             Mean action noise std: 4.50
          Mean value_function loss: 106.5823
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 89.5674
                       Mean reward: 407.52
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.2278
    Episode_Reward/rotating_object: 77.3532
        Episode_Reward/action_rate: -0.1424
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.88s
                      Time elapsed: 00:52:59
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 49329 steps/s (collection: 1.867s, learning 0.126s)
             Mean action noise std: 4.50
          Mean value_function loss: 99.3129
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 89.5788
                       Mean reward: 388.57
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 75.6981
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.99s
                      Time elapsed: 00:53:01
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 52274 steps/s (collection: 1.767s, learning 0.114s)
             Mean action noise std: 4.50
          Mean value_function loss: 81.1256
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 89.5919
                       Mean reward: 421.21
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 79.6728
        Episode_Reward/action_rate: -0.1431
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.88s
                      Time elapsed: 00:53:03
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 52750 steps/s (collection: 1.751s, learning 0.113s)
             Mean action noise std: 4.50
          Mean value_function loss: 92.9276
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 89.6015
                       Mean reward: 387.63
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 74.2408
        Episode_Reward/action_rate: -0.1420
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.86s
                      Time elapsed: 00:53:05
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 53796 steps/s (collection: 1.715s, learning 0.113s)
             Mean action noise std: 4.51
          Mean value_function loss: 83.0894
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.6097
                       Mean reward: 405.90
               Mean episode length: 240.52
    Episode_Reward/reaching_object: 1.2290
    Episode_Reward/rotating_object: 77.3796
        Episode_Reward/action_rate: -0.1435
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.83s
                      Time elapsed: 00:53:07
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 52227 steps/s (collection: 1.789s, learning 0.093s)
             Mean action noise std: 4.51
          Mean value_function loss: 95.3281
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 89.6231
                       Mean reward: 379.10
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 78.8313
        Episode_Reward/action_rate: -0.1427
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.88s
                      Time elapsed: 00:53:09
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 52088 steps/s (collection: 1.771s, learning 0.117s)
             Mean action noise std: 4.51
          Mean value_function loss: 87.9227
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 89.6362
                       Mean reward: 426.15
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 79.1240
        Episode_Reward/action_rate: -0.1422
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.89s
                      Time elapsed: 00:53:11
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 53580 steps/s (collection: 1.721s, learning 0.114s)
             Mean action noise std: 4.51
          Mean value_function loss: 78.6777
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.6518
                       Mean reward: 399.07
               Mean episode length: 233.70
    Episode_Reward/reaching_object: 1.2061
    Episode_Reward/rotating_object: 77.8388
        Episode_Reward/action_rate: -0.1428
          Episode_Reward/joint_vel: -0.0658
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.83s
                      Time elapsed: 00:53:12
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 52319 steps/s (collection: 1.761s, learning 0.118s)
             Mean action noise std: 4.51
          Mean value_function loss: 78.5933
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 89.6677
                       Mean reward: 423.88
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 78.5992
        Episode_Reward/action_rate: -0.1410
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.88s
                      Time elapsed: 00:53:14
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 52889 steps/s (collection: 1.750s, learning 0.109s)
             Mean action noise std: 4.52
          Mean value_function loss: 94.6464
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 89.6868
                       Mean reward: 416.56
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 80.6501
        Episode_Reward/action_rate: -0.1440
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.86s
                      Time elapsed: 00:53:16
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 52004 steps/s (collection: 1.766s, learning 0.124s)
             Mean action noise std: 4.52
          Mean value_function loss: 83.5705
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 89.6992
                       Mean reward: 389.99
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 1.1851
    Episode_Reward/rotating_object: 78.4490
        Episode_Reward/action_rate: -0.1408
          Episode_Reward/joint_vel: -0.0649
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.89s
                      Time elapsed: 00:53:18
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 51387 steps/s (collection: 1.797s, learning 0.116s)
             Mean action noise std: 4.52
          Mean value_function loss: 90.7348
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.7068
                       Mean reward: 376.60
               Mean episode length: 234.28
    Episode_Reward/reaching_object: 1.1907
    Episode_Reward/rotating_object: 78.3414
        Episode_Reward/action_rate: -0.1424
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.91s
                      Time elapsed: 00:53:20
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 52620 steps/s (collection: 1.765s, learning 0.103s)
             Mean action noise std: 4.52
          Mean value_function loss: 96.7949
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 89.7147
                       Mean reward: 388.91
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 78.9248
        Episode_Reward/action_rate: -0.1429
          Episode_Reward/joint_vel: -0.0642
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.87s
                      Time elapsed: 00:53:22
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 51757 steps/s (collection: 1.795s, learning 0.104s)
             Mean action noise std: 4.52
          Mean value_function loss: 96.9539
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 89.7219
                       Mean reward: 403.37
               Mean episode length: 241.49
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 78.7672
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.90s
                      Time elapsed: 00:53:24
                               ETA: 00:04:28

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 49004 steps/s (collection: 1.891s, learning 0.115s)
             Mean action noise std: 4.52
          Mean value_function loss: 87.9019
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 89.7328
                       Mean reward: 457.89
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.1947
    Episode_Reward/rotating_object: 77.4273
        Episode_Reward/action_rate: -0.1431
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.01s
                      Time elapsed: 00:53:26
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 51558 steps/s (collection: 1.786s, learning 0.121s)
             Mean action noise std: 4.53
          Mean value_function loss: 82.4464
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 89.7395
                       Mean reward: 389.00
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 81.7474
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0662
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.91s
                      Time elapsed: 00:53:28
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 48580 steps/s (collection: 1.821s, learning 0.202s)
             Mean action noise std: 4.53
          Mean value_function loss: 96.7246
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 89.7466
                       Mean reward: 388.84
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.1960
    Episode_Reward/rotating_object: 77.9773
        Episode_Reward/action_rate: -0.1429
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.02s
                      Time elapsed: 00:53:30
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 47225 steps/s (collection: 1.970s, learning 0.112s)
             Mean action noise std: 4.53
          Mean value_function loss: 89.6367
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 89.7598
                       Mean reward: 378.71
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.1814
    Episode_Reward/rotating_object: 74.9100
        Episode_Reward/action_rate: -0.1424
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.08s
                      Time elapsed: 00:53:32
                               ETA: 00:04:19

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 49650 steps/s (collection: 1.805s, learning 0.175s)
             Mean action noise std: 4.53
          Mean value_function loss: 91.8003
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 89.7692
                       Mean reward: 437.09
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 81.4314
        Episode_Reward/action_rate: -0.1424
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.98s
                      Time elapsed: 00:53:34
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 50259 steps/s (collection: 1.827s, learning 0.129s)
             Mean action noise std: 4.53
          Mean value_function loss: 84.7933
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 89.7776
                       Mean reward: 419.12
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 81.1371
        Episode_Reward/action_rate: -0.1436
          Episode_Reward/joint_vel: -0.0638
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.96s
                      Time elapsed: 00:53:36
                               ETA: 00:04:14

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 40634 steps/s (collection: 2.208s, learning 0.212s)
             Mean action noise std: 4.53
          Mean value_function loss: 73.3753
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 89.7848
                       Mean reward: 402.46
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.2236
    Episode_Reward/rotating_object: 82.4705
        Episode_Reward/action_rate: -0.1468
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.42s
                      Time elapsed: 00:53:38
                               ETA: 00:04:12

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 45911 steps/s (collection: 1.970s, learning 0.172s)
             Mean action noise std: 4.54
          Mean value_function loss: 73.3556
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 89.8008
                       Mean reward: 402.86
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 76.2381
        Episode_Reward/action_rate: -0.1458
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.14s
                      Time elapsed: 00:53:40
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 50049 steps/s (collection: 1.849s, learning 0.116s)
             Mean action noise std: 4.54
          Mean value_function loss: 76.5087
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.8205
                       Mean reward: 384.37
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 1.1956
    Episode_Reward/rotating_object: 76.9455
        Episode_Reward/action_rate: -0.1452
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.96s
                      Time elapsed: 00:53:42
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 48223 steps/s (collection: 1.929s, learning 0.109s)
             Mean action noise std: 4.54
          Mean value_function loss: 83.6783
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 89.8334
                       Mean reward: 423.26
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.1928
    Episode_Reward/rotating_object: 79.3595
        Episode_Reward/action_rate: -0.1435
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.04s
                      Time elapsed: 00:53:44
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 52613 steps/s (collection: 1.744s, learning 0.125s)
             Mean action noise std: 4.54
          Mean value_function loss: 81.1061
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 89.8418
                       Mean reward: 373.61
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.1654
    Episode_Reward/rotating_object: 72.7101
        Episode_Reward/action_rate: -0.1433
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.87s
                      Time elapsed: 00:53:46
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 52139 steps/s (collection: 1.777s, learning 0.108s)
             Mean action noise std: 4.54
          Mean value_function loss: 75.4315
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 89.8511
                       Mean reward: 384.66
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 76.6664
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0634
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.89s
                      Time elapsed: 00:53:48
                               ETA: 00:04:00

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 53594 steps/s (collection: 1.713s, learning 0.122s)
             Mean action noise std: 4.55
          Mean value_function loss: 82.2188
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 89.8602
                       Mean reward: 375.01
               Mean episode length: 228.11
    Episode_Reward/reaching_object: 1.1849
    Episode_Reward/rotating_object: 77.3625
        Episode_Reward/action_rate: -0.1438
          Episode_Reward/joint_vel: -0.0639
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.83s
                      Time elapsed: 00:53:50
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 53356 steps/s (collection: 1.740s, learning 0.102s)
             Mean action noise std: 4.55
          Mean value_function loss: 82.9633
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 89.8699
                       Mean reward: 375.69
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.1808
    Episode_Reward/rotating_object: 77.4170
        Episode_Reward/action_rate: -0.1434
          Episode_Reward/joint_vel: -0.0629
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.84s
                      Time elapsed: 00:53:52
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 52549 steps/s (collection: 1.745s, learning 0.126s)
             Mean action noise std: 4.55
          Mean value_function loss: 83.8289
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 89.8806
                       Mean reward: 390.84
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 1.1916
    Episode_Reward/rotating_object: 76.7866
        Episode_Reward/action_rate: -0.1451
          Episode_Reward/joint_vel: -0.0636
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.87s
                      Time elapsed: 00:53:53
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 52324 steps/s (collection: 1.765s, learning 0.113s)
             Mean action noise std: 4.55
          Mean value_function loss: 82.5678
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 89.8920
                       Mean reward: 415.78
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 79.8010
        Episode_Reward/action_rate: -0.1461
          Episode_Reward/joint_vel: -0.0647
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.88s
                      Time elapsed: 00:53:55
                               ETA: 00:03:50

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 52394 steps/s (collection: 1.763s, learning 0.114s)
             Mean action noise std: 4.55
          Mean value_function loss: 80.1213
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 89.9036
                       Mean reward: 424.18
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 82.4526
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.88s
                      Time elapsed: 00:53:57
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 52568 steps/s (collection: 1.752s, learning 0.118s)
             Mean action noise std: 4.55
          Mean value_function loss: 73.0019
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 89.9154
                       Mean reward: 392.64
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.2185
    Episode_Reward/rotating_object: 81.9593
        Episode_Reward/action_rate: -0.1461
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.87s
                      Time elapsed: 00:53:59
                               ETA: 00:03:46

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 50642 steps/s (collection: 1.821s, learning 0.120s)
             Mean action noise std: 4.56
          Mean value_function loss: 81.1471
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 89.9315
                       Mean reward: 397.16
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 1.2205
    Episode_Reward/rotating_object: 82.2296
        Episode_Reward/action_rate: -0.1451
          Episode_Reward/joint_vel: -0.0637
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.94s
                      Time elapsed: 00:54:01
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 53964 steps/s (collection: 1.723s, learning 0.099s)
             Mean action noise std: 4.56
          Mean value_function loss: 76.6994
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 89.9434
                       Mean reward: 401.62
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 1.1950
    Episode_Reward/rotating_object: 75.2952
        Episode_Reward/action_rate: -0.1455
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.82s
                      Time elapsed: 00:54:03
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 52660 steps/s (collection: 1.751s, learning 0.116s)
             Mean action noise std: 4.56
          Mean value_function loss: 88.3971
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 89.9536
                       Mean reward: 371.36
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 80.7469
        Episode_Reward/action_rate: -0.1457
          Episode_Reward/joint_vel: -0.0653
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.87s
                      Time elapsed: 00:54:05
                               ETA: 00:03:39

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 53420 steps/s (collection: 1.728s, learning 0.113s)
             Mean action noise std: 4.56
          Mean value_function loss: 75.0719
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 89.9613
                       Mean reward: 423.20
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 76.7975
        Episode_Reward/action_rate: -0.1481
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.84s
                      Time elapsed: 00:54:07
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 53225 steps/s (collection: 1.733s, learning 0.114s)
             Mean action noise std: 4.56
          Mean value_function loss: 72.6153
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.9653
                       Mean reward: 446.48
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 83.9823
        Episode_Reward/action_rate: -0.1480
          Episode_Reward/joint_vel: -0.0665
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.85s
                      Time elapsed: 00:54:08
                               ETA: 00:03:34

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 52740 steps/s (collection: 1.747s, learning 0.117s)
             Mean action noise std: 4.56
          Mean value_function loss: 66.1355
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 89.9767
                       Mean reward: 394.95
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 81.7548
        Episode_Reward/action_rate: -0.1485
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.86s
                      Time elapsed: 00:54:10
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 53942 steps/s (collection: 1.728s, learning 0.095s)
             Mean action noise std: 4.57
          Mean value_function loss: 74.9008
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 89.9924
                       Mean reward: 380.34
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.1923
    Episode_Reward/rotating_object: 79.8151
        Episode_Reward/action_rate: -0.1448
          Episode_Reward/joint_vel: -0.0644
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.82s
                      Time elapsed: 00:54:12
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 52982 steps/s (collection: 1.740s, learning 0.116s)
             Mean action noise std: 4.57
          Mean value_function loss: 75.8130
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 90.0039
                       Mean reward: 427.56
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 1.2322
    Episode_Reward/rotating_object: 81.8297
        Episode_Reward/action_rate: -0.1493
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.86s
                      Time elapsed: 00:54:14
                               ETA: 00:03:27

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 52688 steps/s (collection: 1.748s, learning 0.118s)
             Mean action noise std: 4.57
          Mean value_function loss: 75.1635
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 90.0119
                       Mean reward: 400.26
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.2181
    Episode_Reward/rotating_object: 81.5146
        Episode_Reward/action_rate: -0.1488
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.87s
                      Time elapsed: 00:54:16
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 53052 steps/s (collection: 1.734s, learning 0.119s)
             Mean action noise std: 4.57
          Mean value_function loss: 73.2185
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 90.0232
                       Mean reward: 402.89
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.2201
    Episode_Reward/rotating_object: 79.5527
        Episode_Reward/action_rate: -0.1488
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.85s
                      Time elapsed: 00:54:18
                               ETA: 00:03:22

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 52086 steps/s (collection: 1.770s, learning 0.118s)
             Mean action noise std: 4.58
          Mean value_function loss: 78.1144
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 90.0405
                       Mean reward: 426.13
               Mean episode length: 245.35
    Episode_Reward/reaching_object: 1.2236
    Episode_Reward/rotating_object: 80.7776
        Episode_Reward/action_rate: -0.1494
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.89s
                      Time elapsed: 00:54:20
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 52893 steps/s (collection: 1.746s, learning 0.113s)
             Mean action noise std: 4.58
          Mean value_function loss: 73.6430
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 90.0570
                       Mean reward: 419.15
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 84.6249
        Episode_Reward/action_rate: -0.1485
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.86s
                      Time elapsed: 00:54:21
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 53862 steps/s (collection: 1.731s, learning 0.094s)
             Mean action noise std: 4.58
          Mean value_function loss: 88.5542
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 90.0721
                       Mean reward: 446.71
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.2107
    Episode_Reward/rotating_object: 81.5384
        Episode_Reward/action_rate: -0.1480
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.83s
                      Time elapsed: 00:54:23
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 52509 steps/s (collection: 1.762s, learning 0.111s)
             Mean action noise std: 4.58
          Mean value_function loss: 73.2808
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 90.0886
                       Mean reward: 439.62
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 81.3947
        Episode_Reward/action_rate: -0.1471
          Episode_Reward/joint_vel: -0.0654
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.87s
                      Time elapsed: 00:54:25
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 52744 steps/s (collection: 1.755s, learning 0.109s)
             Mean action noise std: 4.58
          Mean value_function loss: 74.7375
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 90.1078
                       Mean reward: 381.03
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.2056
    Episode_Reward/rotating_object: 79.9886
        Episode_Reward/action_rate: -0.1484
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.86s
                      Time elapsed: 00:54:27
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 51617 steps/s (collection: 1.784s, learning 0.121s)
             Mean action noise std: 4.59
          Mean value_function loss: 74.7823
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 90.1161
                       Mean reward: 435.79
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 88.4046
        Episode_Reward/action_rate: -0.1478
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.90s
                      Time elapsed: 00:54:29
                               ETA: 00:03:08

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 53145 steps/s (collection: 1.727s, learning 0.123s)
             Mean action noise std: 4.59
          Mean value_function loss: 65.8146
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 90.1271
                       Mean reward: 371.85
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 1.1991
    Episode_Reward/rotating_object: 78.7170
        Episode_Reward/action_rate: -0.1482
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.85s
                      Time elapsed: 00:54:31
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 54268 steps/s (collection: 1.714s, learning 0.097s)
             Mean action noise std: 4.59
          Mean value_function loss: 64.2296
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.1385
                       Mean reward: 402.13
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 1.1839
    Episode_Reward/rotating_object: 77.4350
        Episode_Reward/action_rate: -0.1470
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.81s
                      Time elapsed: 00:54:33
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 53580 steps/s (collection: 1.710s, learning 0.125s)
             Mean action noise std: 4.59
          Mean value_function loss: 60.8095
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 90.1443
                       Mean reward: 428.96
               Mean episode length: 241.13
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 82.1687
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0669
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.83s
                      Time elapsed: 00:54:34
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 53427 steps/s (collection: 1.717s, learning 0.123s)
             Mean action noise std: 4.59
          Mean value_function loss: 67.9446
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 90.1472
                       Mean reward: 424.60
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 84.7028
        Episode_Reward/action_rate: -0.1494
          Episode_Reward/joint_vel: -0.0673
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.84s
                      Time elapsed: 00:54:36
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 53428 steps/s (collection: 1.724s, learning 0.116s)
             Mean action noise std: 4.59
          Mean value_function loss: 63.3268
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 90.1499
                       Mean reward: 409.61
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 81.2530
        Episode_Reward/action_rate: -0.1494
          Episode_Reward/joint_vel: -0.0661
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.84s
                      Time elapsed: 00:54:38
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 53623 steps/s (collection: 1.713s, learning 0.120s)
             Mean action noise std: 4.59
          Mean value_function loss: 71.0273
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 90.1532
                       Mean reward: 479.92
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 84.1554
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0686
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.83s
                      Time elapsed: 00:54:40
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 53308 steps/s (collection: 1.745s, learning 0.099s)
             Mean action noise std: 4.59
          Mean value_function loss: 70.9004
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 90.1569
                       Mean reward: 413.08
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 85.3323
        Episode_Reward/action_rate: -0.1483
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.84s
                      Time elapsed: 00:54:42
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 50534 steps/s (collection: 1.830s, learning 0.116s)
             Mean action noise std: 4.59
          Mean value_function loss: 73.7187
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 90.1642
                       Mean reward: 472.16
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 1.1844
    Episode_Reward/rotating_object: 83.3048
        Episode_Reward/action_rate: -0.1491
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.95s
                      Time elapsed: 00:54:44
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 52031 steps/s (collection: 1.769s, learning 0.120s)
             Mean action noise std: 4.59
          Mean value_function loss: 73.5687
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 90.1712
                       Mean reward: 438.50
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 80.8653
        Episode_Reward/action_rate: -0.1496
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.89s
                      Time elapsed: 00:54:46
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 53118 steps/s (collection: 1.741s, learning 0.110s)
             Mean action noise std: 4.60
          Mean value_function loss: 82.6653
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 90.1758
                       Mean reward: 419.71
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 81.6104
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.85s
                      Time elapsed: 00:54:47
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 52129 steps/s (collection: 1.771s, learning 0.115s)
             Mean action noise std: 4.60
          Mean value_function loss: 82.2266
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 90.1876
                       Mean reward: 388.59
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 79.0360
        Episode_Reward/action_rate: -0.1501
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.89s
                      Time elapsed: 00:54:49
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 53208 steps/s (collection: 1.737s, learning 0.111s)
             Mean action noise std: 4.60
          Mean value_function loss: 95.5574
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 90.2022
                       Mean reward: 373.82
               Mean episode length: 234.86
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 83.7665
        Episode_Reward/action_rate: -0.1506
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.85s
                      Time elapsed: 00:54:51
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 52540 steps/s (collection: 1.777s, learning 0.094s)
             Mean action noise std: 4.60
          Mean value_function loss: 83.4635
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.2163
                       Mean reward: 430.78
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 1.1829
    Episode_Reward/rotating_object: 77.2350
        Episode_Reward/action_rate: -0.1471
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.87s
                      Time elapsed: 00:54:53
                               ETA: 00:02:38

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 52930 steps/s (collection: 1.744s, learning 0.114s)
             Mean action noise std: 4.60
          Mean value_function loss: 74.4207
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 90.2295
                       Mean reward: 380.84
               Mean episode length: 247.58
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 81.8524
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0694
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.86s
                      Time elapsed: 00:54:55
                               ETA: 00:02:36

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 52726 steps/s (collection: 1.747s, learning 0.117s)
             Mean action noise std: 4.61
          Mean value_function loss: 90.4146
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 90.2418
                       Mean reward: 420.40
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.2316
    Episode_Reward/rotating_object: 84.2953
        Episode_Reward/action_rate: -0.1496
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.86s
                      Time elapsed: 00:54:57
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 52179 steps/s (collection: 1.758s, learning 0.126s)
             Mean action noise std: 4.61
          Mean value_function loss: 91.8167
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 90.2505
                       Mean reward: 404.51
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.2011
    Episode_Reward/rotating_object: 78.7238
        Episode_Reward/action_rate: -0.1485
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.88s
                      Time elapsed: 00:54:59
                               ETA: 00:02:31

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 51701 steps/s (collection: 1.781s, learning 0.121s)
             Mean action noise std: 4.61
          Mean value_function loss: 73.3737
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 90.2551
                       Mean reward: 451.71
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.2360
    Episode_Reward/rotating_object: 84.9704
        Episode_Reward/action_rate: -0.1510
          Episode_Reward/joint_vel: -0.0718
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.90s
                      Time elapsed: 00:55:01
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 54137 steps/s (collection: 1.719s, learning 0.097s)
             Mean action noise std: 4.61
          Mean value_function loss: 81.3832
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.2658
                       Mean reward: 413.95
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 84.1264
        Episode_Reward/action_rate: -0.1515
          Episode_Reward/joint_vel: -0.0715
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.82s
                      Time elapsed: 00:55:02
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 52775 steps/s (collection: 1.746s, learning 0.117s)
             Mean action noise std: 4.61
          Mean value_function loss: 81.5975
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 90.2786
                       Mean reward: 413.86
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 85.7859
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.86s
                      Time elapsed: 00:55:04
                               ETA: 00:02:24

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 53268 steps/s (collection: 1.726s, learning 0.120s)
             Mean action noise std: 4.62
          Mean value_function loss: 87.4200
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 90.2953
                       Mean reward: 422.11
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 82.3690
        Episode_Reward/action_rate: -0.1469
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.85s
                      Time elapsed: 00:55:06
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 51787 steps/s (collection: 1.780s, learning 0.119s)
             Mean action noise std: 4.62
          Mean value_function loss: 62.5630
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 90.3106
                       Mean reward: 417.50
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 1.2308
    Episode_Reward/rotating_object: 82.6053
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0708
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.90s
                      Time elapsed: 00:55:08
                               ETA: 00:02:20

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 52668 steps/s (collection: 1.751s, learning 0.115s)
             Mean action noise std: 4.62
          Mean value_function loss: 73.4231
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 90.3183
                       Mean reward: 465.19
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 85.2641
        Episode_Reward/action_rate: -0.1515
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.87s
                      Time elapsed: 00:55:10
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 52642 steps/s (collection: 1.761s, learning 0.106s)
             Mean action noise std: 4.62
          Mean value_function loss: 76.1805
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.3300
                       Mean reward: 418.59
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 1.2189
    Episode_Reward/rotating_object: 81.5815
        Episode_Reward/action_rate: -0.1506
          Episode_Reward/joint_vel: -0.0693
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.87s
                      Time elapsed: 00:55:12
                               ETA: 00:02:15

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 52925 steps/s (collection: 1.752s, learning 0.105s)
             Mean action noise std: 4.62
          Mean value_function loss: 76.2926
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 90.3419
                       Mean reward: 404.52
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.2254
    Episode_Reward/rotating_object: 81.3123
        Episode_Reward/action_rate: -0.1510
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.86s
                      Time elapsed: 00:55:14
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 53156 steps/s (collection: 1.727s, learning 0.122s)
             Mean action noise std: 4.62
          Mean value_function loss: 65.7996
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 90.3569
                       Mean reward: 454.71
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 1.2155
    Episode_Reward/rotating_object: 81.2112
        Episode_Reward/action_rate: -0.1494
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.85s
                      Time elapsed: 00:55:15
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 53148 steps/s (collection: 1.739s, learning 0.111s)
             Mean action noise std: 4.63
          Mean value_function loss: 70.6444
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 90.3696
                       Mean reward: 404.47
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 82.7811
        Episode_Reward/action_rate: -0.1502
          Episode_Reward/joint_vel: -0.0692
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.85s
                      Time elapsed: 00:55:17
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 52496 steps/s (collection: 1.754s, learning 0.119s)
             Mean action noise std: 4.63
          Mean value_function loss: 70.0689
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 90.3799
                       Mean reward: 450.66
               Mean episode length: 244.85
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 85.2282
        Episode_Reward/action_rate: -0.1509
          Episode_Reward/joint_vel: -0.0696
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.87s
                      Time elapsed: 00:55:19
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 53072 steps/s (collection: 1.736s, learning 0.117s)
             Mean action noise std: 4.63
          Mean value_function loss: 65.2706
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 90.3882
                       Mean reward: 416.30
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 1.2187
    Episode_Reward/rotating_object: 85.9504
        Episode_Reward/action_rate: -0.1500
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.85s
                      Time elapsed: 00:55:21
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 53445 steps/s (collection: 1.741s, learning 0.099s)
             Mean action noise std: 4.63
          Mean value_function loss: 77.5672
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 90.4008
                       Mean reward: 463.33
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 1.2105
    Episode_Reward/rotating_object: 84.9676
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0681
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.84s
                      Time elapsed: 00:55:23
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 53428 steps/s (collection: 1.728s, learning 0.112s)
             Mean action noise std: 4.63
          Mean value_function loss: 65.1215
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 90.4133
                       Mean reward: 403.38
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.2159
    Episode_Reward/rotating_object: 81.8037
        Episode_Reward/action_rate: -0.1502
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.84s
                      Time elapsed: 00:55:25
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 53016 steps/s (collection: 1.738s, learning 0.116s)
             Mean action noise std: 4.63
          Mean value_function loss: 85.0894
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 90.4220
                       Mean reward: 425.10
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 1.2482
    Episode_Reward/rotating_object: 87.0154
        Episode_Reward/action_rate: -0.1534
          Episode_Reward/joint_vel: -0.0687
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.85s
                      Time elapsed: 00:55:27
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 52894 steps/s (collection: 1.745s, learning 0.113s)
             Mean action noise std: 4.64
          Mean value_function loss: 79.7692
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 90.4282
                       Mean reward: 423.35
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.2218
    Episode_Reward/rotating_object: 82.7617
        Episode_Reward/action_rate: -0.1512
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.86s
                      Time elapsed: 00:55:28
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 51422 steps/s (collection: 1.784s, learning 0.128s)
             Mean action noise std: 4.64
          Mean value_function loss: 74.6063
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.4386
                       Mean reward: 419.55
               Mean episode length: 244.96
    Episode_Reward/reaching_object: 1.2207
    Episode_Reward/rotating_object: 83.0601
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0684
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.91s
                      Time elapsed: 00:55:30
                               ETA: 00:01:52

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 54516 steps/s (collection: 1.706s, learning 0.097s)
             Mean action noise std: 4.64
          Mean value_function loss: 68.3333
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 90.4477
                       Mean reward: 405.89
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 81.9526
        Episode_Reward/action_rate: -0.1523
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.80s
                      Time elapsed: 00:55:32
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 53517 steps/s (collection: 1.702s, learning 0.135s)
             Mean action noise std: 4.64
          Mean value_function loss: 69.4163
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 90.4567
                       Mean reward: 393.19
               Mean episode length: 242.79
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 81.0964
        Episode_Reward/action_rate: -0.1509
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.84s
                      Time elapsed: 00:55:34
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 52809 steps/s (collection: 1.748s, learning 0.114s)
             Mean action noise std: 4.64
          Mean value_function loss: 79.4702
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 90.4651
                       Mean reward: 387.26
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.2036
    Episode_Reward/rotating_object: 79.2663
        Episode_Reward/action_rate: -0.1513
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.86s
                      Time elapsed: 00:55:36
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 52728 steps/s (collection: 1.754s, learning 0.111s)
             Mean action noise std: 4.64
          Mean value_function loss: 86.2932
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 90.4747
                       Mean reward: 415.96
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 1.2146
    Episode_Reward/rotating_object: 83.6657
        Episode_Reward/action_rate: -0.1499
          Episode_Reward/joint_vel: -0.0664
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.86s
                      Time elapsed: 00:55:38
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 52095 steps/s (collection: 1.772s, learning 0.115s)
             Mean action noise std: 4.65
          Mean value_function loss: 72.5960
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 90.4912
                       Mean reward: 440.60
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 84.0382
        Episode_Reward/action_rate: -0.1529
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.89s
                      Time elapsed: 00:55:40
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 52981 steps/s (collection: 1.742s, learning 0.113s)
             Mean action noise std: 4.65
          Mean value_function loss: 81.1967
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 90.5016
                       Mean reward: 427.71
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.2399
    Episode_Reward/rotating_object: 85.9079
        Episode_Reward/action_rate: -0.1535
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.86s
                      Time elapsed: 00:55:41
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 51885 steps/s (collection: 1.798s, learning 0.097s)
             Mean action noise std: 4.65
          Mean value_function loss: 73.0737
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 90.5099
                       Mean reward: 385.31
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.2202
    Episode_Reward/rotating_object: 84.1496
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0660
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.89s
                      Time elapsed: 00:55:43
                               ETA: 00:01:36

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 54015 steps/s (collection: 1.704s, learning 0.116s)
             Mean action noise std: 4.65
          Mean value_function loss: 71.6542
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.5233
                       Mean reward: 384.68
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 1.2143
    Episode_Reward/rotating_object: 82.3741
        Episode_Reward/action_rate: -0.1512
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.82s
                      Time elapsed: 00:55:45
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 53055 steps/s (collection: 1.734s, learning 0.119s)
             Mean action noise std: 4.65
          Mean value_function loss: 79.0138
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 90.5377
                       Mean reward: 452.68
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 1.2160
    Episode_Reward/rotating_object: 82.5663
        Episode_Reward/action_rate: -0.1510
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.85s
                      Time elapsed: 00:55:47
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 53060 steps/s (collection: 1.744s, learning 0.109s)
             Mean action noise std: 4.66
          Mean value_function loss: 74.1143
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 90.5473
                       Mean reward: 413.83
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.2388
    Episode_Reward/rotating_object: 86.5037
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0666
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.85s
                      Time elapsed: 00:55:49
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 53083 steps/s (collection: 1.744s, learning 0.108s)
             Mean action noise std: 4.66
          Mean value_function loss: 80.0540
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 90.5575
                       Mean reward: 435.36
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 1.2343
    Episode_Reward/rotating_object: 84.2975
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0652
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.85s
                      Time elapsed: 00:55:51
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 52616 steps/s (collection: 1.772s, learning 0.096s)
             Mean action noise std: 4.66
          Mean value_function loss: 75.9618
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 90.5661
                       Mean reward: 397.81
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.2176
    Episode_Reward/rotating_object: 84.8827
        Episode_Reward/action_rate: -0.1498
          Episode_Reward/joint_vel: -0.0651
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.87s
                      Time elapsed: 00:55:53
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 53298 steps/s (collection: 1.729s, learning 0.116s)
             Mean action noise std: 4.66
          Mean value_function loss: 84.9161
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 90.5767
                       Mean reward: 388.82
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 81.3071
        Episode_Reward/action_rate: -0.1517
          Episode_Reward/joint_vel: -0.0656
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.84s
                      Time elapsed: 00:55:54
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 52911 steps/s (collection: 1.760s, learning 0.098s)
             Mean action noise std: 4.66
          Mean value_function loss: 88.3579
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 90.5838
                       Mean reward: 453.27
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 1.2504
    Episode_Reward/rotating_object: 85.1468
        Episode_Reward/action_rate: -0.1538
          Episode_Reward/joint_vel: -0.0678
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.86s
                      Time elapsed: 00:55:56
                               ETA: 00:01:20

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 51702 steps/s (collection: 1.786s, learning 0.116s)
             Mean action noise std: 4.66
          Mean value_function loss: 94.1157
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 90.5953
                       Mean reward: 442.83
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 83.8927
        Episode_Reward/action_rate: -0.1527
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.90s
                      Time elapsed: 00:55:58
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 53184 steps/s (collection: 1.728s, learning 0.120s)
             Mean action noise std: 4.67
          Mean value_function loss: 85.0604
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 90.6033
                       Mean reward: 412.04
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 85.3784
        Episode_Reward/action_rate: -0.1513
          Episode_Reward/joint_vel: -0.0663
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.85s
                      Time elapsed: 00:56:00
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 53751 steps/s (collection: 1.729s, learning 0.100s)
             Mean action noise std: 4.67
          Mean value_function loss: 77.3342
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.6153
                       Mean reward: 410.22
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 1.2388
    Episode_Reward/rotating_object: 82.5869
        Episode_Reward/action_rate: -0.1544
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.83s
                      Time elapsed: 00:56:02
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 53172 steps/s (collection: 1.725s, learning 0.124s)
             Mean action noise std: 4.67
          Mean value_function loss: 75.1619
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 90.6276
                       Mean reward: 439.50
               Mean episode length: 245.37
    Episode_Reward/reaching_object: 1.2296
    Episode_Reward/rotating_object: 82.1974
        Episode_Reward/action_rate: -0.1531
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.85s
                      Time elapsed: 00:56:04
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 53631 steps/s (collection: 1.717s, learning 0.116s)
             Mean action noise std: 4.67
          Mean value_function loss: 79.5215
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 90.6358
                       Mean reward: 386.79
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 84.2288
        Episode_Reward/action_rate: -0.1531
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.83s
                      Time elapsed: 00:56:05
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 51566 steps/s (collection: 1.790s, learning 0.116s)
             Mean action noise std: 4.67
          Mean value_function loss: 70.8500
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 90.6429
                       Mean reward: 448.99
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 84.2146
        Episode_Reward/action_rate: -0.1506
          Episode_Reward/joint_vel: -0.0645
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.91s
                      Time elapsed: 00:56:07
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 53735 steps/s (collection: 1.715s, learning 0.114s)
             Mean action noise std: 4.67
          Mean value_function loss: 71.1082
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 90.6543
                       Mean reward: 420.52
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 1.2470
    Episode_Reward/rotating_object: 86.2234
        Episode_Reward/action_rate: -0.1560
          Episode_Reward/joint_vel: -0.0677
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.83s
                      Time elapsed: 00:56:09
                               ETA: 00:01:04

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 52845 steps/s (collection: 1.736s, learning 0.125s)
             Mean action noise std: 4.68
          Mean value_function loss: 80.3987
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 90.6658
                       Mean reward: 466.49
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 1.2321
    Episode_Reward/rotating_object: 82.6013
        Episode_Reward/action_rate: -0.1555
          Episode_Reward/joint_vel: -0.0695
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.86s
                      Time elapsed: 00:56:11
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 53611 steps/s (collection: 1.741s, learning 0.093s)
             Mean action noise std: 4.68
          Mean value_function loss: 85.0066
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 90.6755
                       Mean reward: 430.38
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 1.2132
    Episode_Reward/rotating_object: 84.7683
        Episode_Reward/action_rate: -0.1534
          Episode_Reward/joint_vel: -0.0657
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.83s
                      Time elapsed: 00:56:13
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 52879 steps/s (collection: 1.749s, learning 0.110s)
             Mean action noise std: 4.68
          Mean value_function loss: 85.8632
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 90.6831
                       Mean reward: 420.20
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 81.7481
        Episode_Reward/action_rate: -0.1518
          Episode_Reward/joint_vel: -0.0667
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.86s
                      Time elapsed: 00:56:15
                               ETA: 00:00:57

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 51251 steps/s (collection: 1.799s, learning 0.120s)
             Mean action noise std: 4.68
          Mean value_function loss: 86.3771
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 90.6925
                       Mean reward: 417.58
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.2268
    Episode_Reward/rotating_object: 83.6428
        Episode_Reward/action_rate: -0.1547
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.92s
                      Time elapsed: 00:56:17
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 52965 steps/s (collection: 1.736s, learning 0.120s)
             Mean action noise std: 4.68
          Mean value_function loss: 78.7803
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 90.7011
                       Mean reward: 426.05
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 83.3419
        Episode_Reward/action_rate: -0.1558
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.86s
                      Time elapsed: 00:56:19
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 52501 steps/s (collection: 1.754s, learning 0.119s)
             Mean action noise std: 4.68
          Mean value_function loss: 79.1566
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 90.7167
                       Mean reward: 439.48
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 88.5872
        Episode_Reward/action_rate: -0.1544
          Episode_Reward/joint_vel: -0.0671
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.87s
                      Time elapsed: 00:56:20
                               ETA: 00:00:50

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 52070 steps/s (collection: 1.770s, learning 0.118s)
             Mean action noise std: 4.69
          Mean value_function loss: 83.4601
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 90.7262
                       Mean reward: 443.66
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.2112
    Episode_Reward/rotating_object: 86.2018
        Episode_Reward/action_rate: -0.1517
          Episode_Reward/joint_vel: -0.0655
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.89s
                      Time elapsed: 00:56:22
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 48423 steps/s (collection: 1.912s, learning 0.118s)
             Mean action noise std: 4.69
          Mean value_function loss: 87.3564
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 90.7325
                       Mean reward: 408.86
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 82.1214
        Episode_Reward/action_rate: -0.1550
          Episode_Reward/joint_vel: -0.0676
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.03s
                      Time elapsed: 00:56:24
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 49672 steps/s (collection: 1.884s, learning 0.095s)
             Mean action noise std: 4.69
          Mean value_function loss: 83.8643
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 90.7423
                       Mean reward: 452.16
               Mean episode length: 246.93
    Episode_Reward/reaching_object: 1.2460
    Episode_Reward/rotating_object: 87.2787
        Episode_Reward/action_rate: -0.1562
          Episode_Reward/joint_vel: -0.0675
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.98s
                      Time elapsed: 00:56:26
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 51146 steps/s (collection: 1.791s, learning 0.131s)
             Mean action noise std: 4.69
          Mean value_function loss: 83.3158
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 90.7521
                       Mean reward: 411.73
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 80.8423
        Episode_Reward/action_rate: -0.1523
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.92s
                      Time elapsed: 00:56:28
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 50790 steps/s (collection: 1.812s, learning 0.124s)
             Mean action noise std: 4.69
          Mean value_function loss: 83.0877
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.7593
                       Mean reward: 424.85
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 84.7898
        Episode_Reward/action_rate: -0.1544
          Episode_Reward/joint_vel: -0.0674
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.94s
                      Time elapsed: 00:56:30
                               ETA: 00:00:38

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 52474 steps/s (collection: 1.752s, learning 0.122s)
             Mean action noise std: 4.69
          Mean value_function loss: 78.0391
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.7689
                       Mean reward: 405.86
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.2054
    Episode_Reward/rotating_object: 81.9505
        Episode_Reward/action_rate: -0.1526
          Episode_Reward/joint_vel: -0.0672
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.87s
                      Time elapsed: 00:56:32
                               ETA: 00:00:36

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 50827 steps/s (collection: 1.815s, learning 0.119s)
             Mean action noise std: 4.70
          Mean value_function loss: 90.0861
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.7808
                       Mean reward: 391.31
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.2040
    Episode_Reward/rotating_object: 79.7237
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.93s
                      Time elapsed: 00:56:34
                               ETA: 00:00:34

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 50746 steps/s (collection: 1.829s, learning 0.108s)
             Mean action noise std: 4.70
          Mean value_function loss: 83.2065
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.7918
                       Mean reward: 464.43
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.2165
    Episode_Reward/rotating_object: 87.2954
        Episode_Reward/action_rate: -0.1518
          Episode_Reward/joint_vel: -0.0668
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.94s
                      Time elapsed: 00:56:36
                               ETA: 00:00:31

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 49842 steps/s (collection: 1.848s, learning 0.124s)
             Mean action noise std: 4.70
          Mean value_function loss: 83.0501
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 90.7998
                       Mean reward: 421.86
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 1.2576
    Episode_Reward/rotating_object: 84.0813
        Episode_Reward/action_rate: -0.1570
          Episode_Reward/joint_vel: -0.0700
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.97s
                      Time elapsed: 00:56:38
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 51955 steps/s (collection: 1.775s, learning 0.117s)
             Mean action noise std: 4.70
          Mean value_function loss: 78.1494
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 90.8048
                       Mean reward: 422.20
               Mean episode length: 242.88
    Episode_Reward/reaching_object: 1.2484
    Episode_Reward/rotating_object: 84.4609
        Episode_Reward/action_rate: -0.1574
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.89s
                      Time elapsed: 00:56:40
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 50593 steps/s (collection: 1.822s, learning 0.121s)
             Mean action noise std: 4.70
          Mean value_function loss: 77.1446
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 90.8106
                       Mean reward: 395.92
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 1.2267
    Episode_Reward/rotating_object: 80.8701
        Episode_Reward/action_rate: -0.1542
          Episode_Reward/joint_vel: -0.0682
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.94s
                      Time elapsed: 00:56:42
                               ETA: 00:00:25

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 44401 steps/s (collection: 2.064s, learning 0.150s)
             Mean action noise std: 4.70
          Mean value_function loss: 79.7540
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.8206
                       Mean reward: 399.27
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.2328
    Episode_Reward/rotating_object: 82.3037
        Episode_Reward/action_rate: -0.1550
          Episode_Reward/joint_vel: -0.0685
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.21s
                      Time elapsed: 00:56:44
                               ETA: 00:00:22

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 50596 steps/s (collection: 1.787s, learning 0.156s)
             Mean action noise std: 4.71
          Mean value_function loss: 75.3510
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 90.8373
                       Mean reward: 404.58
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 1.2245
    Episode_Reward/rotating_object: 82.7322
        Episode_Reward/action_rate: -0.1533
          Episode_Reward/joint_vel: -0.0683
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.94s
                      Time elapsed: 00:56:46
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 46437 steps/s (collection: 2.001s, learning 0.116s)
             Mean action noise std: 4.71
          Mean value_function loss: 82.7951
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 90.8505
                       Mean reward: 400.34
               Mean episode length: 234.15
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 82.1256
        Episode_Reward/action_rate: -0.1534
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.12s
                      Time elapsed: 00:56:48
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 51878 steps/s (collection: 1.796s, learning 0.099s)
             Mean action noise std: 4.71
          Mean value_function loss: 80.3975
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 90.8640
                       Mean reward: 402.25
               Mean episode length: 239.80
    Episode_Reward/reaching_object: 1.2545
    Episode_Reward/rotating_object: 84.6777
        Episode_Reward/action_rate: -0.1579
          Episode_Reward/joint_vel: -0.0698
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.89s
                      Time elapsed: 00:56:50
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 48862 steps/s (collection: 1.910s, learning 0.102s)
             Mean action noise std: 4.71
          Mean value_function loss: 82.6730
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.8693
                       Mean reward: 423.72
               Mean episode length: 243.32
    Episode_Reward/reaching_object: 1.2490
    Episode_Reward/rotating_object: 84.9433
        Episode_Reward/action_rate: -0.1576
          Episode_Reward/joint_vel: -0.0691
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.01s
                      Time elapsed: 00:56:52
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 52178 steps/s (collection: 1.765s, learning 0.119s)
             Mean action noise std: 4.71
          Mean value_function loss: 75.1306
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 90.8734
                       Mean reward: 452.54
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 1.2511
    Episode_Reward/rotating_object: 86.3699
        Episode_Reward/action_rate: -0.1575
          Episode_Reward/joint_vel: -0.0705
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.88s
                      Time elapsed: 00:56:54
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 51283 steps/s (collection: 1.795s, learning 0.122s)
             Mean action noise std: 4.71
          Mean value_function loss: 78.8261
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 90.8786
                       Mean reward: 409.00
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.2208
    Episode_Reward/rotating_object: 79.3907
        Episode_Reward/action_rate: -0.1558
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.92s
                      Time elapsed: 00:56:56
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 51803 steps/s (collection: 1.757s, learning 0.141s)
             Mean action noise std: 4.71
          Mean value_function loss: 79.6114
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 90.8897
                       Mean reward: 433.60
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 85.3080
        Episode_Reward/action_rate: -0.1569
          Episode_Reward/joint_vel: -0.0688
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.90s
                      Time elapsed: 00:56:58
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 51348 steps/s (collection: 1.786s, learning 0.128s)
             Mean action noise std: 4.72
          Mean value_function loss: 76.9252
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.9003
                       Mean reward: 429.84
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.2376
    Episode_Reward/rotating_object: 84.9270
        Episode_Reward/action_rate: -0.1570
          Episode_Reward/joint_vel: -0.0680
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.91s
                      Time elapsed: 00:57:00
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 52321 steps/s (collection: 1.761s, learning 0.118s)
             Mean action noise std: 4.72
          Mean value_function loss: 77.2052
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 90.9109
                       Mean reward: 419.64
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.2155
    Episode_Reward/rotating_object: 82.3347
        Episode_Reward/action_rate: -0.1547
          Episode_Reward/joint_vel: -0.0670
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.88s
                      Time elapsed: 00:57:01
                               ETA: 00:00:02

