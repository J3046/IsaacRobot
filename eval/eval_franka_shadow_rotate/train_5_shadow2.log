################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10938 steps/s (collection: 8.718s, learning 0.269s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0028
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 25.5734
                       Mean reward: -0.00
               Mean episode length: 21.40
    Episode_Reward/reaching_object: 0.0004
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0002
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 8.99s
                      Time elapsed: 00:00:08
                               ETA: 03:44:40

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 15930 steps/s (collection: 6.031s, learning 0.140s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 25.6937
                       Mean reward: -0.00
               Mean episode length: 45.09
    Episode_Reward/reaching_object: 0.0011
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0005
          Episode_Reward/joint_vel: -0.0006
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.17s
                      Time elapsed: 00:00:15
                               ETA: 03:09:20

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 15902 steps/s (collection: 6.035s, learning 0.146s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 25.7826
                       Mean reward: -0.00
               Mean episode length: 69.30
    Episode_Reward/reaching_object: 0.0017
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0010
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.18s
                      Time elapsed: 00:00:21
                               ETA: 02:57:35

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 15424 steps/s (collection: 6.213s, learning 0.161s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 25.8161
                       Mean reward: -0.00
               Mean episode length: 93.06
    Episode_Reward/reaching_object: 0.0023
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0012
          Episode_Reward/joint_vel: -0.0015
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.37s
                      Time elapsed: 00:00:27
                               ETA: 02:52:51

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14783 steps/s (collection: 6.506s, learning 0.143s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 25.8561
                       Mean reward: -0.00
               Mean episode length: 117.24
    Episode_Reward/reaching_object: 0.0028
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0016
          Episode_Reward/joint_vel: -0.0019
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.65s
                      Time elapsed: 00:00:34
                               ETA: 02:51:21

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 15412 steps/s (collection: 6.232s, learning 0.146s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 25.8902
                       Mean reward: -0.01
               Mean episode length: 141.16
    Episode_Reward/reaching_object: 0.0032
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0020
          Episode_Reward/joint_vel: -0.0023
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.38s
                      Time elapsed: 00:00:40
                               ETA: 02:49:11

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 15468 steps/s (collection: 6.209s, learning 0.147s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 25.8837
                       Mean reward: -0.01
               Mean episode length: 165.69
    Episode_Reward/reaching_object: 0.0035
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0028
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.36s
                      Time elapsed: 00:00:47
                               ETA: 02:47:31

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 15022 steps/s (collection: 6.389s, learning 0.155s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 25.8529
                       Mean reward: -0.01
               Mean episode length: 189.43
    Episode_Reward/reaching_object: 0.0041
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0027
          Episode_Reward/joint_vel: -0.0032
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.54s
                      Time elapsed: 00:00:53
                               ETA: 02:46:50

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 19890 steps/s (collection: 4.842s, learning 0.100s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 25.8235
                       Mean reward: -0.01
               Mean episode length: 213.24
    Episode_Reward/reaching_object: 0.0044
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0030
          Episode_Reward/joint_vel: -0.0036
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 4.94s
                      Time elapsed: 00:00:58
                               ETA: 02:41:51

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 65422 steps/s (collection: 1.414s, learning 0.089s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 25.7770
                       Mean reward: -0.01
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 0.0047
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.50s
                      Time elapsed: 00:01:00
                               ETA: 02:29:18

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 66787 steps/s (collection: 1.379s, learning 0.093s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 25.7304
                       Mean reward: -0.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0048
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.47s
                      Time elapsed: 00:01:01
                               ETA: 02:18:58

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 63639 steps/s (collection: 1.432s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 25.6630
                       Mean reward: -0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0056
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.54s
                      Time elapsed: 00:01:03
                               ETA: 02:10:29

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 66476 steps/s (collection: 1.379s, learning 0.100s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 25.5619
                       Mean reward: -0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0054
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.48s
                      Time elapsed: 00:01:04
                               ETA: 02:03:11

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 66516 steps/s (collection: 1.377s, learning 0.101s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 25.4830
                       Mean reward: -0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0057
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.48s
                      Time elapsed: 00:01:06
                               ETA: 01:56:56

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 65820 steps/s (collection: 1.403s, learning 0.090s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 25.4144
                       Mean reward: -0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0062
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.49s
                      Time elapsed: 00:01:07
                               ETA: 01:51:32

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 65160 steps/s (collection: 1.401s, learning 0.108s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 25.3881
                       Mean reward: -0.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0069
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.51s
                      Time elapsed: 00:01:09
                               ETA: 01:46:49

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 64449 steps/s (collection: 1.416s, learning 0.110s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 25.3551
                       Mean reward: 0.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0081
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.53s
                      Time elapsed: 00:01:10
                               ETA: 01:42:41

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 65586 steps/s (collection: 1.387s, learning 0.112s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 25.3453
                       Mean reward: 0.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0101
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.50s
                      Time elapsed: 00:01:12
                               ETA: 01:38:58

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 64521 steps/s (collection: 1.410s, learning 0.114s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 25.3331
                       Mean reward: 0.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0124
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.52s
                      Time elapsed: 00:01:13
                               ETA: 01:35:41

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 64792 steps/s (collection: 1.420s, learning 0.098s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 25.3505
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0171
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.52s
                      Time elapsed: 00:01:15
                               ETA: 01:32:42

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 65181 steps/s (collection: 1.407s, learning 0.102s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 25.3629
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0230
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.51s
                      Time elapsed: 00:01:16
                               ETA: 01:30:00

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 63954 steps/s (collection: 1.423s, learning 0.114s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 25.3944
                       Mean reward: 0.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0309
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.54s
                      Time elapsed: 00:01:18
                               ETA: 01:27:35

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 65071 steps/s (collection: 1.420s, learning 0.091s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 25.4164
                       Mean reward: 0.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0429
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.51s
                      Time elapsed: 00:01:19
                               ETA: 01:25:20

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 63492 steps/s (collection: 1.455s, learning 0.093s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 25.4561
                       Mean reward: 0.27
               Mean episode length: 249.96
    Episode_Reward/reaching_object: 0.0560
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.55s
                      Time elapsed: 00:01:21
                               ETA: 01:23:18

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 63042 steps/s (collection: 1.451s, learning 0.108s)
             Mean action noise std: 0.99
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 25.4367
                       Mean reward: 0.36
               Mean episode length: 249.71
    Episode_Reward/reaching_object: 0.0720
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.56s
                      Time elapsed: 00:01:22
                               ETA: 01:21:27

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 60962 steps/s (collection: 1.511s, learning 0.102s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0009
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 25.4741
                       Mean reward: 0.47
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 0.0960
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.61s
                      Time elapsed: 00:01:24
                               ETA: 01:19:48

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 60723 steps/s (collection: 1.525s, learning 0.094s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0008
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 25.4824
                       Mean reward: 0.61
               Mean episode length: 247.61
    Episode_Reward/reaching_object: 0.1155
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.62s
                      Time elapsed: 00:01:26
                               ETA: 01:18:16

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 58874 steps/s (collection: 1.579s, learning 0.091s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0020
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 25.4696
                       Mean reward: 0.69
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.1409
    Episode_Reward/rotating_object: 0.0008
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.67s
                      Time elapsed: 00:01:27
                               ETA: 01:16:53

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 57221 steps/s (collection: 1.616s, learning 0.102s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0025
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 25.4928
                       Mean reward: 0.84
               Mean episode length: 243.94
    Episode_Reward/reaching_object: 0.1546
    Episode_Reward/rotating_object: 0.0075
        Episode_Reward/action_rate: -0.0035
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.72s
                      Time elapsed: 00:01:29
                               ETA: 01:15:38

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 57402 steps/s (collection: 1.613s, learning 0.099s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0037
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 25.5380
                       Mean reward: 0.94
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 0.1766
    Episode_Reward/rotating_object: 0.0035
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.71s
                      Time elapsed: 00:01:31
                               ETA: 01:14:27

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 56942 steps/s (collection: 1.639s, learning 0.088s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0318
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 25.5998
                       Mean reward: 0.97
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 0.1996
    Episode_Reward/rotating_object: 0.0161
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 10.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.73s
                      Time elapsed: 00:01:32
                               ETA: 01:13:22

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 55081 steps/s (collection: 1.686s, learning 0.099s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0589
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 25.6376
                       Mean reward: 1.12
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 0.2090
    Episode_Reward/rotating_object: 0.0099
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 8.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.78s
                      Time elapsed: 00:01:34
                               ETA: 01:12:24

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 55082 steps/s (collection: 1.690s, learning 0.094s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0115
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 25.7460
                       Mean reward: 1.16
               Mean episode length: 214.57
    Episode_Reward/reaching_object: 0.2192
    Episode_Reward/rotating_object: 0.0454
        Episode_Reward/action_rate: -0.0032
          Episode_Reward/joint_vel: -0.0038
      Episode_Termination/time_out: 5.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.78s
                      Time elapsed: 00:01:36
                               ETA: 01:11:29

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 53867 steps/s (collection: 1.725s, learning 0.100s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 25.8422
                       Mean reward: 1.04
               Mean episode length: 206.49
    Episode_Reward/reaching_object: 0.2146
    Episode_Reward/rotating_object: 0.0212
        Episode_Reward/action_rate: -0.0031
          Episode_Reward/joint_vel: -0.0038
      Episode_Termination/time_out: 5.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 19.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.82s
                      Time elapsed: 00:01:38
                               ETA: 01:10:38

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 54001 steps/s (collection: 1.712s, learning 0.108s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0276
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 25.9393
                       Mean reward: 1.15
               Mean episode length: 199.22
    Episode_Reward/reaching_object: 0.2228
    Episode_Reward/rotating_object: 0.0289
        Episode_Reward/action_rate: -0.0031
          Episode_Reward/joint_vel: -0.0038
      Episode_Termination/time_out: 4.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 18.0000
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.82s
                      Time elapsed: 00:01:40
                               ETA: 01:09:51

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 53899 steps/s (collection: 1.733s, learning 0.091s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0342
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 26.0026
                       Mean reward: 1.57
               Mean episode length: 194.53
    Episode_Reward/reaching_object: 0.2338
    Episode_Reward/rotating_object: 0.0495
        Episode_Reward/action_rate: -0.0030
          Episode_Reward/joint_vel: -0.0038
      Episode_Termination/time_out: 4.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.82s
                      Time elapsed: 00:01:41
                               ETA: 01:09:06

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 53641 steps/s (collection: 1.720s, learning 0.113s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0529
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 26.0757
                       Mean reward: 1.11
               Mean episode length: 182.11
    Episode_Reward/reaching_object: 0.2343
    Episode_Reward/rotating_object: 0.0191
        Episode_Reward/action_rate: -0.0030
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 3.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.83s
                      Time elapsed: 00:01:43
                               ETA: 01:08:23

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 53599 steps/s (collection: 1.745s, learning 0.089s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0747
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 26.2080
                       Mean reward: 1.40
               Mean episode length: 189.48
    Episode_Reward/reaching_object: 0.2594
    Episode_Reward/rotating_object: 0.0553
        Episode_Reward/action_rate: -0.0031
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 5.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.83s
                      Time elapsed: 00:01:45
                               ETA: 01:07:43

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 54129 steps/s (collection: 1.728s, learning 0.089s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.1624
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 26.2782
                       Mean reward: 1.57
               Mean episode length: 189.77
    Episode_Reward/reaching_object: 0.2713
    Episode_Reward/rotating_object: 0.0617
        Episode_Reward/action_rate: -0.0031
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 5.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.82s
                      Time elapsed: 00:01:47
                               ETA: 01:07:04

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 52499 steps/s (collection: 1.777s, learning 0.095s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.1584
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 26.3550
                       Mean reward: 3.29
               Mean episode length: 214.10
    Episode_Reward/reaching_object: 0.3051
    Episode_Reward/rotating_object: 0.2277
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 7.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.87s
                      Time elapsed: 00:01:49
                               ETA: 01:06:29

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 54129 steps/s (collection: 1.724s, learning 0.092s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.2239
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 26.5086
                       Mean reward: 2.24
               Mean episode length: 209.10
    Episode_Reward/reaching_object: 0.3248
    Episode_Reward/rotating_object: 0.1286
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 7.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.82s
                      Time elapsed: 00:01:51
                               ETA: 01:05:54

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 52874 steps/s (collection: 1.756s, learning 0.104s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.3330
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 26.5972
                       Mean reward: 2.74
               Mean episode length: 220.57
    Episode_Reward/reaching_object: 0.3574
    Episode_Reward/rotating_object: 0.2017
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 8.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.86s
                      Time elapsed: 00:01:52
                               ETA: 01:05:22

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 52573 steps/s (collection: 1.779s, learning 0.091s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.3452
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 26.6809
                       Mean reward: 2.90
               Mean episode length: 219.06
    Episode_Reward/reaching_object: 0.3956
    Episode_Reward/rotating_object: 0.2127
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 1.87s
                      Time elapsed: 00:01:54
                               ETA: 01:04:52

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 53485 steps/s (collection: 1.746s, learning 0.092s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3145
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 26.8047
                       Mean reward: 3.12
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 0.4040
    Episode_Reward/rotating_object: 0.3979
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.84s
                      Time elapsed: 00:01:56
                               ETA: 01:04:21

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 53370 steps/s (collection: 1.750s, learning 0.092s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.5495
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 26.9186
                       Mean reward: 4.64
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 0.4335
    Episode_Reward/rotating_object: 0.3900
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.84s
                      Time elapsed: 00:01:58
                               ETA: 01:03:53

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 50547 steps/s (collection: 1.840s, learning 0.105s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.4473
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 26.9555
                       Mean reward: 3.80
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 0.4323
    Episode_Reward/rotating_object: 0.4052
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.94s
                      Time elapsed: 00:02:00
                               ETA: 01:03:28

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 51725 steps/s (collection: 1.810s, learning 0.091s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3023
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 27.0693
                       Mean reward: 3.82
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 0.4295
    Episode_Reward/rotating_object: 0.3982
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.90s
                      Time elapsed: 00:02:02
                               ETA: 01:03:03

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 53802 steps/s (collection: 1.717s, learning 0.110s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.7380
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 27.1635
                       Mean reward: 3.84
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 0.4473
    Episode_Reward/rotating_object: 0.4520
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.83s
                      Time elapsed: 00:02:04
                               ETA: 01:02:37

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 31259 steps/s (collection: 2.710s, learning 0.434s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.8600
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 27.2965
                       Mean reward: 4.32
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 0.4473
    Episode_Reward/rotating_object: 0.5892
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 3.14s
                      Time elapsed: 00:02:07
                               ETA: 01:02:51

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 18628 steps/s (collection: 4.974s, learning 0.303s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.8138
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 27.3739
                       Mean reward: 4.28
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 0.4300
    Episode_Reward/rotating_object: 0.5543
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 5.28s
                      Time elapsed: 00:02:12
                               ETA: 01:04:06

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 18100 steps/s (collection: 4.991s, learning 0.440s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.8023
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 27.4843
                       Mean reward: 4.80
               Mean episode length: 231.21
    Episode_Reward/reaching_object: 0.4323
    Episode_Reward/rotating_object: 0.5830
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 5.43s
                      Time elapsed: 00:02:17
                               ETA: 01:05:23

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 20171 steps/s (collection: 4.602s, learning 0.271s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.0627
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 27.5496
                       Mean reward: 9.78
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 0.4505
    Episode_Reward/rotating_object: 1.0873
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 4.87s
                      Time elapsed: 00:02:22
                               ETA: 01:06:20

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 17935 steps/s (collection: 5.203s, learning 0.278s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.9439
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 27.6082
                       Mean reward: 6.72
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 0.4568
    Episode_Reward/rotating_object: 0.7378
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 5.48s
                      Time elapsed: 00:02:28
                               ETA: 01:07:32

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 18840 steps/s (collection: 4.802s, learning 0.416s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.8100
               Mean surrogate loss: 0.0030
                 Mean entropy loss: 27.6408
                       Mean reward: 5.19
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 0.4364
    Episode_Reward/rotating_object: 0.7564
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 5.22s
                      Time elapsed: 00:02:33
                               ETA: 01:08:34

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 18154 steps/s (collection: 5.015s, learning 0.400s)
             Mean action noise std: 1.13
          Mean value_function loss: 2.3337
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 27.6892
                       Mean reward: 6.29
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 0.4464
    Episode_Reward/rotating_object: 0.9558
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 5.41s
                      Time elapsed: 00:02:38
                               ETA: 01:09:39

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 18896 steps/s (collection: 4.774s, learning 0.428s)
             Mean action noise std: 1.14
          Mean value_function loss: 2.2005
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 27.7918
                       Mean reward: 12.88
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 0.4412
    Episode_Reward/rotating_object: 1.6367
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 5.20s
                      Time elapsed: 00:02:44
                               ETA: 01:10:36

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 19739 steps/s (collection: 4.523s, learning 0.457s)
             Mean action noise std: 1.14
          Mean value_function loss: 2.0993
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 27.9081
                       Mean reward: 12.04
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 0.4501
    Episode_Reward/rotating_object: 1.6272
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 4.98s
                      Time elapsed: 00:02:49
                               ETA: 01:11:25

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 16498 steps/s (collection: 5.468s, learning 0.490s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.1175
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 27.9563
                       Mean reward: 10.33
               Mean episode length: 230.57
    Episode_Reward/reaching_object: 0.4645
    Episode_Reward/rotating_object: 1.7242
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 5.96s
                      Time elapsed: 00:02:55
                               ETA: 01:12:36

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 17501 steps/s (collection: 5.148s, learning 0.469s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.1968
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 28.0074
                       Mean reward: 9.49
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 0.4618
    Episode_Reward/rotating_object: 1.3823
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 5.62s
                      Time elapsed: 00:03:00
                               ETA: 01:13:37

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 19312 steps/s (collection: 4.724s, learning 0.366s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.1710
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 28.0561
                       Mean reward: 10.43
               Mean episode length: 242.92
    Episode_Reward/reaching_object: 0.4859
    Episode_Reward/rotating_object: 1.3854
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 5.09s
                      Time elapsed: 00:03:05
                               ETA: 01:14:22

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 18254 steps/s (collection: 4.977s, learning 0.408s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.5467
               Mean surrogate loss: 0.0053
                 Mean entropy loss: 28.0730
                       Mean reward: 11.65
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 0.4840
    Episode_Reward/rotating_object: 1.8211
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 5.39s
                      Time elapsed: 00:03:11
                               ETA: 01:15:13

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 18112 steps/s (collection: 5.077s, learning 0.350s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.5738
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 28.0813
                       Mean reward: 10.23
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 0.4789
    Episode_Reward/rotating_object: 1.3881
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 5.43s
                      Time elapsed: 00:03:16
                               ETA: 01:16:03

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 22525 steps/s (collection: 3.925s, learning 0.439s)
             Mean action noise std: 1.16
          Mean value_function loss: 3.3667
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 28.1097
                       Mean reward: 17.77
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 0.5104
    Episode_Reward/rotating_object: 2.0671
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 4.36s
                      Time elapsed: 00:03:21
                               ETA: 01:16:27

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 20413 steps/s (collection: 4.499s, learning 0.317s)
             Mean action noise std: 1.16
          Mean value_function loss: 3.0728
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 28.1560
                       Mean reward: 16.21
               Mean episode length: 246.35
    Episode_Reward/reaching_object: 0.5063
    Episode_Reward/rotating_object: 2.4652
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 4.82s
                      Time elapsed: 00:03:25
                               ETA: 01:17:01

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 20885 steps/s (collection: 4.364s, learning 0.343s)
             Mean action noise std: 1.16
          Mean value_function loss: 3.3563
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 28.1992
                       Mean reward: 11.78
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.5154
    Episode_Reward/rotating_object: 2.2275
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 4.71s
                      Time elapsed: 00:03:30
                               ETA: 01:17:30

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 18660 steps/s (collection: 4.645s, learning 0.623s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.4040
               Mean surrogate loss: 0.0052
                 Mean entropy loss: 28.2737
                       Mean reward: 15.23
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.5018
    Episode_Reward/rotating_object: 2.0521
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 5.27s
                      Time elapsed: 00:03:35
                               ETA: 01:18:11

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 21839 steps/s (collection: 4.090s, learning 0.411s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.3723
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 28.2906
                       Mean reward: 12.78
               Mean episode length: 247.36
    Episode_Reward/reaching_object: 0.5206
    Episode_Reward/rotating_object: 2.5579
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 4.50s
                      Time elapsed: 00:03:40
                               ETA: 01:18:34

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 19683 steps/s (collection: 4.468s, learning 0.527s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.2380
               Mean surrogate loss: 0.0056
                 Mean entropy loss: 28.3032
                       Mean reward: 15.85
               Mean episode length: 248.47
    Episode_Reward/reaching_object: 0.5121
    Episode_Reward/rotating_object: 2.6569
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 4.99s
                      Time elapsed: 00:03:45
                               ETA: 01:19:07

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 21877 steps/s (collection: 4.180s, learning 0.313s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.0795
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 28.3074
                       Mean reward: 18.11
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.5200
    Episode_Reward/rotating_object: 2.5608
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 4.49s
                      Time elapsed: 00:03:49
                               ETA: 01:19:28

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 22285 steps/s (collection: 4.088s, learning 0.323s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.2538
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 28.3241
                       Mean reward: 13.60
               Mean episode length: 247.16
    Episode_Reward/reaching_object: 0.5227
    Episode_Reward/rotating_object: 2.7419
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 4.41s
                      Time elapsed: 00:03:54
                               ETA: 01:19:47

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 22524 steps/s (collection: 3.965s, learning 0.399s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.3277
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 28.3617
                       Mean reward: 12.73
               Mean episode length: 248.45
    Episode_Reward/reaching_object: 0.4979
    Episode_Reward/rotating_object: 2.5688
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 4.36s
                      Time elapsed: 00:03:58
                               ETA: 01:20:04

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 23288 steps/s (collection: 3.890s, learning 0.331s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.6423
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 28.4170
                       Mean reward: 16.96
               Mean episode length: 242.79
    Episode_Reward/reaching_object: 0.5137
    Episode_Reward/rotating_object: 3.4158
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 4.22s
                      Time elapsed: 00:04:02
                               ETA: 01:20:18

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 19323 steps/s (collection: 4.671s, learning 0.417s)
             Mean action noise std: 1.18
          Mean value_function loss: 4.4552
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 28.4690
                       Mean reward: 15.14
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 0.4871
    Episode_Reward/rotating_object: 2.8196
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 5.09s
                      Time elapsed: 00:04:07
                               ETA: 01:20:48

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 20404 steps/s (collection: 4.462s, learning 0.355s)
             Mean action noise std: 1.18
          Mean value_function loss: 5.5558
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 28.5055
                       Mean reward: 17.72
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 0.5024
    Episode_Reward/rotating_object: 3.1429
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 4.82s
                      Time elapsed: 00:04:12
                               ETA: 01:21:12

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 21057 steps/s (collection: 4.393s, learning 0.275s)
             Mean action noise std: 1.19
          Mean value_function loss: 6.2226
               Mean surrogate loss: 0.0035
                 Mean entropy loss: 28.5622
                       Mean reward: 16.14
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.4943
    Episode_Reward/rotating_object: 3.1747
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 4.67s
                      Time elapsed: 00:04:17
                               ETA: 01:21:33

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 18942 steps/s (collection: 4.845s, learning 0.344s)
             Mean action noise std: 1.19
          Mean value_function loss: 4.9971
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 28.5751
                       Mean reward: 18.48
               Mean episode length: 246.76
    Episode_Reward/reaching_object: 0.4914
    Episode_Reward/rotating_object: 3.6015
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 5.19s
                      Time elapsed: 00:04:22
                               ETA: 01:22:02

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 19128 steps/s (collection: 4.795s, learning 0.344s)
             Mean action noise std: 1.19
          Mean value_function loss: 4.9818
               Mean surrogate loss: 0.0054
                 Mean entropy loss: 28.6050
                       Mean reward: 17.19
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.4922
    Episode_Reward/rotating_object: 3.1456
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 5.14s
                      Time elapsed: 00:04:27
                               ETA: 01:22:30

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 18294 steps/s (collection: 5.106s, learning 0.267s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.5224
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 28.6128
                       Mean reward: 15.07
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 0.4853
    Episode_Reward/rotating_object: 3.3203
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 5.37s
                      Time elapsed: 00:04:33
                               ETA: 01:23:01

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 21646 steps/s (collection: 4.098s, learning 0.444s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.4359
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 28.6462
                       Mean reward: 22.58
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 0.4805
    Episode_Reward/rotating_object: 4.1864
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 4.54s
                      Time elapsed: 00:04:37
                               ETA: 01:23:16

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 24152 steps/s (collection: 3.962s, learning 0.108s)
             Mean action noise std: 1.20
          Mean value_function loss: 5.8122
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 28.6955
                       Mean reward: 17.96
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 0.4917
    Episode_Reward/rotating_object: 2.7424
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 4.07s
                      Time elapsed: 00:04:41
                               ETA: 01:23:23

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 49672 steps/s (collection: 1.883s, learning 0.097s)
             Mean action noise std: 1.20
          Mean value_function loss: 6.5251
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 28.7268
                       Mean reward: 20.97
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 0.4743
    Episode_Reward/rotating_object: 3.7148
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.98s
                      Time elapsed: 00:04:43
                               ETA: 01:22:52

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 48565 steps/s (collection: 1.901s, learning 0.124s)
             Mean action noise std: 1.20
          Mean value_function loss: 7.5868
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 28.7724
                       Mean reward: 18.48
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 0.4855
    Episode_Reward/rotating_object: 3.1402
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.02s
                      Time elapsed: 00:04:45
                               ETA: 01:22:23

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 48346 steps/s (collection: 1.938s, learning 0.095s)
             Mean action noise std: 1.21
          Mean value_function loss: 8.8388
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 28.8270
                       Mean reward: 20.66
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 0.4747
    Episode_Reward/rotating_object: 3.6303
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.03s
                      Time elapsed: 00:04:47
                               ETA: 01:21:55

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 52636 steps/s (collection: 1.772s, learning 0.096s)
             Mean action noise std: 1.21
          Mean value_function loss: 8.1379
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 28.8819
                       Mean reward: 15.60
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 0.4810
    Episode_Reward/rotating_object: 2.7234
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.87s
                      Time elapsed: 00:04:49
                               ETA: 01:21:24

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 50335 steps/s (collection: 1.834s, learning 0.119s)
             Mean action noise std: 1.21
          Mean value_function loss: 8.3321
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 28.9348
                       Mean reward: 22.14
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.4865
    Episode_Reward/rotating_object: 3.9457
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.95s
                      Time elapsed: 00:04:51
                               ETA: 01:20:56

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 52756 steps/s (collection: 1.765s, learning 0.098s)
             Mean action noise std: 1.22
          Mean value_function loss: 8.4509
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 28.9893
                       Mean reward: 25.08
               Mean episode length: 242.45
    Episode_Reward/reaching_object: 0.4982
    Episode_Reward/rotating_object: 4.6666
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.86s
                      Time elapsed: 00:04:53
                               ETA: 01:20:27

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 54368 steps/s (collection: 1.715s, learning 0.093s)
             Mean action noise std: 1.22
          Mean value_function loss: 8.4583
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 29.0395
                       Mean reward: 29.84
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 0.4950
    Episode_Reward/rotating_object: 5.1762
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.81s
                      Time elapsed: 00:04:55
                               ETA: 01:19:57

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 52798 steps/s (collection: 1.760s, learning 0.102s)
             Mean action noise std: 1.22
          Mean value_function loss: 9.2136
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 29.0891
                       Mean reward: 26.90
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 0.4916
    Episode_Reward/rotating_object: 4.2814
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.86s
                      Time elapsed: 00:04:57
                               ETA: 01:19:29

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 52433 steps/s (collection: 1.772s, learning 0.103s)
             Mean action noise std: 1.23
          Mean value_function loss: 8.8842
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 29.1312
                       Mean reward: 22.20
               Mean episode length: 246.24
    Episode_Reward/reaching_object: 0.4871
    Episode_Reward/rotating_object: 4.2955
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.87s
                      Time elapsed: 00:04:58
                               ETA: 01:19:02

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 50428 steps/s (collection: 1.849s, learning 0.100s)
             Mean action noise std: 1.23
          Mean value_function loss: 8.2014
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 29.1851
                       Mean reward: 26.01
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 0.4845
    Episode_Reward/rotating_object: 4.4936
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.95s
                      Time elapsed: 00:05:00
                               ETA: 01:18:37

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 47431 steps/s (collection: 1.965s, learning 0.108s)
             Mean action noise std: 1.23
          Mean value_function loss: 7.1082
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 29.2143
                       Mean reward: 23.47
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.4686
    Episode_Reward/rotating_object: 4.4481
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.07s
                      Time elapsed: 00:05:02
                               ETA: 01:18:14

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 43328 steps/s (collection: 2.167s, learning 0.102s)
             Mean action noise std: 1.23
          Mean value_function loss: 7.4326
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 29.2487
                       Mean reward: 27.46
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 0.4699
    Episode_Reward/rotating_object: 4.7998
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.27s
                      Time elapsed: 00:05:05
                               ETA: 01:17:54

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 48717 steps/s (collection: 1.907s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 8.4316
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 29.2905
                       Mean reward: 26.82
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 0.4722
    Episode_Reward/rotating_object: 4.8475
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.02s
                      Time elapsed: 00:05:07
                               ETA: 01:17:31

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 50244 steps/s (collection: 1.865s, learning 0.092s)
             Mean action noise std: 1.24
          Mean value_function loss: 10.2880
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 29.3306
                       Mean reward: 28.55
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 0.4634
    Episode_Reward/rotating_object: 3.9728
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.96s
                      Time elapsed: 00:05:09
                               ETA: 01:17:08

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 53098 steps/s (collection: 1.762s, learning 0.089s)
             Mean action noise std: 1.24
          Mean value_function loss: 10.8380
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 29.3620
                       Mean reward: 30.25
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 0.4791
    Episode_Reward/rotating_object: 4.7961
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.85s
                      Time elapsed: 00:05:11
                               ETA: 01:16:43

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 53659 steps/s (collection: 1.734s, learning 0.098s)
             Mean action noise std: 1.24
          Mean value_function loss: 11.5561
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 29.3816
                       Mean reward: 22.47
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 0.4784
    Episode_Reward/rotating_object: 3.9649
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.83s
                      Time elapsed: 00:05:12
                               ETA: 01:16:19

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 52882 steps/s (collection: 1.762s, learning 0.097s)
             Mean action noise std: 1.24
          Mean value_function loss: 9.0926
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 29.4101
                       Mean reward: 24.96
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.4832
    Episode_Reward/rotating_object: 4.7160
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.86s
                      Time elapsed: 00:05:14
                               ETA: 01:15:55

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 51734 steps/s (collection: 1.798s, learning 0.103s)
             Mean action noise std: 1.25
          Mean value_function loss: 11.0044
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 29.4498
                       Mean reward: 22.39
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 0.4756
    Episode_Reward/rotating_object: 4.3195
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.90s
                      Time elapsed: 00:05:16
                               ETA: 01:15:33

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 52799 steps/s (collection: 1.761s, learning 0.101s)
             Mean action noise std: 1.25
          Mean value_function loss: 11.9940
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 29.5010
                       Mean reward: 26.32
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.4636
    Episode_Reward/rotating_object: 5.6139
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.86s
                      Time elapsed: 00:05:18
                               ETA: 01:15:10

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 53374 steps/s (collection: 1.747s, learning 0.095s)
             Mean action noise std: 1.25
          Mean value_function loss: 14.7195
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 29.5405
                       Mean reward: 28.09
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 0.4766
    Episode_Reward/rotating_object: 5.7092
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.84s
                      Time elapsed: 00:05:20
                               ETA: 01:14:47

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 51945 steps/s (collection: 1.797s, learning 0.096s)
             Mean action noise std: 1.26
          Mean value_function loss: 13.7931
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 29.5766
                       Mean reward: 35.44
               Mean episode length: 239.91
    Episode_Reward/reaching_object: 0.4701
    Episode_Reward/rotating_object: 5.4468
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.89s
                      Time elapsed: 00:05:22
                               ETA: 01:14:26

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 50739 steps/s (collection: 1.847s, learning 0.091s)
             Mean action noise std: 1.26
          Mean value_function loss: 16.9511
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 29.6265
                       Mean reward: 27.54
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 0.4631
    Episode_Reward/rotating_object: 4.7230
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.94s
                      Time elapsed: 00:05:24
                               ETA: 01:14:06

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 51997 steps/s (collection: 1.786s, learning 0.105s)
             Mean action noise std: 1.26
          Mean value_function loss: 17.7505
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 29.6573
                       Mean reward: 29.56
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 0.4409
    Episode_Reward/rotating_object: 5.0088
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.89s
                      Time elapsed: 00:05:26
                               ETA: 01:13:45

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 49408 steps/s (collection: 1.880s, learning 0.110s)
             Mean action noise std: 1.27
          Mean value_function loss: 17.5390
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 29.6897
                       Mean reward: 29.98
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 0.4582
    Episode_Reward/rotating_object: 5.6815
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.99s
                      Time elapsed: 00:05:28
                               ETA: 01:13:26

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 51411 steps/s (collection: 1.790s, learning 0.122s)
             Mean action noise std: 1.27
          Mean value_function loss: 18.4404
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 29.7365
                       Mean reward: 33.67
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 0.4487
    Episode_Reward/rotating_object: 6.0297
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.91s
                      Time elapsed: 00:05:29
                               ETA: 01:13:06

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 51189 steps/s (collection: 1.806s, learning 0.115s)
             Mean action noise std: 1.27
          Mean value_function loss: 19.8271
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 29.7718
                       Mean reward: 35.66
               Mean episode length: 243.32
    Episode_Reward/reaching_object: 0.4504
    Episode_Reward/rotating_object: 6.8140
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.92s
                      Time elapsed: 00:05:31
                               ETA: 01:12:47

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 50839 steps/s (collection: 1.829s, learning 0.105s)
             Mean action noise std: 1.27
          Mean value_function loss: 21.4743
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 29.7986
                       Mean reward: 38.06
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.4391
    Episode_Reward/rotating_object: 6.7053
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.93s
                      Time elapsed: 00:05:33
                               ETA: 01:12:28

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 52358 steps/s (collection: 1.780s, learning 0.098s)
             Mean action noise std: 1.28
          Mean value_function loss: 19.7041
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 29.8334
                       Mean reward: 45.94
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 0.4358
    Episode_Reward/rotating_object: 6.2196
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.88s
                      Time elapsed: 00:05:35
                               ETA: 01:12:09

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 52875 steps/s (collection: 1.762s, learning 0.097s)
             Mean action noise std: 1.28
          Mean value_function loss: 17.8033
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 29.8806
                       Mean reward: 30.66
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.4235
    Episode_Reward/rotating_object: 6.4285
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.86s
                      Time elapsed: 00:05:37
                               ETA: 01:11:50

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 53800 steps/s (collection: 1.737s, learning 0.090s)
             Mean action noise std: 1.28
          Mean value_function loss: 17.7741
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 29.9351
                       Mean reward: 34.97
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 0.4199
    Episode_Reward/rotating_object: 6.2559
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.83s
                      Time elapsed: 00:05:39
                               ETA: 01:11:31

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 53652 steps/s (collection: 1.726s, learning 0.106s)
             Mean action noise std: 1.29
          Mean value_function loss: 18.2790
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 29.9803
                       Mean reward: 36.61
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.4290
    Episode_Reward/rotating_object: 7.2718
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.83s
                      Time elapsed: 00:05:41
                               ETA: 01:11:12

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 52299 steps/s (collection: 1.790s, learning 0.090s)
             Mean action noise std: 1.29
          Mean value_function loss: 18.8797
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 30.0202
                       Mean reward: 34.21
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.4136
    Episode_Reward/rotating_object: 6.4378
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.88s
                      Time elapsed: 00:05:43
                               ETA: 01:10:54

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 51767 steps/s (collection: 1.781s, learning 0.118s)
             Mean action noise std: 1.29
          Mean value_function loss: 18.7842
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 30.0568
                       Mean reward: 34.61
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.3898
    Episode_Reward/rotating_object: 6.1472
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.90s
                      Time elapsed: 00:05:44
                               ETA: 01:10:37

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 51321 steps/s (collection: 1.803s, learning 0.113s)
             Mean action noise std: 1.29
          Mean value_function loss: 18.4610
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 30.0967
                       Mean reward: 32.78
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 0.3806
    Episode_Reward/rotating_object: 6.5312
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.92s
                      Time elapsed: 00:05:46
                               ETA: 01:10:20

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 48353 steps/s (collection: 1.923s, learning 0.111s)
             Mean action noise std: 1.30
          Mean value_function loss: 20.1423
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 30.1279
                       Mean reward: 40.26
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 0.3917
    Episode_Reward/rotating_object: 6.3590
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.03s
                      Time elapsed: 00:05:48
                               ETA: 01:10:05

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 50224 steps/s (collection: 1.865s, learning 0.093s)
             Mean action noise std: 1.30
          Mean value_function loss: 20.2120
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 30.1566
                       Mean reward: 43.76
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.3920
    Episode_Reward/rotating_object: 6.1769
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.96s
                      Time elapsed: 00:05:50
                               ETA: 01:09:49

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 52231 steps/s (collection: 1.784s, learning 0.098s)
             Mean action noise std: 1.30
          Mean value_function loss: 20.8266
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 30.1911
                       Mean reward: 32.40
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 0.3922
    Episode_Reward/rotating_object: 7.2036
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.88s
                      Time elapsed: 00:05:52
                               ETA: 01:09:33

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 48522 steps/s (collection: 1.917s, learning 0.109s)
             Mean action noise std: 1.30
          Mean value_function loss: 21.0833
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 30.2251
                       Mean reward: 24.48
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 0.3848
    Episode_Reward/rotating_object: 6.8546
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.03s
                      Time elapsed: 00:05:54
                               ETA: 01:09:18

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 51254 steps/s (collection: 1.825s, learning 0.093s)
             Mean action noise std: 1.31
          Mean value_function loss: 18.5907
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 30.2521
                       Mean reward: 30.51
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 0.3814
    Episode_Reward/rotating_object: 6.2777
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.92s
                      Time elapsed: 00:05:56
                               ETA: 01:09:02

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 53959 steps/s (collection: 1.732s, learning 0.090s)
             Mean action noise std: 1.31
          Mean value_function loss: 20.4888
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 30.2795
                       Mean reward: 29.89
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.3950
    Episode_Reward/rotating_object: 7.2558
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.82s
                      Time elapsed: 00:05:58
                               ETA: 01:08:46

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 49271 steps/s (collection: 1.895s, learning 0.101s)
             Mean action noise std: 1.31
          Mean value_function loss: 24.3912
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 30.2994
                       Mean reward: 54.47
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 0.3871
    Episode_Reward/rotating_object: 8.1000
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.00s
                      Time elapsed: 00:06:00
                               ETA: 01:08:31

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 51067 steps/s (collection: 1.830s, learning 0.095s)
             Mean action noise std: 1.31
          Mean value_function loss: 24.2393
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 30.3213
                       Mean reward: 48.54
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.3924
    Episode_Reward/rotating_object: 7.0676
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.92s
                      Time elapsed: 00:06:02
                               ETA: 01:08:17

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 53425 steps/s (collection: 1.750s, learning 0.091s)
             Mean action noise std: 1.31
          Mean value_function loss: 25.9691
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 30.3545
                       Mean reward: 42.44
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 0.3710
    Episode_Reward/rotating_object: 7.5682
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.84s
                      Time elapsed: 00:06:04
                               ETA: 01:08:01

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 50298 steps/s (collection: 1.858s, learning 0.096s)
             Mean action noise std: 1.32
          Mean value_function loss: 23.0130
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 30.3847
                       Mean reward: 49.96
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 0.3907
    Episode_Reward/rotating_object: 9.5350
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.95s
                      Time elapsed: 00:06:06
                               ETA: 01:07:47

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 48612 steps/s (collection: 1.932s, learning 0.091s)
             Mean action noise std: 1.32
          Mean value_function loss: 21.0071
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 30.4179
                       Mean reward: 35.24
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.3687
    Episode_Reward/rotating_object: 7.2525
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.02s
                      Time elapsed: 00:06:08
                               ETA: 01:07:34

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 51678 steps/s (collection: 1.795s, learning 0.108s)
             Mean action noise std: 1.32
          Mean value_function loss: 25.5640
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 30.4481
                       Mean reward: 38.20
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 0.3719
    Episode_Reward/rotating_object: 7.4386
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.90s
                      Time elapsed: 00:06:10
                               ETA: 01:07:19

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 50451 steps/s (collection: 1.810s, learning 0.138s)
             Mean action noise std: 1.32
          Mean value_function loss: 23.5928
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 30.4690
                       Mean reward: 45.35
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 0.3785
    Episode_Reward/rotating_object: 8.8169
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.95s
                      Time elapsed: 00:06:12
                               ETA: 01:07:06

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 48257 steps/s (collection: 1.911s, learning 0.127s)
             Mean action noise std: 1.32
          Mean value_function loss: 25.4989
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 30.4906
                       Mean reward: 46.78
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 0.3696
    Episode_Reward/rotating_object: 8.7271
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.04s
                      Time elapsed: 00:06:14
                               ETA: 01:06:53

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 46944 steps/s (collection: 1.974s, learning 0.120s)
             Mean action noise std: 1.33
          Mean value_function loss: 26.0638
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 30.5230
                       Mean reward: 45.63
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 0.3914
    Episode_Reward/rotating_object: 8.9404
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.09s
                      Time elapsed: 00:06:16
                               ETA: 01:06:41

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 48571 steps/s (collection: 1.914s, learning 0.110s)
             Mean action noise std: 1.33
          Mean value_function loss: 23.9781
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 30.5508
                       Mean reward: 47.04
               Mean episode length: 239.50
    Episode_Reward/reaching_object: 0.3842
    Episode_Reward/rotating_object: 8.5841
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.02s
                      Time elapsed: 00:06:18
                               ETA: 01:06:29

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 50159 steps/s (collection: 1.854s, learning 0.106s)
             Mean action noise std: 1.33
          Mean value_function loss: 27.0659
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 30.5722
                       Mean reward: 41.96
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 0.3796
    Episode_Reward/rotating_object: 8.2637
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.96s
                      Time elapsed: 00:06:20
                               ETA: 01:06:16

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 50842 steps/s (collection: 1.825s, learning 0.108s)
             Mean action noise std: 1.33
          Mean value_function loss: 26.6882
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 30.5962
                       Mean reward: 29.43
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 0.3580
    Episode_Reward/rotating_object: 7.9124
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.93s
                      Time elapsed: 00:06:22
                               ETA: 01:06:03

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 52129 steps/s (collection: 1.792s, learning 0.094s)
             Mean action noise std: 1.33
          Mean value_function loss: 22.2106
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 30.6337
                       Mean reward: 38.46
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 0.3748
    Episode_Reward/rotating_object: 8.7249
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.89s
                      Time elapsed: 00:06:24
                               ETA: 01:05:50

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 46099 steps/s (collection: 2.006s, learning 0.126s)
             Mean action noise std: 1.34
          Mean value_function loss: 25.5136
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 30.6618
                       Mean reward: 45.44
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 0.3838
    Episode_Reward/rotating_object: 8.4133
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.13s
                      Time elapsed: 00:06:26
                               ETA: 01:05:39

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 51149 steps/s (collection: 1.821s, learning 0.101s)
             Mean action noise std: 1.34
          Mean value_function loss: 27.7514
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.6879
                       Mean reward: 44.03
               Mean episode length: 233.20
    Episode_Reward/reaching_object: 0.3772
    Episode_Reward/rotating_object: 10.2622
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.92s
                      Time elapsed: 00:06:28
                               ETA: 01:05:27

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 51273 steps/s (collection: 1.822s, learning 0.095s)
             Mean action noise std: 1.34
          Mean value_function loss: 28.4181
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 30.7057
                       Mean reward: 44.57
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 0.3704
    Episode_Reward/rotating_object: 7.6308
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.92s
                      Time elapsed: 00:06:30
                               ETA: 01:05:14

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 47501 steps/s (collection: 1.965s, learning 0.104s)
             Mean action noise std: 1.34
          Mean value_function loss: 28.4417
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 30.7275
                       Mean reward: 63.86
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 0.3702
    Episode_Reward/rotating_object: 8.3724
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.07s
                      Time elapsed: 00:06:32
                               ETA: 01:05:03

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 47334 steps/s (collection: 1.951s, learning 0.125s)
             Mean action noise std: 1.34
          Mean value_function loss: 26.0972
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 30.7578
                       Mean reward: 40.02
               Mean episode length: 218.90
    Episode_Reward/reaching_object: 0.3645
    Episode_Reward/rotating_object: 8.0397
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.08s
                      Time elapsed: 00:06:34
                               ETA: 01:04:53

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 47116 steps/s (collection: 1.952s, learning 0.134s)
             Mean action noise std: 1.35
          Mean value_function loss: 25.5206
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 30.7831
                       Mean reward: 38.04
               Mean episode length: 220.25
    Episode_Reward/reaching_object: 0.3737
    Episode_Reward/rotating_object: 10.0325
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.09s
                      Time elapsed: 00:06:36
                               ETA: 01:04:42

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 47594 steps/s (collection: 1.942s, learning 0.123s)
             Mean action noise std: 1.35
          Mean value_function loss: 24.5402
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 30.8101
                       Mean reward: 42.67
               Mean episode length: 224.94
    Episode_Reward/reaching_object: 0.3812
    Episode_Reward/rotating_object: 9.7829
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.07s
                      Time elapsed: 00:06:38
                               ETA: 01:04:32

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 48663 steps/s (collection: 1.901s, learning 0.120s)
             Mean action noise std: 1.35
          Mean value_function loss: 27.0560
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 30.8317
                       Mean reward: 54.21
               Mean episode length: 216.09
    Episode_Reward/reaching_object: 0.3833
    Episode_Reward/rotating_object: 9.5542
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 10.5000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.02s
                      Time elapsed: 00:06:40
                               ETA: 01:04:21

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 46730 steps/s (collection: 1.988s, learning 0.115s)
             Mean action noise std: 1.35
          Mean value_function loss: 28.8007
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 30.8483
                       Mean reward: 32.48
               Mean episode length: 216.77
    Episode_Reward/reaching_object: 0.3662
    Episode_Reward/rotating_object: 7.2325
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.10s
                      Time elapsed: 00:06:42
                               ETA: 01:04:11

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 49639 steps/s (collection: 1.874s, learning 0.107s)
             Mean action noise std: 1.35
          Mean value_function loss: 26.4230
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 30.8697
                       Mean reward: 49.84
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 0.3861
    Episode_Reward/rotating_object: 8.7288
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.98s
                      Time elapsed: 00:06:44
                               ETA: 01:04:00

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 49698 steps/s (collection: 1.863s, learning 0.115s)
             Mean action noise std: 1.35
          Mean value_function loss: 25.3024
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 30.8988
                       Mean reward: 43.27
               Mean episode length: 222.42
    Episode_Reward/reaching_object: 0.3869
    Episode_Reward/rotating_object: 9.0517
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 11.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.98s
                      Time elapsed: 00:06:46
                               ETA: 01:03:49

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 50941 steps/s (collection: 1.827s, learning 0.103s)
             Mean action noise std: 1.36
          Mean value_function loss: 25.0468
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 30.9267
                       Mean reward: 63.98
               Mean episode length: 220.05
    Episode_Reward/reaching_object: 0.4012
    Episode_Reward/rotating_object: 10.7887
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.93s
                      Time elapsed: 00:06:48
                               ETA: 01:03:38

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 48744 steps/s (collection: 1.892s, learning 0.125s)
             Mean action noise std: 1.36
          Mean value_function loss: 29.5087
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 30.9568
                       Mean reward: 56.59
               Mean episode length: 219.02
    Episode_Reward/reaching_object: 0.4041
    Episode_Reward/rotating_object: 10.6632
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.02s
                      Time elapsed: 00:06:50
                               ETA: 01:03:28

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 47103 steps/s (collection: 1.989s, learning 0.098s)
             Mean action noise std: 1.36
          Mean value_function loss: 31.1454
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 30.9824
                       Mean reward: 58.71
               Mean episode length: 223.19
    Episode_Reward/reaching_object: 0.4031
    Episode_Reward/rotating_object: 11.5611
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.09s
                      Time elapsed: 00:06:52
                               ETA: 01:03:19

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 49444 steps/s (collection: 1.885s, learning 0.103s)
             Mean action noise std: 1.36
          Mean value_function loss: 28.1080
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.0075
                       Mean reward: 77.84
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 0.4331
    Episode_Reward/rotating_object: 13.7007
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.99s
                      Time elapsed: 00:06:54
                               ETA: 01:03:08

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 44192 steps/s (collection: 2.121s, learning 0.104s)
             Mean action noise std: 1.36
          Mean value_function loss: 35.9964
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.0254
                       Mean reward: 48.75
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 0.4315
    Episode_Reward/rotating_object: 12.4017
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.22s
                      Time elapsed: 00:06:56
                               ETA: 01:03:00

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 46499 steps/s (collection: 2.002s, learning 0.113s)
             Mean action noise std: 1.37
          Mean value_function loss: 35.9044
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.0461
                       Mean reward: 51.63
               Mean episode length: 221.34
    Episode_Reward/reaching_object: 0.4234
    Episode_Reward/rotating_object: 10.1457
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.11s
                      Time elapsed: 00:06:58
                               ETA: 01:02:51

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 50034 steps/s (collection: 1.862s, learning 0.103s)
             Mean action noise std: 1.37
          Mean value_function loss: 31.7198
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.0746
                       Mean reward: 86.61
               Mean episode length: 218.28
    Episode_Reward/reaching_object: 0.4352
    Episode_Reward/rotating_object: 11.8062
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 11.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.96s
                      Time elapsed: 00:07:00
                               ETA: 01:02:41

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 50542 steps/s (collection: 1.833s, learning 0.112s)
             Mean action noise std: 1.37
          Mean value_function loss: 37.0955
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.0978
                       Mean reward: 56.75
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 0.4382
    Episode_Reward/rotating_object: 13.8551
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 11.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.94s
                      Time elapsed: 00:07:02
                               ETA: 01:02:31

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 50348 steps/s (collection: 1.859s, learning 0.094s)
             Mean action noise std: 1.37
          Mean value_function loss: 33.6712
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.1337
                       Mean reward: 61.17
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 0.4325
    Episode_Reward/rotating_object: 11.6353
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.95s
                      Time elapsed: 00:07:04
                               ETA: 01:02:21

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 45478 steps/s (collection: 2.062s, learning 0.100s)
             Mean action noise std: 1.37
          Mean value_function loss: 34.6435
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 31.1555
                       Mean reward: 64.36
               Mean episode length: 216.43
    Episode_Reward/reaching_object: 0.4229
    Episode_Reward/rotating_object: 11.9697
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 11.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.16s
                      Time elapsed: 00:07:06
                               ETA: 01:02:13

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 49127 steps/s (collection: 1.904s, learning 0.097s)
             Mean action noise std: 1.37
          Mean value_function loss: 35.5036
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.1649
                       Mean reward: 79.74
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 0.4421
    Episode_Reward/rotating_object: 13.8127
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.00s
                      Time elapsed: 00:07:08
                               ETA: 01:02:03

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 52179 steps/s (collection: 1.790s, learning 0.094s)
             Mean action noise std: 1.38
          Mean value_function loss: 33.6007
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 31.1859
                       Mean reward: 74.04
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 0.4542
    Episode_Reward/rotating_object: 14.5204
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.88s
                      Time elapsed: 00:07:10
                               ETA: 01:01:53

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 52988 steps/s (collection: 1.766s, learning 0.090s)
             Mean action noise std: 1.38
          Mean value_function loss: 35.9405
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.2051
                       Mean reward: 63.62
               Mean episode length: 224.86
    Episode_Reward/reaching_object: 0.4549
    Episode_Reward/rotating_object: 15.1565
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.86s
                      Time elapsed: 00:07:12
                               ETA: 01:01:42

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 52990 steps/s (collection: 1.766s, learning 0.090s)
             Mean action noise std: 1.38
          Mean value_function loss: 33.9340
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.2281
                       Mean reward: 103.07
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 0.4556
    Episode_Reward/rotating_object: 16.3813
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.86s
                      Time elapsed: 00:07:14
                               ETA: 01:01:32

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 53086 steps/s (collection: 1.761s, learning 0.091s)
             Mean action noise std: 1.38
          Mean value_function loss: 42.4506
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 31.2623
                       Mean reward: 87.37
               Mean episode length: 233.67
    Episode_Reward/reaching_object: 0.4484
    Episode_Reward/rotating_object: 14.5392
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.85s
                      Time elapsed: 00:07:16
                               ETA: 01:01:22

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 52963 steps/s (collection: 1.759s, learning 0.097s)
             Mean action noise std: 1.38
          Mean value_function loss: 41.9542
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.2834
                       Mean reward: 107.49
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 0.4349
    Episode_Reward/rotating_object: 15.8018
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.86s
                      Time elapsed: 00:07:18
                               ETA: 01:01:11

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 53071 steps/s (collection: 1.749s, learning 0.103s)
             Mean action noise std: 1.39
          Mean value_function loss: 42.8988
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 31.3038
                       Mean reward: 73.22
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 0.4405
    Episode_Reward/rotating_object: 16.3448
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.85s
                      Time elapsed: 00:07:19
                               ETA: 01:01:01

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 50978 steps/s (collection: 1.831s, learning 0.098s)
             Mean action noise std: 1.39
          Mean value_function loss: 42.0292
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.3188
                       Mean reward: 104.27
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 0.4595
    Episode_Reward/rotating_object: 16.1426
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.93s
                      Time elapsed: 00:07:21
                               ETA: 01:00:52

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 48145 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 1.39
          Mean value_function loss: 44.2531
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.3305
                       Mean reward: 81.56
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 0.4507
    Episode_Reward/rotating_object: 15.8290
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.04s
                      Time elapsed: 00:07:23
                               ETA: 01:00:44

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 48776 steps/s (collection: 1.921s, learning 0.094s)
             Mean action noise std: 1.39
          Mean value_function loss: 48.3080
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.3459
                       Mean reward: 94.52
               Mean episode length: 230.06
    Episode_Reward/reaching_object: 0.4547
    Episode_Reward/rotating_object: 16.7336
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.02s
                      Time elapsed: 00:07:25
                               ETA: 01:00:35

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 51172 steps/s (collection: 1.822s, learning 0.100s)
             Mean action noise std: 1.39
          Mean value_function loss: 49.3967
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.3696
                       Mean reward: 90.53
               Mean episode length: 223.26
    Episode_Reward/reaching_object: 0.4514
    Episode_Reward/rotating_object: 15.5703
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.92s
                      Time elapsed: 00:07:27
                               ETA: 01:00:26

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 50664 steps/s (collection: 1.841s, learning 0.099s)
             Mean action noise std: 1.39
          Mean value_function loss: 49.7281
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 31.3944
                       Mean reward: 92.11
               Mean episode length: 216.38
    Episode_Reward/reaching_object: 0.4633
    Episode_Reward/rotating_object: 17.5800
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.94s
                      Time elapsed: 00:07:29
                               ETA: 01:00:17

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 52386 steps/s (collection: 1.775s, learning 0.101s)
             Mean action noise std: 1.40
          Mean value_function loss: 55.4387
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.4220
                       Mean reward: 86.28
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 0.4743
    Episode_Reward/rotating_object: 16.9404
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.88s
                      Time elapsed: 00:07:31
                               ETA: 01:00:08

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 50162 steps/s (collection: 1.850s, learning 0.110s)
             Mean action noise std: 1.40
          Mean value_function loss: 56.0714
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.4456
                       Mean reward: 87.80
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 0.4767
    Episode_Reward/rotating_object: 19.4923
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.96s
                      Time elapsed: 00:07:33
                               ETA: 00:59:59

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 51385 steps/s (collection: 1.811s, learning 0.102s)
             Mean action noise std: 1.40
          Mean value_function loss: 52.0204
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 31.4597
                       Mean reward: 93.95
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 0.4702
    Episode_Reward/rotating_object: 18.5779
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.91s
                      Time elapsed: 00:07:35
                               ETA: 00:59:50

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 51398 steps/s (collection: 1.803s, learning 0.110s)
             Mean action noise std: 1.40
          Mean value_function loss: 62.0951
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.4767
                       Mean reward: 100.31
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 0.4877
    Episode_Reward/rotating_object: 18.7750
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.91s
                      Time elapsed: 00:07:37
                               ETA: 00:59:41

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 49884 steps/s (collection: 1.867s, learning 0.104s)
             Mean action noise std: 1.40
          Mean value_function loss: 54.7486
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.4895
                       Mean reward: 113.10
               Mean episode length: 221.43
    Episode_Reward/reaching_object: 0.4706
    Episode_Reward/rotating_object: 19.9044
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.97s
                      Time elapsed: 00:07:39
                               ETA: 00:59:33

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 52542 steps/s (collection: 1.766s, learning 0.105s)
             Mean action noise std: 1.40
          Mean value_function loss: 54.5443
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 31.4976
                       Mean reward: 97.66
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 0.4673
    Episode_Reward/rotating_object: 19.0706
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.87s
                      Time elapsed: 00:07:41
                               ETA: 00:59:24

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 51923 steps/s (collection: 1.803s, learning 0.091s)
             Mean action noise std: 1.40
          Mean value_function loss: 51.5022
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.5108
                       Mean reward: 126.36
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 0.4759
    Episode_Reward/rotating_object: 23.2858
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.89s
                      Time elapsed: 00:07:43
                               ETA: 00:59:15

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 52975 steps/s (collection: 1.760s, learning 0.096s)
             Mean action noise std: 1.40
          Mean value_function loss: 48.7397
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.5242
                       Mean reward: 142.12
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.4907
    Episode_Reward/rotating_object: 22.2633
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.86s
                      Time elapsed: 00:07:45
                               ETA: 00:59:06

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 52374 steps/s (collection: 1.786s, learning 0.091s)
             Mean action noise std: 1.41
          Mean value_function loss: 51.5221
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.5414
                       Mean reward: 100.69
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 0.4630
    Episode_Reward/rotating_object: 18.2718
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.88s
                      Time elapsed: 00:07:46
                               ETA: 00:58:58

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 50900 steps/s (collection: 1.817s, learning 0.115s)
             Mean action noise std: 1.41
          Mean value_function loss: 50.8750
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.5664
                       Mean reward: 134.91
               Mean episode length: 232.16
    Episode_Reward/reaching_object: 0.4759
    Episode_Reward/rotating_object: 22.8528
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.93s
                      Time elapsed: 00:07:48
                               ETA: 00:58:49

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 51808 steps/s (collection: 1.794s, learning 0.103s)
             Mean action noise std: 1.41
          Mean value_function loss: 60.7211
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.5846
                       Mean reward: 129.24
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 0.4790
    Episode_Reward/rotating_object: 22.7865
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.90s
                      Time elapsed: 00:07:50
                               ETA: 00:58:41

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 47044 steps/s (collection: 1.959s, learning 0.131s)
             Mean action noise std: 1.41
          Mean value_function loss: 48.8855
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.6040
                       Mean reward: 106.28
               Mean episode length: 219.57
    Episode_Reward/reaching_object: 0.4568
    Episode_Reward/rotating_object: 20.8437
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.09s
                      Time elapsed: 00:07:52
                               ETA: 00:58:34

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 48142 steps/s (collection: 1.942s, learning 0.100s)
             Mean action noise std: 1.41
          Mean value_function loss: 52.0540
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.6239
                       Mean reward: 112.39
               Mean episode length: 234.90
    Episode_Reward/reaching_object: 0.4564
    Episode_Reward/rotating_object: 20.9506
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.04s
                      Time elapsed: 00:07:54
                               ETA: 00:58:27

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 49426 steps/s (collection: 1.866s, learning 0.123s)
             Mean action noise std: 1.41
          Mean value_function loss: 53.2890
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.6443
                       Mean reward: 142.69
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 0.4520
    Episode_Reward/rotating_object: 22.4387
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 1.99s
                      Time elapsed: 00:07:56
                               ETA: 00:58:19

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 52114 steps/s (collection: 1.790s, learning 0.097s)
             Mean action noise std: 1.42
          Mean value_function loss: 55.0444
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.6617
                       Mean reward: 128.55
               Mean episode length: 225.78
    Episode_Reward/reaching_object: 0.4512
    Episode_Reward/rotating_object: 22.6610
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 1.89s
                      Time elapsed: 00:07:58
                               ETA: 00:58:11

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 50790 steps/s (collection: 1.838s, learning 0.097s)
             Mean action noise std: 1.42
          Mean value_function loss: 51.1929
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.6737
                       Mean reward: 100.16
               Mean episode length: 214.94
    Episode_Reward/reaching_object: 0.4467
    Episode_Reward/rotating_object: 23.3689
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 1.94s
                      Time elapsed: 00:08:00
                               ETA: 00:58:03

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 51944 steps/s (collection: 1.793s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 53.8625
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.6864
                       Mean reward: 113.48
               Mean episode length: 221.89
    Episode_Reward/reaching_object: 0.4529
    Episode_Reward/rotating_object: 21.7193
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 1.89s
                      Time elapsed: 00:08:02
                               ETA: 00:57:55

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 50954 steps/s (collection: 1.825s, learning 0.104s)
             Mean action noise std: 1.42
          Mean value_function loss: 54.2199
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.6984
                       Mean reward: 114.33
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 0.4625
    Episode_Reward/rotating_object: 21.8264
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.93s
                      Time elapsed: 00:08:04
                               ETA: 00:57:48

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 50904 steps/s (collection: 1.804s, learning 0.127s)
             Mean action noise std: 1.42
          Mean value_function loss: 58.0938
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 31.7139
                       Mean reward: 123.66
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 0.4662
    Episode_Reward/rotating_object: 21.9933
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.93s
                      Time elapsed: 00:08:06
                               ETA: 00:57:40

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 49339 steps/s (collection: 1.881s, learning 0.111s)
             Mean action noise std: 1.42
          Mean value_function loss: 51.2199
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.7304
                       Mean reward: 144.67
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 0.4769
    Episode_Reward/rotating_object: 25.5322
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 1.99s
                      Time elapsed: 00:08:08
                               ETA: 00:57:33

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 50326 steps/s (collection: 1.847s, learning 0.107s)
             Mean action noise std: 1.42
          Mean value_function loss: 61.5851
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 31.7478
                       Mean reward: 117.91
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 0.4666
    Episode_Reward/rotating_object: 24.2143
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.95s
                      Time elapsed: 00:08:10
                               ETA: 00:57:25

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 50476 steps/s (collection: 1.811s, learning 0.136s)
             Mean action noise std: 1.42
          Mean value_function loss: 55.1167
               Mean surrogate loss: 0.0060
                 Mean entropy loss: 31.7604
                       Mean reward: 122.21
               Mean episode length: 216.91
    Episode_Reward/reaching_object: 0.4606
    Episode_Reward/rotating_object: 27.2328
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.95s
                      Time elapsed: 00:08:12
                               ETA: 00:57:18

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 47331 steps/s (collection: 1.958s, learning 0.119s)
             Mean action noise std: 1.42
          Mean value_function loss: 48.7471
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.7661
                       Mean reward: 157.18
               Mean episode length: 224.96
    Episode_Reward/reaching_object: 0.4760
    Episode_Reward/rotating_object: 28.0725
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.08s
                      Time elapsed: 00:08:14
                               ETA: 00:57:12

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 53235 steps/s (collection: 1.747s, learning 0.100s)
             Mean action noise std: 1.42
          Mean value_function loss: 48.7891
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 31.7770
                       Mean reward: 115.16
               Mean episode length: 220.86
    Episode_Reward/reaching_object: 0.4515
    Episode_Reward/rotating_object: 26.9524
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.85s
                      Time elapsed: 00:08:16
                               ETA: 00:57:04

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 34240 steps/s (collection: 2.576s, learning 0.295s)
             Mean action noise std: 1.43
          Mean value_function loss: 47.5488
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.7906
                       Mean reward: 146.85
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 0.4707
    Episode_Reward/rotating_object: 29.2566
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.87s
                      Time elapsed: 00:08:19
                               ETA: 00:57:03

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 24381 steps/s (collection: 3.699s, learning 0.333s)
             Mean action noise std: 1.43
          Mean value_function loss: 52.4014
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.8053
                       Mean reward: 150.57
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 0.4704
    Episode_Reward/rotating_object: 28.2895
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 4.03s
                      Time elapsed: 00:08:23
                               ETA: 00:57:10

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 20566 steps/s (collection: 4.359s, learning 0.420s)
             Mean action noise std: 1.43
          Mean value_function loss: 52.8451
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 31.8215
                       Mean reward: 131.74
               Mean episode length: 216.52
    Episode_Reward/reaching_object: 0.4599
    Episode_Reward/rotating_object: 27.9064
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 4.78s
                      Time elapsed: 00:08:27
                               ETA: 00:57:22

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 21344 steps/s (collection: 4.251s, learning 0.354s)
             Mean action noise std: 1.43
          Mean value_function loss: 46.5066
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 31.8340
                       Mean reward: 122.97
               Mean episode length: 216.92
    Episode_Reward/reaching_object: 0.4336
    Episode_Reward/rotating_object: 26.7549
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 4.61s
                      Time elapsed: 00:08:32
                               ETA: 00:57:33

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 22305 steps/s (collection: 4.068s, learning 0.340s)
             Mean action noise std: 1.43
          Mean value_function loss: 51.2334
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.8432
                       Mean reward: 112.04
               Mean episode length: 210.88
    Episode_Reward/reaching_object: 0.4356
    Episode_Reward/rotating_object: 25.1307
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 4.41s
                      Time elapsed: 00:08:36
                               ETA: 00:57:42

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 21663 steps/s (collection: 4.132s, learning 0.406s)
             Mean action noise std: 1.43
          Mean value_function loss: 57.6617
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.8508
                       Mean reward: 139.66
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 0.4435
    Episode_Reward/rotating_object: 28.0015
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 4.54s
                      Time elapsed: 00:08:41
                               ETA: 00:57:52

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 23784 steps/s (collection: 3.793s, learning 0.340s)
             Mean action noise std: 1.43
          Mean value_function loss: 69.0086
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.8570
                       Mean reward: 144.08
               Mean episode length: 225.18
    Episode_Reward/reaching_object: 0.4528
    Episode_Reward/rotating_object: 27.2860
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 4.13s
                      Time elapsed: 00:08:45
                               ETA: 00:57:59

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 20883 steps/s (collection: 4.246s, learning 0.461s)
             Mean action noise std: 1.43
          Mean value_function loss: 70.4563
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 31.8665
                       Mean reward: 140.53
               Mean episode length: 226.81
    Episode_Reward/reaching_object: 0.4891
    Episode_Reward/rotating_object: 30.5736
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 4.71s
                      Time elapsed: 00:08:50
                               ETA: 00:58:10

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 22710 steps/s (collection: 4.008s, learning 0.321s)
             Mean action noise std: 1.43
          Mean value_function loss: 80.5523
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 31.8776
                       Mean reward: 151.13
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 0.4796
    Episode_Reward/rotating_object: 27.6524
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 4.33s
                      Time elapsed: 00:08:54
                               ETA: 00:58:18

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 22231 steps/s (collection: 3.889s, learning 0.532s)
             Mean action noise std: 1.43
          Mean value_function loss: 68.4350
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.8895
                       Mean reward: 180.34
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 0.5033
    Episode_Reward/rotating_object: 32.4581
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 4.42s
                      Time elapsed: 00:08:59
                               ETA: 00:58:26

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 22536 steps/s (collection: 3.986s, learning 0.375s)
             Mean action noise std: 1.44
          Mean value_function loss: 79.0667
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.9000
                       Mean reward: 160.92
               Mean episode length: 219.51
    Episode_Reward/reaching_object: 0.5080
    Episode_Reward/rotating_object: 34.6312
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 4.36s
                      Time elapsed: 00:09:03
                               ETA: 00:58:34

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 23672 steps/s (collection: 3.786s, learning 0.367s)
             Mean action noise std: 1.44
          Mean value_function loss: 82.5528
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.9115
                       Mean reward: 183.29
               Mean episode length: 227.51
    Episode_Reward/reaching_object: 0.5038
    Episode_Reward/rotating_object: 34.2477
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 4.15s
                      Time elapsed: 00:09:07
                               ETA: 00:58:41

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 24424 steps/s (collection: 3.748s, learning 0.276s)
             Mean action noise std: 1.44
          Mean value_function loss: 76.9339
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.9199
                       Mean reward: 175.33
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 0.4914
    Episode_Reward/rotating_object: 32.7060
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 4.02s
                      Time elapsed: 00:09:11
                               ETA: 00:58:47

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 26822 steps/s (collection: 3.409s, learning 0.256s)
             Mean action noise std: 1.44
          Mean value_function loss: 82.4310
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.9277
                       Mean reward: 193.83
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 0.5193
    Episode_Reward/rotating_object: 35.3431
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 3.66s
                      Time elapsed: 00:09:15
                               ETA: 00:58:50

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 26609 steps/s (collection: 3.456s, learning 0.238s)
             Mean action noise std: 1.44
          Mean value_function loss: 79.4829
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.9387
                       Mean reward: 193.59
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 0.5171
    Episode_Reward/rotating_object: 38.0902
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 3.69s
                      Time elapsed: 00:09:18
                               ETA: 00:58:53

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 27654 steps/s (collection: 3.311s, learning 0.244s)
             Mean action noise std: 1.44
          Mean value_function loss: 89.6942
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.9469
                       Mean reward: 187.66
               Mean episode length: 229.60
    Episode_Reward/reaching_object: 0.4981
    Episode_Reward/rotating_object: 38.0516
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 3.55s
                      Time elapsed: 00:09:22
                               ETA: 00:58:56

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 26524 steps/s (collection: 3.473s, learning 0.233s)
             Mean action noise std: 1.44
          Mean value_function loss: 89.4506
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 31.9558
                       Mean reward: 144.11
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 0.4898
    Episode_Reward/rotating_object: 34.1503
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 3.71s
                      Time elapsed: 00:09:26
                               ETA: 00:58:59

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 26243 steps/s (collection: 3.616s, learning 0.130s)
             Mean action noise std: 1.44
          Mean value_function loss: 83.8283
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 31.9701
                       Mean reward: 174.08
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 0.4947
    Episode_Reward/rotating_object: 34.8118
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 3.75s
                      Time elapsed: 00:09:30
                               ETA: 00:59:03

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 48582 steps/s (collection: 1.928s, learning 0.095s)
             Mean action noise std: 1.44
          Mean value_function loss: 78.2640
               Mean surrogate loss: 0.0061
                 Mean entropy loss: 31.9776
                       Mean reward: 183.60
               Mean episode length: 217.43
    Episode_Reward/reaching_object: 0.4847
    Episode_Reward/rotating_object: 35.6170
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.02s
                      Time elapsed: 00:09:32
                               ETA: 00:58:56

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 49886 steps/s (collection: 1.840s, learning 0.130s)
             Mean action noise std: 1.44
          Mean value_function loss: 78.0456
               Mean surrogate loss: 0.0086
                 Mean entropy loss: 31.9799
                       Mean reward: 192.54
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 0.4926
    Episode_Reward/rotating_object: 35.9299
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.97s
                      Time elapsed: 00:09:33
                               ETA: 00:58:48

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 49037 steps/s (collection: 1.904s, learning 0.101s)
             Mean action noise std: 1.44
          Mean value_function loss: 73.8285
               Mean surrogate loss: 0.0076
                 Mean entropy loss: 31.9805
                       Mean reward: 168.02
               Mean episode length: 216.49
    Episode_Reward/reaching_object: 0.4875
    Episode_Reward/rotating_object: 37.7607
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.00s
                      Time elapsed: 00:09:36
                               ETA: 00:58:41

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 51247 steps/s (collection: 1.812s, learning 0.106s)
             Mean action noise std: 1.44
          Mean value_function loss: 69.2482
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 31.9808
                       Mean reward: 193.52
               Mean episode length: 212.13
    Episode_Reward/reaching_object: 0.4882
    Episode_Reward/rotating_object: 38.9282
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.92s
                      Time elapsed: 00:09:37
                               ETA: 00:58:33

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 51217 steps/s (collection: 1.811s, learning 0.108s)
             Mean action noise std: 1.44
          Mean value_function loss: 81.0435
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 31.9849
                       Mean reward: 211.97
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 0.5100
    Episode_Reward/rotating_object: 41.7387
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 1.92s
                      Time elapsed: 00:09:39
                               ETA: 00:58:26

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 47776 steps/s (collection: 1.954s, learning 0.104s)
             Mean action noise std: 1.44
          Mean value_function loss: 68.9793
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 31.9948
                       Mean reward: 211.00
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 0.5304
    Episode_Reward/rotating_object: 43.5154
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.06s
                      Time elapsed: 00:09:41
                               ETA: 00:58:19

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 52126 steps/s (collection: 1.776s, learning 0.110s)
             Mean action noise std: 1.44
          Mean value_function loss: 75.8260
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 32.0078
                       Mean reward: 224.60
               Mean episode length: 224.68
    Episode_Reward/reaching_object: 0.5229
    Episode_Reward/rotating_object: 42.9650
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.89s
                      Time elapsed: 00:09:43
                               ETA: 00:58:11

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 49360 steps/s (collection: 1.880s, learning 0.112s)
             Mean action noise std: 1.45
          Mean value_function loss: 74.0954
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 32.0191
                       Mean reward: 200.59
               Mean episode length: 214.87
    Episode_Reward/reaching_object: 0.5122
    Episode_Reward/rotating_object: 42.5344
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.99s
                      Time elapsed: 00:09:45
                               ETA: 00:58:04

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 52042 steps/s (collection: 1.793s, learning 0.096s)
             Mean action noise std: 1.45
          Mean value_function loss: 75.6166
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 32.0304
                       Mean reward: 182.35
               Mean episode length: 218.27
    Episode_Reward/reaching_object: 0.5026
    Episode_Reward/rotating_object: 41.9064
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 1.89s
                      Time elapsed: 00:09:47
                               ETA: 00:57:57

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 51227 steps/s (collection: 1.781s, learning 0.138s)
             Mean action noise std: 1.45
          Mean value_function loss: 74.9792
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 32.0394
                       Mean reward: 217.97
               Mean episode length: 215.85
    Episode_Reward/reaching_object: 0.4974
    Episode_Reward/rotating_object: 42.7870
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.92s
                      Time elapsed: 00:09:49
                               ETA: 00:57:49

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 51358 steps/s (collection: 1.817s, learning 0.098s)
             Mean action noise std: 1.45
          Mean value_function loss: 81.2680
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 32.0466
                       Mean reward: 197.53
               Mean episode length: 210.78
    Episode_Reward/reaching_object: 0.4983
    Episode_Reward/rotating_object: 41.8261
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 1.91s
                      Time elapsed: 00:09:51
                               ETA: 00:57:42

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 53816 steps/s (collection: 1.714s, learning 0.113s)
             Mean action noise std: 1.45
          Mean value_function loss: 80.9166
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 32.0560
                       Mean reward: 191.91
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 0.4965
    Episode_Reward/rotating_object: 38.2375
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 1.83s
                      Time elapsed: 00:09:53
                               ETA: 00:57:34

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 51749 steps/s (collection: 1.795s, learning 0.105s)
             Mean action noise std: 1.45
          Mean value_function loss: 87.2853
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.0630
                       Mean reward: 197.90
               Mean episode length: 221.84
    Episode_Reward/reaching_object: 0.5132
    Episode_Reward/rotating_object: 42.2519
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 1.90s
                      Time elapsed: 00:09:55
                               ETA: 00:57:27

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 51503 steps/s (collection: 1.800s, learning 0.109s)
             Mean action noise std: 1.45
          Mean value_function loss: 80.2234
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.0723
                       Mean reward: 235.46
               Mean episode length: 219.46
    Episode_Reward/reaching_object: 0.4974
    Episode_Reward/rotating_object: 40.5509
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 1.91s
                      Time elapsed: 00:09:57
                               ETA: 00:57:20

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 52736 steps/s (collection: 1.759s, learning 0.105s)
             Mean action noise std: 1.45
          Mean value_function loss: 81.4955
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.0829
                       Mean reward: 189.96
               Mean episode length: 223.98
    Episode_Reward/reaching_object: 0.5052
    Episode_Reward/rotating_object: 40.2844
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 1.86s
                      Time elapsed: 00:09:58
                               ETA: 00:57:12

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 52386 steps/s (collection: 1.768s, learning 0.108s)
             Mean action noise std: 1.45
          Mean value_function loss: 84.9468
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 32.0983
                       Mean reward: 234.51
               Mean episode length: 222.93
    Episode_Reward/reaching_object: 0.5018
    Episode_Reward/rotating_object: 45.1048
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 1.88s
                      Time elapsed: 00:10:00
                               ETA: 00:57:05

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 52791 steps/s (collection: 1.760s, learning 0.103s)
             Mean action noise std: 1.45
          Mean value_function loss: 81.5840
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 32.1066
                       Mean reward: 223.53
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 0.5050
    Episode_Reward/rotating_object: 43.4148
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 1.86s
                      Time elapsed: 00:10:02
                               ETA: 00:56:58

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 53192 steps/s (collection: 1.743s, learning 0.105s)
             Mean action noise std: 1.45
          Mean value_function loss: 74.0066
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.1156
                       Mean reward: 230.26
               Mean episode length: 221.78
    Episode_Reward/reaching_object: 0.4957
    Episode_Reward/rotating_object: 43.3907
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.85s
                      Time elapsed: 00:10:04
                               ETA: 00:56:50

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 53157 steps/s (collection: 1.753s, learning 0.097s)
             Mean action noise std: 1.45
          Mean value_function loss: 72.2543
               Mean surrogate loss: 0.0064
                 Mean entropy loss: 32.1219
                       Mean reward: 237.10
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 0.5138
    Episode_Reward/rotating_object: 44.9508
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.85s
                      Time elapsed: 00:10:06
                               ETA: 00:56:43

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 54271 steps/s (collection: 1.718s, learning 0.093s)
             Mean action noise std: 1.45
          Mean value_function loss: 74.8796
               Mean surrogate loss: 0.0064
                 Mean entropy loss: 32.1228
                       Mean reward: 223.68
               Mean episode length: 219.62
    Episode_Reward/reaching_object: 0.5127
    Episode_Reward/rotating_object: 47.4142
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.81s
                      Time elapsed: 00:10:08
                               ETA: 00:56:36

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 52379 steps/s (collection: 1.765s, learning 0.112s)
             Mean action noise std: 1.45
          Mean value_function loss: 104.7892
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 32.1240
                       Mean reward: 227.41
               Mean episode length: 226.59
    Episode_Reward/reaching_object: 0.5074
    Episode_Reward/rotating_object: 46.6915
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.88s
                      Time elapsed: 00:10:10
                               ETA: 00:56:28

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 52233 steps/s (collection: 1.766s, learning 0.116s)
             Mean action noise std: 1.46
          Mean value_function loss: 75.8987
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.1291
                       Mean reward: 211.71
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 0.5024
    Episode_Reward/rotating_object: 44.5069
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.88s
                      Time elapsed: 00:10:12
                               ETA: 00:56:21

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 51842 steps/s (collection: 1.781s, learning 0.115s)
             Mean action noise std: 1.46
          Mean value_function loss: 74.4926
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 32.1353
                       Mean reward: 267.46
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 0.5169
    Episode_Reward/rotating_object: 46.3651
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.90s
                      Time elapsed: 00:10:13
                               ETA: 00:56:15

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 51101 steps/s (collection: 1.801s, learning 0.123s)
             Mean action noise std: 1.46
          Mean value_function loss: 81.1016
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.1448
                       Mean reward: 228.26
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 0.4979
    Episode_Reward/rotating_object: 46.7140
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.92s
                      Time elapsed: 00:10:15
                               ETA: 00:56:08

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 51217 steps/s (collection: 1.811s, learning 0.109s)
             Mean action noise std: 1.46
          Mean value_function loss: 90.7469
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.1565
                       Mean reward: 224.14
               Mean episode length: 219.88
    Episode_Reward/reaching_object: 0.5094
    Episode_Reward/rotating_object: 46.1121
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.92s
                      Time elapsed: 00:10:17
                               ETA: 00:56:01

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 51803 steps/s (collection: 1.789s, learning 0.109s)
             Mean action noise std: 1.46
          Mean value_function loss: 77.4679
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.1682
                       Mean reward: 250.94
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 0.5123
    Episode_Reward/rotating_object: 50.0326
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.90s
                      Time elapsed: 00:10:19
                               ETA: 00:55:55

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 50359 steps/s (collection: 1.833s, learning 0.119s)
             Mean action noise std: 1.46
          Mean value_function loss: 75.3532
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 32.1787
                       Mean reward: 249.87
               Mean episode length: 227.79
    Episode_Reward/reaching_object: 0.5152
    Episode_Reward/rotating_object: 51.6419
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.95s
                      Time elapsed: 00:10:21
                               ETA: 00:55:48

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 52075 steps/s (collection: 1.791s, learning 0.097s)
             Mean action noise std: 1.46
          Mean value_function loss: 70.5640
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 32.1868
                       Mean reward: 288.70
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.5375
    Episode_Reward/rotating_object: 54.7878
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.89s
                      Time elapsed: 00:10:23
                               ETA: 00:55:41

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 52318 steps/s (collection: 1.765s, learning 0.114s)
             Mean action noise std: 1.46
          Mean value_function loss: 66.5930
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 32.1970
                       Mean reward: 289.23
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 0.4959
    Episode_Reward/rotating_object: 49.3648
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 1.88s
                      Time elapsed: 00:10:25
                               ETA: 00:55:35

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 52733 steps/s (collection: 1.761s, learning 0.104s)
             Mean action noise std: 1.46
          Mean value_function loss: 78.2461
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 32.2051
                       Mean reward: 258.97
               Mean episode length: 227.82
    Episode_Reward/reaching_object: 0.4972
    Episode_Reward/rotating_object: 49.9371
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 1.86s
                      Time elapsed: 00:10:27
                               ETA: 00:55:28

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 51465 steps/s (collection: 1.809s, learning 0.102s)
             Mean action noise std: 1.46
          Mean value_function loss: 62.1912
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.2125
                       Mean reward: 263.64
               Mean episode length: 228.06
    Episode_Reward/reaching_object: 0.5014
    Episode_Reward/rotating_object: 48.6039
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 1.91s
                      Time elapsed: 00:10:29
                               ETA: 00:55:22

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 49685 steps/s (collection: 1.879s, learning 0.100s)
             Mean action noise std: 1.46
          Mean value_function loss: 69.7880
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 32.2280
                       Mean reward: 293.47
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 0.4973
    Episode_Reward/rotating_object: 51.3795
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 1.98s
                      Time elapsed: 00:10:31
                               ETA: 00:55:15

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 51328 steps/s (collection: 1.815s, learning 0.100s)
             Mean action noise std: 1.46
          Mean value_function loss: 64.9643
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 32.2346
                       Mean reward: 284.89
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 0.5263
    Episode_Reward/rotating_object: 58.0545
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 1.92s
                      Time elapsed: 00:10:33
                               ETA: 00:55:09

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 53061 steps/s (collection: 1.757s, learning 0.096s)
             Mean action noise std: 1.47
          Mean value_function loss: 74.9566
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.2414
                       Mean reward: 259.84
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 0.5133
    Episode_Reward/rotating_object: 55.9798
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 1.85s
                      Time elapsed: 00:10:34
                               ETA: 00:55:02

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 54050 steps/s (collection: 1.716s, learning 0.103s)
             Mean action noise std: 1.47
          Mean value_function loss: 80.5788
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.2525
                       Mean reward: 301.59
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 0.5262
    Episode_Reward/rotating_object: 55.5279
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 1.82s
                      Time elapsed: 00:10:36
                               ETA: 00:54:56

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 51967 steps/s (collection: 1.784s, learning 0.108s)
             Mean action noise std: 1.47
          Mean value_function loss: 91.1077
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.2609
                       Mean reward: 275.60
               Mean episode length: 221.40
    Episode_Reward/reaching_object: 0.5048
    Episode_Reward/rotating_object: 52.9364
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 1.89s
                      Time elapsed: 00:10:38
                               ETA: 00:54:49

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 51086 steps/s (collection: 1.817s, learning 0.107s)
             Mean action noise std: 1.47
          Mean value_function loss: 76.8841
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.2674
                       Mean reward: 302.37
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 0.5323
    Episode_Reward/rotating_object: 57.8919
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.92s
                      Time elapsed: 00:10:40
                               ETA: 00:54:43

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 52842 steps/s (collection: 1.763s, learning 0.097s)
             Mean action noise std: 1.47
          Mean value_function loss: 85.9608
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 32.2754
                       Mean reward: 261.35
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 0.5035
    Episode_Reward/rotating_object: 51.9647
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 1.86s
                      Time elapsed: 00:10:42
                               ETA: 00:54:37

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 53310 steps/s (collection: 1.753s, learning 0.091s)
             Mean action noise std: 1.47
          Mean value_function loss: 75.4711
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.2862
                       Mean reward: 274.02
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 0.5159
    Episode_Reward/rotating_object: 54.9676
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 1.84s
                      Time elapsed: 00:10:44
                               ETA: 00:54:30

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 52207 steps/s (collection: 1.784s, learning 0.099s)
             Mean action noise std: 1.47
          Mean value_function loss: 87.5302
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 32.3007
                       Mean reward: 317.65
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 0.5573
    Episode_Reward/rotating_object: 57.0356
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 1.88s
                      Time elapsed: 00:10:46
                               ETA: 00:54:24

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 51968 steps/s (collection: 1.789s, learning 0.103s)
             Mean action noise std: 1.47
          Mean value_function loss: 74.7435
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 32.3071
                       Mean reward: 284.43
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 0.5581
    Episode_Reward/rotating_object: 57.0569
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 1.89s
                      Time elapsed: 00:10:47
                               ETA: 00:54:18

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 52286 steps/s (collection: 1.773s, learning 0.107s)
             Mean action noise std: 1.47
          Mean value_function loss: 80.0077
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.3146
                       Mean reward: 302.67
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.5577
    Episode_Reward/rotating_object: 58.3950
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 1.88s
                      Time elapsed: 00:10:49
                               ETA: 00:54:11

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 50604 steps/s (collection: 1.830s, learning 0.113s)
             Mean action noise std: 1.47
          Mean value_function loss: 82.0378
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.3224
                       Mean reward: 257.52
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 0.5721
    Episode_Reward/rotating_object: 59.6986
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 1.94s
                      Time elapsed: 00:10:51
                               ETA: 00:54:06

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 52685 steps/s (collection: 1.766s, learning 0.100s)
             Mean action noise std: 1.47
          Mean value_function loss: 79.9348
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 32.3308
                       Mean reward: 329.50
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 0.5426
    Episode_Reward/rotating_object: 58.0508
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 1.87s
                      Time elapsed: 00:10:53
                               ETA: 00:53:59

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 51245 steps/s (collection: 1.808s, learning 0.110s)
             Mean action noise std: 1.47
          Mean value_function loss: 84.0806
               Mean surrogate loss: 0.0058
                 Mean entropy loss: 32.3325
                       Mean reward: 306.14
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 0.5546
    Episode_Reward/rotating_object: 61.5810
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 1.92s
                      Time elapsed: 00:10:55
                               ETA: 00:53:53

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 51307 steps/s (collection: 1.811s, learning 0.105s)
             Mean action noise std: 1.47
          Mean value_function loss: 94.4340
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 32.3332
                       Mean reward: 336.97
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 0.5653
    Episode_Reward/rotating_object: 62.6341
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.92s
                      Time elapsed: 00:10:57
                               ETA: 00:53:48

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 52354 steps/s (collection: 1.777s, learning 0.101s)
             Mean action noise std: 1.47
          Mean value_function loss: 126.8716
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.3363
                       Mean reward: 345.91
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 0.5807
    Episode_Reward/rotating_object: 64.5524
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 1.88s
                      Time elapsed: 00:10:59
                               ETA: 00:53:41

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 51379 steps/s (collection: 1.784s, learning 0.130s)
             Mean action noise std: 1.47
          Mean value_function loss: 119.3100
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.3415
                       Mean reward: 338.75
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 0.5638
    Episode_Reward/rotating_object: 60.6717
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 1.91s
                      Time elapsed: 00:11:01
                               ETA: 00:53:36

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 51502 steps/s (collection: 1.812s, learning 0.097s)
             Mean action noise std: 1.47
          Mean value_function loss: 100.1563
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.3468
                       Mean reward: 329.84
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 0.5525
    Episode_Reward/rotating_object: 59.8550
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 1.91s
                      Time elapsed: 00:11:03
                               ETA: 00:53:30

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 49791 steps/s (collection: 1.870s, learning 0.104s)
             Mean action noise std: 1.47
          Mean value_function loss: 94.0478
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.3540
                       Mean reward: 273.12
               Mean episode length: 224.39
    Episode_Reward/reaching_object: 0.5653
    Episode_Reward/rotating_object: 60.6438
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 1.97s
                      Time elapsed: 00:11:05
                               ETA: 00:53:24

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 51057 steps/s (collection: 1.808s, learning 0.118s)
             Mean action noise std: 1.48
          Mean value_function loss: 92.7568
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.3598
                       Mean reward: 251.24
               Mean episode length: 229.39
    Episode_Reward/reaching_object: 0.5648
    Episode_Reward/rotating_object: 57.7476
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 1.93s
                      Time elapsed: 00:11:07
                               ETA: 00:53:19

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 49187 steps/s (collection: 1.878s, learning 0.121s)
             Mean action noise std: 1.48
          Mean value_function loss: 93.9248
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.3702
                       Mean reward: 306.34
               Mean episode length: 234.15
    Episode_Reward/reaching_object: 0.5783
    Episode_Reward/rotating_object: 61.1111
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.00s
                      Time elapsed: 00:11:09
                               ETA: 00:53:13

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 51391 steps/s (collection: 1.820s, learning 0.093s)
             Mean action noise std: 1.48
          Mean value_function loss: 95.3594
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 32.3841
                       Mean reward: 347.73
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 0.5865
    Episode_Reward/rotating_object: 62.8215
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 1.91s
                      Time elapsed: 00:11:11
                               ETA: 00:53:08

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 50906 steps/s (collection: 1.810s, learning 0.121s)
             Mean action noise std: 1.48
          Mean value_function loss: 83.0610
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.3907
                       Mean reward: 247.43
               Mean episode length: 223.74
    Episode_Reward/reaching_object: 0.5690
    Episode_Reward/rotating_object: 55.1081
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 1.93s
                      Time elapsed: 00:11:12
                               ETA: 00:53:02

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 51774 steps/s (collection: 1.799s, learning 0.100s)
             Mean action noise std: 1.48
          Mean value_function loss: 85.1039
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.3986
                       Mean reward: 309.62
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 0.5726
    Episode_Reward/rotating_object: 58.4020
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 1.90s
                      Time elapsed: 00:11:14
                               ETA: 00:52:56

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 51912 steps/s (collection: 1.778s, learning 0.116s)
             Mean action noise std: 1.48
          Mean value_function loss: 96.9295
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.4074
                       Mean reward: 286.43
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 0.5774
    Episode_Reward/rotating_object: 60.0441
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 1.89s
                      Time elapsed: 00:11:16
                               ETA: 00:52:50

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 50592 steps/s (collection: 1.814s, learning 0.129s)
             Mean action noise std: 1.48
          Mean value_function loss: 94.2569
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.4162
                       Mean reward: 291.09
               Mean episode length: 226.91
    Episode_Reward/reaching_object: 0.5805
    Episode_Reward/rotating_object: 63.4648
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 1.94s
                      Time elapsed: 00:11:18
                               ETA: 00:52:45

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 51009 steps/s (collection: 1.811s, learning 0.116s)
             Mean action noise std: 1.48
          Mean value_function loss: 91.5809
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 32.4243
                       Mean reward: 316.81
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 0.5763
    Episode_Reward/rotating_object: 62.5976
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.93s
                      Time elapsed: 00:11:20
                               ETA: 00:52:40

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 52436 steps/s (collection: 1.769s, learning 0.106s)
             Mean action noise std: 1.48
          Mean value_function loss: 81.4012
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 32.4286
                       Mean reward: 326.47
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 0.5717
    Episode_Reward/rotating_object: 62.0669
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 1.87s
                      Time elapsed: 00:11:22
                               ETA: 00:52:34

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 49596 steps/s (collection: 1.877s, learning 0.105s)
             Mean action noise std: 1.48
          Mean value_function loss: 82.0447
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.4333
                       Mean reward: 330.02
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 0.5866
    Episode_Reward/rotating_object: 67.7911
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 1.98s
                      Time elapsed: 00:11:24
                               ETA: 00:52:29

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 48528 steps/s (collection: 1.914s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 79.0590
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 32.4412
                       Mean reward: 342.44
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 0.5740
    Episode_Reward/rotating_object: 66.1189
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.03s
                      Time elapsed: 00:11:26
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 51188 steps/s (collection: 1.817s, learning 0.104s)
             Mean action noise std: 1.48
          Mean value_function loss: 77.0138
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.4498
                       Mean reward: 335.35
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 0.5633
    Episode_Reward/rotating_object: 64.0501
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 1.92s
                      Time elapsed: 00:11:28
                               ETA: 00:52:18

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 51710 steps/s (collection: 1.798s, learning 0.103s)
             Mean action noise std: 1.48
          Mean value_function loss: 83.3996
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.4566
                       Mean reward: 289.72
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 0.5521
    Episode_Reward/rotating_object: 62.3029
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 1.90s
                      Time elapsed: 00:11:30
                               ETA: 00:52:13

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 49726 steps/s (collection: 1.869s, learning 0.108s)
             Mean action noise std: 1.48
          Mean value_function loss: 90.8188
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.4658
                       Mean reward: 345.79
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 0.5605
    Episode_Reward/rotating_object: 65.5863
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 1.98s
                      Time elapsed: 00:11:32
                               ETA: 00:52:08

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 50480 steps/s (collection: 1.840s, learning 0.108s)
             Mean action noise std: 1.49
          Mean value_function loss: 92.0593
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.4754
                       Mean reward: 329.97
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 0.5606
    Episode_Reward/rotating_object: 63.6028
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 1.95s
                      Time elapsed: 00:11:34
                               ETA: 00:52:02

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 49359 steps/s (collection: 1.875s, learning 0.117s)
             Mean action noise std: 1.49
          Mean value_function loss: 100.1067
               Mean surrogate loss: 0.0059
                 Mean entropy loss: 32.4831
                       Mean reward: 324.74
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 0.5427
    Episode_Reward/rotating_object: 61.9170
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 1.99s
                      Time elapsed: 00:11:36
                               ETA: 00:51:57

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 50168 steps/s (collection: 1.823s, learning 0.136s)
             Mean action noise std: 1.49
          Mean value_function loss: 77.8137
               Mean surrogate loss: 0.0023
                 Mean entropy loss: 32.4856
                       Mean reward: 356.80
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 0.5482
    Episode_Reward/rotating_object: 66.4803
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 1.96s
                      Time elapsed: 00:11:38
                               ETA: 00:51:52

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 52442 steps/s (collection: 1.769s, learning 0.105s)
             Mean action noise std: 1.49
          Mean value_function loss: 76.2687
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 32.4894
                       Mean reward: 374.55
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 0.5687
    Episode_Reward/rotating_object: 70.5032
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 1.87s
                      Time elapsed: 00:11:40
                               ETA: 00:51:47

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 51509 steps/s (collection: 1.816s, learning 0.093s)
             Mean action noise std: 1.49
          Mean value_function loss: 75.3500
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 32.4976
                       Mean reward: 351.01
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 0.5574
    Episode_Reward/rotating_object: 68.5069
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 1.91s
                      Time elapsed: 00:11:41
                               ETA: 00:51:41

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 49813 steps/s (collection: 1.858s, learning 0.115s)
             Mean action noise std: 1.49
          Mean value_function loss: 82.3381
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.5036
                       Mean reward: 394.43
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 0.5778
    Episode_Reward/rotating_object: 71.1285
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 1.97s
                      Time elapsed: 00:11:43
                               ETA: 00:51:36

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 44967 steps/s (collection: 1.996s, learning 0.191s)
             Mean action noise std: 1.49
          Mean value_function loss: 78.8334
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 32.5081
                       Mean reward: 351.59
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 0.5560
    Episode_Reward/rotating_object: 67.2302
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.19s
                      Time elapsed: 00:11:46
                               ETA: 00:51:32

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 46944 steps/s (collection: 1.963s, learning 0.131s)
             Mean action noise std: 1.49
          Mean value_function loss: 72.5573
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 32.5161
                       Mean reward: 397.86
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.5806
    Episode_Reward/rotating_object: 69.2570
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.09s
                      Time elapsed: 00:11:48
                               ETA: 00:51:28

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 46813 steps/s (collection: 1.976s, learning 0.124s)
             Mean action noise std: 1.49
          Mean value_function loss: 72.9285
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 32.5206
                       Mean reward: 358.70
               Mean episode length: 242.82
    Episode_Reward/reaching_object: 0.5752
    Episode_Reward/rotating_object: 72.7429
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.10s
                      Time elapsed: 00:11:50
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 48401 steps/s (collection: 1.905s, learning 0.126s)
             Mean action noise std: 1.49
          Mean value_function loss: 73.3245
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.5239
                       Mean reward: 410.14
               Mean episode length: 234.15
    Episode_Reward/reaching_object: 0.5889
    Episode_Reward/rotating_object: 73.7687
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.03s
                      Time elapsed: 00:11:52
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 47113 steps/s (collection: 1.960s, learning 0.127s)
             Mean action noise std: 1.49
          Mean value_function loss: 79.8467
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.5305
                       Mean reward: 352.53
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 0.5725
    Episode_Reward/rotating_object: 71.0491
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.09s
                      Time elapsed: 00:11:54
                               ETA: 00:51:14

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 48923 steps/s (collection: 1.881s, learning 0.128s)
             Mean action noise std: 1.49
          Mean value_function loss: 81.3777
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.5376
                       Mean reward: 346.05
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 0.5776
    Episode_Reward/rotating_object: 67.6288
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.01s
                      Time elapsed: 00:11:56
                               ETA: 00:51:10

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 50676 steps/s (collection: 1.828s, learning 0.112s)
             Mean action noise std: 1.49
          Mean value_function loss: 90.8880
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.5437
                       Mean reward: 352.63
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 0.5998
    Episode_Reward/rotating_object: 73.6602
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 1.94s
                      Time elapsed: 00:11:58
                               ETA: 00:51:05

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 52457 steps/s (collection: 1.766s, learning 0.108s)
             Mean action noise std: 1.49
          Mean value_function loss: 80.9981
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 32.5491
                       Mean reward: 333.62
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 0.5919
    Episode_Reward/rotating_object: 70.1114
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 1.87s
                      Time elapsed: 00:12:00
                               ETA: 00:50:59

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 34066 steps/s (collection: 2.782s, learning 0.104s)
             Mean action noise std: 1.49
          Mean value_function loss: 79.9445
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 32.5534
                       Mean reward: 340.44
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 0.5869
    Episode_Reward/rotating_object: 74.2123
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.89s
                      Time elapsed: 00:12:03
                               ETA: 00:50:58

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 48407 steps/s (collection: 1.890s, learning 0.141s)
             Mean action noise std: 1.49
          Mean value_function loss: 83.1345
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 32.5574
                       Mean reward: 354.48
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 0.6054
    Episode_Reward/rotating_object: 73.7924
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.03s
                      Time elapsed: 00:12:05
                               ETA: 00:50:54

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 47560 steps/s (collection: 1.963s, learning 0.104s)
             Mean action noise std: 1.49
          Mean value_function loss: 79.5895
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.5613
                       Mean reward: 376.89
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 0.5991
    Episode_Reward/rotating_object: 74.3591
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.07s
                      Time elapsed: 00:12:07
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 49475 steps/s (collection: 1.833s, learning 0.154s)
             Mean action noise std: 1.49
          Mean value_function loss: 76.9623
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.5686
                       Mean reward: 370.05
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 0.5873
    Episode_Reward/rotating_object: 72.0506
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 1.99s
                      Time elapsed: 00:12:09
                               ETA: 00:50:45

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 50623 steps/s (collection: 1.839s, learning 0.103s)
             Mean action noise std: 1.49
          Mean value_function loss: 77.5922
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 32.5730
                       Mean reward: 405.11
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 0.6083
    Episode_Reward/rotating_object: 79.0990
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 1.94s
                      Time elapsed: 00:12:11
                               ETA: 00:50:40

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 47801 steps/s (collection: 1.964s, learning 0.093s)
             Mean action noise std: 1.49
          Mean value_function loss: 76.0873
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.5783
                       Mean reward: 398.48
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 0.6061
    Episode_Reward/rotating_object: 74.9339
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.06s
                      Time elapsed: 00:12:13
                               ETA: 00:50:35

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 50494 steps/s (collection: 1.816s, learning 0.131s)
             Mean action noise std: 1.50
          Mean value_function loss: 79.0929
               Mean surrogate loss: 0.0030
                 Mean entropy loss: 32.5836
                       Mean reward: 404.41
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.5922
    Episode_Reward/rotating_object: 75.5983
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 1.95s
                      Time elapsed: 00:12:15
                               ETA: 00:50:31

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 53388 steps/s (collection: 1.743s, learning 0.098s)
             Mean action noise std: 1.50
          Mean value_function loss: 75.8848
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.5851
                       Mean reward: 374.44
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 0.6029
    Episode_Reward/rotating_object: 76.6331
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 1.84s
                      Time elapsed: 00:12:17
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 51230 steps/s (collection: 1.796s, learning 0.123s)
             Mean action noise std: 1.50
          Mean value_function loss: 82.0520
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 32.5889
                       Mean reward: 383.81
               Mean episode length: 244.59
    Episode_Reward/reaching_object: 0.5913
    Episode_Reward/rotating_object: 71.9469
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 1.92s
                      Time elapsed: 00:12:18
                               ETA: 00:50:20

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 49718 steps/s (collection: 1.860s, learning 0.117s)
             Mean action noise std: 1.50
          Mean value_function loss: 81.1890
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.5960
                       Mean reward: 335.92
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 0.5853
    Episode_Reward/rotating_object: 72.3100
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 1.98s
                      Time elapsed: 00:12:20
                               ETA: 00:50:16

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 47651 steps/s (collection: 1.928s, learning 0.135s)
             Mean action noise std: 1.50
          Mean value_function loss: 74.4529
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.6071
                       Mean reward: 350.24
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 0.5897
    Episode_Reward/rotating_object: 74.0124
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.06s
                      Time elapsed: 00:12:22
                               ETA: 00:50:11

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 46109 steps/s (collection: 1.966s, learning 0.166s)
             Mean action noise std: 1.50
          Mean value_function loss: 92.0994
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.6160
                       Mean reward: 383.06
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 0.6016
    Episode_Reward/rotating_object: 74.4693
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.13s
                      Time elapsed: 00:12:25
                               ETA: 00:50:07

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 48720 steps/s (collection: 1.906s, learning 0.112s)
             Mean action noise std: 1.50
          Mean value_function loss: 81.7312
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 32.6260
                       Mean reward: 371.99
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 0.5917
    Episode_Reward/rotating_object: 73.8992
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.02s
                      Time elapsed: 00:12:27
                               ETA: 00:50:03

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 46151 steps/s (collection: 2.004s, learning 0.126s)
             Mean action noise std: 1.50
          Mean value_function loss: 73.0521
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.6330
                       Mean reward: 421.46
               Mean episode length: 243.10
    Episode_Reward/reaching_object: 0.6151
    Episode_Reward/rotating_object: 83.8652
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.13s
                      Time elapsed: 00:12:29
                               ETA: 00:49:59

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 52441 steps/s (collection: 1.754s, learning 0.121s)
             Mean action noise std: 1.50
          Mean value_function loss: 77.0046
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 32.6377
                       Mean reward: 398.87
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 0.6089
    Episode_Reward/rotating_object: 81.9284
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 1.87s
                      Time elapsed: 00:12:31
                               ETA: 00:49:54

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 51601 steps/s (collection: 1.790s, learning 0.115s)
             Mean action noise std: 1.50
          Mean value_function loss: 74.5192
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.6419
                       Mean reward: 381.92
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 0.6146
    Episode_Reward/rotating_object: 79.6372
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 1.91s
                      Time elapsed: 00:12:33
                               ETA: 00:49:49

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 52050 steps/s (collection: 1.780s, learning 0.109s)
             Mean action noise std: 1.50
          Mean value_function loss: 78.5146
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 32.6508
                       Mean reward: 447.89
               Mean episode length: 235.40
    Episode_Reward/reaching_object: 0.5974
    Episode_Reward/rotating_object: 81.5678
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 1.89s
                      Time elapsed: 00:12:34
                               ETA: 00:49:44

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 47516 steps/s (collection: 1.938s, learning 0.131s)
             Mean action noise std: 1.50
          Mean value_function loss: 83.4923
               Mean surrogate loss: 0.0029
                 Mean entropy loss: 32.6632
                       Mean reward: 369.06
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 0.6063
    Episode_Reward/rotating_object: 78.9997
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.07s
                      Time elapsed: 00:12:37
                               ETA: 00:49:40

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 46088 steps/s (collection: 1.996s, learning 0.137s)
             Mean action noise std: 1.50
          Mean value_function loss: 76.2464
               Mean surrogate loss: 0.0079
                 Mean entropy loss: 32.6675
                       Mean reward: 423.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6222
    Episode_Reward/rotating_object: 81.0476
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.13s
                      Time elapsed: 00:12:39
                               ETA: 00:49:36

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 47868 steps/s (collection: 1.924s, learning 0.130s)
             Mean action noise std: 1.50
          Mean value_function loss: 73.8307
               Mean surrogate loss: 0.0091
                 Mean entropy loss: 32.6685
                       Mean reward: 437.64
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.6152
    Episode_Reward/rotating_object: 82.4882
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.05s
                      Time elapsed: 00:12:41
                               ETA: 00:49:32

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 50895 steps/s (collection: 1.820s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 70.7074
               Mean surrogate loss: 0.0081
                 Mean entropy loss: 32.6688
                       Mean reward: 404.14
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.6199
    Episode_Reward/rotating_object: 85.1122
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 1.93s
                      Time elapsed: 00:12:43
                               ETA: 00:49:27

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 52745 steps/s (collection: 1.760s, learning 0.104s)
             Mean action noise std: 1.50
          Mean value_function loss: 73.4245
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 32.6692
                       Mean reward: 389.46
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 0.6121
    Episode_Reward/rotating_object: 81.1296
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 1.86s
                      Time elapsed: 00:12:44
                               ETA: 00:49:23

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 52619 steps/s (collection: 1.755s, learning 0.113s)
             Mean action noise std: 1.50
          Mean value_function loss: 76.1752
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.6714
                       Mean reward: 423.05
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.6230
    Episode_Reward/rotating_object: 82.5398
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 1.87s
                      Time elapsed: 00:12:46
                               ETA: 00:49:18

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 52685 steps/s (collection: 1.754s, learning 0.112s)
             Mean action noise std: 1.50
          Mean value_function loss: 72.1369
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.6784
                       Mean reward: 379.35
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 0.6108
    Episode_Reward/rotating_object: 80.3825
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 1.87s
                      Time elapsed: 00:12:48
                               ETA: 00:49:13

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 52687 steps/s (collection: 1.744s, learning 0.122s)
             Mean action noise std: 1.51
          Mean value_function loss: 73.5986
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.6901
                       Mean reward: 414.31
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 0.6142
    Episode_Reward/rotating_object: 85.3222
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 1.87s
                      Time elapsed: 00:12:50
                               ETA: 00:49:08

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 52184 steps/s (collection: 1.780s, learning 0.104s)
             Mean action noise std: 1.51
          Mean value_function loss: 69.8265
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 32.6995
                       Mean reward: 455.12
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.6208
    Episode_Reward/rotating_object: 84.9772
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.88s
                      Time elapsed: 00:12:52
                               ETA: 00:49:03

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 52899 steps/s (collection: 1.763s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 69.5502
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.7061
                       Mean reward: 453.98
               Mean episode length: 241.01
    Episode_Reward/reaching_object: 0.6235
    Episode_Reward/rotating_object: 87.3904
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 1.86s
                      Time elapsed: 00:12:54
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 53911 steps/s (collection: 1.725s, learning 0.099s)
             Mean action noise std: 1.51
          Mean value_function loss: 66.7235
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 32.7111
                       Mean reward: 463.84
               Mean episode length: 242.92
    Episode_Reward/reaching_object: 0.6303
    Episode_Reward/rotating_object: 88.8165
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 1.82s
                      Time elapsed: 00:12:56
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 53637 steps/s (collection: 1.722s, learning 0.111s)
             Mean action noise std: 1.51
          Mean value_function loss: 71.3492
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 32.7136
                       Mean reward: 392.13
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 0.6214
    Episode_Reward/rotating_object: 84.3133
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 1.83s
                      Time elapsed: 00:12:57
                               ETA: 00:48:49

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 53787 steps/s (collection: 1.729s, learning 0.099s)
             Mean action noise std: 1.51
          Mean value_function loss: 70.3900
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 32.7162
                       Mean reward: 425.63
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.6232
    Episode_Reward/rotating_object: 84.6277
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 1.83s
                      Time elapsed: 00:12:59
                               ETA: 00:48:44

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 54073 steps/s (collection: 1.717s, learning 0.101s)
             Mean action noise std: 1.51
          Mean value_function loss: 64.5773
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 32.7243
                       Mean reward: 429.99
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 0.6208
    Episode_Reward/rotating_object: 84.4298
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 1.82s
                      Time elapsed: 00:13:01
                               ETA: 00:48:39

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 52720 steps/s (collection: 1.762s, learning 0.103s)
             Mean action noise std: 1.51
          Mean value_function loss: 68.5209
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.7342
                       Mean reward: 397.50
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 0.6148
    Episode_Reward/rotating_object: 81.1875
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 1.86s
                      Time elapsed: 00:13:03
                               ETA: 00:48:34

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 51476 steps/s (collection: 1.817s, learning 0.093s)
             Mean action noise std: 1.51
          Mean value_function loss: 73.8791
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 32.7432
                       Mean reward: 466.24
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 0.6160
    Episode_Reward/rotating_object: 88.4477
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 1.91s
                      Time elapsed: 00:13:05
                               ETA: 00:48:30

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 52862 steps/s (collection: 1.746s, learning 0.113s)
             Mean action noise std: 1.51
          Mean value_function loss: 73.9789
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 32.7478
                       Mean reward: 464.57
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 0.6068
    Episode_Reward/rotating_object: 86.0824
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 1.86s
                      Time elapsed: 00:13:07
                               ETA: 00:48:25

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 53663 steps/s (collection: 1.720s, learning 0.112s)
             Mean action noise std: 1.51
          Mean value_function loss: 70.5649
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.7523
                       Mean reward: 435.00
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 0.6147
    Episode_Reward/rotating_object: 88.6485
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 1.83s
                      Time elapsed: 00:13:09
                               ETA: 00:48:20

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 52318 steps/s (collection: 1.762s, learning 0.117s)
             Mean action noise std: 1.51
          Mean value_function loss: 72.6735
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.7607
                       Mean reward: 482.59
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.6010
    Episode_Reward/rotating_object: 88.2232
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 1.88s
                      Time elapsed: 00:13:10
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 53498 steps/s (collection: 1.744s, learning 0.094s)
             Mean action noise std: 1.51
          Mean value_function loss: 79.4966
               Mean surrogate loss: 0.0190
                 Mean entropy loss: 32.7695
                       Mean reward: 425.92
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 0.6149
    Episode_Reward/rotating_object: 90.7690
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 1.84s
                      Time elapsed: 00:13:12
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 51810 steps/s (collection: 1.789s, learning 0.109s)
             Mean action noise std: 1.51
          Mean value_function loss: 71.5554
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 32.7706
                       Mean reward: 423.39
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 0.6067
    Episode_Reward/rotating_object: 88.3719
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 1.90s
                      Time elapsed: 00:13:14
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 53657 steps/s (collection: 1.732s, learning 0.100s)
             Mean action noise std: 1.51
          Mean value_function loss: 80.5726
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 32.7726
                       Mean reward: 466.94
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 0.6134
    Episode_Reward/rotating_object: 88.6826
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 1.83s
                      Time elapsed: 00:13:16
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 53511 steps/s (collection: 1.737s, learning 0.100s)
             Mean action noise std: 1.51
          Mean value_function loss: 79.0145
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 32.7773
                       Mean reward: 436.75
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 0.6213
    Episode_Reward/rotating_object: 87.7775
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 1.84s
                      Time elapsed: 00:13:18
                               ETA: 00:47:57

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 53982 steps/s (collection: 1.719s, learning 0.102s)
             Mean action noise std: 1.51
          Mean value_function loss: 71.6214
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 32.7828
                       Mean reward: 497.30
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.6270
    Episode_Reward/rotating_object: 93.5368
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 1.82s
                      Time elapsed: 00:13:20
                               ETA: 00:47:52

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 53832 steps/s (collection: 1.728s, learning 0.098s)
             Mean action noise std: 1.51
          Mean value_function loss: 77.3654
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 32.7888
                       Mean reward: 449.45
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 0.6233
    Episode_Reward/rotating_object: 93.2207
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 1.83s
                      Time elapsed: 00:13:22
                               ETA: 00:47:48

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 50845 steps/s (collection: 1.824s, learning 0.109s)
             Mean action noise std: 1.51
          Mean value_function loss: 71.6409
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.7925
                       Mean reward: 500.97
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 0.6324
    Episode_Reward/rotating_object: 93.4927
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 1.93s
                      Time elapsed: 00:13:23
                               ETA: 00:47:43

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 49736 steps/s (collection: 1.838s, learning 0.138s)
             Mean action noise std: 1.52
          Mean value_function loss: 67.7619
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.7979
                       Mean reward: 488.93
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 0.6266
    Episode_Reward/rotating_object: 95.0250
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 1.98s
                      Time elapsed: 00:13:25
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 52984 steps/s (collection: 1.744s, learning 0.111s)
             Mean action noise std: 1.52
          Mean value_function loss: 68.3437
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.8075
                       Mean reward: 507.20
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6488
    Episode_Reward/rotating_object: 97.2047
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 1.86s
                      Time elapsed: 00:13:27
                               ETA: 00:47:35

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 47564 steps/s (collection: 1.949s, learning 0.118s)
             Mean action noise std: 1.52
          Mean value_function loss: 84.9939
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.8186
                       Mean reward: 461.24
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 0.6347
    Episode_Reward/rotating_object: 91.1322
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.07s
                      Time elapsed: 00:13:29
                               ETA: 00:47:31

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 47987 steps/s (collection: 1.919s, learning 0.129s)
             Mean action noise std: 1.52
          Mean value_function loss: 71.8781
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 32.8278
                       Mean reward: 425.75
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 0.6254
    Episode_Reward/rotating_object: 90.7176
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.05s
                      Time elapsed: 00:13:31
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 21988 steps/s (collection: 4.372s, learning 0.099s)
             Mean action noise std: 1.52
          Mean value_function loss: 70.1119
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 32.8301
                       Mean reward: 453.73
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 0.6366
    Episode_Reward/rotating_object: 92.5005
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 4.47s
                      Time elapsed: 00:13:36
                               ETA: 00:47:32

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 17888 steps/s (collection: 5.372s, learning 0.123s)
             Mean action noise std: 1.52
          Mean value_function loss: 66.7353
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.8313
                       Mean reward: 509.58
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 0.6334
    Episode_Reward/rotating_object: 94.0036
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 5.50s
                      Time elapsed: 00:13:41
                               ETA: 00:47:40

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 15645 steps/s (collection: 6.157s, learning 0.126s)
             Mean action noise std: 1.52
          Mean value_function loss: 72.3728
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 32.8343
                       Mean reward: 467.01
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 0.6371
    Episode_Reward/rotating_object: 94.6243
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.28s
                      Time elapsed: 00:13:48
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 16627 steps/s (collection: 5.778s, learning 0.134s)
             Mean action noise std: 1.52
          Mean value_function loss: 72.7237
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.8392
                       Mean reward: 504.68
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 0.6463
    Episode_Reward/rotating_object: 98.4085
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 5.91s
                      Time elapsed: 00:13:54
                               ETA: 00:48:00

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 16618 steps/s (collection: 5.796s, learning 0.120s)
             Mean action noise std: 1.52
          Mean value_function loss: 61.5977
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.8428
                       Mean reward: 467.08
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.6443
    Episode_Reward/rotating_object: 96.1218
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 5.92s
                      Time elapsed: 00:13:59
                               ETA: 00:48:10

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 17464 steps/s (collection: 5.457s, learning 0.172s)
             Mean action noise std: 1.52
          Mean value_function loss: 65.4335
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 32.8483
                       Mean reward: 478.17
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 0.6422
    Episode_Reward/rotating_object: 98.2717
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 5.63s
                      Time elapsed: 00:14:05
                               ETA: 00:48:18

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 17429 steps/s (collection: 5.497s, learning 0.143s)
             Mean action noise std: 1.52
          Mean value_function loss: 57.3025
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.8572
                       Mean reward: 495.40
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 0.6504
    Episode_Reward/rotating_object: 97.4711
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 5.64s
                      Time elapsed: 00:14:11
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 15625 steps/s (collection: 6.075s, learning 0.217s)
             Mean action noise std: 1.52
          Mean value_function loss: 60.8755
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 32.8655
                       Mean reward: 489.37
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 0.6395
    Episode_Reward/rotating_object: 95.6798
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.29s
                      Time elapsed: 00:14:17
                               ETA: 00:48:37

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13604 steps/s (collection: 7.098s, learning 0.128s)
             Mean action noise std: 1.52
          Mean value_function loss: 69.9120
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.8701
                       Mean reward: 496.89
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.6425
    Episode_Reward/rotating_object: 97.9640
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.23s
                      Time elapsed: 00:14:24
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 48926 steps/s (collection: 1.888s, learning 0.122s)
             Mean action noise std: 1.52
          Mean value_function loss: 64.1101
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.8766
                       Mean reward: 519.03
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.6338
    Episode_Reward/rotating_object: 97.6801
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.01s
                      Time elapsed: 00:14:26
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 53680 steps/s (collection: 1.731s, learning 0.101s)
             Mean action noise std: 1.52
          Mean value_function loss: 80.2173
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.8840
                       Mean reward: 496.89
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.6520
    Episode_Reward/rotating_object: 100.0012
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.83s
                      Time elapsed: 00:14:28
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 55773 steps/s (collection: 1.669s, learning 0.093s)
             Mean action noise std: 1.52
          Mean value_function loss: 71.7668
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 32.8936
                       Mean reward: 488.22
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.6417
    Episode_Reward/rotating_object: 98.7783
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.76s
                      Time elapsed: 00:14:30
                               ETA: 00:48:36

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 54960 steps/s (collection: 1.695s, learning 0.094s)
             Mean action noise std: 1.53
          Mean value_function loss: 66.7454
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 32.9009
                       Mean reward: 523.79
               Mean episode length: 246.12
    Episode_Reward/reaching_object: 0.6471
    Episode_Reward/rotating_object: 98.0200
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.79s
                      Time elapsed: 00:14:32
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 54931 steps/s (collection: 1.682s, learning 0.108s)
             Mean action noise std: 1.53
          Mean value_function loss: 67.8310
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.9031
                       Mean reward: 516.96
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 0.6440
    Episode_Reward/rotating_object: 98.3521
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.79s
                      Time elapsed: 00:14:33
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 54613 steps/s (collection: 1.697s, learning 0.103s)
             Mean action noise std: 1.53
          Mean value_function loss: 66.7194
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 32.9060
                       Mean reward: 485.06
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.6413
    Episode_Reward/rotating_object: 96.9304
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.80s
                      Time elapsed: 00:14:35
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 53963 steps/s (collection: 1.705s, learning 0.117s)
             Mean action noise std: 1.53
          Mean value_function loss: 67.2215
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 32.9096
                       Mean reward: 487.79
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 101.5475
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.82s
                      Time elapsed: 00:14:37
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 54347 steps/s (collection: 1.711s, learning 0.098s)
             Mean action noise std: 1.53
          Mean value_function loss: 62.1689
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.9191
                       Mean reward: 462.09
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 0.6486
    Episode_Reward/rotating_object: 99.1693
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.81s
                      Time elapsed: 00:14:39
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 54585 steps/s (collection: 1.703s, learning 0.098s)
             Mean action noise std: 1.53
          Mean value_function loss: 63.2431
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 32.9271
                       Mean reward: 452.62
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 95.9154
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.80s
                      Time elapsed: 00:14:41
                               ETA: 00:48:07

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 53955 steps/s (collection: 1.729s, learning 0.093s)
             Mean action noise std: 1.53
          Mean value_function loss: 67.6374
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.9349
                       Mean reward: 466.67
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 98.1095
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.82s
                      Time elapsed: 00:14:43
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 55189 steps/s (collection: 1.687s, learning 0.094s)
             Mean action noise std: 1.53
          Mean value_function loss: 62.0699
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.9407
                       Mean reward: 497.13
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 0.6469
    Episode_Reward/rotating_object: 97.2947
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.78s
                      Time elapsed: 00:14:44
                               ETA: 00:47:57

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 53616 steps/s (collection: 1.737s, learning 0.096s)
             Mean action noise std: 1.53
          Mean value_function loss: 54.7349
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.9461
                       Mean reward: 525.13
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.6498
    Episode_Reward/rotating_object: 104.7610
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.83s
                      Time elapsed: 00:14:46
                               ETA: 00:47:52

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 54471 steps/s (collection: 1.701s, learning 0.104s)
             Mean action noise std: 1.53
          Mean value_function loss: 59.9924
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.9506
                       Mean reward: 531.00
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6497
    Episode_Reward/rotating_object: 101.1881
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.80s
                      Time elapsed: 00:14:48
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 54533 steps/s (collection: 1.713s, learning 0.090s)
             Mean action noise std: 1.53
          Mean value_function loss: 62.3696
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.9563
                       Mean reward: 498.76
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 0.6410
    Episode_Reward/rotating_object: 102.7687
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.80s
                      Time elapsed: 00:14:50
                               ETA: 00:47:43

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 53623 steps/s (collection: 1.743s, learning 0.091s)
             Mean action noise std: 1.53
          Mean value_function loss: 69.3149
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.9613
                       Mean reward: 541.70
               Mean episode length: 245.19
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 102.8267
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.83s
                      Time elapsed: 00:14:52
                               ETA: 00:47:38

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 54138 steps/s (collection: 1.721s, learning 0.095s)
             Mean action noise std: 1.53
          Mean value_function loss: 65.1577
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.9658
                       Mean reward: 520.68
               Mean episode length: 246.36
    Episode_Reward/reaching_object: 0.6457
    Episode_Reward/rotating_object: 101.7359
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.82s
                      Time elapsed: 00:14:53
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 53481 steps/s (collection: 1.728s, learning 0.110s)
             Mean action noise std: 1.53
          Mean value_function loss: 71.9508
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.9705
                       Mean reward: 461.53
               Mean episode length: 237.96
    Episode_Reward/reaching_object: 0.6440
    Episode_Reward/rotating_object: 101.7812
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.84s
                      Time elapsed: 00:14:55
                               ETA: 00:47:29

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 53591 steps/s (collection: 1.734s, learning 0.101s)
             Mean action noise std: 1.53
          Mean value_function loss: 67.1060
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 32.9785
                       Mean reward: 488.54
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 99.4522
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.83s
                      Time elapsed: 00:14:57
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 53275 steps/s (collection: 1.753s, learning 0.093s)
             Mean action noise std: 1.53
          Mean value_function loss: 69.9837
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 32.9842
                       Mean reward: 512.53
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 0.6473
    Episode_Reward/rotating_object: 102.9348
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.85s
                      Time elapsed: 00:14:59
                               ETA: 00:47:20

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 53670 steps/s (collection: 1.726s, learning 0.106s)
             Mean action noise std: 1.53
          Mean value_function loss: 60.5996
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.9877
                       Mean reward: 531.72
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.6640
    Episode_Reward/rotating_object: 99.3906
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.83s
                      Time elapsed: 00:15:01
                               ETA: 00:47:15

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 52682 steps/s (collection: 1.761s, learning 0.105s)
             Mean action noise std: 1.53
          Mean value_function loss: 67.2901
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.9918
                       Mean reward: 494.58
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 0.6575
    Episode_Reward/rotating_object: 102.2107
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.87s
                      Time elapsed: 00:15:03
                               ETA: 00:47:11

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 53436 steps/s (collection: 1.730s, learning 0.110s)
             Mean action noise std: 1.54
          Mean value_function loss: 58.9125
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.9988
                       Mean reward: 552.36
               Mean episode length: 244.88
    Episode_Reward/reaching_object: 0.6653
    Episode_Reward/rotating_object: 108.9254
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.84s
                      Time elapsed: 00:15:04
                               ETA: 00:47:06

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 54234 steps/s (collection: 1.705s, learning 0.108s)
             Mean action noise std: 1.54
          Mean value_function loss: 64.7701
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 32.9983
                       Mean reward: 541.72
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.6640
    Episode_Reward/rotating_object: 105.7791
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.81s
                      Time elapsed: 00:15:06
                               ETA: 00:47:02

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 52523 steps/s (collection: 1.761s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 73.2451
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.9998
                       Mean reward: 536.58
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 0.6675
    Episode_Reward/rotating_object: 104.9494
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.87s
                      Time elapsed: 00:15:08
                               ETA: 00:46:57

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 52695 steps/s (collection: 1.760s, learning 0.106s)
             Mean action noise std: 1.54
          Mean value_function loss: 71.7856
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.0041
                       Mean reward: 546.63
               Mean episode length: 240.28
    Episode_Reward/reaching_object: 0.6593
    Episode_Reward/rotating_object: 106.8982
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.87s
                      Time elapsed: 00:15:10
                               ETA: 00:46:53

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 52051 steps/s (collection: 1.790s, learning 0.099s)
             Mean action noise std: 1.54
          Mean value_function loss: 67.3905
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.0125
                       Mean reward: 491.39
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 0.6587
    Episode_Reward/rotating_object: 100.9718
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.89s
                      Time elapsed: 00:15:12
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 52316 steps/s (collection: 1.761s, learning 0.118s)
             Mean action noise std: 1.54
          Mean value_function loss: 67.1182
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.0187
                       Mean reward: 573.51
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 110.3162
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.88s
                      Time elapsed: 00:15:14
                               ETA: 00:46:44

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 53349 steps/s (collection: 1.748s, learning 0.095s)
             Mean action noise std: 1.54
          Mean value_function loss: 63.2745
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.0232
                       Mean reward: 554.77
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.6566
    Episode_Reward/rotating_object: 108.1617
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.84s
                      Time elapsed: 00:15:16
                               ETA: 00:46:40

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 52799 steps/s (collection: 1.750s, learning 0.112s)
             Mean action noise std: 1.54
          Mean value_function loss: 67.4915
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.0275
                       Mean reward: 554.76
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.6695
    Episode_Reward/rotating_object: 109.1008
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.86s
                      Time elapsed: 00:15:17
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 52539 steps/s (collection: 1.760s, learning 0.112s)
             Mean action noise std: 1.54
          Mean value_function loss: 81.0637
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.0317
                       Mean reward: 557.31
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 107.5682
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.87s
                      Time elapsed: 00:15:19
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 52948 steps/s (collection: 1.762s, learning 0.095s)
             Mean action noise std: 1.54
          Mean value_function loss: 79.9223
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.0379
                       Mean reward: 523.75
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 0.6602
    Episode_Reward/rotating_object: 105.1574
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.86s
                      Time elapsed: 00:15:21
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 52824 steps/s (collection: 1.752s, learning 0.109s)
             Mean action noise std: 1.54
          Mean value_function loss: 72.9065
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.0472
                       Mean reward: 567.57
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 0.6732
    Episode_Reward/rotating_object: 109.8245
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.86s
                      Time elapsed: 00:15:23
                               ETA: 00:46:22

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 48184 steps/s (collection: 1.930s, learning 0.110s)
             Mean action noise std: 1.54
          Mean value_function loss: 75.7953
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.0562
                       Mean reward: 514.29
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.6696
    Episode_Reward/rotating_object: 105.1153
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.04s
                      Time elapsed: 00:15:25
                               ETA: 00:46:19

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 52663 steps/s (collection: 1.765s, learning 0.102s)
             Mean action noise std: 1.54
          Mean value_function loss: 74.5548
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.0647
                       Mean reward: 545.26
               Mean episode length: 244.64
    Episode_Reward/reaching_object: 0.6784
    Episode_Reward/rotating_object: 105.4457
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.87s
                      Time elapsed: 00:15:27
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 51583 steps/s (collection: 1.815s, learning 0.091s)
             Mean action noise std: 1.54
          Mean value_function loss: 80.7156
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.0704
                       Mean reward: 554.48
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 0.6738
    Episode_Reward/rotating_object: 107.5191
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.91s
                      Time elapsed: 00:15:29
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 52372 steps/s (collection: 1.779s, learning 0.098s)
             Mean action noise std: 1.54
          Mean value_function loss: 88.5484
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.0752
                       Mean reward: 563.19
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 0.6789
    Episode_Reward/rotating_object: 108.8501
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.88s
                      Time elapsed: 00:15:31
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 48866 steps/s (collection: 1.905s, learning 0.107s)
             Mean action noise std: 1.54
          Mean value_function loss: 91.8826
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.0792
                       Mean reward: 501.32
               Mean episode length: 227.48
    Episode_Reward/reaching_object: 0.6605
    Episode_Reward/rotating_object: 104.0603
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.01s
                      Time elapsed: 00:15:33
                               ETA: 00:46:02

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 51445 steps/s (collection: 1.815s, learning 0.096s)
             Mean action noise std: 1.54
          Mean value_function loss: 90.2472
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.0847
                       Mean reward: 555.35
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 0.6894
    Episode_Reward/rotating_object: 110.1330
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.91s
                      Time elapsed: 00:15:35
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 51517 steps/s (collection: 1.816s, learning 0.092s)
             Mean action noise std: 1.54
          Mean value_function loss: 87.0215
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.0905
                       Mean reward: 534.83
               Mean episode length: 241.49
    Episode_Reward/reaching_object: 0.6963
    Episode_Reward/rotating_object: 107.0052
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.91s
                      Time elapsed: 00:15:37
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 52649 steps/s (collection: 1.774s, learning 0.093s)
             Mean action noise std: 1.54
          Mean value_function loss: 82.6523
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.0941
                       Mean reward: 529.26
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 0.6950
    Episode_Reward/rotating_object: 109.6863
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.87s
                      Time elapsed: 00:15:38
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 52861 steps/s (collection: 1.740s, learning 0.120s)
             Mean action noise std: 1.55
          Mean value_function loss: 84.8908
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.0987
                       Mean reward: 581.85
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.7009
    Episode_Reward/rotating_object: 113.5197
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.86s
                      Time elapsed: 00:15:40
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 53799 steps/s (collection: 1.736s, learning 0.091s)
             Mean action noise std: 1.55
          Mean value_function loss: 74.0097
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.1062
                       Mean reward: 566.83
               Mean episode length: 245.15
    Episode_Reward/reaching_object: 0.6909
    Episode_Reward/rotating_object: 111.9576
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.83s
                      Time elapsed: 00:15:42
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 52118 steps/s (collection: 1.757s, learning 0.130s)
             Mean action noise std: 1.55
          Mean value_function loss: 85.5732
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 33.1085
                       Mean reward: 560.38
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 0.6871
    Episode_Reward/rotating_object: 110.7376
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.89s
                      Time elapsed: 00:15:44
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 49766 steps/s (collection: 1.869s, learning 0.107s)
             Mean action noise std: 1.55
          Mean value_function loss: 74.0817
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 33.1098
                       Mean reward: 525.58
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 0.6783
    Episode_Reward/rotating_object: 111.3922
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 1.98s
                      Time elapsed: 00:15:46
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 49035 steps/s (collection: 1.894s, learning 0.111s)
             Mean action noise std: 1.55
          Mean value_function loss: 81.6629
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 33.1120
                       Mean reward: 596.18
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 0.6920
    Episode_Reward/rotating_object: 113.2478
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.00s
                      Time elapsed: 00:15:48
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 47377 steps/s (collection: 1.959s, learning 0.116s)
             Mean action noise std: 1.55
          Mean value_function loss: 85.9593
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 33.1150
                       Mean reward: 575.49
               Mean episode length: 238.31
    Episode_Reward/reaching_object: 0.6956
    Episode_Reward/rotating_object: 113.6877
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.07s
                      Time elapsed: 00:15:50
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 49339 steps/s (collection: 1.898s, learning 0.095s)
             Mean action noise std: 1.55
          Mean value_function loss: 80.9341
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.1195
                       Mean reward: 567.08
               Mean episode length: 244.87
    Episode_Reward/reaching_object: 0.6836
    Episode_Reward/rotating_object: 110.1267
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.99s
                      Time elapsed: 00:15:52
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 39547 steps/s (collection: 2.224s, learning 0.262s)
             Mean action noise std: 1.55
          Mean value_function loss: 76.9181
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 33.1236
                       Mean reward: 565.09
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 0.6865
    Episode_Reward/rotating_object: 112.9049
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.49s
                      Time elapsed: 00:15:55
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 23944 steps/s (collection: 3.791s, learning 0.314s)
             Mean action noise std: 1.55
          Mean value_function loss: 79.7757
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.1269
                       Mean reward: 547.34
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 0.6670
    Episode_Reward/rotating_object: 110.3916
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 4.11s
                      Time elapsed: 00:15:59
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 23803 steps/s (collection: 3.878s, learning 0.252s)
             Mean action noise std: 1.55
          Mean value_function loss: 82.0467
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.1331
                       Mean reward: 575.00
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 0.6754
    Episode_Reward/rotating_object: 111.1668
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 4.13s
                      Time elapsed: 00:16:03
                               ETA: 00:45:25

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 25917 steps/s (collection: 3.519s, learning 0.274s)
             Mean action noise std: 1.55
          Mean value_function loss: 85.7503
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 33.1397
                       Mean reward: 555.50
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 0.6851
    Episode_Reward/rotating_object: 114.1445
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 3.79s
                      Time elapsed: 00:16:07
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 23447 steps/s (collection: 3.930s, learning 0.262s)
             Mean action noise std: 1.55
          Mean value_function loss: 75.5414
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.1506
                       Mean reward: 608.46
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 0.6804
    Episode_Reward/rotating_object: 115.8115
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 4.19s
                      Time elapsed: 00:16:11
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 28531 steps/s (collection: 3.205s, learning 0.241s)
             Mean action noise std: 1.55
          Mean value_function loss: 68.5188
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 33.1607
                       Mean reward: 592.76
               Mean episode length: 241.73
    Episode_Reward/reaching_object: 0.6831
    Episode_Reward/rotating_object: 115.2853
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 3.45s
                      Time elapsed: 00:16:14
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 23861 steps/s (collection: 3.773s, learning 0.346s)
             Mean action noise std: 1.55
          Mean value_function loss: 79.0842
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 33.1665
                       Mean reward: 608.92
               Mean episode length: 246.57
    Episode_Reward/reaching_object: 0.6855
    Episode_Reward/rotating_object: 115.9986
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 4.12s
                      Time elapsed: 00:16:18
                               ETA: 00:45:31

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 21381 steps/s (collection: 4.279s, learning 0.318s)
             Mean action noise std: 1.55
          Mean value_function loss: 64.0954
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.1703
                       Mean reward: 571.71
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.6921
    Episode_Reward/rotating_object: 118.6554
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 4.60s
                      Time elapsed: 00:16:23
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 23386 steps/s (collection: 3.847s, learning 0.357s)
             Mean action noise std: 1.55
          Mean value_function loss: 65.5349
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.1738
                       Mean reward: 588.25
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.6891
    Episode_Reward/rotating_object: 117.0328
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 4.20s
                      Time elapsed: 00:16:27
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 18925 steps/s (collection: 4.792s, learning 0.402s)
             Mean action noise std: 1.55
          Mean value_function loss: 68.2621
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.1797
                       Mean reward: 559.55
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 0.6826
    Episode_Reward/rotating_object: 116.6277
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 5.19s
                      Time elapsed: 00:16:32
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 22759 steps/s (collection: 4.011s, learning 0.308s)
             Mean action noise std: 1.55
          Mean value_function loss: 67.9088
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.1853
                       Mean reward: 626.90
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.6889
    Episode_Reward/rotating_object: 119.0363
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 4.32s
                      Time elapsed: 00:16:37
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 20715 steps/s (collection: 4.393s, learning 0.353s)
             Mean action noise std: 1.55
          Mean value_function loss: 64.8530
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.1935
                       Mean reward: 614.14
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 0.6954
    Episode_Reward/rotating_object: 120.4980
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 4.75s
                      Time elapsed: 00:16:41
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 23483 steps/s (collection: 3.848s, learning 0.338s)
             Mean action noise std: 1.56
          Mean value_function loss: 60.0347
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 33.2006
                       Mean reward: 624.53
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 0.6890
    Episode_Reward/rotating_object: 117.9738
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 4.19s
                      Time elapsed: 00:16:46
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 24873 steps/s (collection: 3.678s, learning 0.274s)
             Mean action noise std: 1.56
          Mean value_function loss: 67.8535
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 33.2074
                       Mean reward: 593.60
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 0.6919
    Episode_Reward/rotating_object: 120.8151
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 3.95s
                      Time elapsed: 00:16:50
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 26030 steps/s (collection: 3.504s, learning 0.273s)
             Mean action noise std: 1.56
          Mean value_function loss: 61.3593
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.2140
                       Mean reward: 636.97
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.6840
    Episode_Reward/rotating_object: 121.5693
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 3.78s
                      Time elapsed: 00:16:53
                               ETA: 00:45:52

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 26154 steps/s (collection: 3.512s, learning 0.246s)
             Mean action noise std: 1.56
          Mean value_function loss: 58.0200
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.2196
                       Mean reward: 601.07
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.6979
    Episode_Reward/rotating_object: 121.1324
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 3.76s
                      Time elapsed: 00:16:57
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 25217 steps/s (collection: 3.643s, learning 0.255s)
             Mean action noise std: 1.56
          Mean value_function loss: 67.3525
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 33.2239
                       Mean reward: 612.40
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 0.6869
    Episode_Reward/rotating_object: 119.3537
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 3.90s
                      Time elapsed: 00:17:01
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 26462 steps/s (collection: 3.461s, learning 0.253s)
             Mean action noise std: 1.56
          Mean value_function loss: 64.4754
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.2284
                       Mean reward: 584.52
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 0.6815
    Episode_Reward/rotating_object: 117.3573
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 3.71s
                      Time elapsed: 00:17:05
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 27952 steps/s (collection: 3.274s, learning 0.243s)
             Mean action noise std: 1.56
          Mean value_function loss: 60.6494
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.2394
                       Mean reward: 591.03
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 0.6847
    Episode_Reward/rotating_object: 120.2224
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 3.52s
                      Time elapsed: 00:17:08
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 28051 steps/s (collection: 3.274s, learning 0.231s)
             Mean action noise std: 1.56
          Mean value_function loss: 64.8373
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.2483
                       Mean reward: 633.70
               Mean episode length: 246.57
    Episode_Reward/reaching_object: 0.6888
    Episode_Reward/rotating_object: 122.0721
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 3.50s
                      Time elapsed: 00:17:12
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 27861 steps/s (collection: 3.324s, learning 0.204s)
             Mean action noise std: 1.56
          Mean value_function loss: 59.9493
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 33.2554
                       Mean reward: 654.04
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6883
    Episode_Reward/rotating_object: 123.5776
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 3.53s
                      Time elapsed: 00:17:15
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 25661 steps/s (collection: 3.591s, learning 0.240s)
             Mean action noise std: 1.56
          Mean value_function loss: 67.6480
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.2617
                       Mean reward: 640.02
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 0.6807
    Episode_Reward/rotating_object: 122.9710
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 3.83s
                      Time elapsed: 00:17:19
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 27913 steps/s (collection: 3.291s, learning 0.231s)
             Mean action noise std: 1.56
          Mean value_function loss: 59.0848
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 33.2668
                       Mean reward: 616.62
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 0.6817
    Episode_Reward/rotating_object: 122.2074
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 3.52s
                      Time elapsed: 00:17:23
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 28400 steps/s (collection: 3.240s, learning 0.221s)
             Mean action noise std: 1.56
          Mean value_function loss: 65.5452
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.2724
                       Mean reward: 622.04
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.6979
    Episode_Reward/rotating_object: 126.2982
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 3.46s
                      Time elapsed: 00:17:26
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 26705 steps/s (collection: 3.421s, learning 0.260s)
             Mean action noise std: 1.56
          Mean value_function loss: 64.3612
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.2751
                       Mean reward: 593.22
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 0.6837
    Episode_Reward/rotating_object: 124.0843
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 3.68s
                      Time elapsed: 00:17:30
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 26814 steps/s (collection: 3.448s, learning 0.218s)
             Mean action noise std: 1.56
          Mean value_function loss: 62.5620
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.2859
                       Mean reward: 606.10
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 0.6819
    Episode_Reward/rotating_object: 123.7381
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 3.67s
                      Time elapsed: 00:17:33
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 27968 steps/s (collection: 3.284s, learning 0.231s)
             Mean action noise std: 1.56
          Mean value_function loss: 54.2053
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.2936
                       Mean reward: 619.36
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 0.6901
    Episode_Reward/rotating_object: 123.6517
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 3.51s
                      Time elapsed: 00:17:37
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 27305 steps/s (collection: 3.372s, learning 0.228s)
             Mean action noise std: 1.56
          Mean value_function loss: 63.4871
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.2960
                       Mean reward: 614.52
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 0.6833
    Episode_Reward/rotating_object: 123.4115
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 3.60s
                      Time elapsed: 00:17:40
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 28066 steps/s (collection: 3.266s, learning 0.237s)
             Mean action noise std: 1.57
          Mean value_function loss: 64.9791
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 33.3000
                       Mean reward: 630.19
               Mean episode length: 242.29
    Episode_Reward/reaching_object: 0.6891
    Episode_Reward/rotating_object: 126.3427
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 3.50s
                      Time elapsed: 00:17:44
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 27320 steps/s (collection: 3.360s, learning 0.238s)
             Mean action noise std: 1.57
          Mean value_function loss: 63.3932
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 33.3030
                       Mean reward: 622.59
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 0.6826
    Episode_Reward/rotating_object: 124.3844
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 3.60s
                      Time elapsed: 00:17:48
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 27475 steps/s (collection: 3.365s, learning 0.213s)
             Mean action noise std: 1.57
          Mean value_function loss: 70.6017
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.3085
                       Mean reward: 638.83
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 0.6814
    Episode_Reward/rotating_object: 126.1072
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 3.58s
                      Time elapsed: 00:17:51
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 27993 steps/s (collection: 3.283s, learning 0.229s)
             Mean action noise std: 1.57
          Mean value_function loss: 71.5525
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.3132
                       Mean reward: 638.94
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 0.6846
    Episode_Reward/rotating_object: 127.9224
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 3.51s
                      Time elapsed: 00:17:55
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 28155 steps/s (collection: 3.252s, learning 0.239s)
             Mean action noise std: 1.57
          Mean value_function loss: 67.3353
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.3182
                       Mean reward: 651.45
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.6839
    Episode_Reward/rotating_object: 126.0649
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 3.49s
                      Time elapsed: 00:17:58
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 27000 steps/s (collection: 3.418s, learning 0.223s)
             Mean action noise std: 1.57
          Mean value_function loss: 72.8469
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.3267
                       Mean reward: 640.99
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 0.6799
    Episode_Reward/rotating_object: 124.8135
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 3.64s
                      Time elapsed: 00:18:02
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 28374 steps/s (collection: 3.267s, learning 0.197s)
             Mean action noise std: 1.57
          Mean value_function loss: 59.5602
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.3359
                       Mean reward: 634.99
               Mean episode length: 245.39
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 124.8452
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 3.46s
                      Time elapsed: 00:18:05
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 28121 steps/s (collection: 3.281s, learning 0.215s)
             Mean action noise std: 1.57
          Mean value_function loss: 65.5658
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.3431
                       Mean reward: 634.92
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 0.6814
    Episode_Reward/rotating_object: 126.2312
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 3.50s
                      Time elapsed: 00:18:09
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 25819 steps/s (collection: 3.572s, learning 0.235s)
             Mean action noise std: 1.57
          Mean value_function loss: 65.5897
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.3518
                       Mean reward: 626.08
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.6808
    Episode_Reward/rotating_object: 127.7019
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 3.81s
                      Time elapsed: 00:18:13
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 27780 steps/s (collection: 3.286s, learning 0.253s)
             Mean action noise std: 1.57
          Mean value_function loss: 58.2275
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.3597
                       Mean reward: 652.52
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 0.6743
    Episode_Reward/rotating_object: 127.7619
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 3.54s
                      Time elapsed: 00:18:16
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 25203 steps/s (collection: 3.503s, learning 0.397s)
             Mean action noise std: 1.57
          Mean value_function loss: 63.7626
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.3639
                       Mean reward: 665.82
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 0.6693
    Episode_Reward/rotating_object: 130.3020
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 3.90s
                      Time elapsed: 00:18:20
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 40043 steps/s (collection: 2.339s, learning 0.116s)
             Mean action noise std: 1.57
          Mean value_function loss: 62.9861
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.3654
                       Mean reward: 654.85
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.6675
    Episode_Reward/rotating_object: 126.9839
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.45s
                      Time elapsed: 00:18:22
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 53045 steps/s (collection: 1.750s, learning 0.103s)
             Mean action noise std: 1.57
          Mean value_function loss: 66.3208
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.3669
                       Mean reward: 629.76
               Mean episode length: 243.02
    Episode_Reward/reaching_object: 0.6620
    Episode_Reward/rotating_object: 121.6661
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.85s
                      Time elapsed: 00:18:24
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 53035 steps/s (collection: 1.764s, learning 0.090s)
             Mean action noise std: 1.57
          Mean value_function loss: 67.1716
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 33.3694
                       Mean reward: 621.69
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 0.6692
    Episode_Reward/rotating_object: 127.4092
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.85s
                      Time elapsed: 00:18:26
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 52342 steps/s (collection: 1.775s, learning 0.103s)
             Mean action noise std: 1.57
          Mean value_function loss: 69.2726
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.3733
                       Mean reward: 635.75
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 0.6731
    Episode_Reward/rotating_object: 126.5336
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.88s
                      Time elapsed: 00:18:28
                               ETA: 00:45:43

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 53337 steps/s (collection: 1.747s, learning 0.096s)
             Mean action noise std: 1.57
          Mean value_function loss: 66.8095
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.3822
                       Mean reward: 648.43
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 0.6754
    Episode_Reward/rotating_object: 129.4098
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.84s
                      Time elapsed: 00:18:30
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 50580 steps/s (collection: 1.823s, learning 0.121s)
             Mean action noise std: 1.58
          Mean value_function loss: 68.0228
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.3890
                       Mean reward: 616.32
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 0.6682
    Episode_Reward/rotating_object: 125.6901
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.94s
                      Time elapsed: 00:18:32
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 53237 steps/s (collection: 1.752s, learning 0.094s)
             Mean action noise std: 1.58
          Mean value_function loss: 57.6918
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.3981
                       Mean reward: 654.99
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 0.6827
    Episode_Reward/rotating_object: 129.5851
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.85s
                      Time elapsed: 00:18:34
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 51453 steps/s (collection: 1.801s, learning 0.110s)
             Mean action noise std: 1.58
          Mean value_function loss: 65.3807
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.4049
                       Mean reward: 666.93
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.6809
    Episode_Reward/rotating_object: 129.0858
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.91s
                      Time elapsed: 00:18:36
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 51457 steps/s (collection: 1.809s, learning 0.102s)
             Mean action noise std: 1.58
          Mean value_function loss: 69.0194
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.4116
                       Mean reward: 647.08
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 0.6819
    Episode_Reward/rotating_object: 131.1566
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.91s
                      Time elapsed: 00:18:38
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 52108 steps/s (collection: 1.775s, learning 0.112s)
             Mean action noise std: 1.58
          Mean value_function loss: 64.7124
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.4175
                       Mean reward: 624.35
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 0.6870
    Episode_Reward/rotating_object: 130.2357
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.89s
                      Time elapsed: 00:18:39
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 50684 steps/s (collection: 1.843s, learning 0.097s)
             Mean action noise std: 1.58
          Mean value_function loss: 55.0212
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.4246
                       Mean reward: 676.75
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.6841
    Episode_Reward/rotating_object: 130.0585
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.94s
                      Time elapsed: 00:18:41
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 51768 steps/s (collection: 1.787s, learning 0.112s)
             Mean action noise std: 1.58
          Mean value_function loss: 58.3230
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.4300
                       Mean reward: 651.75
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.6788
    Episode_Reward/rotating_object: 130.4365
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.90s
                      Time elapsed: 00:18:43
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 52775 steps/s (collection: 1.760s, learning 0.103s)
             Mean action noise std: 1.58
          Mean value_function loss: 60.0763
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.4395
                       Mean reward: 630.70
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.6809
    Episode_Reward/rotating_object: 129.2049
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.86s
                      Time elapsed: 00:18:45
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 52497 steps/s (collection: 1.775s, learning 0.098s)
             Mean action noise std: 1.58
          Mean value_function loss: 59.9828
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.4476
                       Mean reward: 677.24
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 0.6814
    Episode_Reward/rotating_object: 132.4984
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.87s
                      Time elapsed: 00:18:47
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 51508 steps/s (collection: 1.801s, learning 0.107s)
             Mean action noise std: 1.58
          Mean value_function loss: 56.2356
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.4562
                       Mean reward: 649.48
               Mean episode length: 242.34
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 133.2487
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.91s
                      Time elapsed: 00:18:49
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 53075 steps/s (collection: 1.751s, learning 0.101s)
             Mean action noise std: 1.58
          Mean value_function loss: 65.4364
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.4646
                       Mean reward: 693.40
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 0.6752
    Episode_Reward/rotating_object: 129.8700
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.85s
                      Time elapsed: 00:18:51
                               ETA: 00:44:53

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 53210 steps/s (collection: 1.755s, learning 0.093s)
             Mean action noise std: 1.58
          Mean value_function loss: 66.2704
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.4689
                       Mean reward: 628.71
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 0.6791
    Episode_Reward/rotating_object: 130.9690
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.85s
                      Time elapsed: 00:18:53
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 52897 steps/s (collection: 1.758s, learning 0.101s)
             Mean action noise std: 1.58
          Mean value_function loss: 69.6840
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.4772
                       Mean reward: 661.03
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 129.2692
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.86s
                      Time elapsed: 00:18:54
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 52626 steps/s (collection: 1.777s, learning 0.091s)
             Mean action noise std: 1.59
          Mean value_function loss: 57.1233
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.4891
                       Mean reward: 669.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6796
    Episode_Reward/rotating_object: 131.5579
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.87s
                      Time elapsed: 00:18:56
                               ETA: 00:44:40

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 53237 steps/s (collection: 1.749s, learning 0.098s)
             Mean action noise std: 1.59
          Mean value_function loss: 65.1802
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 33.4946
                       Mean reward: 660.72
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 0.6734
    Episode_Reward/rotating_object: 131.9908
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.85s
                      Time elapsed: 00:18:58
                               ETA: 00:44:36

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 52882 steps/s (collection: 1.756s, learning 0.103s)
             Mean action noise std: 1.59
          Mean value_function loss: 59.9577
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.4969
                       Mean reward: 664.63
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.6738
    Episode_Reward/rotating_object: 130.4059
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.86s
                      Time elapsed: 00:19:00
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 50776 steps/s (collection: 1.816s, learning 0.120s)
             Mean action noise std: 1.59
          Mean value_function loss: 53.3121
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.5016
                       Mean reward: 656.91
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.6790
    Episode_Reward/rotating_object: 131.8807
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.94s
                      Time elapsed: 00:19:02
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 51343 steps/s (collection: 1.813s, learning 0.102s)
             Mean action noise std: 1.59
          Mean value_function loss: 61.4485
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.5074
                       Mean reward: 642.46
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 0.6762
    Episode_Reward/rotating_object: 131.9756
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.91s
                      Time elapsed: 00:19:04
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 52118 steps/s (collection: 1.788s, learning 0.099s)
             Mean action noise std: 1.59
          Mean value_function loss: 55.9945
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.5097
                       Mean reward: 662.16
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 0.6829
    Episode_Reward/rotating_object: 134.9595
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.89s
                      Time elapsed: 00:19:06
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 52806 steps/s (collection: 1.764s, learning 0.097s)
             Mean action noise std: 1.59
          Mean value_function loss: 57.1232
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.5171
                       Mean reward: 641.94
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 0.6751
    Episode_Reward/rotating_object: 130.4466
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.86s
                      Time elapsed: 00:19:08
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 51956 steps/s (collection: 1.787s, learning 0.105s)
             Mean action noise std: 1.59
          Mean value_function loss: 53.5852
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.5269
                       Mean reward: 674.34
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.6876
    Episode_Reward/rotating_object: 135.2905
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.89s
                      Time elapsed: 00:19:10
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 51544 steps/s (collection: 1.802s, learning 0.106s)
             Mean action noise std: 1.59
          Mean value_function loss: 55.9678
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.5314
                       Mean reward: 688.94
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.6785
    Episode_Reward/rotating_object: 133.7045
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.91s
                      Time elapsed: 00:19:11
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 51507 steps/s (collection: 1.796s, learning 0.112s)
             Mean action noise std: 1.59
          Mean value_function loss: 59.8988
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.5367
                       Mean reward: 691.46
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.6821
    Episode_Reward/rotating_object: 135.2090
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.91s
                      Time elapsed: 00:19:13
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 52326 steps/s (collection: 1.775s, learning 0.104s)
             Mean action noise std: 1.59
          Mean value_function loss: 52.5014
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.5444
                       Mean reward: 633.70
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 0.6747
    Episode_Reward/rotating_object: 130.8193
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.88s
                      Time elapsed: 00:19:15
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 52543 steps/s (collection: 1.765s, learning 0.106s)
             Mean action noise std: 1.59
          Mean value_function loss: 52.0131
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 33.5523
                       Mean reward: 703.02
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6879
    Episode_Reward/rotating_object: 137.3671
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.87s
                      Time elapsed: 00:19:17
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 53304 steps/s (collection: 1.753s, learning 0.092s)
             Mean action noise std: 1.59
          Mean value_function loss: 53.0910
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 33.5599
                       Mean reward: 667.62
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.6898
    Episode_Reward/rotating_object: 136.0656
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.84s
                      Time elapsed: 00:19:19
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 53160 steps/s (collection: 1.755s, learning 0.094s)
             Mean action noise std: 1.59
          Mean value_function loss: 55.0599
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.5629
                       Mean reward: 687.16
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 0.6849
    Episode_Reward/rotating_object: 135.7899
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.85s
                      Time elapsed: 00:19:21
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 53023 steps/s (collection: 1.759s, learning 0.095s)
             Mean action noise std: 1.59
          Mean value_function loss: 46.2888
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.5691
                       Mean reward: 676.07
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.6980
    Episode_Reward/rotating_object: 138.7822
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.85s
                      Time elapsed: 00:19:23
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 52790 steps/s (collection: 1.770s, learning 0.093s)
             Mean action noise std: 1.59
          Mean value_function loss: 55.4361
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.5773
                       Mean reward: 694.39
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.6868
    Episode_Reward/rotating_object: 136.5527
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.86s
                      Time elapsed: 00:19:24
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 52373 steps/s (collection: 1.769s, learning 0.108s)
             Mean action noise std: 1.60
          Mean value_function loss: 55.6486
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.5821
                       Mean reward: 662.91
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.6840
    Episode_Reward/rotating_object: 133.3565
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.88s
                      Time elapsed: 00:19:26
                               ETA: 00:43:35

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 49989 steps/s (collection: 1.863s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 51.8577
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.5873
                       Mean reward: 698.96
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.6915
    Episode_Reward/rotating_object: 136.5843
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.97s
                      Time elapsed: 00:19:28
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 51705 steps/s (collection: 1.800s, learning 0.102s)
             Mean action noise std: 1.60
          Mean value_function loss: 57.4455
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.5956
                       Mean reward: 644.53
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.6827
    Episode_Reward/rotating_object: 135.2236
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.90s
                      Time elapsed: 00:19:30
                               ETA: 00:43:28

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 49882 steps/s (collection: 1.866s, learning 0.105s)
             Mean action noise std: 1.60
          Mean value_function loss: 53.9786
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.6036
                       Mean reward: 699.10
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 136.9484
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.97s
                      Time elapsed: 00:19:32
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 49672 steps/s (collection: 1.872s, learning 0.107s)
             Mean action noise std: 1.60
          Mean value_function loss: 52.7603
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 33.6074
                       Mean reward: 694.93
               Mean episode length: 248.80
    Episode_Reward/reaching_object: 0.6935
    Episode_Reward/rotating_object: 135.2167
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.98s
                      Time elapsed: 00:19:34
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 48896 steps/s (collection: 1.882s, learning 0.128s)
             Mean action noise std: 1.60
          Mean value_function loss: 52.6477
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.6098
                       Mean reward: 686.01
               Mean episode length: 246.64
    Episode_Reward/reaching_object: 0.6919
    Episode_Reward/rotating_object: 134.7371
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.01s
                      Time elapsed: 00:19:36
                               ETA: 00:43:17

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 50870 steps/s (collection: 1.828s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 53.2460
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.6128
                       Mean reward: 686.88
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6975
    Episode_Reward/rotating_object: 139.3940
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.93s
                      Time elapsed: 00:19:38
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 52202 steps/s (collection: 1.787s, learning 0.097s)
             Mean action noise std: 1.60
          Mean value_function loss: 52.0224
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.6159
                       Mean reward: 714.43
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.6985
    Episode_Reward/rotating_object: 140.7986
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.88s
                      Time elapsed: 00:19:40
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 50018 steps/s (collection: 1.871s, learning 0.094s)
             Mean action noise std: 1.60
          Mean value_function loss: 52.2093
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.6265
                       Mean reward: 698.43
               Mean episode length: 248.54
    Episode_Reward/reaching_object: 0.7018
    Episode_Reward/rotating_object: 137.0899
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.97s
                      Time elapsed: 00:19:42
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 52524 steps/s (collection: 1.766s, learning 0.105s)
             Mean action noise std: 1.60
          Mean value_function loss: 59.3251
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 33.6382
                       Mean reward: 670.71
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 0.6866
    Episode_Reward/rotating_object: 136.3339
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.87s
                      Time elapsed: 00:19:44
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 51123 steps/s (collection: 1.806s, learning 0.117s)
             Mean action noise std: 1.60
          Mean value_function loss: 51.2909
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.6443
                       Mean reward: 710.61
               Mean episode length: 247.34
    Episode_Reward/reaching_object: 0.6939
    Episode_Reward/rotating_object: 137.9377
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.92s
                      Time elapsed: 00:19:46
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 45256 steps/s (collection: 2.056s, learning 0.116s)
             Mean action noise std: 1.60
          Mean value_function loss: 53.9395
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.6530
                       Mean reward: 691.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 134.5123
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.17s
                      Time elapsed: 00:19:48
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 50296 steps/s (collection: 1.859s, learning 0.096s)
             Mean action noise std: 1.61
          Mean value_function loss: 54.2379
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.6696
                       Mean reward: 699.75
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.6969
    Episode_Reward/rotating_object: 139.7883
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.95s
                      Time elapsed: 00:19:50
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 52364 steps/s (collection: 1.781s, learning 0.096s)
             Mean action noise std: 1.61
          Mean value_function loss: 49.0674
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.6827
                       Mean reward: 708.03
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.6851
    Episode_Reward/rotating_object: 136.7465
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.88s
                      Time elapsed: 00:19:52
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 52617 steps/s (collection: 1.761s, learning 0.107s)
             Mean action noise std: 1.61
          Mean value_function loss: 42.5794
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 33.6837
                       Mean reward: 668.24
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 0.6875
    Episode_Reward/rotating_object: 137.5553
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.87s
                      Time elapsed: 00:19:54
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 52545 steps/s (collection: 1.778s, learning 0.093s)
             Mean action noise std: 1.61
          Mean value_function loss: 43.0617
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.6867
                       Mean reward: 700.52
               Mean episode length: 249.06
    Episode_Reward/reaching_object: 0.6929
    Episode_Reward/rotating_object: 140.8354
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.87s
                      Time elapsed: 00:19:56
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 52217 steps/s (collection: 1.756s, learning 0.127s)
             Mean action noise std: 1.61
          Mean value_function loss: 47.7693
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.6952
                       Mean reward: 695.83
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 0.6920
    Episode_Reward/rotating_object: 140.4774
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.88s
                      Time elapsed: 00:19:57
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 53795 steps/s (collection: 1.727s, learning 0.100s)
             Mean action noise std: 1.61
          Mean value_function loss: 47.1906
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 33.7085
                       Mean reward: 668.57
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.6923
    Episode_Reward/rotating_object: 138.6084
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.83s
                      Time elapsed: 00:19:59
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 53624 steps/s (collection: 1.746s, learning 0.088s)
             Mean action noise std: 1.61
          Mean value_function loss: 45.5853
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 33.7174
                       Mean reward: 683.21
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 0.6889
    Episode_Reward/rotating_object: 137.8378
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.83s
                      Time elapsed: 00:20:01
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 49580 steps/s (collection: 1.884s, learning 0.099s)
             Mean action noise std: 1.61
          Mean value_function loss: 49.3518
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 33.7294
                       Mean reward: 684.21
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 0.6862
    Episode_Reward/rotating_object: 137.2622
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.98s
                      Time elapsed: 00:20:03
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 52455 steps/s (collection: 1.780s, learning 0.094s)
             Mean action noise std: 1.61
          Mean value_function loss: 44.8459
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.7355
                       Mean reward: 682.79
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.6936
    Episode_Reward/rotating_object: 141.4757
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.87s
                      Time elapsed: 00:20:05
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 52915 steps/s (collection: 1.763s, learning 0.095s)
             Mean action noise std: 1.61
          Mean value_function loss: 47.9599
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.7467
                       Mean reward: 689.80
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.6790
    Episode_Reward/rotating_object: 136.1013
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.86s
                      Time elapsed: 00:20:07
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 50330 steps/s (collection: 1.852s, learning 0.102s)
             Mean action noise std: 1.62
          Mean value_function loss: 44.4729
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 33.7648
                       Mean reward: 711.13
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.6858
    Episode_Reward/rotating_object: 138.6903
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.95s
                      Time elapsed: 00:20:09
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 51290 steps/s (collection: 1.824s, learning 0.093s)
             Mean action noise std: 1.62
          Mean value_function loss: 49.1457
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.7707
                       Mean reward: 678.83
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 0.6843
    Episode_Reward/rotating_object: 139.2047
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.92s
                      Time elapsed: 00:20:11
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 49535 steps/s (collection: 1.882s, learning 0.102s)
             Mean action noise std: 1.62
          Mean value_function loss: 44.4876
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.7833
                       Mean reward: 723.70
               Mean episode length: 249.71
    Episode_Reward/reaching_object: 0.6925
    Episode_Reward/rotating_object: 142.2408
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.98s
                      Time elapsed: 00:20:13
                               ETA: 00:42:05

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 21221 steps/s (collection: 4.320s, learning 0.312s)
             Mean action noise std: 1.62
          Mean value_function loss: 47.0978
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.7936
                       Mean reward: 691.43
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 0.6878
    Episode_Reward/rotating_object: 139.1861
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 4.63s
                      Time elapsed: 00:20:17
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 23702 steps/s (collection: 3.874s, learning 0.274s)
             Mean action noise std: 1.62
          Mean value_function loss: 43.9337
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.8026
                       Mean reward: 712.88
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6901
    Episode_Reward/rotating_object: 139.5982
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 4.15s
                      Time elapsed: 00:20:21
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 21938 steps/s (collection: 4.175s, learning 0.306s)
             Mean action noise std: 1.62
          Mean value_function loss: 42.9860
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.8109
                       Mean reward: 715.81
               Mean episode length: 248.31
    Episode_Reward/reaching_object: 0.6804
    Episode_Reward/rotating_object: 138.2240
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 4.48s
                      Time elapsed: 00:20:26
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 23584 steps/s (collection: 3.924s, learning 0.244s)
             Mean action noise std: 1.62
          Mean value_function loss: 50.0310
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.8158
                       Mean reward: 711.32
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 138.0140
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 4.17s
                      Time elapsed: 00:20:30
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 21529 steps/s (collection: 4.298s, learning 0.268s)
             Mean action noise std: 1.62
          Mean value_function loss: 51.2828
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.8217
                       Mean reward: 720.72
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 0.6983
    Episode_Reward/rotating_object: 142.0830
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 4.57s
                      Time elapsed: 00:20:35
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 25643 steps/s (collection: 3.631s, learning 0.202s)
             Mean action noise std: 1.62
          Mean value_function loss: 49.1686
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 33.8317
                       Mean reward: 697.78
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.6904
    Episode_Reward/rotating_object: 141.3238
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 3.83s
                      Time elapsed: 00:20:38
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 29887 steps/s (collection: 3.049s, learning 0.240s)
             Mean action noise std: 1.62
          Mean value_function loss: 46.0297
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.8391
                       Mean reward: 672.49
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.6869
    Episode_Reward/rotating_object: 139.1044
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 3.29s
                      Time elapsed: 00:20:42
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 27124 steps/s (collection: 3.387s, learning 0.237s)
             Mean action noise std: 1.62
          Mean value_function loss: 42.1180
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.8409
                       Mean reward: 714.72
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.6901
    Episode_Reward/rotating_object: 138.8610
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 3.62s
                      Time elapsed: 00:20:45
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 28398 steps/s (collection: 3.176s, learning 0.286s)
             Mean action noise std: 1.62
          Mean value_function loss: 42.2495
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.8426
                       Mean reward: 705.42
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.6986
    Episode_Reward/rotating_object: 140.5631
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 3.46s
                      Time elapsed: 00:20:49
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 27154 steps/s (collection: 3.207s, learning 0.413s)
             Mean action noise std: 1.63
          Mean value_function loss: 42.5940
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.8522
                       Mean reward: 713.13
               Mean episode length: 249.07
    Episode_Reward/reaching_object: 0.7023
    Episode_Reward/rotating_object: 142.9794
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 3.62s
                      Time elapsed: 00:20:52
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 30419 steps/s (collection: 3.123s, learning 0.109s)
             Mean action noise std: 1.63
          Mean value_function loss: 47.8627
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 33.8681
                       Mean reward: 709.40
               Mean episode length: 245.22
    Episode_Reward/reaching_object: 0.6934
    Episode_Reward/rotating_object: 142.2627
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 3.23s
                      Time elapsed: 00:20:56
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 50877 steps/s (collection: 1.819s, learning 0.114s)
             Mean action noise std: 1.63
          Mean value_function loss: 42.9008
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.8833
                       Mean reward: 706.54
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.6995
    Episode_Reward/rotating_object: 143.4883
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.93s
                      Time elapsed: 00:20:58
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 51474 steps/s (collection: 1.817s, learning 0.093s)
             Mean action noise std: 1.63
          Mean value_function loss: 39.9622
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.8944
                       Mean reward: 729.10
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.6990
    Episode_Reward/rotating_object: 142.9494
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.91s
                      Time elapsed: 00:21:00
                               ETA: 00:42:02

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 53968 steps/s (collection: 1.719s, learning 0.103s)
             Mean action noise std: 1.63
          Mean value_function loss: 36.4468
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.8958
                       Mean reward: 719.22
               Mean episode length: 247.01
    Episode_Reward/reaching_object: 0.6903
    Episode_Reward/rotating_object: 140.2566
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.82s
                      Time elapsed: 00:21:01
                               ETA: 00:41:58

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 53079 steps/s (collection: 1.747s, learning 0.105s)
             Mean action noise std: 1.63
          Mean value_function loss: 36.7778
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.8992
                       Mean reward: 727.06
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6996
    Episode_Reward/rotating_object: 141.2145
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.85s
                      Time elapsed: 00:21:03
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 53469 steps/s (collection: 1.738s, learning 0.100s)
             Mean action noise std: 1.63
          Mean value_function loss: 50.3873
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.9059
                       Mean reward: 719.78
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 0.6853
    Episode_Reward/rotating_object: 141.1418
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.84s
                      Time elapsed: 00:21:05
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 51521 steps/s (collection: 1.801s, learning 0.107s)
             Mean action noise std: 1.63
          Mean value_function loss: 37.1089
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 33.9180
                       Mean reward: 720.79
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.6992
    Episode_Reward/rotating_object: 144.4202
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.91s
                      Time elapsed: 00:21:07
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 52807 steps/s (collection: 1.756s, learning 0.106s)
             Mean action noise std: 1.63
          Mean value_function loss: 34.6691
               Mean surrogate loss: 0.0045
                 Mean entropy loss: 33.9217
                       Mean reward: 690.43
               Mean episode length: 247.01
    Episode_Reward/reaching_object: 0.6906
    Episode_Reward/rotating_object: 141.2402
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.86s
                      Time elapsed: 00:21:09
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 52526 steps/s (collection: 1.772s, learning 0.100s)
             Mean action noise std: 1.63
          Mean value_function loss: 45.6318
               Mean surrogate loss: 0.0032
                 Mean entropy loss: 33.9239
                       Mean reward: 712.59
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.6984
    Episode_Reward/rotating_object: 143.0795
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.87s
                      Time elapsed: 00:21:11
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 51645 steps/s (collection: 1.803s, learning 0.101s)
             Mean action noise std: 1.63
          Mean value_function loss: 42.4106
               Mean surrogate loss: 0.0049
                 Mean entropy loss: 33.9274
                       Mean reward: 699.21
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 141.1186
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.90s
                      Time elapsed: 00:21:13
                               ETA: 00:41:35

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 51670 steps/s (collection: 1.802s, learning 0.100s)
             Mean action noise std: 1.63
          Mean value_function loss: 39.4677
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.9328
                       Mean reward: 714.22
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 0.6922
    Episode_Reward/rotating_object: 143.1897
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.90s
                      Time elapsed: 00:21:14
                               ETA: 00:41:32

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 51919 steps/s (collection: 1.785s, learning 0.108s)
             Mean action noise std: 1.64
          Mean value_function loss: 42.2934
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.9381
                       Mean reward: 742.91
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6979
    Episode_Reward/rotating_object: 145.6875
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.89s
                      Time elapsed: 00:21:16
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 51606 steps/s (collection: 1.799s, learning 0.106s)
             Mean action noise std: 1.64
          Mean value_function loss: 38.9055
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.9520
                       Mean reward: 738.31
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 0.6946
    Episode_Reward/rotating_object: 144.6656
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.90s
                      Time elapsed: 00:21:18
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 52051 steps/s (collection: 1.781s, learning 0.107s)
             Mean action noise std: 1.64
          Mean value_function loss: 37.7302
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 33.9643
                       Mean reward: 724.14
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 0.6854
    Episode_Reward/rotating_object: 141.8725
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.89s
                      Time elapsed: 00:21:20
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 52782 steps/s (collection: 1.764s, learning 0.099s)
             Mean action noise std: 1.64
          Mean value_function loss: 35.0250
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.9795
                       Mean reward: 725.51
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7039
    Episode_Reward/rotating_object: 145.0333
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.86s
                      Time elapsed: 00:21:22
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 53216 steps/s (collection: 1.753s, learning 0.094s)
             Mean action noise std: 1.64
          Mean value_function loss: 40.0638
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.9961
                       Mean reward: 746.52
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6984
    Episode_Reward/rotating_object: 147.0059
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.85s
                      Time elapsed: 00:21:24
                               ETA: 00:41:13

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 52913 steps/s (collection: 1.754s, learning 0.104s)
             Mean action noise std: 1.64
          Mean value_function loss: 38.5258
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.0109
                       Mean reward: 731.61
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.6868
    Episode_Reward/rotating_object: 143.5376
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.86s
                      Time elapsed: 00:21:26
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 50807 steps/s (collection: 1.829s, learning 0.106s)
             Mean action noise std: 1.64
          Mean value_function loss: 39.7239
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 34.0142
                       Mean reward: 715.86
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6947
    Episode_Reward/rotating_object: 144.9665
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.93s
                      Time elapsed: 00:21:28
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 51009 steps/s (collection: 1.830s, learning 0.097s)
             Mean action noise std: 1.64
          Mean value_function loss: 39.9901
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 34.0150
                       Mean reward: 726.17
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.6992
    Episode_Reward/rotating_object: 144.5538
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.93s
                      Time elapsed: 00:21:30
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 50607 steps/s (collection: 1.827s, learning 0.115s)
             Mean action noise std: 1.64
          Mean value_function loss: 38.8519
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 34.0157
                       Mean reward: 754.80
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.6925
    Episode_Reward/rotating_object: 144.6805
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.94s
                      Time elapsed: 00:21:32
                               ETA: 00:40:59

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 49275 steps/s (collection: 1.885s, learning 0.110s)
             Mean action noise std: 1.64
          Mean value_function loss: 48.6667
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.0166
                       Mean reward: 676.21
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 0.6958
    Episode_Reward/rotating_object: 142.7851
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.99s
                      Time elapsed: 00:21:34
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 52886 steps/s (collection: 1.766s, learning 0.093s)
             Mean action noise std: 1.65
          Mean value_function loss: 45.2531
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 34.0214
                       Mean reward: 719.12
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.6983
    Episode_Reward/rotating_object: 142.9126
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.86s
                      Time elapsed: 00:21:35
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 54006 steps/s (collection: 1.731s, learning 0.090s)
             Mean action noise std: 1.65
          Mean value_function loss: 47.8557
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.0341
                       Mean reward: 718.69
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7029
    Episode_Reward/rotating_object: 144.5599
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.82s
                      Time elapsed: 00:21:37
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 53143 steps/s (collection: 1.755s, learning 0.095s)
             Mean action noise std: 1.65
          Mean value_function loss: 43.5904
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 34.0535
                       Mean reward: 704.57
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 143.5585
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.85s
                      Time elapsed: 00:21:39
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 53703 steps/s (collection: 1.738s, learning 0.092s)
             Mean action noise std: 1.65
          Mean value_function loss: 46.1535
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.0746
                       Mean reward: 720.38
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.7007
    Episode_Reward/rotating_object: 144.4977
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.83s
                      Time elapsed: 00:21:41
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 47302 steps/s (collection: 1.879s, learning 0.199s)
             Mean action noise std: 1.65
          Mean value_function loss: 46.6351
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.0812
                       Mean reward: 718.40
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 0.7006
    Episode_Reward/rotating_object: 145.4508
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.08s
                      Time elapsed: 00:21:43
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 44886 steps/s (collection: 2.077s, learning 0.113s)
             Mean action noise std: 1.65
          Mean value_function loss: 39.3458
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.0924
                       Mean reward: 703.53
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 0.6985
    Episode_Reward/rotating_object: 142.7776
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.19s
                      Time elapsed: 00:21:45
                               ETA: 00:40:34

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 47634 steps/s (collection: 1.961s, learning 0.103s)
             Mean action noise std: 1.65
          Mean value_function loss: 37.6404
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.1053
                       Mean reward: 702.62
               Mean episode length: 244.88
    Episode_Reward/reaching_object: 0.7009
    Episode_Reward/rotating_object: 142.7624
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.06s
                      Time elapsed: 00:21:47
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 50041 steps/s (collection: 1.857s, learning 0.107s)
             Mean action noise std: 1.65
          Mean value_function loss: 38.5143
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.1116
                       Mean reward: 725.84
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 0.7054
    Episode_Reward/rotating_object: 146.4796
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.96s
                      Time elapsed: 00:21:49
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 49430 steps/s (collection: 1.888s, learning 0.101s)
             Mean action noise std: 1.66
          Mean value_function loss: 37.4053
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.1145
                       Mean reward: 730.40
               Mean episode length: 246.83
    Episode_Reward/reaching_object: 0.6974
    Episode_Reward/rotating_object: 142.4950
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.99s
                      Time elapsed: 00:21:51
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 52703 steps/s (collection: 1.770s, learning 0.095s)
             Mean action noise std: 1.66
          Mean value_function loss: 29.8610
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 34.1275
                       Mean reward: 730.54
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 146.2515
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.87s
                      Time elapsed: 00:21:53
                               ETA: 00:40:20

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 49977 steps/s (collection: 1.875s, learning 0.092s)
             Mean action noise std: 1.66
          Mean value_function loss: 37.9082
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 34.1359
                       Mean reward: 726.82
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7063
    Episode_Reward/rotating_object: 144.7520
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.97s
                      Time elapsed: 00:21:55
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 50970 steps/s (collection: 1.830s, learning 0.099s)
             Mean action noise std: 1.66
          Mean value_function loss: 37.0429
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.1482
                       Mean reward: 723.26
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 0.7029
    Episode_Reward/rotating_object: 146.5536
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.93s
                      Time elapsed: 00:21:57
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 51317 steps/s (collection: 1.809s, learning 0.107s)
             Mean action noise std: 1.66
          Mean value_function loss: 32.9225
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.1693
                       Mean reward: 738.21
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7040
    Episode_Reward/rotating_object: 147.0286
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.92s
                      Time elapsed: 00:21:59
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 50774 steps/s (collection: 1.829s, learning 0.107s)
             Mean action noise std: 1.66
          Mean value_function loss: 33.4080
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 34.1881
                       Mean reward: 733.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7052
    Episode_Reward/rotating_object: 148.2834
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 1.94s
                      Time elapsed: 00:22:01
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 51847 steps/s (collection: 1.793s, learning 0.104s)
             Mean action noise std: 1.66
          Mean value_function loss: 30.2469
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.1996
                       Mean reward: 732.18
               Mean episode length: 246.92
    Episode_Reward/reaching_object: 0.7057
    Episode_Reward/rotating_object: 145.9336
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.90s
                      Time elapsed: 00:22:03
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 49218 steps/s (collection: 1.894s, learning 0.103s)
             Mean action noise std: 1.67
          Mean value_function loss: 34.7038
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.2066
                       Mean reward: 744.39
               Mean episode length: 248.98
    Episode_Reward/reaching_object: 0.7045
    Episode_Reward/rotating_object: 147.2960
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.00s
                      Time elapsed: 00:22:05
                               ETA: 00:39:59

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 52409 steps/s (collection: 1.781s, learning 0.095s)
             Mean action noise std: 1.67
          Mean value_function loss: 37.2991
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.2136
                       Mean reward: 735.24
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7017
    Episode_Reward/rotating_object: 146.8236
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.88s
                      Time elapsed: 00:22:07
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 50616 steps/s (collection: 1.833s, learning 0.109s)
             Mean action noise std: 1.67
          Mean value_function loss: 30.7668
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.2249
                       Mean reward: 759.76
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7148
    Episode_Reward/rotating_object: 149.8750
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.94s
                      Time elapsed: 00:22:08
                               ETA: 00:39:52

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 50144 steps/s (collection: 1.857s, learning 0.103s)
             Mean action noise std: 1.67
          Mean value_function loss: 40.4764
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.2400
                       Mean reward: 753.72
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7048
    Episode_Reward/rotating_object: 148.9257
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.96s
                      Time elapsed: 00:22:10
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 50227 steps/s (collection: 1.862s, learning 0.095s)
             Mean action noise std: 1.67
          Mean value_function loss: 33.6507
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.2538
                       Mean reward: 736.35
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.7112
    Episode_Reward/rotating_object: 148.7927
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.96s
                      Time elapsed: 00:22:12
                               ETA: 00:39:45

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 51233 steps/s (collection: 1.819s, learning 0.100s)
             Mean action noise std: 1.67
          Mean value_function loss: 42.7537
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.2720
                       Mean reward: 723.65
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 0.7010
    Episode_Reward/rotating_object: 145.5847
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.92s
                      Time elapsed: 00:22:14
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 51299 steps/s (collection: 1.810s, learning 0.107s)
             Mean action noise std: 1.68
          Mean value_function loss: 36.2632
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.2911
                       Mean reward: 760.97
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.7072
    Episode_Reward/rotating_object: 146.2619
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.92s
                      Time elapsed: 00:22:16
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 53376 steps/s (collection: 1.734s, learning 0.108s)
             Mean action noise std: 1.68
          Mean value_function loss: 35.3740
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.3136
                       Mean reward: 745.49
               Mean episode length: 246.23
    Episode_Reward/reaching_object: 0.7092
    Episode_Reward/rotating_object: 149.7409
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.84s
                      Time elapsed: 00:22:18
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 52718 steps/s (collection: 1.756s, learning 0.109s)
             Mean action noise std: 1.68
          Mean value_function loss: 30.6692
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.3219
                       Mean reward: 742.97
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.7049
    Episode_Reward/rotating_object: 147.4286
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.86s
                      Time elapsed: 00:22:20
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 54130 steps/s (collection: 1.722s, learning 0.095s)
             Mean action noise std: 1.68
          Mean value_function loss: 34.3337
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.3375
                       Mean reward: 730.91
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 0.7051
    Episode_Reward/rotating_object: 145.9763
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.82s
                      Time elapsed: 00:22:22
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 50698 steps/s (collection: 1.827s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 32.9825
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.3566
                       Mean reward: 703.36
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 0.7021
    Episode_Reward/rotating_object: 145.0092
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.94s
                      Time elapsed: 00:22:24
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 53666 steps/s (collection: 1.742s, learning 0.090s)
             Mean action noise std: 1.68
          Mean value_function loss: 33.8857
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.3692
                       Mean reward: 746.82
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 0.7055
    Episode_Reward/rotating_object: 150.0439
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.83s
                      Time elapsed: 00:22:26
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 50940 steps/s (collection: 1.832s, learning 0.098s)
             Mean action noise std: 1.69
          Mean value_function loss: 35.7793
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.3897
                       Mean reward: 749.43
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.7075
    Episode_Reward/rotating_object: 148.6028
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 1.93s
                      Time elapsed: 00:22:27
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 52853 steps/s (collection: 1.763s, learning 0.097s)
             Mean action noise std: 1.69
          Mean value_function loss: 34.6943
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 34.4200
                       Mean reward: 726.12
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 149.1284
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 1.86s
                      Time elapsed: 00:22:29
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 52929 steps/s (collection: 1.767s, learning 0.091s)
             Mean action noise std: 1.69
          Mean value_function loss: 29.8002
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.4286
                       Mean reward: 765.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7083
    Episode_Reward/rotating_object: 148.4871
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.86s
                      Time elapsed: 00:22:31
                               ETA: 00:39:10

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 52924 steps/s (collection: 1.763s, learning 0.094s)
             Mean action noise std: 1.69
          Mean value_function loss: 38.9072
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 34.4407
                       Mean reward: 750.53
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.7111
    Episode_Reward/rotating_object: 149.6467
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 1.86s
                      Time elapsed: 00:22:33
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 49470 steps/s (collection: 1.896s, learning 0.092s)
             Mean action noise std: 1.70
          Mean value_function loss: 33.3937
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.4688
                       Mean reward: 728.26
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 0.7051
    Episode_Reward/rotating_object: 145.3532
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.99s
                      Time elapsed: 00:22:35
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 49481 steps/s (collection: 1.879s, learning 0.108s)
             Mean action noise std: 1.70
          Mean value_function loss: 33.4566
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 34.4963
                       Mean reward: 709.45
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.7078
    Episode_Reward/rotating_object: 146.9625
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 1.99s
                      Time elapsed: 00:22:37
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 49957 steps/s (collection: 1.872s, learning 0.096s)
             Mean action noise std: 1.70
          Mean value_function loss: 34.2052
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.5097
                       Mean reward: 741.11
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6946
    Episode_Reward/rotating_object: 144.9446
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 1.97s
                      Time elapsed: 00:22:39
                               ETA: 00:38:57

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 48745 steps/s (collection: 1.911s, learning 0.106s)
             Mean action noise std: 1.70
          Mean value_function loss: 31.0684
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 34.5213
                       Mean reward: 736.84
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 0.7067
    Episode_Reward/rotating_object: 146.4937
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.02s
                      Time elapsed: 00:22:41
                               ETA: 00:38:54

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 48962 steps/s (collection: 1.902s, learning 0.106s)
             Mean action noise std: 1.70
          Mean value_function loss: 30.6447
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.5296
                       Mean reward: 751.76
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7095
    Episode_Reward/rotating_object: 149.1920
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.01s
                      Time elapsed: 00:22:43
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 50082 steps/s (collection: 1.844s, learning 0.119s)
             Mean action noise std: 1.70
          Mean value_function loss: 38.4729
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.5403
                       Mean reward: 731.88
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 147.3097
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 1.96s
                      Time elapsed: 00:22:45
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 51719 steps/s (collection: 1.799s, learning 0.101s)
             Mean action noise std: 1.71
          Mean value_function loss: 35.3204
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.5492
                       Mean reward: 764.77
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7159
    Episode_Reward/rotating_object: 148.7366
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 1.90s
                      Time elapsed: 00:22:47
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 50279 steps/s (collection: 1.843s, learning 0.112s)
             Mean action noise std: 1.71
          Mean value_function loss: 33.8904
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.5547
                       Mean reward: 738.65
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 0.7148
    Episode_Reward/rotating_object: 149.6905
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 1.96s
                      Time elapsed: 00:22:49
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 50069 steps/s (collection: 1.822s, learning 0.142s)
             Mean action noise std: 1.71
          Mean value_function loss: 33.4504
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.5697
                       Mean reward: 758.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 149.0254
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 1.96s
                      Time elapsed: 00:22:51
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 49717 steps/s (collection: 1.868s, learning 0.109s)
             Mean action noise std: 1.71
          Mean value_function loss: 33.9530
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.5891
                       Mean reward: 751.92
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.7186
    Episode_Reward/rotating_object: 149.3680
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.98s
                      Time elapsed: 00:22:53
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 49424 steps/s (collection: 1.889s, learning 0.100s)
             Mean action noise std: 1.71
          Mean value_function loss: 32.1773
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.5997
                       Mean reward: 748.14
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7139
    Episode_Reward/rotating_object: 149.7250
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.99s
                      Time elapsed: 00:22:55
                               ETA: 00:38:30

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 51370 steps/s (collection: 1.818s, learning 0.096s)
             Mean action noise std: 1.71
          Mean value_function loss: 26.4884
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.6202
                       Mean reward: 734.86
               Mean episode length: 247.34
    Episode_Reward/reaching_object: 0.7136
    Episode_Reward/rotating_object: 148.0639
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.91s
                      Time elapsed: 00:22:57
                               ETA: 00:38:27

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 50604 steps/s (collection: 1.821s, learning 0.122s)
             Mean action noise std: 1.72
          Mean value_function loss: 24.8793
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.6434
                       Mean reward: 765.46
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7108
    Episode_Reward/rotating_object: 148.7038
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 1.94s
                      Time elapsed: 00:22:59
                               ETA: 00:38:24

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 50217 steps/s (collection: 1.849s, learning 0.109s)
             Mean action noise std: 1.72
          Mean value_function loss: 28.2195
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.6575
                       Mean reward: 759.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7214
    Episode_Reward/rotating_object: 151.0444
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.96s
                      Time elapsed: 00:23:01
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 49473 steps/s (collection: 1.871s, learning 0.116s)
             Mean action noise std: 1.72
          Mean value_function loss: 30.9497
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.6653
                       Mean reward: 736.20
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7192
    Episode_Reward/rotating_object: 150.1429
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.99s
                      Time elapsed: 00:23:03
                               ETA: 00:38:17

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 51641 steps/s (collection: 1.806s, learning 0.098s)
             Mean action noise std: 1.72
          Mean value_function loss: 36.9262
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.6783
                       Mean reward: 735.92
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.7174
    Episode_Reward/rotating_object: 149.1847
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.90s
                      Time elapsed: 00:23:04
                               ETA: 00:38:14

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 51521 steps/s (collection: 1.788s, learning 0.120s)
             Mean action noise std: 1.72
          Mean value_function loss: 33.2872
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.6961
                       Mean reward: 727.31
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.7123
    Episode_Reward/rotating_object: 148.4562
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.91s
                      Time elapsed: 00:23:06
                               ETA: 00:38:11

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 48039 steps/s (collection: 1.927s, learning 0.120s)
             Mean action noise std: 1.73
          Mean value_function loss: 28.1224
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.7183
                       Mean reward: 745.03
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7162
    Episode_Reward/rotating_object: 148.7185
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.05s
                      Time elapsed: 00:23:08
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 51951 steps/s (collection: 1.786s, learning 0.106s)
             Mean action noise std: 1.73
          Mean value_function loss: 30.7891
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.7410
                       Mean reward: 752.14
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.7208
    Episode_Reward/rotating_object: 148.8750
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 1.89s
                      Time elapsed: 00:23:10
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 52711 steps/s (collection: 1.775s, learning 0.090s)
             Mean action noise std: 1.73
          Mean value_function loss: 31.5138
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.7606
                       Mean reward: 773.77
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7188
    Episode_Reward/rotating_object: 149.7702
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.86s
                      Time elapsed: 00:23:12
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 51695 steps/s (collection: 1.811s, learning 0.091s)
             Mean action noise std: 1.73
          Mean value_function loss: 34.7808
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 34.7761
                       Mean reward: 746.34
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 148.7398
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.90s
                      Time elapsed: 00:23:14
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 51162 steps/s (collection: 1.804s, learning 0.118s)
             Mean action noise std: 1.73
          Mean value_function loss: 36.6697
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 34.7900
                       Mean reward: 756.11
               Mean episode length: 249.48
    Episode_Reward/reaching_object: 0.7224
    Episode_Reward/rotating_object: 151.6954
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.92s
                      Time elapsed: 00:23:16
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 52052 steps/s (collection: 1.784s, learning 0.105s)
             Mean action noise std: 1.74
          Mean value_function loss: 29.8466
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.8072
                       Mean reward: 746.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 151.1949
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.89s
                      Time elapsed: 00:23:18
                               ETA: 00:37:51

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 40237 steps/s (collection: 2.277s, learning 0.167s)
             Mean action noise std: 1.74
          Mean value_function loss: 32.8543
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 34.8160
                       Mean reward: 745.33
               Mean episode length: 245.39
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 150.0341
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.44s
                      Time elapsed: 00:23:20
                               ETA: 00:37:48

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 49241 steps/s (collection: 1.890s, learning 0.107s)
             Mean action noise std: 1.74
          Mean value_function loss: 27.3722
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.8257
                       Mean reward: 745.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7233
    Episode_Reward/rotating_object: 149.2008
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.00s
                      Time elapsed: 00:23:22
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 51691 steps/s (collection: 1.790s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 29.9789
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.8493
                       Mean reward: 764.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 151.3116
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 1.90s
                      Time elapsed: 00:23:24
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 48272 steps/s (collection: 1.932s, learning 0.104s)
             Mean action noise std: 1.74
          Mean value_function loss: 31.2772
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.8742
                       Mean reward: 762.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7162
    Episode_Reward/rotating_object: 150.6550
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.04s
                      Time elapsed: 00:23:26
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 46192 steps/s (collection: 2.019s, learning 0.109s)
             Mean action noise std: 1.75
          Mean value_function loss: 31.3312
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.8947
                       Mean reward: 769.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 151.8696
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.13s
                      Time elapsed: 00:23:28
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 50576 steps/s (collection: 1.846s, learning 0.098s)
             Mean action noise std: 1.75
          Mean value_function loss: 31.2146
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.9061
                       Mean reward: 762.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7137
    Episode_Reward/rotating_object: 150.3080
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.94s
                      Time elapsed: 00:23:30
                               ETA: 00:37:32

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 50633 steps/s (collection: 1.810s, learning 0.131s)
             Mean action noise std: 1.75
          Mean value_function loss: 29.5041
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.9107
                       Mean reward: 769.02
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.7166
    Episode_Reward/rotating_object: 152.1083
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.94s
                      Time elapsed: 00:23:32
                               ETA: 00:37:29

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 49030 steps/s (collection: 1.904s, learning 0.101s)
             Mean action noise std: 1.75
          Mean value_function loss: 28.1381
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.9193
                       Mean reward: 759.27
               Mean episode length: 248.76
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 152.5234
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.00s
                      Time elapsed: 00:23:34
                               ETA: 00:37:26

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 48145 steps/s (collection: 1.932s, learning 0.110s)
             Mean action noise std: 1.75
          Mean value_function loss: 31.4590
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.9381
                       Mean reward: 761.52
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 151.1324
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.04s
                      Time elapsed: 00:23:36
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 50100 steps/s (collection: 1.872s, learning 0.091s)
             Mean action noise std: 1.75
          Mean value_function loss: 28.1814
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.9524
                       Mean reward: 744.81
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.7094
    Episode_Reward/rotating_object: 149.3189
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.96s
                      Time elapsed: 00:23:38
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 53085 steps/s (collection: 1.759s, learning 0.093s)
             Mean action noise std: 1.76
          Mean value_function loss: 28.6207
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.9677
                       Mean reward: 754.84
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.7141
    Episode_Reward/rotating_object: 150.2281
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.85s
                      Time elapsed: 00:23:40
                               ETA: 00:37:16

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 51664 steps/s (collection: 1.803s, learning 0.100s)
             Mean action noise std: 1.76
          Mean value_function loss: 29.8860
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.9899
                       Mean reward: 740.77
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 0.7210
    Episode_Reward/rotating_object: 151.0174
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.90s
                      Time elapsed: 00:23:42
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 51195 steps/s (collection: 1.809s, learning 0.111s)
             Mean action noise std: 1.76
          Mean value_function loss: 30.1203
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.0085
                       Mean reward: 771.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 151.3979
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.92s
                      Time elapsed: 00:23:44
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 51599 steps/s (collection: 1.808s, learning 0.098s)
             Mean action noise std: 1.76
          Mean value_function loss: 29.9800
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.0204
                       Mean reward: 744.35
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7162
    Episode_Reward/rotating_object: 150.2397
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.91s
                      Time elapsed: 00:23:46
                               ETA: 00:37:07

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 50275 steps/s (collection: 1.848s, learning 0.108s)
             Mean action noise std: 1.76
          Mean value_function loss: 30.9445
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.0344
                       Mean reward: 771.03
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7239
    Episode_Reward/rotating_object: 150.9025
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.96s
                      Time elapsed: 00:23:48
                               ETA: 00:37:03

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 50910 steps/s (collection: 1.825s, learning 0.106s)
             Mean action noise std: 1.76
          Mean value_function loss: 30.7189
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.0385
                       Mean reward: 745.62
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 0.7218
    Episode_Reward/rotating_object: 150.8699
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.93s
                      Time elapsed: 00:23:50
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 49313 steps/s (collection: 1.879s, learning 0.114s)
             Mean action noise std: 1.76
          Mean value_function loss: 23.0371
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.0457
                       Mean reward: 734.85
               Mean episode length: 246.94
    Episode_Reward/reaching_object: 0.7255
    Episode_Reward/rotating_object: 151.9285
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.99s
                      Time elapsed: 00:23:52
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 50946 steps/s (collection: 1.825s, learning 0.105s)
             Mean action noise std: 1.77
          Mean value_function loss: 30.6843
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.0558
                       Mean reward: 785.54
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7306
    Episode_Reward/rotating_object: 152.3399
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.93s
                      Time elapsed: 00:23:54
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 50409 steps/s (collection: 1.846s, learning 0.105s)
             Mean action noise std: 1.77
          Mean value_function loss: 24.9003
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.0708
                       Mean reward: 776.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7224
    Episode_Reward/rotating_object: 151.9618
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.95s
                      Time elapsed: 00:23:56
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 46697 steps/s (collection: 1.973s, learning 0.132s)
             Mean action noise std: 1.77
          Mean value_function loss: 32.7090
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.0896
                       Mean reward: 747.57
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 151.7045
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.11s
                      Time elapsed: 00:23:58
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 50424 steps/s (collection: 1.848s, learning 0.102s)
             Mean action noise std: 1.77
          Mean value_function loss: 27.3709
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 35.1061
                       Mean reward: 760.44
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 152.0797
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 1.95s
                      Time elapsed: 00:24:00
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 50395 steps/s (collection: 1.852s, learning 0.099s)
             Mean action noise std: 1.77
          Mean value_function loss: 26.5276
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.1188
                       Mean reward: 750.70
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.7248
    Episode_Reward/rotating_object: 150.4675
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 1.95s
                      Time elapsed: 00:24:02
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 48951 steps/s (collection: 1.889s, learning 0.120s)
             Mean action noise std: 1.77
          Mean value_function loss: 24.8870
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.1291
                       Mean reward: 752.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7332
    Episode_Reward/rotating_object: 152.8955
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.01s
                      Time elapsed: 00:24:04
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 49593 steps/s (collection: 1.881s, learning 0.102s)
             Mean action noise std: 1.78
          Mean value_function loss: 26.6739
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.1451
                       Mean reward: 776.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 152.5520
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.98s
                      Time elapsed: 00:24:06
                               ETA: 00:36:35

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 47739 steps/s (collection: 1.958s, learning 0.101s)
             Mean action noise std: 1.78
          Mean value_function loss: 35.5304
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.1620
                       Mean reward: 780.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7273
    Episode_Reward/rotating_object: 152.6518
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.06s
                      Time elapsed: 00:24:08
                               ETA: 00:36:32

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 50554 steps/s (collection: 1.835s, learning 0.109s)
             Mean action noise std: 1.78
          Mean value_function loss: 29.3301
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.1852
                       Mean reward: 746.71
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7323
    Episode_Reward/rotating_object: 153.5634
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 1.94s
                      Time elapsed: 00:24:10
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 49023 steps/s (collection: 1.909s, learning 0.097s)
             Mean action noise std: 1.78
          Mean value_function loss: 24.6580
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 35.1931
                       Mean reward: 784.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 152.7984
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.01s
                      Time elapsed: 00:24:12
                               ETA: 00:36:26

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 51580 steps/s (collection: 1.791s, learning 0.115s)
             Mean action noise std: 1.78
          Mean value_function loss: 22.4202
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 35.1968
                       Mean reward: 778.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7236
    Episode_Reward/rotating_object: 151.1224
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.91s
                      Time elapsed: 00:24:14
                               ETA: 00:36:23

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 48445 steps/s (collection: 1.928s, learning 0.102s)
             Mean action noise std: 1.78
          Mean value_function loss: 24.7916
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.2036
                       Mean reward: 766.63
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 152.0153
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.03s
                      Time elapsed: 00:24:16
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 49712 steps/s (collection: 1.861s, learning 0.117s)
             Mean action noise std: 1.79
          Mean value_function loss: 23.5299
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.2185
                       Mean reward: 775.39
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7230
    Episode_Reward/rotating_object: 154.2865
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 1.98s
                      Time elapsed: 00:24:18
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 49751 steps/s (collection: 1.860s, learning 0.116s)
             Mean action noise std: 1.79
          Mean value_function loss: 27.9773
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.2442
                       Mean reward: 762.83
               Mean episode length: 246.22
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 153.4419
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.98s
                      Time elapsed: 00:24:20
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 51231 steps/s (collection: 1.809s, learning 0.110s)
             Mean action noise std: 1.79
          Mean value_function loss: 32.8656
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 35.2676
                       Mean reward: 769.99
               Mean episode length: 248.84
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 153.7304
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 1.92s
                      Time elapsed: 00:24:21
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 51294 steps/s (collection: 1.798s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 28.5600
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.2857
                       Mean reward: 775.62
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 0.7205
    Episode_Reward/rotating_object: 153.0142
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.92s
                      Time elapsed: 00:24:23
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 51050 steps/s (collection: 1.825s, learning 0.101s)
             Mean action noise std: 1.79
          Mean value_function loss: 26.2157
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.3069
                       Mean reward: 745.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7261
    Episode_Reward/rotating_object: 150.2201
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 1.93s
                      Time elapsed: 00:24:25
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 50189 steps/s (collection: 1.844s, learning 0.115s)
             Mean action noise std: 1.80
          Mean value_function loss: 24.9878
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 35.3190
                       Mean reward: 768.17
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7278
    Episode_Reward/rotating_object: 150.5887
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 1.96s
                      Time elapsed: 00:24:27
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 50004 steps/s (collection: 1.855s, learning 0.111s)
             Mean action noise std: 1.80
          Mean value_function loss: 23.2303
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.3282
                       Mean reward: 760.09
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7336
    Episode_Reward/rotating_object: 153.5655
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.97s
                      Time elapsed: 00:24:29
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 50984 steps/s (collection: 1.821s, learning 0.107s)
             Mean action noise std: 1.80
          Mean value_function loss: 28.9374
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.3422
                       Mean reward: 753.14
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 0.7248
    Episode_Reward/rotating_object: 154.1780
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.93s
                      Time elapsed: 00:24:31
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 48501 steps/s (collection: 1.904s, learning 0.123s)
             Mean action noise std: 1.80
          Mean value_function loss: 29.4816
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 35.3548
                       Mean reward: 775.32
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.7318
    Episode_Reward/rotating_object: 154.7220
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.03s
                      Time elapsed: 00:24:33
                               ETA: 00:35:52

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 49531 steps/s (collection: 1.882s, learning 0.103s)
             Mean action noise std: 1.80
          Mean value_function loss: 26.7538
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 35.3669
                       Mean reward: 783.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 154.5694
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.98s
                      Time elapsed: 00:24:35
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 51419 steps/s (collection: 1.808s, learning 0.104s)
             Mean action noise std: 1.80
          Mean value_function loss: 24.7184
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 35.3835
                       Mean reward: 779.29
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7287
    Episode_Reward/rotating_object: 153.6264
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.91s
                      Time elapsed: 00:24:37
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 49708 steps/s (collection: 1.851s, learning 0.127s)
             Mean action noise std: 1.81
          Mean value_function loss: 29.1693
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.4015
                       Mean reward: 729.96
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7268
    Episode_Reward/rotating_object: 149.6548
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 1.98s
                      Time elapsed: 00:24:39
                               ETA: 00:35:43

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 47494 steps/s (collection: 1.942s, learning 0.128s)
             Mean action noise std: 1.81
          Mean value_function loss: 28.5282
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.4290
                       Mean reward: 780.04
               Mean episode length: 248.64
    Episode_Reward/reaching_object: 0.7298
    Episode_Reward/rotating_object: 152.4419
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.07s
                      Time elapsed: 00:24:41
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 43117 steps/s (collection: 2.125s, learning 0.155s)
             Mean action noise std: 1.81
          Mean value_function loss: 24.3686
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.4457
                       Mean reward: 757.26
               Mean episode length: 247.23
    Episode_Reward/reaching_object: 0.7324
    Episode_Reward/rotating_object: 152.0465
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.28s
                      Time elapsed: 00:24:43
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 44761 steps/s (collection: 2.059s, learning 0.138s)
             Mean action noise std: 1.81
          Mean value_function loss: 24.4100
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.4553
                       Mean reward: 773.86
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7350
    Episode_Reward/rotating_object: 153.8673
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.20s
                      Time elapsed: 00:24:46
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 50133 steps/s (collection: 1.858s, learning 0.103s)
             Mean action noise std: 1.81
          Mean value_function loss: 29.1054
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 35.4618
                       Mean reward: 768.33
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 152.6590
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.96s
                      Time elapsed: 00:24:48
                               ETA: 00:35:31

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 50253 steps/s (collection: 1.851s, learning 0.106s)
             Mean action noise std: 1.82
          Mean value_function loss: 34.0642
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.4725
                       Mean reward: 770.62
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 153.7145
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.96s
                      Time elapsed: 00:24:49
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 49031 steps/s (collection: 1.845s, learning 0.160s)
             Mean action noise std: 1.82
          Mean value_function loss: 21.9561
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.4908
                       Mean reward: 740.44
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 0.7276
    Episode_Reward/rotating_object: 152.0025
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.00s
                      Time elapsed: 00:24:52
                               ETA: 00:35:25

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 49761 steps/s (collection: 1.872s, learning 0.104s)
             Mean action noise std: 1.82
          Mean value_function loss: 30.2760
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.5138
                       Mean reward: 771.94
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 154.8575
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 1.98s
                      Time elapsed: 00:24:53
                               ETA: 00:35:22

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 49420 steps/s (collection: 1.885s, learning 0.104s)
             Mean action noise std: 1.82
          Mean value_function loss: 26.1968
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 35.5371
                       Mean reward: 773.95
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7313
    Episode_Reward/rotating_object: 152.4815
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.99s
                      Time elapsed: 00:24:55
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 47255 steps/s (collection: 1.970s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 31.8707
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 35.5515
                       Mean reward: 760.42
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.7255
    Episode_Reward/rotating_object: 152.3881
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.08s
                      Time elapsed: 00:24:58
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 49151 steps/s (collection: 1.898s, learning 0.102s)
             Mean action noise std: 1.83
          Mean value_function loss: 22.7547
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.5734
                       Mean reward: 756.99
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 0.7212
    Episode_Reward/rotating_object: 151.7586
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.00s
                      Time elapsed: 00:25:00
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 51017 steps/s (collection: 1.811s, learning 0.116s)
             Mean action noise std: 1.83
          Mean value_function loss: 23.5975
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.6000
                       Mean reward: 758.20
               Mean episode length: 247.29
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 153.4006
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 1.93s
                      Time elapsed: 00:25:01
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 49805 steps/s (collection: 1.865s, learning 0.109s)
             Mean action noise std: 1.83
          Mean value_function loss: 24.1657
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.6227
                       Mean reward: 750.62
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 0.7237
    Episode_Reward/rotating_object: 152.1650
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.97s
                      Time elapsed: 00:25:03
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 48473 steps/s (collection: 1.910s, learning 0.118s)
             Mean action noise std: 1.84
          Mean value_function loss: 26.8722
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 35.6470
                       Mean reward: 754.76
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 154.5214
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.03s
                      Time elapsed: 00:25:05
                               ETA: 00:35:04

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 47126 steps/s (collection: 1.971s, learning 0.115s)
             Mean action noise std: 1.84
          Mean value_function loss: 27.2146
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.6700
                       Mean reward: 784.36
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 155.1831
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.09s
                      Time elapsed: 00:25:08
                               ETA: 00:35:02

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 50339 steps/s (collection: 1.843s, learning 0.110s)
             Mean action noise std: 1.84
          Mean value_function loss: 24.7445
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.6983
                       Mean reward: 773.14
               Mean episode length: 247.55
    Episode_Reward/reaching_object: 0.7333
    Episode_Reward/rotating_object: 154.9808
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.95s
                      Time elapsed: 00:25:10
                               ETA: 00:34:59

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 50476 steps/s (collection: 1.832s, learning 0.115s)
             Mean action noise std: 1.84
          Mean value_function loss: 23.4096
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.7142
                       Mean reward: 774.02
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7281
    Episode_Reward/rotating_object: 153.2930
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.95s
                      Time elapsed: 00:25:11
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 50377 steps/s (collection: 1.844s, learning 0.107s)
             Mean action noise std: 1.85
          Mean value_function loss: 20.9692
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.7269
                       Mean reward: 778.32
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7334
    Episode_Reward/rotating_object: 156.0522
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.95s
                      Time elapsed: 00:25:13
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 50176 steps/s (collection: 1.855s, learning 0.104s)
             Mean action noise std: 1.85
          Mean value_function loss: 20.8708
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.7496
                       Mean reward: 778.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7308
    Episode_Reward/rotating_object: 152.9996
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.96s
                      Time elapsed: 00:25:15
                               ETA: 00:34:50

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 50184 steps/s (collection: 1.855s, learning 0.104s)
             Mean action noise std: 1.85
          Mean value_function loss: 31.7930
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.7601
                       Mean reward: 785.04
               Mean episode length: 249.46
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 153.9226
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.96s
                      Time elapsed: 00:25:17
                               ETA: 00:34:47

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 48964 steps/s (collection: 1.861s, learning 0.147s)
             Mean action noise std: 1.85
          Mean value_function loss: 34.3736
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.7683
                       Mean reward: 770.41
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 153.6186
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.01s
                      Time elapsed: 00:25:19
                               ETA: 00:34:44

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 48033 steps/s (collection: 1.928s, learning 0.119s)
             Mean action noise std: 1.85
          Mean value_function loss: 29.6931
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.7791
                       Mean reward: 766.72
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 153.3742
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.05s
                      Time elapsed: 00:25:21
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 48532 steps/s (collection: 1.903s, learning 0.123s)
             Mean action noise std: 1.85
          Mean value_function loss: 28.3771
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.7932
                       Mean reward: 766.93
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.7378
    Episode_Reward/rotating_object: 155.0634
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.03s
                      Time elapsed: 00:25:23
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 43361 steps/s (collection: 2.152s, learning 0.116s)
             Mean action noise std: 1.85
          Mean value_function loss: 23.1683
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.8097
                       Mean reward: 760.16
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7305
    Episode_Reward/rotating_object: 152.0882
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.27s
                      Time elapsed: 00:25:26
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 44137 steps/s (collection: 2.099s, learning 0.129s)
             Mean action noise std: 1.86
          Mean value_function loss: 26.8960
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.8231
                       Mean reward: 800.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7407
    Episode_Reward/rotating_object: 155.4186
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.23s
                      Time elapsed: 00:25:28
                               ETA: 00:34:33

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 44970 steps/s (collection: 2.061s, learning 0.125s)
             Mean action noise std: 1.86
          Mean value_function loss: 26.3553
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.8332
                       Mean reward: 789.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7385
    Episode_Reward/rotating_object: 153.7017
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.19s
                      Time elapsed: 00:25:30
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 46402 steps/s (collection: 2.003s, learning 0.115s)
             Mean action noise std: 1.86
          Mean value_function loss: 28.3497
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.8460
                       Mean reward: 774.59
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.7420
    Episode_Reward/rotating_object: 156.0662
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.12s
                      Time elapsed: 00:25:32
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 45446 steps/s (collection: 2.031s, learning 0.132s)
             Mean action noise std: 1.86
          Mean value_function loss: 30.0824
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.8648
                       Mean reward: 775.82
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7351
    Episode_Reward/rotating_object: 155.1568
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.16s
                      Time elapsed: 00:25:34
                               ETA: 00:34:24

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 44607 steps/s (collection: 2.086s, learning 0.118s)
             Mean action noise std: 1.86
          Mean value_function loss: 21.4909
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 35.8860
                       Mean reward: 767.88
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 155.7533
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.20s
                      Time elapsed: 00:25:37
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 49017 steps/s (collection: 1.874s, learning 0.132s)
             Mean action noise std: 1.87
          Mean value_function loss: 33.7563
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.9020
                       Mean reward: 771.93
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7272
    Episode_Reward/rotating_object: 151.9987
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.01s
                      Time elapsed: 00:25:39
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 48372 steps/s (collection: 1.913s, learning 0.119s)
             Mean action noise std: 1.87
          Mean value_function loss: 23.0264
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.9241
                       Mean reward: 768.53
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 151.2741
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.03s
                      Time elapsed: 00:25:41
                               ETA: 00:34:16

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 48400 steps/s (collection: 1.887s, learning 0.144s)
             Mean action noise std: 1.87
          Mean value_function loss: 25.3972
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.9382
                       Mean reward: 805.80
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7443
    Episode_Reward/rotating_object: 157.0120
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.03s
                      Time elapsed: 00:25:43
                               ETA: 00:34:13

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 47744 steps/s (collection: 1.946s, learning 0.113s)
             Mean action noise std: 1.87
          Mean value_function loss: 23.6132
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.9576
                       Mean reward: 802.36
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7400
    Episode_Reward/rotating_object: 156.4906
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.06s
                      Time elapsed: 00:25:45
                               ETA: 00:34:10

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 48630 steps/s (collection: 1.908s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 30.0924
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.9676
                       Mean reward: 778.50
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 152.3354
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.02s
                      Time elapsed: 00:25:47
                               ETA: 00:34:07

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 47182 steps/s (collection: 1.966s, learning 0.117s)
             Mean action noise std: 1.88
          Mean value_function loss: 31.6371
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.9840
                       Mean reward: 787.77
               Mean episode length: 246.52
    Episode_Reward/reaching_object: 0.7270
    Episode_Reward/rotating_object: 153.5413
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.08s
                      Time elapsed: 00:25:49
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 49077 steps/s (collection: 1.880s, learning 0.123s)
             Mean action noise std: 1.88
          Mean value_function loss: 30.8548
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.0012
                       Mean reward: 769.72
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 0.7361
    Episode_Reward/rotating_object: 153.8589
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.00s
                      Time elapsed: 00:25:51
                               ETA: 00:34:02

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 48286 steps/s (collection: 1.918s, learning 0.118s)
             Mean action noise std: 1.88
          Mean value_function loss: 27.1609
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.0103
                       Mean reward: 778.25
               Mean episode length: 248.53
    Episode_Reward/reaching_object: 0.7344
    Episode_Reward/rotating_object: 154.0125
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.04s
                      Time elapsed: 00:25:53
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 49129 steps/s (collection: 1.889s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 30.3603
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.0297
                       Mean reward: 761.20
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 0.7282
    Episode_Reward/rotating_object: 154.7180
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.00s
                      Time elapsed: 00:25:55
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 48279 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 1.88
          Mean value_function loss: 28.9132
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.0457
                       Mean reward: 766.37
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 154.8963
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.04s
                      Time elapsed: 00:25:57
                               ETA: 00:33:53

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 48498 steps/s (collection: 1.906s, learning 0.121s)
             Mean action noise std: 1.89
          Mean value_function loss: 28.0884
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.0581
                       Mean reward: 773.88
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 0.7316
    Episode_Reward/rotating_object: 152.9906
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.03s
                      Time elapsed: 00:25:59
                               ETA: 00:33:50

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 49226 steps/s (collection: 1.893s, learning 0.104s)
             Mean action noise std: 1.89
          Mean value_function loss: 30.7709
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.0765
                       Mean reward: 789.07
               Mean episode length: 246.86
    Episode_Reward/reaching_object: 0.7361
    Episode_Reward/rotating_object: 155.9213
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.00s
                      Time elapsed: 00:26:01
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 48802 steps/s (collection: 1.891s, learning 0.124s)
             Mean action noise std: 1.89
          Mean value_function loss: 23.3835
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.1012
                       Mean reward: 794.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7393
    Episode_Reward/rotating_object: 155.5564
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.01s
                      Time elapsed: 00:26:03
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 49342 steps/s (collection: 1.880s, learning 0.112s)
             Mean action noise std: 1.89
          Mean value_function loss: 29.7593
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.1126
                       Mean reward: 773.06
               Mean episode length: 247.26
    Episode_Reward/reaching_object: 0.7330
    Episode_Reward/rotating_object: 154.1185
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.99s
                      Time elapsed: 00:26:05
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 48497 steps/s (collection: 1.902s, learning 0.125s)
             Mean action noise std: 1.89
          Mean value_function loss: 28.8979
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.1219
                       Mean reward: 769.92
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 155.2276
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.03s
                      Time elapsed: 00:26:07
                               ETA: 00:33:39

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 48006 steps/s (collection: 1.917s, learning 0.131s)
             Mean action noise std: 1.90
          Mean value_function loss: 28.0028
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.1374
                       Mean reward: 796.83
               Mean episode length: 248.81
    Episode_Reward/reaching_object: 0.7264
    Episode_Reward/rotating_object: 152.5575
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.05s
                      Time elapsed: 00:26:09
                               ETA: 00:33:36

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 48046 steps/s (collection: 1.932s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 22.7132
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.1511
                       Mean reward: 781.65
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 0.7423
    Episode_Reward/rotating_object: 155.6665
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.05s
                      Time elapsed: 00:26:11
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 48729 steps/s (collection: 1.908s, learning 0.110s)
             Mean action noise std: 1.90
          Mean value_function loss: 20.1696
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.1633
                       Mean reward: 788.56
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7338
    Episode_Reward/rotating_object: 154.2300
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.02s
                      Time elapsed: 00:26:13
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 48701 steps/s (collection: 1.904s, learning 0.115s)
             Mean action noise std: 1.90
          Mean value_function loss: 22.8717
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.1892
                       Mean reward: 767.99
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7361
    Episode_Reward/rotating_object: 155.0730
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.02s
                      Time elapsed: 00:26:15
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 48910 steps/s (collection: 1.892s, learning 0.118s)
             Mean action noise std: 1.90
          Mean value_function loss: 28.0685
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.2051
                       Mean reward: 804.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7348
    Episode_Reward/rotating_object: 155.8829
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.01s
                      Time elapsed: 00:26:17
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 50636 steps/s (collection: 1.824s, learning 0.117s)
             Mean action noise std: 1.91
          Mean value_function loss: 29.0083
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.2245
                       Mean reward: 753.22
               Mean episode length: 236.96
    Episode_Reward/reaching_object: 0.7257
    Episode_Reward/rotating_object: 151.6913
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.94s
                      Time elapsed: 00:26:19
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 49797 steps/s (collection: 1.850s, learning 0.124s)
             Mean action noise std: 1.91
          Mean value_function loss: 21.8300
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.2361
                       Mean reward: 802.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7357
    Episode_Reward/rotating_object: 154.4167
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.97s
                      Time elapsed: 00:26:21
                               ETA: 00:33:18

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 47201 steps/s (collection: 1.951s, learning 0.132s)
             Mean action noise std: 1.91
          Mean value_function loss: 23.1637
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.2453
                       Mean reward: 790.44
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7369
    Episode_Reward/rotating_object: 155.5182
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.08s
                      Time elapsed: 00:26:23
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 47271 steps/s (collection: 1.948s, learning 0.132s)
             Mean action noise std: 1.91
          Mean value_function loss: 23.9690
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.2512
                       Mean reward: 781.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7369
    Episode_Reward/rotating_object: 154.8275
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.08s
                      Time elapsed: 00:26:25
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 46581 steps/s (collection: 1.979s, learning 0.131s)
             Mean action noise std: 1.91
          Mean value_function loss: 23.6075
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.2655
                       Mean reward: 796.22
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7393
    Episode_Reward/rotating_object: 156.1942
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.11s
                      Time elapsed: 00:26:27
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 29038 steps/s (collection: 3.253s, learning 0.132s)
             Mean action noise std: 1.92
          Mean value_function loss: 31.7877
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 36.2903
                       Mean reward: 760.11
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 0.7369
    Episode_Reward/rotating_object: 155.1514
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.39s
                      Time elapsed: 00:26:31
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 13968 steps/s (collection: 6.872s, learning 0.165s)
             Mean action noise std: 1.92
          Mean value_function loss: 24.9451
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 36.3145
                       Mean reward: 791.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 154.9882
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 7.04s
                      Time elapsed: 00:26:38
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14974 steps/s (collection: 6.432s, learning 0.133s)
             Mean action noise std: 1.92
          Mean value_function loss: 19.2180
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 36.3204
                       Mean reward: 790.94
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.7394
    Episode_Reward/rotating_object: 156.5174
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.56s
                      Time elapsed: 00:26:44
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 15309 steps/s (collection: 6.276s, learning 0.145s)
             Mean action noise std: 1.92
          Mean value_function loss: 22.1555
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 36.3240
                       Mean reward: 807.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 156.4044
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.42s
                      Time elapsed: 00:26:51
                               ETA: 00:33:18

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 15819 steps/s (collection: 6.067s, learning 0.147s)
             Mean action noise std: 1.92
          Mean value_function loss: 21.2844
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 36.3307
                       Mean reward: 792.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 156.1781
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.21s
                      Time elapsed: 00:26:57
                               ETA: 00:33:20

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14681 steps/s (collection: 6.561s, learning 0.135s)
             Mean action noise std: 1.92
          Mean value_function loss: 25.2275
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 36.3341
                       Mean reward: 783.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7318
    Episode_Reward/rotating_object: 153.0659
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.70s
                      Time elapsed: 00:27:04
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 16652 steps/s (collection: 5.782s, learning 0.122s)
             Mean action noise std: 1.92
          Mean value_function loss: 23.4276
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 36.3362
                       Mean reward: 782.50
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 155.7780
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 5.90s
                      Time elapsed: 00:27:09
                               ETA: 00:33:25

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 15630 steps/s (collection: 6.160s, learning 0.130s)
             Mean action noise std: 1.92
          Mean value_function loss: 24.5878
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.3389
                       Mean reward: 776.31
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7335
    Episode_Reward/rotating_object: 153.5069
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.29s
                      Time elapsed: 00:27:16
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 15562 steps/s (collection: 6.174s, learning 0.143s)
             Mean action noise std: 1.92
          Mean value_function loss: 26.8085
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.3539
                       Mean reward: 766.61
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 154.4196
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.32s
                      Time elapsed: 00:27:22
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 23357 steps/s (collection: 4.109s, learning 0.100s)
             Mean action noise std: 1.93
          Mean value_function loss: 25.6461
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 36.3754
                       Mean reward: 775.95
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7461
    Episode_Reward/rotating_object: 155.2260
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.21s
                      Time elapsed: 00:27:26
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 52952 steps/s (collection: 1.763s, learning 0.094s)
             Mean action noise std: 1.93
          Mean value_function loss: 20.3616
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 36.3872
                       Mean reward: 773.95
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7394
    Episode_Reward/rotating_object: 153.2775
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.86s
                      Time elapsed: 00:27:28
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 51540 steps/s (collection: 1.790s, learning 0.117s)
             Mean action noise std: 1.93
          Mean value_function loss: 24.2249
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.3979
                       Mean reward: 792.05
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 156.9823
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.91s
                      Time elapsed: 00:27:30
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 52635 steps/s (collection: 1.745s, learning 0.123s)
             Mean action noise std: 1.93
          Mean value_function loss: 17.0095
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.4097
                       Mean reward: 792.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 159.0211
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.87s
                      Time elapsed: 00:27:32
                               ETA: 00:33:20

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 49581 steps/s (collection: 1.868s, learning 0.115s)
             Mean action noise std: 1.93
          Mean value_function loss: 19.2058
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 36.4209
                       Mean reward: 789.48
               Mean episode length: 249.05
    Episode_Reward/reaching_object: 0.7367
    Episode_Reward/rotating_object: 155.9710
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.98s
                      Time elapsed: 00:27:34
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 47887 steps/s (collection: 1.942s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 26.6622
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 36.4343
                       Mean reward: 774.70
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.7399
    Episode_Reward/rotating_object: 156.5799
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.05s
                      Time elapsed: 00:27:36
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 48335 steps/s (collection: 1.911s, learning 0.123s)
             Mean action noise std: 1.93
          Mean value_function loss: 18.1125
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.4476
                       Mean reward: 804.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 158.1103
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.03s
                      Time elapsed: 00:27:38
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 23044 steps/s (collection: 3.872s, learning 0.394s)
             Mean action noise std: 1.94
          Mean value_function loss: 16.0181
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.4569
                       Mean reward: 789.32
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7413
    Episode_Reward/rotating_object: 156.8656
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 4.27s
                      Time elapsed: 00:27:42
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 17512 steps/s (collection: 5.304s, learning 0.309s)
             Mean action noise std: 1.94
          Mean value_function loss: 17.4774
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 36.4663
                       Mean reward: 799.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7387
    Episode_Reward/rotating_object: 155.2613
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 5.61s
                      Time elapsed: 00:27:48
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 19530 steps/s (collection: 4.710s, learning 0.323s)
             Mean action noise std: 1.94
          Mean value_function loss: 27.1699
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.4749
                       Mean reward: 798.25
               Mean episode length: 248.44
    Episode_Reward/reaching_object: 0.7422
    Episode_Reward/rotating_object: 156.1241
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 5.03s
                      Time elapsed: 00:27:53
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 21835 steps/s (collection: 4.184s, learning 0.318s)
             Mean action noise std: 1.94
          Mean value_function loss: 28.6531
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 36.4838
                       Mean reward: 790.59
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.7369
    Episode_Reward/rotating_object: 155.1377
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 4.50s
                      Time elapsed: 00:27:57
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 21462 steps/s (collection: 4.171s, learning 0.409s)
             Mean action noise std: 1.94
          Mean value_function loss: 28.9623
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 36.5066
                       Mean reward: 734.49
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 153.1899
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 4.58s
                      Time elapsed: 00:28:02
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 19363 steps/s (collection: 4.675s, learning 0.402s)
             Mean action noise std: 1.94
          Mean value_function loss: 23.8613
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.5240
                       Mean reward: 784.15
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7375
    Episode_Reward/rotating_object: 154.4994
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 5.08s
                      Time elapsed: 00:28:07
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 17504 steps/s (collection: 5.272s, learning 0.344s)
             Mean action noise std: 1.95
          Mean value_function loss: 28.0505
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.5346
                       Mean reward: 757.73
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 154.9237
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 5.62s
                      Time elapsed: 00:28:13
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 21471 steps/s (collection: 4.224s, learning 0.355s)
             Mean action noise std: 1.95
          Mean value_function loss: 30.5416
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.5448
                       Mean reward: 790.61
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 0.7408
    Episode_Reward/rotating_object: 155.6982
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 4.58s
                      Time elapsed: 00:28:17
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 22144 steps/s (collection: 4.142s, learning 0.298s)
             Mean action noise std: 1.95
          Mean value_function loss: 25.4559
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 36.5591
                       Mean reward: 788.57
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 156.5925
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 4.44s
                      Time elapsed: 00:28:22
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 25570 steps/s (collection: 3.597s, learning 0.247s)
             Mean action noise std: 1.95
          Mean value_function loss: 21.0346
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 36.5734
                       Mean reward: 783.17
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 158.0508
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 3.84s
                      Time elapsed: 00:28:26
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 26729 steps/s (collection: 3.460s, learning 0.218s)
             Mean action noise std: 1.95
          Mean value_function loss: 25.7862
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 36.5839
                       Mean reward: 779.61
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 156.7628
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 3.68s
                      Time elapsed: 00:28:29
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 25553 steps/s (collection: 3.539s, learning 0.308s)
             Mean action noise std: 1.95
          Mean value_function loss: 20.7753
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.5908
                       Mean reward: 765.47
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7426
    Episode_Reward/rotating_object: 155.3460
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 3.85s
                      Time elapsed: 00:28:33
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 26308 steps/s (collection: 3.470s, learning 0.266s)
             Mean action noise std: 1.95
          Mean value_function loss: 22.4873
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 36.5925
                       Mean reward: 766.85
               Mean episode length: 249.33
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 156.0892
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 3.74s
                      Time elapsed: 00:28:37
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 24354 steps/s (collection: 3.755s, learning 0.281s)
             Mean action noise std: 1.95
          Mean value_function loss: 22.7353
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 36.5934
                       Mean reward: 780.18
               Mean episode length: 244.51
    Episode_Reward/reaching_object: 0.7424
    Episode_Reward/rotating_object: 156.7612
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 4.04s
                      Time elapsed: 00:28:41
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 22171 steps/s (collection: 4.174s, learning 0.260s)
             Mean action noise std: 1.96
          Mean value_function loss: 17.9245
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 36.5964
                       Mean reward: 798.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 158.3888
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 4.43s
                      Time elapsed: 00:28:45
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 26546 steps/s (collection: 3.456s, learning 0.247s)
             Mean action noise std: 1.96
          Mean value_function loss: 17.9440
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 36.6018
                       Mean reward: 780.72
               Mean episode length: 246.79
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 155.3978
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 3.70s
                      Time elapsed: 00:28:49
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 28158 steps/s (collection: 3.245s, learning 0.246s)
             Mean action noise std: 1.96
          Mean value_function loss: 20.1092
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.6146
                       Mean reward: 799.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 155.4413
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 3.49s
                      Time elapsed: 00:28:52
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 26691 steps/s (collection: 3.422s, learning 0.261s)
             Mean action noise std: 1.96
          Mean value_function loss: 22.2686
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.6205
                       Mean reward: 781.84
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 157.1888
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 3.68s
                      Time elapsed: 00:28:56
                               ETA: 00:33:07

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 28192 steps/s (collection: 3.279s, learning 0.207s)
             Mean action noise std: 1.96
          Mean value_function loss: 17.0448
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.6257
                       Mean reward: 774.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 157.1081
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 3.49s
                      Time elapsed: 00:29:00
                               ETA: 00:33:05

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 27186 steps/s (collection: 3.368s, learning 0.248s)
             Mean action noise std: 1.96
          Mean value_function loss: 25.5693
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 36.6386
                       Mean reward: 782.14
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 157.5096
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 3.62s
                      Time elapsed: 00:29:03
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 28029 steps/s (collection: 3.270s, learning 0.237s)
             Mean action noise std: 1.96
          Mean value_function loss: 14.9410
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 36.6495
                       Mean reward: 784.29
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 158.7112
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 3.51s
                      Time elapsed: 00:29:07
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 25244 steps/s (collection: 3.659s, learning 0.235s)
             Mean action noise std: 1.96
          Mean value_function loss: 25.6689
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.6543
                       Mean reward: 782.54
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 157.1370
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 3.89s
                      Time elapsed: 00:29:11
                               ETA: 00:33:02

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 26126 steps/s (collection: 3.518s, learning 0.245s)
             Mean action noise std: 1.97
          Mean value_function loss: 21.0996
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.6634
                       Mean reward: 788.11
               Mean episode length: 249.95
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 156.9759
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 3.76s
                      Time elapsed: 00:29:14
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 25950 steps/s (collection: 3.557s, learning 0.231s)
             Mean action noise std: 1.97
          Mean value_function loss: 24.0307
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.6820
                       Mean reward: 792.96
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7471
    Episode_Reward/rotating_object: 157.1871
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 3.79s
                      Time elapsed: 00:29:18
                               ETA: 00:33:00

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 28223 steps/s (collection: 3.210s, learning 0.273s)
             Mean action noise std: 1.97
          Mean value_function loss: 19.9597
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.7073
                       Mean reward: 798.80
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 157.7265
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 3.48s
                      Time elapsed: 00:29:22
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 24954 steps/s (collection: 3.693s, learning 0.246s)
             Mean action noise std: 1.97
          Mean value_function loss: 32.2886
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.7208
                       Mean reward: 757.22
               Mean episode length: 244.99
    Episode_Reward/reaching_object: 0.7380
    Episode_Reward/rotating_object: 154.7055
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 3.94s
                      Time elapsed: 00:29:26
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 21246 steps/s (collection: 4.337s, learning 0.290s)
             Mean action noise std: 1.97
          Mean value_function loss: 18.2891
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.7270
                       Mean reward: 785.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 155.7269
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 4.63s
                      Time elapsed: 00:29:30
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 24495 steps/s (collection: 3.731s, learning 0.282s)
             Mean action noise std: 1.97
          Mean value_function loss: 28.5226
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.7342
                       Mean reward: 780.77
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.7447
    Episode_Reward/rotating_object: 156.4820
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 4.01s
                      Time elapsed: 00:29:34
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 23942 steps/s (collection: 3.747s, learning 0.359s)
             Mean action noise std: 1.98
          Mean value_function loss: 28.5064
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 36.7492
                       Mean reward: 794.08
               Mean episode length: 248.78
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 157.1826
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 4.11s
                      Time elapsed: 00:29:38
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 23599 steps/s (collection: 3.788s, learning 0.378s)
             Mean action noise std: 1.98
          Mean value_function loss: 32.1542
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 36.7651
                       Mean reward: 768.52
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 156.1040
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 4.17s
                      Time elapsed: 00:29:43
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 23202 steps/s (collection: 3.910s, learning 0.326s)
             Mean action noise std: 1.98
          Mean value_function loss: 27.4439
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 36.7755
                       Mean reward: 782.76
               Mean episode length: 249.00
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 154.6391
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 4.24s
                      Time elapsed: 00:29:47
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 23869 steps/s (collection: 3.826s, learning 0.293s)
             Mean action noise std: 1.98
          Mean value_function loss: 15.1661
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 36.7828
                       Mean reward: 766.11
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 155.4242
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 4.12s
                      Time elapsed: 00:29:51
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 22280 steps/s (collection: 4.057s, learning 0.355s)
             Mean action noise std: 1.98
          Mean value_function loss: 24.1193
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.7838
                       Mean reward: 790.88
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 156.3894
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 4.41s
                      Time elapsed: 00:29:55
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 21023 steps/s (collection: 4.367s, learning 0.309s)
             Mean action noise std: 1.98
          Mean value_function loss: 23.0956
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.7915
                       Mean reward: 808.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7530
    Episode_Reward/rotating_object: 158.4779
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 4.68s
                      Time elapsed: 00:30:00
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 22659 steps/s (collection: 4.032s, learning 0.307s)
             Mean action noise std: 1.99
          Mean value_function loss: 19.9292
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.8107
                       Mean reward: 784.15
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 156.7853
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 4.34s
                      Time elapsed: 00:30:04
                               ETA: 00:32:53

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 24209 steps/s (collection: 3.756s, learning 0.304s)
             Mean action noise std: 1.99
          Mean value_function loss: 20.8834
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.8318
                       Mean reward: 800.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 158.2124
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 4.06s
                      Time elapsed: 00:30:08
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 23428 steps/s (collection: 3.702s, learning 0.494s)
             Mean action noise std: 1.99
          Mean value_function loss: 21.5795
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 36.8461
                       Mean reward: 780.47
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7457
    Episode_Reward/rotating_object: 156.7947
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 4.20s
                      Time elapsed: 00:30:13
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 20881 steps/s (collection: 4.390s, learning 0.318s)
             Mean action noise std: 1.99
          Mean value_function loss: 22.6259
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.8573
                       Mean reward: 803.44
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7487
    Episode_Reward/rotating_object: 156.6090
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 4.71s
                      Time elapsed: 00:30:17
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 20634 steps/s (collection: 4.325s, learning 0.439s)
             Mean action noise std: 1.99
          Mean value_function loss: 22.6029
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.8687
                       Mean reward: 764.02
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 154.8619
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 4.76s
                      Time elapsed: 00:30:22
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 21073 steps/s (collection: 4.307s, learning 0.358s)
             Mean action noise std: 1.99
          Mean value_function loss: 27.6777
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.8744
                       Mean reward: 782.82
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 158.1971
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 4.66s
                      Time elapsed: 00:30:27
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 22154 steps/s (collection: 4.094s, learning 0.343s)
             Mean action noise std: 2.00
          Mean value_function loss: 22.2071
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.8915
                       Mean reward: 812.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7557
    Episode_Reward/rotating_object: 157.3331
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 4.44s
                      Time elapsed: 00:30:31
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 20942 steps/s (collection: 4.335s, learning 0.359s)
             Mean action noise std: 2.00
          Mean value_function loss: 28.8319
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 36.9086
                       Mean reward: 756.41
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 0.7532
    Episode_Reward/rotating_object: 156.5263
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 4.69s
                      Time elapsed: 00:30:36
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 21717 steps/s (collection: 4.199s, learning 0.327s)
             Mean action noise std: 2.00
          Mean value_function loss: 22.8620
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.9161
                       Mean reward: 770.48
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 156.1035
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 4.53s
                      Time elapsed: 00:30:40
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 22288 steps/s (collection: 4.055s, learning 0.355s)
             Mean action noise std: 2.00
          Mean value_function loss: 27.8135
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 36.9295
                       Mean reward: 791.31
               Mean episode length: 246.95
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 157.2416
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 4.41s
                      Time elapsed: 00:30:45
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 21090 steps/s (collection: 4.299s, learning 0.362s)
             Mean action noise std: 2.00
          Mean value_function loss: 21.7951
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.9431
                       Mean reward: 777.04
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 158.9868
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 4.66s
                      Time elapsed: 00:30:49
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 21369 steps/s (collection: 4.238s, learning 0.363s)
             Mean action noise std: 2.01
          Mean value_function loss: 19.0883
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 36.9638
                       Mean reward: 804.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 156.2129
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 4.60s
                      Time elapsed: 00:30:54
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 23351 steps/s (collection: 3.941s, learning 0.269s)
             Mean action noise std: 2.01
          Mean value_function loss: 19.2963
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 36.9754
                       Mean reward: 807.40
               Mean episode length: 248.29
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 160.8061
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 4.21s
                      Time elapsed: 00:30:58
                               ETA: 00:32:48

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 24642 steps/s (collection: 3.682s, learning 0.307s)
             Mean action noise std: 2.01
          Mean value_function loss: 17.6340
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.9812
                       Mean reward: 806.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 156.3057
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 3.99s
                      Time elapsed: 00:31:02
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 26116 steps/s (collection: 3.493s, learning 0.271s)
             Mean action noise std: 2.01
          Mean value_function loss: 20.6159
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 36.9906
                       Mean reward: 752.30
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 156.1294
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 3.76s
                      Time elapsed: 00:31:06
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 21564 steps/s (collection: 4.001s, learning 0.557s)
             Mean action noise std: 2.01
          Mean value_function loss: 20.3220
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 37.0046
                       Mean reward: 775.67
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 156.8811
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 4.56s
                      Time elapsed: 00:31:11
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 17976 steps/s (collection: 5.212s, learning 0.256s)
             Mean action noise std: 2.01
          Mean value_function loss: 16.4679
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.0177
                       Mean reward: 792.38
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 158.2538
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 5.47s
                      Time elapsed: 00:31:16
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 18379 steps/s (collection: 4.899s, learning 0.449s)
             Mean action noise std: 2.01
          Mean value_function loss: 24.6655
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.0315
                       Mean reward: 806.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 159.5744
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 5.35s
                      Time elapsed: 00:31:21
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 18385 steps/s (collection: 5.042s, learning 0.305s)
             Mean action noise std: 2.02
          Mean value_function loss: 22.8733
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 37.0444
                       Mean reward: 753.29
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.7342
    Episode_Reward/rotating_object: 151.9560
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 5.35s
                      Time elapsed: 00:31:27
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 23332 steps/s (collection: 3.932s, learning 0.281s)
             Mean action noise std: 2.02
          Mean value_function loss: 20.1559
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.0561
                       Mean reward: 799.68
               Mean episode length: 246.66
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 158.2875
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 4.21s
                      Time elapsed: 00:31:31
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 23702 steps/s (collection: 3.853s, learning 0.294s)
             Mean action noise std: 2.02
          Mean value_function loss: 30.4712
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.0716
                       Mean reward: 792.97
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 157.6123
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 4.15s
                      Time elapsed: 00:31:35
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 23474 steps/s (collection: 3.800s, learning 0.388s)
             Mean action noise std: 2.02
          Mean value_function loss: 20.6221
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.0912
                       Mean reward: 809.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 159.8083
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 4.19s
                      Time elapsed: 00:31:39
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 20650 steps/s (collection: 4.387s, learning 0.374s)
             Mean action noise std: 2.02
          Mean value_function loss: 25.5440
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 37.1045
                       Mean reward: 756.47
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 157.0544
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 4.76s
                      Time elapsed: 00:31:44
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 22991 steps/s (collection: 3.876s, learning 0.399s)
             Mean action noise std: 2.02
          Mean value_function loss: 17.5754
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.1113
                       Mean reward: 796.34
               Mean episode length: 249.99
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 157.6148
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 4.28s
                      Time elapsed: 00:31:48
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 22028 steps/s (collection: 4.061s, learning 0.401s)
             Mean action noise std: 2.03
          Mean value_function loss: 28.4605
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.1209
                       Mean reward: 778.96
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 155.8930
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 4.46s
                      Time elapsed: 00:31:53
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 24864 steps/s (collection: 3.616s, learning 0.338s)
             Mean action noise std: 2.03
          Mean value_function loss: 19.0056
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.1292
                       Mean reward: 791.12
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 159.2463
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 3.95s
                      Time elapsed: 00:31:57
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 19340 steps/s (collection: 4.576s, learning 0.507s)
             Mean action noise std: 2.03
          Mean value_function loss: 25.1383
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.1353
                       Mean reward: 791.56
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 158.5586
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 5.08s
                      Time elapsed: 00:32:02
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 20866 steps/s (collection: 4.360s, learning 0.351s)
             Mean action noise std: 2.03
          Mean value_function loss: 22.3100
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 37.1446
                       Mean reward: 775.24
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.7428
    Episode_Reward/rotating_object: 156.2354
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 4.71s
                      Time elapsed: 00:32:07
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 20161 steps/s (collection: 4.419s, learning 0.457s)
             Mean action noise std: 2.03
          Mean value_function loss: 20.0376
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.1472
                       Mean reward: 756.05
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 156.6774
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 4.88s
                      Time elapsed: 00:32:11
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 20979 steps/s (collection: 4.293s, learning 0.392s)
             Mean action noise std: 2.03
          Mean value_function loss: 23.1626
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.1553
                       Mean reward: 780.62
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7503
    Episode_Reward/rotating_object: 157.1442
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 4.69s
                      Time elapsed: 00:32:16
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 19371 steps/s (collection: 4.760s, learning 0.314s)
             Mean action noise std: 2.03
          Mean value_function loss: 22.3132
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.1626
                       Mean reward: 808.94
               Mean episode length: 249.90
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 155.6106
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 5.07s
                      Time elapsed: 00:32:21
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 20819 steps/s (collection: 4.391s, learning 0.331s)
             Mean action noise std: 2.03
          Mean value_function loss: 16.7479
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.1697
                       Mean reward: 810.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 158.8122
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 4.72s
                      Time elapsed: 00:32:26
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 19989 steps/s (collection: 4.629s, learning 0.289s)
             Mean action noise std: 2.04
          Mean value_function loss: 19.6682
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 37.1780
                       Mean reward: 808.72
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7541
    Episode_Reward/rotating_object: 160.9985
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 4.92s
                      Time elapsed: 00:32:31
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 20604 steps/s (collection: 4.300s, learning 0.471s)
             Mean action noise std: 2.04
          Mean value_function loss: 23.0887
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 37.1818
                       Mean reward: 798.01
               Mean episode length: 248.47
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 158.3012
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 4.77s
                      Time elapsed: 00:32:36
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 20658 steps/s (collection: 4.310s, learning 0.449s)
             Mean action noise std: 2.04
          Mean value_function loss: 17.6194
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 37.1865
                       Mean reward: 780.72
               Mean episode length: 248.94
    Episode_Reward/reaching_object: 0.7539
    Episode_Reward/rotating_object: 157.2322
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 4.76s
                      Time elapsed: 00:32:40
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 21809 steps/s (collection: 4.107s, learning 0.400s)
             Mean action noise std: 2.04
          Mean value_function loss: 24.9395
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.1995
                       Mean reward: 807.26
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 159.4934
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 4.51s
                      Time elapsed: 00:32:45
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 20617 steps/s (collection: 4.411s, learning 0.357s)
             Mean action noise std: 2.04
          Mean value_function loss: 21.7730
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.2157
                       Mean reward: 811.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 158.8571
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 4.77s
                      Time elapsed: 00:32:50
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 20664 steps/s (collection: 4.384s, learning 0.373s)
             Mean action noise std: 2.04
          Mean value_function loss: 22.3316
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 37.2208
                       Mean reward: 802.37
               Mean episode length: 249.68
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 158.8902
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 4.76s
                      Time elapsed: 00:32:54
                               ETA: 00:32:36

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 21178 steps/s (collection: 4.221s, learning 0.421s)
             Mean action noise std: 2.04
          Mean value_function loss: 26.4324
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.2241
                       Mean reward: 766.70
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 156.7460
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 4.64s
                      Time elapsed: 00:32:59
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 18608 steps/s (collection: 4.916s, learning 0.367s)
             Mean action noise std: 2.04
          Mean value_function loss: 20.1589
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.2345
                       Mean reward: 784.89
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 158.0750
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 5.28s
                      Time elapsed: 00:33:04
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 20803 steps/s (collection: 4.298s, learning 0.428s)
             Mean action noise std: 2.05
          Mean value_function loss: 22.8518
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.2571
                       Mean reward: 788.03
               Mean episode length: 244.93
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 158.8451
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 4.73s
                      Time elapsed: 00:33:09
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 20793 steps/s (collection: 4.402s, learning 0.326s)
             Mean action noise std: 2.05
          Mean value_function loss: 19.5669
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 37.2851
                       Mean reward: 792.35
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7540
    Episode_Reward/rotating_object: 159.2502
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 4.73s
                      Time elapsed: 00:33:14
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 21529 steps/s (collection: 4.210s, learning 0.356s)
             Mean action noise std: 2.05
          Mean value_function loss: 18.4777
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 37.2918
                       Mean reward: 782.56
               Mean episode length: 246.90
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 159.6341
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 4.57s
                      Time elapsed: 00:33:18
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 21036 steps/s (collection: 4.344s, learning 0.329s)
             Mean action noise std: 2.05
          Mean value_function loss: 20.8064
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.3010
                       Mean reward: 783.26
               Mean episode length: 247.25
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 156.9154
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 4.67s
                      Time elapsed: 00:33:23
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 22193 steps/s (collection: 4.017s, learning 0.413s)
             Mean action noise std: 2.05
          Mean value_function loss: 23.8713
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 37.3124
                       Mean reward: 786.42
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 157.8467
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 4.43s
                      Time elapsed: 00:33:27
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 21737 steps/s (collection: 4.139s, learning 0.383s)
             Mean action noise std: 2.06
          Mean value_function loss: 23.7015
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.3259
                       Mean reward: 801.10
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 159.7895
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 4.52s
                      Time elapsed: 00:33:32
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 20766 steps/s (collection: 4.410s, learning 0.324s)
             Mean action noise std: 2.06
          Mean value_function loss: 20.0896
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.3416
                       Mean reward: 796.05
               Mean episode length: 247.45
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 160.2094
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 4.73s
                      Time elapsed: 00:33:37
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 20528 steps/s (collection: 4.476s, learning 0.313s)
             Mean action noise std: 2.06
          Mean value_function loss: 20.5881
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.3574
                       Mean reward: 790.23
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 158.0693
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 4.79s
                      Time elapsed: 00:33:41
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 21676 steps/s (collection: 4.079s, learning 0.456s)
             Mean action noise std: 2.06
          Mean value_function loss: 20.5171
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 37.3711
                       Mean reward: 803.45
               Mean episode length: 246.24
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 158.6356
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 4.53s
                      Time elapsed: 00:33:46
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 22058 steps/s (collection: 4.204s, learning 0.252s)
             Mean action noise std: 2.06
          Mean value_function loss: 18.5561
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.3765
                       Mean reward: 776.29
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7488
    Episode_Reward/rotating_object: 157.2090
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 4.46s
                      Time elapsed: 00:33:50
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 20687 steps/s (collection: 4.390s, learning 0.362s)
             Mean action noise std: 2.06
          Mean value_function loss: 23.2052
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.3870
                       Mean reward: 792.87
               Mean episode length: 245.15
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 158.0688
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 4.75s
                      Time elapsed: 00:33:55
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 23830 steps/s (collection: 3.715s, learning 0.410s)
             Mean action noise std: 2.06
          Mean value_function loss: 30.5204
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.3943
                       Mean reward: 788.81
               Mean episode length: 246.67
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 156.5677
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 4.13s
                      Time elapsed: 00:33:59
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 24265 steps/s (collection: 3.644s, learning 0.407s)
             Mean action noise std: 2.07
          Mean value_function loss: 23.2071
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.4048
                       Mean reward: 808.26
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 161.0316
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 4.05s
                      Time elapsed: 00:34:03
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 22487 steps/s (collection: 4.084s, learning 0.288s)
             Mean action noise std: 2.07
          Mean value_function loss: 23.1923
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.4151
                       Mean reward: 816.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 159.7717
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 4.37s
                      Time elapsed: 00:34:08
                               ETA: 00:32:24

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 20363 steps/s (collection: 4.485s, learning 0.342s)
             Mean action noise std: 2.07
          Mean value_function loss: 19.1578
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 37.4219
                       Mean reward: 800.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 157.9672
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 4.83s
                      Time elapsed: 00:34:13
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 23626 steps/s (collection: 3.874s, learning 0.287s)
             Mean action noise std: 2.07
          Mean value_function loss: 19.5061
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 37.4247
                       Mean reward: 790.96
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 160.1338
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 4.16s
                      Time elapsed: 00:34:17
                               ETA: 00:32:22

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 22561 steps/s (collection: 4.032s, learning 0.325s)
             Mean action noise std: 2.07
          Mean value_function loss: 16.8311
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 37.4254
                       Mean reward: 794.26
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 157.6466
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 4.36s
                      Time elapsed: 00:34:21
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 20782 steps/s (collection: 4.401s, learning 0.329s)
             Mean action noise std: 2.07
          Mean value_function loss: 23.0914
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.4266
                       Mean reward: 798.19
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 158.3578
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 4.73s
                      Time elapsed: 00:34:26
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 23348 steps/s (collection: 3.931s, learning 0.280s)
             Mean action noise std: 2.07
          Mean value_function loss: 22.5958
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.4334
                       Mean reward: 795.86
               Mean episode length: 249.45
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 157.8558
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 4.21s
                      Time elapsed: 00:34:30
                               ETA: 00:32:19

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 24382 steps/s (collection: 3.764s, learning 0.268s)
             Mean action noise std: 2.07
          Mean value_function loss: 19.5354
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.4452
                       Mean reward: 802.75
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7452
    Episode_Reward/rotating_object: 157.8636
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 4.03s
                      Time elapsed: 00:34:34
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 24298 steps/s (collection: 3.787s, learning 0.259s)
             Mean action noise std: 2.07
          Mean value_function loss: 27.6242
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.4527
                       Mean reward: 790.11
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 158.0258
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 4.05s
                      Time elapsed: 00:34:38
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 24075 steps/s (collection: 3.771s, learning 0.312s)
             Mean action noise std: 2.07
          Mean value_function loss: 19.3522
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 37.4620
                       Mean reward: 804.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 159.3239
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 4.08s
                      Time elapsed: 00:34:42
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 24368 steps/s (collection: 3.723s, learning 0.311s)
             Mean action noise std: 2.08
          Mean value_function loss: 15.2712
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.4697
                       Mean reward: 785.30
               Mean episode length: 244.89
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 157.9430
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 4.03s
                      Time elapsed: 00:34:46
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 21914 steps/s (collection: 3.958s, learning 0.528s)
             Mean action noise std: 2.08
          Mean value_function loss: 21.0057
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 37.4847
                       Mean reward: 800.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7489
    Episode_Reward/rotating_object: 157.0280
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 4.49s
                      Time elapsed: 00:34:51
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 21969 steps/s (collection: 4.169s, learning 0.306s)
             Mean action noise std: 2.08
          Mean value_function loss: 20.4802
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.4983
                       Mean reward: 781.47
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 159.0021
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 4.47s
                      Time elapsed: 00:34:55
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 21253 steps/s (collection: 4.239s, learning 0.386s)
             Mean action noise std: 2.08
          Mean value_function loss: 15.1301
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.5120
                       Mean reward: 800.81
               Mean episode length: 246.98
    Episode_Reward/reaching_object: 0.7543
    Episode_Reward/rotating_object: 159.9605
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 4.63s
                      Time elapsed: 00:35:00
                               ETA: 00:32:11

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 18852 steps/s (collection: 4.860s, learning 0.354s)
             Mean action noise std: 2.08
          Mean value_function loss: 15.8475
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 37.5265
                       Mean reward: 788.08
               Mean episode length: 248.46
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 158.9190
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 5.21s
                      Time elapsed: 00:35:05
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 21331 steps/s (collection: 4.140s, learning 0.468s)
             Mean action noise std: 2.09
          Mean value_function loss: 24.0963
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.5429
                       Mean reward: 807.83
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 157.1722
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 4.61s
                      Time elapsed: 00:35:10
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 21205 steps/s (collection: 4.360s, learning 0.275s)
             Mean action noise std: 2.09
          Mean value_function loss: 22.0283
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.5681
                       Mean reward: 791.12
               Mean episode length: 249.71
    Episode_Reward/reaching_object: 0.7417
    Episode_Reward/rotating_object: 156.1078
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 4.64s
                      Time elapsed: 00:35:14
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 22663 steps/s (collection: 3.928s, learning 0.410s)
             Mean action noise std: 2.09
          Mean value_function loss: 13.4029
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.5817
                       Mean reward: 814.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7530
    Episode_Reward/rotating_object: 161.0705
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 4.34s
                      Time elapsed: 00:35:19
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 22771 steps/s (collection: 4.071s, learning 0.246s)
             Mean action noise std: 2.09
          Mean value_function loss: 25.0866
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 37.5875
                       Mean reward: 767.14
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 0.7497
    Episode_Reward/rotating_object: 158.7389
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 4.32s
                      Time elapsed: 00:35:23
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 28339 steps/s (collection: 3.224s, learning 0.245s)
             Mean action noise std: 2.09
          Mean value_function loss: 15.8068
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.5954
                       Mean reward: 798.41
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7463
    Episode_Reward/rotating_object: 159.1274
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 3.47s
                      Time elapsed: 00:35:26
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 28247 steps/s (collection: 3.208s, learning 0.272s)
             Mean action noise std: 2.09
          Mean value_function loss: 30.0809
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.6084
                       Mean reward: 797.03
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 158.0706
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 3.48s
                      Time elapsed: 00:35:30
                               ETA: 00:32:02

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 26511 steps/s (collection: 3.474s, learning 0.234s)
             Mean action noise std: 2.10
          Mean value_function loss: 30.1224
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.6215
                       Mean reward: 754.20
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 155.4314
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 3.71s
                      Time elapsed: 00:35:34
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 26474 steps/s (collection: 3.361s, learning 0.352s)
             Mean action noise std: 2.10
          Mean value_function loss: 20.8830
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.6299
                       Mean reward: 801.98
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 158.8148
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 3.71s
                      Time elapsed: 00:35:37
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 26472 steps/s (collection: 3.495s, learning 0.218s)
             Mean action noise std: 2.10
          Mean value_function loss: 22.0953
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.6400
                       Mean reward: 788.41
               Mean episode length: 248.63
    Episode_Reward/reaching_object: 0.7534
    Episode_Reward/rotating_object: 160.4829
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 3.71s
                      Time elapsed: 00:35:41
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 26402 steps/s (collection: 3.494s, learning 0.229s)
             Mean action noise std: 2.10
          Mean value_function loss: 24.7901
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.6549
                       Mean reward: 779.22
               Mean episode length: 244.34
    Episode_Reward/reaching_object: 0.7505
    Episode_Reward/rotating_object: 159.8715
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 3.72s
                      Time elapsed: 00:35:45
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 27693 steps/s (collection: 3.287s, learning 0.263s)
             Mean action noise std: 2.10
          Mean value_function loss: 23.0780
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 37.6649
                       Mean reward: 801.72
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 158.9007
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 3.55s
                      Time elapsed: 00:35:48
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 27709 steps/s (collection: 3.293s, learning 0.255s)
             Mean action noise std: 2.10
          Mean value_function loss: 21.1996
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.6701
                       Mean reward: 796.84
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 157.4215
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 3.55s
                      Time elapsed: 00:35:52
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 26968 steps/s (collection: 3.388s, learning 0.258s)
             Mean action noise std: 2.11
          Mean value_function loss: 28.5499
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 37.6849
                       Mean reward: 776.76
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 0.7380
    Episode_Reward/rotating_object: 156.7605
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 3.65s
                      Time elapsed: 00:35:55
                               ETA: 00:31:49

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 27010 steps/s (collection: 3.367s, learning 0.273s)
             Mean action noise std: 2.11
          Mean value_function loss: 17.9439
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 37.7022
                       Mean reward: 793.00
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 158.8032
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 3.64s
                      Time elapsed: 00:35:59
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 23510 steps/s (collection: 3.952s, learning 0.229s)
             Mean action noise std: 2.11
          Mean value_function loss: 24.7264
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 37.7146
                       Mean reward: 795.95
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7413
    Episode_Reward/rotating_object: 154.8271
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 4.18s
                      Time elapsed: 00:36:03
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 24856 steps/s (collection: 3.683s, learning 0.272s)
             Mean action noise std: 2.11
          Mean value_function loss: 22.2507
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 37.7214
                       Mean reward: 805.34
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 158.8973
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 3.95s
                      Time elapsed: 00:36:07
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 24749 steps/s (collection: 3.737s, learning 0.235s)
             Mean action noise std: 2.11
          Mean value_function loss: 29.5535
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.7315
                       Mean reward: 771.43
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 0.7420
    Episode_Reward/rotating_object: 157.1207
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 3.97s
                      Time elapsed: 00:36:11
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 25098 steps/s (collection: 3.691s, learning 0.226s)
             Mean action noise std: 2.11
          Mean value_function loss: 24.3665
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 37.7409
                       Mean reward: 800.71
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7489
    Episode_Reward/rotating_object: 158.6305
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 3.92s
                      Time elapsed: 00:36:15
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 27043 steps/s (collection: 3.415s, learning 0.220s)
             Mean action noise std: 2.11
          Mean value_function loss: 26.8719
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.7477
                       Mean reward: 820.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 158.3800
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 3.64s
                      Time elapsed: 00:36:19
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 23114 steps/s (collection: 3.750s, learning 0.503s)
             Mean action noise std: 2.11
          Mean value_function loss: 27.5724
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 37.7547
                       Mean reward: 807.36
               Mean episode length: 248.53
    Episode_Reward/reaching_object: 0.7463
    Episode_Reward/rotating_object: 157.6247
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 4.25s
                      Time elapsed: 00:36:23
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 19179 steps/s (collection: 4.782s, learning 0.343s)
             Mean action noise std: 2.12
          Mean value_function loss: 25.8211
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.7676
                       Mean reward: 815.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 158.2682
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 5.13s
                      Time elapsed: 00:36:28
                               ETA: 00:31:37

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 20775 steps/s (collection: 4.246s, learning 0.486s)
             Mean action noise std: 2.12
          Mean value_function loss: 21.8123
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.7823
                       Mean reward: 811.66
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 158.8179
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 4.73s
                      Time elapsed: 00:36:33
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 22257 steps/s (collection: 4.072s, learning 0.344s)
             Mean action noise std: 2.12
          Mean value_function loss: 23.8489
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 37.7896
                       Mean reward: 821.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 159.3346
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 4.42s
                      Time elapsed: 00:36:37
                               ETA: 00:31:35

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 21309 steps/s (collection: 4.285s, learning 0.328s)
             Mean action noise std: 2.12
          Mean value_function loss: 21.1771
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.8024
                       Mean reward: 807.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 157.1394
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 4.61s
                      Time elapsed: 00:36:42
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 21482 steps/s (collection: 4.249s, learning 0.327s)
             Mean action noise std: 2.12
          Mean value_function loss: 20.7908
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.8253
                       Mean reward: 814.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7540
    Episode_Reward/rotating_object: 160.0202
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 4.58s
                      Time elapsed: 00:36:47
                               ETA: 00:31:32

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 21880 steps/s (collection: 4.168s, learning 0.325s)
             Mean action noise std: 2.13
          Mean value_function loss: 18.6167
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.8454
                       Mean reward: 797.46
               Mean episode length: 244.64
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 159.7279
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 4.49s
                      Time elapsed: 00:36:51
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 20437 steps/s (collection: 4.450s, learning 0.360s)
             Mean action noise std: 2.13
          Mean value_function loss: 29.3632
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.8612
                       Mean reward: 790.34
               Mean episode length: 247.34
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 156.7734
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 4.81s
                      Time elapsed: 00:36:56
                               ETA: 00:31:30

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 19271 steps/s (collection: 4.716s, learning 0.385s)
             Mean action noise std: 2.13
          Mean value_function loss: 18.2594
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.8734
                       Mean reward: 802.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 158.8152
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 5.10s
                      Time elapsed: 00:37:01
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 20212 steps/s (collection: 4.470s, learning 0.394s)
             Mean action noise std: 2.13
          Mean value_function loss: 23.5794
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 37.8806
                       Mean reward: 787.54
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 158.2862
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 4.86s
                      Time elapsed: 00:37:06
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 21783 steps/s (collection: 4.189s, learning 0.324s)
             Mean action noise std: 2.13
          Mean value_function loss: 17.2567
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 37.8826
                       Mean reward: 807.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 159.9334
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 4.51s
                      Time elapsed: 00:37:10
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 21158 steps/s (collection: 4.198s, learning 0.448s)
             Mean action noise std: 2.13
          Mean value_function loss: 26.4466
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 37.8842
                       Mean reward: 777.85
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 156.9589
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 4.65s
                      Time elapsed: 00:37:15
                               ETA: 00:31:26

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 21100 steps/s (collection: 4.144s, learning 0.515s)
             Mean action noise std: 2.13
          Mean value_function loss: 25.9317
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 37.8856
                       Mean reward: 808.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 159.6700
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 4.66s
                      Time elapsed: 00:37:20
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 21556 steps/s (collection: 4.226s, learning 0.335s)
             Mean action noise std: 2.13
          Mean value_function loss: 23.4486
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 37.8877
                       Mean reward: 791.22
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.7491
    Episode_Reward/rotating_object: 159.0506
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 4.56s
                      Time elapsed: 00:37:24
                               ETA: 00:31:24

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 20818 steps/s (collection: 4.330s, learning 0.392s)
             Mean action noise std: 2.13
          Mean value_function loss: 19.6342
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.8928
                       Mean reward: 819.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 159.0693
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 4.72s
                      Time elapsed: 00:37:29
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 20955 steps/s (collection: 4.342s, learning 0.349s)
             Mean action noise std: 2.13
          Mean value_function loss: 21.4243
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.9056
                       Mean reward: 785.93
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 156.2424
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 4.69s
                      Time elapsed: 00:37:34
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 21937 steps/s (collection: 4.171s, learning 0.311s)
             Mean action noise std: 2.14
          Mean value_function loss: 29.1510
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 37.9247
                       Mean reward: 775.29
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 156.0823
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 4.48s
                      Time elapsed: 00:37:38
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 19167 steps/s (collection: 4.775s, learning 0.353s)
             Mean action noise std: 2.14
          Mean value_function loss: 17.2462
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.9355
                       Mean reward: 802.97
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 160.1903
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 5.13s
                      Time elapsed: 00:37:43
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 19024 steps/s (collection: 4.784s, learning 0.383s)
             Mean action noise std: 2.14
          Mean value_function loss: 18.0057
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.9477
                       Mean reward: 781.65
               Mean episode length: 244.77
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 157.5969
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 5.17s
                      Time elapsed: 00:37:48
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 21583 steps/s (collection: 4.153s, learning 0.401s)
             Mean action noise std: 2.14
          Mean value_function loss: 25.6224
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.9679
                       Mean reward: 792.11
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.7494
    Episode_Reward/rotating_object: 159.5019
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 4.55s
                      Time elapsed: 00:37:53
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 19741 steps/s (collection: 4.658s, learning 0.321s)
             Mean action noise std: 2.14
          Mean value_function loss: 31.8344
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 37.9818
                       Mean reward: 760.13
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 154.1416
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 4.98s
                      Time elapsed: 00:37:58
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 22106 steps/s (collection: 4.118s, learning 0.329s)
             Mean action noise std: 2.15
          Mean value_function loss: 21.6390
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.9924
                       Mean reward: 792.61
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 158.6158
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 4.45s
                      Time elapsed: 00:38:02
                               ETA: 00:31:15

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 22291 steps/s (collection: 4.139s, learning 0.271s)
             Mean action noise std: 2.15
          Mean value_function loss: 16.2793
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 38.0068
                       Mean reward: 810.61
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7534
    Episode_Reward/rotating_object: 160.8835
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 4.41s
                      Time elapsed: 00:38:07
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 24080 steps/s (collection: 3.778s, learning 0.305s)
             Mean action noise std: 2.15
          Mean value_function loss: 23.3394
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 38.0148
                       Mean reward: 778.84
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 158.5988
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 4.08s
                      Time elapsed: 00:38:11
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 26242 steps/s (collection: 3.420s, learning 0.326s)
             Mean action noise std: 2.15
          Mean value_function loss: 22.0576
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.0213
                       Mean reward: 796.10
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.7488
    Episode_Reward/rotating_object: 158.9370
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 3.75s
                      Time elapsed: 00:38:15
                               ETA: 00:31:10

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 20585 steps/s (collection: 4.344s, learning 0.432s)
             Mean action noise std: 2.15
          Mean value_function loss: 23.4947
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.0321
                       Mean reward: 803.78
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 158.5687
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 4.78s
                      Time elapsed: 00:38:19
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 22174 steps/s (collection: 3.963s, learning 0.470s)
             Mean action noise std: 2.15
          Mean value_function loss: 28.4741
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.0413
                       Mean reward: 798.61
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 158.5464
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 4.43s
                      Time elapsed: 00:38:24
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 21630 steps/s (collection: 4.193s, learning 0.351s)
             Mean action noise std: 2.15
          Mean value_function loss: 27.2288
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.0522
                       Mean reward: 793.98
               Mean episode length: 246.34
    Episode_Reward/reaching_object: 0.7405
    Episode_Reward/rotating_object: 158.0568
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 4.54s
                      Time elapsed: 00:38:28
                               ETA: 00:31:06

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 23254 steps/s (collection: 3.866s, learning 0.362s)
             Mean action noise std: 2.16
          Mean value_function loss: 24.7572
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.0643
                       Mean reward: 806.88
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7377
    Episode_Reward/rotating_object: 156.8922
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 4.23s
                      Time elapsed: 00:38:33
                               ETA: 00:31:04

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 24407 steps/s (collection: 3.661s, learning 0.366s)
             Mean action noise std: 2.16
          Mean value_function loss: 16.3463
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.0740
                       Mean reward: 813.51
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 158.6591
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 4.03s
                      Time elapsed: 00:38:37
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 21167 steps/s (collection: 4.237s, learning 0.407s)
             Mean action noise std: 2.16
          Mean value_function loss: 20.8808
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 38.0811
                       Mean reward: 805.12
               Mean episode length: 246.39
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 158.8376
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 4.64s
                      Time elapsed: 00:38:41
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 21145 steps/s (collection: 4.254s, learning 0.395s)
             Mean action noise std: 2.16
          Mean value_function loss: 26.3281
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.0862
                       Mean reward: 802.18
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 160.1570
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 4.65s
                      Time elapsed: 00:38:46
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 19089 steps/s (collection: 4.807s, learning 0.343s)
             Mean action noise std: 2.16
          Mean value_function loss: 25.9589
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 38.1000
                       Mean reward: 784.49
               Mean episode length: 243.10
    Episode_Reward/reaching_object: 0.7411
    Episode_Reward/rotating_object: 156.9605
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 5.15s
                      Time elapsed: 00:38:51
                               ETA: 00:30:59

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 23364 steps/s (collection: 3.788s, learning 0.420s)
             Mean action noise std: 2.16
          Mean value_function loss: 26.3294
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.1182
                       Mean reward: 781.96
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 159.2706
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 4.21s
                      Time elapsed: 00:38:55
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 21209 steps/s (collection: 4.201s, learning 0.434s)
             Mean action noise std: 2.17
          Mean value_function loss: 19.3837
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.1366
                       Mean reward: 774.77
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 156.2547
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 4.63s
                      Time elapsed: 00:39:00
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 20144 steps/s (collection: 4.578s, learning 0.302s)
             Mean action noise std: 2.17
          Mean value_function loss: 27.8021
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.1513
                       Mean reward: 787.49
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 159.5413
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 4.88s
                      Time elapsed: 00:39:05
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 22366 steps/s (collection: 4.116s, learning 0.280s)
             Mean action noise std: 2.17
          Mean value_function loss: 20.7290
               Mean surrogate loss: 0.0067
                 Mean entropy loss: 38.1641
                       Mean reward: 815.49
               Mean episode length: 249.32
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 158.7684
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 4.40s
                      Time elapsed: 00:39:09
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 21247 steps/s (collection: 4.314s, learning 0.312s)
             Mean action noise std: 2.17
          Mean value_function loss: 24.0373
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 38.1691
                       Mean reward: 806.19
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 158.1865
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 4.63s
                      Time elapsed: 00:39:14
                               ETA: 00:30:52

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 21262 steps/s (collection: 4.281s, learning 0.342s)
             Mean action noise std: 2.17
          Mean value_function loss: 16.0961
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.1751
                       Mean reward: 800.78
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7522
    Episode_Reward/rotating_object: 159.4384
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 4.62s
                      Time elapsed: 00:39:18
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 21206 steps/s (collection: 4.191s, learning 0.444s)
             Mean action noise std: 2.17
          Mean value_function loss: 22.6818
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.1820
                       Mean reward: 818.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 159.4374
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 4.64s
                      Time elapsed: 00:39:23
                               ETA: 00:30:49

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 22831 steps/s (collection: 3.946s, learning 0.359s)
             Mean action noise std: 2.17
          Mean value_function loss: 15.8166
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.1902
                       Mean reward: 806.91
               Mean episode length: 249.12
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 159.9522
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 4.31s
                      Time elapsed: 00:39:27
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 24121 steps/s (collection: 3.781s, learning 0.294s)
             Mean action noise std: 2.17
          Mean value_function loss: 18.7058
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.2007
                       Mean reward: 826.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 157.2880
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 4.08s
                      Time elapsed: 00:39:31
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 21873 steps/s (collection: 4.185s, learning 0.309s)
             Mean action noise std: 2.18
          Mean value_function loss: 18.3449
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.2167
                       Mean reward: 788.60
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7484
    Episode_Reward/rotating_object: 160.9988
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 4.49s
                      Time elapsed: 00:39:36
                               ETA: 00:30:44

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 21940 steps/s (collection: 4.069s, learning 0.411s)
             Mean action noise std: 2.18
          Mean value_function loss: 22.2603
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.2343
                       Mean reward: 813.09
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 160.5877
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 4.48s
                      Time elapsed: 00:39:40
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 22290 steps/s (collection: 3.979s, learning 0.431s)
             Mean action noise std: 2.18
          Mean value_function loss: 28.1027
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.2553
                       Mean reward: 815.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 159.2132
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 4.41s
                      Time elapsed: 00:39:45
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 22039 steps/s (collection: 4.152s, learning 0.308s)
             Mean action noise std: 2.18
          Mean value_function loss: 22.2887
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.2776
                       Mean reward: 800.61
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7494
    Episode_Reward/rotating_object: 160.7654
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 4.46s
                      Time elapsed: 00:39:49
                               ETA: 00:30:40

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 22745 steps/s (collection: 4.065s, learning 0.257s)
             Mean action noise std: 2.19
          Mean value_function loss: 42.5235
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.2961
                       Mean reward: 790.36
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.7343
    Episode_Reward/rotating_object: 157.1429
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 4.32s
                      Time elapsed: 00:39:54
                               ETA: 00:30:38

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 26094 steps/s (collection: 3.466s, learning 0.301s)
             Mean action noise std: 2.19
          Mean value_function loss: 26.7563
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.3068
                       Mean reward: 792.97
               Mean episode length: 244.68
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 159.2133
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 3.77s
                      Time elapsed: 00:39:57
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 22642 steps/s (collection: 4.076s, learning 0.266s)
             Mean action noise std: 2.19
          Mean value_function loss: 22.7984
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 38.3165
                       Mean reward: 818.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 159.9502
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 4.34s
                      Time elapsed: 00:40:02
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 21857 steps/s (collection: 4.208s, learning 0.290s)
             Mean action noise std: 2.19
          Mean value_function loss: 25.0978
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.3257
                       Mean reward: 776.71
               Mean episode length: 242.83
    Episode_Reward/reaching_object: 0.7356
    Episode_Reward/rotating_object: 155.6475
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 4.50s
                      Time elapsed: 00:40:06
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 21313 steps/s (collection: 4.161s, learning 0.451s)
             Mean action noise std: 2.19
          Mean value_function loss: 22.3147
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.3348
                       Mean reward: 801.81
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 158.5049
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 4.61s
                      Time elapsed: 00:40:11
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 22936 steps/s (collection: 3.896s, learning 0.390s)
             Mean action noise std: 2.19
          Mean value_function loss: 22.7044
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 38.3437
                       Mean reward: 805.67
               Mean episode length: 246.42
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 159.9519
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 4.29s
                      Time elapsed: 00:40:15
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 21505 steps/s (collection: 4.192s, learning 0.379s)
             Mean action noise std: 2.20
          Mean value_function loss: 27.9510
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.3587
                       Mean reward: 781.73
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 158.0553
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 4.57s
                      Time elapsed: 00:40:20
                               ETA: 00:30:28

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 20978 steps/s (collection: 4.295s, learning 0.391s)
             Mean action noise std: 2.20
          Mean value_function loss: 24.0637
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.3760
                       Mean reward: 790.23
               Mean episode length: 248.73
    Episode_Reward/reaching_object: 0.7416
    Episode_Reward/rotating_object: 156.9749
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 4.69s
                      Time elapsed: 00:40:24
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 19540 steps/s (collection: 4.762s, learning 0.269s)
             Mean action noise std: 2.20
          Mean value_function loss: 25.7878
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 38.3917
                       Mean reward: 797.48
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 159.1081
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 5.03s
                      Time elapsed: 00:40:29
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 21570 steps/s (collection: 4.178s, learning 0.379s)
             Mean action noise std: 2.20
          Mean value_function loss: 14.4967
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.4013
                       Mean reward: 794.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7572
    Episode_Reward/rotating_object: 158.6992
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 4.56s
                      Time elapsed: 00:40:34
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 20163 steps/s (collection: 4.513s, learning 0.362s)
             Mean action noise std: 2.20
          Mean value_function loss: 21.7941
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.4067
                       Mean reward: 810.03
               Mean episode length: 248.81
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 157.0497
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 4.88s
                      Time elapsed: 00:40:39
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 19971 steps/s (collection: 4.568s, learning 0.354s)
             Mean action noise std: 2.20
          Mean value_function loss: 24.8967
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.4156
                       Mean reward: 812.47
               Mean episode length: 249.38
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 158.7674
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 4.92s
                      Time elapsed: 00:40:44
                               ETA: 00:30:21

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 21296 steps/s (collection: 4.302s, learning 0.314s)
             Mean action noise std: 2.20
          Mean value_function loss: 30.9196
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.4246
                       Mean reward: 781.36
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 158.3866
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 4.62s
                      Time elapsed: 00:40:48
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 21767 steps/s (collection: 4.092s, learning 0.424s)
             Mean action noise std: 2.21
          Mean value_function loss: 26.1394
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.4302
                       Mean reward: 779.00
               Mean episode length: 241.69
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 158.6064
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 4.52s
                      Time elapsed: 00:40:53
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 21169 steps/s (collection: 4.270s, learning 0.373s)
             Mean action noise std: 2.21
          Mean value_function loss: 21.4859
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.4393
                       Mean reward: 786.05
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 157.7690
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 4.64s
                      Time elapsed: 00:40:57
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 21554 steps/s (collection: 4.186s, learning 0.375s)
             Mean action noise std: 2.21
          Mean value_function loss: 22.4217
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.4521
                       Mean reward: 808.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 155.1334
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 4.56s
                      Time elapsed: 00:41:02
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 19040 steps/s (collection: 4.755s, learning 0.408s)
             Mean action noise std: 2.21
          Mean value_function loss: 15.2770
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 38.4624
                       Mean reward: 803.12
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7553
    Episode_Reward/rotating_object: 161.7001
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 5.16s
                      Time elapsed: 00:41:07
                               ETA: 00:30:14

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 21009 steps/s (collection: 4.329s, learning 0.350s)
             Mean action noise std: 2.21
          Mean value_function loss: 25.8270
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.4758
                       Mean reward: 815.29
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 159.3154
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 4.68s
                      Time elapsed: 00:41:12
                               ETA: 00:30:12

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 18201 steps/s (collection: 4.974s, learning 0.427s)
             Mean action noise std: 2.21
          Mean value_function loss: 21.9422
               Mean surrogate loss: 0.0036
                 Mean entropy loss: 38.4855
                       Mean reward: 814.04
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 159.4110
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 5.40s
                      Time elapsed: 00:41:17
                               ETA: 00:30:11

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 17916 steps/s (collection: 5.091s, learning 0.396s)
             Mean action noise std: 2.21
          Mean value_function loss: 20.6560
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.4864
                       Mean reward: 793.82
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 159.0053
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 5.49s
                      Time elapsed: 00:41:23
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 20574 steps/s (collection: 4.445s, learning 0.333s)
             Mean action noise std: 2.21
          Mean value_function loss: 27.5726
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.4900
                       Mean reward: 820.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 158.9168
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 4.78s
                      Time elapsed: 00:41:28
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 22455 steps/s (collection: 4.041s, learning 0.337s)
             Mean action noise std: 2.22
          Mean value_function loss: 24.9017
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 38.5048
                       Mean reward: 783.47
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 0.7407
    Episode_Reward/rotating_object: 156.3613
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 4.38s
                      Time elapsed: 00:41:32
                               ETA: 00:30:07

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 20661 steps/s (collection: 4.250s, learning 0.507s)
             Mean action noise std: 2.22
          Mean value_function loss: 22.8828
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.5290
                       Mean reward: 810.12
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 158.3356
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 4.76s
                      Time elapsed: 00:41:37
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 20969 steps/s (collection: 4.234s, learning 0.454s)
             Mean action noise std: 2.22
          Mean value_function loss: 25.6765
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.5422
                       Mean reward: 786.58
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 158.1733
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 4.69s
                      Time elapsed: 00:41:41
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 19123 steps/s (collection: 4.661s, learning 0.479s)
             Mean action noise std: 2.22
          Mean value_function loss: 25.2696
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.5468
                       Mean reward: 803.42
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 156.7770
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 5.14s
                      Time elapsed: 00:41:47
                               ETA: 00:30:03

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 20269 steps/s (collection: 4.497s, learning 0.353s)
             Mean action noise std: 2.22
          Mean value_function loss: 23.8135
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.5557
                       Mean reward: 789.96
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 0.7346
    Episode_Reward/rotating_object: 155.4991
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 4.85s
                      Time elapsed: 00:41:51
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 21805 steps/s (collection: 4.132s, learning 0.377s)
             Mean action noise std: 2.22
          Mean value_function loss: 21.4231
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.5636
                       Mean reward: 782.92
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 158.6816
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 4.51s
                      Time elapsed: 00:41:56
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 18581 steps/s (collection: 4.887s, learning 0.404s)
             Mean action noise std: 2.23
          Mean value_function loss: 21.4923
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.5732
                       Mean reward: 806.53
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 160.0620
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 5.29s
                      Time elapsed: 00:42:01
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 18971 steps/s (collection: 4.829s, learning 0.353s)
             Mean action noise std: 2.23
          Mean value_function loss: 26.2059
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.5871
                       Mean reward: 788.68
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 159.3078
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 5.18s
                      Time elapsed: 00:42:06
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 20157 steps/s (collection: 4.484s, learning 0.393s)
             Mean action noise std: 2.23
          Mean value_function loss: 22.8208
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.5997
                       Mean reward: 776.42
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 157.9307
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 4.88s
                      Time elapsed: 00:42:11
                               ETA: 00:29:56

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 21665 steps/s (collection: 4.232s, learning 0.305s)
             Mean action noise std: 2.23
          Mean value_function loss: 18.4750
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.6115
                       Mean reward: 812.43
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 159.6565
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 4.54s
                      Time elapsed: 00:42:16
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 21393 steps/s (collection: 4.222s, learning 0.373s)
             Mean action noise std: 2.23
          Mean value_function loss: 23.0297
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.6214
                       Mean reward: 807.61
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 160.3448
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 4.60s
                      Time elapsed: 00:42:20
                               ETA: 00:29:53

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 21204 steps/s (collection: 4.293s, learning 0.343s)
             Mean action noise std: 2.24
          Mean value_function loss: 23.2815
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.6438
                       Mean reward: 805.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 160.0348
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 4.64s
                      Time elapsed: 00:42:25
                               ETA: 00:29:51

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 21832 steps/s (collection: 4.076s, learning 0.426s)
             Mean action noise std: 2.24
          Mean value_function loss: 27.0001
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.6615
                       Mean reward: 789.21
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 158.8045
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 4.50s
                      Time elapsed: 00:42:29
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 21301 steps/s (collection: 4.365s, learning 0.250s)
             Mean action noise std: 2.24
          Mean value_function loss: 21.7251
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 38.6732
                       Mean reward: 804.99
               Mean episode length: 248.21
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 160.6639
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 4.61s
                      Time elapsed: 00:42:34
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 29030 steps/s (collection: 3.128s, learning 0.258s)
             Mean action noise std: 2.24
          Mean value_function loss: 32.7754
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.6750
                       Mean reward: 783.08
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 158.1327
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 3.39s
                      Time elapsed: 00:42:37
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 28399 steps/s (collection: 3.193s, learning 0.268s)
             Mean action noise std: 2.24
          Mean value_function loss: 28.8904
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.6823
                       Mean reward: 800.62
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 158.4008
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 3.46s
                      Time elapsed: 00:42:41
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 26341 steps/s (collection: 3.452s, learning 0.280s)
             Mean action noise std: 2.24
          Mean value_function loss: 29.5166
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 38.6982
                       Mean reward: 771.86
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 0.7396
    Episode_Reward/rotating_object: 157.4393
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 3.73s
                      Time elapsed: 00:42:45
                               ETA: 00:29:40

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 27057 steps/s (collection: 3.378s, learning 0.255s)
             Mean action noise std: 2.24
          Mean value_function loss: 30.9083
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.7108
                       Mean reward: 795.90
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 159.6619
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 3.63s
                      Time elapsed: 00:42:48
                               ETA: 00:29:38

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 27225 steps/s (collection: 3.327s, learning 0.284s)
             Mean action noise std: 2.25
          Mean value_function loss: 31.8812
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.7256
                       Mean reward: 799.86
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 158.3136
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 3.61s
                      Time elapsed: 00:42:52
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 28349 steps/s (collection: 3.204s, learning 0.264s)
             Mean action noise std: 2.25
          Mean value_function loss: 29.7093
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.7376
                       Mean reward: 783.17
               Mean episode length: 245.37
    Episode_Reward/reaching_object: 0.7416
    Episode_Reward/rotating_object: 157.6716
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 3.47s
                      Time elapsed: 00:42:55
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 26612 steps/s (collection: 3.366s, learning 0.328s)
             Mean action noise std: 2.25
          Mean value_function loss: 26.7623
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.7444
                       Mean reward: 794.63
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7382
    Episode_Reward/rotating_object: 156.9491
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 3.69s
                      Time elapsed: 00:42:59
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 26089 steps/s (collection: 3.522s, learning 0.246s)
             Mean action noise std: 2.25
          Mean value_function loss: 21.2478
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 38.7507
                       Mean reward: 813.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 159.8471
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 3.77s
                      Time elapsed: 00:43:03
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 26200 steps/s (collection: 3.518s, learning 0.234s)
             Mean action noise std: 2.25
          Mean value_function loss: 23.8668
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.7549
                       Mean reward: 784.59
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 158.1845
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 3.75s
                      Time elapsed: 00:43:07
                               ETA: 00:29:26

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 26750 steps/s (collection: 3.388s, learning 0.287s)
             Mean action noise std: 2.25
          Mean value_function loss: 25.2399
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.7657
                       Mean reward: 781.09
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 0.7417
    Episode_Reward/rotating_object: 156.1427
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 3.67s
                      Time elapsed: 00:43:10
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 28139 steps/s (collection: 3.255s, learning 0.238s)
             Mean action noise std: 2.26
          Mean value_function loss: 29.1118
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.7802
                       Mean reward: 769.61
               Mean episode length: 242.75
    Episode_Reward/reaching_object: 0.7350
    Episode_Reward/rotating_object: 156.6762
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 3.49s
                      Time elapsed: 00:43:14
                               ETA: 00:29:21

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 22581 steps/s (collection: 3.947s, learning 0.406s)
             Mean action noise std: 2.26
          Mean value_function loss: 23.8323
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 38.7937
                       Mean reward: 787.67
               Mean episode length: 246.79
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 159.7518
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 4.35s
                      Time elapsed: 00:43:18
                               ETA: 00:29:19

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 19855 steps/s (collection: 4.570s, learning 0.381s)
             Mean action noise std: 2.26
          Mean value_function loss: 22.6620
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 38.8038
                       Mean reward: 786.60
               Mean episode length: 248.86
    Episode_Reward/reaching_object: 0.7439
    Episode_Reward/rotating_object: 158.4099
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 4.95s
                      Time elapsed: 00:43:23
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 20195 steps/s (collection: 4.518s, learning 0.350s)
             Mean action noise std: 2.26
          Mean value_function loss: 27.6610
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.8186
                       Mean reward: 779.97
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 158.0613
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 4.87s
                      Time elapsed: 00:43:28
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 17900 steps/s (collection: 5.118s, learning 0.374s)
             Mean action noise std: 2.26
          Mean value_function loss: 27.5379
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.8353
                       Mean reward: 775.05
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.7414
    Episode_Reward/rotating_object: 157.5063
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 5.49s
                      Time elapsed: 00:43:33
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 19845 steps/s (collection: 4.597s, learning 0.356s)
             Mean action noise std: 2.26
          Mean value_function loss: 20.1191
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.8489
                       Mean reward: 785.75
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 0.7381
    Episode_Reward/rotating_object: 158.8839
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 4.95s
                      Time elapsed: 00:43:38
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 19179 steps/s (collection: 4.750s, learning 0.376s)
             Mean action noise std: 2.27
          Mean value_function loss: 31.9170
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.8626
                       Mean reward: 795.70
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.7396
    Episode_Reward/rotating_object: 158.7846
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 5.13s
                      Time elapsed: 00:43:44
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 19918 steps/s (collection: 4.584s, learning 0.351s)
             Mean action noise std: 2.27
          Mean value_function loss: 18.4844
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 38.8729
                       Mean reward: 798.25
               Mean episode length: 245.37
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 157.3337
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 4.94s
                      Time elapsed: 00:43:48
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 19236 steps/s (collection: 4.707s, learning 0.403s)
             Mean action noise std: 2.27
          Mean value_function loss: 25.0077
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.8796
                       Mean reward: 794.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 157.4851
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 5.11s
                      Time elapsed: 00:43:54
                               ETA: 00:29:09

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 19344 steps/s (collection: 4.668s, learning 0.414s)
             Mean action noise std: 2.27
          Mean value_function loss: 34.4413
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.8948
                       Mean reward: 788.54
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 156.7937
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 5.08s
                      Time elapsed: 00:43:59
                               ETA: 00:29:07

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 19465 steps/s (collection: 4.693s, learning 0.357s)
             Mean action noise std: 2.27
          Mean value_function loss: 24.6834
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.9097
                       Mean reward: 801.63
               Mean episode length: 247.48
    Episode_Reward/reaching_object: 0.7397
    Episode_Reward/rotating_object: 157.1305
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 5.05s
                      Time elapsed: 00:44:04
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 18217 steps/s (collection: 5.023s, learning 0.373s)
             Mean action noise std: 2.27
          Mean value_function loss: 28.7582
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.9197
                       Mean reward: 807.91
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.7423
    Episode_Reward/rotating_object: 158.2013
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 5.40s
                      Time elapsed: 00:44:09
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 16535 steps/s (collection: 5.556s, learning 0.390s)
             Mean action noise std: 2.28
          Mean value_function loss: 24.9123
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 38.9280
                       Mean reward: 787.89
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 158.2892
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 5.95s
                      Time elapsed: 00:44:15
                               ETA: 00:29:03

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 18910 steps/s (collection: 4.830s, learning 0.368s)
             Mean action noise std: 2.28
          Mean value_function loss: 25.3800
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.9409
                       Mean reward: 754.42
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 0.7411
    Episode_Reward/rotating_object: 156.8184
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 5.20s
                      Time elapsed: 00:44:20
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 20144 steps/s (collection: 4.572s, learning 0.308s)
             Mean action noise std: 2.28
          Mean value_function loss: 27.5105
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.9594
                       Mean reward: 788.88
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 0.7457
    Episode_Reward/rotating_object: 160.4225
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 4.88s
                      Time elapsed: 00:44:25
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 20689 steps/s (collection: 4.407s, learning 0.344s)
             Mean action noise std: 2.28
          Mean value_function loss: 32.6320
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.9811
                       Mean reward: 799.45
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7378
    Episode_Reward/rotating_object: 156.5814
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 4.75s
                      Time elapsed: 00:44:30
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 20100 steps/s (collection: 4.545s, learning 0.346s)
             Mean action noise std: 2.29
          Mean value_function loss: 25.3358
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 39.0052
                       Mean reward: 791.44
               Mean episode length: 244.89
    Episode_Reward/reaching_object: 0.7418
    Episode_Reward/rotating_object: 158.9098
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 4.89s
                      Time elapsed: 00:44:35
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 39699 steps/s (collection: 2.375s, learning 0.102s)
             Mean action noise std: 2.29
          Mean value_function loss: 24.2135
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.0179
                       Mean reward: 783.95
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 158.9446
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.48s
                      Time elapsed: 00:44:37
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 51666 steps/s (collection: 1.796s, learning 0.107s)
             Mean action noise std: 2.29
          Mean value_function loss: 24.7200
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.0316
                       Mean reward: 794.59
               Mean episode length: 248.93
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 159.0571
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.90s
                      Time elapsed: 00:44:39
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 52131 steps/s (collection: 1.791s, learning 0.095s)
             Mean action noise std: 2.29
          Mean value_function loss: 29.5267
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.0487
                       Mean reward: 788.91
               Mean episode length: 246.39
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 156.9648
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 1.89s
                      Time elapsed: 00:44:41
                               ETA: 00:28:46

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 52800 steps/s (collection: 1.755s, learning 0.107s)
             Mean action noise std: 2.29
          Mean value_function loss: 24.2597
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.0695
                       Mean reward: 807.68
               Mean episode length: 248.79
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 159.0811
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.86s
                      Time elapsed: 00:44:43
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 53390 steps/s (collection: 1.746s, learning 0.095s)
             Mean action noise std: 2.30
          Mean value_function loss: 23.1267
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.0896
                       Mean reward: 785.90
               Mean episode length: 246.28
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 158.6344
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.84s
                      Time elapsed: 00:44:45
                               ETA: 00:28:39

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 51500 steps/s (collection: 1.806s, learning 0.103s)
             Mean action noise std: 2.30
          Mean value_function loss: 21.1337
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.0993
                       Mean reward: 806.31
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 159.2885
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.91s
                      Time elapsed: 00:44:47
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 51193 steps/s (collection: 1.820s, learning 0.101s)
             Mean action noise std: 2.30
          Mean value_function loss: 21.9472
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.1071
                       Mean reward: 798.71
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 158.8691
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.92s
                      Time elapsed: 00:44:49
                               ETA: 00:28:32

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 51260 steps/s (collection: 1.811s, learning 0.107s)
             Mean action noise std: 2.30
          Mean value_function loss: 19.4772
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.1204
                       Mean reward: 806.62
               Mean episode length: 248.39
    Episode_Reward/reaching_object: 0.7511
    Episode_Reward/rotating_object: 159.5914
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.92s
                      Time elapsed: 00:44:50
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 25953 steps/s (collection: 3.393s, learning 0.394s)
             Mean action noise std: 2.30
          Mean value_function loss: 16.9911
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 39.1387
                       Mean reward: 821.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 160.3378
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 3.79s
                      Time elapsed: 00:44:54
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 25328 steps/s (collection: 3.776s, learning 0.105s)
             Mean action noise std: 2.31
          Mean value_function loss: 26.5142
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.1491
                       Mean reward: 784.39
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 159.9362
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 3.88s
                      Time elapsed: 00:44:58
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 48391 steps/s (collection: 1.938s, learning 0.094s)
             Mean action noise std: 2.31
          Mean value_function loss: 21.6385
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.1592
                       Mean reward: 790.98
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.7341
    Episode_Reward/rotating_object: 156.3170
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.03s
                      Time elapsed: 00:45:00
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 40583 steps/s (collection: 2.233s, learning 0.189s)
             Mean action noise std: 2.31
          Mean value_function loss: 23.3071
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.1730
                       Mean reward: 760.96
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 0.7411
    Episode_Reward/rotating_object: 155.8126
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.42s
                      Time elapsed: 00:45:03
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 45972 steps/s (collection: 2.024s, learning 0.114s)
             Mean action noise std: 2.31
          Mean value_function loss: 21.0398
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.1826
                       Mean reward: 811.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7511
    Episode_Reward/rotating_object: 160.7412
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.14s
                      Time elapsed: 00:45:05
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 49882 steps/s (collection: 1.866s, learning 0.105s)
             Mean action noise std: 2.31
          Mean value_function loss: 26.0722
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 39.1914
                       Mean reward: 779.10
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 157.2039
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.97s
                      Time elapsed: 00:45:07
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 52414 steps/s (collection: 1.773s, learning 0.102s)
             Mean action noise std: 2.31
          Mean value_function loss: 17.9140
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.1990
                       Mean reward: 796.93
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 0.7440
    Episode_Reward/rotating_object: 160.3688
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.88s
                      Time elapsed: 00:45:09
                               ETA: 00:28:06

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 53367 steps/s (collection: 1.741s, learning 0.101s)
             Mean action noise std: 2.31
          Mean value_function loss: 19.0202
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.2058
                       Mean reward: 803.83
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 160.4447
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.84s
                      Time elapsed: 00:45:10
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 53544 steps/s (collection: 1.742s, learning 0.093s)
             Mean action noise std: 2.31
          Mean value_function loss: 21.5773
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.2134
                       Mean reward: 796.19
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 158.0099
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.84s
                      Time elapsed: 00:45:12
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 51544 steps/s (collection: 1.806s, learning 0.102s)
             Mean action noise std: 2.32
          Mean value_function loss: 22.6282
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.2204
                       Mean reward: 803.64
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7481
    Episode_Reward/rotating_object: 161.4945
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.91s
                      Time elapsed: 00:45:14
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 53534 steps/s (collection: 1.738s, learning 0.099s)
             Mean action noise std: 2.32
          Mean value_function loss: 18.3087
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.2331
                       Mean reward: 803.60
               Mean episode length: 247.57
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 161.6952
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.84s
                      Time elapsed: 00:45:16
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 52245 steps/s (collection: 1.780s, learning 0.102s)
             Mean action noise std: 2.32
          Mean value_function loss: 20.9970
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.2488
                       Mean reward: 807.46
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7505
    Episode_Reward/rotating_object: 159.5148
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.88s
                      Time elapsed: 00:45:18
                               ETA: 00:27:49

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 52853 steps/s (collection: 1.759s, learning 0.101s)
             Mean action noise std: 2.32
          Mean value_function loss: 24.7534
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.2605
                       Mean reward: 808.75
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 159.8854
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 1.86s
                      Time elapsed: 00:45:20
                               ETA: 00:27:45

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 53726 steps/s (collection: 1.724s, learning 0.106s)
             Mean action noise std: 2.32
          Mean value_function loss: 21.7232
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.2796
                       Mean reward: 788.83
               Mean episode length: 248.33
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 157.5192
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.83s
                      Time elapsed: 00:45:22
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 50417 steps/s (collection: 1.832s, learning 0.118s)
             Mean action noise std: 2.33
          Mean value_function loss: 22.6695
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.2936
                       Mean reward: 790.08
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 156.7423
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.95s
                      Time elapsed: 00:45:24
                               ETA: 00:27:38

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 51841 steps/s (collection: 1.783s, learning 0.113s)
             Mean action noise std: 2.33
          Mean value_function loss: 25.4350
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.3013
                       Mean reward: 805.30
               Mean episode length: 247.24
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 161.4671
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.90s
                      Time elapsed: 00:45:25
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 52393 steps/s (collection: 1.769s, learning 0.108s)
             Mean action noise std: 2.33
          Mean value_function loss: 21.8321
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.3048
                       Mean reward: 774.97
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 160.2901
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.88s
                      Time elapsed: 00:45:27
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 50316 steps/s (collection: 1.843s, learning 0.111s)
             Mean action noise std: 2.33
          Mean value_function loss: 31.3469
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.3085
                       Mean reward: 801.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 158.8100
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.95s
                      Time elapsed: 00:45:29
                               ETA: 00:27:27

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 52455 steps/s (collection: 1.764s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 30.4732
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.3185
                       Mean reward: 786.17
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.7429
    Episode_Reward/rotating_object: 157.7336
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.87s
                      Time elapsed: 00:45:31
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 50391 steps/s (collection: 1.845s, learning 0.106s)
             Mean action noise std: 2.33
          Mean value_function loss: 29.6195
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.3319
                       Mean reward: 785.02
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 158.1120
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.95s
                      Time elapsed: 00:45:33
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 53573 steps/s (collection: 1.737s, learning 0.098s)
             Mean action noise std: 2.33
          Mean value_function loss: 21.5640
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.3456
                       Mean reward: 812.59
               Mean episode length: 248.33
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 160.4231
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 1.83s
                      Time elapsed: 00:45:35
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 53305 steps/s (collection: 1.741s, learning 0.104s)
             Mean action noise std: 2.34
          Mean value_function loss: 26.5229
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.3549
                       Mean reward: 786.17
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 157.6484
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.84s
                      Time elapsed: 00:45:37
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 50450 steps/s (collection: 1.846s, learning 0.103s)
             Mean action noise std: 2.34
          Mean value_function loss: 23.9006
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.3626
                       Mean reward: 803.80
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 159.6045
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.95s
                      Time elapsed: 00:45:39
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 52266 steps/s (collection: 1.771s, learning 0.110s)
             Mean action noise std: 2.34
          Mean value_function loss: 19.2222
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.3656
                       Mean reward: 807.53
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 160.4809
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.88s
                      Time elapsed: 00:45:41
                               ETA: 00:27:06

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 52416 steps/s (collection: 1.769s, learning 0.106s)
             Mean action noise std: 2.34
          Mean value_function loss: 27.2499
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.3689
                       Mean reward: 792.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7403
    Episode_Reward/rotating_object: 157.2556
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.88s
                      Time elapsed: 00:45:42
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 52880 steps/s (collection: 1.762s, learning 0.097s)
             Mean action noise std: 2.34
          Mean value_function loss: 26.2282
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.3739
                       Mean reward: 792.60
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 157.2154
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.86s
                      Time elapsed: 00:45:44
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 51657 steps/s (collection: 1.787s, learning 0.116s)
             Mean action noise std: 2.34
          Mean value_function loss: 25.1831
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.3770
                       Mean reward: 804.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 158.4966
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.90s
                      Time elapsed: 00:45:46
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 52308 steps/s (collection: 1.773s, learning 0.106s)
             Mean action noise std: 2.34
          Mean value_function loss: 19.8976
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.3826
                       Mean reward: 783.80
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 0.7447
    Episode_Reward/rotating_object: 158.0632
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.88s
                      Time elapsed: 00:45:48
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 52940 steps/s (collection: 1.756s, learning 0.101s)
             Mean action noise std: 2.34
          Mean value_function loss: 19.5628
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.3961
                       Mean reward: 793.04
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 158.6212
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.86s
                      Time elapsed: 00:45:50
                               ETA: 00:26:49

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 53584 steps/s (collection: 1.735s, learning 0.100s)
             Mean action noise std: 2.34
          Mean value_function loss: 23.7046
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 39.4062
                       Mean reward: 816.63
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7533
    Episode_Reward/rotating_object: 160.5071
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.83s
                      Time elapsed: 00:45:52
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 53798 steps/s (collection: 1.724s, learning 0.104s)
             Mean action noise std: 2.35
          Mean value_function loss: 24.5488
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.4132
                       Mean reward: 773.59
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7448
    Episode_Reward/rotating_object: 157.9475
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.83s
                      Time elapsed: 00:45:54
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 52961 steps/s (collection: 1.762s, learning 0.095s)
             Mean action noise std: 2.35
          Mean value_function loss: 26.5238
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 39.4198
                       Mean reward: 787.04
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 159.6201
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.86s
                      Time elapsed: 00:45:55
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 52820 steps/s (collection: 1.756s, learning 0.105s)
             Mean action noise std: 2.35
          Mean value_function loss: 16.2904
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.4236
                       Mean reward: 799.86
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.7463
    Episode_Reward/rotating_object: 161.0197
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.86s
                      Time elapsed: 00:45:57
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 51986 steps/s (collection: 1.784s, learning 0.107s)
             Mean action noise std: 2.35
          Mean value_function loss: 14.6170
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 39.4337
                       Mean reward: 807.72
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7439
    Episode_Reward/rotating_object: 158.1924
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 1.89s
                      Time elapsed: 00:45:59
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 52676 steps/s (collection: 1.749s, learning 0.117s)
             Mean action noise std: 2.35
          Mean value_function loss: 25.0961
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.4495
                       Mean reward: 803.84
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.7423
    Episode_Reward/rotating_object: 160.0576
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.87s
                      Time elapsed: 00:46:01
                               ETA: 00:26:27

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 53673 steps/s (collection: 1.730s, learning 0.101s)
             Mean action noise std: 2.35
          Mean value_function loss: 21.8024
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.4664
                       Mean reward: 802.28
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.7448
    Episode_Reward/rotating_object: 158.9752
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.83s
                      Time elapsed: 00:46:03
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 52657 steps/s (collection: 1.764s, learning 0.103s)
             Mean action noise std: 2.35
          Mean value_function loss: 31.8316
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 39.4796
                       Mean reward: 800.86
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.7402
    Episode_Reward/rotating_object: 158.6778
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.87s
                      Time elapsed: 00:46:05
                               ETA: 00:26:20

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 52699 steps/s (collection: 1.759s, learning 0.107s)
             Mean action noise std: 2.36
          Mean value_function loss: 24.4809
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.4840
                       Mean reward: 803.00
               Mean episode length: 246.35
    Episode_Reward/reaching_object: 0.7402
    Episode_Reward/rotating_object: 159.4517
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.87s
                      Time elapsed: 00:46:07
                               ETA: 00:26:17

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 52968 steps/s (collection: 1.754s, learning 0.102s)
             Mean action noise std: 2.36
          Mean value_function loss: 25.1404
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.4929
                       Mean reward: 809.45
               Mean episode length: 246.71
    Episode_Reward/reaching_object: 0.7457
    Episode_Reward/rotating_object: 160.0181
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.86s
                      Time elapsed: 00:46:09
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 51000 steps/s (collection: 1.818s, learning 0.109s)
             Mean action noise std: 2.36
          Mean value_function loss: 24.9552
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.5056
                       Mean reward: 800.99
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 158.6188
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.93s
                      Time elapsed: 00:46:10
                               ETA: 00:26:10

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 52835 steps/s (collection: 1.760s, learning 0.101s)
             Mean action noise std: 2.36
          Mean value_function loss: 30.2291
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.5190
                       Mean reward: 806.85
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 159.0803
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 1.86s
                      Time elapsed: 00:46:12
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 53178 steps/s (collection: 1.742s, learning 0.107s)
             Mean action noise std: 2.36
          Mean value_function loss: 25.4245
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.5369
                       Mean reward: 810.33
               Mean episode length: 246.45
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 159.3665
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.85s
                      Time elapsed: 00:46:14
                               ETA: 00:26:03

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 53107 steps/s (collection: 1.747s, learning 0.104s)
             Mean action noise std: 2.37
          Mean value_function loss: 24.9710
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.5479
                       Mean reward: 820.40
               Mean episode length: 248.57
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 160.8162
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.85s
                      Time elapsed: 00:46:16
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 51543 steps/s (collection: 1.801s, learning 0.106s)
             Mean action noise std: 2.37
          Mean value_function loss: 22.7639
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.5526
                       Mean reward: 792.75
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 159.8742
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.91s
                      Time elapsed: 00:46:18
                               ETA: 00:25:56

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 51992 steps/s (collection: 1.782s, learning 0.109s)
             Mean action noise std: 2.37
          Mean value_function loss: 25.1003
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.5632
                       Mean reward: 806.36
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 161.5533
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 1.89s
                      Time elapsed: 00:46:20
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 52482 steps/s (collection: 1.769s, learning 0.104s)
             Mean action noise std: 2.37
          Mean value_function loss: 21.1754
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 39.5709
                       Mean reward: 813.64
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 159.7103
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.87s
                      Time elapsed: 00:46:22
                               ETA: 00:25:49

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 52472 steps/s (collection: 1.764s, learning 0.109s)
             Mean action noise std: 2.37
          Mean value_function loss: 22.2620
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.5750
                       Mean reward: 794.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 156.1573
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.87s
                      Time elapsed: 00:46:24
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 53024 steps/s (collection: 1.747s, learning 0.107s)
             Mean action noise std: 2.37
          Mean value_function loss: 28.6402
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.5816
                       Mean reward: 777.58
               Mean episode length: 245.12
    Episode_Reward/reaching_object: 0.7418
    Episode_Reward/rotating_object: 158.6860
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.85s
                      Time elapsed: 00:46:25
                               ETA: 00:25:42

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 52319 steps/s (collection: 1.780s, learning 0.099s)
             Mean action noise std: 2.37
          Mean value_function loss: 27.9315
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.5947
                       Mean reward: 787.42
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 0.7346
    Episode_Reward/rotating_object: 156.2866
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.88s
                      Time elapsed: 00:46:27
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 51156 steps/s (collection: 1.815s, learning 0.107s)
             Mean action noise std: 2.38
          Mean value_function loss: 24.6761
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.6109
                       Mean reward: 806.01
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 159.9195
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.92s
                      Time elapsed: 00:46:29
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 48496 steps/s (collection: 1.898s, learning 0.129s)
             Mean action noise std: 2.38
          Mean value_function loss: 30.1080
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.6225
                       Mean reward: 789.75
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7452
    Episode_Reward/rotating_object: 158.6418
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.03s
                      Time elapsed: 00:46:31
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 47310 steps/s (collection: 1.968s, learning 0.110s)
             Mean action noise std: 2.38
          Mean value_function loss: 28.0665
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.6311
                       Mean reward: 781.90
               Mean episode length: 244.69
    Episode_Reward/reaching_object: 0.7452
    Episode_Reward/rotating_object: 157.8052
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.08s
                      Time elapsed: 00:46:33
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 51088 steps/s (collection: 1.811s, learning 0.113s)
             Mean action noise std: 2.38
          Mean value_function loss: 34.0584
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.6381
                       Mean reward: 802.81
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 0.7438
    Episode_Reward/rotating_object: 159.8130
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.92s
                      Time elapsed: 00:46:35
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 48492 steps/s (collection: 1.896s, learning 0.132s)
             Mean action noise std: 2.38
          Mean value_function loss: 41.7429
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.6498
                       Mean reward: 767.73
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 0.7382
    Episode_Reward/rotating_object: 156.9645
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.03s
                      Time elapsed: 00:46:37
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 45113 steps/s (collection: 2.076s, learning 0.104s)
             Mean action noise std: 2.38
          Mean value_function loss: 34.1965
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 39.6653
                       Mean reward: 774.12
               Mean episode length: 240.65
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 157.5195
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.18s
                      Time elapsed: 00:46:39
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 45041 steps/s (collection: 2.047s, learning 0.135s)
             Mean action noise std: 2.38
          Mean value_function loss: 23.9438
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.6699
                       Mean reward: 786.85
               Mean episode length: 240.65
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 156.5971
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.18s
                      Time elapsed: 00:46:42
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 49662 steps/s (collection: 1.886s, learning 0.093s)
             Mean action noise std: 2.38
          Mean value_function loss: 24.8948
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 39.6741
                       Mean reward: 799.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7413
    Episode_Reward/rotating_object: 157.2320
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 1.98s
                      Time elapsed: 00:46:44
                               ETA: 00:25:12

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 50791 steps/s (collection: 1.839s, learning 0.096s)
             Mean action noise std: 2.39
          Mean value_function loss: 24.5298
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.6822
                       Mean reward: 793.08
               Mean episode length: 242.88
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 157.8850
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 1.94s
                      Time elapsed: 00:46:46
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 51472 steps/s (collection: 1.801s, learning 0.109s)
             Mean action noise std: 2.39
          Mean value_function loss: 28.8163
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 39.6897
                       Mean reward: 796.97
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 158.3819
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 1.91s
                      Time elapsed: 00:46:47
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 51479 steps/s (collection: 1.818s, learning 0.092s)
             Mean action noise std: 2.39
          Mean value_function loss: 33.2397
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.6960
                       Mean reward: 760.31
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 155.5129
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.91s
                      Time elapsed: 00:46:49
                               ETA: 00:25:02

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 51393 steps/s (collection: 1.812s, learning 0.101s)
             Mean action noise std: 2.39
          Mean value_function loss: 35.3611
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.7038
                       Mean reward: 798.39
               Mean episode length: 244.35
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 156.5281
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 1.91s
                      Time elapsed: 00:46:51
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 48542 steps/s (collection: 1.860s, learning 0.165s)
             Mean action noise std: 2.39
          Mean value_function loss: 19.9689
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.7123
                       Mean reward: 794.67
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 158.0820
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.03s
                      Time elapsed: 00:46:53
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 48719 steps/s (collection: 1.888s, learning 0.130s)
             Mean action noise std: 2.39
          Mean value_function loss: 23.0198
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.7248
                       Mean reward: 805.41
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 160.1377
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.02s
                      Time elapsed: 00:46:55
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 46043 steps/s (collection: 2.011s, learning 0.124s)
             Mean action noise std: 2.40
          Mean value_function loss: 24.0578
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 39.7401
                       Mean reward: 785.12
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 158.2301
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.14s
                      Time elapsed: 00:46:57
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 48706 steps/s (collection: 1.912s, learning 0.106s)
             Mean action noise std: 2.40
          Mean value_function loss: 27.4360
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.7467
                       Mean reward: 806.48
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 157.6599
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.02s
                      Time elapsed: 00:46:59
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 49897 steps/s (collection: 1.870s, learning 0.101s)
             Mean action noise std: 2.40
          Mean value_function loss: 25.8384
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.7544
                       Mean reward: 805.84
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7522
    Episode_Reward/rotating_object: 162.1108
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.97s
                      Time elapsed: 00:47:01
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 49699 steps/s (collection: 1.878s, learning 0.099s)
             Mean action noise std: 2.40
          Mean value_function loss: 18.6372
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.7626
                       Mean reward: 824.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 161.5391
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.98s
                      Time elapsed: 00:47:03
                               ETA: 00:24:39

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 49613 steps/s (collection: 1.879s, learning 0.103s)
             Mean action noise std: 2.40
          Mean value_function loss: 17.1404
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 39.7773
                       Mean reward: 812.66
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 162.0558
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.98s
                      Time elapsed: 00:47:05
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 49777 steps/s (collection: 1.878s, learning 0.097s)
             Mean action noise std: 2.40
          Mean value_function loss: 30.4016
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.7841
                       Mean reward: 789.82
               Mean episode length: 242.83
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 159.2804
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.97s
                      Time elapsed: 00:47:07
                               ETA: 00:24:32

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 50161 steps/s (collection: 1.852s, learning 0.108s)
             Mean action noise std: 2.41
          Mean value_function loss: 32.7865
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.7978
                       Mean reward: 802.00
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7397
    Episode_Reward/rotating_object: 157.5534
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.96s
                      Time elapsed: 00:47:09
                               ETA: 00:24:29

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 45820 steps/s (collection: 2.020s, learning 0.126s)
             Mean action noise std: 2.41
          Mean value_function loss: 20.5028
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.8102
                       Mean reward: 785.44
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 160.4191
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.15s
                      Time elapsed: 00:47:11
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 42415 steps/s (collection: 2.140s, learning 0.178s)
             Mean action noise std: 2.41
          Mean value_function loss: 19.0873
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 39.8142
                       Mean reward: 811.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7456
    Episode_Reward/rotating_object: 158.1097
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.32s
                      Time elapsed: 00:47:14
                               ETA: 00:24:22

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 45083 steps/s (collection: 2.067s, learning 0.113s)
             Mean action noise std: 2.41
          Mean value_function loss: 25.4135
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.8215
                       Mean reward: 815.33
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7503
    Episode_Reward/rotating_object: 160.7710
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.18s
                      Time elapsed: 00:47:16
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 47809 steps/s (collection: 1.942s, learning 0.114s)
             Mean action noise std: 2.41
          Mean value_function loss: 19.1324
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.8281
                       Mean reward: 793.92
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 160.7117
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.06s
                      Time elapsed: 00:47:18
                               ETA: 00:24:16

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 45661 steps/s (collection: 2.059s, learning 0.094s)
             Mean action noise std: 2.41
          Mean value_function loss: 31.6036
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.8372
                       Mean reward: 801.39
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 158.3875
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.15s
                      Time elapsed: 00:47:20
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 49544 steps/s (collection: 1.868s, learning 0.116s)
             Mean action noise std: 2.41
          Mean value_function loss: 22.0552
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.8499
                       Mean reward: 792.25
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 158.7505
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 1.98s
                      Time elapsed: 00:47:22
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 46976 steps/s (collection: 1.974s, learning 0.119s)
             Mean action noise std: 2.41
          Mean value_function loss: 22.1141
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 39.8590
                       Mean reward: 808.49
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 161.5845
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.09s
                      Time elapsed: 00:47:24
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 43856 steps/s (collection: 2.108s, learning 0.133s)
             Mean action noise std: 2.42
          Mean value_function loss: 23.5874
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.8681
                       Mean reward: 806.45
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 159.3647
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.24s
                      Time elapsed: 00:47:26
                               ETA: 00:24:03

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 42753 steps/s (collection: 2.187s, learning 0.113s)
             Mean action noise std: 2.42
          Mean value_function loss: 20.2185
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.8793
                       Mean reward: 809.16
               Mean episode length: 248.83
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 160.6343
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.30s
                      Time elapsed: 00:47:29
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 49472 steps/s (collection: 1.872s, learning 0.115s)
             Mean action noise std: 2.42
          Mean value_function loss: 19.0831
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.8908
                       Mean reward: 779.57
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 158.6456
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 1.99s
                      Time elapsed: 00:47:31
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 48044 steps/s (collection: 1.927s, learning 0.119s)
             Mean action noise std: 2.42
          Mean value_function loss: 24.7099
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.8987
                       Mean reward: 785.04
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 158.9727
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.05s
                      Time elapsed: 00:47:33
                               ETA: 00:23:53

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 49708 steps/s (collection: 1.871s, learning 0.107s)
             Mean action noise std: 2.42
          Mean value_function loss: 21.4943
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.9106
                       Mean reward: 788.26
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 0.7447
    Episode_Reward/rotating_object: 157.3379
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 1.98s
                      Time elapsed: 00:47:35
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 13288 steps/s (collection: 7.267s, learning 0.131s)
             Mean action noise std: 2.42
          Mean value_function loss: 24.5833
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.9202
                       Mean reward: 803.22
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 160.8721
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 7.40s
                      Time elapsed: 00:47:42
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 13229 steps/s (collection: 7.273s, learning 0.158s)
             Mean action noise std: 2.43
          Mean value_function loss: 19.5203
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 39.9286
                       Mean reward: 804.45
               Mean episode length: 249.08
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 158.7868
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 7.43s
                      Time elapsed: 00:47:50
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 12787 steps/s (collection: 7.454s, learning 0.234s)
             Mean action noise std: 2.43
          Mean value_function loss: 20.5360
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 39.9342
                       Mean reward: 819.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7497
    Episode_Reward/rotating_object: 159.3047
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 7.69s
                      Time elapsed: 00:47:57
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 13756 steps/s (collection: 6.976s, learning 0.170s)
             Mean action noise std: 2.43
          Mean value_function loss: 20.9466
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.9407
                       Mean reward: 781.31
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.7491
    Episode_Reward/rotating_object: 160.1516
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 7.15s
                      Time elapsed: 00:48:04
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 13102 steps/s (collection: 7.365s, learning 0.138s)
             Mean action noise std: 2.43
          Mean value_function loss: 25.8639
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 39.9567
                       Mean reward: 797.27
               Mean episode length: 247.07
    Episode_Reward/reaching_object: 0.7484
    Episode_Reward/rotating_object: 158.8892
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 7.50s
                      Time elapsed: 00:48:12
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 11558 steps/s (collection: 8.345s, learning 0.161s)
             Mean action noise std: 2.43
          Mean value_function loss: 34.6126
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.9636
                       Mean reward: 805.62
               Mean episode length: 248.42
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 159.6405
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 8.51s
                      Time elapsed: 00:48:20
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 17462 steps/s (collection: 5.508s, learning 0.122s)
             Mean action noise std: 2.43
          Mean value_function loss: 27.8848
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.9745
                       Mean reward: 765.89
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 0.7408
    Episode_Reward/rotating_object: 158.1739
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 5.63s
                      Time elapsed: 00:48:26
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 15792 steps/s (collection: 6.095s, learning 0.130s)
             Mean action noise std: 2.44
          Mean value_function loss: 22.0989
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.9886
                       Mean reward: 803.51
               Mean episode length: 246.99
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 161.0973
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.22s
                      Time elapsed: 00:48:32
                               ETA: 00:23:44

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 17392 steps/s (collection: 5.548s, learning 0.104s)
             Mean action noise std: 2.44
          Mean value_function loss: 20.9122
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.0050
                       Mean reward: 800.43
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 160.5888
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 5.65s
                      Time elapsed: 00:48:38
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 46717 steps/s (collection: 1.991s, learning 0.113s)
             Mean action noise std: 2.44
          Mean value_function loss: 24.2719
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.0159
                       Mean reward: 805.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7541
    Episode_Reward/rotating_object: 159.9434
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.10s
                      Time elapsed: 00:48:40
                               ETA: 00:23:39

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 45966 steps/s (collection: 2.017s, learning 0.122s)
             Mean action noise std: 2.44
          Mean value_function loss: 19.8312
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.0205
                       Mean reward: 797.83
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 159.4271
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.14s
                      Time elapsed: 00:48:42
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 50513 steps/s (collection: 1.830s, learning 0.116s)
             Mean action noise std: 2.44
          Mean value_function loss: 19.1112
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 40.0225
                       Mean reward: 823.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7557
    Episode_Reward/rotating_object: 161.7270
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.95s
                      Time elapsed: 00:48:44
                               ETA: 00:23:33

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 51729 steps/s (collection: 1.793s, learning 0.108s)
             Mean action noise std: 2.44
          Mean value_function loss: 18.4747
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.0229
                       Mean reward: 822.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 159.8942
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.90s
                      Time elapsed: 00:48:46
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 42844 steps/s (collection: 2.175s, learning 0.119s)
             Mean action noise std: 2.44
          Mean value_function loss: 21.8726
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.0282
                       Mean reward: 819.27
               Mean episode length: 248.72
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 161.1740
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.29s
                      Time elapsed: 00:48:48
                               ETA: 00:23:26

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 51392 steps/s (collection: 1.791s, learning 0.122s)
             Mean action noise std: 2.44
          Mean value_function loss: 31.8145
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.0382
                       Mean reward: 788.37
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 0.7403
    Episode_Reward/rotating_object: 156.4455
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.91s
                      Time elapsed: 00:48:50
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 48156 steps/s (collection: 1.935s, learning 0.107s)
             Mean action noise std: 2.45
          Mean value_function loss: 23.7344
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.0537
                       Mean reward: 772.27
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.7357
    Episode_Reward/rotating_object: 155.3062
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.04s
                      Time elapsed: 00:48:52
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 51132 steps/s (collection: 1.819s, learning 0.104s)
             Mean action noise std: 2.45
          Mean value_function loss: 25.9401
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.0617
                       Mean reward: 804.39
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 0.7443
    Episode_Reward/rotating_object: 157.8991
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.92s
                      Time elapsed: 00:48:54
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 51848 steps/s (collection: 1.787s, learning 0.109s)
             Mean action noise std: 2.45
          Mean value_function loss: 32.1585
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.0722
                       Mean reward: 807.74
               Mean episode length: 247.07
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 161.8440
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.90s
                      Time elapsed: 00:48:56
                               ETA: 00:23:13

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 52167 steps/s (collection: 1.779s, learning 0.105s)
             Mean action noise std: 2.45
          Mean value_function loss: 25.7568
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.0797
                       Mean reward: 817.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7461
    Episode_Reward/rotating_object: 157.8446
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.88s
                      Time elapsed: 00:48:58
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 52187 steps/s (collection: 1.779s, learning 0.105s)
             Mean action noise std: 2.45
          Mean value_function loss: 25.9332
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.0825
                       Mean reward: 792.96
               Mean episode length: 243.94
    Episode_Reward/reaching_object: 0.7397
    Episode_Reward/rotating_object: 155.8365
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.88s
                      Time elapsed: 00:49:00
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 51360 steps/s (collection: 1.813s, learning 0.101s)
             Mean action noise std: 2.45
          Mean value_function loss: 23.0466
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 40.0909
                       Mean reward: 796.80
               Mean episode length: 247.01
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 161.3552
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.91s
                      Time elapsed: 00:49:02
                               ETA: 00:23:03

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 50866 steps/s (collection: 1.822s, learning 0.111s)
             Mean action noise std: 2.46
          Mean value_function loss: 23.5633
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.1060
                       Mean reward: 801.03
               Mean episode length: 245.44
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 160.5121
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.93s
                      Time elapsed: 00:49:04
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 52521 steps/s (collection: 1.769s, learning 0.103s)
             Mean action noise std: 2.46
          Mean value_function loss: 17.3518
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.1202
                       Mean reward: 790.05
               Mean episode length: 244.67
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 158.7412
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.87s
                      Time elapsed: 00:49:06
                               ETA: 00:22:56

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 50217 steps/s (collection: 1.842s, learning 0.116s)
             Mean action noise std: 2.46
          Mean value_function loss: 24.4621
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.1288
                       Mean reward: 784.84
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 159.0884
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.96s
                      Time elapsed: 00:49:08
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 52533 steps/s (collection: 1.758s, learning 0.113s)
             Mean action noise std: 2.46
          Mean value_function loss: 24.6026
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.1370
                       Mean reward: 809.36
               Mean episode length: 246.57
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 159.5554
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.87s
                      Time elapsed: 00:49:09
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 50329 steps/s (collection: 1.854s, learning 0.099s)
             Mean action noise std: 2.46
          Mean value_function loss: 19.1099
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.1487
                       Mean reward: 790.99
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7494
    Episode_Reward/rotating_object: 157.8080
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.95s
                      Time elapsed: 00:49:11
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 51625 steps/s (collection: 1.797s, learning 0.107s)
             Mean action noise std: 2.46
          Mean value_function loss: 26.3920
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.1569
                       Mean reward: 798.05
               Mean episode length: 248.68
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 160.5260
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.90s
                      Time elapsed: 00:49:13
                               ETA: 00:22:43

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 51327 steps/s (collection: 1.808s, learning 0.107s)
             Mean action noise std: 2.47
          Mean value_function loss: 22.3929
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.1688
                       Mean reward: 800.62
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 158.9270
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.92s
                      Time elapsed: 00:49:15
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 46329 steps/s (collection: 1.999s, learning 0.123s)
             Mean action noise std: 2.47
          Mean value_function loss: 25.6393
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.1867
                       Mean reward: 800.29
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 0.7461
    Episode_Reward/rotating_object: 156.7112
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.12s
                      Time elapsed: 00:49:17
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 50559 steps/s (collection: 1.841s, learning 0.103s)
             Mean action noise std: 2.47
          Mean value_function loss: 24.0868
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.1979
                       Mean reward: 804.61
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 162.3058
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.94s
                      Time elapsed: 00:49:19
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 50728 steps/s (collection: 1.833s, learning 0.105s)
             Mean action noise std: 2.47
          Mean value_function loss: 18.1773
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 40.2033
                       Mean reward: 818.70
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 161.0457
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.94s
                      Time elapsed: 00:49:21
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 44962 steps/s (collection: 2.074s, learning 0.113s)
             Mean action noise std: 2.47
          Mean value_function loss: 23.7865
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.2046
                       Mean reward: 796.74
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 160.1413
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.19s
                      Time elapsed: 00:49:23
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 50371 steps/s (collection: 1.846s, learning 0.106s)
             Mean action noise std: 2.47
          Mean value_function loss: 32.1887
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.2083
                       Mean reward: 802.24
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 161.7949
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.95s
                      Time elapsed: 00:49:25
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 46176 steps/s (collection: 2.016s, learning 0.113s)
             Mean action noise std: 2.47
          Mean value_function loss: 24.0675
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.2179
                       Mean reward: 780.57
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 0.7399
    Episode_Reward/rotating_object: 158.5101
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.13s
                      Time elapsed: 00:49:27
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 44800 steps/s (collection: 2.098s, learning 0.096s)
             Mean action noise std: 2.48
          Mean value_function loss: 15.9578
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.2244
                       Mean reward: 804.67
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 161.8824
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.19s
                      Time elapsed: 00:49:30
                               ETA: 00:22:17

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 44710 steps/s (collection: 2.101s, learning 0.098s)
             Mean action noise std: 2.48
          Mean value_function loss: 24.8023
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.2288
                       Mean reward: 797.48
               Mean episode length: 247.10
    Episode_Reward/reaching_object: 0.7494
    Episode_Reward/rotating_object: 159.5217
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.20s
                      Time elapsed: 00:49:32
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 52310 steps/s (collection: 1.770s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 27.7559
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.2385
                       Mean reward: 792.66
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 159.4221
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.88s
                      Time elapsed: 00:49:34
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 48456 steps/s (collection: 1.922s, learning 0.107s)
             Mean action noise std: 2.48
          Mean value_function loss: 20.9344
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.2463
                       Mean reward: 811.54
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 158.5854
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.03s
                      Time elapsed: 00:49:36
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 44646 steps/s (collection: 2.068s, learning 0.134s)
             Mean action noise std: 2.48
          Mean value_function loss: 21.3128
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 40.2563
                       Mean reward: 801.61
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 0.7428
    Episode_Reward/rotating_object: 160.2027
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.20s
                      Time elapsed: 00:49:38
                               ETA: 00:22:04

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 47006 steps/s (collection: 1.970s, learning 0.121s)
             Mean action noise std: 2.48
          Mean value_function loss: 22.4749
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.2634
                       Mean reward: 805.28
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 159.9921
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.09s
                      Time elapsed: 00:49:40
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 49022 steps/s (collection: 1.877s, learning 0.128s)
             Mean action noise std: 2.48
          Mean value_function loss: 21.9958
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.2716
                       Mean reward: 797.94
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 160.5448
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.01s
                      Time elapsed: 00:49:42
                               ETA: 00:21:57

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 35664 steps/s (collection: 2.509s, learning 0.248s)
             Mean action noise std: 2.49
          Mean value_function loss: 22.0527
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.2781
                       Mean reward: 813.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7545
    Episode_Reward/rotating_object: 160.8216
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.76s
                      Time elapsed: 00:49:45
                               ETA: 00:21:55

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 37075 steps/s (collection: 2.547s, learning 0.104s)
             Mean action noise std: 2.49
          Mean value_function loss: 28.1100
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.2862
                       Mean reward: 795.32
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 163.0202
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.65s
                      Time elapsed: 00:49:48
                               ETA: 00:21:52

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 41788 steps/s (collection: 2.226s, learning 0.126s)
             Mean action noise std: 2.49
          Mean value_function loss: 26.3893
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.2974
                       Mean reward: 820.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7438
    Episode_Reward/rotating_object: 159.3224
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.35s
                      Time elapsed: 00:49:50
                               ETA: 00:21:48

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 47891 steps/s (collection: 1.933s, learning 0.120s)
             Mean action noise std: 2.49
          Mean value_function loss: 21.1129
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 40.3069
                       Mean reward: 818.33
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 162.0343
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.05s
                      Time elapsed: 00:49:52
                               ETA: 00:21:45

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 39430 steps/s (collection: 2.384s, learning 0.109s)
             Mean action noise std: 2.49
          Mean value_function loss: 25.0628
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.3121
                       Mean reward: 812.07
               Mean episode length: 247.05
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 156.5432
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.49s
                      Time elapsed: 00:49:54
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 45418 steps/s (collection: 1.983s, learning 0.181s)
             Mean action noise std: 2.49
          Mean value_function loss: 19.8503
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.3206
                       Mean reward: 799.98
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 159.6478
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.16s
                      Time elapsed: 00:49:57
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 42298 steps/s (collection: 2.174s, learning 0.150s)
             Mean action noise std: 2.50
          Mean value_function loss: 23.0460
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.3356
                       Mean reward: 810.28
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 162.1424
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.32s
                      Time elapsed: 00:49:59
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 38897 steps/s (collection: 2.398s, learning 0.129s)
             Mean action noise std: 2.50
          Mean value_function loss: 14.9869
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.3490
                       Mean reward: 817.92
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 162.2589
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.53s
                      Time elapsed: 00:50:01
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 40974 steps/s (collection: 2.197s, learning 0.203s)
             Mean action noise std: 2.50
          Mean value_function loss: 23.9577
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.3596
                       Mean reward: 808.29
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 159.5132
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.40s
                      Time elapsed: 00:50:04
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 45176 steps/s (collection: 2.058s, learning 0.118s)
             Mean action noise std: 2.50
          Mean value_function loss: 23.4930
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.3719
                       Mean reward: 802.73
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 163.3169
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.18s
                      Time elapsed: 00:50:06
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 43956 steps/s (collection: 2.035s, learning 0.201s)
             Mean action noise std: 2.50
          Mean value_function loss: 16.1908
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.3841
                       Mean reward: 812.55
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 158.6438
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.24s
                      Time elapsed: 00:50:08
                               ETA: 00:21:24

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 37669 steps/s (collection: 2.426s, learning 0.183s)
             Mean action noise std: 2.50
          Mean value_function loss: 18.2285
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 40.3939
                       Mean reward: 826.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 162.7208
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.61s
                      Time elapsed: 00:50:11
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 41501 steps/s (collection: 2.191s, learning 0.178s)
             Mean action noise std: 2.50
          Mean value_function loss: 14.7521
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.3941
                       Mean reward: 819.03
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 162.1884
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.37s
                      Time elapsed: 00:50:13
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 49060 steps/s (collection: 1.887s, learning 0.117s)
             Mean action noise std: 2.50
          Mean value_function loss: 22.7573
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 40.3941
                       Mean reward: 814.75
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.7425
    Episode_Reward/rotating_object: 160.1319
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.00s
                      Time elapsed: 00:50:15
                               ETA: 00:21:14

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 50610 steps/s (collection: 1.839s, learning 0.103s)
             Mean action noise std: 2.51
          Mean value_function loss: 22.6607
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.3982
                       Mean reward: 796.31
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 157.5234
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.94s
                      Time elapsed: 00:50:17
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 51472 steps/s (collection: 1.807s, learning 0.103s)
             Mean action noise std: 2.51
          Mean value_function loss: 28.9388
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.4073
                       Mean reward: 805.14
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7452
    Episode_Reward/rotating_object: 159.9159
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.91s
                      Time elapsed: 00:50:19
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 50295 steps/s (collection: 1.852s, learning 0.102s)
             Mean action noise std: 2.51
          Mean value_function loss: 26.9143
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.4145
                       Mean reward: 803.43
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 161.0974
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.95s
                      Time elapsed: 00:50:21
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 50708 steps/s (collection: 1.823s, learning 0.115s)
             Mean action noise std: 2.51
          Mean value_function loss: 18.5170
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 40.4205
                       Mean reward: 796.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 159.9167
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.94s
                      Time elapsed: 00:50:23
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 49529 steps/s (collection: 1.861s, learning 0.124s)
             Mean action noise std: 2.51
          Mean value_function loss: 18.6893
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 40.4276
                       Mean reward: 812.39
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7402
    Episode_Reward/rotating_object: 159.6605
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.98s
                      Time elapsed: 00:50:25
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 50973 steps/s (collection: 1.812s, learning 0.117s)
             Mean action noise std: 2.51
          Mean value_function loss: 26.4898
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.4328
                       Mean reward: 803.33
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 161.3237
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.93s
                      Time elapsed: 00:50:27
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 49841 steps/s (collection: 1.849s, learning 0.123s)
             Mean action noise std: 2.51
          Mean value_function loss: 22.8159
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.4427
                       Mean reward: 812.71
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 161.1641
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.97s
                      Time elapsed: 00:50:29
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 50748 steps/s (collection: 1.821s, learning 0.116s)
             Mean action noise std: 2.52
          Mean value_function loss: 19.9119
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.4536
                       Mean reward: 826.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 160.5831
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.94s
                      Time elapsed: 00:50:31
                               ETA: 00:20:49

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 50955 steps/s (collection: 1.813s, learning 0.116s)
             Mean action noise std: 2.52
          Mean value_function loss: 25.7736
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.4657
                       Mean reward: 813.69
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 161.7746
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.93s
                      Time elapsed: 00:50:33
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 46536 steps/s (collection: 2.010s, learning 0.103s)
             Mean action noise std: 2.52
          Mean value_function loss: 20.9312
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.4788
                       Mean reward: 820.30
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 161.7027
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.11s
                      Time elapsed: 00:50:35
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 51897 steps/s (collection: 1.787s, learning 0.107s)
             Mean action noise std: 2.52
          Mean value_function loss: 18.8015
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.4876
                       Mean reward: 804.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 159.2993
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.89s
                      Time elapsed: 00:50:37
                               ETA: 00:20:39

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 47479 steps/s (collection: 1.950s, learning 0.121s)
             Mean action noise std: 2.52
          Mean value_function loss: 22.0038
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.4999
                       Mean reward: 806.59
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 160.5572
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.07s
                      Time elapsed: 00:50:39
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 50903 steps/s (collection: 1.839s, learning 0.093s)
             Mean action noise std: 2.53
          Mean value_function loss: 19.3011
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.5214
                       Mean reward: 813.42
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 160.3946
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.93s
                      Time elapsed: 00:50:41
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 50774 steps/s (collection: 1.827s, learning 0.110s)
             Mean action noise std: 2.53
          Mean value_function loss: 16.3681
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 40.5334
                       Mean reward: 819.97
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 162.6504
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.94s
                      Time elapsed: 00:50:43
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 51110 steps/s (collection: 1.818s, learning 0.105s)
             Mean action noise std: 2.53
          Mean value_function loss: 22.5440
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.5394
                       Mean reward: 830.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 162.4561
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.92s
                      Time elapsed: 00:50:45
                               ETA: 00:20:26

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 51290 steps/s (collection: 1.813s, learning 0.104s)
             Mean action noise std: 2.53
          Mean value_function loss: 24.2649
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.5486
                       Mean reward: 813.62
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 160.8063
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.92s
                      Time elapsed: 00:50:46
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 50422 steps/s (collection: 1.823s, learning 0.127s)
             Mean action noise std: 2.53
          Mean value_function loss: 20.6075
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.5597
                       Mean reward: 808.02
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 162.0165
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.95s
                      Time elapsed: 00:50:48
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 49706 steps/s (collection: 1.857s, learning 0.121s)
             Mean action noise std: 2.53
          Mean value_function loss: 25.9370
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.5672
                       Mean reward: 823.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 157.8717
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.98s
                      Time elapsed: 00:50:50
                               ETA: 00:20:16

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 49705 steps/s (collection: 1.875s, learning 0.102s)
             Mean action noise std: 2.53
          Mean value_function loss: 17.1546
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 40.5769
                       Mean reward: 796.01
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 160.1964
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.98s
                      Time elapsed: 00:50:52
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 50007 steps/s (collection: 1.850s, learning 0.116s)
             Mean action noise std: 2.54
          Mean value_function loss: 24.4744
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.5863
                       Mean reward: 803.37
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 160.6427
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.97s
                      Time elapsed: 00:50:54
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 51082 steps/s (collection: 1.822s, learning 0.102s)
             Mean action noise std: 2.54
          Mean value_function loss: 20.4216
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 40.5923
                       Mean reward: 805.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 159.0067
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.92s
                      Time elapsed: 00:50:56
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 51039 steps/s (collection: 1.833s, learning 0.093s)
             Mean action noise std: 2.54
          Mean value_function loss: 18.1883
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.5931
                       Mean reward: 819.97
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 161.5630
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.93s
                      Time elapsed: 00:50:58
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 49067 steps/s (collection: 1.900s, learning 0.103s)
             Mean action noise std: 2.54
          Mean value_function loss: 24.5270
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.5987
                       Mean reward: 787.34
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 160.2451
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.00s
                      Time elapsed: 00:51:00
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 47855 steps/s (collection: 1.867s, learning 0.187s)
             Mean action noise std: 2.54
          Mean value_function loss: 19.7480
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.6047
                       Mean reward: 793.98
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 160.3404
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.05s
                      Time elapsed: 00:51:02
                               ETA: 00:19:57

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 44954 steps/s (collection: 2.088s, learning 0.099s)
             Mean action noise std: 2.54
          Mean value_function loss: 25.0165
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.6099
                       Mean reward: 787.62
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7471
    Episode_Reward/rotating_object: 158.0353
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.19s
                      Time elapsed: 00:51:04
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 48170 steps/s (collection: 1.941s, learning 0.100s)
             Mean action noise std: 2.54
          Mean value_function loss: 18.6891
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.6172
                       Mean reward: 831.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7559
    Episode_Reward/rotating_object: 161.7896
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.04s
                      Time elapsed: 00:51:07
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 50192 steps/s (collection: 1.857s, learning 0.102s)
             Mean action noise std: 2.55
          Mean value_function loss: 17.1845
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.6272
                       Mean reward: 800.66
               Mean episode length: 246.70
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 160.5473
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.96s
                      Time elapsed: 00:51:08
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 49490 steps/s (collection: 1.892s, learning 0.094s)
             Mean action noise std: 2.55
          Mean value_function loss: 23.4552
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.6360
                       Mean reward: 833.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7487
    Episode_Reward/rotating_object: 161.8502
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.99s
                      Time elapsed: 00:51:10
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 46492 steps/s (collection: 1.973s, learning 0.142s)
             Mean action noise std: 2.55
          Mean value_function loss: 20.4963
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.6437
                       Mean reward: 780.06
               Mean episode length: 245.06
    Episode_Reward/reaching_object: 0.7538
    Episode_Reward/rotating_object: 160.7057
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.11s
                      Time elapsed: 00:51:13
                               ETA: 00:19:42

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 48068 steps/s (collection: 1.926s, learning 0.120s)
             Mean action noise std: 2.55
          Mean value_function loss: 20.7013
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.6537
                       Mean reward: 791.91
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 0.7443
    Episode_Reward/rotating_object: 158.4645
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.05s
                      Time elapsed: 00:51:15
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 50771 steps/s (collection: 1.828s, learning 0.108s)
             Mean action noise std: 2.55
          Mean value_function loss: 21.9222
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 40.6638
                       Mean reward: 823.25
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.7511
    Episode_Reward/rotating_object: 162.4295
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.94s
                      Time elapsed: 00:51:17
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 47880 steps/s (collection: 1.948s, learning 0.106s)
             Mean action noise std: 2.55
          Mean value_function loss: 14.0996
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.6721
                       Mean reward: 805.23
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 160.3241
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.05s
                      Time elapsed: 00:51:19
                               ETA: 00:19:32

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 49907 steps/s (collection: 1.861s, learning 0.109s)
             Mean action noise std: 2.56
          Mean value_function loss: 29.3813
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.6799
                       Mean reward: 805.74
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 159.5113
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.97s
                      Time elapsed: 00:51:21
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 50329 steps/s (collection: 1.856s, learning 0.097s)
             Mean action noise std: 2.56
          Mean value_function loss: 26.4723
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.6903
                       Mean reward: 781.73
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 159.9085
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.95s
                      Time elapsed: 00:51:23
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 48874 steps/s (collection: 1.904s, learning 0.107s)
             Mean action noise std: 2.56
          Mean value_function loss: 21.7731
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.7021
                       Mean reward: 790.11
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 160.6438
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.01s
                      Time elapsed: 00:51:25
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 49163 steps/s (collection: 1.895s, learning 0.105s)
             Mean action noise std: 2.56
          Mean value_function loss: 27.8528
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.7142
                       Mean reward: 806.87
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 160.7281
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.00s
                      Time elapsed: 00:51:27
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 48781 steps/s (collection: 1.910s, learning 0.105s)
             Mean action noise std: 2.56
          Mean value_function loss: 23.6141
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.7283
                       Mean reward: 778.46
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 0.7504
    Episode_Reward/rotating_object: 159.8886
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.02s
                      Time elapsed: 00:51:29
                               ETA: 00:19:16

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 47361 steps/s (collection: 1.951s, learning 0.125s)
             Mean action noise std: 2.56
          Mean value_function loss: 31.5482
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.7412
                       Mean reward: 813.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 163.1654
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.08s
                      Time elapsed: 00:51:31
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 45225 steps/s (collection: 2.053s, learning 0.121s)
             Mean action noise std: 2.57
          Mean value_function loss: 21.2807
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 40.7544
                       Mean reward: 820.84
               Mean episode length: 248.53
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 161.1371
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.17s
                      Time elapsed: 00:51:33
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 50986 steps/s (collection: 1.825s, learning 0.104s)
             Mean action noise std: 2.57
          Mean value_function loss: 20.2321
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.7592
                       Mean reward: 825.13
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7481
    Episode_Reward/rotating_object: 159.9558
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.93s
                      Time elapsed: 00:51:35
                               ETA: 00:19:07

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 50203 steps/s (collection: 1.855s, learning 0.103s)
             Mean action noise std: 2.57
          Mean value_function loss: 27.3486
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.7630
                       Mean reward: 812.00
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.7489
    Episode_Reward/rotating_object: 161.9830
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.96s
                      Time elapsed: 00:51:37
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 50594 steps/s (collection: 1.841s, learning 0.102s)
             Mean action noise std: 2.57
          Mean value_function loss: 19.6875
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.7714
                       Mean reward: 798.20
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 162.1667
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.94s
                      Time elapsed: 00:51:39
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 50776 steps/s (collection: 1.830s, learning 0.106s)
             Mean action noise std: 2.57
          Mean value_function loss: 23.3435
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.7868
                       Mean reward: 791.50
               Mean episode length: 244.99
    Episode_Reward/reaching_object: 0.7426
    Episode_Reward/rotating_object: 159.7320
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.94s
                      Time elapsed: 00:51:41
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 50046 steps/s (collection: 1.866s, learning 0.098s)
             Mean action noise std: 2.57
          Mean value_function loss: 19.8167
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.7996
                       Mean reward: 823.35
               Mean episode length: 248.53
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 162.6066
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.96s
                      Time elapsed: 00:51:43
                               ETA: 00:18:55

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 51050 steps/s (collection: 1.812s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 28.4794
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.8105
                       Mean reward: 795.85
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 160.6619
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.93s
                      Time elapsed: 00:51:44
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 50803 steps/s (collection: 1.826s, learning 0.109s)
             Mean action noise std: 2.58
          Mean value_function loss: 26.0162
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.8288
                       Mean reward: 805.56
               Mean episode length: 248.20
    Episode_Reward/reaching_object: 0.7397
    Episode_Reward/rotating_object: 159.0164
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.93s
                      Time elapsed: 00:51:46
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 45612 steps/s (collection: 2.060s, learning 0.095s)
             Mean action noise std: 2.58
          Mean value_function loss: 21.0654
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 40.8417
                       Mean reward: 790.62
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 160.6315
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.16s
                      Time elapsed: 00:51:49
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 47537 steps/s (collection: 1.970s, learning 0.098s)
             Mean action noise std: 2.58
          Mean value_function loss: 28.6054
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.8468
                       Mean reward: 793.19
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.7487
    Episode_Reward/rotating_object: 159.1740
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.07s
                      Time elapsed: 00:51:51
                               ETA: 00:18:42

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 47974 steps/s (collection: 1.939s, learning 0.110s)
             Mean action noise std: 2.58
          Mean value_function loss: 15.9332
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.8614
                       Mean reward: 808.73
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 162.0987
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.05s
                      Time elapsed: 00:51:53
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 49968 steps/s (collection: 1.872s, learning 0.096s)
             Mean action noise std: 2.58
          Mean value_function loss: 19.2778
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.8745
                       Mean reward: 788.00
               Mean episode length: 246.29
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 158.6537
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.97s
                      Time elapsed: 00:51:55
                               ETA: 00:18:36

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 50968 steps/s (collection: 1.829s, learning 0.100s)
             Mean action noise std: 2.58
          Mean value_function loss: 17.1507
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.8870
                       Mean reward: 806.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 161.8637
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.93s
                      Time elapsed: 00:51:57
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 48860 steps/s (collection: 1.908s, learning 0.104s)
             Mean action noise std: 2.59
          Mean value_function loss: 28.4152
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.8935
                       Mean reward: 786.15
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 159.8438
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.01s
                      Time elapsed: 00:51:59
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 50394 steps/s (collection: 1.840s, learning 0.111s)
             Mean action noise std: 2.59
          Mean value_function loss: 23.5599
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.9013
                       Mean reward: 812.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 160.2167
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.95s
                      Time elapsed: 00:52:01
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 50851 steps/s (collection: 1.822s, learning 0.111s)
             Mean action noise std: 2.59
          Mean value_function loss: 17.9915
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 40.9108
                       Mean reward: 800.49
               Mean episode length: 246.35
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 161.1275
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.93s
                      Time elapsed: 00:52:02
                               ETA: 00:18:23

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 50370 steps/s (collection: 1.856s, learning 0.096s)
             Mean action noise std: 2.59
          Mean value_function loss: 22.4404
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.9160
                       Mean reward: 778.88
               Mean episode length: 244.95
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 160.6932
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.95s
                      Time elapsed: 00:52:04
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 50782 steps/s (collection: 1.840s, learning 0.096s)
             Mean action noise std: 2.59
          Mean value_function loss: 27.0987
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.9228
                       Mean reward: 810.73
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 160.8062
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.94s
                      Time elapsed: 00:52:06
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 51440 steps/s (collection: 1.817s, learning 0.094s)
             Mean action noise std: 2.59
          Mean value_function loss: 16.5696
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.9287
                       Mean reward: 787.25
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 159.0330
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.91s
                      Time elapsed: 00:52:08
                               ETA: 00:18:14

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 51189 steps/s (collection: 1.821s, learning 0.100s)
             Mean action noise std: 2.59
          Mean value_function loss: 20.4878
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.9340
                       Mean reward: 813.14
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 160.4701
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.92s
                      Time elapsed: 00:52:10
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 51845 steps/s (collection: 1.799s, learning 0.097s)
             Mean action noise std: 2.59
          Mean value_function loss: 19.8427
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.9393
                       Mean reward: 810.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 160.3413
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.90s
                      Time elapsed: 00:52:12
                               ETA: 00:18:08

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 48572 steps/s (collection: 1.913s, learning 0.111s)
             Mean action noise std: 2.60
          Mean value_function loss: 16.5448
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.9491
                       Mean reward: 812.93
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 159.5804
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.02s
                      Time elapsed: 00:52:14
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 51183 steps/s (collection: 1.831s, learning 0.090s)
             Mean action noise std: 2.60
          Mean value_function loss: 22.2012
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.9604
                       Mean reward: 786.51
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 159.4493
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.92s
                      Time elapsed: 00:52:16
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 51038 steps/s (collection: 1.821s, learning 0.106s)
             Mean action noise std: 2.60
          Mean value_function loss: 17.6320
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.9724
                       Mean reward: 796.98
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 159.6081
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.93s
                      Time elapsed: 00:52:18
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 49995 steps/s (collection: 1.867s, learning 0.100s)
             Mean action noise std: 2.60
          Mean value_function loss: 14.1019
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 40.9830
                       Mean reward: 809.54
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 159.8834
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.97s
                      Time elapsed: 00:52:20
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 50311 steps/s (collection: 1.860s, learning 0.094s)
             Mean action noise std: 2.60
          Mean value_function loss: 19.7406
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 40.9879
                       Mean reward: 813.09
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7497
    Episode_Reward/rotating_object: 162.0728
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.95s
                      Time elapsed: 00:52:22
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 50459 steps/s (collection: 1.853s, learning 0.095s)
             Mean action noise std: 2.60
          Mean value_function loss: 20.7217
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.9927
                       Mean reward: 804.17
               Mean episode length: 246.68
    Episode_Reward/reaching_object: 0.7497
    Episode_Reward/rotating_object: 159.8161
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.95s
                      Time elapsed: 00:52:24
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 48510 steps/s (collection: 1.917s, learning 0.110s)
             Mean action noise std: 2.60
          Mean value_function loss: 22.1943
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.9963
                       Mean reward: 802.29
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 160.7476
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.03s
                      Time elapsed: 00:52:26
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 47687 steps/s (collection: 1.950s, learning 0.111s)
             Mean action noise std: 2.61
          Mean value_function loss: 25.0994
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.0082
                       Mean reward: 792.71
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 160.3105
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.06s
                      Time elapsed: 00:52:28
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 49474 steps/s (collection: 1.880s, learning 0.107s)
             Mean action noise std: 2.61
          Mean value_function loss: 21.1256
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.0192
                       Mean reward: 828.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 163.1680
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.99s
                      Time elapsed: 00:52:30
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 49635 steps/s (collection: 1.882s, learning 0.099s)
             Mean action noise std: 2.61
          Mean value_function loss: 24.2790
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.0263
                       Mean reward: 796.54
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.7481
    Episode_Reward/rotating_object: 161.7586
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.98s
                      Time elapsed: 00:52:32
                               ETA: 00:17:37

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 46784 steps/s (collection: 2.009s, learning 0.093s)
             Mean action noise std: 2.61
          Mean value_function loss: 12.0368
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 41.0340
                       Mean reward: 812.68
               Mean episode length: 246.45
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 161.1664
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.10s
                      Time elapsed: 00:52:34
                               ETA: 00:17:34

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 50201 steps/s (collection: 1.863s, learning 0.096s)
             Mean action noise std: 2.61
          Mean value_function loss: 17.4269
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.0375
                       Mean reward: 820.91
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 161.9923
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.96s
                      Time elapsed: 00:52:36
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 50419 steps/s (collection: 1.856s, learning 0.094s)
             Mean action noise std: 2.61
          Mean value_function loss: 21.5957
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.0420
                       Mean reward: 816.39
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 162.0337
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.95s
                      Time elapsed: 00:52:38
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 50208 steps/s (collection: 1.854s, learning 0.104s)
             Mean action noise std: 2.61
          Mean value_function loss: 23.3340
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.0528
                       Mean reward: 815.15
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 163.0649
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.96s
                      Time elapsed: 00:52:40
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 49007 steps/s (collection: 1.899s, learning 0.107s)
             Mean action noise std: 2.62
          Mean value_function loss: 18.1391
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.0628
                       Mean reward: 823.19
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 160.7026
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.01s
                      Time elapsed: 00:52:42
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 50067 steps/s (collection: 1.862s, learning 0.102s)
             Mean action noise std: 2.62
          Mean value_function loss: 26.8800
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.0694
                       Mean reward: 815.04
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 161.6553
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.96s
                      Time elapsed: 00:52:44
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 49843 steps/s (collection: 1.878s, learning 0.094s)
             Mean action noise std: 2.62
          Mean value_function loss: 29.0160
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.0772
                       Mean reward: 770.64
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 160.3084
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.97s
                      Time elapsed: 00:52:46
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 50520 steps/s (collection: 1.848s, learning 0.098s)
             Mean action noise std: 2.62
          Mean value_function loss: 25.0048
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.0914
                       Mean reward: 792.08
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 0.7442
    Episode_Reward/rotating_object: 160.6412
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.95s
                      Time elapsed: 00:52:48
                               ETA: 00:17:12

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 50226 steps/s (collection: 1.854s, learning 0.104s)
             Mean action noise std: 2.62
          Mean value_function loss: 30.9920
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.1046
                       Mean reward: 820.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 162.0515
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.96s
                      Time elapsed: 00:52:50
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 50935 steps/s (collection: 1.821s, learning 0.109s)
             Mean action noise std: 2.62
          Mean value_function loss: 22.3539
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.1162
                       Mean reward: 818.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 160.6763
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.93s
                      Time elapsed: 00:52:52
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 47196 steps/s (collection: 1.983s, learning 0.100s)
             Mean action noise std: 2.63
          Mean value_function loss: 23.3179
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.1258
                       Mean reward: 795.07
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 161.7738
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.08s
                      Time elapsed: 00:52:54
                               ETA: 00:17:03

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 51643 steps/s (collection: 1.805s, learning 0.099s)
             Mean action noise std: 2.63
          Mean value_function loss: 20.5738
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.1342
                       Mean reward: 814.44
               Mean episode length: 246.52
    Episode_Reward/reaching_object: 0.7448
    Episode_Reward/rotating_object: 161.5956
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.90s
                      Time elapsed: 00:52:56
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 50194 steps/s (collection: 1.852s, learning 0.107s)
             Mean action noise std: 2.63
          Mean value_function loss: 13.5580
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.1429
                       Mean reward: 820.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 162.8578
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.96s
                      Time elapsed: 00:52:58
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 50618 steps/s (collection: 1.820s, learning 0.122s)
             Mean action noise std: 2.63
          Mean value_function loss: 22.3072
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.1495
                       Mean reward: 816.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7429
    Episode_Reward/rotating_object: 159.6151
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.94s
                      Time elapsed: 00:52:59
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 50239 steps/s (collection: 1.853s, learning 0.104s)
             Mean action noise std: 2.63
          Mean value_function loss: 23.4198
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.1575
                       Mean reward: 789.52
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 0.7408
    Episode_Reward/rotating_object: 159.5840
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.96s
                      Time elapsed: 00:53:01
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 50200 steps/s (collection: 1.855s, learning 0.104s)
             Mean action noise std: 2.63
          Mean value_function loss: 18.9361
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.1622
                       Mean reward: 812.25
               Mean episode length: 249.88
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 159.5915
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.96s
                      Time elapsed: 00:53:03
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 50465 steps/s (collection: 1.824s, learning 0.124s)
             Mean action noise std: 2.63
          Mean value_function loss: 21.3397
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.1696
                       Mean reward: 801.72
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 160.3182
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.95s
                      Time elapsed: 00:53:05
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 41002 steps/s (collection: 2.290s, learning 0.107s)
             Mean action noise std: 2.64
          Mean value_function loss: 18.8027
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.1851
                       Mean reward: 796.34
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7481
    Episode_Reward/rotating_object: 158.9873
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.40s
                      Time elapsed: 00:53:08
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 48197 steps/s (collection: 1.943s, learning 0.097s)
             Mean action noise std: 2.64
          Mean value_function loss: 24.4790
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.2006
                       Mean reward: 819.77
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 161.5470
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.04s
                      Time elapsed: 00:53:10
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 47594 steps/s (collection: 1.970s, learning 0.095s)
             Mean action noise std: 2.64
          Mean value_function loss: 26.0081
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.2149
                       Mean reward: 814.56
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 160.8721
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.07s
                      Time elapsed: 00:53:12
                               ETA: 00:16:36

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 49476 steps/s (collection: 1.873s, learning 0.114s)
             Mean action noise std: 2.64
          Mean value_function loss: 26.3341
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 41.2252
                       Mean reward: 804.45
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7440
    Episode_Reward/rotating_object: 159.4325
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.99s
                      Time elapsed: 00:53:14
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 45139 steps/s (collection: 2.063s, learning 0.115s)
             Mean action noise std: 2.64
          Mean value_function loss: 23.8848
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.2300
                       Mean reward: 820.55
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 160.5940
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.18s
                      Time elapsed: 00:53:16
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 46510 steps/s (collection: 1.991s, learning 0.123s)
             Mean action noise std: 2.64
          Mean value_function loss: 21.7928
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.2406
                       Mean reward: 803.62
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 162.4990
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.11s
                      Time elapsed: 00:53:18
                               ETA: 00:16:27

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 47983 steps/s (collection: 1.918s, learning 0.131s)
             Mean action noise std: 2.65
          Mean value_function loss: 27.6726
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.2494
                       Mean reward: 799.52
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.7443
    Episode_Reward/rotating_object: 161.5616
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.05s
                      Time elapsed: 00:53:20
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 42044 steps/s (collection: 2.222s, learning 0.117s)
             Mean action noise std: 2.65
          Mean value_function loss: 21.8954
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.2557
                       Mean reward: 813.94
               Mean episode length: 246.40
    Episode_Reward/reaching_object: 0.7484
    Episode_Reward/rotating_object: 161.7469
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.34s
                      Time elapsed: 00:53:23
                               ETA: 00:16:21

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 45908 steps/s (collection: 2.019s, learning 0.123s)
             Mean action noise std: 2.65
          Mean value_function loss: 20.4747
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.2634
                       Mean reward: 804.40
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 159.4726
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.14s
                      Time elapsed: 00:53:25
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 47768 steps/s (collection: 1.946s, learning 0.112s)
             Mean action noise std: 2.65
          Mean value_function loss: 26.9145
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 41.2742
                       Mean reward: 808.38
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 161.0298
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.06s
                      Time elapsed: 00:53:27
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 30732 steps/s (collection: 2.799s, learning 0.400s)
             Mean action noise std: 2.65
          Mean value_function loss: 17.7287
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.2847
                       Mean reward: 784.81
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 160.6763
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 3.20s
                      Time elapsed: 00:53:30
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 24520 steps/s (collection: 3.822s, learning 0.187s)
             Mean action noise std: 2.65
          Mean value_function loss: 21.4967
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.2921
                       Mean reward: 813.24
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 159.8837
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 4.01s
                      Time elapsed: 00:53:34
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 31156 steps/s (collection: 2.983s, learning 0.173s)
             Mean action noise std: 2.66
          Mean value_function loss: 18.8394
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.2994
                       Mean reward: 807.27
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 160.8504
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 3.16s
                      Time elapsed: 00:53:37
                               ETA: 00:16:07

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 39028 steps/s (collection: 2.314s, learning 0.205s)
             Mean action noise std: 2.66
          Mean value_function loss: 20.1587
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.3075
                       Mean reward: 798.80
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 160.7399
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.52s
                      Time elapsed: 00:53:40
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 47761 steps/s (collection: 1.904s, learning 0.155s)
             Mean action noise std: 2.66
          Mean value_function loss: 30.3138
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.3159
                       Mean reward: 809.41
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 158.7681
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.06s
                      Time elapsed: 00:53:42
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 45006 steps/s (collection: 2.048s, learning 0.136s)
             Mean action noise std: 2.66
          Mean value_function loss: 15.3764
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.3243
                       Mean reward: 789.70
               Mean episode length: 244.12
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 160.6988
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.18s
                      Time elapsed: 00:53:44
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 44476 steps/s (collection: 2.032s, learning 0.178s)
             Mean action noise std: 2.66
          Mean value_function loss: 18.7162
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.3287
                       Mean reward: 793.33
               Mean episode length: 243.15
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 161.0169
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.21s
                      Time elapsed: 00:53:46
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 31806 steps/s (collection: 2.833s, learning 0.258s)
             Mean action noise std: 2.66
          Mean value_function loss: 24.7285
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 41.3343
                       Mean reward: 812.78
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7456
    Episode_Reward/rotating_object: 161.1556
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 3.09s
                      Time elapsed: 00:53:49
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 27987 steps/s (collection: 3.194s, learning 0.319s)
             Mean action noise std: 2.66
          Mean value_function loss: 19.2717
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.3410
                       Mean reward: 811.86
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 160.1975
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 3.51s
                      Time elapsed: 00:53:53
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 39474 steps/s (collection: 2.306s, learning 0.184s)
             Mean action noise std: 2.66
          Mean value_function loss: 22.2568
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.3484
                       Mean reward: 804.05
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 161.4388
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.49s
                      Time elapsed: 00:53:55
                               ETA: 00:15:47

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 38319 steps/s (collection: 2.358s, learning 0.207s)
             Mean action noise std: 2.67
          Mean value_function loss: 14.4913
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.3569
                       Mean reward: 816.07
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7559
    Episode_Reward/rotating_object: 162.8264
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.57s
                      Time elapsed: 00:53:58
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 39972 steps/s (collection: 2.242s, learning 0.218s)
             Mean action noise std: 2.67
          Mean value_function loss: 26.6870
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.3705
                       Mean reward: 795.94
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 160.6653
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.46s
                      Time elapsed: 00:54:00
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 38373 steps/s (collection: 2.429s, learning 0.133s)
             Mean action noise std: 2.67
          Mean value_function loss: 22.2496
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.3878
                       Mean reward: 820.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 159.9219
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.56s
                      Time elapsed: 00:54:03
                               ETA: 00:15:38

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 47507 steps/s (collection: 1.943s, learning 0.126s)
             Mean action noise std: 2.67
          Mean value_function loss: 32.6539
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.3979
                       Mean reward: 805.03
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 0.7494
    Episode_Reward/rotating_object: 160.8676
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.07s
                      Time elapsed: 00:54:05
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 45977 steps/s (collection: 2.003s, learning 0.135s)
             Mean action noise std: 2.67
          Mean value_function loss: 17.4685
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.4061
                       Mean reward: 821.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7558
    Episode_Reward/rotating_object: 161.9597
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.14s
                      Time elapsed: 00:54:07
                               ETA: 00:15:33

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 45175 steps/s (collection: 2.070s, learning 0.106s)
             Mean action noise std: 2.68
          Mean value_function loss: 18.9593
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.4162
                       Mean reward: 825.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 161.2176
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.18s
                      Time elapsed: 00:54:09
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 40533 steps/s (collection: 2.205s, learning 0.221s)
             Mean action noise std: 2.68
          Mean value_function loss: 23.0698
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.4263
                       Mean reward: 819.37
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7535
    Episode_Reward/rotating_object: 161.4663
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.43s
                      Time elapsed: 00:54:12
                               ETA: 00:15:27

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 45876 steps/s (collection: 1.989s, learning 0.154s)
             Mean action noise std: 2.68
          Mean value_function loss: 22.0877
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.4336
                       Mean reward: 782.84
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 157.1436
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.14s
                      Time elapsed: 00:54:14
                               ETA: 00:15:24

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 44316 steps/s (collection: 2.047s, learning 0.172s)
             Mean action noise std: 2.68
          Mean value_function loss: 18.3230
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.4472
                       Mean reward: 827.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7565
    Episode_Reward/rotating_object: 160.6608
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.22s
                      Time elapsed: 00:54:16
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 45482 steps/s (collection: 2.032s, learning 0.130s)
             Mean action noise std: 2.68
          Mean value_function loss: 28.6763
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.4594
                       Mean reward: 800.44
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 157.6974
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.16s
                      Time elapsed: 00:54:18
                               ETA: 00:15:18

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 42784 steps/s (collection: 2.062s, learning 0.236s)
             Mean action noise std: 2.68
          Mean value_function loss: 23.4098
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.4689
                       Mean reward: 819.93
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 161.3788
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.30s
                      Time elapsed: 00:54:20
                               ETA: 00:15:15

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 37024 steps/s (collection: 2.361s, learning 0.294s)
             Mean action noise std: 2.68
          Mean value_function loss: 14.5613
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.4745
                       Mean reward: 815.70
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7541
    Episode_Reward/rotating_object: 161.0883
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.66s
                      Time elapsed: 00:54:23
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 39758 steps/s (collection: 2.336s, learning 0.137s)
             Mean action noise std: 2.69
          Mean value_function loss: 22.6881
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.4836
                       Mean reward: 804.01
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7565
    Episode_Reward/rotating_object: 160.8647
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.47s
                      Time elapsed: 00:54:25
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 47886 steps/s (collection: 1.946s, learning 0.107s)
             Mean action noise std: 2.69
          Mean value_function loss: 37.3924
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.5024
                       Mean reward: 801.26
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7539
    Episode_Reward/rotating_object: 161.9838
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.05s
                      Time elapsed: 00:54:28
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 49244 steps/s (collection: 1.881s, learning 0.115s)
             Mean action noise std: 2.69
          Mean value_function loss: 24.2896
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.5162
                       Mean reward: 810.82
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 160.8462
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.00s
                      Time elapsed: 00:54:30
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 44984 steps/s (collection: 2.061s, learning 0.124s)
             Mean action noise std: 2.69
          Mean value_function loss: 21.5348
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.5257
                       Mean reward: 793.33
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 161.2227
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.19s
                      Time elapsed: 00:54:32
                               ETA: 00:15:00

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 47770 steps/s (collection: 1.940s, learning 0.118s)
             Mean action noise std: 2.69
          Mean value_function loss: 21.5501
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.5350
                       Mean reward: 815.52
               Mean episode length: 248.23
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 162.0211
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.06s
                      Time elapsed: 00:54:34
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 50707 steps/s (collection: 1.843s, learning 0.096s)
             Mean action noise std: 2.70
          Mean value_function loss: 32.3569
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.5457
                       Mean reward: 813.83
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7520
    Episode_Reward/rotating_object: 160.6999
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.94s
                      Time elapsed: 00:54:36
                               ETA: 00:14:54

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 50860 steps/s (collection: 1.842s, learning 0.091s)
             Mean action noise std: 2.70
          Mean value_function loss: 17.2627
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.5534
                       Mean reward: 805.92
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7484
    Episode_Reward/rotating_object: 160.3995
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.93s
                      Time elapsed: 00:54:38
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 50411 steps/s (collection: 1.849s, learning 0.101s)
             Mean action noise std: 2.70
          Mean value_function loss: 13.5188
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.5577
                       Mean reward: 800.88
               Mean episode length: 247.40
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 160.0003
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.95s
                      Time elapsed: 00:54:40
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 50385 steps/s (collection: 1.839s, learning 0.112s)
             Mean action noise std: 2.70
          Mean value_function loss: 20.6462
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.5611
                       Mean reward: 820.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7580
    Episode_Reward/rotating_object: 162.4069
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.95s
                      Time elapsed: 00:54:42
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 50242 steps/s (collection: 1.852s, learning 0.105s)
             Mean action noise std: 2.70
          Mean value_function loss: 23.4803
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.5703
                       Mean reward: 818.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 160.2594
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.96s
                      Time elapsed: 00:54:44
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 51034 steps/s (collection: 1.830s, learning 0.096s)
             Mean action noise std: 2.70
          Mean value_function loss: 21.6727
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.5903
                       Mean reward: 795.72
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 0.7555
    Episode_Reward/rotating_object: 160.7031
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.93s
                      Time elapsed: 00:54:45
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 50224 steps/s (collection: 1.851s, learning 0.106s)
             Mean action noise std: 2.71
          Mean value_function loss: 19.8868
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 41.5999
                       Mean reward: 802.40
               Mean episode length: 246.99
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 160.1454
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.96s
                      Time elapsed: 00:54:47
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 50381 steps/s (collection: 1.849s, learning 0.103s)
             Mean action noise std: 2.71
          Mean value_function loss: 20.7674
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.6044
                       Mean reward: 797.43
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 160.3554
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.95s
                      Time elapsed: 00:54:49
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 50890 steps/s (collection: 1.837s, learning 0.095s)
             Mean action noise std: 2.71
          Mean value_function loss: 18.4447
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.6119
                       Mean reward: 804.50
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 161.7316
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.93s
                      Time elapsed: 00:54:51
                               ETA: 00:14:30

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 50347 steps/s (collection: 1.853s, learning 0.099s)
             Mean action noise std: 2.71
          Mean value_function loss: 11.7438
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 41.6228
                       Mean reward: 801.72
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 158.6616
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.95s
                      Time elapsed: 00:54:53
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 50339 steps/s (collection: 1.859s, learning 0.094s)
             Mean action noise std: 2.71
          Mean value_function loss: 15.1408
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.6305
                       Mean reward: 823.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 162.4941
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.95s
                      Time elapsed: 00:54:55
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 50771 steps/s (collection: 1.835s, learning 0.102s)
             Mean action noise std: 2.71
          Mean value_function loss: 14.8678
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.6361
                       Mean reward: 813.49
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.7559
    Episode_Reward/rotating_object: 163.8814
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.94s
                      Time elapsed: 00:54:57
                               ETA: 00:14:21

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 51076 steps/s (collection: 1.827s, learning 0.098s)
             Mean action noise std: 2.71
          Mean value_function loss: 23.1308
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.6431
                       Mean reward: 790.44
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 158.3619
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.92s
                      Time elapsed: 00:54:59
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 50775 steps/s (collection: 1.831s, learning 0.106s)
             Mean action noise std: 2.72
          Mean value_function loss: 25.3721
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.6555
                       Mean reward: 816.79
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 161.7806
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.94s
                      Time elapsed: 00:55:01
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 51030 steps/s (collection: 1.826s, learning 0.100s)
             Mean action noise std: 2.72
          Mean value_function loss: 23.0513
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.6655
                       Mean reward: 818.44
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7471
    Episode_Reward/rotating_object: 160.0244
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.93s
                      Time elapsed: 00:55:03
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 49714 steps/s (collection: 1.880s, learning 0.097s)
             Mean action noise std: 2.72
          Mean value_function loss: 17.9177
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.6724
                       Mean reward: 833.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7550
    Episode_Reward/rotating_object: 162.9781
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.98s
                      Time elapsed: 00:55:05
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 49720 steps/s (collection: 1.882s, learning 0.095s)
             Mean action noise std: 2.72
          Mean value_function loss: 24.0302
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.6804
                       Mean reward: 789.62
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 0.7439
    Episode_Reward/rotating_object: 159.1201
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.98s
                      Time elapsed: 00:55:07
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 50294 steps/s (collection: 1.843s, learning 0.111s)
             Mean action noise std: 2.72
          Mean value_function loss: 22.9985
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 41.6927
                       Mean reward: 806.80
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 162.3749
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.95s
                      Time elapsed: 00:55:09
                               ETA: 00:14:03

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 49912 steps/s (collection: 1.872s, learning 0.097s)
             Mean action noise std: 2.72
          Mean value_function loss: 26.5859
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.7004
                       Mean reward: 819.23
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7558
    Episode_Reward/rotating_object: 163.4732
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.97s
                      Time elapsed: 00:55:11
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 49431 steps/s (collection: 1.890s, learning 0.099s)
             Mean action noise std: 2.72
          Mean value_function loss: 16.6811
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.7109
                       Mean reward: 823.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 163.2195
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.99s
                      Time elapsed: 00:55:13
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 48391 steps/s (collection: 1.920s, learning 0.112s)
             Mean action noise std: 2.73
          Mean value_function loss: 19.7805
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.7196
                       Mean reward: 824.64
               Mean episode length: 249.82
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 161.7590
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.03s
                      Time elapsed: 00:55:15
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 48323 steps/s (collection: 1.917s, learning 0.117s)
             Mean action noise std: 2.73
          Mean value_function loss: 26.4666
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.7267
                       Mean reward: 803.21
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 160.4848
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.03s
                      Time elapsed: 00:55:17
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 50242 steps/s (collection: 1.840s, learning 0.117s)
             Mean action noise std: 2.73
          Mean value_function loss: 16.7792
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.7385
                       Mean reward: 814.95
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 160.4932
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.96s
                      Time elapsed: 00:55:19
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 24367 steps/s (collection: 3.669s, learning 0.365s)
             Mean action noise std: 2.73
          Mean value_function loss: 32.2595
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.7518
                       Mean reward: 768.89
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 0.7388
    Episode_Reward/rotating_object: 157.8274
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 4.03s
                      Time elapsed: 00:55:23
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 22102 steps/s (collection: 4.297s, learning 0.151s)
             Mean action noise std: 2.73
          Mean value_function loss: 18.9725
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.7657
                       Mean reward: 819.38
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7499
    Episode_Reward/rotating_object: 160.3495
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 4.45s
                      Time elapsed: 00:55:27
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 48844 steps/s (collection: 1.895s, learning 0.118s)
             Mean action noise std: 2.73
          Mean value_function loss: 16.6647
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.7716
                       Mean reward: 814.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 161.6534
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.01s
                      Time elapsed: 00:55:29
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 44701 steps/s (collection: 2.092s, learning 0.107s)
             Mean action noise std: 2.73
          Mean value_function loss: 20.5295
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.7768
                       Mean reward: 816.54
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7543
    Episode_Reward/rotating_object: 161.7911
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.20s
                      Time elapsed: 00:55:31
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 45595 steps/s (collection: 2.057s, learning 0.099s)
             Mean action noise std: 2.74
          Mean value_function loss: 18.2759
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.7849
                       Mean reward: 807.68
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 162.3046
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.16s
                      Time elapsed: 00:55:34
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 50229 steps/s (collection: 1.857s, learning 0.100s)
             Mean action noise std: 2.74
          Mean value_function loss: 18.3847
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.7908
                       Mean reward: 830.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 162.2891
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.96s
                      Time elapsed: 00:55:36
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 45099 steps/s (collection: 2.082s, learning 0.098s)
             Mean action noise std: 2.74
          Mean value_function loss: 18.3212
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.7931
                       Mean reward: 813.92
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 160.7033
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.18s
                      Time elapsed: 00:55:38
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 52265 steps/s (collection: 1.786s, learning 0.095s)
             Mean action noise std: 2.74
          Mean value_function loss: 20.4830
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.7963
                       Mean reward: 814.31
               Mean episode length: 246.33
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 158.7545
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.88s
                      Time elapsed: 00:55:40
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 47501 steps/s (collection: 1.964s, learning 0.106s)
             Mean action noise std: 2.74
          Mean value_function loss: 21.3283
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 41.8008
                       Mean reward: 805.50
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 160.7815
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.07s
                      Time elapsed: 00:55:42
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 49454 steps/s (collection: 1.881s, learning 0.107s)
             Mean action noise std: 2.74
          Mean value_function loss: 16.8395
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.8039
                       Mean reward: 805.46
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 161.9593
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.99s
                      Time elapsed: 00:55:44
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 50665 steps/s (collection: 1.838s, learning 0.102s)
             Mean action noise std: 2.74
          Mean value_function loss: 20.7480
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.8090
                       Mean reward: 821.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7575
    Episode_Reward/rotating_object: 163.8181
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.94s
                      Time elapsed: 00:55:46
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 50624 steps/s (collection: 1.827s, learning 0.115s)
             Mean action noise std: 2.74
          Mean value_function loss: 26.2073
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.8186
                       Mean reward: 814.99
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.7553
    Episode_Reward/rotating_object: 162.5433
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.94s
                      Time elapsed: 00:55:48
                               ETA: 00:13:14

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 51060 steps/s (collection: 1.820s, learning 0.106s)
             Mean action noise std: 2.74
          Mean value_function loss: 19.4367
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.8317
                       Mean reward: 820.52
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 159.3009
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.93s
                      Time elapsed: 00:55:50
                               ETA: 00:13:11

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 51726 steps/s (collection: 1.791s, learning 0.109s)
             Mean action noise std: 2.75
          Mean value_function loss: 15.5485
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 41.8442
                       Mean reward: 824.84
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 161.5690
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.90s
                      Time elapsed: 00:55:51
                               ETA: 00:13:09

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 50872 steps/s (collection: 1.841s, learning 0.091s)
             Mean action noise std: 2.75
          Mean value_function loss: 21.6431
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.8529
                       Mean reward: 821.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7554
    Episode_Reward/rotating_object: 162.4614
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.93s
                      Time elapsed: 00:55:53
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 49815 steps/s (collection: 1.869s, learning 0.104s)
             Mean action noise std: 2.75
          Mean value_function loss: 26.8993
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.8586
                       Mean reward: 789.26
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 161.5948
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.97s
                      Time elapsed: 00:55:55
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 50691 steps/s (collection: 1.846s, learning 0.094s)
             Mean action noise std: 2.75
          Mean value_function loss: 18.4050
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.8659
                       Mean reward: 835.51
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 162.3419
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.94s
                      Time elapsed: 00:55:57
                               ETA: 00:13:00

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 50539 steps/s (collection: 1.846s, learning 0.099s)
             Mean action noise std: 2.75
          Mean value_function loss: 21.5836
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.8761
                       Mean reward: 799.78
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 0.7533
    Episode_Reward/rotating_object: 162.3515
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.95s
                      Time elapsed: 00:55:59
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 50060 steps/s (collection: 1.866s, learning 0.098s)
             Mean action noise std: 2.75
          Mean value_function loss: 22.7076
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.8864
                       Mean reward: 802.89
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 161.5320
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.96s
                      Time elapsed: 00:56:01
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 50470 steps/s (collection: 1.839s, learning 0.109s)
             Mean action noise std: 2.76
          Mean value_function loss: 22.7194
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.8968
                       Mean reward: 820.55
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 163.3015
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.95s
                      Time elapsed: 00:56:03
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 51502 steps/s (collection: 1.805s, learning 0.104s)
             Mean action noise std: 2.76
          Mean value_function loss: 21.2466
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.9084
                       Mean reward: 812.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 160.7429
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.91s
                      Time elapsed: 00:56:05
                               ETA: 00:12:48

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 50047 steps/s (collection: 1.847s, learning 0.118s)
             Mean action noise std: 2.76
          Mean value_function loss: 15.4000
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.9182
                       Mean reward: 815.03
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 162.2163
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.96s
                      Time elapsed: 00:56:07
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 50798 steps/s (collection: 1.831s, learning 0.104s)
             Mean action noise std: 2.76
          Mean value_function loss: 16.7624
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.9236
                       Mean reward: 824.62
               Mean episode length: 248.44
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 162.6173
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.94s
                      Time elapsed: 00:56:09
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 50251 steps/s (collection: 1.842s, learning 0.114s)
             Mean action noise std: 2.76
          Mean value_function loss: 17.4010
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.9270
                       Mean reward: 806.32
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 162.7480
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.96s
                      Time elapsed: 00:56:11
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 52397 steps/s (collection: 1.787s, learning 0.089s)
             Mean action noise std: 2.76
          Mean value_function loss: 13.7480
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.9291
                       Mean reward: 810.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7583
    Episode_Reward/rotating_object: 162.6720
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.88s
                      Time elapsed: 00:56:13
                               ETA: 00:12:36

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 51353 steps/s (collection: 1.823s, learning 0.092s)
             Mean action noise std: 2.76
          Mean value_function loss: 19.2055
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.9367
                       Mean reward: 830.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7543
    Episode_Reward/rotating_object: 162.5789
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.91s
                      Time elapsed: 00:56:15
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 50157 steps/s (collection: 1.864s, learning 0.096s)
             Mean action noise std: 2.76
          Mean value_function loss: 16.1428
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.9447
                       Mean reward: 811.19
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 163.0985
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.96s
                      Time elapsed: 00:56:17
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 49895 steps/s (collection: 1.860s, learning 0.110s)
             Mean action noise std: 2.77
          Mean value_function loss: 22.2687
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.9542
                       Mean reward: 828.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7562
    Episode_Reward/rotating_object: 162.8141
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.97s
                      Time elapsed: 00:56:19
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 50226 steps/s (collection: 1.839s, learning 0.119s)
             Mean action noise std: 2.77
          Mean value_function loss: 22.2627
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.9645
                       Mean reward: 800.49
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7556
    Episode_Reward/rotating_object: 162.7090
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.96s
                      Time elapsed: 00:56:21
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 49843 steps/s (collection: 1.873s, learning 0.099s)
             Mean action noise std: 2.77
          Mean value_function loss: 15.9613
               Mean surrogate loss: 0.0085
                 Mean entropy loss: 41.9722
                       Mean reward: 809.71
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 160.4554
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.97s
                      Time elapsed: 00:56:23
                               ETA: 00:12:22

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 43703 steps/s (collection: 2.138s, learning 0.111s)
             Mean action noise std: 2.77
          Mean value_function loss: 17.4363
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 41.9739
                       Mean reward: 819.97
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7582
    Episode_Reward/rotating_object: 164.1998
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.25s
                      Time elapsed: 00:56:25
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 48048 steps/s (collection: 1.927s, learning 0.119s)
             Mean action noise std: 2.77
          Mean value_function loss: 18.6525
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.9793
                       Mean reward: 820.06
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 160.0188
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.05s
                      Time elapsed: 00:56:27
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 45241 steps/s (collection: 2.043s, learning 0.130s)
             Mean action noise std: 2.77
          Mean value_function loss: 19.2882
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.9897
                       Mean reward: 806.67
               Mean episode length: 248.60
    Episode_Reward/reaching_object: 0.7585
    Episode_Reward/rotating_object: 162.0630
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.17s
                      Time elapsed: 00:56:29
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 48655 steps/s (collection: 1.901s, learning 0.119s)
             Mean action noise std: 2.77
          Mean value_function loss: 17.1384
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.9995
                       Mean reward: 824.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7570
    Episode_Reward/rotating_object: 162.6158
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.02s
                      Time elapsed: 00:56:31
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 46990 steps/s (collection: 1.959s, learning 0.133s)
             Mean action noise std: 2.78
          Mean value_function loss: 23.9694
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.0102
                       Mean reward: 818.13
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 162.6420
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.09s
                      Time elapsed: 00:56:33
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 46342 steps/s (collection: 1.980s, learning 0.141s)
             Mean action noise std: 2.78
          Mean value_function loss: 17.1788
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.0181
                       Mean reward: 815.71
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7552
    Episode_Reward/rotating_object: 161.1638
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.12s
                      Time elapsed: 00:56:35
                               ETA: 00:12:04

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 48488 steps/s (collection: 1.914s, learning 0.113s)
             Mean action noise std: 2.78
          Mean value_function loss: 22.0310
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.0189
                       Mean reward: 818.99
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 160.1345
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.03s
                      Time elapsed: 00:56:37
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 33586 steps/s (collection: 2.461s, learning 0.466s)
             Mean action noise std: 2.78
          Mean value_function loss: 30.2099
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.0253
                       Mean reward: 808.97
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 161.7468
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.93s
                      Time elapsed: 00:56:40
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 19779 steps/s (collection: 4.486s, learning 0.484s)
             Mean action noise std: 2.78
          Mean value_function loss: 19.5225
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.0340
                       Mean reward: 810.47
               Mean episode length: 244.81
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 160.5201
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 4.97s
                      Time elapsed: 00:56:45
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 24782 steps/s (collection: 3.844s, learning 0.123s)
             Mean action noise std: 2.78
          Mean value_function loss: 25.7064
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.0394
                       Mean reward: 808.52
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 0.7409
    Episode_Reward/rotating_object: 159.6214
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 3.97s
                      Time elapsed: 00:56:49
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 49317 steps/s (collection: 1.876s, learning 0.118s)
             Mean action noise std: 2.78
          Mean value_function loss: 16.4721
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.0469
                       Mean reward: 813.66
               Mean episode length: 248.48
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 160.0158
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.99s
                      Time elapsed: 00:56:51
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 48798 steps/s (collection: 1.864s, learning 0.150s)
             Mean action noise std: 2.79
          Mean value_function loss: 21.5267
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.0586
                       Mean reward: 805.39
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.7545
    Episode_Reward/rotating_object: 161.9388
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.01s
                      Time elapsed: 00:56:53
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 48606 steps/s (collection: 1.890s, learning 0.133s)
             Mean action noise std: 2.79
          Mean value_function loss: 29.3178
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.0772
                       Mean reward: 814.08
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 0.7535
    Episode_Reward/rotating_object: 163.2261
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.02s
                      Time elapsed: 00:56:55
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 46525 steps/s (collection: 1.981s, learning 0.132s)
             Mean action noise std: 2.79
          Mean value_function loss: 32.8415
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.0915
                       Mean reward: 773.41
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 157.5773
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.11s
                      Time elapsed: 00:56:57
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 47424 steps/s (collection: 1.933s, learning 0.140s)
             Mean action noise std: 2.79
          Mean value_function loss: 17.3203
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 42.1069
                       Mean reward: 818.78
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7564
    Episode_Reward/rotating_object: 162.5640
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.07s
                      Time elapsed: 00:56:59
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 47205 steps/s (collection: 1.963s, learning 0.120s)
             Mean action noise std: 2.79
          Mean value_function loss: 13.9317
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.1131
                       Mean reward: 817.47
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7527
    Episode_Reward/rotating_object: 161.8213
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.08s
                      Time elapsed: 00:57:01
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 48812 steps/s (collection: 1.905s, learning 0.109s)
             Mean action noise std: 2.80
          Mean value_function loss: 23.5155
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.1215
                       Mean reward: 807.73
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 160.2261
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.01s
                      Time elapsed: 00:57:03
                               ETA: 00:11:34

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 49232 steps/s (collection: 1.880s, learning 0.117s)
             Mean action noise std: 2.80
          Mean value_function loss: 19.6661
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.1299
                       Mean reward: 806.72
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 162.3878
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.00s
                      Time elapsed: 00:57:05
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 44093 steps/s (collection: 2.128s, learning 0.101s)
             Mean action noise std: 2.80
          Mean value_function loss: 21.7543
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.1354
                       Mean reward: 787.37
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 159.9050
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.23s
                      Time elapsed: 00:57:08
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 48908 steps/s (collection: 1.903s, learning 0.107s)
             Mean action noise std: 2.80
          Mean value_function loss: 20.3850
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.1434
                       Mean reward: 833.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7585
    Episode_Reward/rotating_object: 164.6992
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.01s
                      Time elapsed: 00:57:10
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 47201 steps/s (collection: 1.976s, learning 0.107s)
             Mean action noise std: 2.80
          Mean value_function loss: 20.8748
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.1558
                       Mean reward: 814.06
               Mean episode length: 246.66
    Episode_Reward/reaching_object: 0.7534
    Episode_Reward/rotating_object: 161.3125
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.08s
                      Time elapsed: 00:57:12
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 47726 steps/s (collection: 1.951s, learning 0.108s)
             Mean action noise std: 2.80
          Mean value_function loss: 19.8336
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.1692
                       Mean reward: 814.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7574
    Episode_Reward/rotating_object: 163.1782
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.06s
                      Time elapsed: 00:57:14
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 50011 steps/s (collection: 1.868s, learning 0.098s)
             Mean action noise std: 2.80
          Mean value_function loss: 25.2986
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.1764
                       Mean reward: 797.83
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 161.2024
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 1.97s
                      Time elapsed: 00:57:16
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 48855 steps/s (collection: 1.877s, learning 0.135s)
             Mean action noise std: 2.81
          Mean value_function loss: 25.5911
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.1888
                       Mean reward: 822.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7543
    Episode_Reward/rotating_object: 161.9423
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.01s
                      Time elapsed: 00:57:18
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 46739 steps/s (collection: 1.988s, learning 0.115s)
             Mean action noise std: 2.81
          Mean value_function loss: 22.0968
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.2006
                       Mean reward: 816.79
               Mean episode length: 248.20
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 162.4118
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.10s
                      Time elapsed: 00:57:20
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 43840 steps/s (collection: 2.129s, learning 0.113s)
             Mean action noise std: 2.81
          Mean value_function loss: 19.4581
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.2072
                       Mean reward: 788.47
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.7497
    Episode_Reward/rotating_object: 160.6469
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.24s
                      Time elapsed: 00:57:22
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 38753 steps/s (collection: 2.427s, learning 0.110s)
             Mean action noise std: 2.81
          Mean value_function loss: 26.0773
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.2156
                       Mean reward: 782.51
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 160.1971
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.54s
                      Time elapsed: 00:57:25
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 50245 steps/s (collection: 1.847s, learning 0.109s)
             Mean action noise std: 2.81
          Mean value_function loss: 26.8875
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.2204
                       Mean reward: 815.69
               Mean episode length: 246.56
    Episode_Reward/reaching_object: 0.7523
    Episode_Reward/rotating_object: 161.5276
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 1.96s
                      Time elapsed: 00:57:27
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 49122 steps/s (collection: 1.904s, learning 0.098s)
             Mean action noise std: 2.81
          Mean value_function loss: 17.5456
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.2257
                       Mean reward: 781.77
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 159.1265
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.00s
                      Time elapsed: 00:57:29
                               ETA: 00:10:59

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 51042 steps/s (collection: 1.821s, learning 0.105s)
             Mean action noise std: 2.82
          Mean value_function loss: 24.7240
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.2291
                       Mean reward: 795.85
               Mean episode length: 244.64
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 160.1885
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 1.93s
                      Time elapsed: 00:57:31
                               ETA: 00:10:56

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 46884 steps/s (collection: 1.967s, learning 0.130s)
             Mean action noise std: 2.82
          Mean value_function loss: 18.0042
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.2367
                       Mean reward: 804.47
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 160.1884
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.10s
                      Time elapsed: 00:57:33
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 45543 steps/s (collection: 2.033s, learning 0.126s)
             Mean action noise std: 2.82
          Mean value_function loss: 15.2668
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.2419
                       Mean reward: 815.67
               Mean episode length: 248.40
    Episode_Reward/reaching_object: 0.7612
    Episode_Reward/rotating_object: 163.6433
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.16s
                      Time elapsed: 00:57:35
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 47911 steps/s (collection: 1.936s, learning 0.116s)
             Mean action noise std: 2.82
          Mean value_function loss: 15.5471
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.2467
                       Mean reward: 805.83
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.7621
    Episode_Reward/rotating_object: 161.7995
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.05s
                      Time elapsed: 00:57:37
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 48416 steps/s (collection: 1.916s, learning 0.114s)
             Mean action noise std: 2.82
          Mean value_function loss: 26.5656
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.2563
                       Mean reward: 811.38
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 159.8244
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.03s
                      Time elapsed: 00:57:39
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 43975 steps/s (collection: 2.040s, learning 0.196s)
             Mean action noise std: 2.82
          Mean value_function loss: 24.5799
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.2651
                       Mean reward: 794.83
               Mean episode length: 246.77
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 160.0839
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.24s
                      Time elapsed: 00:57:41
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 44422 steps/s (collection: 2.091s, learning 0.122s)
             Mean action noise std: 2.82
          Mean value_function loss: 34.3153
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.2715
                       Mean reward: 809.82
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 161.6056
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.21s
                      Time elapsed: 00:57:43
                               ETA: 00:10:39

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 46956 steps/s (collection: 1.970s, learning 0.123s)
             Mean action noise std: 2.83
          Mean value_function loss: 21.3691
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.2776
                       Mean reward: 802.50
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7487
    Episode_Reward/rotating_object: 159.7902
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.09s
                      Time elapsed: 00:57:45
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 45730 steps/s (collection: 2.023s, learning 0.127s)
             Mean action noise std: 2.83
          Mean value_function loss: 24.2067
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.2894
                       Mean reward: 793.98
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 0.7357
    Episode_Reward/rotating_object: 158.7316
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.15s
                      Time elapsed: 00:57:48
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 42316 steps/s (collection: 2.194s, learning 0.129s)
             Mean action noise std: 2.83
          Mean value_function loss: 27.7793
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.2964
                       Mean reward: 815.13
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 163.0004
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.32s
                      Time elapsed: 00:57:50
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 46476 steps/s (collection: 1.983s, learning 0.133s)
             Mean action noise std: 2.83
          Mean value_function loss: 23.0459
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.3087
                       Mean reward: 825.17
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 160.7819
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.12s
                      Time elapsed: 00:57:52
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 46677 steps/s (collection: 1.971s, learning 0.135s)
             Mean action noise std: 2.83
          Mean value_function loss: 27.5237
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.3242
                       Mean reward: 807.34
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7523
    Episode_Reward/rotating_object: 161.2993
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.11s
                      Time elapsed: 00:57:54
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 47345 steps/s (collection: 1.949s, learning 0.128s)
             Mean action noise std: 2.84
          Mean value_function loss: 20.1414
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.3320
                       Mean reward: 825.17
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7539
    Episode_Reward/rotating_object: 162.5192
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.08s
                      Time elapsed: 00:57:56
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 45847 steps/s (collection: 2.023s, learning 0.122s)
             Mean action noise std: 2.84
          Mean value_function loss: 15.9894
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.3394
                       Mean reward: 819.38
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7545
    Episode_Reward/rotating_object: 162.7747
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.14s
                      Time elapsed: 00:57:58
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 44182 steps/s (collection: 2.091s, learning 0.134s)
             Mean action noise std: 2.84
          Mean value_function loss: 21.6660
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.3451
                       Mean reward: 813.49
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 161.8301
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.22s
                      Time elapsed: 00:58:01
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 42544 steps/s (collection: 2.189s, learning 0.122s)
             Mean action noise std: 2.84
          Mean value_function loss: 25.6185
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.3528
                       Mean reward: 798.89
               Mean episode length: 244.66
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 158.9224
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.31s
                      Time elapsed: 00:58:03
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 47532 steps/s (collection: 1.954s, learning 0.115s)
             Mean action noise std: 2.84
          Mean value_function loss: 26.6319
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.3637
                       Mean reward: 822.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 162.1453
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.07s
                      Time elapsed: 00:58:05
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 46361 steps/s (collection: 1.997s, learning 0.124s)
             Mean action noise std: 2.84
          Mean value_function loss: 18.0129
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.3794
                       Mean reward: 832.54
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 161.7933
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.12s
                      Time elapsed: 00:58:07
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 46233 steps/s (collection: 2.000s, learning 0.127s)
             Mean action noise std: 2.85
          Mean value_function loss: 23.4546
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.3917
                       Mean reward: 784.84
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7457
    Episode_Reward/rotating_object: 158.2496
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.13s
                      Time elapsed: 00:58:09
                               ETA: 00:10:05

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 44942 steps/s (collection: 2.042s, learning 0.146s)
             Mean action noise std: 2.85
          Mean value_function loss: 18.0551
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.4056
                       Mean reward: 823.22
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 163.5494
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.19s
                      Time elapsed: 00:58:11
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 47196 steps/s (collection: 1.968s, learning 0.115s)
             Mean action noise std: 2.85
          Mean value_function loss: 25.2378
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.4144
                       Mean reward: 801.20
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 160.1730
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.08s
                      Time elapsed: 00:58:13
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 46680 steps/s (collection: 1.985s, learning 0.121s)
             Mean action noise std: 2.85
          Mean value_function loss: 25.3120
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.4242
                       Mean reward: 819.69
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 161.1638
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.11s
                      Time elapsed: 00:58:16
                               ETA: 00:09:57

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 46134 steps/s (collection: 1.994s, learning 0.137s)
             Mean action noise std: 2.85
          Mean value_function loss: 17.1315
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.4403
                       Mean reward: 812.54
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 0.7534
    Episode_Reward/rotating_object: 162.4418
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.13s
                      Time elapsed: 00:58:18
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 46133 steps/s (collection: 2.011s, learning 0.120s)
             Mean action noise std: 2.85
          Mean value_function loss: 26.1651
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.4544
                       Mean reward: 823.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7515
    Episode_Reward/rotating_object: 160.6513
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.13s
                      Time elapsed: 00:58:20
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 46151 steps/s (collection: 2.008s, learning 0.122s)
             Mean action noise std: 2.86
          Mean value_function loss: 20.4587
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.4699
                       Mean reward: 795.38
               Mean episode length: 249.39
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 161.5867
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.13s
                      Time elapsed: 00:58:22
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 41206 steps/s (collection: 2.245s, learning 0.141s)
             Mean action noise std: 2.86
          Mean value_function loss: 21.1633
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.4846
                       Mean reward: 817.10
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 161.0169
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.39s
                      Time elapsed: 00:58:24
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 46135 steps/s (collection: 2.000s, learning 0.131s)
             Mean action noise std: 2.86
          Mean value_function loss: 18.8258
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.4925
                       Mean reward: 823.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 161.5247
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.13s
                      Time elapsed: 00:58:26
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 46185 steps/s (collection: 2.003s, learning 0.125s)
             Mean action noise std: 2.86
          Mean value_function loss: 21.7713
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 42.5064
                       Mean reward: 807.85
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 161.7866
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.13s
                      Time elapsed: 00:58:29
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 44631 steps/s (collection: 2.061s, learning 0.142s)
             Mean action noise std: 2.86
          Mean value_function loss: 14.8796
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 42.5196
                       Mean reward: 814.63
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 161.2672
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 18.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.20s
                      Time elapsed: 00:58:31
                               ETA: 00:09:37

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 47655 steps/s (collection: 1.944s, learning 0.119s)
             Mean action noise std: 2.87
          Mean value_function loss: 21.5030
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.5245
                       Mean reward: 797.04
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 161.9712
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.06s
                      Time elapsed: 00:58:33
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 46140 steps/s (collection: 1.994s, learning 0.136s)
             Mean action noise std: 2.87
          Mean value_function loss: 16.4866
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 42.5306
                       Mean reward: 800.86
               Mean episode length: 246.12
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 160.2778
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.13s
                      Time elapsed: 00:58:35
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 40497 steps/s (collection: 2.316s, learning 0.111s)
             Mean action noise std: 2.87
          Mean value_function loss: 14.8703
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.5342
                       Mean reward: 830.58
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7558
    Episode_Reward/rotating_object: 162.7451
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.43s
                      Time elapsed: 00:58:37
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 46891 steps/s (collection: 1.968s, learning 0.128s)
             Mean action noise std: 2.87
          Mean value_function loss: 18.3382
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.5379
                       Mean reward: 804.20
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7550
    Episode_Reward/rotating_object: 161.7083
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.10s
                      Time elapsed: 00:58:40
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 41817 steps/s (collection: 2.237s, learning 0.114s)
             Mean action noise std: 2.87
          Mean value_function loss: 15.1373
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.5435
                       Mean reward: 825.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7505
    Episode_Reward/rotating_object: 161.0120
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.35s
                      Time elapsed: 00:58:42
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 45804 steps/s (collection: 2.021s, learning 0.125s)
             Mean action noise std: 2.87
          Mean value_function loss: 24.5680
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.5489
                       Mean reward: 814.72
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 160.4887
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.15s
                      Time elapsed: 00:58:44
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 47102 steps/s (collection: 1.968s, learning 0.119s)
             Mean action noise std: 2.87
          Mean value_function loss: 25.4374
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.5585
                       Mean reward: 819.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7540
    Episode_Reward/rotating_object: 162.5676
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.09s
                      Time elapsed: 00:58:46
                               ETA: 00:09:17

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 43725 steps/s (collection: 2.120s, learning 0.128s)
             Mean action noise std: 2.88
          Mean value_function loss: 30.0904
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.5705
                       Mean reward: 807.72
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.7447
    Episode_Reward/rotating_object: 160.0600
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.25s
                      Time elapsed: 00:58:48
                               ETA: 00:09:15

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 47114 steps/s (collection: 1.930s, learning 0.156s)
             Mean action noise std: 2.88
          Mean value_function loss: 22.4596
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.5753
                       Mean reward: 819.07
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 161.9535
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.09s
                      Time elapsed: 00:58:50
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 45837 steps/s (collection: 2.010s, learning 0.135s)
             Mean action noise std: 2.88
          Mean value_function loss: 25.5903
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.5765
                       Mean reward: 821.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7576
    Episode_Reward/rotating_object: 163.8679
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.14s
                      Time elapsed: 00:58:53
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 43151 steps/s (collection: 2.139s, learning 0.139s)
             Mean action noise std: 2.88
          Mean value_function loss: 15.3153
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.5826
                       Mean reward: 823.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 162.4855
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.28s
                      Time elapsed: 00:58:55
                               ETA: 00:09:06

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 44718 steps/s (collection: 2.064s, learning 0.134s)
             Mean action noise std: 2.88
          Mean value_function loss: 27.4154
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.5861
                       Mean reward: 819.07
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7485
    Episode_Reward/rotating_object: 161.3194
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.20s
                      Time elapsed: 00:58:57
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 45875 steps/s (collection: 2.020s, learning 0.123s)
             Mean action noise std: 2.88
          Mean value_function loss: 29.1800
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.5942
                       Mean reward: 787.90
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 0.7375
    Episode_Reward/rotating_object: 157.1709
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.14s
                      Time elapsed: 00:58:59
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 47755 steps/s (collection: 1.939s, learning 0.120s)
             Mean action noise std: 2.88
          Mean value_function loss: 26.8999
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.6072
                       Mean reward: 813.81
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 0.7457
    Episode_Reward/rotating_object: 160.9077
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.06s
                      Time elapsed: 00:59:01
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 48001 steps/s (collection: 1.930s, learning 0.118s)
             Mean action noise std: 2.89
          Mean value_function loss: 23.0768
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.6207
                       Mean reward: 817.21
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.7533
    Episode_Reward/rotating_object: 161.0579
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.05s
                      Time elapsed: 00:59:03
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 41170 steps/s (collection: 2.139s, learning 0.249s)
             Mean action noise std: 2.89
          Mean value_function loss: 18.1658
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.6274
                       Mean reward: 781.78
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 0.7426
    Episode_Reward/rotating_object: 159.1357
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.39s
                      Time elapsed: 00:59:06
                               ETA: 00:08:52

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 45693 steps/s (collection: 2.029s, learning 0.122s)
             Mean action noise std: 2.89
          Mean value_function loss: 21.7747
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6283
                       Mean reward: 818.16
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7515
    Episode_Reward/rotating_object: 161.3426
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.15s
                      Time elapsed: 00:59:08
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 46422 steps/s (collection: 1.992s, learning 0.126s)
             Mean action noise std: 2.89
          Mean value_function loss: 23.8545
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6326
                       Mean reward: 823.29
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 161.4698
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.12s
                      Time elapsed: 00:59:10
                               ETA: 00:08:47

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 46037 steps/s (collection: 2.018s, learning 0.117s)
             Mean action noise std: 2.89
          Mean value_function loss: 15.9528
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6363
                       Mean reward: 825.87
               Mean episode length: 248.50
    Episode_Reward/reaching_object: 0.7513
    Episode_Reward/rotating_object: 161.9353
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.14s
                      Time elapsed: 00:59:12
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 47188 steps/s (collection: 1.964s, learning 0.119s)
             Mean action noise std: 2.89
          Mean value_function loss: 25.9165
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.6339
                       Mean reward: 824.39
               Mean episode length: 248.28
    Episode_Reward/reaching_object: 0.7533
    Episode_Reward/rotating_object: 161.7034
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.08s
                      Time elapsed: 00:59:14
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 46854 steps/s (collection: 1.984s, learning 0.114s)
             Mean action noise std: 2.89
          Mean value_function loss: 25.3122
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.6401
                       Mean reward: 836.25
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7546
    Episode_Reward/rotating_object: 162.8681
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 18.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.10s
                      Time elapsed: 00:59:16
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 46146 steps/s (collection: 2.000s, learning 0.131s)
             Mean action noise std: 2.89
          Mean value_function loss: 26.7231
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.6453
                       Mean reward: 772.63
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 159.4030
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.13s
                      Time elapsed: 00:59:18
                               ETA: 00:08:35

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 45614 steps/s (collection: 2.003s, learning 0.153s)
             Mean action noise std: 2.89
          Mean value_function loss: 28.9750
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.6500
                       Mean reward: 787.76
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 160.4013
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.16s
                      Time elapsed: 00:59:21
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 45645 steps/s (collection: 2.011s, learning 0.143s)
             Mean action noise std: 2.90
          Mean value_function loss: 23.6173
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.6591
                       Mean reward: 808.87
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 159.5066
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.15s
                      Time elapsed: 00:59:23
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 46563 steps/s (collection: 1.979s, learning 0.132s)
             Mean action noise std: 2.90
          Mean value_function loss: 16.4034
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.6662
                       Mean reward: 824.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7538
    Episode_Reward/rotating_object: 162.7145
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.11s
                      Time elapsed: 00:59:25
                               ETA: 00:08:27

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 46316 steps/s (collection: 2.004s, learning 0.118s)
             Mean action noise std: 2.90
          Mean value_function loss: 21.2914
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.6713
                       Mean reward: 795.97
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7523
    Episode_Reward/rotating_object: 161.4910
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.12s
                      Time elapsed: 00:59:27
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 43803 steps/s (collection: 2.030s, learning 0.215s)
             Mean action noise std: 2.90
          Mean value_function loss: 24.2632
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 42.6758
                       Mean reward: 783.13
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 160.6354
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.24s
                      Time elapsed: 00:59:29
                               ETA: 00:08:21

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 35678 steps/s (collection: 2.656s, learning 0.100s)
             Mean action noise std: 2.90
          Mean value_function loss: 16.2157
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.6791
                       Mean reward: 804.54
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 0.7477
    Episode_Reward/rotating_object: 162.2594
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.76s
                      Time elapsed: 00:59:32
                               ETA: 00:08:19

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 47414 steps/s (collection: 1.979s, learning 0.095s)
             Mean action noise std: 2.90
          Mean value_function loss: 24.0130
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.6874
                       Mean reward: 783.85
               Mean episode length: 246.36
    Episode_Reward/reaching_object: 0.7503
    Episode_Reward/rotating_object: 160.3678
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.07s
                      Time elapsed: 00:59:34
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 47872 steps/s (collection: 1.946s, learning 0.107s)
             Mean action noise std: 2.91
          Mean value_function loss: 25.5535
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.6977
                       Mean reward: 793.56
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 159.1304
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.05s
                      Time elapsed: 00:59:36
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 47078 steps/s (collection: 1.983s, learning 0.106s)
             Mean action noise std: 2.91
          Mean value_function loss: 18.7013
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 42.7073
                       Mean reward: 806.43
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 162.0969
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.09s
                      Time elapsed: 00:59:38
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 48827 steps/s (collection: 1.909s, learning 0.104s)
             Mean action noise std: 2.91
          Mean value_function loss: 25.8784
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.7119
                       Mean reward: 819.86
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 162.4302
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.01s
                      Time elapsed: 00:59:40
                               ETA: 00:08:07

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 48621 steps/s (collection: 1.917s, learning 0.105s)
             Mean action noise std: 2.91
          Mean value_function loss: 18.9213
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.7169
                       Mean reward: 822.53
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7456
    Episode_Reward/rotating_object: 161.4117
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.02s
                      Time elapsed: 00:59:42
                               ETA: 00:08:05

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 48218 steps/s (collection: 1.930s, learning 0.108s)
             Mean action noise std: 2.91
          Mean value_function loss: 14.8270
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.7226
                       Mean reward: 836.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7577
    Episode_Reward/rotating_object: 165.1142
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.04s
                      Time elapsed: 00:59:44
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 49127 steps/s (collection: 1.893s, learning 0.108s)
             Mean action noise std: 2.91
          Mean value_function loss: 11.2577
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.7268
                       Mean reward: 827.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 162.2755
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.00s
                      Time elapsed: 00:59:46
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 47116 steps/s (collection: 1.987s, learning 0.099s)
             Mean action noise std: 2.91
          Mean value_function loss: 18.3977
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 42.7267
                       Mean reward: 821.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 163.2606
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.09s
                      Time elapsed: 00:59:48
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 49165 steps/s (collection: 1.873s, learning 0.126s)
             Mean action noise std: 2.91
          Mean value_function loss: 23.7061
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.7316
                       Mean reward: 813.87
               Mean episode length: 246.74
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 162.5364
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.00s
                      Time elapsed: 00:59:50
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 48738 steps/s (collection: 1.896s, learning 0.121s)
             Mean action noise std: 2.92
          Mean value_function loss: 27.1865
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.7450
                       Mean reward: 795.69
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 0.7448
    Episode_Reward/rotating_object: 160.9064
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.02s
                      Time elapsed: 00:59:52
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 49012 steps/s (collection: 1.886s, learning 0.120s)
             Mean action noise std: 2.92
          Mean value_function loss: 22.0948
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.7607
                       Mean reward: 820.74
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 160.2547
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.01s
                      Time elapsed: 00:59:54
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 47332 steps/s (collection: 1.974s, learning 0.103s)
             Mean action noise std: 2.92
          Mean value_function loss: 22.6184
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.7700
                       Mean reward: 783.54
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 162.0102
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.08s
                      Time elapsed: 00:59:56
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 48132 steps/s (collection: 1.936s, learning 0.107s)
             Mean action noise std: 2.92
          Mean value_function loss: 17.3732
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.7782
                       Mean reward: 833.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 162.4359
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.04s
                      Time elapsed: 00:59:58
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 47701 steps/s (collection: 1.945s, learning 0.116s)
             Mean action noise std: 2.92
          Mean value_function loss: 18.5197
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.7865
                       Mean reward: 812.29
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 160.2313
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.06s
                      Time elapsed: 01:00:01
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 47620 steps/s (collection: 1.940s, learning 0.125s)
             Mean action noise std: 2.92
          Mean value_function loss: 18.6225
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.7895
                       Mean reward: 826.47
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 161.7673
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.06s
                      Time elapsed: 01:00:03
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 48228 steps/s (collection: 1.905s, learning 0.134s)
             Mean action noise std: 2.93
          Mean value_function loss: 22.6396
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.7986
                       Mean reward: 814.05
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 162.6663
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.04s
                      Time elapsed: 01:00:05
                               ETA: 00:07:34

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 18792 steps/s (collection: 5.080s, learning 0.152s)
             Mean action noise std: 2.93
          Mean value_function loss: 19.5372
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.8122
                       Mean reward: 805.95
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 162.1834
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.23s
                      Time elapsed: 01:00:10
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 12834 steps/s (collection: 7.523s, learning 0.137s)
             Mean action noise std: 2.93
          Mean value_function loss: 22.9290
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.8250
                       Mean reward: 795.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7439
    Episode_Reward/rotating_object: 158.6144
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 7.66s
                      Time elapsed: 01:00:18
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 13336 steps/s (collection: 7.098s, learning 0.274s)
             Mean action noise std: 2.93
          Mean value_function loss: 22.4048
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.8375
                       Mean reward: 773.74
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 0.7443
    Episode_Reward/rotating_object: 159.3499
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 7.37s
                      Time elapsed: 01:00:25
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 13376 steps/s (collection: 7.201s, learning 0.148s)
             Mean action noise std: 2.93
          Mean value_function loss: 20.2417
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.8478
                       Mean reward: 821.74
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 162.6278
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 7.35s
                      Time elapsed: 01:00:32
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 15405 steps/s (collection: 6.233s, learning 0.149s)
             Mean action noise std: 2.93
          Mean value_function loss: 35.2923
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 42.8544
                       Mean reward: 803.44
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 160.6635
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.38s
                      Time elapsed: 01:00:39
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 13319 steps/s (collection: 7.142s, learning 0.239s)
             Mean action noise std: 2.93
          Mean value_function loss: 17.6075
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.8557
                       Mean reward: 802.25
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 0.7448
    Episode_Reward/rotating_object: 161.1100
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 7.38s
                      Time elapsed: 01:00:46
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 13882 steps/s (collection: 6.843s, learning 0.238s)
             Mean action noise std: 2.94
          Mean value_function loss: 24.3947
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.8597
                       Mean reward: 808.41
               Mean episode length: 244.96
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 162.5478
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 7.08s
                      Time elapsed: 01:00:53
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 13234 steps/s (collection: 7.235s, learning 0.194s)
             Mean action noise std: 2.94
          Mean value_function loss: 35.2497
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.8672
                       Mean reward: 780.48
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 0.7417
    Episode_Reward/rotating_object: 160.5053
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 7.43s
                      Time elapsed: 01:01:01
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 12043 steps/s (collection: 7.995s, learning 0.168s)
             Mean action noise std: 2.94
          Mean value_function loss: 26.6146
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.8772
                       Mean reward: 806.24
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 161.2610
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 8.16s
                      Time elapsed: 01:01:09
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 38584 steps/s (collection: 2.339s, learning 0.209s)
             Mean action noise std: 2.94
          Mean value_function loss: 20.9558
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.8875
                       Mean reward: 811.66
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 161.7783
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.55s
                      Time elapsed: 01:01:11
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 44829 steps/s (collection: 2.081s, learning 0.112s)
             Mean action noise std: 2.94
          Mean value_function loss: 25.2168
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.8969
                       Mean reward: 825.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7447
    Episode_Reward/rotating_object: 160.7544
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.19s
                      Time elapsed: 01:01:13
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 50077 steps/s (collection: 1.870s, learning 0.093s)
             Mean action noise std: 2.94
          Mean value_function loss: 23.5571
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.9006
                       Mean reward: 822.69
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7515
    Episode_Reward/rotating_object: 162.4407
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.96s
                      Time elapsed: 01:01:15
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 43702 steps/s (collection: 2.132s, learning 0.117s)
             Mean action noise std: 2.94
          Mean value_function loss: 30.0540
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.9025
                       Mean reward: 802.01
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 161.6545
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.25s
                      Time elapsed: 01:01:18
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 49618 steps/s (collection: 1.879s, learning 0.102s)
             Mean action noise std: 2.95
          Mean value_function loss: 27.4515
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.9070
                       Mean reward: 809.08
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 159.0418
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.98s
                      Time elapsed: 01:01:20
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 48235 steps/s (collection: 1.901s, learning 0.137s)
             Mean action noise std: 2.95
          Mean value_function loss: 18.8852
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.9163
                       Mean reward: 823.13
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7444
    Episode_Reward/rotating_object: 160.9890
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.04s
                      Time elapsed: 01:01:22
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 43907 steps/s (collection: 2.100s, learning 0.139s)
             Mean action noise std: 2.95
          Mean value_function loss: 34.4113
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.9239
                       Mean reward: 793.64
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.7368
    Episode_Reward/rotating_object: 158.0405
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.24s
                      Time elapsed: 01:01:24
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 37988 steps/s (collection: 2.408s, learning 0.180s)
             Mean action noise std: 2.95
          Mean value_function loss: 20.1032
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.9303
                       Mean reward: 828.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 163.5040
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.59s
                      Time elapsed: 01:01:27
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 39898 steps/s (collection: 2.326s, learning 0.138s)
             Mean action noise std: 2.95
          Mean value_function loss: 23.5895
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.9347
                       Mean reward: 821.10
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 158.2152
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.46s
                      Time elapsed: 01:01:29
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 37149 steps/s (collection: 2.466s, learning 0.181s)
             Mean action noise std: 2.95
          Mean value_function loss: 19.7160
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.9394
                       Mean reward: 811.00
               Mean episode length: 247.57
    Episode_Reward/reaching_object: 0.7533
    Episode_Reward/rotating_object: 162.8815
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.65s
                      Time elapsed: 01:01:32
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 36192 steps/s (collection: 2.514s, learning 0.202s)
             Mean action noise std: 2.96
          Mean value_function loss: 23.0776
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.9489
                       Mean reward: 814.22
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 161.5205
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.72s
                      Time elapsed: 01:01:34
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 43053 steps/s (collection: 2.119s, learning 0.165s)
             Mean action noise std: 2.96
          Mean value_function loss: 33.3425
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.9588
                       Mean reward: 810.75
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.7422
    Episode_Reward/rotating_object: 159.6982
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.28s
                      Time elapsed: 01:01:37
                               ETA: 00:06:41

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 41955 steps/s (collection: 2.172s, learning 0.171s)
             Mean action noise std: 2.96
          Mean value_function loss: 19.8153
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 42.9700
                       Mean reward: 835.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7530
    Episode_Reward/rotating_object: 162.0175
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.34s
                      Time elapsed: 01:01:39
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 41725 steps/s (collection: 2.128s, learning 0.228s)
             Mean action noise std: 2.96
          Mean value_function loss: 14.1817
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.9718
                       Mean reward: 823.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 161.9794
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.36s
                      Time elapsed: 01:01:41
                               ETA: 00:06:35

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 43455 steps/s (collection: 2.133s, learning 0.130s)
             Mean action noise std: 2.96
          Mean value_function loss: 18.3885
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.9766
                       Mean reward: 794.72
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 162.0877
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.26s
                      Time elapsed: 01:01:44
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 36698 steps/s (collection: 2.541s, learning 0.138s)
             Mean action noise std: 2.96
          Mean value_function loss: 24.1307
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.9900
                       Mean reward: 822.73
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7432
    Episode_Reward/rotating_object: 160.7709
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.68s
                      Time elapsed: 01:01:46
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 44437 steps/s (collection: 2.066s, learning 0.146s)
             Mean action noise std: 2.96
          Mean value_function loss: 22.2897
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.9942
                       Mean reward: 805.52
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 161.7018
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.21s
                      Time elapsed: 01:01:48
                               ETA: 00:06:27

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 41732 steps/s (collection: 2.184s, learning 0.171s)
             Mean action noise std: 2.96
          Mean value_function loss: 21.5522
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.9954
                       Mean reward: 821.60
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7465
    Episode_Reward/rotating_object: 162.6487
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.36s
                      Time elapsed: 01:01:51
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 42445 steps/s (collection: 2.154s, learning 0.162s)
             Mean action noise std: 2.97
          Mean value_function loss: 19.8355
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.0007
                       Mean reward: 826.81
               Mean episode length: 249.06
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 161.3818
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.32s
                      Time elapsed: 01:01:53
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 29366 steps/s (collection: 3.125s, learning 0.222s)
             Mean action noise std: 2.97
          Mean value_function loss: 16.8170
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.0080
                       Mean reward: 808.62
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 162.6175
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 3.35s
                      Time elapsed: 01:01:56
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 27242 steps/s (collection: 3.402s, learning 0.206s)
             Mean action noise std: 2.97
          Mean value_function loss: 20.8995
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.0129
                       Mean reward: 813.40
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.7537
    Episode_Reward/rotating_object: 161.9999
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 3.61s
                      Time elapsed: 01:02:00
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 39526 steps/s (collection: 2.331s, learning 0.156s)
             Mean action noise std: 2.97
          Mean value_function loss: 17.7803
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.0207
                       Mean reward: 826.45
               Mean episode length: 248.99
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 162.0282
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.49s
                      Time elapsed: 01:02:03
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 40437 steps/s (collection: 2.321s, learning 0.110s)
             Mean action noise std: 2.97
          Mean value_function loss: 23.9267
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.0327
                       Mean reward: 813.93
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.7424
    Episode_Reward/rotating_object: 160.3595
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.43s
                      Time elapsed: 01:02:05
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 38630 steps/s (collection: 2.390s, learning 0.155s)
             Mean action noise std: 2.97
          Mean value_function loss: 29.0069
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.0429
                       Mean reward: 787.50
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 0.7432
    Episode_Reward/rotating_object: 161.5160
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.54s
                      Time elapsed: 01:02:08
                               ETA: 00:06:08

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 41331 steps/s (collection: 2.215s, learning 0.164s)
             Mean action noise std: 2.98
          Mean value_function loss: 21.6722
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.0559
                       Mean reward: 814.53
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 0.7444
    Episode_Reward/rotating_object: 160.8648
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.38s
                      Time elapsed: 01:02:10
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 36859 steps/s (collection: 2.455s, learning 0.212s)
             Mean action noise std: 2.98
          Mean value_function loss: 18.4743
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.0681
                       Mean reward: 828.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7507
    Episode_Reward/rotating_object: 162.1151
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.67s
                      Time elapsed: 01:02:13
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 39951 steps/s (collection: 2.309s, learning 0.151s)
             Mean action noise std: 2.98
          Mean value_function loss: 24.6102
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.0755
                       Mean reward: 822.29
               Mean episode length: 247.18
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 161.7535
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.46s
                      Time elapsed: 01:02:15
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 39670 steps/s (collection: 2.339s, learning 0.139s)
             Mean action noise std: 2.98
          Mean value_function loss: 15.2401
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.0817
                       Mean reward: 827.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 162.8608
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.48s
                      Time elapsed: 01:02:18
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 35999 steps/s (collection: 2.575s, learning 0.156s)
             Mean action noise std: 2.98
          Mean value_function loss: 23.6519
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.0884
                       Mean reward: 812.82
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 163.9220
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.73s
                      Time elapsed: 01:02:20
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 33693 steps/s (collection: 2.724s, learning 0.194s)
             Mean action noise std: 2.98
          Mean value_function loss: 15.7788
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.0936
                       Mean reward: 814.90
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 161.8489
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.92s
                      Time elapsed: 01:02:23
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 36644 steps/s (collection: 2.518s, learning 0.165s)
             Mean action noise std: 2.98
          Mean value_function loss: 23.5699
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.0990
                       Mean reward: 801.84
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 159.2885
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.68s
                      Time elapsed: 01:02:26
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 40392 steps/s (collection: 2.197s, learning 0.237s)
             Mean action noise std: 2.99
          Mean value_function loss: 17.9949
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 43.1037
                       Mean reward: 802.64
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7411
    Episode_Reward/rotating_object: 158.4830
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.43s
                      Time elapsed: 01:02:28
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 36321 steps/s (collection: 2.528s, learning 0.178s)
             Mean action noise std: 2.99
          Mean value_function loss: 19.7065
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 43.1053
                       Mean reward: 818.96
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 162.7383
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.71s
                      Time elapsed: 01:02:31
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 34749 steps/s (collection: 2.612s, learning 0.217s)
             Mean action noise std: 2.99
          Mean value_function loss: 19.1418
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.1064
                       Mean reward: 826.46
               Mean episode length: 248.23
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 161.8267
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.83s
                      Time elapsed: 01:02:34
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 38114 steps/s (collection: 2.396s, learning 0.184s)
             Mean action noise std: 2.99
          Mean value_function loss: 23.4317
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.1100
                       Mean reward: 831.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7505
    Episode_Reward/rotating_object: 162.0212
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.58s
                      Time elapsed: 01:02:36
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 30328 steps/s (collection: 2.878s, learning 0.364s)
             Mean action noise std: 2.99
          Mean value_function loss: 22.1482
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.1178
                       Mean reward: 814.97
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 161.7734
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 3.24s
                      Time elapsed: 01:02:40
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 40329 steps/s (collection: 2.256s, learning 0.182s)
             Mean action noise std: 2.99
          Mean value_function loss: 21.7152
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.1278
                       Mean reward: 811.71
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7466
    Episode_Reward/rotating_object: 160.8445
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.44s
                      Time elapsed: 01:02:42
                               ETA: 00:05:32

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 37485 steps/s (collection: 2.376s, learning 0.246s)
             Mean action noise std: 2.99
          Mean value_function loss: 16.9752
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.1389
                       Mean reward: 826.28
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 163.4501
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.62s
                      Time elapsed: 01:02:45
                               ETA: 00:05:30

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 36675 steps/s (collection: 2.530s, learning 0.150s)
             Mean action noise std: 2.99
          Mean value_function loss: 25.4288
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.1507
                       Mean reward: 802.37
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 0.7403
    Episode_Reward/rotating_object: 161.3277
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.68s
                      Time elapsed: 01:02:47
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 41756 steps/s (collection: 2.182s, learning 0.173s)
             Mean action noise std: 3.00
          Mean value_function loss: 14.2721
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.1612
                       Mean reward: 812.06
               Mean episode length: 249.57
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 161.5989
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.35s
                      Time elapsed: 01:02:50
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 38787 steps/s (collection: 2.329s, learning 0.205s)
             Mean action noise std: 3.00
          Mean value_function loss: 16.4784
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.1686
                       Mean reward: 823.25
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 164.7139
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.53s
                      Time elapsed: 01:02:52
                               ETA: 00:05:21

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 31451 steps/s (collection: 2.901s, learning 0.224s)
             Mean action noise std: 3.00
          Mean value_function loss: 20.5976
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.1751
                       Mean reward: 819.25
               Mean episode length: 246.34
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 164.2836
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 3.13s
                      Time elapsed: 01:02:55
                               ETA: 00:05:19

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 38273 steps/s (collection: 2.388s, learning 0.180s)
             Mean action noise std: 3.00
          Mean value_function loss: 22.4597
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.1788
                       Mean reward: 804.11
               Mean episode length: 246.43
    Episode_Reward/reaching_object: 0.7463
    Episode_Reward/rotating_object: 161.7371
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.57s
                      Time elapsed: 01:02:58
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 32618 steps/s (collection: 2.882s, learning 0.132s)
             Mean action noise std: 3.00
          Mean value_function loss: 17.1654
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.1834
                       Mean reward: 826.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 163.1169
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 3.01s
                      Time elapsed: 01:03:01
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 41809 steps/s (collection: 2.143s, learning 0.209s)
             Mean action noise std: 3.00
          Mean value_function loss: 17.3449
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.1865
                       Mean reward: 807.86
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 163.1834
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.35s
                      Time elapsed: 01:03:03
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 43146 steps/s (collection: 2.118s, learning 0.161s)
             Mean action noise std: 3.00
          Mean value_function loss: 23.3357
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.1923
                       Mean reward: 836.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 162.7892
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.28s
                      Time elapsed: 01:03:06
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 40998 steps/s (collection: 2.298s, learning 0.100s)
             Mean action noise std: 3.01
          Mean value_function loss: 20.5408
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.1979
                       Mean reward: 825.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 160.8427
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.40s
                      Time elapsed: 01:03:08
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 45032 steps/s (collection: 2.049s, learning 0.134s)
             Mean action noise std: 3.01
          Mean value_function loss: 28.1130
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.2059
                       Mean reward: 800.34
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 0.7405
    Episode_Reward/rotating_object: 161.5695
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.18s
                      Time elapsed: 01:03:10
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 41886 steps/s (collection: 2.142s, learning 0.205s)
             Mean action noise std: 3.01
          Mean value_function loss: 18.4080
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.2148
                       Mean reward: 806.68
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 161.7072
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.35s
                      Time elapsed: 01:03:13
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 45202 steps/s (collection: 2.074s, learning 0.101s)
             Mean action noise std: 3.01
          Mean value_function loss: 20.8661
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.2206
                       Mean reward: 818.81
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 163.0584
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.17s
                      Time elapsed: 01:03:15
                               ETA: 00:04:57

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 43459 steps/s (collection: 2.113s, learning 0.149s)
             Mean action noise std: 3.01
          Mean value_function loss: 23.2498
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.2298
                       Mean reward: 818.30
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 163.4582
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.26s
                      Time elapsed: 01:03:17
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 45004 steps/s (collection: 2.043s, learning 0.141s)
             Mean action noise std: 3.01
          Mean value_function loss: 20.9024
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.2366
                       Mean reward: 822.44
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7505
    Episode_Reward/rotating_object: 163.9513
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.18s
                      Time elapsed: 01:03:19
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 43451 steps/s (collection: 2.082s, learning 0.180s)
             Mean action noise std: 3.01
          Mean value_function loss: 22.0061
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.2396
                       Mean reward: 801.86
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 0.7451
    Episode_Reward/rotating_object: 160.9692
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.26s
                      Time elapsed: 01:03:21
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 38947 steps/s (collection: 2.320s, learning 0.204s)
             Mean action noise std: 3.01
          Mean value_function loss: 19.8459
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.2462
                       Mean reward: 820.81
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 163.8624
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.52s
                      Time elapsed: 01:03:24
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 30166 steps/s (collection: 3.084s, learning 0.175s)
             Mean action noise std: 3.02
          Mean value_function loss: 22.2403
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.2506
                       Mean reward: 822.18
               Mean episode length: 246.52
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 163.9242
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 3.26s
                      Time elapsed: 01:03:27
                               ETA: 00:04:43

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 29006 steps/s (collection: 3.220s, learning 0.169s)
             Mean action noise std: 3.02
          Mean value_function loss: 15.1694
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.2556
                       Mean reward: 811.32
               Mean episode length: 246.18
    Episode_Reward/reaching_object: 0.7525
    Episode_Reward/rotating_object: 162.7099
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 3.39s
                      Time elapsed: 01:03:31
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 46282 steps/s (collection: 2.019s, learning 0.105s)
             Mean action noise std: 3.02
          Mean value_function loss: 12.4973
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 43.2616
                       Mean reward: 804.60
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 162.9186
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.12s
                      Time elapsed: 01:03:33
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 42740 steps/s (collection: 2.169s, learning 0.131s)
             Mean action noise std: 3.02
          Mean value_function loss: 20.1869
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 43.2650
                       Mean reward: 819.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7518
    Episode_Reward/rotating_object: 163.5222
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.30s
                      Time elapsed: 01:03:35
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 44250 steps/s (collection: 2.095s, learning 0.126s)
             Mean action noise std: 3.02
          Mean value_function loss: 28.0885
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 43.2663
                       Mean reward: 823.98
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7489
    Episode_Reward/rotating_object: 163.4794
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.22s
                      Time elapsed: 01:03:37
                               ETA: 00:04:32

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 38713 steps/s (collection: 2.380s, learning 0.160s)
             Mean action noise std: 3.02
          Mean value_function loss: 23.4153
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.2675
                       Mean reward: 802.21
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 162.3607
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.54s
                      Time elapsed: 01:03:40
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 43395 steps/s (collection: 2.151s, learning 0.115s)
             Mean action noise std: 3.02
          Mean value_function loss: 24.7639
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.2698
                       Mean reward: 814.86
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.7463
    Episode_Reward/rotating_object: 160.3553
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.27s
                      Time elapsed: 01:03:42
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 38495 steps/s (collection: 2.368s, learning 0.186s)
             Mean action noise std: 3.02
          Mean value_function loss: 29.7793
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.2725
                       Mean reward: 802.58
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 160.7463
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.55s
                      Time elapsed: 01:03:45
                               ETA: 00:04:24

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 40341 steps/s (collection: 2.298s, learning 0.139s)
             Mean action noise std: 3.02
          Mean value_function loss: 11.2930
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.2772
                       Mean reward: 819.50
               Mean episode length: 248.30
    Episode_Reward/reaching_object: 0.7535
    Episode_Reward/rotating_object: 163.9508
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.44s
                      Time elapsed: 01:03:47
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 43050 steps/s (collection: 2.124s, learning 0.159s)
             Mean action noise std: 3.02
          Mean value_function loss: 22.9727
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.2803
                       Mean reward: 816.92
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7558
    Episode_Reward/rotating_object: 163.6229
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.28s
                      Time elapsed: 01:03:49
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 44238 steps/s (collection: 2.064s, learning 0.159s)
             Mean action noise std: 3.02
          Mean value_function loss: 26.3734
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.2864
                       Mean reward: 791.32
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 160.7276
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.22s
                      Time elapsed: 01:03:52
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 40354 steps/s (collection: 2.248s, learning 0.188s)
             Mean action noise std: 3.03
          Mean value_function loss: 29.6091
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.2925
                       Mean reward: 836.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7438
    Episode_Reward/rotating_object: 161.5105
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.44s
                      Time elapsed: 01:03:54
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 42890 steps/s (collection: 2.136s, learning 0.156s)
             Mean action noise std: 3.03
          Mean value_function loss: 15.8101
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.3008
                       Mean reward: 811.53
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 163.5506
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.29s
                      Time elapsed: 01:03:56
                               ETA: 00:04:10

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 37317 steps/s (collection: 2.459s, learning 0.176s)
             Mean action noise std: 3.03
          Mean value_function loss: 25.5327
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.3119
                       Mean reward: 810.01
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 160.8339
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.63s
                      Time elapsed: 01:03:59
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 39957 steps/s (collection: 2.284s, learning 0.177s)
             Mean action noise std: 3.03
          Mean value_function loss: 22.8629
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.3269
                       Mean reward: 810.24
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.7378
    Episode_Reward/rotating_object: 159.5713
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.46s
                      Time elapsed: 01:04:01
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 39887 steps/s (collection: 2.312s, learning 0.152s)
             Mean action noise std: 3.03
          Mean value_function loss: 22.0993
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.3352
                       Mean reward: 821.77
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 161.7778
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.46s
                      Time elapsed: 01:04:04
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 38833 steps/s (collection: 2.360s, learning 0.171s)
             Mean action noise std: 3.03
          Mean value_function loss: 27.3429
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.3419
                       Mean reward: 828.09
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 162.6186
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.53s
                      Time elapsed: 01:04:06
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 33803 steps/s (collection: 2.753s, learning 0.155s)
             Mean action noise std: 3.03
          Mean value_function loss: 27.8500
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.3517
                       Mean reward: 812.83
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.7490
    Episode_Reward/rotating_object: 162.6252
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 18.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.91s
                      Time elapsed: 01:04:09
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 37036 steps/s (collection: 2.519s, learning 0.135s)
             Mean action noise std: 3.04
          Mean value_function loss: 23.8581
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.3615
                       Mean reward: 815.94
               Mean episode length: 246.42
    Episode_Reward/reaching_object: 0.7444
    Episode_Reward/rotating_object: 161.2886
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.65s
                      Time elapsed: 01:04:12
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 38108 steps/s (collection: 2.372s, learning 0.208s)
             Mean action noise std: 3.04
          Mean value_function loss: 28.7677
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.3672
                       Mean reward: 822.52
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7417
    Episode_Reward/rotating_object: 160.4620
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.58s
                      Time elapsed: 01:04:15
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 39318 steps/s (collection: 2.320s, learning 0.180s)
             Mean action noise std: 3.04
          Mean value_function loss: 24.7504
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.3711
                       Mean reward: 762.45
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 0.7390
    Episode_Reward/rotating_object: 158.8831
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.50s
                      Time elapsed: 01:04:17
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 43341 steps/s (collection: 2.158s, learning 0.111s)
             Mean action noise std: 3.04
          Mean value_function loss: 27.0700
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.3768
                       Mean reward: 804.40
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.7451
    Episode_Reward/rotating_object: 160.0851
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.27s
                      Time elapsed: 01:04:19
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 48301 steps/s (collection: 1.924s, learning 0.111s)
             Mean action noise std: 3.04
          Mean value_function loss: 22.1844
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.3786
                       Mean reward: 797.19
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 161.9532
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.04s
                      Time elapsed: 01:04:21
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 49661 steps/s (collection: 1.851s, learning 0.129s)
             Mean action noise std: 3.04
          Mean value_function loss: 19.4414
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.3823
                       Mean reward: 822.45
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 162.4214
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.98s
                      Time elapsed: 01:04:23
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 20180 steps/s (collection: 4.282s, learning 0.590s)
             Mean action noise std: 3.04
          Mean value_function loss: 16.5219
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.3880
                       Mean reward: 829.97
               Mean episode length: 248.44
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 162.7637
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 4.87s
                      Time elapsed: 01:04:28
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 30064 steps/s (collection: 3.150s, learning 0.120s)
             Mean action noise std: 3.04
          Mean value_function loss: 32.0634
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.3933
                       Mean reward: 813.03
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 0.7327
    Episode_Reward/rotating_object: 157.9022
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 3.27s
                      Time elapsed: 01:04:31
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 39772 steps/s (collection: 2.375s, learning 0.096s)
             Mean action noise std: 3.04
          Mean value_function loss: 20.5705
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.4027
                       Mean reward: 825.28
               Mean episode length: 247.61
    Episode_Reward/reaching_object: 0.7496
    Episode_Reward/rotating_object: 163.7567
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.47s
                      Time elapsed: 01:04:34
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 40488 steps/s (collection: 2.268s, learning 0.160s)
             Mean action noise std: 3.05
          Mean value_function loss: 19.7319
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.4128
                       Mean reward: 826.08
               Mean episode length: 248.22
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 163.7621
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.43s
                      Time elapsed: 01:04:36
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 36894 steps/s (collection: 2.552s, learning 0.113s)
             Mean action noise std: 3.05
          Mean value_function loss: 19.1606
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.4234
                       Mean reward: 799.97
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 0.7407
    Episode_Reward/rotating_object: 161.1721
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.66s
                      Time elapsed: 01:04:39
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 49422 steps/s (collection: 1.879s, learning 0.110s)
             Mean action noise std: 3.05
          Mean value_function loss: 23.7517
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.4294
                       Mean reward: 818.96
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 164.7566
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.99s
                      Time elapsed: 01:04:41
                               ETA: 00:03:24

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 43987 steps/s (collection: 2.123s, learning 0.112s)
             Mean action noise std: 3.05
          Mean value_function loss: 25.0866
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.4369
                       Mean reward: 801.41
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 0.7379
    Episode_Reward/rotating_object: 161.5249
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.23s
                      Time elapsed: 01:04:43
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 46740 steps/s (collection: 1.962s, learning 0.141s)
             Mean action noise std: 3.05
          Mean value_function loss: 25.1684
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.4464
                       Mean reward: 813.69
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.7489
    Episode_Reward/rotating_object: 161.8176
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.10s
                      Time elapsed: 01:04:45
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 48541 steps/s (collection: 1.931s, learning 0.095s)
             Mean action noise std: 3.05
          Mean value_function loss: 23.7126
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.4539
                       Mean reward: 809.08
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 0.7424
    Episode_Reward/rotating_object: 161.4354
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.03s
                      Time elapsed: 01:04:47
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 47816 steps/s (collection: 1.939s, learning 0.117s)
             Mean action noise std: 3.06
          Mean value_function loss: 23.3120
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.4641
                       Mean reward: 840.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 163.9475
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.06s
                      Time elapsed: 01:04:49
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 47745 steps/s (collection: 1.955s, learning 0.104s)
             Mean action noise std: 3.06
          Mean value_function loss: 21.4848
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.4738
                       Mean reward: 812.74
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.7409
    Episode_Reward/rotating_object: 161.0844
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.06s
                      Time elapsed: 01:04:51
                               ETA: 00:03:10

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 41215 steps/s (collection: 2.168s, learning 0.218s)
             Mean action noise std: 3.06
          Mean value_function loss: 21.2789
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.4841
                       Mean reward: 799.31
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 162.9466
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.39s
                      Time elapsed: 01:04:54
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 41782 steps/s (collection: 2.255s, learning 0.098s)
             Mean action noise std: 3.06
          Mean value_function loss: 18.4671
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.4908
                       Mean reward: 794.83
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 161.9940
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.35s
                      Time elapsed: 01:04:56
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 48108 steps/s (collection: 1.947s, learning 0.096s)
             Mean action noise std: 3.06
          Mean value_function loss: 17.0007
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.4945
                       Mean reward: 803.37
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.7481
    Episode_Reward/rotating_object: 161.3016
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.04s
                      Time elapsed: 01:04:58
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 49525 steps/s (collection: 1.887s, learning 0.098s)
             Mean action noise std: 3.06
          Mean value_function loss: 22.4285
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.4985
                       Mean reward: 829.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 164.9806
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.98s
                      Time elapsed: 01:05:00
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 43363 steps/s (collection: 2.167s, learning 0.100s)
             Mean action noise std: 3.06
          Mean value_function loss: 24.6903
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.5026
                       Mean reward: 818.72
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 160.5226
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.27s
                      Time elapsed: 01:05:03
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 47248 steps/s (collection: 1.974s, learning 0.107s)
             Mean action noise std: 3.06
          Mean value_function loss: 31.8621
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.5051
                       Mean reward: 798.60
               Mean episode length: 244.65
    Episode_Reward/reaching_object: 0.7488
    Episode_Reward/rotating_object: 162.7583
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.08s
                      Time elapsed: 01:05:05
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 46804 steps/s (collection: 1.978s, learning 0.123s)
             Mean action noise std: 3.06
          Mean value_function loss: 24.4907
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 43.5064
                       Mean reward: 812.01
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 160.5346
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.10s
                      Time elapsed: 01:05:07
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 48373 steps/s (collection: 1.911s, learning 0.122s)
             Mean action noise std: 3.06
          Mean value_function loss: 32.9584
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.5074
                       Mean reward: 794.00
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 161.3026
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.03s
                      Time elapsed: 01:05:09
                               ETA: 00:02:48

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 49368 steps/s (collection: 1.868s, learning 0.123s)
             Mean action noise std: 3.07
          Mean value_function loss: 32.4348
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.5100
                       Mean reward: 811.38
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 161.3743
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.99s
                      Time elapsed: 01:05:11
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 42860 steps/s (collection: 2.161s, learning 0.133s)
             Mean action noise std: 3.07
          Mean value_function loss: 15.5702
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.5129
                       Mean reward: 816.45
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7470
    Episode_Reward/rotating_object: 162.4642
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.29s
                      Time elapsed: 01:05:13
                               ETA: 00:02:42

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 46416 steps/s (collection: 2.010s, learning 0.108s)
             Mean action noise std: 3.07
          Mean value_function loss: 19.0529
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.5168
                       Mean reward: 827.12
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.7573
    Episode_Reward/rotating_object: 164.0550
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.12s
                      Time elapsed: 01:05:15
                               ETA: 00:02:40

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 47406 steps/s (collection: 1.956s, learning 0.118s)
             Mean action noise std: 3.07
          Mean value_function loss: 30.3839
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.5232
                       Mean reward: 813.25
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 162.3102
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.07s
                      Time elapsed: 01:05:17
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 47967 steps/s (collection: 1.928s, learning 0.122s)
             Mean action noise std: 3.07
          Mean value_function loss: 21.2436
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.5296
                       Mean reward: 811.84
               Mean episode length: 246.84
    Episode_Reward/reaching_object: 0.7461
    Episode_Reward/rotating_object: 162.0287
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.05s
                      Time elapsed: 01:05:19
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 34917 steps/s (collection: 2.714s, learning 0.101s)
             Mean action noise std: 3.07
          Mean value_function loss: 31.1818
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.5446
                       Mean reward: 818.53
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 162.1380
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.82s
                      Time elapsed: 01:05:22
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 45468 steps/s (collection: 2.060s, learning 0.102s)
             Mean action noise std: 3.08
          Mean value_function loss: 24.0898
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.5585
                       Mean reward: 785.57
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 160.0992
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.16s
                      Time elapsed: 01:05:24
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 48192 steps/s (collection: 1.936s, learning 0.104s)
             Mean action noise std: 3.08
          Mean value_function loss: 23.1557
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.5646
                       Mean reward: 807.15
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7468
    Episode_Reward/rotating_object: 162.3985
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.04s
                      Time elapsed: 01:05:26
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 48916 steps/s (collection: 1.903s, learning 0.107s)
             Mean action noise std: 3.08
          Mean value_function loss: 19.9491
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.5678
                       Mean reward: 821.54
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 163.9240
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.01s
                      Time elapsed: 01:05:28
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 48166 steps/s (collection: 1.938s, learning 0.103s)
             Mean action noise std: 3.08
          Mean value_function loss: 24.4093
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.5738
                       Mean reward: 822.41
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 162.8336
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.04s
                      Time elapsed: 01:05:30
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 48548 steps/s (collection: 1.926s, learning 0.099s)
             Mean action noise std: 3.08
          Mean value_function loss: 25.0217
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.5865
                       Mean reward: 823.24
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7457
    Episode_Reward/rotating_object: 162.6287
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.02s
                      Time elapsed: 01:05:32
                               ETA: 00:02:18

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 49845 steps/s (collection: 1.866s, learning 0.107s)
             Mean action noise std: 3.08
          Mean value_function loss: 18.9628
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.5970
                       Mean reward: 770.60
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 160.2359
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.97s
                      Time elapsed: 01:05:34
                               ETA: 00:02:15

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 44017 steps/s (collection: 2.114s, learning 0.120s)
             Mean action noise std: 3.08
          Mean value_function loss: 22.0561
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.6031
                       Mean reward: 827.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7561
    Episode_Reward/rotating_object: 163.5945
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.23s
                      Time elapsed: 01:05:37
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 46660 steps/s (collection: 1.974s, learning 0.133s)
             Mean action noise std: 3.09
          Mean value_function loss: 24.7745
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.6145
                       Mean reward: 828.78
               Mean episode length: 248.48
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 161.4734
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.11s
                      Time elapsed: 01:05:39
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 47959 steps/s (collection: 1.912s, learning 0.138s)
             Mean action noise std: 3.09
          Mean value_function loss: 19.2359
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.6281
                       Mean reward: 829.99
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7487
    Episode_Reward/rotating_object: 164.1192
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.05s
                      Time elapsed: 01:05:41
                               ETA: 00:02:07

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 49969 steps/s (collection: 1.842s, learning 0.126s)
             Mean action noise std: 3.09
          Mean value_function loss: 18.0574
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 43.6398
                       Mean reward: 838.72
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7531
    Episode_Reward/rotating_object: 164.9947
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.97s
                      Time elapsed: 01:05:43
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 48691 steps/s (collection: 1.915s, learning 0.104s)
             Mean action noise std: 3.09
          Mean value_function loss: 26.9179
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.6450
                       Mean reward: 821.68
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7539
    Episode_Reward/rotating_object: 164.1123
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 18.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.02s
                      Time elapsed: 01:05:45
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 49350 steps/s (collection: 1.887s, learning 0.105s)
             Mean action noise std: 3.09
          Mean value_function loss: 13.6991
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 43.6542
                       Mean reward: 825.04
               Mean episode length: 247.61
    Episode_Reward/reaching_object: 0.7494
    Episode_Reward/rotating_object: 163.4679
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.99s
                      Time elapsed: 01:05:47
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 44762 steps/s (collection: 2.088s, learning 0.109s)
             Mean action noise std: 3.09
          Mean value_function loss: 17.3832
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.6598
                       Mean reward: 824.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 163.2240
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.20s
                      Time elapsed: 01:05:49
                               ETA: 00:01:56

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 51459 steps/s (collection: 1.814s, learning 0.097s)
             Mean action noise std: 3.09
          Mean value_function loss: 23.9248
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 43.6639
                       Mean reward: 820.63
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 164.1324
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.91s
                      Time elapsed: 01:05:51
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 46366 steps/s (collection: 1.956s, learning 0.165s)
             Mean action noise std: 3.09
          Mean value_function loss: 23.6052
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.6673
                       Mean reward: 807.07
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 163.2877
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.12s
                      Time elapsed: 01:05:53
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 50542 steps/s (collection: 1.833s, learning 0.112s)
             Mean action noise std: 3.10
          Mean value_function loss: 28.8515
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.6720
                       Mean reward: 811.78
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 161.9911
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.94s
                      Time elapsed: 01:05:55
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 37474 steps/s (collection: 2.522s, learning 0.101s)
             Mean action noise std: 3.10
          Mean value_function loss: 19.3894
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.6780
                       Mean reward: 793.85
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 161.5490
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.62s
                      Time elapsed: 01:05:57
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 35594 steps/s (collection: 2.662s, learning 0.100s)
             Mean action noise std: 3.10
          Mean value_function loss: 21.1491
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.6851
                       Mean reward: 805.84
               Mean episode length: 246.74
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 163.0304
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.76s
                      Time elapsed: 01:06:00
                               ETA: 00:01:42

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 47402 steps/s (collection: 1.955s, learning 0.119s)
             Mean action noise std: 3.10
          Mean value_function loss: 22.1265
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.6933
                       Mean reward: 818.00
               Mean episode length: 248.53
    Episode_Reward/reaching_object: 0.7535
    Episode_Reward/rotating_object: 161.9638
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.07s
                      Time elapsed: 01:06:02
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 49688 steps/s (collection: 1.881s, learning 0.098s)
             Mean action noise std: 3.10
          Mean value_function loss: 13.7052
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.6999
                       Mean reward: 819.19
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 164.0049
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.98s
                      Time elapsed: 01:06:04
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 45252 steps/s (collection: 2.053s, learning 0.119s)
             Mean action noise std: 3.10
          Mean value_function loss: 24.9256
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.7041
                       Mean reward: 793.51
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 162.5175
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.17s
                      Time elapsed: 01:06:06
                               ETA: 00:01:34

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 47167 steps/s (collection: 1.980s, learning 0.104s)
             Mean action noise std: 3.10
          Mean value_function loss: 18.6837
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.7118
                       Mean reward: 817.96
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 164.4305
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.08s
                      Time elapsed: 01:06:09
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 46852 steps/s (collection: 1.985s, learning 0.114s)
             Mean action noise std: 3.11
          Mean value_function loss: 22.8774
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 43.7186
                       Mean reward: 811.56
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 161.6292
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.10s
                      Time elapsed: 01:06:11
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 50020 steps/s (collection: 1.863s, learning 0.102s)
             Mean action noise std: 3.11
          Mean value_function loss: 18.4956
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.7225
                       Mean reward: 819.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7520
    Episode_Reward/rotating_object: 163.0556
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.97s
                      Time elapsed: 01:06:13
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 50081 steps/s (collection: 1.853s, learning 0.110s)
             Mean action noise std: 3.11
          Mean value_function loss: 15.9300
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.7332
                       Mean reward: 812.69
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 163.5972
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.96s
                      Time elapsed: 01:06:15
                               ETA: 00:01:23

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 49203 steps/s (collection: 1.896s, learning 0.102s)
             Mean action noise std: 3.11
          Mean value_function loss: 21.4786
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.7440
                       Mean reward: 793.71
               Mean episode length: 242.79
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 160.7748
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.00s
                      Time elapsed: 01:06:17
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 49009 steps/s (collection: 1.904s, learning 0.102s)
             Mean action noise std: 3.11
          Mean value_function loss: 18.4787
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.7518
                       Mean reward: 809.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 161.8936
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.01s
                      Time elapsed: 01:06:19
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 48503 steps/s (collection: 1.913s, learning 0.114s)
             Mean action noise std: 3.11
          Mean value_function loss: 16.4166
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.7586
                       Mean reward: 817.41
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7535
    Episode_Reward/rotating_object: 163.6827
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.03s
                      Time elapsed: 01:06:21
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 45381 steps/s (collection: 2.071s, learning 0.096s)
             Mean action noise std: 3.11
          Mean value_function loss: 19.1267
               Mean surrogate loss: 0.0054
                 Mean entropy loss: 43.7645
                       Mean reward: 822.44
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 163.3981
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.17s
                      Time elapsed: 01:06:23
                               ETA: 00:01:12

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 48989 steps/s (collection: 1.897s, learning 0.110s)
             Mean action noise std: 3.11
          Mean value_function loss: 23.0869
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.7658
                       Mean reward: 807.63
               Mean episode length: 248.62
    Episode_Reward/reaching_object: 0.7443
    Episode_Reward/rotating_object: 161.3204
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.01s
                      Time elapsed: 01:06:25
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 40101 steps/s (collection: 2.299s, learning 0.152s)
             Mean action noise std: 3.12
          Mean value_function loss: 22.4888
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.7689
                       Mean reward: 824.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7514
    Episode_Reward/rotating_object: 163.4132
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.45s
                      Time elapsed: 01:06:27
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 44950 steps/s (collection: 2.077s, learning 0.110s)
             Mean action noise std: 3.12
          Mean value_function loss: 19.5271
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.7746
                       Mean reward: 831.05
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 161.3856
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.19s
                      Time elapsed: 01:06:29
                               ETA: 00:01:04

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 42575 steps/s (collection: 2.165s, learning 0.144s)
             Mean action noise std: 3.12
          Mean value_function loss: 22.0343
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.7792
                       Mean reward: 784.96
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 0.7432
    Episode_Reward/rotating_object: 161.1120
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.31s
                      Time elapsed: 01:06:32
                               ETA: 00:01:02

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 40709 steps/s (collection: 2.303s, learning 0.112s)
             Mean action noise std: 3.12
          Mean value_function loss: 25.4231
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.7886
                       Mean reward: 818.27
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 162.0780
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.41s
                      Time elapsed: 01:06:34
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 48957 steps/s (collection: 1.883s, learning 0.125s)
             Mean action noise std: 3.12
          Mean value_function loss: 16.8342
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.7986
                       Mean reward: 812.18
               Mean episode length: 248.56
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 163.8943
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.01s
                      Time elapsed: 01:06:36
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 41694 steps/s (collection: 2.244s, learning 0.113s)
             Mean action noise std: 3.12
          Mean value_function loss: 22.8974
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.8061
                       Mean reward: 814.20
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 163.3542
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.36s
                      Time elapsed: 01:06:38
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 45126 steps/s (collection: 2.064s, learning 0.115s)
             Mean action noise std: 3.12
          Mean value_function loss: 23.5461
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.8116
                       Mean reward: 814.36
               Mean episode length: 246.62
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 162.4071
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.18s
                      Time elapsed: 01:06:41
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 47878 steps/s (collection: 1.948s, learning 0.106s)
             Mean action noise std: 3.13
          Mean value_function loss: 23.7358
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.8193
                       Mean reward: 785.57
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 161.7631
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.05s
                      Time elapsed: 01:06:43
                               ETA: 00:00:48

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 49700 steps/s (collection: 1.880s, learning 0.098s)
             Mean action noise std: 3.13
          Mean value_function loss: 26.9977
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.8259
                       Mean reward: 818.26
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 162.4619
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.98s
                      Time elapsed: 01:06:45
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 48433 steps/s (collection: 1.931s, learning 0.099s)
             Mean action noise std: 3.13
          Mean value_function loss: 19.0737
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.8319
                       Mean reward: 808.77
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 163.1470
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.03s
                      Time elapsed: 01:06:47
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 48853 steps/s (collection: 1.915s, learning 0.098s)
             Mean action noise std: 3.13
          Mean value_function loss: 25.4301
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.8352
                       Mean reward: 820.05
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.7491
    Episode_Reward/rotating_object: 163.3686
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.01s
                      Time elapsed: 01:06:49
                               ETA: 00:00:40

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 46982 steps/s (collection: 1.990s, learning 0.103s)
             Mean action noise std: 3.13
          Mean value_function loss: 21.6575
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.8459
                       Mean reward: 801.53
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7475
    Episode_Reward/rotating_object: 162.3982
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.09s
                      Time elapsed: 01:06:51
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 48218 steps/s (collection: 1.927s, learning 0.112s)
             Mean action noise std: 3.13
          Mean value_function loss: 25.6138
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 43.8542
                       Mean reward: 760.87
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 159.8073
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.04s
                      Time elapsed: 01:06:53
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 36250 steps/s (collection: 2.558s, learning 0.154s)
             Mean action noise std: 3.13
          Mean value_function loss: 25.6780
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.8575
                       Mean reward: 838.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 162.2134
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.71s
                      Time elapsed: 01:06:56
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 36937 steps/s (collection: 2.527s, learning 0.135s)
             Mean action noise std: 3.14
          Mean value_function loss: 18.0392
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.8630
                       Mean reward: 836.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 163.8936
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.66s
                      Time elapsed: 01:06:58
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 36478 steps/s (collection: 2.572s, learning 0.123s)
             Mean action noise std: 3.14
          Mean value_function loss: 18.5704
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.8676
                       Mean reward: 821.59
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 163.6113
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.69s
                      Time elapsed: 01:07:01
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 38235 steps/s (collection: 2.426s, learning 0.145s)
             Mean action noise std: 3.14
          Mean value_function loss: 24.3573
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.8691
                       Mean reward: 806.62
               Mean episode length: 246.29
    Episode_Reward/reaching_object: 0.7503
    Episode_Reward/rotating_object: 162.7844
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.57s
                      Time elapsed: 01:07:04
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 42473 steps/s (collection: 2.206s, learning 0.108s)
             Mean action noise std: 3.14
          Mean value_function loss: 20.8742
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.8706
                       Mean reward: 806.85
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 0.7409
    Episode_Reward/rotating_object: 160.6586
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.31s
                      Time elapsed: 01:07:06
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 42674 steps/s (collection: 2.150s, learning 0.154s)
             Mean action noise std: 3.14
          Mean value_function loss: 12.8595
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.8759
                       Mean reward: 833.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7581
    Episode_Reward/rotating_object: 165.4097
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.30s
                      Time elapsed: 01:07:08
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 36381 steps/s (collection: 2.593s, learning 0.109s)
             Mean action noise std: 3.14
          Mean value_function loss: 29.2193
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.8847
                       Mean reward: 807.80
               Mean episode length: 246.18
    Episode_Reward/reaching_object: 0.7546
    Episode_Reward/rotating_object: 163.5813
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.70s
                      Time elapsed: 01:07:11
                               ETA: 00:00:16

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 46297 steps/s (collection: 2.011s, learning 0.112s)
             Mean action noise std: 3.14
          Mean value_function loss: 27.5903
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.8922
                       Mean reward: 815.22
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 161.6234
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.12s
                      Time elapsed: 01:07:13
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 40575 steps/s (collection: 2.294s, learning 0.129s)
             Mean action noise std: 3.14
          Mean value_function loss: 19.9263
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.9019
                       Mean reward: 821.41
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 162.3661
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.42s
                      Time elapsed: 01:07:15
                               ETA: 00:00:10

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 43371 steps/s (collection: 2.135s, learning 0.132s)
             Mean action noise std: 3.15
          Mean value_function loss: 18.4435
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.9120
                       Mean reward: 835.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 163.5303
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.27s
                      Time elapsed: 01:07:18
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 45855 steps/s (collection: 2.013s, learning 0.131s)
             Mean action noise std: 3.15
          Mean value_function loss: 22.4569
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.9204
                       Mean reward: 831.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7498
    Episode_Reward/rotating_object: 163.7436
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.14s
                      Time elapsed: 01:07:20
                               ETA: 00:00:05

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 47101 steps/s (collection: 1.963s, learning 0.124s)
             Mean action noise std: 3.15
          Mean value_function loss: 19.2516
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.9304
                       Mean reward: 823.81
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7551
    Episode_Reward/rotating_object: 165.5117
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.09s
                      Time elapsed: 01:07:22
                               ETA: 00:00:02

