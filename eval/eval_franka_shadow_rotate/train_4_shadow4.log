################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 21086 steps/s (collection: 4.521s, learning 0.141s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0037
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 36.9395
                       Mean reward: 0.00
               Mean episode length: 21.94
    Episode_Reward/reaching_object: 0.0009
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 4.66s
                      Time elapsed: 00:00:04
                               ETA: 01:56:32

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 48086 steps/s (collection: 1.906s, learning 0.138s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 37.0445
                       Mean reward: 0.00
               Mean episode length: 45.00
    Episode_Reward/reaching_object: 0.0024
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0008
          Episode_Reward/joint_vel: -0.0011
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 2.04s
                      Time elapsed: 00:00:06
                               ETA: 01:23:46

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 48863 steps/s (collection: 1.870s, learning 0.142s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.1102
                       Mean reward: 0.01
               Mean episode length: 69.37
    Episode_Reward/reaching_object: 0.0037
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0013
          Episode_Reward/joint_vel: -0.0018
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 2.01s
                      Time elapsed: 00:00:08
                               ETA: 01:12:33

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 48239 steps/s (collection: 1.908s, learning 0.130s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.1497
                       Mean reward: 0.00
               Mean episode length: 93.77
    Episode_Reward/reaching_object: 0.0051
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0018
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 2.04s
                      Time elapsed: 00:00:10
                               ETA: 01:07:05

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 49503 steps/s (collection: 1.854s, learning 0.132s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.1523
                       Mean reward: 0.00
               Mean episode length: 117.34
    Episode_Reward/reaching_object: 0.0066
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0033
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 1.99s
                      Time elapsed: 00:00:12
                               ETA: 01:03:32

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 54788 steps/s (collection: 1.683s, learning 0.111s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.1623
                       Mean reward: 0.01
               Mean episode length: 141.43
    Episode_Reward/reaching_object: 0.0080
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.79s
                      Time elapsed: 00:00:14
                               ETA: 01:00:21

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 54290 steps/s (collection: 1.696s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 37.1780
                       Mean reward: 0.01
               Mean episode length: 165.01
    Episode_Reward/reaching_object: 0.0109
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.81s
                      Time elapsed: 00:00:16
                               ETA: 00:58:08

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 53008 steps/s (collection: 1.731s, learning 0.123s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 37.1871
                       Mean reward: 0.02
               Mean episode length: 189.52
    Episode_Reward/reaching_object: 0.0115
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.85s
                      Time elapsed: 00:00:18
                               ETA: 00:56:36

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 51698 steps/s (collection: 1.779s, learning 0.122s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 37.1622
                       Mean reward: 0.02
               Mean episode length: 213.81
    Episode_Reward/reaching_object: 0.0144
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 1.90s
                      Time elapsed: 00:00:20
                               ETA: 00:55:32

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 51309 steps/s (collection: 1.792s, learning 0.124s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 37.1856
                       Mean reward: 0.04
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 0.0176
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.92s
                      Time elapsed: 00:00:22
                               ETA: 00:54:42

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 51308 steps/s (collection: 1.791s, learning 0.125s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 37.1793
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0194
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.92s
                      Time elapsed: 00:00:23
                               ETA: 00:54:02

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 52044 steps/s (collection: 1.768s, learning 0.121s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 37.2028
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0211
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.89s
                      Time elapsed: 00:00:25
                               ETA: 00:53:24

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 51597 steps/s (collection: 1.782s, learning 0.123s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 37.2410
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0273
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.91s
                      Time elapsed: 00:00:27
                               ETA: 00:52:53

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 51131 steps/s (collection: 1.799s, learning 0.124s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 37.2728
                       Mean reward: 0.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0333
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.92s
                      Time elapsed: 00:00:29
                               ETA: 00:52:29

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 51626 steps/s (collection: 1.782s, learning 0.122s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 37.3217
                       Mean reward: 0.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0411
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.90s
                      Time elapsed: 00:00:31
                               ETA: 00:52:06

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 52021 steps/s (collection: 1.770s, learning 0.120s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 37.3629
                       Mean reward: 0.25
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0504
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.89s
                      Time elapsed: 00:00:33
                               ETA: 00:51:44

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 52097 steps/s (collection: 1.768s, learning 0.119s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 37.4468
                       Mean reward: 0.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0703
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.89s
                      Time elapsed: 00:00:35
                               ETA: 00:51:24

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 51309 steps/s (collection: 1.795s, learning 0.121s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0009
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 37.4751
                       Mean reward: 0.44
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0995
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.92s
                      Time elapsed: 00:00:37
                               ETA: 00:51:08

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 49880 steps/s (collection: 1.848s, learning 0.123s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0080
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 37.5022
                       Mean reward: 0.54
               Mean episode length: 249.99
    Episode_Reward/reaching_object: 0.1119
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.97s
                      Time elapsed: 00:00:39
                               ETA: 00:50:59

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 47658 steps/s (collection: 1.933s, learning 0.130s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0071
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 37.5210
                       Mean reward: 0.85
               Mean episode length: 249.29
    Episode_Reward/reaching_object: 0.1543
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 2.06s
                      Time elapsed: 00:00:41
                               ETA: 00:50:56

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 47703 steps/s (collection: 1.939s, learning 0.122s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0035
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.5654
                       Mean reward: 0.89
               Mean episode length: 248.95
    Episode_Reward/reaching_object: 0.1898
    Episode_Reward/rotating_object: 0.0006
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 2.06s
                      Time elapsed: 00:00:43
                               ETA: 00:50:54

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 46467 steps/s (collection: 1.987s, learning 0.128s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0047
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.5790
                       Mean reward: 1.32
               Mean episode length: 246.49
    Episode_Reward/reaching_object: 0.2390
    Episode_Reward/rotating_object: 0.0027
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 2.12s
                      Time elapsed: 00:00:45
                               ETA: 00:50:55

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 46129 steps/s (collection: 1.995s, learning 0.136s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0048
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.6258
                       Mean reward: 1.35
               Mean episode length: 244.65
    Episode_Reward/reaching_object: 0.2869
    Episode_Reward/rotating_object: 0.0048
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 2.13s
                      Time elapsed: 00:00:47
                               ETA: 00:50:58

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 45946 steps/s (collection: 2.005s, learning 0.135s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0065
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 37.6753
                       Mean reward: 1.63
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 0.3219
    Episode_Reward/rotating_object: 0.0032
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.14s
                      Time elapsed: 00:00:49
                               ETA: 00:51:00

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 45908 steps/s (collection: 2.007s, learning 0.134s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0080
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 37.7563
                       Mean reward: 1.73
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 0.3599
    Episode_Reward/rotating_object: 0.0053
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.14s
                      Time elapsed: 00:00:51
                               ETA: 00:51:02

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 45105 steps/s (collection: 2.044s, learning 0.136s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0099
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 37.7963
                       Mean reward: 1.96
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.3767
    Episode_Reward/rotating_object: 0.0090
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 9.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.18s
                      Time elapsed: 00:00:54
                               ETA: 00:51:06

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 45095 steps/s (collection: 2.042s, learning 0.138s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0277
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 37.8905
                       Mean reward: 2.59
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 0.4139
    Episode_Reward/rotating_object: 0.0304
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 7.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.18s
                      Time elapsed: 00:00:56
                               ETA: 00:51:09

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 45034 steps/s (collection: 2.048s, learning 0.135s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0113
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 38.0622
                       Mean reward: 2.26
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 0.4443
    Episode_Reward/rotating_object: 0.0193
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 7.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.18s
                      Time elapsed: 00:00:58
                               ETA: 00:51:12

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 45198 steps/s (collection: 2.054s, learning 0.121s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0145
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 38.1343
                       Mean reward: 2.42
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 0.4493
    Episode_Reward/rotating_object: 0.0199
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 6.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.17s
                      Time elapsed: 00:01:00
                               ETA: 00:51:15

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 43870 steps/s (collection: 2.104s, learning 0.137s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0277
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 38.2324
                       Mean reward: 2.46
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 0.4615
    Episode_Reward/rotating_object: 0.0367
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 4.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.24s
                      Time elapsed: 00:01:02
                               ETA: 00:51:20

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 44556 steps/s (collection: 2.078s, learning 0.129s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0460
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.3463
                       Mean reward: 2.62
               Mean episode length: 220.00
    Episode_Reward/reaching_object: 0.4764
    Episode_Reward/rotating_object: 0.0675
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 5.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.21s
                      Time elapsed: 00:01:05
                               ETA: 00:51:23

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 44213 steps/s (collection: 2.075s, learning 0.148s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0461
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.3945
                       Mean reward: 2.62
               Mean episode length: 224.19
    Episode_Reward/reaching_object: 0.4825
    Episode_Reward/rotating_object: 0.0265
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 5.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.22s
                      Time elapsed: 00:01:07
                               ETA: 00:51:27

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 42033 steps/s (collection: 2.223s, learning 0.116s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0471
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 38.4937
                       Mean reward: 2.60
               Mean episode length: 217.69
    Episode_Reward/reaching_object: 0.4952
    Episode_Reward/rotating_object: 0.0490
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 4.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.34s
                      Time elapsed: 00:01:09
                               ETA: 00:51:35

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 45239 steps/s (collection: 2.059s, learning 0.114s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0348
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 38.6204
                       Mean reward: 2.91
               Mean episode length: 212.38
    Episode_Reward/reaching_object: 0.5000
    Episode_Reward/rotating_object: 0.0489
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 4.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.17s
                      Time elapsed: 00:01:11
                               ETA: 00:51:36

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 45051 steps/s (collection: 2.066s, learning 0.116s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0822
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 38.7557
                       Mean reward: 3.19
               Mean episode length: 212.87
    Episode_Reward/reaching_object: 0.5491
    Episode_Reward/rotating_object: 0.0619
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 5.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.18s
                      Time elapsed: 00:01:13
                               ETA: 00:51:37

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 43400 steps/s (collection: 2.142s, learning 0.123s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3155
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.8845
                       Mean reward: 2.90
               Mean episode length: 212.83
    Episode_Reward/reaching_object: 0.5606
    Episode_Reward/rotating_object: 0.0800
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 5.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.27s
                      Time elapsed: 00:01:16
                               ETA: 00:51:41

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 42023 steps/s (collection: 2.218s, learning 0.121s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.2869
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.1010
                       Mean reward: 3.67
               Mean episode length: 212.74
    Episode_Reward/reaching_object: 0.6090
    Episode_Reward/rotating_object: 0.1505
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 6.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.34s
                      Time elapsed: 00:01:18
                               ETA: 00:51:48

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 41985 steps/s (collection: 2.221s, learning 0.121s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.3523
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.2159
                       Mean reward: 4.57
               Mean episode length: 206.30
    Episode_Reward/reaching_object: 0.6446
    Episode_Reward/rotating_object: 0.1577
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 8.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.34s
                      Time elapsed: 00:01:20
                               ETA: 00:51:54

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 41644 steps/s (collection: 2.240s, learning 0.120s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.4613
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.4411
                       Mean reward: 6.62
               Mean episode length: 219.51
    Episode_Reward/reaching_object: 0.6943
    Episode_Reward/rotating_object: 0.3494
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 9.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.36s
                      Time elapsed: 00:01:23
                               ETA: 00:52:01

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 41445 steps/s (collection: 2.251s, learning 0.121s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.2523
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 39.6165
                       Mean reward: 4.15
               Mean episode length: 207.82
    Episode_Reward/reaching_object: 0.6883
    Episode_Reward/rotating_object: 0.2348
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 9.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.37s
                      Time elapsed: 00:01:25
                               ETA: 00:52:07

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 42045 steps/s (collection: 2.217s, learning 0.121s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.3779
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.8113
                       Mean reward: 5.43
               Mean episode length: 229.85
    Episode_Reward/reaching_object: 0.7896
    Episode_Reward/rotating_object: 0.2331
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 11.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.34s
                      Time elapsed: 00:01:27
                               ETA: 00:52:12

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 40459 steps/s (collection: 2.300s, learning 0.130s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.6840
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.9818
                       Mean reward: 5.51
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 0.8101
    Episode_Reward/rotating_object: 0.3377
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.43s
                      Time elapsed: 00:01:30
                               ETA: 00:52:20

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 41240 steps/s (collection: 2.261s, learning 0.123s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.8439
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 40.1562
                       Mean reward: 5.99
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 0.8381
    Episode_Reward/rotating_object: 0.3418
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.38s
                      Time elapsed: 00:01:32
                               ETA: 00:52:25

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 42258 steps/s (collection: 2.207s, learning 0.119s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.1882
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.2977
                       Mean reward: 8.68
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 0.8694
    Episode_Reward/rotating_object: 0.6272
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.33s
                      Time elapsed: 00:01:35
                               ETA: 00:52:29

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 42379 steps/s (collection: 2.201s, learning 0.118s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.4175
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.3973
                       Mean reward: 8.20
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.8788
    Episode_Reward/rotating_object: 0.8234
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.32s
                      Time elapsed: 00:01:37
                               ETA: 00:52:32

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 41348 steps/s (collection: 2.251s, learning 0.126s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.3736
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.5609
                       Mean reward: 6.61
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 0.9363
    Episode_Reward/rotating_object: 0.5890
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.38s
                      Time elapsed: 00:01:39
                               ETA: 00:52:36

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 40853 steps/s (collection: 2.279s, learning 0.127s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.3010
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.6444
                       Mean reward: 7.50
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 0.9360
    Episode_Reward/rotating_object: 0.8056
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.41s
                      Time elapsed: 00:01:42
                               ETA: 00:52:41

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 40837 steps/s (collection: 2.281s, learning 0.126s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.0475
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.7836
                       Mean reward: 6.55
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 0.9716
    Episode_Reward/rotating_object: 0.7739
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.41s
                      Time elapsed: 00:01:44
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 40805 steps/s (collection: 2.282s, learning 0.127s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.8605
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.8732
                       Mean reward: 9.26
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 0.9945
    Episode_Reward/rotating_object: 1.2554
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.41s
                      Time elapsed: 00:01:47
                               ETA: 00:52:51

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 40764 steps/s (collection: 2.285s, learning 0.127s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.5144
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.0217
                       Mean reward: 10.60
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.9910
    Episode_Reward/rotating_object: 1.1804
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.41s
                      Time elapsed: 00:01:49
                               ETA: 00:52:55

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 40515 steps/s (collection: 2.300s, learning 0.126s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.2746
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 41.1249
                       Mean reward: 9.18
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 0.9882
    Episode_Reward/rotating_object: 0.8584
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.43s
                      Time elapsed: 00:01:51
                               ETA: 00:53:00

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 40915 steps/s (collection: 2.283s, learning 0.120s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.4935
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.1532
                       Mean reward: 7.59
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 1.0019
    Episode_Reward/rotating_object: 1.1360
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.40s
                      Time elapsed: 00:01:54
                               ETA: 00:53:04

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 41403 steps/s (collection: 2.254s, learning 0.120s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.3440
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.2251
                       Mean reward: 10.51
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.9905
    Episode_Reward/rotating_object: 1.4103
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.37s
                      Time elapsed: 00:01:56
                               ETA: 00:53:06

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 41936 steps/s (collection: 2.225s, learning 0.120s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.4030
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.3462
                       Mean reward: 8.55
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 0.9978
    Episode_Reward/rotating_object: 1.4430
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.34s
                      Time elapsed: 00:01:58
                               ETA: 00:53:08

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 41802 steps/s (collection: 2.232s, learning 0.119s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.9451
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.4225
                       Mean reward: 12.19
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 0.9915
    Episode_Reward/rotating_object: 1.3925
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.35s
                      Time elapsed: 00:02:01
                               ETA: 00:53:10

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 41841 steps/s (collection: 2.230s, learning 0.119s)
             Mean action noise std: 1.19
          Mean value_function loss: 3.2242
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 41.4728
                       Mean reward: 8.15
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 0.9926
    Episode_Reward/rotating_object: 0.9622
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.35s
                      Time elapsed: 00:02:03
                               ETA: 00:53:11

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 41747 steps/s (collection: 2.233s, learning 0.122s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.9228
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.5056
                       Mean reward: 10.71
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 0.9964
    Episode_Reward/rotating_object: 1.3321
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.35s
                      Time elapsed: 00:02:06
                               ETA: 00:53:13

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 41668 steps/s (collection: 2.241s, learning 0.119s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.7394
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.5851
                       Mean reward: 25.08
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 1.0177
    Episode_Reward/rotating_object: 2.2596
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.36s
                      Time elapsed: 00:02:08
                               ETA: 00:53:14

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 41865 steps/s (collection: 2.226s, learning 0.122s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.5214
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 41.6511
                       Mean reward: 14.16
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.0201
    Episode_Reward/rotating_object: 2.0795
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.35s
                      Time elapsed: 00:02:10
                               ETA: 00:53:15

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 42151 steps/s (collection: 2.214s, learning 0.119s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.8401
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.6914
                       Mean reward: 13.78
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 1.0046
    Episode_Reward/rotating_object: 1.6116
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.33s
                      Time elapsed: 00:02:13
                               ETA: 00:53:16

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 42206 steps/s (collection: 2.209s, learning 0.120s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.0987
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.7763
                       Mean reward: 10.50
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 1.0333
    Episode_Reward/rotating_object: 1.3903
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.33s
                      Time elapsed: 00:02:15
                               ETA: 00:53:16

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 42203 steps/s (collection: 2.211s, learning 0.118s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.4166
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.8640
                       Mean reward: 19.09
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.0273
    Episode_Reward/rotating_object: 2.0050
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.33s
                      Time elapsed: 00:02:17
                               ETA: 00:53:16

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 42359 steps/s (collection: 2.201s, learning 0.119s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.2599
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 41.9003
                       Mean reward: 15.49
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 1.0506
    Episode_Reward/rotating_object: 1.8000
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.32s
                      Time elapsed: 00:02:20
                               ETA: 00:53:16

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 42197 steps/s (collection: 2.209s, learning 0.120s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.0147
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.9417
                       Mean reward: 18.52
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 1.0184
    Episode_Reward/rotating_object: 1.8792
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.33s
                      Time elapsed: 00:02:22
                               ETA: 00:53:17

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 42228 steps/s (collection: 2.205s, learning 0.123s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.2358
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.0277
                       Mean reward: 15.14
               Mean episode length: 246.58
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 1.6875
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.33s
                      Time elapsed: 00:02:24
                               ETA: 00:53:17

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 42120 steps/s (collection: 2.217s, learning 0.117s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.8162
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.1270
                       Mean reward: 13.09
               Mean episode length: 242.44
    Episode_Reward/reaching_object: 1.0718
    Episode_Reward/rotating_object: 1.5380
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.33s
                      Time elapsed: 00:02:27
                               ETA: 00:53:17

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 43756 steps/s (collection: 2.132s, learning 0.115s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.6638
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.1965
                       Mean reward: 17.68
               Mean episode length: 246.88
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 1.6060
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.25s
                      Time elapsed: 00:02:29
                               ETA: 00:53:15

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 43753 steps/s (collection: 2.132s, learning 0.115s)
             Mean action noise std: 1.23
          Mean value_function loss: 2.0278
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.2574
                       Mean reward: 8.93
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 1.0001
    Episode_Reward/rotating_object: 1.4189
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.25s
                      Time elapsed: 00:02:31
                               ETA: 00:53:13

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 44009 steps/s (collection: 2.123s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.3511
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.3762
                       Mean reward: 15.60
               Mean episode length: 243.07
    Episode_Reward/reaching_object: 1.0452
    Episode_Reward/rotating_object: 1.5631
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.23s
                      Time elapsed: 00:02:33
                               ETA: 00:53:11

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 43752 steps/s (collection: 2.136s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.2858
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 42.4118
                       Mean reward: 16.53
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.0371
    Episode_Reward/rotating_object: 2.1795
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.25s
                      Time elapsed: 00:02:36
                               ETA: 00:53:09

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 44003 steps/s (collection: 2.123s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.5623
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 42.4236
                       Mean reward: 9.85
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 1.0307
    Episode_Reward/rotating_object: 1.2296
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.23s
                      Time elapsed: 00:02:38
                               ETA: 00:53:07

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 43715 steps/s (collection: 2.137s, learning 0.112s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.5136
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 42.4501
                       Mean reward: 14.83
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.0429
    Episode_Reward/rotating_object: 1.6149
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.25s
                      Time elapsed: 00:02:40
                               ETA: 00:53:05

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 43346 steps/s (collection: 2.154s, learning 0.114s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.4323
               Mean surrogate loss: 0.0040
                 Mean entropy loss: 42.4631
                       Mean reward: 16.05
               Mean episode length: 244.67
    Episode_Reward/reaching_object: 1.0296
    Episode_Reward/rotating_object: 2.3865
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.27s
                      Time elapsed: 00:02:42
                               ETA: 00:53:04

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 43604 steps/s (collection: 2.143s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.4268
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 42.4728
                       Mean reward: 13.13
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 1.0392
    Episode_Reward/rotating_object: 2.0155
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.25s
                      Time elapsed: 00:02:45
                               ETA: 00:53:02

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 43297 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.2253
               Mean surrogate loss: 0.0044
                 Mean entropy loss: 42.4881
                       Mean reward: 10.46
               Mean episode length: 244.69
    Episode_Reward/reaching_object: 1.0217
    Episode_Reward/rotating_object: 1.6919
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.27s
                      Time elapsed: 00:02:47
                               ETA: 00:53:00

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 44126 steps/s (collection: 2.116s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.9136
               Mean surrogate loss: 0.0047
                 Mean entropy loss: 42.4977
                       Mean reward: 12.09
               Mean episode length: 246.41
    Episode_Reward/reaching_object: 1.0119
    Episode_Reward/rotating_object: 2.4516
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.23s
                      Time elapsed: 00:02:49
                               ETA: 00:52:58

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 44212 steps/s (collection: 2.112s, learning 0.112s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.5339
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 42.5090
                       Mean reward: 11.63
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.9990
    Episode_Reward/rotating_object: 1.5706
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.22s
                      Time elapsed: 00:02:51
                               ETA: 00:52:56

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 45182 steps/s (collection: 2.061s, learning 0.114s)
             Mean action noise std: 1.25
          Mean value_function loss: 2.8188
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 42.5598
                       Mean reward: 17.82
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 2.0237
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.18s
                      Time elapsed: 00:02:53
                               ETA: 00:52:53

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 44195 steps/s (collection: 2.107s, learning 0.117s)
             Mean action noise std: 1.25
          Mean value_function loss: 3.2699
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.6215
                       Mean reward: 18.60
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 1.0244
    Episode_Reward/rotating_object: 2.0366
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.22s
                      Time elapsed: 00:02:56
                               ETA: 00:52:50

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 43557 steps/s (collection: 2.138s, learning 0.119s)
             Mean action noise std: 1.25
          Mean value_function loss: 2.9548
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 42.6885
                       Mean reward: 23.57
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.0160
    Episode_Reward/rotating_object: 2.2409
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.26s
                      Time elapsed: 00:02:58
                               ETA: 00:52:48

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 43952 steps/s (collection: 2.117s, learning 0.119s)
             Mean action noise std: 1.25
          Mean value_function loss: 2.4998
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.7238
                       Mean reward: 21.60
               Mean episode length: 246.27
    Episode_Reward/reaching_object: 1.0006
    Episode_Reward/rotating_object: 2.2831
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.24s
                      Time elapsed: 00:03:00
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 41345 steps/s (collection: 2.252s, learning 0.125s)
             Mean action noise std: 1.26
          Mean value_function loss: 2.6423
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.7824
                       Mean reward: 12.37
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.0189
    Episode_Reward/rotating_object: 2.1651
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.38s
                      Time elapsed: 00:03:03
                               ETA: 00:52:47

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 41545 steps/s (collection: 2.242s, learning 0.124s)
             Mean action noise std: 1.26
          Mean value_function loss: 2.6948
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.8231
                       Mean reward: 12.22
               Mean episode length: 249.76
    Episode_Reward/reaching_object: 1.0136
    Episode_Reward/rotating_object: 2.2878
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.37s
                      Time elapsed: 00:03:05
                               ETA: 00:52:47

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 42138 steps/s (collection: 2.211s, learning 0.122s)
             Mean action noise std: 1.26
          Mean value_function loss: 3.0637
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.8981
                       Mean reward: 14.61
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.9974
    Episode_Reward/rotating_object: 1.9972
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.33s
                      Time elapsed: 00:03:07
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 41574 steps/s (collection: 2.243s, learning 0.121s)
             Mean action noise std: 1.27
          Mean value_function loss: 3.1133
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.0158
                       Mean reward: 21.38
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 1.0257
    Episode_Reward/rotating_object: 2.2353
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.36s
                      Time elapsed: 00:03:10
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 42148 steps/s (collection: 2.213s, learning 0.119s)
             Mean action noise std: 1.27
          Mean value_function loss: 3.1402
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.0706
                       Mean reward: 17.57
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.0311
    Episode_Reward/rotating_object: 2.1419
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.33s
                      Time elapsed: 00:03:12
                               ETA: 00:52:45

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 41741 steps/s (collection: 2.229s, learning 0.126s)
             Mean action noise std: 1.28
          Mean value_function loss: 3.0042
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.1615
                       Mean reward: 18.32
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 0.9925
    Episode_Reward/rotating_object: 2.5997
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.36s
                      Time elapsed: 00:03:14
                               ETA: 00:52:45

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 40883 steps/s (collection: 2.279s, learning 0.126s)
             Mean action noise std: 1.28
          Mean value_function loss: 3.8302
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.2489
                       Mean reward: 16.70
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.9932
    Episode_Reward/rotating_object: 1.9431
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.40s
                      Time elapsed: 00:03:17
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 41047 steps/s (collection: 2.269s, learning 0.126s)
             Mean action noise std: 1.28
          Mean value_function loss: 3.6924
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.3313
                       Mean reward: 22.68
               Mean episode length: 240.76
    Episode_Reward/reaching_object: 0.9670
    Episode_Reward/rotating_object: 2.1745
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.39s
                      Time elapsed: 00:03:19
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 41030 steps/s (collection: 2.280s, learning 0.116s)
             Mean action noise std: 1.29
          Mean value_function loss: 4.7390
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.4131
                       Mean reward: 14.99
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 0.9684
    Episode_Reward/rotating_object: 2.0427
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.40s
                      Time elapsed: 00:03:21
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 44240 steps/s (collection: 2.110s, learning 0.112s)
             Mean action noise std: 1.29
          Mean value_function loss: 4.9443
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.5185
                       Mean reward: 24.55
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.9694
    Episode_Reward/rotating_object: 2.6194
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.22s
                      Time elapsed: 00:03:24
                               ETA: 00:52:43

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 43490 steps/s (collection: 2.142s, learning 0.118s)
             Mean action noise std: 1.30
          Mean value_function loss: 5.4801
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.6000
                       Mean reward: 15.43
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.0007
    Episode_Reward/rotating_object: 2.3076
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.26s
                      Time elapsed: 00:03:26
                               ETA: 00:52:41

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 44232 steps/s (collection: 2.112s, learning 0.111s)
             Mean action noise std: 1.30
          Mean value_function loss: 4.9063
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.6782
                       Mean reward: 19.41
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.9906
    Episode_Reward/rotating_object: 3.2226
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.22s
                      Time elapsed: 00:03:28
                               ETA: 00:52:39

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 43355 steps/s (collection: 2.156s, learning 0.111s)
             Mean action noise std: 1.30
          Mean value_function loss: 4.2675
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.7462
                       Mean reward: 20.49
               Mean episode length: 244.76
    Episode_Reward/reaching_object: 1.0158
    Episode_Reward/rotating_object: 3.2579
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.27s
                      Time elapsed: 00:03:30
                               ETA: 00:52:37

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 43155 steps/s (collection: 2.158s, learning 0.120s)
             Mean action noise std: 1.31
          Mean value_function loss: 4.0433
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 43.8276
                       Mean reward: 15.80
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 1.0342
    Episode_Reward/rotating_object: 2.8409
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.28s
                      Time elapsed: 00:03:33
                               ETA: 00:52:35

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 41813 steps/s (collection: 2.223s, learning 0.128s)
             Mean action noise std: 1.31
          Mean value_function loss: 4.1633
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.8880
                       Mean reward: 11.58
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 0.9887
    Episode_Reward/rotating_object: 2.5227
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.35s
                      Time elapsed: 00:03:35
                               ETA: 00:52:34

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 41777 steps/s (collection: 2.220s, learning 0.133s)
             Mean action noise std: 1.31
          Mean value_function loss: 5.3946
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.9453
                       Mean reward: 22.10
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 0.9874
    Episode_Reward/rotating_object: 3.1256
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.35s
                      Time elapsed: 00:03:37
                               ETA: 00:52:34

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 42121 steps/s (collection: 2.196s, learning 0.137s)
             Mean action noise std: 1.32
          Mean value_function loss: 4.7472
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.0166
                       Mean reward: 16.58
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 1.0005
    Episode_Reward/rotating_object: 2.7864
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.33s
                      Time elapsed: 00:03:40
                               ETA: 00:52:33

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 42185 steps/s (collection: 2.210s, learning 0.120s)
             Mean action noise std: 1.32
          Mean value_function loss: 4.6497
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.1149
                       Mean reward: 17.99
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 0.9839
    Episode_Reward/rotating_object: 3.4050
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.33s
                      Time elapsed: 00:03:42
                               ETA: 00:52:32

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 42298 steps/s (collection: 2.203s, learning 0.121s)
             Mean action noise std: 1.33
          Mean value_function loss: 4.9067
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.2410
                       Mean reward: 14.43
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.9904
    Episode_Reward/rotating_object: 3.1784
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.32s
                      Time elapsed: 00:03:44
                               ETA: 00:52:30

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 42202 steps/s (collection: 2.208s, learning 0.121s)
             Mean action noise std: 1.33
          Mean value_function loss: 4.3790
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.3351
                       Mean reward: 19.28
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 1.0095
    Episode_Reward/rotating_object: 2.8634
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.33s
                      Time elapsed: 00:03:47
                               ETA: 00:52:29

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 42560 steps/s (collection: 2.188s, learning 0.122s)
             Mean action noise std: 1.34
          Mean value_function loss: 5.1807
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.4313
                       Mean reward: 16.65
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.0114
    Episode_Reward/rotating_object: 3.0117
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.31s
                      Time elapsed: 00:03:49
                               ETA: 00:52:28

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 41645 steps/s (collection: 2.239s, learning 0.121s)
             Mean action noise std: 1.34
          Mean value_function loss: 7.9432
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.5095
                       Mean reward: 24.62
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 0.9771
    Episode_Reward/rotating_object: 2.6699
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.36s
                      Time elapsed: 00:03:51
                               ETA: 00:52:27

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 41762 steps/s (collection: 2.234s, learning 0.120s)
             Mean action noise std: 1.35
          Mean value_function loss: 6.4999
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.5624
                       Mean reward: 16.50
               Mean episode length: 242.48
    Episode_Reward/reaching_object: 0.9856
    Episode_Reward/rotating_object: 2.9377
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.35s
                      Time elapsed: 00:03:54
                               ETA: 00:52:26

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 41960 steps/s (collection: 2.221s, learning 0.122s)
             Mean action noise std: 1.35
          Mean value_function loss: 7.7777
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.6364
                       Mean reward: 22.25
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 0.9724
    Episode_Reward/rotating_object: 3.1686
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.34s
                      Time elapsed: 00:03:56
                               ETA: 00:52:25

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 42382 steps/s (collection: 2.200s, learning 0.119s)
             Mean action noise std: 1.35
          Mean value_function loss: 7.6769
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.7221
                       Mean reward: 18.50
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 0.9724
    Episode_Reward/rotating_object: 3.4956
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.32s
                      Time elapsed: 00:03:58
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 42753 steps/s (collection: 2.181s, learning 0.119s)
             Mean action noise std: 1.36
          Mean value_function loss: 7.2678
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.7514
                       Mean reward: 16.78
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.9488
    Episode_Reward/rotating_object: 2.9098
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.30s
                      Time elapsed: 00:04:01
                               ETA: 00:52:22

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 42693 steps/s (collection: 2.179s, learning 0.123s)
             Mean action noise std: 1.36
          Mean value_function loss: 8.1147
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.8166
                       Mean reward: 25.99
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 0.9610
    Episode_Reward/rotating_object: 3.3233
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.30s
                      Time elapsed: 00:04:03
                               ETA: 00:52:21

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 41168 steps/s (collection: 2.262s, learning 0.126s)
             Mean action noise std: 1.36
          Mean value_function loss: 8.3994
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.8780
                       Mean reward: 24.03
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 0.9639
    Episode_Reward/rotating_object: 3.5558
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.39s
                      Time elapsed: 00:04:05
                               ETA: 00:52:20

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 41245 steps/s (collection: 2.258s, learning 0.125s)
             Mean action noise std: 1.37
          Mean value_function loss: 9.0271
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.9345
                       Mean reward: 23.56
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 0.9421
    Episode_Reward/rotating_object: 4.6789
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.38s
                      Time elapsed: 00:04:08
                               ETA: 00:52:19

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 40881 steps/s (collection: 2.279s, learning 0.125s)
             Mean action noise std: 1.37
          Mean value_function loss: 9.1635
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 45.0369
                       Mean reward: 24.04
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 0.9364
    Episode_Reward/rotating_object: 3.3099
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.40s
                      Time elapsed: 00:04:10
                               ETA: 00:52:19

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 44268 steps/s (collection: 2.109s, learning 0.111s)
             Mean action noise std: 1.38
          Mean value_function loss: 9.9700
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 45.1421
                       Mean reward: 20.39
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 0.9329
    Episode_Reward/rotating_object: 3.3362
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.22s
                      Time elapsed: 00:04:12
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 43965 steps/s (collection: 2.125s, learning 0.111s)
             Mean action noise std: 1.38
          Mean value_function loss: 10.9197
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.2195
                       Mean reward: 19.45
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 0.9211
    Episode_Reward/rotating_object: 2.8681
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.24s
                      Time elapsed: 00:04:15
                               ETA: 00:52:14

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 43889 steps/s (collection: 2.128s, learning 0.112s)
             Mean action noise std: 1.39
          Mean value_function loss: 10.3864
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 45.3066
                       Mean reward: 25.47
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 0.9257
    Episode_Reward/rotating_object: 4.5578
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.24s
                      Time elapsed: 00:04:17
                               ETA: 00:52:11

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 42543 steps/s (collection: 2.190s, learning 0.121s)
             Mean action noise std: 1.39
          Mean value_function loss: 9.0210
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.3733
                       Mean reward: 17.89
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 0.9231
    Episode_Reward/rotating_object: 3.3030
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.31s
                      Time elapsed: 00:04:19
                               ETA: 00:52:10

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 41782 steps/s (collection: 2.231s, learning 0.122s)
             Mean action noise std: 1.39
          Mean value_function loss: 10.5514
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 45.4636
                       Mean reward: 32.59
               Mean episode length: 230.54
    Episode_Reward/reaching_object: 0.9090
    Episode_Reward/rotating_object: 5.2057
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.35s
                      Time elapsed: 00:04:22
                               ETA: 00:52:08

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 42252 steps/s (collection: 2.203s, learning 0.123s)
             Mean action noise std: 1.40
          Mean value_function loss: 10.4300
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.5297
                       Mean reward: 28.04
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 0.9069
    Episode_Reward/rotating_object: 4.3716
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.33s
                      Time elapsed: 00:04:24
                               ETA: 00:52:07

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 41897 steps/s (collection: 2.218s, learning 0.129s)
             Mean action noise std: 1.40
          Mean value_function loss: 11.3287
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 45.5919
                       Mean reward: 14.75
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 0.8895
    Episode_Reward/rotating_object: 3.7310
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.35s
                      Time elapsed: 00:04:26
                               ETA: 00:52:06

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 42400 steps/s (collection: 2.196s, learning 0.123s)
             Mean action noise std: 1.41
          Mean value_function loss: 11.9553
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.6759
                       Mean reward: 16.85
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 0.9083
    Episode_Reward/rotating_object: 3.5554
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.32s
                      Time elapsed: 00:04:29
                               ETA: 00:52:04

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 42076 steps/s (collection: 2.214s, learning 0.122s)
             Mean action noise std: 1.41
          Mean value_function loss: 11.3292
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 45.7509
                       Mean reward: 23.84
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 0.9147
    Episode_Reward/rotating_object: 3.4883
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.34s
                      Time elapsed: 00:04:31
                               ETA: 00:52:03

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 42068 steps/s (collection: 2.215s, learning 0.122s)
             Mean action noise std: 1.41
          Mean value_function loss: 12.9892
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.8298
                       Mean reward: 24.04
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 0.9150
    Episode_Reward/rotating_object: 4.0260
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.34s
                      Time elapsed: 00:04:33
                               ETA: 00:52:01

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 41713 steps/s (collection: 2.239s, learning 0.117s)
             Mean action noise std: 1.42
          Mean value_function loss: 12.5640
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 45.9116
                       Mean reward: 30.94
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 0.9440
    Episode_Reward/rotating_object: 4.3072
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.36s
                      Time elapsed: 00:04:36
                               ETA: 00:52:00

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 42700 steps/s (collection: 2.176s, learning 0.126s)
             Mean action noise std: 1.42
          Mean value_function loss: 12.6764
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.9892
                       Mean reward: 33.69
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.9163
    Episode_Reward/rotating_object: 5.5954
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.30s
                      Time elapsed: 00:04:38
                               ETA: 00:51:58

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 42606 steps/s (collection: 2.182s, learning 0.126s)
             Mean action noise std: 1.42
          Mean value_function loss: 12.4565
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.0400
                       Mean reward: 26.81
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 0.9175
    Episode_Reward/rotating_object: 4.1130
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.31s
                      Time elapsed: 00:04:40
                               ETA: 00:51:57

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 42516 steps/s (collection: 2.176s, learning 0.136s)
             Mean action noise std: 1.43
          Mean value_function loss: 12.1760
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.0810
                       Mean reward: 32.35
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 0.9123
    Episode_Reward/rotating_object: 4.8872
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.31s
                      Time elapsed: 00:04:43
                               ETA: 00:51:55

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 42365 steps/s (collection: 2.191s, learning 0.129s)
             Mean action noise std: 1.43
          Mean value_function loss: 14.1313
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.1313
                       Mean reward: 35.52
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 0.9288
    Episode_Reward/rotating_object: 5.9852
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.32s
                      Time elapsed: 00:04:45
                               ETA: 00:51:53

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 42650 steps/s (collection: 2.185s, learning 0.120s)
             Mean action noise std: 1.43
          Mean value_function loss: 12.0866
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.1980
                       Mean reward: 34.07
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 0.8970
    Episode_Reward/rotating_object: 4.3377
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.30s
                      Time elapsed: 00:04:47
                               ETA: 00:51:51

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 42608 steps/s (collection: 2.181s, learning 0.126s)
             Mean action noise std: 1.43
          Mean value_function loss: 13.4882
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.2195
                       Mean reward: 31.62
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 0.9175
    Episode_Reward/rotating_object: 5.0151
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.31s
                      Time elapsed: 00:04:49
                               ETA: 00:51:50

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 43142 steps/s (collection: 2.159s, learning 0.119s)
             Mean action noise std: 1.44
          Mean value_function loss: 12.3219
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.2699
                       Mean reward: 25.84
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 0.8745
    Episode_Reward/rotating_object: 4.3037
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.28s
                      Time elapsed: 00:04:52
                               ETA: 00:51:47

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 42334 steps/s (collection: 2.195s, learning 0.127s)
             Mean action noise std: 1.44
          Mean value_function loss: 11.2483
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.3153
                       Mean reward: 28.10
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 0.8814
    Episode_Reward/rotating_object: 4.6790
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.32s
                      Time elapsed: 00:04:54
                               ETA: 00:51:46

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 40697 steps/s (collection: 2.289s, learning 0.126s)
             Mean action noise std: 1.45
          Mean value_function loss: 12.3413
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.4080
                       Mean reward: 31.33
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 0.8656
    Episode_Reward/rotating_object: 5.0339
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.42s
                      Time elapsed: 00:04:56
                               ETA: 00:51:45

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 42454 steps/s (collection: 2.196s, learning 0.119s)
             Mean action noise std: 1.45
          Mean value_function loss: 12.0241
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.4939
                       Mean reward: 28.94
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 0.8595
    Episode_Reward/rotating_object: 4.5713
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.32s
                      Time elapsed: 00:04:59
                               ETA: 00:51:43

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 42602 steps/s (collection: 2.181s, learning 0.126s)
             Mean action noise std: 1.46
          Mean value_function loss: 13.7016
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.5860
                       Mean reward: 28.35
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 0.8784
    Episode_Reward/rotating_object: 4.8239
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.31s
                      Time elapsed: 00:05:01
                               ETA: 00:51:41

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 41465 steps/s (collection: 2.245s, learning 0.126s)
             Mean action noise std: 1.46
          Mean value_function loss: 13.6105
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.6533
                       Mean reward: 32.86
               Mean episode length: 238.06
    Episode_Reward/reaching_object: 0.8870
    Episode_Reward/rotating_object: 5.5037
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.37s
                      Time elapsed: 00:05:03
                               ETA: 00:51:40

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 40709 steps/s (collection: 2.287s, learning 0.128s)
             Mean action noise std: 1.47
          Mean value_function loss: 14.0834
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 46.7466
                       Mean reward: 27.63
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 0.8762
    Episode_Reward/rotating_object: 4.5538
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.41s
                      Time elapsed: 00:05:06
                               ETA: 00:51:39

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 43499 steps/s (collection: 2.137s, learning 0.123s)
             Mean action noise std: 1.47
          Mean value_function loss: 13.8399
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.8361
                       Mean reward: 22.82
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 0.8810
    Episode_Reward/rotating_object: 5.1948
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.26s
                      Time elapsed: 00:05:08
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 41451 steps/s (collection: 2.236s, learning 0.136s)
             Mean action noise std: 1.47
          Mean value_function loss: 12.9626
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.9060
                       Mean reward: 30.50
               Mean episode length: 235.74
    Episode_Reward/reaching_object: 0.9162
    Episode_Reward/rotating_object: 5.2871
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.37s
                      Time elapsed: 00:05:10
                               ETA: 00:51:36

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 42291 steps/s (collection: 2.202s, learning 0.122s)
             Mean action noise std: 1.48
          Mean value_function loss: 13.4694
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.9791
                       Mean reward: 27.36
               Mean episode length: 237.80
    Episode_Reward/reaching_object: 0.8959
    Episode_Reward/rotating_object: 4.7758
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.32s
                      Time elapsed: 00:05:13
                               ETA: 00:51:34

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 43138 steps/s (collection: 2.157s, learning 0.121s)
             Mean action noise std: 1.48
          Mean value_function loss: 13.0134
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.0481
                       Mean reward: 25.41
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 0.9133
    Episode_Reward/rotating_object: 4.7600
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.28s
                      Time elapsed: 00:05:15
                               ETA: 00:51:32

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 43374 steps/s (collection: 2.147s, learning 0.119s)
             Mean action noise std: 1.49
          Mean value_function loss: 12.7238
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 47.1219
                       Mean reward: 39.28
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 0.9194
    Episode_Reward/rotating_object: 5.7275
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.27s
                      Time elapsed: 00:05:17
                               ETA: 00:51:30

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 43204 steps/s (collection: 2.157s, learning 0.119s)
             Mean action noise std: 1.49
          Mean value_function loss: 12.8582
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 47.1922
                       Mean reward: 42.50
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 0.8955
    Episode_Reward/rotating_object: 5.3407
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.28s
                      Time elapsed: 00:05:20
                               ETA: 00:51:27

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 43141 steps/s (collection: 2.157s, learning 0.122s)
             Mean action noise std: 1.49
          Mean value_function loss: 14.0814
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 47.2625
                       Mean reward: 43.64
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.8967
    Episode_Reward/rotating_object: 6.2568
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.28s
                      Time elapsed: 00:05:22
                               ETA: 00:51:25

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 43066 steps/s (collection: 2.162s, learning 0.121s)
             Mean action noise std: 1.50
          Mean value_function loss: 12.4677
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 47.3203
                       Mean reward: 33.58
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.8885
    Episode_Reward/rotating_object: 6.4202
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.28s
                      Time elapsed: 00:05:24
                               ETA: 00:51:23

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 43194 steps/s (collection: 2.154s, learning 0.121s)
             Mean action noise std: 1.50
          Mean value_function loss: 13.6094
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 47.3846
                       Mean reward: 39.19
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 0.8892
    Episode_Reward/rotating_object: 6.4225
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.28s
                      Time elapsed: 00:05:26
                               ETA: 00:51:21

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 43310 steps/s (collection: 2.142s, learning 0.128s)
             Mean action noise std: 1.50
          Mean value_function loss: 15.6763
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 47.4422
                       Mean reward: 32.48
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.8735
    Episode_Reward/rotating_object: 5.0560
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.27s
                      Time elapsed: 00:05:29
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 42528 steps/s (collection: 2.174s, learning 0.138s)
             Mean action noise std: 1.51
          Mean value_function loss: 14.5532
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 47.5022
                       Mean reward: 33.49
               Mean episode length: 233.26
    Episode_Reward/reaching_object: 0.8678
    Episode_Reward/rotating_object: 7.1440
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.31s
                      Time elapsed: 00:05:31
                               ETA: 00:51:17

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 41658 steps/s (collection: 2.227s, learning 0.132s)
             Mean action noise std: 1.51
          Mean value_function loss: 14.9575
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.5494
                       Mean reward: 41.50
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 0.9080
    Episode_Reward/rotating_object: 5.4796
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.36s
                      Time elapsed: 00:05:33
                               ETA: 00:51:15

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 42571 steps/s (collection: 2.189s, learning 0.120s)
             Mean action noise std: 1.52
          Mean value_function loss: 17.1183
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.6165
                       Mean reward: 34.39
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 0.8809
    Episode_Reward/rotating_object: 6.1805
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.31s
                      Time elapsed: 00:05:36
                               ETA: 00:51:13

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 41870 steps/s (collection: 2.214s, learning 0.134s)
             Mean action noise std: 1.52
          Mean value_function loss: 17.8899
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.6858
                       Mean reward: 35.92
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 0.8976
    Episode_Reward/rotating_object: 6.9971
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.35s
                      Time elapsed: 00:05:38
                               ETA: 00:51:12

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 42791 steps/s (collection: 2.171s, learning 0.126s)
             Mean action noise std: 1.52
          Mean value_function loss: 17.8031
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.7435
                       Mean reward: 36.06
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.9272
    Episode_Reward/rotating_object: 6.1535
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.30s
                      Time elapsed: 00:05:40
                               ETA: 00:51:10

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 41979 steps/s (collection: 2.216s, learning 0.126s)
             Mean action noise std: 1.53
          Mean value_function loss: 15.9913
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 47.8082
                       Mean reward: 54.75
               Mean episode length: 243.19
    Episode_Reward/reaching_object: 0.9178
    Episode_Reward/rotating_object: 7.6974
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.34s
                      Time elapsed: 00:05:43
                               ETA: 00:51:08

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 42002 steps/s (collection: 2.214s, learning 0.126s)
             Mean action noise std: 1.53
          Mean value_function loss: 16.1602
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.8952
                       Mean reward: 41.15
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 0.9130
    Episode_Reward/rotating_object: 6.9744
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.34s
                      Time elapsed: 00:05:45
                               ETA: 00:51:06

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 41666 steps/s (collection: 2.234s, learning 0.125s)
             Mean action noise std: 1.54
          Mean value_function loss: 16.5508
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.9733
                       Mean reward: 41.41
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 0.8783
    Episode_Reward/rotating_object: 7.4165
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.36s
                      Time elapsed: 00:05:47
                               ETA: 00:51:05

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 42383 steps/s (collection: 2.194s, learning 0.126s)
             Mean action noise std: 1.54
          Mean value_function loss: 19.8746
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 48.0198
                       Mean reward: 50.63
               Mean episode length: 240.76
    Episode_Reward/reaching_object: 0.9058
    Episode_Reward/rotating_object: 6.5080
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.32s
                      Time elapsed: 00:05:50
                               ETA: 00:51:03

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 41528 steps/s (collection: 2.239s, learning 0.128s)
             Mean action noise std: 1.54
          Mean value_function loss: 17.4335
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.0597
                       Mean reward: 42.19
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 0.9252
    Episode_Reward/rotating_object: 8.6629
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.37s
                      Time elapsed: 00:05:52
                               ETA: 00:51:01

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 42504 steps/s (collection: 2.194s, learning 0.119s)
             Mean action noise std: 1.54
          Mean value_function loss: 20.0418
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 48.0997
                       Mean reward: 30.19
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 0.9000
    Episode_Reward/rotating_object: 7.0312
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.31s
                      Time elapsed: 00:05:54
                               ETA: 00:50:59

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 42868 steps/s (collection: 2.169s, learning 0.125s)
             Mean action noise std: 1.55
          Mean value_function loss: 20.2212
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 48.1589
                       Mean reward: 46.63
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 0.8963
    Episode_Reward/rotating_object: 7.8200
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.29s
                      Time elapsed: 00:05:57
                               ETA: 00:50:57

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 42191 steps/s (collection: 2.205s, learning 0.124s)
             Mean action noise std: 1.55
          Mean value_function loss: 19.8436
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 48.2099
                       Mean reward: 42.17
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 0.9058
    Episode_Reward/rotating_object: 8.6309
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.33s
                      Time elapsed: 00:05:59
                               ETA: 00:50:56

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 42370 steps/s (collection: 2.195s, learning 0.125s)
             Mean action noise std: 1.55
          Mean value_function loss: 17.7196
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.2386
                       Mean reward: 53.85
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 0.8907
    Episode_Reward/rotating_object: 7.8544
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.32s
                      Time elapsed: 00:06:01
                               ETA: 00:50:54

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 42670 steps/s (collection: 2.180s, learning 0.124s)
             Mean action noise std: 1.56
          Mean value_function loss: 17.4009
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.3049
                       Mean reward: 39.41
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 0.9107
    Episode_Reward/rotating_object: 7.9946
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.30s
                      Time elapsed: 00:06:04
                               ETA: 00:50:52

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 42861 steps/s (collection: 2.172s, learning 0.122s)
             Mean action noise std: 1.56
          Mean value_function loss: 19.9272
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 48.3492
                       Mean reward: 41.27
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 0.8896
    Episode_Reward/rotating_object: 7.9278
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.29s
                      Time elapsed: 00:06:06
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 42233 steps/s (collection: 2.204s, learning 0.123s)
             Mean action noise std: 1.56
          Mean value_function loss: 21.3686
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.3812
                       Mean reward: 40.50
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 0.9026
    Episode_Reward/rotating_object: 7.4009
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.33s
                      Time elapsed: 00:06:08
                               ETA: 00:50:48

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 42877 steps/s (collection: 2.170s, learning 0.122s)
             Mean action noise std: 1.56
          Mean value_function loss: 20.4832
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.4267
                       Mean reward: 42.36
               Mean episode length: 229.50
    Episode_Reward/reaching_object: 0.9155
    Episode_Reward/rotating_object: 8.6663
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.29s
                      Time elapsed: 00:06:11
                               ETA: 00:50:45

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 42891 steps/s (collection: 2.172s, learning 0.120s)
             Mean action noise std: 1.57
          Mean value_function loss: 21.5942
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 48.4789
                       Mean reward: 55.40
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 0.9053
    Episode_Reward/rotating_object: 9.9673
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.29s
                      Time elapsed: 00:06:13
                               ETA: 00:50:43

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 42964 steps/s (collection: 2.169s, learning 0.119s)
             Mean action noise std: 1.57
          Mean value_function loss: 22.8260
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.5358
                       Mean reward: 53.89
               Mean episode length: 231.94
    Episode_Reward/reaching_object: 0.9327
    Episode_Reward/rotating_object: 11.3587
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.29s
                      Time elapsed: 00:06:15
                               ETA: 00:50:41

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 43073 steps/s (collection: 2.160s, learning 0.122s)
             Mean action noise std: 1.57
          Mean value_function loss: 22.4072
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.5714
                       Mean reward: 53.62
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 0.9171
    Episode_Reward/rotating_object: 10.5022
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.28s
                      Time elapsed: 00:06:17
                               ETA: 00:50:39

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 41863 steps/s (collection: 2.230s, learning 0.119s)
             Mean action noise std: 1.57
          Mean value_function loss: 23.8172
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 48.6165
                       Mean reward: 52.40
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 0.8795
    Episode_Reward/rotating_object: 9.0514
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.35s
                      Time elapsed: 00:06:20
                               ETA: 00:50:37

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 42553 steps/s (collection: 2.190s, learning 0.120s)
             Mean action noise std: 1.58
          Mean value_function loss: 22.4749
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 48.6520
                       Mean reward: 50.35
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 0.8955
    Episode_Reward/rotating_object: 9.5096
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.31s
                      Time elapsed: 00:06:22
                               ETA: 00:50:35

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 42433 steps/s (collection: 2.194s, learning 0.123s)
             Mean action noise std: 1.58
          Mean value_function loss: 25.8288
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 48.7110
                       Mean reward: 48.07
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 0.8866
    Episode_Reward/rotating_object: 8.7356
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.32s
                      Time elapsed: 00:06:24
                               ETA: 00:50:33

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 42017 steps/s (collection: 2.219s, learning 0.120s)
             Mean action noise std: 1.58
          Mean value_function loss: 24.6666
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 48.7755
                       Mean reward: 62.96
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 0.9168
    Episode_Reward/rotating_object: 9.6948
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.34s
                      Time elapsed: 00:06:27
                               ETA: 00:50:31

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 41108 steps/s (collection: 2.265s, learning 0.126s)
             Mean action noise std: 1.59
          Mean value_function loss: 26.0747
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.8174
                       Mean reward: 42.24
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 0.8815
    Episode_Reward/rotating_object: 9.2956
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.39s
                      Time elapsed: 00:06:29
                               ETA: 00:50:30

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 42110 steps/s (collection: 2.209s, learning 0.126s)
             Mean action noise std: 1.59
          Mean value_function loss: 22.3420
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 48.8625
                       Mean reward: 48.29
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 0.9026
    Episode_Reward/rotating_object: 9.4205
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.33s
                      Time elapsed: 00:06:31
                               ETA: 00:50:28

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 41875 steps/s (collection: 2.220s, learning 0.127s)
             Mean action noise std: 1.59
          Mean value_function loss: 19.7838
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.9278
                       Mean reward: 52.83
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 0.8963
    Episode_Reward/rotating_object: 10.4192
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.35s
                      Time elapsed: 00:06:34
                               ETA: 00:50:26

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 42124 steps/s (collection: 2.208s, learning 0.126s)
             Mean action noise std: 1.60
          Mean value_function loss: 19.6643
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.9709
                       Mean reward: 50.20
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 0.9049
    Episode_Reward/rotating_object: 8.9478
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.33s
                      Time elapsed: 00:06:36
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 42190 steps/s (collection: 2.204s, learning 0.126s)
             Mean action noise std: 1.60
          Mean value_function loss: 19.0694
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.0073
                       Mean reward: 61.52
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 0.9045
    Episode_Reward/rotating_object: 9.6043
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.33s
                      Time elapsed: 00:06:38
                               ETA: 00:50:23

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 41422 steps/s (collection: 2.249s, learning 0.124s)
             Mean action noise std: 1.60
          Mean value_function loss: 20.6701
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 49.0468
                       Mean reward: 44.41
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 0.8949
    Episode_Reward/rotating_object: 9.3947
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.37s
                      Time elapsed: 00:06:41
                               ETA: 00:50:21

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 44052 steps/s (collection: 2.117s, learning 0.115s)
             Mean action noise std: 1.60
          Mean value_function loss: 22.9143
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.0865
                       Mean reward: 69.88
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 0.9144
    Episode_Reward/rotating_object: 10.7844
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.23s
                      Time elapsed: 00:06:43
                               ETA: 00:50:18

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 43505 steps/s (collection: 2.140s, learning 0.120s)
             Mean action noise std: 1.61
          Mean value_function loss: 23.8565
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.1322
                       Mean reward: 38.43
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 0.8922
    Episode_Reward/rotating_object: 8.7057
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.26s
                      Time elapsed: 00:06:45
                               ETA: 00:50:16

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 43411 steps/s (collection: 2.143s, learning 0.122s)
             Mean action noise std: 1.61
          Mean value_function loss: 24.2358
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 49.1642
                       Mean reward: 57.56
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 0.9150
    Episode_Reward/rotating_object: 10.2099
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.26s
                      Time elapsed: 00:06:48
                               ETA: 00:50:14

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 43021 steps/s (collection: 2.161s, learning 0.124s)
             Mean action noise std: 1.61
          Mean value_function loss: 24.3794
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 49.1989
                       Mean reward: 62.57
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 0.8945
    Episode_Reward/rotating_object: 11.2220
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.28s
                      Time elapsed: 00:06:50
                               ETA: 00:50:11

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 43045 steps/s (collection: 2.166s, learning 0.118s)
             Mean action noise std: 1.61
          Mean value_function loss: 25.6385
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 49.2466
                       Mean reward: 57.92
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 0.8779
    Episode_Reward/rotating_object: 8.5347
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.28s
                      Time elapsed: 00:06:52
                               ETA: 00:50:09

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 42992 steps/s (collection: 2.163s, learning 0.124s)
             Mean action noise std: 1.62
          Mean value_function loss: 27.2300
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.2940
                       Mean reward: 54.97
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 0.9051
    Episode_Reward/rotating_object: 10.3988
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.29s
                      Time elapsed: 00:06:54
                               ETA: 00:50:07

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 43219 steps/s (collection: 2.160s, learning 0.114s)
             Mean action noise std: 1.62
          Mean value_function loss: 27.7441
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.3381
                       Mean reward: 48.34
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 0.8787
    Episode_Reward/rotating_object: 8.8967
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.27s
                      Time elapsed: 00:06:57
                               ETA: 00:50:05

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 44176 steps/s (collection: 2.111s, learning 0.114s)
             Mean action noise std: 1.62
          Mean value_function loss: 25.7363
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.3870
                       Mean reward: 60.29
               Mean episode length: 231.81
    Episode_Reward/reaching_object: 0.8504
    Episode_Reward/rotating_object: 9.9096
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.23s
                      Time elapsed: 00:06:59
                               ETA: 00:50:02

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 42439 steps/s (collection: 2.192s, learning 0.124s)
             Mean action noise std: 1.62
          Mean value_function loss: 28.7523
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.4177
                       Mean reward: 66.85
               Mean episode length: 235.49
    Episode_Reward/reaching_object: 0.8639
    Episode_Reward/rotating_object: 10.7519
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.32s
                      Time elapsed: 00:07:01
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 42379 steps/s (collection: 2.199s, learning 0.120s)
             Mean action noise std: 1.63
          Mean value_function loss: 25.5999
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.4402
                       Mean reward: 42.44
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 0.8596
    Episode_Reward/rotating_object: 10.6950
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.32s
                      Time elapsed: 00:07:04
                               ETA: 00:49:58

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 42514 steps/s (collection: 2.192s, learning 0.120s)
             Mean action noise std: 1.63
          Mean value_function loss: 25.0519
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 49.4787
                       Mean reward: 61.58
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 0.8816
    Episode_Reward/rotating_object: 11.3396
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.31s
                      Time elapsed: 00:07:06
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 42550 steps/s (collection: 2.188s, learning 0.122s)
             Mean action noise std: 1.63
          Mean value_function loss: 26.6854
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 49.5199
                       Mean reward: 55.94
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 0.8448
    Episode_Reward/rotating_object: 9.6748
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.31s
                      Time elapsed: 00:07:08
                               ETA: 00:49:54

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 42628 steps/s (collection: 2.190s, learning 0.116s)
             Mean action noise std: 1.63
          Mean value_function loss: 29.4667
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.5619
                       Mean reward: 43.60
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 0.8768
    Episode_Reward/rotating_object: 10.6593
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.31s
                      Time elapsed: 00:07:11
                               ETA: 00:49:52

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 42573 steps/s (collection: 2.184s, learning 0.125s)
             Mean action noise std: 1.64
          Mean value_function loss: 29.3891
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.6041
                       Mean reward: 63.73
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 0.8793
    Episode_Reward/rotating_object: 12.2934
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.31s
                      Time elapsed: 00:07:13
                               ETA: 00:49:50

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 42180 steps/s (collection: 2.198s, learning 0.133s)
             Mean action noise std: 1.64
          Mean value_function loss: 29.9883
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 49.6478
                       Mean reward: 74.60
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 0.8770
    Episode_Reward/rotating_object: 11.0316
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.33s
                      Time elapsed: 00:07:15
                               ETA: 00:49:48

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 41298 steps/s (collection: 2.254s, learning 0.126s)
             Mean action noise std: 1.64
          Mean value_function loss: 28.0974
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 49.6955
                       Mean reward: 50.45
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 0.8656
    Episode_Reward/rotating_object: 11.0485
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.38s
                      Time elapsed: 00:07:18
                               ETA: 00:49:46

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 41393 steps/s (collection: 2.249s, learning 0.126s)
             Mean action noise std: 1.65
          Mean value_function loss: 34.1505
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 49.7455
                       Mean reward: 41.33
               Mean episode length: 219.84
    Episode_Reward/reaching_object: 0.8275
    Episode_Reward/rotating_object: 10.3028
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.37s
                      Time elapsed: 00:07:20
                               ETA: 00:49:44

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 40881 steps/s (collection: 2.277s, learning 0.128s)
             Mean action noise std: 1.65
          Mean value_function loss: 31.8525
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 49.7984
                       Mean reward: 58.26
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 0.8646
    Episode_Reward/rotating_object: 11.2732
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.40s
                      Time elapsed: 00:07:22
                               ETA: 00:49:43

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 41180 steps/s (collection: 2.260s, learning 0.127s)
             Mean action noise std: 1.65
          Mean value_function loss: 31.3283
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.8434
                       Mean reward: 80.02
               Mean episode length: 225.99
    Episode_Reward/reaching_object: 0.8837
    Episode_Reward/rotating_object: 13.2323
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.39s
                      Time elapsed: 00:07:25
                               ETA: 00:49:41

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 40190 steps/s (collection: 2.319s, learning 0.127s)
             Mean action noise std: 1.65
          Mean value_function loss: 33.8782
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 49.8749
                       Mean reward: 75.89
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 0.8612
    Episode_Reward/rotating_object: 11.7543
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.45s
                      Time elapsed: 00:07:27
                               ETA: 00:49:40

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 40529 steps/s (collection: 2.296s, learning 0.129s)
             Mean action noise std: 1.66
          Mean value_function loss: 36.3940
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 49.9112
                       Mean reward: 56.77
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 0.8668
    Episode_Reward/rotating_object: 12.4011
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.43s
                      Time elapsed: 00:07:30
                               ETA: 00:49:39

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 43031 steps/s (collection: 2.165s, learning 0.119s)
             Mean action noise std: 1.66
          Mean value_function loss: 35.8394
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 49.9468
                       Mean reward: 69.79
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 0.8541
    Episode_Reward/rotating_object: 12.3036
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.28s
                      Time elapsed: 00:07:32
                               ETA: 00:49:37

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 42211 steps/s (collection: 2.206s, learning 0.123s)
             Mean action noise std: 1.66
          Mean value_function loss: 37.1625
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 49.9901
                       Mean reward: 66.50
               Mean episode length: 224.86
    Episode_Reward/reaching_object: 0.8621
    Episode_Reward/rotating_object: 12.0275
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.33s
                      Time elapsed: 00:07:34
                               ETA: 00:49:35

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 42184 steps/s (collection: 2.211s, learning 0.119s)
             Mean action noise std: 1.66
          Mean value_function loss: 36.8427
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.0338
                       Mean reward: 63.91
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 0.8292
    Episode_Reward/rotating_object: 11.2421
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.33s
                      Time elapsed: 00:07:37
                               ETA: 00:49:33

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 42405 steps/s (collection: 2.198s, learning 0.120s)
             Mean action noise std: 1.67
          Mean value_function loss: 36.3518
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 50.0810
                       Mean reward: 62.51
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 0.8375
    Episode_Reward/rotating_object: 10.4347
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.32s
                      Time elapsed: 00:07:39
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 42630 steps/s (collection: 2.185s, learning 0.121s)
             Mean action noise std: 1.67
          Mean value_function loss: 39.6782
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.1277
                       Mean reward: 66.28
               Mean episode length: 224.17
    Episode_Reward/reaching_object: 0.8682
    Episode_Reward/rotating_object: 13.8651
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.31s
                      Time elapsed: 00:07:41
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 42442 steps/s (collection: 2.193s, learning 0.124s)
             Mean action noise std: 1.67
          Mean value_function loss: 44.6069
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 50.1565
                       Mean reward: 67.12
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 0.8859
    Episode_Reward/rotating_object: 12.6535
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.32s
                      Time elapsed: 00:07:43
                               ETA: 00:49:26

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 42382 steps/s (collection: 2.199s, learning 0.120s)
             Mean action noise std: 1.67
          Mean value_function loss: 41.8246
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.1951
                       Mean reward: 55.99
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 0.8809
    Episode_Reward/rotating_object: 12.5249
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.32s
                      Time elapsed: 00:07:46
                               ETA: 00:49:24

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 41495 steps/s (collection: 2.247s, learning 0.122s)
             Mean action noise std: 1.68
          Mean value_function loss: 47.7712
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.2302
                       Mean reward: 69.73
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 0.8750
    Episode_Reward/rotating_object: 13.0978
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.37s
                      Time elapsed: 00:07:48
                               ETA: 00:49:22

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 41875 steps/s (collection: 2.229s, learning 0.119s)
             Mean action noise std: 1.68
          Mean value_function loss: 43.8450
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 50.2696
                       Mean reward: 55.08
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 0.8805
    Episode_Reward/rotating_object: 11.4099
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.35s
                      Time elapsed: 00:07:51
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 41534 steps/s (collection: 2.245s, learning 0.122s)
             Mean action noise std: 1.68
          Mean value_function loss: 41.5746
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 50.2993
                       Mean reward: 59.60
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 0.9043
    Episode_Reward/rotating_object: 12.4441
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.37s
                      Time elapsed: 00:07:53
                               ETA: 00:49:19

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 41504 steps/s (collection: 2.244s, learning 0.125s)
             Mean action noise std: 1.68
          Mean value_function loss: 50.3446
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 50.3322
                       Mean reward: 54.00
               Mean episode length: 220.34
    Episode_Reward/reaching_object: 0.8405
    Episode_Reward/rotating_object: 10.6238
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.37s
                      Time elapsed: 00:07:55
                               ETA: 00:49:17

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 41483 steps/s (collection: 2.250s, learning 0.120s)
             Mean action noise std: 1.69
          Mean value_function loss: 47.0972
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 50.3683
                       Mean reward: 74.01
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 0.8936
    Episode_Reward/rotating_object: 13.3330
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.37s
                      Time elapsed: 00:07:58
                               ETA: 00:49:15

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 41956 steps/s (collection: 2.221s, learning 0.122s)
             Mean action noise std: 1.69
          Mean value_function loss: 41.5035
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 50.4055
                       Mean reward: 56.02
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 0.8835
    Episode_Reward/rotating_object: 11.9615
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.34s
                      Time elapsed: 00:08:00
                               ETA: 00:49:13

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 41788 steps/s (collection: 2.231s, learning 0.121s)
             Mean action noise std: 1.69
          Mean value_function loss: 41.8528
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.4458
                       Mean reward: 68.08
               Mean episode length: 225.16
    Episode_Reward/reaching_object: 0.8976
    Episode_Reward/rotating_object: 13.4580
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.35s
                      Time elapsed: 00:08:02
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 42467 steps/s (collection: 2.202s, learning 0.112s)
             Mean action noise std: 1.69
          Mean value_function loss: 44.4202
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 50.4826
                       Mean reward: 72.65
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 0.9122
    Episode_Reward/rotating_object: 14.9788
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.31s
                      Time elapsed: 00:08:05
                               ETA: 00:49:09

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 43299 steps/s (collection: 2.159s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 43.9283
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.5198
                       Mean reward: 86.18
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 0.8925
    Episode_Reward/rotating_object: 13.9195
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.27s
                      Time elapsed: 00:08:07
                               ETA: 00:49:07

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 43359 steps/s (collection: 2.155s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 43.1878
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.5492
                       Mean reward: 76.26
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 0.9163
    Episode_Reward/rotating_object: 15.1187
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.27s
                      Time elapsed: 00:08:09
                               ETA: 00:49:04

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 43085 steps/s (collection: 2.157s, learning 0.124s)
             Mean action noise std: 1.70
          Mean value_function loss: 45.5546
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 50.5735
                       Mean reward: 73.16
               Mean episode length: 228.96
    Episode_Reward/reaching_object: 0.8848
    Episode_Reward/rotating_object: 13.0543
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.28s
                      Time elapsed: 00:08:11
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 43291 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 1.70
          Mean value_function loss: 42.3500
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.6063
                       Mean reward: 71.77
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 0.8704
    Episode_Reward/rotating_object: 12.1385
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.27s
                      Time elapsed: 00:08:14
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 43079 steps/s (collection: 2.170s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 44.6784
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 50.6490
                       Mean reward: 69.79
               Mean episode length: 215.75
    Episode_Reward/reaching_object: 0.8809
    Episode_Reward/rotating_object: 13.2874
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.28s
                      Time elapsed: 00:08:16
                               ETA: 00:48:57

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 41415 steps/s (collection: 2.244s, learning 0.130s)
             Mean action noise std: 1.71
          Mean value_function loss: 49.8492
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 50.6840
                       Mean reward: 88.23
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 0.8856
    Episode_Reward/rotating_object: 14.4710
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.37s
                      Time elapsed: 00:08:18
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 40873 steps/s (collection: 2.283s, learning 0.122s)
             Mean action noise std: 1.71
          Mean value_function loss: 47.3703
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 50.7223
                       Mean reward: 85.77
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 0.9130
    Episode_Reward/rotating_object: 15.1884
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.41s
                      Time elapsed: 00:08:21
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 41476 steps/s (collection: 2.250s, learning 0.120s)
             Mean action noise std: 1.71
          Mean value_function loss: 45.0837
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.7511
                       Mean reward: 88.89
               Mean episode length: 232.93
    Episode_Reward/reaching_object: 0.8795
    Episode_Reward/rotating_object: 14.7912
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.37s
                      Time elapsed: 00:08:23
                               ETA: 00:48:52

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 40932 steps/s (collection: 2.282s, learning 0.120s)
             Mean action noise std: 1.71
          Mean value_function loss: 43.0275
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.7707
                       Mean reward: 92.66
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 0.9100
    Episode_Reward/rotating_object: 15.9535
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.40s
                      Time elapsed: 00:08:26
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 41473 steps/s (collection: 2.252s, learning 0.119s)
             Mean action noise std: 1.71
          Mean value_function loss: 44.1148
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 50.8043
                       Mean reward: 97.30
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 0.9005
    Episode_Reward/rotating_object: 17.0020
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.37s
                      Time elapsed: 00:08:28
                               ETA: 00:48:49

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 41132 steps/s (collection: 2.266s, learning 0.124s)
             Mean action noise std: 1.72
          Mean value_function loss: 40.3517
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.8380
                       Mean reward: 73.68
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 0.8849
    Episode_Reward/rotating_object: 15.3345
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.39s
                      Time elapsed: 00:08:30
                               ETA: 00:48:47

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 41544 steps/s (collection: 2.246s, learning 0.120s)
             Mean action noise std: 1.72
          Mean value_function loss: 41.5964
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.8577
                       Mean reward: 95.56
               Mean episode length: 230.18
    Episode_Reward/reaching_object: 0.9092
    Episode_Reward/rotating_object: 17.5202
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.37s
                      Time elapsed: 00:08:33
                               ETA: 00:48:45

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 41179 steps/s (collection: 2.264s, learning 0.123s)
             Mean action noise std: 1.72
          Mean value_function loss: 42.7191
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.8948
                       Mean reward: 75.80
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 0.8967
    Episode_Reward/rotating_object: 16.5766
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.39s
                      Time elapsed: 00:08:35
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 41436 steps/s (collection: 2.252s, learning 0.120s)
             Mean action noise std: 1.72
          Mean value_function loss: 48.6629
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 50.9297
                       Mean reward: 61.58
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 0.8731
    Episode_Reward/rotating_object: 14.6506
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.37s
                      Time elapsed: 00:08:37
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 41234 steps/s (collection: 2.261s, learning 0.123s)
             Mean action noise std: 1.73
          Mean value_function loss: 46.1258
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 50.9576
                       Mean reward: 95.76
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 0.8629
    Episode_Reward/rotating_object: 14.5212
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.38s
                      Time elapsed: 00:08:40
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 41303 steps/s (collection: 2.261s, learning 0.119s)
             Mean action noise std: 1.73
          Mean value_function loss: 46.7176
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 50.9987
                       Mean reward: 82.90
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.8652
    Episode_Reward/rotating_object: 16.7352
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.38s
                      Time elapsed: 00:08:42
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 41425 steps/s (collection: 2.253s, learning 0.120s)
             Mean action noise std: 1.73
          Mean value_function loss: 55.0291
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 51.0349
                       Mean reward: 92.93
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 0.8675
    Episode_Reward/rotating_object: 20.0685
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.37s
                      Time elapsed: 00:08:45
                               ETA: 00:48:36

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 41227 steps/s (collection: 2.263s, learning 0.121s)
             Mean action noise std: 1.73
          Mean value_function loss: 47.8594
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 51.0580
                       Mean reward: 81.39
               Mean episode length: 227.69
    Episode_Reward/reaching_object: 0.8877
    Episode_Reward/rotating_object: 17.7574
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.38s
                      Time elapsed: 00:08:47
                               ETA: 00:48:34

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 40919 steps/s (collection: 2.282s, learning 0.120s)
             Mean action noise std: 1.73
          Mean value_function loss: 47.6020
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 51.0744
                       Mean reward: 107.15
               Mean episode length: 225.42
    Episode_Reward/reaching_object: 0.8684
    Episode_Reward/rotating_object: 17.6881
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.40s
                      Time elapsed: 00:08:49
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 41489 steps/s (collection: 2.251s, learning 0.118s)
             Mean action noise std: 1.73
          Mean value_function loss: 45.9226
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 51.0875
                       Mean reward: 83.91
               Mean episode length: 226.55
    Episode_Reward/reaching_object: 0.8518
    Episode_Reward/rotating_object: 16.9836
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.37s
                      Time elapsed: 00:08:52
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 40501 steps/s (collection: 2.303s, learning 0.124s)
             Mean action noise std: 1.73
          Mean value_function loss: 41.8841
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.1008
                       Mean reward: 116.78
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 0.8909
    Episode_Reward/rotating_object: 20.6655
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.43s
                      Time elapsed: 00:08:54
                               ETA: 00:48:29

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 41818 steps/s (collection: 2.232s, learning 0.119s)
             Mean action noise std: 1.74
          Mean value_function loss: 42.1516
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 51.1277
                       Mean reward: 81.22
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 0.8730
    Episode_Reward/rotating_object: 19.8606
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.35s
                      Time elapsed: 00:08:57
                               ETA: 00:48:27

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 41417 steps/s (collection: 2.250s, learning 0.123s)
             Mean action noise std: 1.74
          Mean value_function loss: 50.8379
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 51.1524
                       Mean reward: 106.19
               Mean episode length: 226.79
    Episode_Reward/reaching_object: 0.8828
    Episode_Reward/rotating_object: 19.8626
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.37s
                      Time elapsed: 00:08:59
                               ETA: 00:48:25

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 39856 steps/s (collection: 2.340s, learning 0.127s)
             Mean action noise std: 1.74
          Mean value_function loss: 48.4809
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.1742
                       Mean reward: 97.66
               Mean episode length: 222.18
    Episode_Reward/reaching_object: 0.8814
    Episode_Reward/rotating_object: 18.9839
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.47s
                      Time elapsed: 00:09:01
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 41114 steps/s (collection: 2.278s, learning 0.113s)
             Mean action noise std: 1.74
          Mean value_function loss: 46.3172
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.1927
                       Mean reward: 91.70
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 0.9029
    Episode_Reward/rotating_object: 20.0236
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.39s
                      Time elapsed: 00:09:04
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 42084 steps/s (collection: 2.217s, learning 0.119s)
             Mean action noise std: 1.74
          Mean value_function loss: 49.3197
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.2220
                       Mean reward: 72.94
               Mean episode length: 225.70
    Episode_Reward/reaching_object: 0.8482
    Episode_Reward/rotating_object: 15.9577
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.34s
                      Time elapsed: 00:09:06
                               ETA: 00:48:20

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 41326 steps/s (collection: 2.258s, learning 0.120s)
             Mean action noise std: 1.74
          Mean value_function loss: 50.0614
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 51.2475
                       Mean reward: 110.73
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 0.9018
    Episode_Reward/rotating_object: 21.3772
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.38s
                      Time elapsed: 00:09:08
                               ETA: 00:48:18

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 41323 steps/s (collection: 2.261s, learning 0.118s)
             Mean action noise std: 1.75
          Mean value_function loss: 47.9870
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 51.2759
                       Mean reward: 91.09
               Mean episode length: 217.14
    Episode_Reward/reaching_object: 0.8774
    Episode_Reward/rotating_object: 18.6092
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.38s
                      Time elapsed: 00:09:11
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 41283 steps/s (collection: 2.262s, learning 0.119s)
             Mean action noise std: 1.75
          Mean value_function loss: 52.0035
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 51.3081
                       Mean reward: 62.97
               Mean episode length: 219.70
    Episode_Reward/reaching_object: 0.8136
    Episode_Reward/rotating_object: 16.8497
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.38s
                      Time elapsed: 00:09:13
                               ETA: 00:48:14

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 40597 steps/s (collection: 2.301s, learning 0.121s)
             Mean action noise std: 1.75
          Mean value_function loss: 53.7399
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.3321
                       Mean reward: 93.35
               Mean episode length: 223.44
    Episode_Reward/reaching_object: 0.9256
    Episode_Reward/rotating_object: 21.2420
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.42s
                      Time elapsed: 00:09:16
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 40350 steps/s (collection: 2.301s, learning 0.136s)
             Mean action noise std: 1.75
          Mean value_function loss: 55.7586
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.3684
                       Mean reward: 103.04
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 0.8981
    Episode_Reward/rotating_object: 19.9554
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.44s
                      Time elapsed: 00:09:18
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 41012 steps/s (collection: 2.278s, learning 0.119s)
             Mean action noise std: 1.75
          Mean value_function loss: 51.1361
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.4005
                       Mean reward: 96.71
               Mean episode length: 221.66
    Episode_Reward/reaching_object: 0.8606
    Episode_Reward/rotating_object: 19.8430
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.40s
                      Time elapsed: 00:09:20
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 41015 steps/s (collection: 2.275s, learning 0.121s)
             Mean action noise std: 1.76
          Mean value_function loss: 52.8968
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.4133
                       Mean reward: 108.66
               Mean episode length: 219.51
    Episode_Reward/reaching_object: 0.9000
    Episode_Reward/rotating_object: 22.7530
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.40s
                      Time elapsed: 00:09:23
                               ETA: 00:48:08

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 41036 steps/s (collection: 2.274s, learning 0.122s)
             Mean action noise std: 1.76
          Mean value_function loss: 48.1492
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.4275
                       Mean reward: 92.57
               Mean episode length: 220.90
    Episode_Reward/reaching_object: 0.8943
    Episode_Reward/rotating_object: 20.0425
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.40s
                      Time elapsed: 00:09:25
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 40927 steps/s (collection: 2.281s, learning 0.121s)
             Mean action noise std: 1.76
          Mean value_function loss: 57.9080
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.4477
                       Mean reward: 99.46
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 0.9120
    Episode_Reward/rotating_object: 20.0549
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.40s
                      Time elapsed: 00:09:28
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 40850 steps/s (collection: 2.284s, learning 0.123s)
             Mean action noise std: 1.76
          Mean value_function loss: 68.0746
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.4727
                       Mean reward: 120.01
               Mean episode length: 224.83
    Episode_Reward/reaching_object: 0.9053
    Episode_Reward/rotating_object: 20.7021
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.41s
                      Time elapsed: 00:09:30
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 40344 steps/s (collection: 2.317s, learning 0.120s)
             Mean action noise std: 1.76
          Mean value_function loss: 63.4403
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 51.4871
                       Mean reward: 116.88
               Mean episode length: 225.87
    Episode_Reward/reaching_object: 0.9031
    Episode_Reward/rotating_object: 20.0183
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.44s
                      Time elapsed: 00:09:33
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 40338 steps/s (collection: 2.318s, learning 0.119s)
             Mean action noise std: 1.76
          Mean value_function loss: 61.1669
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 51.5040
                       Mean reward: 113.75
               Mean episode length: 224.74
    Episode_Reward/reaching_object: 0.9113
    Episode_Reward/rotating_object: 22.5491
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.44s
                      Time elapsed: 00:09:35
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 40610 steps/s (collection: 2.300s, learning 0.121s)
             Mean action noise std: 1.76
          Mean value_function loss: 61.5213
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 51.5268
                       Mean reward: 109.19
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 0.9188
    Episode_Reward/rotating_object: 23.8690
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.42s
                      Time elapsed: 00:09:37
                               ETA: 00:47:57

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 39667 steps/s (collection: 2.352s, learning 0.127s)
             Mean action noise std: 1.77
          Mean value_function loss: 64.8257
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 51.5628
                       Mean reward: 120.51
               Mean episode length: 215.26
    Episode_Reward/reaching_object: 0.8956
    Episode_Reward/rotating_object: 21.6467
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.48s
                      Time elapsed: 00:09:40
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 38386 steps/s (collection: 2.434s, learning 0.127s)
             Mean action noise std: 1.77
          Mean value_function loss: 66.6259
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.5905
                       Mean reward: 101.22
               Mean episode length: 226.76
    Episode_Reward/reaching_object: 0.9150
    Episode_Reward/rotating_object: 22.2490
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.56s
                      Time elapsed: 00:09:42
                               ETA: 00:47:55

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 39208 steps/s (collection: 2.380s, learning 0.127s)
             Mean action noise std: 1.77
          Mean value_function loss: 72.3871
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 51.6122
                       Mean reward: 130.95
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 0.9416
    Episode_Reward/rotating_object: 24.5002
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.51s
                      Time elapsed: 00:09:45
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 39063 steps/s (collection: 2.384s, learning 0.132s)
             Mean action noise std: 1.77
          Mean value_function loss: 64.1713
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 51.6331
                       Mean reward: 106.45
               Mean episode length: 218.57
    Episode_Reward/reaching_object: 0.9245
    Episode_Reward/rotating_object: 23.1063
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.52s
                      Time elapsed: 00:09:47
                               ETA: 00:47:52

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 42122 steps/s (collection: 2.222s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 62.6935
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 51.6529
                       Mean reward: 127.48
               Mean episode length: 222.57
    Episode_Reward/reaching_object: 0.9451
    Episode_Reward/rotating_object: 23.4096
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.33s
                      Time elapsed: 00:09:50
                               ETA: 00:47:50

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 41853 steps/s (collection: 2.237s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 59.7727
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 51.6721
                       Mean reward: 115.77
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 0.9164
    Episode_Reward/rotating_object: 21.4705
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.35s
                      Time elapsed: 00:09:52
                               ETA: 00:47:48

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 41199 steps/s (collection: 2.274s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 59.9881
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 51.6954
                       Mean reward: 119.91
               Mean episode length: 227.78
    Episode_Reward/reaching_object: 0.9599
    Episode_Reward/rotating_object: 25.1278
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.39s
                      Time elapsed: 00:09:54
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 40725 steps/s (collection: 2.287s, learning 0.127s)
             Mean action noise std: 1.78
          Mean value_function loss: 64.0631
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 51.7206
                       Mean reward: 121.31
               Mean episode length: 222.79
    Episode_Reward/reaching_object: 0.9460
    Episode_Reward/rotating_object: 25.5950
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.41s
                      Time elapsed: 00:09:57
                               ETA: 00:47:44

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 40415 steps/s (collection: 2.301s, learning 0.131s)
             Mean action noise std: 1.78
          Mean value_function loss: 67.6934
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 51.7433
                       Mean reward: 162.31
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 0.9813
    Episode_Reward/rotating_object: 28.0097
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.43s
                      Time elapsed: 00:09:59
                               ETA: 00:47:43

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 40794 steps/s (collection: 2.276s, learning 0.133s)
             Mean action noise std: 1.78
          Mean value_function loss: 65.6917
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 51.7636
                       Mean reward: 141.84
               Mean episode length: 225.84
    Episode_Reward/reaching_object: 0.9646
    Episode_Reward/rotating_object: 25.8564
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.41s
                      Time elapsed: 00:10:02
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 40644 steps/s (collection: 2.284s, learning 0.134s)
             Mean action noise std: 1.78
          Mean value_function loss: 66.5398
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 51.7875
                       Mean reward: 116.67
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 0.9745
    Episode_Reward/rotating_object: 26.6050
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.42s
                      Time elapsed: 00:10:04
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 40435 steps/s (collection: 2.302s, learning 0.129s)
             Mean action noise std: 1.78
          Mean value_function loss: 70.5604
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 51.8058
                       Mean reward: 133.54
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 0.9772
    Episode_Reward/rotating_object: 26.5516
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.43s
                      Time elapsed: 00:10:07
                               ETA: 00:47:37

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 40638 steps/s (collection: 2.296s, learning 0.123s)
             Mean action noise std: 1.78
          Mean value_function loss: 61.9366
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.8185
                       Mean reward: 157.92
               Mean episode length: 219.38
    Episode_Reward/reaching_object: 0.9778
    Episode_Reward/rotating_object: 30.0234
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.42s
                      Time elapsed: 00:10:09
                               ETA: 00:47:35

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 40402 steps/s (collection: 2.308s, learning 0.126s)
             Mean action noise std: 1.79
          Mean value_function loss: 63.5827
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.8361
                       Mean reward: 140.86
               Mean episode length: 218.19
    Episode_Reward/reaching_object: 0.9427
    Episode_Reward/rotating_object: 26.1941
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.43s
                      Time elapsed: 00:10:11
                               ETA: 00:47:34

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 40646 steps/s (collection: 2.298s, learning 0.120s)
             Mean action noise std: 1.79
          Mean value_function loss: 66.2467
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.8655
                       Mean reward: 131.15
               Mean episode length: 214.20
    Episode_Reward/reaching_object: 0.9697
    Episode_Reward/rotating_object: 25.9730
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.42s
                      Time elapsed: 00:10:14
                               ETA: 00:47:32

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 40075 steps/s (collection: 2.326s, learning 0.127s)
             Mean action noise std: 1.79
          Mean value_function loss: 66.0576
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 51.8890
                       Mean reward: 154.17
               Mean episode length: 223.17
    Episode_Reward/reaching_object: 1.0103
    Episode_Reward/rotating_object: 31.8838
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.45s
                      Time elapsed: 00:10:16
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 39913 steps/s (collection: 2.345s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 72.5510
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 51.9041
                       Mean reward: 175.04
               Mean episode length: 222.53
    Episode_Reward/reaching_object: 0.9915
    Episode_Reward/rotating_object: 30.8049
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.46s
                      Time elapsed: 00:10:19
                               ETA: 00:47:29

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 40335 steps/s (collection: 2.312s, learning 0.126s)
             Mean action noise std: 1.79
          Mean value_function loss: 65.7750
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.9202
                       Mean reward: 148.33
               Mean episode length: 221.13
    Episode_Reward/reaching_object: 0.9775
    Episode_Reward/rotating_object: 28.0538
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.44s
                      Time elapsed: 00:10:21
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 40534 steps/s (collection: 2.299s, learning 0.126s)
             Mean action noise std: 1.79
          Mean value_function loss: 70.8162
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.9317
                       Mean reward: 147.10
               Mean episode length: 224.28
    Episode_Reward/reaching_object: 0.9987
    Episode_Reward/rotating_object: 30.0181
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.43s
                      Time elapsed: 00:10:24
                               ETA: 00:47:25

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 40774 steps/s (collection: 2.292s, learning 0.119s)
             Mean action noise std: 1.79
          Mean value_function loss: 73.1667
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.9488
                       Mean reward: 165.17
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 0.9955
    Episode_Reward/rotating_object: 29.6779
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.41s
                      Time elapsed: 00:10:26
                               ETA: 00:47:23

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 39956 steps/s (collection: 2.333s, learning 0.127s)
             Mean action noise std: 1.80
          Mean value_function loss: 70.6572
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 51.9717
                       Mean reward: 129.55
               Mean episode length: 210.09
    Episode_Reward/reaching_object: 1.0203
    Episode_Reward/rotating_object: 31.3493
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.46s
                      Time elapsed: 00:10:29
                               ETA: 00:47:22

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 39504 steps/s (collection: 2.362s, learning 0.126s)
             Mean action noise std: 1.80
          Mean value_function loss: 65.5543
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.9928
                       Mean reward: 159.77
               Mean episode length: 226.44
    Episode_Reward/reaching_object: 1.0164
    Episode_Reward/rotating_object: 30.5560
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.49s
                      Time elapsed: 00:10:31
                               ETA: 00:47:20

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 38870 steps/s (collection: 2.396s, learning 0.133s)
             Mean action noise std: 1.80
          Mean value_function loss: 79.2310
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 52.0104
                       Mean reward: 180.04
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 0.9991
    Episode_Reward/rotating_object: 32.4729
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.53s
                      Time elapsed: 00:10:34
                               ETA: 00:47:19

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 38091 steps/s (collection: 2.448s, learning 0.133s)
             Mean action noise std: 1.80
          Mean value_function loss: 91.7786
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.0199
                       Mean reward: 189.54
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 0.9951
    Episode_Reward/rotating_object: 29.3894
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.58s
                      Time elapsed: 00:10:36
                               ETA: 00:47:18

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 35616 steps/s (collection: 2.617s, learning 0.143s)
             Mean action noise std: 1.80
          Mean value_function loss: 80.6192
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.0342
                       Mean reward: 165.31
               Mean episode length: 226.53
    Episode_Reward/reaching_object: 1.0351
    Episode_Reward/rotating_object: 32.2341
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.76s
                      Time elapsed: 00:10:39
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 39492 steps/s (collection: 2.377s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 76.8139
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 52.0492
                       Mean reward: 152.00
               Mean episode length: 216.90
    Episode_Reward/reaching_object: 1.0064
    Episode_Reward/rotating_object: 29.5355
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.49s
                      Time elapsed: 00:10:41
                               ETA: 00:47:16

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 40315 steps/s (collection: 2.306s, learning 0.132s)
             Mean action noise std: 1.80
          Mean value_function loss: 70.6991
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.0591
                       Mean reward: 155.42
               Mean episode length: 221.68
    Episode_Reward/reaching_object: 1.0061
    Episode_Reward/rotating_object: 29.6806
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.44s
                      Time elapsed: 00:10:44
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 40379 steps/s (collection: 2.316s, learning 0.119s)
             Mean action noise std: 1.80
          Mean value_function loss: 63.4822
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.0727
                       Mean reward: 173.49
               Mean episode length: 220.12
    Episode_Reward/reaching_object: 1.0176
    Episode_Reward/rotating_object: 32.6715
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.43s
                      Time elapsed: 00:10:46
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 40628 steps/s (collection: 2.297s, learning 0.123s)
             Mean action noise std: 1.80
          Mean value_function loss: 61.0809
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 52.0866
                       Mean reward: 158.29
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 1.0139
    Episode_Reward/rotating_object: 32.2435
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.42s
                      Time elapsed: 00:10:49
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 40483 steps/s (collection: 2.304s, learning 0.124s)
             Mean action noise std: 1.81
          Mean value_function loss: 61.7098
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.1036
                       Mean reward: 156.73
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 0.9979
    Episode_Reward/rotating_object: 32.6845
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.43s
                      Time elapsed: 00:10:51
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 40297 steps/s (collection: 2.318s, learning 0.122s)
             Mean action noise std: 1.81
          Mean value_function loss: 65.1758
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.1253
                       Mean reward: 221.79
               Mean episode length: 224.79
    Episode_Reward/reaching_object: 1.0365
    Episode_Reward/rotating_object: 37.6231
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.44s
                      Time elapsed: 00:10:54
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 40309 steps/s (collection: 2.315s, learning 0.124s)
             Mean action noise std: 1.81
          Mean value_function loss: 69.0619
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.1489
                       Mean reward: 202.21
               Mean episode length: 227.02
    Episode_Reward/reaching_object: 1.0305
    Episode_Reward/rotating_object: 35.4162
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.44s
                      Time elapsed: 00:10:56
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 40590 steps/s (collection: 2.299s, learning 0.123s)
             Mean action noise std: 1.81
          Mean value_function loss: 75.9885
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.1784
                       Mean reward: 162.90
               Mean episode length: 221.05
    Episode_Reward/reaching_object: 1.0010
    Episode_Reward/rotating_object: 34.4692
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.42s
                      Time elapsed: 00:10:58
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 40056 steps/s (collection: 2.332s, learning 0.122s)
             Mean action noise std: 1.81
          Mean value_function loss: 72.2831
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.2046
                       Mean reward: 173.08
               Mean episode length: 222.05
    Episode_Reward/reaching_object: 1.0282
    Episode_Reward/rotating_object: 32.7917
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.45s
                      Time elapsed: 00:11:01
                               ETA: 00:47:01

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 39879 steps/s (collection: 2.346s, learning 0.119s)
             Mean action noise std: 1.81
          Mean value_function loss: 75.3048
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 52.2304
                       Mean reward: 222.97
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 38.9598
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.47s
                      Time elapsed: 00:11:03
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 39789 steps/s (collection: 2.348s, learning 0.123s)
             Mean action noise std: 1.82
          Mean value_function loss: 83.3785
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 52.2528
                       Mean reward: 244.03
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.0709
    Episode_Reward/rotating_object: 39.3305
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.47s
                      Time elapsed: 00:11:06
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 40159 steps/s (collection: 2.326s, learning 0.122s)
             Mean action noise std: 1.82
          Mean value_function loss: 87.1028
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 52.2725
                       Mean reward: 174.88
               Mean episode length: 220.81
    Episode_Reward/reaching_object: 1.0937
    Episode_Reward/rotating_object: 38.6278
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.45s
                      Time elapsed: 00:11:08
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 39874 steps/s (collection: 2.346s, learning 0.120s)
             Mean action noise std: 1.82
          Mean value_function loss: 92.2150
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 52.2864
                       Mean reward: 214.05
               Mean episode length: 223.21
    Episode_Reward/reaching_object: 1.0514
    Episode_Reward/rotating_object: 39.7204
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.47s
                      Time elapsed: 00:11:11
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 40186 steps/s (collection: 2.316s, learning 0.130s)
             Mean action noise std: 1.82
          Mean value_function loss: 91.4116
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.3004
                       Mean reward: 224.31
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 40.7004
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.45s
                      Time elapsed: 00:11:13
                               ETA: 00:46:53

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 40473 steps/s (collection: 2.313s, learning 0.116s)
             Mean action noise std: 1.82
          Mean value_function loss: 102.7546
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 52.3184
                       Mean reward: 174.33
               Mean episode length: 210.79
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 36.3726
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.43s
                      Time elapsed: 00:11:16
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 40628 steps/s (collection: 2.300s, learning 0.119s)
             Mean action noise std: 1.82
          Mean value_function loss: 90.3242
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 52.3321
                       Mean reward: 209.02
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 1.0472
    Episode_Reward/rotating_object: 37.2977
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.42s
                      Time elapsed: 00:11:18
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 40875 steps/s (collection: 2.285s, learning 0.120s)
             Mean action noise std: 1.82
          Mean value_function loss: 84.4829
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 52.3378
                       Mean reward: 212.59
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 1.1016
    Episode_Reward/rotating_object: 42.8441
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.40s
                      Time elapsed: 00:11:20
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 40051 steps/s (collection: 2.326s, learning 0.128s)
             Mean action noise std: 1.82
          Mean value_function loss: 84.9851
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 52.3446
                       Mean reward: 224.93
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 1.1045
    Episode_Reward/rotating_object: 40.3380
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.45s
                      Time elapsed: 00:11:23
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 40827 steps/s (collection: 2.288s, learning 0.120s)
             Mean action noise std: 1.82
          Mean value_function loss: 82.9254
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.3556
                       Mean reward: 263.13
               Mean episode length: 233.35
    Episode_Reward/reaching_object: 1.1126
    Episode_Reward/rotating_object: 44.3252
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.41s
                      Time elapsed: 00:11:25
                               ETA: 00:46:43

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 40457 steps/s (collection: 2.307s, learning 0.122s)
             Mean action noise std: 1.82
          Mean value_function loss: 86.5836
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.3681
                       Mean reward: 232.00
               Mean episode length: 228.83
    Episode_Reward/reaching_object: 1.1109
    Episode_Reward/rotating_object: 44.5134
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.43s
                      Time elapsed: 00:11:28
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 40450 steps/s (collection: 2.299s, learning 0.131s)
             Mean action noise std: 1.83
          Mean value_function loss: 89.3496
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.3788
                       Mean reward: 193.47
               Mean episode length: 220.27
    Episode_Reward/reaching_object: 1.0912
    Episode_Reward/rotating_object: 40.8616
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.43s
                      Time elapsed: 00:11:30
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 39981 steps/s (collection: 2.336s, learning 0.123s)
             Mean action noise std: 1.83
          Mean value_function loss: 84.6573
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 52.3904
                       Mean reward: 247.53
               Mean episode length: 219.58
    Episode_Reward/reaching_object: 1.0745
    Episode_Reward/rotating_object: 42.5428
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.46s
                      Time elapsed: 00:11:33
                               ETA: 00:46:37

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 40252 steps/s (collection: 2.323s, learning 0.119s)
             Mean action noise std: 1.83
          Mean value_function loss: 81.3799
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 52.4018
                       Mean reward: 187.87
               Mean episode length: 216.83
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 40.3451
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.44s
                      Time elapsed: 00:11:35
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 40019 steps/s (collection: 2.332s, learning 0.124s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.9579
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 52.4057
                       Mean reward: 217.33
               Mean episode length: 223.44
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 41.9854
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.46s
                      Time elapsed: 00:11:37
                               ETA: 00:46:34

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 39511 steps/s (collection: 2.347s, learning 0.141s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.7234
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.4118
                       Mean reward: 232.80
               Mean episode length: 215.98
    Episode_Reward/reaching_object: 1.0754
    Episode_Reward/rotating_object: 45.2114
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.49s
                      Time elapsed: 00:11:40
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 39625 steps/s (collection: 2.351s, learning 0.130s)
             Mean action noise std: 1.83
          Mean value_function loss: 82.0623
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.4254
                       Mean reward: 241.16
               Mean episode length: 225.67
    Episode_Reward/reaching_object: 1.1280
    Episode_Reward/rotating_object: 48.0188
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.48s
                      Time elapsed: 00:11:42
                               ETA: 00:46:30

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 39917 steps/s (collection: 2.339s, learning 0.124s)
             Mean action noise std: 1.83
          Mean value_function loss: 88.9655
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.4543
                       Mean reward: 206.07
               Mean episode length: 220.10
    Episode_Reward/reaching_object: 1.1034
    Episode_Reward/rotating_object: 46.9421
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.46s
                      Time elapsed: 00:11:45
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 40310 steps/s (collection: 2.318s, learning 0.121s)
             Mean action noise std: 1.83
          Mean value_function loss: 100.3796
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.4716
                       Mean reward: 226.57
               Mean episode length: 221.67
    Episode_Reward/reaching_object: 1.0520
    Episode_Reward/rotating_object: 41.8194
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.44s
                      Time elapsed: 00:11:47
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 39832 steps/s (collection: 2.346s, learning 0.122s)
             Mean action noise std: 1.83
          Mean value_function loss: 107.3060
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 52.4839
                       Mean reward: 213.14
               Mean episode length: 224.01
    Episode_Reward/reaching_object: 1.0831
    Episode_Reward/rotating_object: 44.7763
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.47s
                      Time elapsed: 00:11:50
                               ETA: 00:46:25

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 40153 steps/s (collection: 2.327s, learning 0.121s)
             Mean action noise std: 1.83
          Mean value_function loss: 92.6928
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.4920
                       Mean reward: 196.46
               Mean episode length: 212.42
    Episode_Reward/reaching_object: 1.0465
    Episode_Reward/rotating_object: 43.2218
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.45s
                      Time elapsed: 00:11:52
                               ETA: 00:46:23

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 39835 steps/s (collection: 2.346s, learning 0.122s)
             Mean action noise std: 1.84
          Mean value_function loss: 91.6618
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.5098
                       Mean reward: 188.49
               Mean episode length: 217.64
    Episode_Reward/reaching_object: 1.0514
    Episode_Reward/rotating_object: 44.3979
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.47s
                      Time elapsed: 00:11:55
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 40330 steps/s (collection: 2.318s, learning 0.120s)
             Mean action noise std: 1.84
          Mean value_function loss: 93.7217
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.5372
                       Mean reward: 260.52
               Mean episode length: 224.47
    Episode_Reward/reaching_object: 1.0846
    Episode_Reward/rotating_object: 47.4298
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.44s
                      Time elapsed: 00:11:57
                               ETA: 00:46:19

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 39692 steps/s (collection: 2.348s, learning 0.129s)
             Mean action noise std: 1.84
          Mean value_function loss: 103.0809
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 52.5554
                       Mean reward: 256.26
               Mean episode length: 221.21
    Episode_Reward/reaching_object: 1.0894
    Episode_Reward/rotating_object: 45.3496
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.48s
                      Time elapsed: 00:12:00
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 38645 steps/s (collection: 2.415s, learning 0.129s)
             Mean action noise std: 1.84
          Mean value_function loss: 101.2915
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.5683
                       Mean reward: 232.17
               Mean episode length: 217.87
    Episode_Reward/reaching_object: 1.0712
    Episode_Reward/rotating_object: 44.5069
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.54s
                      Time elapsed: 00:12:02
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 35730 steps/s (collection: 2.605s, learning 0.146s)
             Mean action noise std: 1.84
          Mean value_function loss: 106.6697
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.5864
                       Mean reward: 226.89
               Mean episode length: 216.73
    Episode_Reward/reaching_object: 1.0945
    Episode_Reward/rotating_object: 47.7227
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.75s
                      Time elapsed: 00:12:05
                               ETA: 00:46:15

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 38462 steps/s (collection: 2.406s, learning 0.150s)
             Mean action noise std: 1.84
          Mean value_function loss: 102.7022
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.6102
                       Mean reward: 242.79
               Mean episode length: 214.42
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 47.5129
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.56s
                      Time elapsed: 00:12:07
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 37598 steps/s (collection: 2.483s, learning 0.131s)
             Mean action noise std: 1.84
          Mean value_function loss: 103.4173
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.6300
                       Mean reward: 233.28
               Mean episode length: 218.35
    Episode_Reward/reaching_object: 1.0828
    Episode_Reward/rotating_object: 46.5328
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.61s
                      Time elapsed: 00:12:10
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 37578 steps/s (collection: 2.490s, learning 0.126s)
             Mean action noise std: 1.84
          Mean value_function loss: 104.8546
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.6419
                       Mean reward: 248.12
               Mean episode length: 219.78
    Episode_Reward/reaching_object: 1.1050
    Episode_Reward/rotating_object: 46.5790
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.62s
                      Time elapsed: 00:12:13
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 38159 steps/s (collection: 2.449s, learning 0.127s)
             Mean action noise std: 1.85
          Mean value_function loss: 110.2893
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.6526
                       Mean reward: 255.30
               Mean episode length: 222.40
    Episode_Reward/reaching_object: 1.1203
    Episode_Reward/rotating_object: 49.1106
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.58s
                      Time elapsed: 00:12:15
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 38263 steps/s (collection: 2.440s, learning 0.129s)
             Mean action noise std: 1.85
          Mean value_function loss: 97.7963
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.6672
                       Mean reward: 252.46
               Mean episode length: 220.72
    Episode_Reward/reaching_object: 1.1167
    Episode_Reward/rotating_object: 48.1023
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.57s
                      Time elapsed: 00:12:18
                               ETA: 00:46:08

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 39112 steps/s (collection: 2.393s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 111.5450
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 52.6854
                       Mean reward: 282.51
               Mean episode length: 222.04
    Episode_Reward/reaching_object: 1.1168
    Episode_Reward/rotating_object: 51.5090
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.51s
                      Time elapsed: 00:12:20
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 39863 steps/s (collection: 2.340s, learning 0.126s)
             Mean action noise std: 1.85
          Mean value_function loss: 110.7184
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.7015
                       Mean reward: 283.41
               Mean episode length: 220.14
    Episode_Reward/reaching_object: 1.1134
    Episode_Reward/rotating_object: 51.2170
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.47s
                      Time elapsed: 00:12:23
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 39904 steps/s (collection: 2.334s, learning 0.129s)
             Mean action noise std: 1.85
          Mean value_function loss: 117.5443
               Mean surrogate loss: 0.0154
                 Mean entropy loss: 52.7098
                       Mean reward: 272.75
               Mean episode length: 214.67
    Episode_Reward/reaching_object: 1.1588
    Episode_Reward/rotating_object: 55.4721
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.46s
                      Time elapsed: 00:12:25
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 39495 steps/s (collection: 2.369s, learning 0.120s)
             Mean action noise std: 1.85
          Mean value_function loss: 107.6962
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 52.7127
                       Mean reward: 255.58
               Mean episode length: 211.33
    Episode_Reward/reaching_object: 1.1241
    Episode_Reward/rotating_object: 52.1291
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.49s
                      Time elapsed: 00:12:28
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 39645 steps/s (collection: 2.358s, learning 0.122s)
             Mean action noise std: 1.85
          Mean value_function loss: 109.5332
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.7185
                       Mean reward: 245.88
               Mean episode length: 213.44
    Episode_Reward/reaching_object: 1.1261
    Episode_Reward/rotating_object: 51.0182
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.48s
                      Time elapsed: 00:12:30
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 39884 steps/s (collection: 2.339s, learning 0.125s)
             Mean action noise std: 1.85
          Mean value_function loss: 126.3759
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 52.7245
                       Mean reward: 266.93
               Mean episode length: 213.84
    Episode_Reward/reaching_object: 1.1151
    Episode_Reward/rotating_object: 52.8610
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.46s
                      Time elapsed: 00:12:33
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 40205 steps/s (collection: 2.325s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 114.8095
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 52.7297
                       Mean reward: 294.18
               Mean episode length: 214.43
    Episode_Reward/reaching_object: 1.1473
    Episode_Reward/rotating_object: 55.7705
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.45s
                      Time elapsed: 00:12:35
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 40289 steps/s (collection: 2.318s, learning 0.122s)
             Mean action noise std: 1.85
          Mean value_function loss: 104.0377
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 52.7342
                       Mean reward: 258.09
               Mean episode length: 221.17
    Episode_Reward/reaching_object: 1.1286
    Episode_Reward/rotating_object: 54.4867
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.44s
                      Time elapsed: 00:12:38
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 39975 steps/s (collection: 2.338s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 103.9013
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.7379
                       Mean reward: 232.01
               Mean episode length: 211.28
    Episode_Reward/reaching_object: 1.0919
    Episode_Reward/rotating_object: 50.1869
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.46s
                      Time elapsed: 00:12:40
                               ETA: 00:45:52

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 40176 steps/s (collection: 2.326s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 112.6718
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.7431
                       Mean reward: 224.87
               Mean episode length: 204.09
    Episode_Reward/reaching_object: 1.1440
    Episode_Reward/rotating_object: 55.5987
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.45s
                      Time elapsed: 00:12:43
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 40081 steps/s (collection: 2.332s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 116.5805
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 52.7520
                       Mean reward: 246.80
               Mean episode length: 197.86
    Episode_Reward/reaching_object: 1.1011
    Episode_Reward/rotating_object: 51.6176
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.45s
                      Time elapsed: 00:12:45
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 39774 steps/s (collection: 2.351s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 101.1913
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 52.7597
                       Mean reward: 265.22
               Mean episode length: 208.55
    Episode_Reward/reaching_object: 1.0901
    Episode_Reward/rotating_object: 50.8794
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.47s
                      Time elapsed: 00:12:47
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 39312 steps/s (collection: 2.377s, learning 0.124s)
             Mean action noise std: 1.85
          Mean value_function loss: 100.0548
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 52.7673
                       Mean reward: 300.91
               Mean episode length: 218.67
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 55.2989
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.50s
                      Time elapsed: 00:12:50
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 38580 steps/s (collection: 2.420s, learning 0.128s)
             Mean action noise std: 1.86
          Mean value_function loss: 93.8128
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.7760
                       Mean reward: 223.21
               Mean episode length: 205.42
    Episode_Reward/reaching_object: 1.1300
    Episode_Reward/rotating_object: 56.0239
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.55s
                      Time elapsed: 00:12:53
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 38252 steps/s (collection: 2.443s, learning 0.127s)
             Mean action noise std: 1.86
          Mean value_function loss: 107.2405
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.7880
                       Mean reward: 334.81
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 1.1735
    Episode_Reward/rotating_object: 61.9269
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.57s
                      Time elapsed: 00:12:55
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 38567 steps/s (collection: 2.435s, learning 0.114s)
             Mean action noise std: 1.86
          Mean value_function loss: 111.1720
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 52.8063
                       Mean reward: 262.38
               Mean episode length: 212.77
    Episode_Reward/reaching_object: 1.0976
    Episode_Reward/rotating_object: 52.2712
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.55s
                      Time elapsed: 00:12:58
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 41980 steps/s (collection: 2.231s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 111.1927
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.8218
                       Mean reward: 318.64
               Mean episode length: 214.12
    Episode_Reward/reaching_object: 1.0903
    Episode_Reward/rotating_object: 55.0976
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.34s
                      Time elapsed: 00:13:00
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 42020 steps/s (collection: 2.226s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 109.1174
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.8358
                       Mean reward: 273.29
               Mean episode length: 210.71
    Episode_Reward/reaching_object: 1.1187
    Episode_Reward/rotating_object: 57.8059
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 2.34s
                      Time elapsed: 00:13:02
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 41735 steps/s (collection: 2.242s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 113.3775
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 52.8522
                       Mean reward: 309.15
               Mean episode length: 219.88
    Episode_Reward/reaching_object: 1.1287
    Episode_Reward/rotating_object: 57.5804
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 2.36s
                      Time elapsed: 00:13:05
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 40946 steps/s (collection: 2.288s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 103.4326
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 52.8577
                       Mean reward: 259.85
               Mean episode length: 208.64
    Episode_Reward/reaching_object: 1.0767
    Episode_Reward/rotating_object: 54.4721
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 2.40s
                      Time elapsed: 00:13:07
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 40553 steps/s (collection: 2.304s, learning 0.120s)
             Mean action noise std: 1.86
          Mean value_function loss: 105.1037
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 52.8614
                       Mean reward: 313.14
               Mean episode length: 211.82
    Episode_Reward/reaching_object: 1.1141
    Episode_Reward/rotating_object: 60.4264
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 2.42s
                      Time elapsed: 00:13:09
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 39517 steps/s (collection: 2.366s, learning 0.122s)
             Mean action noise std: 1.86
          Mean value_function loss: 91.6175
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.8646
                       Mean reward: 311.35
               Mean episode length: 203.14
    Episode_Reward/reaching_object: 1.0973
    Episode_Reward/rotating_object: 59.4275
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 2.49s
                      Time elapsed: 00:13:12
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 40176 steps/s (collection: 2.327s, learning 0.120s)
             Mean action noise std: 1.86
          Mean value_function loss: 97.6917
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.8719
                       Mean reward: 275.46
               Mean episode length: 207.05
    Episode_Reward/reaching_object: 1.0931
    Episode_Reward/rotating_object: 55.9543
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 2.45s
                      Time elapsed: 00:13:14
                               ETA: 00:45:24

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 40187 steps/s (collection: 2.327s, learning 0.120s)
             Mean action noise std: 1.86
          Mean value_function loss: 96.8753
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.8839
                       Mean reward: 282.47
               Mean episode length: 204.55
    Episode_Reward/reaching_object: 1.1078
    Episode_Reward/rotating_object: 59.5528
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 2.45s
                      Time elapsed: 00:13:17
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 39637 steps/s (collection: 2.360s, learning 0.120s)
             Mean action noise std: 1.86
          Mean value_function loss: 104.3176
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.8931
                       Mean reward: 305.10
               Mean episode length: 219.76
    Episode_Reward/reaching_object: 1.1491
    Episode_Reward/rotating_object: 64.4480
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 2.48s
                      Time elapsed: 00:13:19
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 39419 steps/s (collection: 2.372s, learning 0.122s)
             Mean action noise std: 1.87
          Mean value_function loss: 101.8051
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.9042
                       Mean reward: 257.05
               Mean episode length: 208.19
    Episode_Reward/reaching_object: 1.1222
    Episode_Reward/rotating_object: 57.0228
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 2.49s
                      Time elapsed: 00:13:22
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 39522 steps/s (collection: 2.363s, learning 0.124s)
             Mean action noise std: 1.87
          Mean value_function loss: 113.0774
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 52.9171
                       Mean reward: 330.66
               Mean episode length: 217.22
    Episode_Reward/reaching_object: 1.1365
    Episode_Reward/rotating_object: 62.2000
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.49s
                      Time elapsed: 00:13:24
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 39727 steps/s (collection: 2.346s, learning 0.129s)
             Mean action noise std: 1.87
          Mean value_function loss: 106.2648
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 52.9238
                       Mean reward: 302.01
               Mean episode length: 214.33
    Episode_Reward/reaching_object: 1.1466
    Episode_Reward/rotating_object: 63.6174
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.47s
                      Time elapsed: 00:13:27
                               ETA: 00:45:15

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 39076 steps/s (collection: 2.393s, learning 0.123s)
             Mean action noise std: 1.87
          Mean value_function loss: 104.7733
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 52.9286
                       Mean reward: 299.27
               Mean episode length: 208.66
    Episode_Reward/reaching_object: 1.1159
    Episode_Reward/rotating_object: 59.2040
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.52s
                      Time elapsed: 00:13:29
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 39587 steps/s (collection: 2.362s, learning 0.121s)
             Mean action noise std: 1.87
          Mean value_function loss: 112.0848
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.9326
                       Mean reward: 355.50
               Mean episode length: 217.61
    Episode_Reward/reaching_object: 1.0859
    Episode_Reward/rotating_object: 61.0431
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.48s
                      Time elapsed: 00:13:32
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 39620 steps/s (collection: 2.362s, learning 0.119s)
             Mean action noise std: 1.87
          Mean value_function loss: 109.1726
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.9408
                       Mean reward: 304.22
               Mean episode length: 218.76
    Episode_Reward/reaching_object: 1.1266
    Episode_Reward/rotating_object: 60.0197
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.48s
                      Time elapsed: 00:13:34
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 40179 steps/s (collection: 2.327s, learning 0.120s)
             Mean action noise std: 1.87
          Mean value_function loss: 97.9242
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 52.9536
                       Mean reward: 314.13
               Mean episode length: 209.54
    Episode_Reward/reaching_object: 1.1211
    Episode_Reward/rotating_object: 63.2227
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.45s
                      Time elapsed: 00:13:37
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 39935 steps/s (collection: 2.342s, learning 0.119s)
             Mean action noise std: 1.87
          Mean value_function loss: 113.3770
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 52.9682
                       Mean reward: 323.37
               Mean episode length: 205.68
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 64.6439
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.46s
                      Time elapsed: 00:13:39
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 39177 steps/s (collection: 2.383s, learning 0.126s)
             Mean action noise std: 1.87
          Mean value_function loss: 105.6032
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.9715
                       Mean reward: 320.31
               Mean episode length: 205.39
    Episode_Reward/reaching_object: 1.1217
    Episode_Reward/rotating_object: 65.4777
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.51s
                      Time elapsed: 00:13:42
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 38895 steps/s (collection: 2.400s, learning 0.127s)
             Mean action noise std: 1.87
          Mean value_function loss: 109.7000
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.9788
                       Mean reward: 292.91
               Mean episode length: 204.78
    Episode_Reward/reaching_object: 1.1362
    Episode_Reward/rotating_object: 64.9051
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.53s
                      Time elapsed: 00:13:44
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 39092 steps/s (collection: 2.385s, learning 0.130s)
             Mean action noise std: 1.87
          Mean value_function loss: 102.7943
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 52.9893
                       Mean reward: 321.66
               Mean episode length: 207.43
    Episode_Reward/reaching_object: 1.1509
    Episode_Reward/rotating_object: 67.8263
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.51s
                      Time elapsed: 00:13:47
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 38605 steps/s (collection: 2.420s, learning 0.126s)
             Mean action noise std: 1.87
          Mean value_function loss: 116.7229
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.0007
                       Mean reward: 304.87
               Mean episode length: 209.85
    Episode_Reward/reaching_object: 1.1602
    Episode_Reward/rotating_object: 66.2107
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.55s
                      Time elapsed: 00:13:49
                               ETA: 00:44:58

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 39229 steps/s (collection: 2.379s, learning 0.126s)
             Mean action noise std: 1.87
          Mean value_function loss: 106.3417
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 53.0077
                       Mean reward: 361.35
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 72.7308
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.51s
                      Time elapsed: 00:13:52
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 39697 steps/s (collection: 2.363s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 108.2297
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.0147
                       Mean reward: 344.46
               Mean episode length: 217.68
    Episode_Reward/reaching_object: 1.1549
    Episode_Reward/rotating_object: 67.7635
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.48s
                      Time elapsed: 00:13:54
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 40821 steps/s (collection: 2.294s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 105.0884
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 53.0262
                       Mean reward: 334.62
               Mean episode length: 207.03
    Episode_Reward/reaching_object: 1.1205
    Episode_Reward/rotating_object: 68.0620
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.41s
                      Time elapsed: 00:13:57
                               ETA: 00:44:52

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 41163 steps/s (collection: 2.276s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 107.4778
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 53.0378
                       Mean reward: 295.55
               Mean episode length: 207.94
    Episode_Reward/reaching_object: 1.1334
    Episode_Reward/rotating_object: 66.0226
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.39s
                      Time elapsed: 00:13:59
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 40439 steps/s (collection: 2.308s, learning 0.123s)
             Mean action noise std: 1.88
          Mean value_function loss: 88.9048
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.0495
                       Mean reward: 354.89
               Mean episode length: 211.33
    Episode_Reward/reaching_object: 1.1398
    Episode_Reward/rotating_object: 70.3299
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.43s
                      Time elapsed: 00:14:01
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 40180 steps/s (collection: 2.326s, learning 0.121s)
             Mean action noise std: 1.88
          Mean value_function loss: 102.0986
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 53.0597
                       Mean reward: 392.17
               Mean episode length: 218.36
    Episode_Reward/reaching_object: 1.1519
    Episode_Reward/rotating_object: 71.6030
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.45s
                      Time elapsed: 00:14:04
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 38785 steps/s (collection: 2.415s, learning 0.119s)
             Mean action noise std: 1.88
          Mean value_function loss: 105.6677
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.0654
                       Mean reward: 341.41
               Mean episode length: 215.27
    Episode_Reward/reaching_object: 1.1164
    Episode_Reward/rotating_object: 67.3327
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.53s
                      Time elapsed: 00:14:06
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 39163 steps/s (collection: 2.357s, learning 0.153s)
             Mean action noise std: 1.88
          Mean value_function loss: 113.6560
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.0694
                       Mean reward: 328.93
               Mean episode length: 207.43
    Episode_Reward/reaching_object: 1.1201
    Episode_Reward/rotating_object: 69.0301
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.51s
                      Time elapsed: 00:14:09
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 39837 steps/s (collection: 2.344s, learning 0.124s)
             Mean action noise std: 1.88
          Mean value_function loss: 125.5288
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 53.0779
                       Mean reward: 360.15
               Mean episode length: 223.37
    Episode_Reward/reaching_object: 1.1710
    Episode_Reward/rotating_object: 75.2922
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.47s
                      Time elapsed: 00:14:11
                               ETA: 00:44:40

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 40290 steps/s (collection: 2.318s, learning 0.122s)
             Mean action noise std: 1.88
          Mean value_function loss: 114.3979
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 53.0876
                       Mean reward: 360.54
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 1.1315
    Episode_Reward/rotating_object: 69.5554
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.44s
                      Time elapsed: 00:14:14
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 40381 steps/s (collection: 2.317s, learning 0.118s)
             Mean action noise std: 1.88
          Mean value_function loss: 118.6804
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.1039
                       Mean reward: 358.38
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 73.1941
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.43s
                      Time elapsed: 00:14:16
                               ETA: 00:44:36

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 40140 steps/s (collection: 2.330s, learning 0.119s)
             Mean action noise std: 1.88
          Mean value_function loss: 126.7340
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.1142
                       Mean reward: 357.73
               Mean episode length: 208.93
    Episode_Reward/reaching_object: 1.1316
    Episode_Reward/rotating_object: 70.0848
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.45s
                      Time elapsed: 00:14:19
                               ETA: 00:44:34

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 39589 steps/s (collection: 2.365s, learning 0.118s)
             Mean action noise std: 1.88
          Mean value_function loss: 120.6391
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.1252
                       Mean reward: 372.50
               Mean episode length: 210.03
    Episode_Reward/reaching_object: 1.0986
    Episode_Reward/rotating_object: 71.3599
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.48s
                      Time elapsed: 00:14:21
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 39933 steps/s (collection: 2.336s, learning 0.125s)
             Mean action noise std: 1.88
          Mean value_function loss: 102.1100
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 53.1339
                       Mean reward: 329.55
               Mean episode length: 217.88
    Episode_Reward/reaching_object: 1.1675
    Episode_Reward/rotating_object: 72.5143
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.46s
                      Time elapsed: 00:14:24
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 40254 steps/s (collection: 2.322s, learning 0.120s)
             Mean action noise std: 1.88
          Mean value_function loss: 94.3639
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.1376
                       Mean reward: 376.35
               Mean episode length: 217.07
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 70.2987
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.44s
                      Time elapsed: 00:14:26
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 39706 steps/s (collection: 2.349s, learning 0.127s)
             Mean action noise std: 1.88
          Mean value_function loss: 97.7512
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.1445
                       Mean reward: 348.89
               Mean episode length: 221.46
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 75.6908
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.48s
                      Time elapsed: 00:14:29
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 39072 steps/s (collection: 2.397s, learning 0.119s)
             Mean action noise std: 1.89
          Mean value_function loss: 98.0122
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.1508
                       Mean reward: 344.30
               Mean episode length: 217.93
    Episode_Reward/reaching_object: 1.1461
    Episode_Reward/rotating_object: 71.8155
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.52s
                      Time elapsed: 00:14:31
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 39472 steps/s (collection: 2.364s, learning 0.126s)
             Mean action noise std: 1.89
          Mean value_function loss: 111.8902
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.1623
                       Mean reward: 375.80
               Mean episode length: 220.55
    Episode_Reward/reaching_object: 1.1545
    Episode_Reward/rotating_object: 73.2934
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.49s
                      Time elapsed: 00:14:34
                               ETA: 00:44:22

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 39031 steps/s (collection: 2.393s, learning 0.126s)
             Mean action noise std: 1.89
          Mean value_function loss: 118.4498
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 53.1717
                       Mean reward: 378.34
               Mean episode length: 216.10
    Episode_Reward/reaching_object: 1.1327
    Episode_Reward/rotating_object: 72.6112
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.52s
                      Time elapsed: 00:14:36
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 38326 steps/s (collection: 2.437s, learning 0.128s)
             Mean action noise std: 1.89
          Mean value_function loss: 110.8409
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.1790
                       Mean reward: 390.42
               Mean episode length: 210.05
    Episode_Reward/reaching_object: 1.1338
    Episode_Reward/rotating_object: 74.8608
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.56s
                      Time elapsed: 00:14:39
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 39734 steps/s (collection: 2.353s, learning 0.121s)
             Mean action noise std: 1.89
          Mean value_function loss: 114.0455
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 53.1910
                       Mean reward: 356.15
               Mean episode length: 207.13
    Episode_Reward/reaching_object: 1.1320
    Episode_Reward/rotating_object: 73.3452
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.47s
                      Time elapsed: 00:14:41
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 39973 steps/s (collection: 2.340s, learning 0.120s)
             Mean action noise std: 1.89
          Mean value_function loss: 117.0565
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 53.2024
                       Mean reward: 407.37
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.1522
    Episode_Reward/rotating_object: 74.6828
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.46s
                      Time elapsed: 00:14:44
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 39885 steps/s (collection: 2.344s, learning 0.121s)
             Mean action noise std: 1.89
          Mean value_function loss: 108.2995
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 53.2135
                       Mean reward: 384.07
               Mean episode length: 208.47
    Episode_Reward/reaching_object: 1.1029
    Episode_Reward/rotating_object: 75.0678
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.46s
                      Time elapsed: 00:14:46
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 39282 steps/s (collection: 2.382s, learning 0.120s)
             Mean action noise std: 1.89
          Mean value_function loss: 113.4089
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.2221
                       Mean reward: 381.94
               Mean episode length: 219.30
    Episode_Reward/reaching_object: 1.1475
    Episode_Reward/rotating_object: 76.9502
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.50s
                      Time elapsed: 00:14:49
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 39675 steps/s (collection: 2.356s, learning 0.121s)
             Mean action noise std: 1.89
          Mean value_function loss: 120.4656
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.2319
                       Mean reward: 380.51
               Mean episode length: 211.61
    Episode_Reward/reaching_object: 1.1219
    Episode_Reward/rotating_object: 71.9324
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.48s
                      Time elapsed: 00:14:51
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 39805 steps/s (collection: 2.349s, learning 0.121s)
             Mean action noise std: 1.89
          Mean value_function loss: 115.2738
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.2439
                       Mean reward: 383.88
               Mean episode length: 216.28
    Episode_Reward/reaching_object: 1.1130
    Episode_Reward/rotating_object: 72.1985
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.47s
                      Time elapsed: 00:14:54
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 39705 steps/s (collection: 2.352s, learning 0.124s)
             Mean action noise std: 1.89
          Mean value_function loss: 125.2018
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.2583
                       Mean reward: 339.97
               Mean episode length: 215.42
    Episode_Reward/reaching_object: 1.1172
    Episode_Reward/rotating_object: 70.9035
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.48s
                      Time elapsed: 00:14:56
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 39585 steps/s (collection: 2.361s, learning 0.122s)
             Mean action noise std: 1.90
          Mean value_function loss: 127.7426
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.2711
                       Mean reward: 371.09
               Mean episode length: 208.84
    Episode_Reward/reaching_object: 1.1251
    Episode_Reward/rotating_object: 74.1993
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.48s
                      Time elapsed: 00:14:59
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 39815 steps/s (collection: 2.347s, learning 0.122s)
             Mean action noise std: 1.90
          Mean value_function loss: 112.5407
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 53.2835
                       Mean reward: 382.52
               Mean episode length: 209.98
    Episode_Reward/reaching_object: 1.1235
    Episode_Reward/rotating_object: 73.2106
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.47s
                      Time elapsed: 00:15:01
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 39415 steps/s (collection: 2.370s, learning 0.124s)
             Mean action noise std: 1.90
          Mean value_function loss: 104.7868
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.2894
                       Mean reward: 402.08
               Mean episode length: 220.92
    Episode_Reward/reaching_object: 1.1580
    Episode_Reward/rotating_object: 79.6555
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.49s
                      Time elapsed: 00:15:04
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 39927 steps/s (collection: 2.341s, learning 0.121s)
             Mean action noise std: 1.90
          Mean value_function loss: 110.9745
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.2966
                       Mean reward: 329.06
               Mean episode length: 207.10
    Episode_Reward/reaching_object: 1.1278
    Episode_Reward/rotating_object: 74.1003
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.46s
                      Time elapsed: 00:15:06
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 39925 steps/s (collection: 2.342s, learning 0.120s)
             Mean action noise std: 1.90
          Mean value_function loss: 107.7635
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 53.3104
                       Mean reward: 355.82
               Mean episode length: 210.93
    Episode_Reward/reaching_object: 1.1206
    Episode_Reward/rotating_object: 75.1301
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.46s
                      Time elapsed: 00:15:08
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 40039 steps/s (collection: 2.327s, learning 0.128s)
             Mean action noise std: 1.90
          Mean value_function loss: 106.7360
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.3172
                       Mean reward: 410.55
               Mean episode length: 220.97
    Episode_Reward/reaching_object: 1.1405
    Episode_Reward/rotating_object: 75.2494
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.46s
                      Time elapsed: 00:15:11
                               ETA: 00:43:52

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 39325 steps/s (collection: 2.376s, learning 0.124s)
             Mean action noise std: 1.90
          Mean value_function loss: 119.5040
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 53.3272
                       Mean reward: 340.88
               Mean episode length: 207.17
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 67.5290
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.50s
                      Time elapsed: 00:15:13
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 39586 steps/s (collection: 2.353s, learning 0.130s)
             Mean action noise std: 1.90
          Mean value_function loss: 111.1846
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.3389
                       Mean reward: 398.64
               Mean episode length: 216.10
    Episode_Reward/reaching_object: 1.1442
    Episode_Reward/rotating_object: 77.3869
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.48s
                      Time elapsed: 00:15:16
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 38634 steps/s (collection: 2.418s, learning 0.126s)
             Mean action noise std: 1.90
          Mean value_function loss: 100.3730
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 53.3532
                       Mean reward: 378.18
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 75.2146
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.54s
                      Time elapsed: 00:15:18
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 39354 steps/s (collection: 2.372s, learning 0.126s)
             Mean action noise std: 1.90
          Mean value_function loss: 88.5041
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.3617
                       Mean reward: 409.15
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 1.1265
    Episode_Reward/rotating_object: 78.6159
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.50s
                      Time elapsed: 00:15:21
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 39087 steps/s (collection: 2.388s, learning 0.127s)
             Mean action noise std: 1.90
          Mean value_function loss: 97.0333
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.3688
                       Mean reward: 419.72
               Mean episode length: 218.04
    Episode_Reward/reaching_object: 1.0959
    Episode_Reward/rotating_object: 74.5754
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.51s
                      Time elapsed: 00:15:23
                               ETA: 00:43:42

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 39129 steps/s (collection: 2.382s, learning 0.130s)
             Mean action noise std: 1.90
          Mean value_function loss: 98.6632
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.3760
                       Mean reward: 406.42
               Mean episode length: 220.09
    Episode_Reward/reaching_object: 1.1171
    Episode_Reward/rotating_object: 75.3805
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.51s
                      Time elapsed: 00:15:26
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 38967 steps/s (collection: 2.402s, learning 0.120s)
             Mean action noise std: 1.90
          Mean value_function loss: 100.0880
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.3848
                       Mean reward: 359.20
               Mean episode length: 207.06
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 76.6738
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.52s
                      Time elapsed: 00:15:28
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 39758 steps/s (collection: 2.333s, learning 0.139s)
             Mean action noise std: 1.90
          Mean value_function loss: 94.9973
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.3917
                       Mean reward: 396.83
               Mean episode length: 213.51
    Episode_Reward/reaching_object: 1.0852
    Episode_Reward/rotating_object: 76.6657
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.47s
                      Time elapsed: 00:15:31
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 41450 steps/s (collection: 2.250s, learning 0.122s)
             Mean action noise std: 1.91
          Mean value_function loss: 103.5409
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 53.4027
                       Mean reward: 438.01
               Mean episode length: 225.99
    Episode_Reward/reaching_object: 1.1265
    Episode_Reward/rotating_object: 78.8648
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.37s
                      Time elapsed: 00:15:33
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 42742 steps/s (collection: 2.182s, learning 0.118s)
             Mean action noise std: 1.91
          Mean value_function loss: 99.1072
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 53.4164
                       Mean reward: 417.03
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.1102
    Episode_Reward/rotating_object: 80.5408
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.30s
                      Time elapsed: 00:15:36
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 42611 steps/s (collection: 2.187s, learning 0.120s)
             Mean action noise std: 1.91
          Mean value_function loss: 93.4476
               Mean surrogate loss: 0.0093
                 Mean entropy loss: 53.4227
                       Mean reward: 411.17
               Mean episode length: 218.87
    Episode_Reward/reaching_object: 1.1453
    Episode_Reward/rotating_object: 81.9843
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.31s
                      Time elapsed: 00:15:38
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 41586 steps/s (collection: 2.246s, learning 0.118s)
             Mean action noise std: 1.91
          Mean value_function loss: 102.5375
               Mean surrogate loss: 0.0023
                 Mean entropy loss: 53.4232
                       Mean reward: 393.63
               Mean episode length: 219.35
    Episode_Reward/reaching_object: 1.1481
    Episode_Reward/rotating_object: 83.0909
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.36s
                      Time elapsed: 00:15:40
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 41945 steps/s (collection: 2.226s, learning 0.118s)
             Mean action noise std: 1.91
          Mean value_function loss: 103.1247
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 53.4236
                       Mean reward: 423.81
               Mean episode length: 217.88
    Episode_Reward/reaching_object: 1.1355
    Episode_Reward/rotating_object: 81.8652
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.34s
                      Time elapsed: 00:15:43
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 41855 steps/s (collection: 2.230s, learning 0.119s)
             Mean action noise std: 1.91
          Mean value_function loss: 87.9833
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.4257
                       Mean reward: 424.52
               Mean episode length: 218.74
    Episode_Reward/reaching_object: 1.1537
    Episode_Reward/rotating_object: 85.9276
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.35s
                      Time elapsed: 00:15:45
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 41236 steps/s (collection: 2.254s, learning 0.129s)
             Mean action noise std: 1.91
          Mean value_function loss: 85.4702
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.4320
                       Mean reward: 419.27
               Mean episode length: 222.17
    Episode_Reward/reaching_object: 1.1413
    Episode_Reward/rotating_object: 84.4801
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.38s
                      Time elapsed: 00:15:47
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 38747 steps/s (collection: 2.406s, learning 0.131s)
             Mean action noise std: 1.91
          Mean value_function loss: 101.7572
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.4419
                       Mean reward: 469.25
               Mean episode length: 229.68
    Episode_Reward/reaching_object: 1.1621
    Episode_Reward/rotating_object: 91.2978
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.54s
                      Time elapsed: 00:15:50
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 40676 steps/s (collection: 2.296s, learning 0.121s)
             Mean action noise std: 1.91
          Mean value_function loss: 98.4758
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 53.4496
                       Mean reward: 408.98
               Mean episode length: 214.15
    Episode_Reward/reaching_object: 1.1225
    Episode_Reward/rotating_object: 84.8909
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.42s
                      Time elapsed: 00:15:52
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 40937 steps/s (collection: 2.283s, learning 0.118s)
             Mean action noise std: 1.91
          Mean value_function loss: 87.8217
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.4600
                       Mean reward: 458.26
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 87.8607
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.40s
                      Time elapsed: 00:15:55
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 39862 steps/s (collection: 2.346s, learning 0.120s)
             Mean action noise std: 1.91
          Mean value_function loss: 92.5956
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 53.4707
                       Mean reward: 472.88
               Mean episode length: 228.67
    Episode_Reward/reaching_object: 1.1472
    Episode_Reward/rotating_object: 87.9650
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.47s
                      Time elapsed: 00:15:57
                               ETA: 00:43:11

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 40310 steps/s (collection: 2.319s, learning 0.119s)
             Mean action noise std: 1.91
          Mean value_function loss: 95.8869
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 53.4788
                       Mean reward: 435.43
               Mean episode length: 221.50
    Episode_Reward/reaching_object: 1.1186
    Episode_Reward/rotating_object: 82.7387
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.44s
                      Time elapsed: 00:16:00
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 40480 steps/s (collection: 2.305s, learning 0.123s)
             Mean action noise std: 1.91
          Mean value_function loss: 97.1954
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.4858
                       Mean reward: 441.41
               Mean episode length: 220.27
    Episode_Reward/reaching_object: 1.1558
    Episode_Reward/rotating_object: 90.3263
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.43s
                      Time elapsed: 00:16:02
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 39637 steps/s (collection: 2.354s, learning 0.127s)
             Mean action noise std: 1.91
          Mean value_function loss: 94.9917
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.4972
                       Mean reward: 504.20
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 1.1601
    Episode_Reward/rotating_object: 94.2737
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.48s
                      Time elapsed: 00:16:05
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 40000 steps/s (collection: 2.332s, learning 0.126s)
             Mean action noise std: 1.91
          Mean value_function loss: 116.2175
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.5144
                       Mean reward: 483.73
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.1459
    Episode_Reward/rotating_object: 90.2792
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.46s
                      Time elapsed: 00:16:07
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 39610 steps/s (collection: 2.350s, learning 0.131s)
             Mean action noise std: 1.92
          Mean value_function loss: 113.0411
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.5267
                       Mean reward: 444.96
               Mean episode length: 220.95
    Episode_Reward/reaching_object: 1.1566
    Episode_Reward/rotating_object: 91.9984
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.48s
                      Time elapsed: 00:16:09
                               ETA: 00:43:01

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 39639 steps/s (collection: 2.353s, learning 0.126s)
             Mean action noise std: 1.92
          Mean value_function loss: 110.7422
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.5382
                       Mean reward: 435.30
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.1691
    Episode_Reward/rotating_object: 89.5055
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.48s
                      Time elapsed: 00:16:12
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 39970 steps/s (collection: 2.348s, learning 0.112s)
             Mean action noise std: 1.92
          Mean value_function loss: 116.8905
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.5514
                       Mean reward: 437.52
               Mean episode length: 215.91
    Episode_Reward/reaching_object: 1.1217
    Episode_Reward/rotating_object: 91.3947
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.46s
                      Time elapsed: 00:16:14
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 39884 steps/s (collection: 2.338s, learning 0.127s)
             Mean action noise std: 1.92
          Mean value_function loss: 112.3631
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.5601
                       Mean reward: 451.83
               Mean episode length: 219.67
    Episode_Reward/reaching_object: 1.1483
    Episode_Reward/rotating_object: 92.2414
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.46s
                      Time elapsed: 00:16:17
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 38927 steps/s (collection: 2.397s, learning 0.128s)
             Mean action noise std: 1.92
          Mean value_function loss: 109.5667
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.5688
                       Mean reward: 496.46
               Mean episode length: 227.90
    Episode_Reward/reaching_object: 1.1424
    Episode_Reward/rotating_object: 89.6230
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.53s
                      Time elapsed: 00:16:19
                               ETA: 00:42:52

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 38550 steps/s (collection: 2.421s, learning 0.129s)
             Mean action noise std: 1.92
          Mean value_function loss: 104.9629
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.5768
                       Mean reward: 385.01
               Mean episode length: 210.00
    Episode_Reward/reaching_object: 1.1240
    Episode_Reward/rotating_object: 85.0145
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.55s
                      Time elapsed: 00:16:22
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 39706 steps/s (collection: 2.356s, learning 0.120s)
             Mean action noise std: 1.92
          Mean value_function loss: 100.5777
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.5864
                       Mean reward: 479.41
               Mean episode length: 224.04
    Episode_Reward/reaching_object: 1.1322
    Episode_Reward/rotating_object: 87.9301
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.48s
                      Time elapsed: 00:16:24
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 39889 steps/s (collection: 2.341s, learning 0.123s)
             Mean action noise std: 1.92
          Mean value_function loss: 104.9436
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.5963
                       Mean reward: 445.64
               Mean episode length: 216.93
    Episode_Reward/reaching_object: 1.1443
    Episode_Reward/rotating_object: 89.7355
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.46s
                      Time elapsed: 00:16:27
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 40564 steps/s (collection: 2.304s, learning 0.120s)
             Mean action noise std: 1.92
          Mean value_function loss: 109.3931
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 53.6046
                       Mean reward: 497.51
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.1571
    Episode_Reward/rotating_object: 91.6004
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.42s
                      Time elapsed: 00:16:29
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 40468 steps/s (collection: 2.300s, learning 0.129s)
             Mean action noise std: 1.92
          Mean value_function loss: 108.8238
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 53.6106
                       Mean reward: 468.41
               Mean episode length: 217.59
    Episode_Reward/reaching_object: 1.1684
    Episode_Reward/rotating_object: 89.5518
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.43s
                      Time elapsed: 00:16:32
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 40069 steps/s (collection: 2.333s, learning 0.120s)
             Mean action noise std: 1.92
          Mean value_function loss: 95.3486
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.6136
                       Mean reward: 442.94
               Mean episode length: 212.82
    Episode_Reward/reaching_object: 1.1458
    Episode_Reward/rotating_object: 93.2432
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.45s
                      Time elapsed: 00:16:34
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 40341 steps/s (collection: 2.315s, learning 0.122s)
             Mean action noise std: 1.92
          Mean value_function loss: 104.8678
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.6171
                       Mean reward: 490.91
               Mean episode length: 224.35
    Episode_Reward/reaching_object: 1.1701
    Episode_Reward/rotating_object: 94.1398
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.44s
                      Time elapsed: 00:16:37
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 40260 steps/s (collection: 2.321s, learning 0.121s)
             Mean action noise std: 1.92
          Mean value_function loss: 106.2761
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 53.6252
                       Mean reward: 445.46
               Mean episode length: 218.52
    Episode_Reward/reaching_object: 1.1329
    Episode_Reward/rotating_object: 89.6023
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.44s
                      Time elapsed: 00:16:39
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 40126 steps/s (collection: 2.300s, learning 0.150s)
             Mean action noise std: 1.92
          Mean value_function loss: 106.0546
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 53.6336
                       Mean reward: 446.65
               Mean episode length: 214.14
    Episode_Reward/reaching_object: 1.1075
    Episode_Reward/rotating_object: 89.8225
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.45s
                      Time elapsed: 00:16:42
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 40296 steps/s (collection: 2.320s, learning 0.120s)
             Mean action noise std: 1.93
          Mean value_function loss: 108.0505
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.6422
                       Mean reward: 446.83
               Mean episode length: 217.98
    Episode_Reward/reaching_object: 1.1425
    Episode_Reward/rotating_object: 90.5492
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.44s
                      Time elapsed: 00:16:44
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 39712 steps/s (collection: 2.343s, learning 0.133s)
             Mean action noise std: 1.93
          Mean value_function loss: 110.8302
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.6532
                       Mean reward: 427.15
               Mean episode length: 220.33
    Episode_Reward/reaching_object: 1.1148
    Episode_Reward/rotating_object: 89.8801
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.48s
                      Time elapsed: 00:16:46
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 39843 steps/s (collection: 2.348s, learning 0.119s)
             Mean action noise std: 1.93
          Mean value_function loss: 114.7463
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 53.6645
                       Mean reward: 449.58
               Mean episode length: 210.71
    Episode_Reward/reaching_object: 1.1376
    Episode_Reward/rotating_object: 93.2435
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.47s
                      Time elapsed: 00:16:49
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 40658 steps/s (collection: 2.284s, learning 0.134s)
             Mean action noise std: 1.93
          Mean value_function loss: 101.5657
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 53.6793
                       Mean reward: 482.95
               Mean episode length: 218.78
    Episode_Reward/reaching_object: 1.1465
    Episode_Reward/rotating_object: 93.4472
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.42s
                      Time elapsed: 00:16:51
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 40841 steps/s (collection: 2.275s, learning 0.132s)
             Mean action noise std: 1.93
          Mean value_function loss: 109.4112
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.6867
                       Mean reward: 489.41
               Mean episode length: 223.50
    Episode_Reward/reaching_object: 1.1741
    Episode_Reward/rotating_object: 96.0065
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.41s
                      Time elapsed: 00:16:54
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 41557 steps/s (collection: 2.252s, learning 0.113s)
             Mean action noise std: 1.93
          Mean value_function loss: 106.1293
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.6950
                       Mean reward: 506.92
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.1890
    Episode_Reward/rotating_object: 98.1442
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.37s
                      Time elapsed: 00:16:56
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 41213 steps/s (collection: 2.253s, learning 0.132s)
             Mean action noise std: 1.93
          Mean value_function loss: 110.0455
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 53.7056
                       Mean reward: 508.45
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 1.1904
    Episode_Reward/rotating_object: 99.4677
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.39s
                      Time elapsed: 00:16:58
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 39543 steps/s (collection: 2.360s, learning 0.126s)
             Mean action noise std: 1.93
          Mean value_function loss: 101.9097
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.7126
                       Mean reward: 482.74
               Mean episode length: 218.22
    Episode_Reward/reaching_object: 1.1774
    Episode_Reward/rotating_object: 95.0338
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.49s
                      Time elapsed: 00:17:01
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 39484 steps/s (collection: 2.363s, learning 0.127s)
             Mean action noise std: 1.93
          Mean value_function loss: 104.1078
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.7213
                       Mean reward: 517.24
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 1.1796
    Episode_Reward/rotating_object: 99.1845
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.49s
                      Time elapsed: 00:17:03
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 39009 steps/s (collection: 2.402s, learning 0.118s)
             Mean action noise std: 1.93
          Mean value_function loss: 108.2432
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.7309
                       Mean reward: 476.70
               Mean episode length: 223.65
    Episode_Reward/reaching_object: 1.1822
    Episode_Reward/rotating_object: 98.8823
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.52s
                      Time elapsed: 00:17:06
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 41585 steps/s (collection: 2.253s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 101.0836
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.7385
                       Mean reward: 486.01
               Mean episode length: 218.38
    Episode_Reward/reaching_object: 1.1348
    Episode_Reward/rotating_object: 92.3221
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.36s
                      Time elapsed: 00:17:08
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 40748 steps/s (collection: 2.284s, learning 0.129s)
             Mean action noise std: 1.93
          Mean value_function loss: 105.3685
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.7507
                       Mean reward: 509.23
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.1890
    Episode_Reward/rotating_object: 98.7961
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.41s
                      Time elapsed: 00:17:11
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 40352 steps/s (collection: 2.317s, learning 0.119s)
             Mean action noise std: 1.93
          Mean value_function loss: 101.5798
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 53.7581
                       Mean reward: 505.64
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 1.1730
    Episode_Reward/rotating_object: 96.8937
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.44s
                      Time elapsed: 00:17:13
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 40743 steps/s (collection: 2.296s, learning 0.117s)
             Mean action noise std: 1.93
          Mean value_function loss: 97.2653
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.7631
                       Mean reward: 419.88
               Mean episode length: 215.35
    Episode_Reward/reaching_object: 1.1474
    Episode_Reward/rotating_object: 97.8735
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.41s
                      Time elapsed: 00:17:16
                               ETA: 00:42:02

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 39737 steps/s (collection: 2.352s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 100.2544
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.7698
                       Mean reward: 432.17
               Mean episode length: 209.20
    Episode_Reward/reaching_object: 1.1302
    Episode_Reward/rotating_object: 95.2386
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.47s
                      Time elapsed: 00:17:18
                               ETA: 00:42:00

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 40358 steps/s (collection: 2.314s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 99.4071
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.7817
                       Mean reward: 481.02
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 1.1485
    Episode_Reward/rotating_object: 96.0730
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.44s
                      Time elapsed: 00:17:20
                               ETA: 00:41:58

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 40099 steps/s (collection: 2.329s, learning 0.123s)
             Mean action noise std: 1.94
          Mean value_function loss: 104.0439
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 53.7929
                       Mean reward: 498.20
               Mean episode length: 224.95
    Episode_Reward/reaching_object: 1.1636
    Episode_Reward/rotating_object: 99.6936
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.45s
                      Time elapsed: 00:17:23
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 40535 steps/s (collection: 2.304s, learning 0.121s)
             Mean action noise std: 1.94
          Mean value_function loss: 96.6906
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 53.7985
                       Mean reward: 501.74
               Mean episode length: 223.90
    Episode_Reward/reaching_object: 1.1596
    Episode_Reward/rotating_object: 97.9762
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.43s
                      Time elapsed: 00:17:25
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 40836 steps/s (collection: 2.285s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 105.3851
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.8052
                       Mean reward: 489.95
               Mean episode length: 225.30
    Episode_Reward/reaching_object: 1.1238
    Episode_Reward/rotating_object: 94.3092
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.41s
                      Time elapsed: 00:17:28
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 40675 steps/s (collection: 2.295s, learning 0.121s)
             Mean action noise std: 1.94
          Mean value_function loss: 103.2863
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.8162
                       Mean reward: 525.92
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 1.1775
    Episode_Reward/rotating_object: 101.6431
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.42s
                      Time elapsed: 00:17:30
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 40673 steps/s (collection: 2.298s, learning 0.119s)
             Mean action noise std: 1.94
          Mean value_function loss: 108.4047
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.8305
                       Mean reward: 503.37
               Mean episode length: 221.24
    Episode_Reward/reaching_object: 1.1566
    Episode_Reward/rotating_object: 99.3934
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.42s
                      Time elapsed: 00:17:33
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 41051 steps/s (collection: 2.277s, learning 0.118s)
             Mean action noise std: 1.94
          Mean value_function loss: 104.4414
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.8417
                       Mean reward: 494.03
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 1.1348
    Episode_Reward/rotating_object: 97.2876
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.39s
                      Time elapsed: 00:17:35
                               ETA: 00:41:44

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 40459 steps/s (collection: 2.307s, learning 0.123s)
             Mean action noise std: 1.94
          Mean value_function loss: 103.6565
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.8512
                       Mean reward: 435.15
               Mean episode length: 208.78
    Episode_Reward/reaching_object: 1.1312
    Episode_Reward/rotating_object: 94.7709
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.43s
                      Time elapsed: 00:17:37
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 40315 steps/s (collection: 2.308s, learning 0.130s)
             Mean action noise std: 1.94
          Mean value_function loss: 114.0571
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.8579
                       Mean reward: 474.81
               Mean episode length: 214.95
    Episode_Reward/reaching_object: 1.1565
    Episode_Reward/rotating_object: 95.4172
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.44s
                      Time elapsed: 00:17:40
                               ETA: 00:41:40

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 39716 steps/s (collection: 2.350s, learning 0.126s)
             Mean action noise std: 1.94
          Mean value_function loss: 102.9847
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 53.8685
                       Mean reward: 456.33
               Mean episode length: 216.40
    Episode_Reward/reaching_object: 1.1776
    Episode_Reward/rotating_object: 101.1089
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.48s
                      Time elapsed: 00:17:42
                               ETA: 00:41:38

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 39928 steps/s (collection: 2.336s, learning 0.126s)
             Mean action noise std: 1.94
          Mean value_function loss: 105.1833
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.8787
                       Mean reward: 538.02
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 1.1742
    Episode_Reward/rotating_object: 97.1453
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.46s
                      Time elapsed: 00:17:45
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 39907 steps/s (collection: 2.337s, learning 0.127s)
             Mean action noise std: 1.95
          Mean value_function loss: 106.4496
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.8899
                       Mean reward: 490.17
               Mean episode length: 220.97
    Episode_Reward/reaching_object: 1.1649
    Episode_Reward/rotating_object: 95.9671
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.46s
                      Time elapsed: 00:17:47
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 39521 steps/s (collection: 2.361s, learning 0.126s)
             Mean action noise std: 1.95
          Mean value_function loss: 98.0983
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.9016
                       Mean reward: 517.21
               Mean episode length: 225.66
    Episode_Reward/reaching_object: 1.1561
    Episode_Reward/rotating_object: 95.3596
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.49s
                      Time elapsed: 00:17:50
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 39768 steps/s (collection: 2.344s, learning 0.128s)
             Mean action noise std: 1.95
          Mean value_function loss: 88.7283
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.9133
                       Mean reward: 498.11
               Mean episode length: 220.06
    Episode_Reward/reaching_object: 1.1432
    Episode_Reward/rotating_object: 98.6087
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.47s
                      Time elapsed: 00:17:52
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 39222 steps/s (collection: 2.386s, learning 0.120s)
             Mean action noise std: 1.95
          Mean value_function loss: 88.1511
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 53.9253
                       Mean reward: 520.38
               Mean episode length: 217.67
    Episode_Reward/reaching_object: 1.1644
    Episode_Reward/rotating_object: 101.5951
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.51s
                      Time elapsed: 00:17:55
                               ETA: 00:41:27

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 40292 steps/s (collection: 2.316s, learning 0.124s)
             Mean action noise std: 1.95
          Mean value_function loss: 93.0565
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 53.9392
                       Mean reward: 547.89
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 1.1605
    Episode_Reward/rotating_object: 101.2788
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.44s
                      Time elapsed: 00:17:57
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 40222 steps/s (collection: 2.320s, learning 0.124s)
             Mean action noise std: 1.95
          Mean value_function loss: 92.7305
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.9520
                       Mean reward: 540.42
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 105.4645
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.44s
                      Time elapsed: 00:18:00
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 39925 steps/s (collection: 2.338s, learning 0.124s)
             Mean action noise std: 1.95
          Mean value_function loss: 97.6914
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.9647
                       Mean reward: 507.21
               Mean episode length: 212.72
    Episode_Reward/reaching_object: 1.1676
    Episode_Reward/rotating_object: 103.9578
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.46s
                      Time elapsed: 00:18:02
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 40082 steps/s (collection: 2.327s, learning 0.125s)
             Mean action noise std: 1.95
          Mean value_function loss: 102.0936
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.9871
                       Mean reward: 448.44
               Mean episode length: 207.64
    Episode_Reward/reaching_object: 1.1269
    Episode_Reward/rotating_object: 94.6113
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.45s
                      Time elapsed: 00:18:05
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 40224 steps/s (collection: 2.321s, learning 0.123s)
             Mean action noise std: 1.96
          Mean value_function loss: 107.1854
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 54.0116
                       Mean reward: 535.73
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 1.1464
    Episode_Reward/rotating_object: 99.9245
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.44s
                      Time elapsed: 00:18:07
                               ETA: 00:41:16

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 40527 steps/s (collection: 2.307s, learning 0.119s)
             Mean action noise std: 1.96
          Mean value_function loss: 102.8394
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.0230
                       Mean reward: 500.29
               Mean episode length: 217.24
    Episode_Reward/reaching_object: 1.1529
    Episode_Reward/rotating_object: 100.9398
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.43s
                      Time elapsed: 00:18:09
                               ETA: 00:41:14

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 40209 steps/s (collection: 2.318s, learning 0.127s)
             Mean action noise std: 1.96
          Mean value_function loss: 109.2783
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.0323
                       Mean reward: 533.63
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.1710
    Episode_Reward/rotating_object: 101.7984
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.44s
                      Time elapsed: 00:18:12
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 40505 steps/s (collection: 2.307s, learning 0.120s)
             Mean action noise std: 1.96
          Mean value_function loss: 108.3112
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.0427
                       Mean reward: 497.70
               Mean episode length: 219.85
    Episode_Reward/reaching_object: 1.1669
    Episode_Reward/rotating_object: 100.9464
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.43s
                      Time elapsed: 00:18:14
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 40437 steps/s (collection: 2.310s, learning 0.121s)
             Mean action noise std: 1.96
          Mean value_function loss: 98.0010
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.0571
                       Mean reward: 550.36
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 1.1774
    Episode_Reward/rotating_object: 105.6153
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.43s
                      Time elapsed: 00:18:17
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 40552 steps/s (collection: 2.304s, learning 0.120s)
             Mean action noise std: 1.96
          Mean value_function loss: 98.9492
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 54.0733
                       Mean reward: 543.84
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.2038
    Episode_Reward/rotating_object: 107.2043
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.42s
                      Time elapsed: 00:18:19
                               ETA: 00:41:05

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 40455 steps/s (collection: 2.308s, learning 0.122s)
             Mean action noise std: 1.96
          Mean value_function loss: 92.7798
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 54.0779
                       Mean reward: 553.74
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 1.2048
    Episode_Reward/rotating_object: 106.0744
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.43s
                      Time elapsed: 00:18:22
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 40620 steps/s (collection: 2.298s, learning 0.122s)
             Mean action noise std: 1.96
          Mean value_function loss: 99.2631
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 54.0800
                       Mean reward: 556.02
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.1919
    Episode_Reward/rotating_object: 105.8509
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.42s
                      Time elapsed: 00:18:24
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 40565 steps/s (collection: 2.299s, learning 0.125s)
             Mean action noise std: 1.96
          Mean value_function loss: 91.0485
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 54.0807
                       Mean reward: 557.21
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 1.2244
    Episode_Reward/rotating_object: 112.1294
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.42s
                      Time elapsed: 00:18:26
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 39697 steps/s (collection: 2.349s, learning 0.127s)
             Mean action noise std: 1.96
          Mean value_function loss: 86.7073
               Mean surrogate loss: 0.0075
                 Mean entropy loss: 54.0815
                       Mean reward: 531.66
               Mean episode length: 221.40
    Episode_Reward/reaching_object: 1.1578
    Episode_Reward/rotating_object: 100.1456
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.48s
                      Time elapsed: 00:18:29
                               ETA: 00:40:56

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 42415 steps/s (collection: 2.194s, learning 0.124s)
             Mean action noise std: 1.96
          Mean value_function loss: 81.5112
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 54.0820
                       Mean reward: 558.57
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.2160
    Episode_Reward/rotating_object: 106.9718
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.32s
                      Time elapsed: 00:18:31
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 42338 steps/s (collection: 2.201s, learning 0.121s)
             Mean action noise std: 1.96
          Mean value_function loss: 95.2432
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 54.0826
                       Mean reward: 567.77
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.2114
    Episode_Reward/rotating_object: 108.9771
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.32s
                      Time elapsed: 00:18:34
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 42701 steps/s (collection: 2.191s, learning 0.111s)
             Mean action noise std: 1.96
          Mean value_function loss: 107.5383
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.0866
                       Mean reward: 553.48
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 110.4154
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.30s
                      Time elapsed: 00:18:36
                               ETA: 00:40:48

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 42233 steps/s (collection: 2.216s, learning 0.111s)
             Mean action noise std: 1.96
          Mean value_function loss: 108.7708
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.0977
                       Mean reward: 526.41
               Mean episode length: 227.66
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 107.1178
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.33s
                      Time elapsed: 00:18:38
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 41945 steps/s (collection: 2.230s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 103.9554
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.1158
                       Mean reward: 544.25
               Mean episode length: 217.72
    Episode_Reward/reaching_object: 1.1594
    Episode_Reward/rotating_object: 104.2011
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.34s
                      Time elapsed: 00:18:41
                               ETA: 00:40:43

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 41830 steps/s (collection: 2.235s, learning 0.115s)
             Mean action noise std: 1.97
          Mean value_function loss: 106.0411
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.1427
                       Mean reward: 527.87
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 108.0721
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.35s
                      Time elapsed: 00:18:43
                               ETA: 00:40:41

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 40578 steps/s (collection: 2.287s, learning 0.135s)
             Mean action noise std: 1.97
          Mean value_function loss: 116.4028
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.1574
                       Mean reward: 495.03
               Mean episode length: 221.77
    Episode_Reward/reaching_object: 1.1899
    Episode_Reward/rotating_object: 106.0817
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.42s
                      Time elapsed: 00:18:45
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 39736 steps/s (collection: 2.339s, learning 0.135s)
             Mean action noise std: 1.97
          Mean value_function loss: 101.4258
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.1685
                       Mean reward: 566.62
               Mean episode length: 227.84
    Episode_Reward/reaching_object: 1.1736
    Episode_Reward/rotating_object: 107.4893
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.47s
                      Time elapsed: 00:18:48
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 40135 steps/s (collection: 2.329s, learning 0.120s)
             Mean action noise std: 1.97
          Mean value_function loss: 93.1397
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.1769
                       Mean reward: 522.55
               Mean episode length: 219.87
    Episode_Reward/reaching_object: 1.1977
    Episode_Reward/rotating_object: 108.8619
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.45s
                      Time elapsed: 00:18:50
                               ETA: 00:40:34

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 39968 steps/s (collection: 2.336s, learning 0.124s)
             Mean action noise std: 1.97
          Mean value_function loss: 92.6010
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.1957
                       Mean reward: 525.18
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 105.7188
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.46s
                      Time elapsed: 00:18:53
                               ETA: 00:40:32

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 40405 steps/s (collection: 2.309s, learning 0.124s)
             Mean action noise std: 1.97
          Mean value_function loss: 105.3846
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 54.2200
                       Mean reward: 518.64
               Mean episode length: 219.11
    Episode_Reward/reaching_object: 1.1789
    Episode_Reward/rotating_object: 106.5448
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.43s
                      Time elapsed: 00:18:55
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 40039 steps/s (collection: 2.333s, learning 0.123s)
             Mean action noise std: 1.97
          Mean value_function loss: 99.1664
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 54.2276
                       Mean reward: 563.30
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.2093
    Episode_Reward/rotating_object: 107.1756
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.46s
                      Time elapsed: 00:18:58
                               ETA: 00:40:28

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 39964 steps/s (collection: 2.336s, learning 0.123s)
             Mean action noise std: 1.98
          Mean value_function loss: 106.0838
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.2407
                       Mean reward: 537.71
               Mean episode length: 223.49
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 107.9749
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.46s
                      Time elapsed: 00:19:00
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 39959 steps/s (collection: 2.337s, learning 0.123s)
             Mean action noise std: 1.98
          Mean value_function loss: 103.7852
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.2667
                       Mean reward: 499.39
               Mean episode length: 215.30
    Episode_Reward/reaching_object: 1.1443
    Episode_Reward/rotating_object: 99.7471
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.46s
                      Time elapsed: 00:19:02
                               ETA: 00:40:23

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 40128 steps/s (collection: 2.324s, learning 0.126s)
             Mean action noise std: 1.98
          Mean value_function loss: 84.8700
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.2787
                       Mean reward: 532.53
               Mean episode length: 229.49
    Episode_Reward/reaching_object: 1.1775
    Episode_Reward/rotating_object: 104.8405
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.45s
                      Time elapsed: 00:19:05
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 40134 steps/s (collection: 2.325s, learning 0.124s)
             Mean action noise std: 1.98
          Mean value_function loss: 92.2046
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.2909
                       Mean reward: 584.78
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 111.8870
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.45s
                      Time elapsed: 00:19:07
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 40581 steps/s (collection: 2.300s, learning 0.122s)
             Mean action noise std: 1.98
          Mean value_function loss: 92.4857
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 54.3098
                       Mean reward: 521.23
               Mean episode length: 222.14
    Episode_Reward/reaching_object: 1.1775
    Episode_Reward/rotating_object: 106.1964
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.42s
                      Time elapsed: 00:19:10
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 40388 steps/s (collection: 2.310s, learning 0.124s)
             Mean action noise std: 1.98
          Mean value_function loss: 85.5274
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 54.3195
                       Mean reward: 531.64
               Mean episode length: 217.22
    Episode_Reward/reaching_object: 1.1553
    Episode_Reward/rotating_object: 105.4355
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.43s
                      Time elapsed: 00:19:12
                               ETA: 00:40:14

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 40711 steps/s (collection: 2.289s, learning 0.126s)
             Mean action noise std: 1.98
          Mean value_function loss: 82.1071
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 54.3301
                       Mean reward: 588.90
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 112.3983
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.41s
                      Time elapsed: 00:19:15
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 39607 steps/s (collection: 2.356s, learning 0.126s)
             Mean action noise std: 1.98
          Mean value_function loss: 89.7404
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.3406
                       Mean reward: 523.50
               Mean episode length: 215.09
    Episode_Reward/reaching_object: 1.1568
    Episode_Reward/rotating_object: 108.2269
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.48s
                      Time elapsed: 00:19:17
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 39453 steps/s (collection: 2.368s, learning 0.123s)
             Mean action noise std: 1.98
          Mean value_function loss: 82.8141
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.3530
                       Mean reward: 534.57
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 1.1633
    Episode_Reward/rotating_object: 106.8316
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.49s
                      Time elapsed: 00:19:20
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 40747 steps/s (collection: 2.297s, learning 0.116s)
             Mean action noise std: 1.99
          Mean value_function loss: 94.3432
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.3687
                       Mean reward: 552.18
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.1971
    Episode_Reward/rotating_object: 106.7900
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.41s
                      Time elapsed: 00:19:22
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 41753 steps/s (collection: 2.243s, learning 0.111s)
             Mean action noise std: 1.99
          Mean value_function loss: 105.0652
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.3874
                       Mean reward: 541.33
               Mean episode length: 224.99
    Episode_Reward/reaching_object: 1.1674
    Episode_Reward/rotating_object: 106.3545
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.35s
                      Time elapsed: 00:19:24
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 40634 steps/s (collection: 2.308s, learning 0.111s)
             Mean action noise std: 1.99
          Mean value_function loss: 91.0234
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.4046
                       Mean reward: 581.88
               Mean episode length: 237.11
    Episode_Reward/reaching_object: 1.1840
    Episode_Reward/rotating_object: 109.0282
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.42s
                      Time elapsed: 00:19:27
                               ETA: 00:40:01

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 42658 steps/s (collection: 2.193s, learning 0.112s)
             Mean action noise std: 1.99
          Mean value_function loss: 96.5351
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.4156
                       Mean reward: 511.37
               Mean episode length: 227.63
    Episode_Reward/reaching_object: 1.1947
    Episode_Reward/rotating_object: 107.6027
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.30s
                      Time elapsed: 00:19:29
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 39445 steps/s (collection: 2.366s, learning 0.126s)
             Mean action noise std: 1.99
          Mean value_function loss: 87.0588
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 54.4320
                       Mean reward: 543.25
               Mean episode length: 229.77
    Episode_Reward/reaching_object: 1.2139
    Episode_Reward/rotating_object: 110.3191
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.49s
                      Time elapsed: 00:19:32
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 40560 steps/s (collection: 2.303s, learning 0.120s)
             Mean action noise std: 1.99
          Mean value_function loss: 98.9322
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.4446
                       Mean reward: 612.25
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 116.4941
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.42s
                      Time elapsed: 00:19:34
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 40366 steps/s (collection: 2.315s, learning 0.121s)
             Mean action noise std: 1.99
          Mean value_function loss: 95.9830
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.4559
                       Mean reward: 573.54
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 113.5880
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.44s
                      Time elapsed: 00:19:36
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 41135 steps/s (collection: 2.268s, learning 0.122s)
             Mean action noise std: 1.99
          Mean value_function loss: 88.0216
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 54.4681
                       Mean reward: 548.56
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 110.8526
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.39s
                      Time elapsed: 00:19:39
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 40969 steps/s (collection: 2.274s, learning 0.125s)
             Mean action noise std: 1.99
          Mean value_function loss: 84.9821
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.4758
                       Mean reward: 572.53
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 113.9001
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.40s
                      Time elapsed: 00:19:41
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 41068 steps/s (collection: 2.274s, learning 0.120s)
             Mean action noise std: 2.00
          Mean value_function loss: 87.9944
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.4912
                       Mean reward: 588.38
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 110.6064
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.39s
                      Time elapsed: 00:19:44
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 41097 steps/s (collection: 2.267s, learning 0.125s)
             Mean action noise std: 2.00
          Mean value_function loss: 88.5205
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.5031
                       Mean reward: 625.29
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.2282
    Episode_Reward/rotating_object: 118.4673
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.39s
                      Time elapsed: 00:19:46
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 40839 steps/s (collection: 2.287s, learning 0.120s)
             Mean action noise std: 2.00
          Mean value_function loss: 90.8622
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.5173
                       Mean reward: 541.12
               Mean episode length: 229.55
    Episode_Reward/reaching_object: 1.1977
    Episode_Reward/rotating_object: 110.9740
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.41s
                      Time elapsed: 00:19:48
                               ETA: 00:39:40

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 40678 steps/s (collection: 2.295s, learning 0.122s)
             Mean action noise std: 2.00
          Mean value_function loss: 93.1523
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.5385
                       Mean reward: 596.00
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 1.2269
    Episode_Reward/rotating_object: 114.4149
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.42s
                      Time elapsed: 00:19:51
                               ETA: 00:39:37

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 40672 steps/s (collection: 2.295s, learning 0.122s)
             Mean action noise std: 2.00
          Mean value_function loss: 97.6106
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.5557
                       Mean reward: 561.99
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 112.0255
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.42s
                      Time elapsed: 00:19:53
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 40551 steps/s (collection: 2.303s, learning 0.122s)
             Mean action noise std: 2.00
          Mean value_function loss: 93.1548
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.5714
                       Mean reward: 545.95
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 1.1838
    Episode_Reward/rotating_object: 110.2853
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.42s
                      Time elapsed: 00:19:56
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 40312 steps/s (collection: 2.315s, learning 0.123s)
             Mean action noise std: 2.00
          Mean value_function loss: 100.3139
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.5867
                       Mean reward: 548.74
               Mean episode length: 223.79
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 113.5232
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.44s
                      Time elapsed: 00:19:58
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 40421 steps/s (collection: 2.312s, learning 0.120s)
             Mean action noise std: 2.00
          Mean value_function loss: 95.7524
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.5948
                       Mean reward: 536.31
               Mean episode length: 217.41
    Episode_Reward/reaching_object: 1.1571
    Episode_Reward/rotating_object: 109.6397
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.43s
                      Time elapsed: 00:20:01
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 41002 steps/s (collection: 2.274s, learning 0.124s)
             Mean action noise std: 2.00
          Mean value_function loss: 87.0512
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 54.6044
                       Mean reward: 551.68
               Mean episode length: 230.92
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 111.3849
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.40s
                      Time elapsed: 00:20:03
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 39910 steps/s (collection: 2.334s, learning 0.130s)
             Mean action noise std: 2.01
          Mean value_function loss: 85.8506
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.6149
                       Mean reward: 559.56
               Mean episode length: 226.54
    Episode_Reward/reaching_object: 1.2152
    Episode_Reward/rotating_object: 115.9528
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.46s
                      Time elapsed: 00:20:05
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 39967 steps/s (collection: 2.334s, learning 0.126s)
             Mean action noise std: 2.01
          Mean value_function loss: 93.9260
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.6279
                       Mean reward: 567.20
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 112.2436
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.46s
                      Time elapsed: 00:20:08
                               ETA: 00:39:22

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 39842 steps/s (collection: 2.342s, learning 0.126s)
             Mean action noise std: 2.01
          Mean value_function loss: 96.2840
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.6456
                       Mean reward: 553.97
               Mean episode length: 224.51
    Episode_Reward/reaching_object: 1.1959
    Episode_Reward/rotating_object: 109.5738
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.47s
                      Time elapsed: 00:20:10
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 39570 steps/s (collection: 2.359s, learning 0.125s)
             Mean action noise std: 2.01
          Mean value_function loss: 94.4394
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 54.6646
                       Mean reward: 574.73
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 1.1809
    Episode_Reward/rotating_object: 110.7031
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.48s
                      Time elapsed: 00:20:13
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 39828 steps/s (collection: 2.340s, learning 0.129s)
             Mean action noise std: 2.01
          Mean value_function loss: 96.6991
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.6732
                       Mean reward: 543.35
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 1.2113
    Episode_Reward/rotating_object: 114.1752
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.47s
                      Time elapsed: 00:20:15
                               ETA: 00:39:15

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 38922 steps/s (collection: 2.398s, learning 0.128s)
             Mean action noise std: 2.01
          Mean value_function loss: 96.1102
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.6940
                       Mean reward: 579.60
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 1.1805
    Episode_Reward/rotating_object: 112.9050
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.53s
                      Time elapsed: 00:20:18
                               ETA: 00:39:13

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 37875 steps/s (collection: 2.467s, learning 0.128s)
             Mean action noise std: 2.02
          Mean value_function loss: 87.3135
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 54.7220
                       Mean reward: 575.01
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.1985
    Episode_Reward/rotating_object: 112.9994
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.60s
                      Time elapsed: 00:20:20
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 39681 steps/s (collection: 2.358s, learning 0.120s)
             Mean action noise std: 2.02
          Mean value_function loss: 89.3001
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.7414
                       Mean reward: 567.86
               Mean episode length: 223.11
    Episode_Reward/reaching_object: 1.1786
    Episode_Reward/rotating_object: 110.9390
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.48s
                      Time elapsed: 00:20:23
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 40956 steps/s (collection: 2.279s, learning 0.121s)
             Mean action noise std: 2.02
          Mean value_function loss: 89.3895
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.7578
                       Mean reward: 558.76
               Mean episode length: 226.13
    Episode_Reward/reaching_object: 1.2030
    Episode_Reward/rotating_object: 115.1547
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.40s
                      Time elapsed: 00:20:25
                               ETA: 00:39:06

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 40488 steps/s (collection: 2.308s, learning 0.120s)
             Mean action noise std: 2.02
          Mean value_function loss: 94.1004
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.7732
                       Mean reward: 530.90
               Mean episode length: 224.72
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 114.3026
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.43s
                      Time elapsed: 00:20:28
                               ETA: 00:39:04

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 40855 steps/s (collection: 2.283s, learning 0.123s)
             Mean action noise std: 2.02
          Mean value_function loss: 90.8692
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 54.7873
                       Mean reward: 558.22
               Mean episode length: 224.08
    Episode_Reward/reaching_object: 1.1771
    Episode_Reward/rotating_object: 110.7897
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.41s
                      Time elapsed: 00:20:30
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 40937 steps/s (collection: 2.281s, learning 0.121s)
             Mean action noise std: 2.02
          Mean value_function loss: 87.0408
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 54.8029
                       Mean reward: 532.13
               Mean episode length: 218.77
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 113.4435
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.40s
                      Time elapsed: 00:20:33
                               ETA: 00:38:59

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 40349 steps/s (collection: 2.317s, learning 0.120s)
             Mean action noise std: 2.02
          Mean value_function loss: 88.1542
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.8222
                       Mean reward: 614.80
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.2210
    Episode_Reward/rotating_object: 115.2116
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.44s
                      Time elapsed: 00:20:35
                               ETA: 00:38:57

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 41211 steps/s (collection: 2.266s, learning 0.120s)
             Mean action noise std: 2.03
          Mean value_function loss: 94.3773
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.8420
                       Mean reward: 589.90
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 113.7728
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.39s
                      Time elapsed: 00:20:37
                               ETA: 00:38:55

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 40925 steps/s (collection: 2.281s, learning 0.121s)
             Mean action noise std: 2.03
          Mean value_function loss: 98.5915
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.8653
                       Mean reward: 596.21
               Mean episode length: 228.96
    Episode_Reward/reaching_object: 1.2236
    Episode_Reward/rotating_object: 117.0895
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.40s
                      Time elapsed: 00:20:40
                               ETA: 00:38:52

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 40735 steps/s (collection: 2.290s, learning 0.123s)
             Mean action noise std: 2.03
          Mean value_function loss: 91.7243
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.8886
                       Mean reward: 573.53
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.2107
    Episode_Reward/rotating_object: 113.1105
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.41s
                      Time elapsed: 00:20:42
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 40362 steps/s (collection: 2.312s, learning 0.123s)
             Mean action noise std: 2.03
          Mean value_function loss: 88.2074
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.9132
                       Mean reward: 590.81
               Mean episode length: 227.63
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 115.9682
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.44s
                      Time elapsed: 00:20:45
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 40323 steps/s (collection: 2.317s, learning 0.121s)
             Mean action noise std: 2.03
          Mean value_function loss: 91.8323
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.9271
                       Mean reward: 562.69
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 115.6646
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.44s
                      Time elapsed: 00:20:47
                               ETA: 00:38:46

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 40051 steps/s (collection: 2.332s, learning 0.123s)
             Mean action noise std: 2.03
          Mean value_function loss: 92.7972
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.9388
                       Mean reward: 599.47
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 117.2763
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.45s
                      Time elapsed: 00:20:49
                               ETA: 00:38:43

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 40150 steps/s (collection: 2.329s, learning 0.120s)
             Mean action noise std: 2.03
          Mean value_function loss: 95.3546
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.9504
                       Mean reward: 592.85
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 116.2029
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.45s
                      Time elapsed: 00:20:52
                               ETA: 00:38:41

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 40996 steps/s (collection: 2.279s, learning 0.119s)
             Mean action noise std: 2.04
          Mean value_function loss: 93.0149
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.9715
                       Mean reward: 592.06
               Mean episode length: 225.74
    Episode_Reward/reaching_object: 1.2040
    Episode_Reward/rotating_object: 116.8668
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.40s
                      Time elapsed: 00:20:54
                               ETA: 00:38:39

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 41312 steps/s (collection: 2.254s, learning 0.125s)
             Mean action noise std: 2.04
          Mean value_function loss: 80.4605
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.9940
                       Mean reward: 586.25
               Mean episode length: 223.57
    Episode_Reward/reaching_object: 1.1953
    Episode_Reward/rotating_object: 118.0899
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.38s
                      Time elapsed: 00:20:57
                               ETA: 00:38:36

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 39828 steps/s (collection: 2.343s, learning 0.125s)
             Mean action noise std: 2.04
          Mean value_function loss: 79.9454
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.0059
                       Mean reward: 613.98
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.2228
    Episode_Reward/rotating_object: 117.6720
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.47s
                      Time elapsed: 00:20:59
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 39231 steps/s (collection: 2.379s, learning 0.127s)
             Mean action noise std: 2.04
          Mean value_function loss: 84.8983
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.0198
                       Mean reward: 604.54
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 118.0225
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.51s
                      Time elapsed: 00:21:02
                               ETA: 00:38:32

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 40015 steps/s (collection: 2.326s, learning 0.131s)
             Mean action noise std: 2.04
          Mean value_function loss: 91.6425
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.0407
                       Mean reward: 644.20
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.2437
    Episode_Reward/rotating_object: 119.0196
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.46s
                      Time elapsed: 00:21:04
                               ETA: 00:38:30

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 40723 steps/s (collection: 2.294s, learning 0.120s)
             Mean action noise std: 2.04
          Mean value_function loss: 83.3582
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.0581
                       Mean reward: 558.37
               Mean episode length: 219.15
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 121.5756
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.41s
                      Time elapsed: 00:21:07
                               ETA: 00:38:27

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 41174 steps/s (collection: 2.267s, learning 0.121s)
             Mean action noise std: 2.04
          Mean value_function loss: 88.4170
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.0752
                       Mean reward: 603.44
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 118.9103
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.39s
                      Time elapsed: 00:21:09
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 40864 steps/s (collection: 2.282s, learning 0.124s)
             Mean action noise std: 2.05
          Mean value_function loss: 96.8894
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.0882
                       Mean reward: 590.09
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 115.4998
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.41s
                      Time elapsed: 00:21:11
                               ETA: 00:38:23

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 40668 steps/s (collection: 2.296s, learning 0.121s)
             Mean action noise std: 2.05
          Mean value_function loss: 100.7072
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.1006
                       Mean reward: 613.88
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 119.7190
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.42s
                      Time elapsed: 00:21:14
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 40999 steps/s (collection: 2.271s, learning 0.126s)
             Mean action noise std: 2.05
          Mean value_function loss: 90.1912
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.1161
                       Mean reward: 629.98
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 1.2169
    Episode_Reward/rotating_object: 118.1222
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.40s
                      Time elapsed: 00:21:16
                               ETA: 00:38:18

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 40586 steps/s (collection: 2.301s, learning 0.121s)
             Mean action noise std: 2.05
          Mean value_function loss: 98.0945
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 55.1261
                       Mean reward: 591.54
               Mean episode length: 224.93
    Episode_Reward/reaching_object: 1.1957
    Episode_Reward/rotating_object: 117.1952
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.42s
                      Time elapsed: 00:21:19
                               ETA: 00:38:16

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 40895 steps/s (collection: 2.277s, learning 0.127s)
             Mean action noise std: 2.05
          Mean value_function loss: 86.3225
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 55.1313
                       Mean reward: 602.70
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 124.1176
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.40s
                      Time elapsed: 00:21:21
                               ETA: 00:38:13

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 40609 steps/s (collection: 2.298s, learning 0.123s)
             Mean action noise std: 2.05
          Mean value_function loss: 78.7539
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.1472
                       Mean reward: 632.09
               Mean episode length: 239.50
    Episode_Reward/reaching_object: 1.2487
    Episode_Reward/rotating_object: 121.7422
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.42s
                      Time elapsed: 00:21:23
                               ETA: 00:38:11

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 40631 steps/s (collection: 2.298s, learning 0.121s)
             Mean action noise std: 2.05
          Mean value_function loss: 93.1050
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.1674
                       Mean reward: 581.79
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 121.5129
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.42s
                      Time elapsed: 00:21:26
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 40731 steps/s (collection: 2.292s, learning 0.121s)
             Mean action noise std: 2.05
          Mean value_function loss: 86.5965
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.1839
                       Mean reward: 613.65
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 1.2363
    Episode_Reward/rotating_object: 121.4798
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.41s
                      Time elapsed: 00:21:28
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 40477 steps/s (collection: 2.295s, learning 0.133s)
             Mean action noise std: 2.06
          Mean value_function loss: 90.4012
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.2030
                       Mean reward: 615.13
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.2160
    Episode_Reward/rotating_object: 118.0714
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.43s
                      Time elapsed: 00:21:31
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 41047 steps/s (collection: 2.276s, learning 0.119s)
             Mean action noise std: 2.06
          Mean value_function loss: 80.8844
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.2309
                       Mean reward: 639.80
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 121.8252
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.39s
                      Time elapsed: 00:21:33
                               ETA: 00:38:02

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 40919 steps/s (collection: 2.281s, learning 0.122s)
             Mean action noise std: 2.06
          Mean value_function loss: 83.3408
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.2489
                       Mean reward: 605.02
               Mean episode length: 234.86
    Episode_Reward/reaching_object: 1.2460
    Episode_Reward/rotating_object: 122.5886
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.40s
                      Time elapsed: 00:21:35
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 40903 steps/s (collection: 2.281s, learning 0.122s)
             Mean action noise std: 2.06
          Mean value_function loss: 85.8117
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.2643
                       Mean reward: 607.09
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 119.4337
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.40s
                      Time elapsed: 00:21:38
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 40632 steps/s (collection: 2.300s, learning 0.120s)
             Mean action noise std: 2.06
          Mean value_function loss: 94.1745
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.2845
                       Mean reward: 612.04
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 118.8638
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.42s
                      Time elapsed: 00:21:40
                               ETA: 00:37:55

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 42724 steps/s (collection: 2.190s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 89.2160
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.3071
                       Mean reward: 620.83
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 118.4911
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.30s
                      Time elapsed: 00:21:43
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 42935 steps/s (collection: 2.179s, learning 0.111s)
             Mean action noise std: 2.07
          Mean value_function loss: 82.3905
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.3269
                       Mean reward: 623.85
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 120.9581
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.29s
                      Time elapsed: 00:21:45
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 42875 steps/s (collection: 2.181s, learning 0.112s)
             Mean action noise std: 2.07
          Mean value_function loss: 84.6522
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.3501
                       Mean reward: 600.54
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 120.9607
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.29s
                      Time elapsed: 00:21:47
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 43038 steps/s (collection: 2.173s, learning 0.111s)
             Mean action noise std: 2.07
          Mean value_function loss: 92.8101
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.3713
                       Mean reward: 604.36
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.2173
    Episode_Reward/rotating_object: 119.2072
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.28s
                      Time elapsed: 00:21:49
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 42752 steps/s (collection: 2.188s, learning 0.111s)
             Mean action noise std: 2.07
          Mean value_function loss: 88.1788
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.3972
                       Mean reward: 572.63
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 1.2148
    Episode_Reward/rotating_object: 116.4379
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.30s
                      Time elapsed: 00:21:52
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 42715 steps/s (collection: 2.186s, learning 0.115s)
             Mean action noise std: 2.08
          Mean value_function loss: 80.2113
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.4273
                       Mean reward: 588.16
               Mean episode length: 224.69
    Episode_Reward/reaching_object: 1.2159
    Episode_Reward/rotating_object: 118.5587
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.30s
                      Time elapsed: 00:21:54
                               ETA: 00:37:40

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 42086 steps/s (collection: 2.222s, learning 0.114s)
             Mean action noise std: 2.08
          Mean value_function loss: 91.8868
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.4513
                       Mean reward: 584.30
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 114.9527
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.34s
                      Time elapsed: 00:21:56
                               ETA: 00:37:37

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 42217 steps/s (collection: 2.217s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 77.0195
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 55.4654
                       Mean reward: 644.42
               Mean episode length: 238.12
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 124.8636
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.33s
                      Time elapsed: 00:21:59
                               ETA: 00:37:35

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 41592 steps/s (collection: 2.240s, learning 0.123s)
             Mean action noise std: 2.08
          Mean value_function loss: 93.6948
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.4802
                       Mean reward: 610.05
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 1.2437
    Episode_Reward/rotating_object: 121.8391
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.36s
                      Time elapsed: 00:22:01
                               ETA: 00:37:32

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 40866 steps/s (collection: 2.279s, learning 0.126s)
             Mean action noise std: 2.08
          Mean value_function loss: 89.7921
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.4964
                       Mean reward: 566.00
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 115.8462
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.41s
                      Time elapsed: 00:22:04
                               ETA: 00:37:30

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 41153 steps/s (collection: 2.266s, learning 0.122s)
             Mean action noise std: 2.08
          Mean value_function loss: 91.3313
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 55.5131
                       Mean reward: 664.69
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.2380
    Episode_Reward/rotating_object: 120.6258
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.39s
                      Time elapsed: 00:22:06
                               ETA: 00:37:27

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 40765 steps/s (collection: 2.289s, learning 0.122s)
             Mean action noise std: 2.08
          Mean value_function loss: 93.7735
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.5210
                       Mean reward: 617.92
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.2201
    Episode_Reward/rotating_object: 123.2862
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.41s
                      Time elapsed: 00:22:08
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 41089 steps/s (collection: 2.271s, learning 0.122s)
             Mean action noise std: 2.08
          Mean value_function loss: 85.0599
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.5377
                       Mean reward: 602.26
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 119.3220
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.39s
                      Time elapsed: 00:22:11
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 40897 steps/s (collection: 2.282s, learning 0.122s)
             Mean action noise std: 2.09
          Mean value_function loss: 84.1853
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 55.5629
                       Mean reward: 664.69
               Mean episode length: 242.46
    Episode_Reward/reaching_object: 1.2680
    Episode_Reward/rotating_object: 127.4451
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.40s
                      Time elapsed: 00:22:13
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 40815 steps/s (collection: 2.288s, learning 0.121s)
             Mean action noise std: 2.09
          Mean value_function loss: 86.8209
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.5943
                       Mean reward: 669.71
               Mean episode length: 242.67
    Episode_Reward/reaching_object: 1.2616
    Episode_Reward/rotating_object: 125.6693
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.41s
                      Time elapsed: 00:22:16
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 41167 steps/s (collection: 2.268s, learning 0.120s)
             Mean action noise std: 2.09
          Mean value_function loss: 81.1610
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.6152
                       Mean reward: 605.47
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 120.5361
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.39s
                      Time elapsed: 00:22:18
                               ETA: 00:37:16

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 41225 steps/s (collection: 2.262s, learning 0.122s)
             Mean action noise std: 2.09
          Mean value_function loss: 85.6677
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.6416
                       Mean reward: 648.29
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 1.2185
    Episode_Reward/rotating_object: 120.6561
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.38s
                      Time elapsed: 00:22:20
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 41319 steps/s (collection: 2.258s, learning 0.121s)
             Mean action noise std: 2.10
          Mean value_function loss: 82.4040
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.6739
                       Mean reward: 631.93
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 1.2594
    Episode_Reward/rotating_object: 124.4721
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.38s
                      Time elapsed: 00:22:23
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 40902 steps/s (collection: 2.280s, learning 0.124s)
             Mean action noise std: 2.10
          Mean value_function loss: 86.6674
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.7019
                       Mean reward: 629.74
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 121.3966
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.40s
                      Time elapsed: 00:22:25
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 40038 steps/s (collection: 2.328s, learning 0.127s)
             Mean action noise std: 2.10
          Mean value_function loss: 93.3475
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 55.7228
                       Mean reward: 597.45
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.2296
    Episode_Reward/rotating_object: 123.6067
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.46s
                      Time elapsed: 00:22:28
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 39741 steps/s (collection: 2.348s, learning 0.126s)
             Mean action noise std: 2.10
          Mean value_function loss: 93.5468
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.7509
                       Mean reward: 647.14
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 1.2363
    Episode_Reward/rotating_object: 123.4303
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.47s
                      Time elapsed: 00:22:30
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 39904 steps/s (collection: 2.338s, learning 0.126s)
             Mean action noise std: 2.11
          Mean value_function loss: 98.2677
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.7808
                       Mean reward: 602.81
               Mean episode length: 226.46
    Episode_Reward/reaching_object: 1.2277
    Episode_Reward/rotating_object: 121.7714
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.46s
                      Time elapsed: 00:22:32
                               ETA: 00:37:02

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 40180 steps/s (collection: 2.320s, learning 0.126s)
             Mean action noise std: 2.11
          Mean value_function loss: 97.1281
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 55.7991
                       Mean reward: 641.90
               Mean episode length: 231.39
    Episode_Reward/reaching_object: 1.2496
    Episode_Reward/rotating_object: 123.1095
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.45s
                      Time elapsed: 00:22:35
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 40006 steps/s (collection: 2.343s, learning 0.114s)
             Mean action noise std: 2.11
          Mean value_function loss: 92.5110
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.8103
                       Mean reward: 583.80
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 124.8902
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.46s
                      Time elapsed: 00:22:37
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 42841 steps/s (collection: 2.184s, learning 0.111s)
             Mean action noise std: 2.11
          Mean value_function loss: 87.9863
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 55.8341
                       Mean reward: 657.72
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.2603
    Episode_Reward/rotating_object: 124.8806
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.29s
                      Time elapsed: 00:22:40
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 42419 steps/s (collection: 2.206s, learning 0.111s)
             Mean action noise std: 2.11
          Mean value_function loss: 100.0357
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.8647
                       Mean reward: 644.56
               Mean episode length: 229.82
    Episode_Reward/reaching_object: 1.2193
    Episode_Reward/rotating_object: 120.8065
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.32s
                      Time elapsed: 00:22:42
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 42263 steps/s (collection: 2.211s, learning 0.115s)
             Mean action noise std: 2.11
          Mean value_function loss: 81.8252
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.8898
                       Mean reward: 664.22
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 126.1499
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.33s
                      Time elapsed: 00:22:44
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 42481 steps/s (collection: 2.200s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 80.8881
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 55.9118
                       Mean reward: 657.24
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 1.2493
    Episode_Reward/rotating_object: 123.6356
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.31s
                      Time elapsed: 00:22:47
                               ETA: 00:36:47

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 42003 steps/s (collection: 2.226s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 82.1469
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.9357
                       Mean reward: 605.10
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 120.7265
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.34s
                      Time elapsed: 00:22:49
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 41985 steps/s (collection: 2.221s, learning 0.121s)
             Mean action noise std: 2.12
          Mean value_function loss: 76.6161
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.9589
                       Mean reward: 630.39
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 1.2585
    Episode_Reward/rotating_object: 125.9028
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.34s
                      Time elapsed: 00:22:51
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 40432 steps/s (collection: 2.307s, learning 0.124s)
             Mean action noise std: 2.12
          Mean value_function loss: 96.5372
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.9814
                       Mean reward: 604.63
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.2582
    Episode_Reward/rotating_object: 123.8523
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.43s
                      Time elapsed: 00:22:54
                               ETA: 00:36:40

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 40444 steps/s (collection: 2.301s, learning 0.130s)
             Mean action noise std: 2.13
          Mean value_function loss: 84.8467
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.0085
                       Mean reward: 627.48
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 1.2514
    Episode_Reward/rotating_object: 122.6866
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.43s
                      Time elapsed: 00:22:56
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 40539 steps/s (collection: 2.304s, learning 0.121s)
             Mean action noise std: 2.13
          Mean value_function loss: 92.3003
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.0372
                       Mean reward: 639.84
               Mean episode length: 236.01
    Episode_Reward/reaching_object: 1.2541
    Episode_Reward/rotating_object: 126.0726
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.42s
                      Time elapsed: 00:22:59
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 40557 steps/s (collection: 2.301s, learning 0.123s)
             Mean action noise std: 2.13
          Mean value_function loss: 78.6994
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.0616
                       Mean reward: 596.19
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 123.0841
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.42s
                      Time elapsed: 00:23:01
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 40767 steps/s (collection: 2.285s, learning 0.126s)
             Mean action noise std: 2.13
          Mean value_function loss: 86.5468
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.0847
                       Mean reward: 624.84
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.2695
    Episode_Reward/rotating_object: 126.3203
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.41s
                      Time elapsed: 00:23:03
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 40156 steps/s (collection: 2.325s, learning 0.123s)
             Mean action noise std: 2.13
          Mean value_function loss: 91.8421
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.1040
                       Mean reward: 612.24
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.2639
    Episode_Reward/rotating_object: 127.8771
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.45s
                      Time elapsed: 00:23:06
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 40892 steps/s (collection: 2.277s, learning 0.127s)
             Mean action noise std: 2.14
          Mean value_function loss: 80.9892
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.1231
                       Mean reward: 628.93
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 1.2609
    Episode_Reward/rotating_object: 124.9095
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.40s
                      Time elapsed: 00:23:08
                               ETA: 00:36:26

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 40835 steps/s (collection: 2.276s, learning 0.131s)
             Mean action noise std: 2.14
          Mean value_function loss: 88.9070
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.1387
                       Mean reward: 595.36
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 122.4981
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.41s
                      Time elapsed: 00:23:11
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 40958 steps/s (collection: 2.278s, learning 0.123s)
             Mean action noise std: 2.14
          Mean value_function loss: 69.4970
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.1641
                       Mean reward: 625.09
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 1.2567
    Episode_Reward/rotating_object: 125.3763
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.40s
                      Time elapsed: 00:23:13
                               ETA: 00:36:22

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 40750 steps/s (collection: 2.300s, learning 0.112s)
             Mean action noise std: 2.14
          Mean value_function loss: 80.6438
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.1848
                       Mean reward: 629.14
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.2591
    Episode_Reward/rotating_object: 126.4910
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.41s
                      Time elapsed: 00:23:15
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 42863 steps/s (collection: 2.182s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 88.4856
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.2063
                       Mean reward: 648.48
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 1.2660
    Episode_Reward/rotating_object: 128.3160
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.29s
                      Time elapsed: 00:23:18
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 43061 steps/s (collection: 2.172s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 82.3597
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.2281
                       Mean reward: 624.82
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 1.2671
    Episode_Reward/rotating_object: 128.2403
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.28s
                      Time elapsed: 00:23:20
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 42860 steps/s (collection: 2.179s, learning 0.115s)
             Mean action noise std: 2.15
          Mean value_function loss: 91.9279
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 56.2545
                       Mean reward: 601.65
               Mean episode length: 222.24
    Episode_Reward/reaching_object: 1.2331
    Episode_Reward/rotating_object: 124.9646
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.29s
                      Time elapsed: 00:23:22
                               ETA: 00:36:12

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 42304 steps/s (collection: 2.213s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 74.0545
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.2869
                       Mean reward: 593.29
               Mean episode length: 232.64
    Episode_Reward/reaching_object: 1.2625
    Episode_Reward/rotating_object: 124.1634
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.32s
                      Time elapsed: 00:23:25
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 42520 steps/s (collection: 2.200s, learning 0.112s)
             Mean action noise std: 2.15
          Mean value_function loss: 71.5552
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.3159
                       Mean reward: 653.24
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.2643
    Episode_Reward/rotating_object: 127.9747
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.31s
                      Time elapsed: 00:23:27
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 41981 steps/s (collection: 2.218s, learning 0.123s)
             Mean action noise std: 2.16
          Mean value_function loss: 73.6013
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.3505
                       Mean reward: 644.73
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.2595
    Episode_Reward/rotating_object: 126.9101
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.34s
                      Time elapsed: 00:23:29
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 41674 steps/s (collection: 2.246s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 78.3040
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.3775
                       Mean reward: 657.26
               Mean episode length: 236.63
    Episode_Reward/reaching_object: 1.2664
    Episode_Reward/rotating_object: 129.3128
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.36s
                      Time elapsed: 00:23:32
                               ETA: 00:36:02

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 42446 steps/s (collection: 2.201s, learning 0.115s)
             Mean action noise std: 2.16
          Mean value_function loss: 78.0510
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 56.3987
                       Mean reward: 631.34
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 1.2327
    Episode_Reward/rotating_object: 125.0059
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.32s
                      Time elapsed: 00:23:34
                               ETA: 00:35:59

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 42200 steps/s (collection: 2.219s, learning 0.111s)
             Mean action noise std: 2.16
          Mean value_function loss: 68.2859
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.4200
                       Mean reward: 644.30
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.2667
    Episode_Reward/rotating_object: 127.9440
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.33s
                      Time elapsed: 00:23:36
                               ETA: 00:35:57

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 42494 steps/s (collection: 2.199s, learning 0.114s)
             Mean action noise std: 2.16
          Mean value_function loss: 65.3122
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.4512
                       Mean reward: 644.26
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 1.2592
    Episode_Reward/rotating_object: 127.5324
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.31s
                      Time elapsed: 00:23:39
                               ETA: 00:35:54

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 42845 steps/s (collection: 2.183s, learning 0.112s)
             Mean action noise std: 2.17
          Mean value_function loss: 75.1515
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.4751
                       Mean reward: 642.53
               Mean episode length: 239.80
    Episode_Reward/reaching_object: 1.2600
    Episode_Reward/rotating_object: 128.9880
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.29s
                      Time elapsed: 00:23:41
                               ETA: 00:35:52

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 42053 steps/s (collection: 2.223s, learning 0.114s)
             Mean action noise std: 2.17
          Mean value_function loss: 81.4098
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.5060
                       Mean reward: 620.73
               Mean episode length: 228.90
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 126.9892
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.34s
                      Time elapsed: 00:23:43
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 41870 steps/s (collection: 2.223s, learning 0.125s)
             Mean action noise std: 2.17
          Mean value_function loss: 80.7974
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.5335
                       Mean reward: 627.81
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.2151
    Episode_Reward/rotating_object: 124.4316
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.35s
                      Time elapsed: 00:23:46
                               ETA: 00:35:47

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 40446 steps/s (collection: 2.289s, learning 0.142s)
             Mean action noise std: 2.17
          Mean value_function loss: 86.5163
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.5672
                       Mean reward: 605.35
               Mean episode length: 225.04
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 128.5672
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.43s
                      Time elapsed: 00:23:48
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 40814 steps/s (collection: 2.288s, learning 0.120s)
             Mean action noise std: 2.18
          Mean value_function loss: 75.2925
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.5916
                       Mean reward: 644.28
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 128.8334
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.41s
                      Time elapsed: 00:23:50
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 40771 steps/s (collection: 2.291s, learning 0.121s)
             Mean action noise std: 2.18
          Mean value_function loss: 71.2080
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 56.6203
                       Mean reward: 655.17
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.2767
    Episode_Reward/rotating_object: 131.7065
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.41s
                      Time elapsed: 00:23:53
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 41028 steps/s (collection: 2.273s, learning 0.123s)
             Mean action noise std: 2.18
          Mean value_function loss: 75.0476
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 56.6582
                       Mean reward: 657.97
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.2583
    Episode_Reward/rotating_object: 126.8499
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.40s
                      Time elapsed: 00:23:55
                               ETA: 00:35:38

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 41113 steps/s (collection: 2.264s, learning 0.127s)
             Mean action noise std: 2.18
          Mean value_function loss: 77.3949
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.6954
                       Mean reward: 654.43
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 1.2130
    Episode_Reward/rotating_object: 125.6273
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.39s
                      Time elapsed: 00:23:58
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 41074 steps/s (collection: 2.273s, learning 0.120s)
             Mean action noise std: 2.19
          Mean value_function loss: 75.1340
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.7222
                       Mean reward: 693.67
               Mean episode length: 240.68
    Episode_Reward/reaching_object: 1.2555
    Episode_Reward/rotating_object: 132.6649
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.39s
                      Time elapsed: 00:24:00
                               ETA: 00:35:33

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 40978 steps/s (collection: 2.278s, learning 0.121s)
             Mean action noise std: 2.19
          Mean value_function loss: 73.4858
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 56.7585
                       Mean reward: 644.48
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.2700
    Episode_Reward/rotating_object: 131.5352
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.40s
                      Time elapsed: 00:24:02
                               ETA: 00:35:31

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 41016 steps/s (collection: 2.276s, learning 0.121s)
             Mean action noise std: 2.19
          Mean value_function loss: 74.8533
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.7882
                       Mean reward: 633.46
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.2451
    Episode_Reward/rotating_object: 129.8995
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.40s
                      Time elapsed: 00:24:05
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 41557 steps/s (collection: 2.244s, learning 0.121s)
             Mean action noise std: 2.19
          Mean value_function loss: 64.9800
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.8037
                       Mean reward: 648.82
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.2665
    Episode_Reward/rotating_object: 134.8726
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.37s
                      Time elapsed: 00:24:07
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 41337 steps/s (collection: 2.258s, learning 0.120s)
             Mean action noise std: 2.20
          Mean value_function loss: 73.5601
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.8196
                       Mean reward: 650.30
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.2678
    Episode_Reward/rotating_object: 130.5592
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.38s
                      Time elapsed: 00:24:10
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 40317 steps/s (collection: 2.312s, learning 0.127s)
             Mean action noise std: 2.20
          Mean value_function loss: 79.7968
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.8512
                       Mean reward: 647.05
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 128.6372
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.44s
                      Time elapsed: 00:24:12
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 40182 steps/s (collection: 2.317s, learning 0.129s)
             Mean action noise std: 2.20
          Mean value_function loss: 82.1522
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.8811
                       Mean reward: 680.38
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.2659
    Episode_Reward/rotating_object: 132.8810
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.45s
                      Time elapsed: 00:24:14
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 39655 steps/s (collection: 2.353s, learning 0.126s)
             Mean action noise std: 2.20
          Mean value_function loss: 86.8369
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.9143
                       Mean reward: 627.74
               Mean episode length: 227.26
    Episode_Reward/reaching_object: 1.2322
    Episode_Reward/rotating_object: 126.4892
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.48s
                      Time elapsed: 00:24:17
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 41550 steps/s (collection: 2.252s, learning 0.114s)
             Mean action noise std: 2.21
          Mean value_function loss: 70.9033
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.9425
                       Mean reward: 649.67
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.2682
    Episode_Reward/rotating_object: 130.3523
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.37s
                      Time elapsed: 00:24:19
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 42572 steps/s (collection: 2.198s, learning 0.111s)
             Mean action noise std: 2.21
          Mean value_function loss: 82.8990
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.9583
                       Mean reward: 646.84
               Mean episode length: 231.61
    Episode_Reward/reaching_object: 1.2581
    Episode_Reward/rotating_object: 129.7756
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.31s
                      Time elapsed: 00:24:22
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 41348 steps/s (collection: 2.255s, learning 0.122s)
             Mean action noise std: 2.21
          Mean value_function loss: 82.9566
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.9814
                       Mean reward: 687.94
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 1.2605
    Episode_Reward/rotating_object: 129.8182
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.38s
                      Time elapsed: 00:24:24
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 40583 steps/s (collection: 2.300s, learning 0.122s)
             Mean action noise std: 2.21
          Mean value_function loss: 77.3543
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 57.0130
                       Mean reward: 659.19
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.2753
    Episode_Reward/rotating_object: 131.8867
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.42s
                      Time elapsed: 00:24:26
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 41171 steps/s (collection: 2.266s, learning 0.122s)
             Mean action noise std: 2.22
          Mean value_function loss: 77.5709
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.0406
                       Mean reward: 660.69
               Mean episode length: 236.25
    Episode_Reward/reaching_object: 1.2592
    Episode_Reward/rotating_object: 131.1363
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.39s
                      Time elapsed: 00:24:29
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 41160 steps/s (collection: 2.266s, learning 0.122s)
             Mean action noise std: 2.22
          Mean value_function loss: 80.0108
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.0709
                       Mean reward: 629.65
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.2410
    Episode_Reward/rotating_object: 129.2716
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.39s
                      Time elapsed: 00:24:31
                               ETA: 00:35:02

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 40859 steps/s (collection: 2.284s, learning 0.122s)
             Mean action noise std: 2.22
          Mean value_function loss: 79.6620
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 57.1004
                       Mean reward: 617.00
               Mean episode length: 223.99
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 127.3941
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.41s
                      Time elapsed: 00:24:34
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 40901 steps/s (collection: 2.283s, learning 0.120s)
             Mean action noise std: 2.22
          Mean value_function loss: 77.6123
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.1360
                       Mean reward: 669.19
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 1.2775
    Episode_Reward/rotating_object: 133.4310
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.40s
                      Time elapsed: 00:24:36
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 40253 steps/s (collection: 2.309s, learning 0.133s)
             Mean action noise std: 2.23
          Mean value_function loss: 92.3781
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.1715
                       Mean reward: 652.39
               Mean episode length: 232.93
    Episode_Reward/reaching_object: 1.2531
    Episode_Reward/rotating_object: 128.0473
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.44s
                      Time elapsed: 00:24:38
                               ETA: 00:34:55

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 41046 steps/s (collection: 2.273s, learning 0.122s)
             Mean action noise std: 2.23
          Mean value_function loss: 81.0046
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.1971
                       Mean reward: 610.70
               Mean episode length: 224.16
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 123.9811
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.39s
                      Time elapsed: 00:24:41
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 40765 steps/s (collection: 2.292s, learning 0.119s)
             Mean action noise std: 2.23
          Mean value_function loss: 76.7869
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.2287
                       Mean reward: 649.30
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 127.1613
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.41s
                      Time elapsed: 00:24:43
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 40808 steps/s (collection: 2.288s, learning 0.121s)
             Mean action noise std: 2.23
          Mean value_function loss: 82.6824
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.2628
                       Mean reward: 588.56
               Mean episode length: 227.52
    Episode_Reward/reaching_object: 1.2715
    Episode_Reward/rotating_object: 127.2444
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.41s
                      Time elapsed: 00:24:46
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 40997 steps/s (collection: 2.278s, learning 0.120s)
             Mean action noise std: 2.24
          Mean value_function loss: 95.9706
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 57.2910
                       Mean reward: 677.70
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.2334
    Episode_Reward/rotating_object: 124.7570
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.40s
                      Time elapsed: 00:24:48
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 40487 steps/s (collection: 2.299s, learning 0.129s)
             Mean action noise std: 2.24
          Mean value_function loss: 76.1343
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 57.3214
                       Mean reward: 682.96
               Mean episode length: 241.05
    Episode_Reward/reaching_object: 1.2680
    Episode_Reward/rotating_object: 129.8857
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.43s
                      Time elapsed: 00:24:51
                               ETA: 00:34:44

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 40424 steps/s (collection: 2.306s, learning 0.126s)
             Mean action noise std: 2.24
          Mean value_function loss: 76.7035
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.3519
                       Mean reward: 647.05
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.2687
    Episode_Reward/rotating_object: 131.4283
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.43s
                      Time elapsed: 00:24:53
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 39534 steps/s (collection: 2.360s, learning 0.126s)
             Mean action noise std: 2.25
          Mean value_function loss: 82.6982
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.3844
                       Mean reward: 674.56
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 1.2601
    Episode_Reward/rotating_object: 129.5067
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.49s
                      Time elapsed: 00:24:55
                               ETA: 00:34:39

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 40647 steps/s (collection: 2.305s, learning 0.114s)
             Mean action noise std: 2.25
          Mean value_function loss: 77.0573
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.4199
                       Mean reward: 654.50
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 128.5457
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.42s
                      Time elapsed: 00:24:58
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 42999 steps/s (collection: 2.175s, learning 0.112s)
             Mean action noise std: 2.25
          Mean value_function loss: 81.2374
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.4464
                       Mean reward: 688.53
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.2714
    Episode_Reward/rotating_object: 132.0148
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.29s
                      Time elapsed: 00:25:00
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 42962 steps/s (collection: 2.176s, learning 0.112s)
             Mean action noise std: 2.25
          Mean value_function loss: 85.1546
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.4666
                       Mean reward: 683.20
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 1.2587
    Episode_Reward/rotating_object: 132.8764
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.29s
                      Time elapsed: 00:25:02
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 43023 steps/s (collection: 2.171s, learning 0.114s)
             Mean action noise std: 2.26
          Mean value_function loss: 70.8584
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.4986
                       Mean reward: 689.19
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.2833
    Episode_Reward/rotating_object: 134.1883
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.28s
                      Time elapsed: 00:25:05
                               ETA: 00:34:29

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 43150 steps/s (collection: 2.163s, learning 0.115s)
             Mean action noise std: 2.26
          Mean value_function loss: 83.3132
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.5328
                       Mean reward: 637.23
               Mean episode length: 227.62
    Episode_Reward/reaching_object: 1.2602
    Episode_Reward/rotating_object: 133.1669
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.28s
                      Time elapsed: 00:25:07
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 41586 steps/s (collection: 2.242s, learning 0.122s)
             Mean action noise std: 2.26
          Mean value_function loss: 86.6598
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 57.5607
                       Mean reward: 624.87
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 1.2459
    Episode_Reward/rotating_object: 128.0436
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.36s
                      Time elapsed: 00:25:09
                               ETA: 00:34:24

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 40933 steps/s (collection: 2.278s, learning 0.123s)
             Mean action noise std: 2.27
          Mean value_function loss: 78.1600
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 57.5990
                       Mean reward: 637.30
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.2676
    Episode_Reward/rotating_object: 132.0342
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.40s
                      Time elapsed: 00:25:12
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 40902 steps/s (collection: 2.274s, learning 0.130s)
             Mean action noise std: 2.27
          Mean value_function loss: 85.6291
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 57.6391
                       Mean reward: 658.86
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 130.4482
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.40s
                      Time elapsed: 00:25:14
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 40632 steps/s (collection: 2.285s, learning 0.134s)
             Mean action noise std: 2.27
          Mean value_function loss: 81.3889
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.6868
                       Mean reward: 617.68
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 128.6749
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.42s
                      Time elapsed: 00:25:17
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 40791 steps/s (collection: 2.273s, learning 0.137s)
             Mean action noise std: 2.28
          Mean value_function loss: 78.7521
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.7285
                       Mean reward: 669.24
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.2544
    Episode_Reward/rotating_object: 131.2892
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.41s
                      Time elapsed: 00:25:19
                               ETA: 00:34:15

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 40783 steps/s (collection: 2.275s, learning 0.136s)
             Mean action noise std: 2.28
          Mean value_function loss: 78.8408
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.7676
                       Mean reward: 655.60
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 129.0057
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.41s
                      Time elapsed: 00:25:21
                               ETA: 00:34:13

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 40729 steps/s (collection: 2.280s, learning 0.134s)
             Mean action noise std: 2.29
          Mean value_function loss: 92.6199
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 57.8070
                       Mean reward: 642.08
               Mean episode length: 223.56
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 129.4783
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.41s
                      Time elapsed: 00:25:24
                               ETA: 00:34:10

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 41255 steps/s (collection: 2.255s, learning 0.128s)
             Mean action noise std: 2.29
          Mean value_function loss: 82.2695
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.8425
                       Mean reward: 634.18
               Mean episode length: 231.78
    Episode_Reward/reaching_object: 1.2416
    Episode_Reward/rotating_object: 130.2253
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.38s
                      Time elapsed: 00:25:26
                               ETA: 00:34:08

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 41279 steps/s (collection: 2.262s, learning 0.119s)
             Mean action noise std: 2.29
          Mean value_function loss: 82.8698
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.8680
                       Mean reward: 649.63
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.2314
    Episode_Reward/rotating_object: 129.6553
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.38s
                      Time elapsed: 00:25:29
                               ETA: 00:34:05

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 41202 steps/s (collection: 2.266s, learning 0.120s)
             Mean action noise std: 2.29
          Mean value_function loss: 81.2021
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.8921
                       Mean reward: 616.90
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 1.2159
    Episode_Reward/rotating_object: 126.4333
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.39s
                      Time elapsed: 00:25:31
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 41412 steps/s (collection: 2.253s, learning 0.121s)
             Mean action noise std: 2.30
          Mean value_function loss: 74.8341
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.9216
                       Mean reward: 670.27
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 127.9497
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.37s
                      Time elapsed: 00:25:33
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 41225 steps/s (collection: 2.266s, learning 0.119s)
             Mean action noise std: 2.30
          Mean value_function loss: 69.6212
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.9538
                       Mean reward: 621.80
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.2372
    Episode_Reward/rotating_object: 127.2375
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.38s
                      Time elapsed: 00:25:36
                               ETA: 00:33:58

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 41129 steps/s (collection: 2.270s, learning 0.121s)
             Mean action noise std: 2.30
          Mean value_function loss: 80.0613
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.9832
                       Mean reward: 638.32
               Mean episode length: 231.36
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 129.7144
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.39s
                      Time elapsed: 00:25:38
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 40836 steps/s (collection: 2.281s, learning 0.126s)
             Mean action noise std: 2.31
          Mean value_function loss: 83.2688
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.0239
                       Mean reward: 647.38
               Mean episode length: 234.72
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 128.6384
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.41s
                      Time elapsed: 00:25:41
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 40318 steps/s (collection: 2.309s, learning 0.129s)
             Mean action noise std: 2.31
          Mean value_function loss: 72.3812
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.0646
                       Mean reward: 679.27
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 131.9591
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.44s
                      Time elapsed: 00:25:43
                               ETA: 00:33:51

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 40076 steps/s (collection: 2.334s, learning 0.119s)
             Mean action noise std: 2.31
          Mean value_function loss: 86.7294
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.0939
                       Mean reward: 683.10
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.2218
    Episode_Reward/rotating_object: 126.5785
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.45s
                      Time elapsed: 00:25:45
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 40492 steps/s (collection: 2.302s, learning 0.126s)
             Mean action noise std: 2.31
          Mean value_function loss: 87.4787
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.1235
                       Mean reward: 616.03
               Mean episode length: 227.66
    Episode_Reward/reaching_object: 1.2195
    Episode_Reward/rotating_object: 128.8161
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.43s
                      Time elapsed: 00:25:48
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 40150 steps/s (collection: 2.317s, learning 0.131s)
             Mean action noise std: 2.32
          Mean value_function loss: 93.9106
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.1498
                       Mean reward: 657.64
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.2161
    Episode_Reward/rotating_object: 125.6406
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.45s
                      Time elapsed: 00:25:50
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 40389 steps/s (collection: 2.319s, learning 0.115s)
             Mean action noise std: 2.32
          Mean value_function loss: 89.1573
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.1915
                       Mean reward: 599.40
               Mean episode length: 223.58
    Episode_Reward/reaching_object: 1.2251
    Episode_Reward/rotating_object: 128.0432
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.43s
                      Time elapsed: 00:25:53
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 40599 steps/s (collection: 2.288s, learning 0.133s)
             Mean action noise std: 2.33
          Mean value_function loss: 75.5573
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.2349
                       Mean reward: 675.54
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 1.2537
    Episode_Reward/rotating_object: 131.8515
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.42s
                      Time elapsed: 00:25:55
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 41069 steps/s (collection: 2.264s, learning 0.129s)
             Mean action noise std: 2.33
          Mean value_function loss: 94.4551
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.2617
                       Mean reward: 664.13
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 1.2202
    Episode_Reward/rotating_object: 132.3427
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.39s
                      Time elapsed: 00:25:58
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 40561 steps/s (collection: 2.304s, learning 0.119s)
             Mean action noise std: 2.33
          Mean value_function loss: 74.5746
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.2782
                       Mean reward: 688.46
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 1.2729
    Episode_Reward/rotating_object: 135.2889
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.42s
                      Time elapsed: 00:26:00
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 41305 steps/s (collection: 2.253s, learning 0.127s)
             Mean action noise std: 2.33
          Mean value_function loss: 69.7975
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.2953
                       Mean reward: 665.88
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.2445
    Episode_Reward/rotating_object: 130.5477
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.38s
                      Time elapsed: 00:26:02
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 41171 steps/s (collection: 2.264s, learning 0.124s)
             Mean action noise std: 2.33
          Mean value_function loss: 73.4114
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.3149
                       Mean reward: 665.66
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 130.4472
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.39s
                      Time elapsed: 00:26:05
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 40677 steps/s (collection: 2.295s, learning 0.122s)
             Mean action noise std: 2.33
          Mean value_function loss: 86.9201
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 58.3324
                       Mean reward: 647.56
               Mean episode length: 227.27
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 131.1896
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.42s
                      Time elapsed: 00:26:07
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 40773 steps/s (collection: 2.278s, learning 0.133s)
             Mean action noise std: 2.34
          Mean value_function loss: 85.8805
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.3566
                       Mean reward: 638.25
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.2173
    Episode_Reward/rotating_object: 130.4322
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.41s
                      Time elapsed: 00:26:10
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 41187 steps/s (collection: 2.265s, learning 0.122s)
             Mean action noise std: 2.34
          Mean value_function loss: 75.4932
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.3843
                       Mean reward: 685.16
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 133.5163
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.39s
                      Time elapsed: 00:26:12
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 41265 steps/s (collection: 2.261s, learning 0.121s)
             Mean action noise std: 2.34
          Mean value_function loss: 79.8559
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 58.4109
                       Mean reward: 691.61
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 1.2351
    Episode_Reward/rotating_object: 130.3147
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.38s
                      Time elapsed: 00:26:14
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 41800 steps/s (collection: 2.232s, learning 0.120s)
             Mean action noise std: 2.35
          Mean value_function loss: 87.8385
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 58.4487
                       Mean reward: 655.17
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 132.7811
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.35s
                      Time elapsed: 00:26:17
                               ETA: 00:33:18

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 41068 steps/s (collection: 2.271s, learning 0.123s)
             Mean action noise std: 2.35
          Mean value_function loss: 85.4228
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.4830
                       Mean reward: 640.35
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 130.5862
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.39s
                      Time elapsed: 00:26:19
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 41246 steps/s (collection: 2.263s, learning 0.120s)
             Mean action noise std: 2.35
          Mean value_function loss: 92.0242
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 58.5265
                       Mean reward: 673.05
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 127.4023
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.38s
                      Time elapsed: 00:26:21
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 41272 steps/s (collection: 2.263s, learning 0.119s)
             Mean action noise std: 2.36
          Mean value_function loss: 91.2936
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 58.5729
                       Mean reward: 638.87
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 130.1459
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.38s
                      Time elapsed: 00:26:24
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 41669 steps/s (collection: 2.233s, learning 0.126s)
             Mean action noise std: 2.36
          Mean value_function loss: 86.9485
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.6135
                       Mean reward: 694.74
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 131.4619
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.36s
                      Time elapsed: 00:26:26
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 40563 steps/s (collection: 2.297s, learning 0.126s)
             Mean action noise std: 2.36
          Mean value_function loss: 92.8680
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.6416
                       Mean reward: 599.84
               Mean episode length: 221.51
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 124.6705
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 2.42s
                      Time elapsed: 00:26:29
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 40243 steps/s (collection: 2.317s, learning 0.126s)
             Mean action noise std: 2.37
          Mean value_function loss: 86.6659
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.6763
                       Mean reward: 689.00
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.2384
    Episode_Reward/rotating_object: 129.7751
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 2.44s
                      Time elapsed: 00:26:31
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 40066 steps/s (collection: 2.326s, learning 0.127s)
             Mean action noise std: 2.37
          Mean value_function loss: 72.4408
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.7078
                       Mean reward: 669.42
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.2336
    Episode_Reward/rotating_object: 130.9799
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 2.45s
                      Time elapsed: 00:26:34
                               ETA: 00:33:02

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 40316 steps/s (collection: 2.314s, learning 0.124s)
             Mean action noise std: 2.37
          Mean value_function loss: 81.3795
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.7289
                       Mean reward: 626.42
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 1.2287
    Episode_Reward/rotating_object: 129.5309
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 2.44s
                      Time elapsed: 00:26:36
                               ETA: 00:33:00

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 43269 steps/s (collection: 2.161s, learning 0.111s)
             Mean action noise std: 2.38
          Mean value_function loss: 75.5238
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 58.7652
                       Mean reward: 659.20
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 130.4950
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 2.27s
                      Time elapsed: 00:26:38
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 42959 steps/s (collection: 2.166s, learning 0.122s)
             Mean action noise std: 2.38
          Mean value_function loss: 71.9525
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 58.8057
                       Mean reward: 680.89
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.2564
    Episode_Reward/rotating_object: 133.0205
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 2.29s
                      Time elapsed: 00:26:41
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 42681 steps/s (collection: 2.189s, learning 0.114s)
             Mean action noise std: 2.38
          Mean value_function loss: 86.1960
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.8441
                       Mean reward: 651.76
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.2581
    Episode_Reward/rotating_object: 131.7222
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 2.30s
                      Time elapsed: 00:26:43
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 42068 steps/s (collection: 2.220s, learning 0.117s)
             Mean action noise std: 2.39
          Mean value_function loss: 86.8009
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 58.8749
                       Mean reward: 676.01
               Mean episode length: 232.51
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 132.4508
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 2.34s
                      Time elapsed: 00:26:45
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 42731 steps/s (collection: 2.188s, learning 0.112s)
             Mean action noise std: 2.39
          Mean value_function loss: 85.2879
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.9052
                       Mean reward: 646.40
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.2495
    Episode_Reward/rotating_object: 130.8499
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 2.30s
                      Time elapsed: 00:26:47
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 42068 steps/s (collection: 2.223s, learning 0.113s)
             Mean action noise std: 2.39
          Mean value_function loss: 78.1024
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.9525
                       Mean reward: 669.12
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 128.4704
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 2.34s
                      Time elapsed: 00:26:50
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 41829 steps/s (collection: 2.225s, learning 0.125s)
             Mean action noise std: 2.40
          Mean value_function loss: 75.2091
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.9952
                       Mean reward: 667.64
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.2505
    Episode_Reward/rotating_object: 133.1717
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.35s
                      Time elapsed: 00:26:52
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 40163 steps/s (collection: 2.326s, learning 0.121s)
             Mean action noise std: 2.40
          Mean value_function loss: 101.3367
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.0282
                       Mean reward: 707.32
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.2356
    Episode_Reward/rotating_object: 133.6810
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.45s
                      Time elapsed: 00:26:55
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 40758 steps/s (collection: 2.290s, learning 0.122s)
             Mean action noise std: 2.40
          Mean value_function loss: 83.5635
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 59.0600
                       Mean reward: 661.57
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.2466
    Episode_Reward/rotating_object: 131.2283
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.41s
                      Time elapsed: 00:26:57
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 40697 steps/s (collection: 2.296s, learning 0.120s)
             Mean action noise std: 2.40
          Mean value_function loss: 92.2163
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.0800
                       Mean reward: 631.62
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.2208
    Episode_Reward/rotating_object: 124.2249
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.42s
                      Time elapsed: 00:26:59
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 39266 steps/s (collection: 2.370s, learning 0.134s)
             Mean action noise std: 2.41
          Mean value_function loss: 93.3747
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.0975
                       Mean reward: 681.48
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 132.6581
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.50s
                      Time elapsed: 00:27:02
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 40631 steps/s (collection: 2.285s, learning 0.134s)
             Mean action noise std: 2.41
          Mean value_function loss: 78.5603
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.1174
                       Mean reward: 653.39
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 1.2665
    Episode_Reward/rotating_object: 132.8221
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.42s
                      Time elapsed: 00:27:04
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 41166 steps/s (collection: 2.267s, learning 0.121s)
             Mean action noise std: 2.41
          Mean value_function loss: 87.1184
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.1442
                       Mean reward: 662.89
               Mean episode length: 232.08
    Episode_Reward/reaching_object: 1.2566
    Episode_Reward/rotating_object: 129.1225
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.39s
                      Time elapsed: 00:27:07
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 40460 steps/s (collection: 2.307s, learning 0.123s)
             Mean action noise std: 2.41
          Mean value_function loss: 86.2612
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.1754
                       Mean reward: 667.74
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 131.1131
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.43s
                      Time elapsed: 00:27:09
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 41102 steps/s (collection: 2.269s, learning 0.123s)
             Mean action noise std: 2.42
          Mean value_function loss: 91.8450
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.2103
                       Mean reward: 652.65
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 1.2559
    Episode_Reward/rotating_object: 133.4673
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.39s
                      Time elapsed: 00:27:12
                               ETA: 00:32:24

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 40722 steps/s (collection: 2.289s, learning 0.125s)
             Mean action noise std: 2.42
          Mean value_function loss: 80.9465
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.2430
                       Mean reward: 667.94
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.2634
    Episode_Reward/rotating_object: 133.7346
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.41s
                      Time elapsed: 00:27:14
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 40450 steps/s (collection: 2.304s, learning 0.126s)
             Mean action noise std: 2.43
          Mean value_function loss: 92.4753
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.2740
                       Mean reward: 650.01
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.2724
    Episode_Reward/rotating_object: 132.3979
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.43s
                      Time elapsed: 00:27:16
                               ETA: 00:32:19

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 42468 steps/s (collection: 2.202s, learning 0.113s)
             Mean action noise std: 2.43
          Mean value_function loss: 88.9027
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.3084
                       Mean reward: 630.04
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 1.2639
    Episode_Reward/rotating_object: 132.6007
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.31s
                      Time elapsed: 00:27:19
                               ETA: 00:32:17

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 42050 steps/s (collection: 2.215s, learning 0.122s)
             Mean action noise std: 2.43
          Mean value_function loss: 83.8841
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 59.3497
                       Mean reward: 651.27
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 1.2604
    Episode_Reward/rotating_object: 130.5374
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.34s
                      Time elapsed: 00:27:21
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 40377 steps/s (collection: 2.316s, learning 0.119s)
             Mean action noise std: 2.44
          Mean value_function loss: 81.5852
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 59.3842
                       Mean reward: 628.37
               Mean episode length: 225.67
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 132.0798
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.43s
                      Time elapsed: 00:27:23
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 41305 steps/s (collection: 2.261s, learning 0.119s)
             Mean action noise std: 2.44
          Mean value_function loss: 87.0781
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.4183
                       Mean reward: 639.02
               Mean episode length: 226.93
    Episode_Reward/reaching_object: 1.2526
    Episode_Reward/rotating_object: 131.1182
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.38s
                      Time elapsed: 00:27:26
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 41542 steps/s (collection: 2.246s, learning 0.121s)
             Mean action noise std: 2.44
          Mean value_function loss: 77.8735
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.4516
                       Mean reward: 616.49
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 1.2263
    Episode_Reward/rotating_object: 126.8843
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.37s
                      Time elapsed: 00:27:28
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 41370 steps/s (collection: 2.255s, learning 0.122s)
             Mean action noise std: 2.45
          Mean value_function loss: 98.4488
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.4843
                       Mean reward: 652.93
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 1.2491
    Episode_Reward/rotating_object: 130.4743
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.38s
                      Time elapsed: 00:27:31
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 41299 steps/s (collection: 2.260s, learning 0.121s)
             Mean action noise std: 2.45
          Mean value_function loss: 76.6613
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.5133
                       Mean reward: 702.45
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.2619
    Episode_Reward/rotating_object: 132.1380
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.38s
                      Time elapsed: 00:27:33
                               ETA: 00:32:02

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 40520 steps/s (collection: 2.305s, learning 0.121s)
             Mean action noise std: 2.45
          Mean value_function loss: 83.9286
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.5453
                       Mean reward: 681.55
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.2731
    Episode_Reward/rotating_object: 134.1680
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.43s
                      Time elapsed: 00:27:35
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 41240 steps/s (collection: 2.263s, learning 0.121s)
             Mean action noise std: 2.45
          Mean value_function loss: 91.2183
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.5816
                       Mean reward: 683.61
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 129.3886
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.38s
                      Time elapsed: 00:27:38
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 40963 steps/s (collection: 2.274s, learning 0.126s)
             Mean action noise std: 2.46
          Mean value_function loss: 84.7743
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.6175
                       Mean reward: 657.89
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 127.7513
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.40s
                      Time elapsed: 00:27:40
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 40336 steps/s (collection: 2.296s, learning 0.141s)
             Mean action noise std: 2.46
          Mean value_function loss: 94.7360
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.6460
                       Mean reward: 708.21
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 131.4569
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.44s
                      Time elapsed: 00:27:43
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 40801 steps/s (collection: 2.286s, learning 0.123s)
             Mean action noise std: 2.46
          Mean value_function loss: 88.7270
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.6795
                       Mean reward: 597.47
               Mean episode length: 221.55
    Episode_Reward/reaching_object: 1.2363
    Episode_Reward/rotating_object: 131.8759
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.41s
                      Time elapsed: 00:27:45
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 40904 steps/s (collection: 2.283s, learning 0.121s)
             Mean action noise std: 2.47
          Mean value_function loss: 89.9166
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.7123
                       Mean reward: 643.74
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.2227
    Episode_Reward/rotating_object: 128.8519
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.40s
                      Time elapsed: 00:27:47
                               ETA: 00:31:48

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 40334 steps/s (collection: 2.315s, learning 0.122s)
             Mean action noise std: 2.47
          Mean value_function loss: 88.2764
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 59.7376
                       Mean reward: 643.64
               Mean episode length: 228.44
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 130.2707
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.44s
                      Time elapsed: 00:27:50
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 41298 steps/s (collection: 2.261s, learning 0.119s)
             Mean action noise std: 2.47
          Mean value_function loss: 85.0178
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 59.7755
                       Mean reward: 653.80
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.2259
    Episode_Reward/rotating_object: 128.0372
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.38s
                      Time elapsed: 00:27:52
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 41295 steps/s (collection: 2.260s, learning 0.121s)
             Mean action noise std: 2.48
          Mean value_function loss: 78.7245
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.8153
                       Mean reward: 661.91
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 134.8508
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.38s
                      Time elapsed: 00:27:55
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 40702 steps/s (collection: 2.293s, learning 0.122s)
             Mean action noise std: 2.48
          Mean value_function loss: 90.5354
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 59.8414
                       Mean reward: 628.18
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 127.4171
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.42s
                      Time elapsed: 00:27:57
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 41091 steps/s (collection: 2.271s, learning 0.122s)
             Mean action noise std: 2.48
          Mean value_function loss: 87.4608
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.8703
                       Mean reward: 667.82
               Mean episode length: 231.21
    Episode_Reward/reaching_object: 1.2218
    Episode_Reward/rotating_object: 130.0614
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.39s
                      Time elapsed: 00:27:59
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 40935 steps/s (collection: 2.281s, learning 0.121s)
             Mean action noise std: 2.49
          Mean value_function loss: 70.9918
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.9077
                       Mean reward: 651.69
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.2416
    Episode_Reward/rotating_object: 132.9970
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.40s
                      Time elapsed: 00:28:02
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 42050 steps/s (collection: 2.227s, learning 0.111s)
             Mean action noise std: 2.49
          Mean value_function loss: 87.8492
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 59.9534
                       Mean reward: 640.07
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 1.2331
    Episode_Reward/rotating_object: 128.5724
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.34s
                      Time elapsed: 00:28:04
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 42901 steps/s (collection: 2.180s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 80.9573
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.9986
                       Mean reward: 692.83
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.2555
    Episode_Reward/rotating_object: 132.5379
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.29s
                      Time elapsed: 00:28:06
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 42752 steps/s (collection: 2.186s, learning 0.113s)
             Mean action noise std: 2.50
          Mean value_function loss: 94.7837
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.0382
                       Mean reward: 653.24
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 1.2115
    Episode_Reward/rotating_object: 125.5292
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.30s
                      Time elapsed: 00:28:09
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 42339 steps/s (collection: 2.211s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 91.7763
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.0660
                       Mean reward: 617.88
               Mean episode length: 213.62
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 131.0559
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.32s
                      Time elapsed: 00:28:11
                               ETA: 00:31:24

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 42384 steps/s (collection: 2.208s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 84.6411
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 60.0858
                       Mean reward: 637.86
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 127.4407
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.32s
                      Time elapsed: 00:28:13
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 42841 steps/s (collection: 2.183s, learning 0.111s)
             Mean action noise std: 2.51
          Mean value_function loss: 94.1636
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.1234
                       Mean reward: 669.37
               Mean episode length: 227.36
    Episode_Reward/reaching_object: 1.2099
    Episode_Reward/rotating_object: 125.5843
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.29s
                      Time elapsed: 00:28:16
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 41976 steps/s (collection: 2.228s, learning 0.114s)
             Mean action noise std: 2.51
          Mean value_function loss: 90.7342
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.1617
                       Mean reward: 653.54
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.2350
    Episode_Reward/rotating_object: 131.3236
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.34s
                      Time elapsed: 00:28:18
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 43532 steps/s (collection: 2.138s, learning 0.120s)
             Mean action noise std: 2.51
          Mean value_function loss: 94.6638
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 60.1847
                       Mean reward: 685.86
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 133.8243
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.26s
                      Time elapsed: 00:28:20
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 43428 steps/s (collection: 2.139s, learning 0.124s)
             Mean action noise std: 2.52
          Mean value_function loss: 90.4604
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.2108
                       Mean reward: 643.94
               Mean episode length: 226.59
    Episode_Reward/reaching_object: 1.2441
    Episode_Reward/rotating_object: 132.9138
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.26s
                      Time elapsed: 00:28:23
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 42806 steps/s (collection: 2.163s, learning 0.134s)
             Mean action noise std: 2.52
          Mean value_function loss: 112.3417
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.2431
                       Mean reward: 649.80
               Mean episode length: 227.09
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 127.9733
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.30s
                      Time elapsed: 00:28:25
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 42775 steps/s (collection: 2.180s, learning 0.118s)
             Mean action noise std: 2.52
          Mean value_function loss: 79.5912
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 60.2688
                       Mean reward: 677.54
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 1.2586
    Episode_Reward/rotating_object: 132.9920
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.30s
                      Time elapsed: 00:28:27
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 42583 steps/s (collection: 2.188s, learning 0.121s)
             Mean action noise std: 2.53
          Mean value_function loss: 77.0752
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.3083
                       Mean reward: 649.07
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 1.2537
    Episode_Reward/rotating_object: 131.3296
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.31s
                      Time elapsed: 00:28:29
                               ETA: 00:31:04

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 39869 steps/s (collection: 2.336s, learning 0.130s)
             Mean action noise std: 2.53
          Mean value_function loss: 77.6402
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.3514
                       Mean reward: 666.01
               Mean episode length: 238.97
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 130.8003
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.47s
                      Time elapsed: 00:28:32
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 40559 steps/s (collection: 2.300s, learning 0.124s)
             Mean action noise std: 2.54
          Mean value_function loss: 84.7537
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.3856
                       Mean reward: 695.70
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.2492
    Episode_Reward/rotating_object: 134.9327
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.42s
                      Time elapsed: 00:28:34
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 40793 steps/s (collection: 2.291s, learning 0.119s)
             Mean action noise std: 2.54
          Mean value_function loss: 78.2307
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.4182
                       Mean reward: 668.46
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.2493
    Episode_Reward/rotating_object: 135.0908
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.41s
                      Time elapsed: 00:28:37
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 41058 steps/s (collection: 2.275s, learning 0.119s)
             Mean action noise std: 2.54
          Mean value_function loss: 75.9248
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.4442
                       Mean reward: 680.07
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 1.2637
    Episode_Reward/rotating_object: 132.9966
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.39s
                      Time elapsed: 00:28:39
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 40751 steps/s (collection: 2.290s, learning 0.122s)
             Mean action noise std: 2.55
          Mean value_function loss: 90.7761
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 60.4757
                       Mean reward: 625.37
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 128.9188
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.41s
                      Time elapsed: 00:28:42
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 40552 steps/s (collection: 2.303s, learning 0.121s)
             Mean action noise std: 2.55
          Mean value_function loss: 90.9746
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.5192
                       Mean reward: 617.10
               Mean episode length: 225.43
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 129.9897
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.42s
                      Time elapsed: 00:28:44
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 40447 steps/s (collection: 2.300s, learning 0.130s)
             Mean action noise std: 2.55
          Mean value_function loss: 96.6021
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.5614
                       Mean reward: 619.41
               Mean episode length: 225.89
    Episode_Reward/reaching_object: 1.2287
    Episode_Reward/rotating_object: 125.9475
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.43s
                      Time elapsed: 00:28:46
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 40201 steps/s (collection: 2.312s, learning 0.133s)
             Mean action noise std: 2.56
          Mean value_function loss: 88.4735
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.5874
                       Mean reward: 672.78
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.2670
    Episode_Reward/rotating_object: 134.6805
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.45s
                      Time elapsed: 00:28:49
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 40572 steps/s (collection: 2.293s, learning 0.130s)
             Mean action noise std: 2.56
          Mean value_function loss: 82.3278
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.6075
                       Mean reward: 689.73
               Mean episode length: 240.87
    Episode_Reward/reaching_object: 1.2537
    Episode_Reward/rotating_object: 133.4837
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.42s
                      Time elapsed: 00:28:51
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 39842 steps/s (collection: 2.332s, learning 0.135s)
             Mean action noise std: 2.56
          Mean value_function loss: 81.9471
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 60.6209
                       Mean reward: 669.94
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.2327
    Episode_Reward/rotating_object: 130.1109
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.47s
                      Time elapsed: 00:28:54
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 40089 steps/s (collection: 2.316s, learning 0.136s)
             Mean action noise std: 2.56
          Mean value_function loss: 83.1380
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 60.6439
                       Mean reward: 635.05
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 1.2289
    Episode_Reward/rotating_object: 129.1573
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.45s
                      Time elapsed: 00:28:56
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 39969 steps/s (collection: 2.332s, learning 0.128s)
             Mean action noise std: 2.57
          Mean value_function loss: 70.4902
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.6822
                       Mean reward: 692.09
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 1.2657
    Episode_Reward/rotating_object: 134.5732
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.46s
                      Time elapsed: 00:28:59
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 39701 steps/s (collection: 2.337s, learning 0.139s)
             Mean action noise std: 2.57
          Mean value_function loss: 93.5716
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.7188
                       Mean reward: 643.93
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 1.2462
    Episode_Reward/rotating_object: 134.9673
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.48s
                      Time elapsed: 00:29:01
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 39232 steps/s (collection: 2.368s, learning 0.138s)
             Mean action noise std: 2.57
          Mean value_function loss: 70.7521
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.7511
                       Mean reward: 674.55
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.2329
    Episode_Reward/rotating_object: 133.1394
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.51s
                      Time elapsed: 00:29:04
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 38756 steps/s (collection: 2.396s, learning 0.141s)
             Mean action noise std: 2.58
          Mean value_function loss: 81.7559
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 60.7818
                       Mean reward: 657.59
               Mean episode length: 231.13
    Episode_Reward/reaching_object: 1.2526
    Episode_Reward/rotating_object: 129.8079
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.54s
                      Time elapsed: 00:29:06
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 39486 steps/s (collection: 2.367s, learning 0.122s)
             Mean action noise std: 2.58
          Mean value_function loss: 76.5145
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.8184
                       Mean reward: 656.94
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 131.5719
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.49s
                      Time elapsed: 00:29:09
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 40899 steps/s (collection: 2.282s, learning 0.122s)
             Mean action noise std: 2.58
          Mean value_function loss: 74.0588
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.8505
                       Mean reward: 713.72
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.2680
    Episode_Reward/rotating_object: 134.7733
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.40s
                      Time elapsed: 00:29:11
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 40866 steps/s (collection: 2.283s, learning 0.122s)
             Mean action noise std: 2.59
          Mean value_function loss: 72.3128
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 60.8715
                       Mean reward: 673.31
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.2565
    Episode_Reward/rotating_object: 134.0166
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.41s
                      Time elapsed: 00:29:13
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 40769 steps/s (collection: 2.286s, learning 0.126s)
             Mean action noise std: 2.59
          Mean value_function loss: 84.0679
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.8966
                       Mean reward: 657.48
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.2562
    Episode_Reward/rotating_object: 134.6313
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.41s
                      Time elapsed: 00:29:16
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 41353 steps/s (collection: 2.255s, learning 0.123s)
             Mean action noise std: 2.59
          Mean value_function loss: 76.0721
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.9330
                       Mean reward: 709.41
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.2459
    Episode_Reward/rotating_object: 133.0248
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.38s
                      Time elapsed: 00:29:18
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 40922 steps/s (collection: 2.279s, learning 0.123s)
             Mean action noise std: 2.60
          Mean value_function loss: 84.4608
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 60.9678
                       Mean reward: 669.21
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 135.0028
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.40s
                      Time elapsed: 00:29:21
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 41267 steps/s (collection: 2.260s, learning 0.122s)
             Mean action noise std: 2.60
          Mean value_function loss: 90.3036
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 61.0081
                       Mean reward: 660.36
               Mean episode length: 226.04
    Episode_Reward/reaching_object: 1.2315
    Episode_Reward/rotating_object: 134.4954
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.38s
                      Time elapsed: 00:29:23
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 40980 steps/s (collection: 2.276s, learning 0.123s)
             Mean action noise std: 2.60
          Mean value_function loss: 72.1792
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 61.0448
                       Mean reward: 690.22
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 135.2324
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.40s
                      Time elapsed: 00:29:25
                               ETA: 00:30:11

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 40947 steps/s (collection: 2.279s, learning 0.121s)
             Mean action noise std: 2.61
          Mean value_function loss: 73.4893
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 61.0699
                       Mean reward: 654.31
               Mean episode length: 227.26
    Episode_Reward/reaching_object: 1.2280
    Episode_Reward/rotating_object: 132.1763
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.40s
                      Time elapsed: 00:29:28
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 40652 steps/s (collection: 2.281s, learning 0.137s)
             Mean action noise std: 2.61
          Mean value_function loss: 81.4735
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.0971
                       Mean reward: 684.35
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.2432
    Episode_Reward/rotating_object: 134.0872
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.42s
                      Time elapsed: 00:29:30
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 40820 steps/s (collection: 2.283s, learning 0.125s)
             Mean action noise std: 2.61
          Mean value_function loss: 74.8838
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 61.1342
                       Mean reward: 678.55
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 1.2420
    Episode_Reward/rotating_object: 136.4337
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.41s
                      Time elapsed: 00:29:33
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 40926 steps/s (collection: 2.278s, learning 0.123s)
             Mean action noise std: 2.62
          Mean value_function loss: 70.7722
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.1665
                       Mean reward: 673.71
               Mean episode length: 238.33
    Episode_Reward/reaching_object: 1.2448
    Episode_Reward/rotating_object: 132.1718
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.40s
                      Time elapsed: 00:29:35
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 40942 steps/s (collection: 2.281s, learning 0.120s)
             Mean action noise std: 2.62
          Mean value_function loss: 95.0955
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.2021
                       Mean reward: 648.08
               Mean episode length: 228.89
    Episode_Reward/reaching_object: 1.2309
    Episode_Reward/rotating_object: 131.3973
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.40s
                      Time elapsed: 00:29:37
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 40559 steps/s (collection: 2.298s, learning 0.126s)
             Mean action noise std: 2.62
          Mean value_function loss: 83.5506
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 61.2311
                       Mean reward: 643.05
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.2399
    Episode_Reward/rotating_object: 131.7575
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.42s
                      Time elapsed: 00:29:40
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 40577 steps/s (collection: 2.297s, learning 0.126s)
             Mean action noise std: 2.63
          Mean value_function loss: 83.1396
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.2573
                       Mean reward: 675.99
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.2435
    Episode_Reward/rotating_object: 132.4632
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.42s
                      Time elapsed: 00:29:42
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 40270 steps/s (collection: 2.316s, learning 0.125s)
             Mean action noise std: 2.63
          Mean value_function loss: 94.1588
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.2762
                       Mean reward: 681.94
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 1.2327
    Episode_Reward/rotating_object: 132.8508
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.44s
                      Time elapsed: 00:29:45
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 40567 steps/s (collection: 2.297s, learning 0.126s)
             Mean action noise std: 2.63
          Mean value_function loss: 74.6219
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 61.3029
                       Mean reward: 671.89
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.2428
    Episode_Reward/rotating_object: 134.1712
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.42s
                      Time elapsed: 00:29:47
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 40461 steps/s (collection: 2.302s, learning 0.127s)
             Mean action noise std: 2.63
          Mean value_function loss: 82.9635
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 61.3300
                       Mean reward: 707.22
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 133.9892
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.43s
                      Time elapsed: 00:29:50
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 40459 steps/s (collection: 2.302s, learning 0.128s)
             Mean action noise std: 2.64
          Mean value_function loss: 78.1356
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 61.3522
                       Mean reward: 697.80
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 132.7576
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.43s
                      Time elapsed: 00:29:52
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 42649 steps/s (collection: 2.178s, learning 0.127s)
             Mean action noise std: 2.64
          Mean value_function loss: 85.3573
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.3820
                       Mean reward: 681.64
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 134.6068
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.30s
                      Time elapsed: 00:29:54
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 41753 steps/s (collection: 2.232s, learning 0.123s)
             Mean action noise std: 2.64
          Mean value_function loss: 81.4566
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.4195
                       Mean reward: 653.06
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.2410
    Episode_Reward/rotating_object: 131.6310
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.35s
                      Time elapsed: 00:29:57
                               ETA: 00:29:40

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 41144 steps/s (collection: 2.254s, learning 0.136s)
             Mean action noise std: 2.65
          Mean value_function loss: 66.9214
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.4503
                       Mean reward: 692.42
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 1.2634
    Episode_Reward/rotating_object: 137.8887
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.39s
                      Time elapsed: 00:29:59
                               ETA: 00:29:38

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 40589 steps/s (collection: 2.303s, learning 0.119s)
             Mean action noise std: 2.65
          Mean value_function loss: 79.1126
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 61.4812
                       Mean reward: 635.62
               Mean episode length: 221.25
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 133.7226
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.42s
                      Time elapsed: 00:30:02
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 40661 steps/s (collection: 2.297s, learning 0.120s)
             Mean action noise std: 2.66
          Mean value_function loss: 75.6374
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 61.5213
                       Mean reward: 669.23
               Mean episode length: 230.76
    Episode_Reward/reaching_object: 1.2478
    Episode_Reward/rotating_object: 135.2263
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.42s
                      Time elapsed: 00:30:04
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 40863 steps/s (collection: 2.276s, learning 0.130s)
             Mean action noise std: 2.66
          Mean value_function loss: 72.7182
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 61.5638
                       Mean reward: 711.75
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 1.2634
    Episode_Reward/rotating_object: 139.2731
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.41s
                      Time elapsed: 00:30:06
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 40422 steps/s (collection: 2.311s, learning 0.121s)
             Mean action noise std: 2.66
          Mean value_function loss: 87.2467
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.5984
                       Mean reward: 682.27
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 1.2276
    Episode_Reward/rotating_object: 132.0376
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.43s
                      Time elapsed: 00:30:09
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 41398 steps/s (collection: 2.254s, learning 0.121s)
             Mean action noise std: 2.66
          Mean value_function loss: 83.4439
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.6176
                       Mean reward: 649.90
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.2536
    Episode_Reward/rotating_object: 133.2915
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.37s
                      Time elapsed: 00:30:11
                               ETA: 00:29:26

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 41186 steps/s (collection: 2.269s, learning 0.118s)
             Mean action noise std: 2.67
          Mean value_function loss: 82.6933
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 61.6365
                       Mean reward: 704.80
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.2556
    Episode_Reward/rotating_object: 135.6137
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.39s
                      Time elapsed: 00:30:14
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 41366 steps/s (collection: 2.256s, learning 0.120s)
             Mean action noise std: 2.67
          Mean value_function loss: 105.1338
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.6586
                       Mean reward: 655.24
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 1.2166
    Episode_Reward/rotating_object: 128.2404
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.38s
                      Time elapsed: 00:30:16
                               ETA: 00:29:21

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 41662 steps/s (collection: 2.239s, learning 0.121s)
             Mean action noise std: 2.67
          Mean value_function loss: 99.5926
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 61.6883
                       Mean reward: 639.41
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.2218
    Episode_Reward/rotating_object: 130.5491
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.36s
                      Time elapsed: 00:30:18
                               ETA: 00:29:19

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 41218 steps/s (collection: 2.266s, learning 0.119s)
             Mean action noise std: 2.67
          Mean value_function loss: 86.9697
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.7169
                       Mean reward: 680.80
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 133.8924
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.38s
                      Time elapsed: 00:30:21
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 40650 steps/s (collection: 2.297s, learning 0.122s)
             Mean action noise std: 2.68
          Mean value_function loss: 79.8720
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 61.7314
                       Mean reward: 679.60
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.2394
    Episode_Reward/rotating_object: 131.7658
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.42s
                      Time elapsed: 00:30:23
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 41424 steps/s (collection: 2.251s, learning 0.122s)
             Mean action noise std: 2.68
          Mean value_function loss: 73.1169
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 61.7648
                       Mean reward: 700.23
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.2444
    Episode_Reward/rotating_object: 133.4935
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.37s
                      Time elapsed: 00:30:25
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 40936 steps/s (collection: 2.275s, learning 0.127s)
             Mean action noise std: 2.68
          Mean value_function loss: 72.8883
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.7983
                       Mean reward: 673.15
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.2493
    Episode_Reward/rotating_object: 136.3354
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.40s
                      Time elapsed: 00:30:28
                               ETA: 00:29:09

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 40285 steps/s (collection: 2.313s, learning 0.127s)
             Mean action noise std: 2.69
          Mean value_function loss: 87.4880
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 61.8202
                       Mean reward: 645.44
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.2370
    Episode_Reward/rotating_object: 133.8985
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.44s
                      Time elapsed: 00:30:30
                               ETA: 00:29:07

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 40268 steps/s (collection: 2.315s, learning 0.126s)
             Mean action noise std: 2.69
          Mean value_function loss: 68.9302
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.8566
                       Mean reward: 625.35
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 1.2287
    Episode_Reward/rotating_object: 128.5265
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.44s
                      Time elapsed: 00:30:33
                               ETA: 00:29:05

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 40179 steps/s (collection: 2.321s, learning 0.126s)
             Mean action noise std: 2.69
          Mean value_function loss: 75.7864
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 61.8899
                       Mean reward: 619.90
               Mean episode length: 227.16
    Episode_Reward/reaching_object: 1.2473
    Episode_Reward/rotating_object: 133.7731
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.45s
                      Time elapsed: 00:30:35
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 41045 steps/s (collection: 2.281s, learning 0.114s)
             Mean action noise std: 2.70
          Mean value_function loss: 81.3677
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 61.9158
                       Mean reward: 649.80
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 128.4619
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.39s
                      Time elapsed: 00:30:38
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 43304 steps/s (collection: 2.158s, learning 0.112s)
             Mean action noise std: 2.70
          Mean value_function loss: 81.8070
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.9509
                       Mean reward: 693.73
               Mean episode length: 235.50
    Episode_Reward/reaching_object: 1.2234
    Episode_Reward/rotating_object: 131.6207
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.27s
                      Time elapsed: 00:30:40
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 42469 steps/s (collection: 2.202s, learning 0.113s)
             Mean action noise std: 2.70
          Mean value_function loss: 88.1704
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.9744
                       Mean reward: 723.11
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 135.8119
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.31s
                      Time elapsed: 00:30:42
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 41461 steps/s (collection: 2.250s, learning 0.121s)
             Mean action noise std: 2.71
          Mean value_function loss: 70.8041
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 61.9931
                       Mean reward: 681.05
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.2692
    Episode_Reward/rotating_object: 139.4763
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.37s
                      Time elapsed: 00:30:45
                               ETA: 00:28:53

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 41439 steps/s (collection: 2.253s, learning 0.119s)
             Mean action noise std: 2.71
          Mean value_function loss: 82.7601
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 62.0241
                       Mean reward: 677.74
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.2240
    Episode_Reward/rotating_object: 132.6475
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.37s
                      Time elapsed: 00:30:47
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 41055 steps/s (collection: 2.275s, learning 0.119s)
             Mean action noise std: 2.71
          Mean value_function loss: 71.3939
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.0513
                       Mean reward: 699.82
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 1.2580
    Episode_Reward/rotating_object: 136.4737
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.39s
                      Time elapsed: 00:30:49
                               ETA: 00:28:48

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 41470 steps/s (collection: 2.249s, learning 0.121s)
             Mean action noise std: 2.72
          Mean value_function loss: 90.8726
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.0826
                       Mean reward: 658.79
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.2531
    Episode_Reward/rotating_object: 133.6247
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.37s
                      Time elapsed: 00:30:52
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 41260 steps/s (collection: 2.261s, learning 0.122s)
             Mean action noise std: 2.72
          Mean value_function loss: 76.0572
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 62.1220
                       Mean reward: 690.31
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 137.1624
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.38s
                      Time elapsed: 00:30:54
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 41574 steps/s (collection: 2.243s, learning 0.122s)
             Mean action noise std: 2.72
          Mean value_function loss: 85.5881
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.1546
                       Mean reward: 632.33
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 131.6074
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.36s
                      Time elapsed: 00:30:56
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 41467 steps/s (collection: 2.251s, learning 0.120s)
             Mean action noise std: 2.73
          Mean value_function loss: 75.0597
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.1753
                       Mean reward: 683.90
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 133.7625
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.37s
                      Time elapsed: 00:30:59
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 41575 steps/s (collection: 2.245s, learning 0.120s)
             Mean action noise std: 2.73
          Mean value_function loss: 70.1954
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.1967
                       Mean reward: 671.78
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 132.4171
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.36s
                      Time elapsed: 00:31:01
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 41394 steps/s (collection: 2.257s, learning 0.118s)
             Mean action noise std: 2.73
          Mean value_function loss: 84.3265
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.2269
                       Mean reward: 687.30
               Mean episode length: 240.23
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 134.4498
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.37s
                      Time elapsed: 00:31:04
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 41546 steps/s (collection: 2.249s, learning 0.118s)
             Mean action noise std: 2.74
          Mean value_function loss: 91.7873
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 62.2577
                       Mean reward: 678.28
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 134.5455
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.37s
                      Time elapsed: 00:31:06
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 41688 steps/s (collection: 2.240s, learning 0.118s)
             Mean action noise std: 2.74
          Mean value_function loss: 71.3177
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 62.2818
                       Mean reward: 700.24
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 1.2570
    Episode_Reward/rotating_object: 136.0902
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.36s
                      Time elapsed: 00:31:08
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 41594 steps/s (collection: 2.244s, learning 0.120s)
             Mean action noise std: 2.74
          Mean value_function loss: 86.4667
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.3194
                       Mean reward: 685.84
               Mean episode length: 236.20
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 129.5128
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.36s
                      Time elapsed: 00:31:11
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 41522 steps/s (collection: 2.247s, learning 0.121s)
             Mean action noise std: 2.74
          Mean value_function loss: 82.0194
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.3460
                       Mean reward: 706.26
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 132.6781
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.37s
                      Time elapsed: 00:31:13
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 41148 steps/s (collection: 2.262s, learning 0.127s)
             Mean action noise std: 2.75
          Mean value_function loss: 73.4725
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.3667
                       Mean reward: 700.66
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 132.8440
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.39s
                      Time elapsed: 00:31:15
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 40584 steps/s (collection: 2.296s, learning 0.127s)
             Mean action noise std: 2.75
          Mean value_function loss: 88.0814
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 62.3967
                       Mean reward: 700.11
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 1.2466
    Episode_Reward/rotating_object: 138.9869
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.42s
                      Time elapsed: 00:31:18
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 40530 steps/s (collection: 2.306s, learning 0.119s)
             Mean action noise std: 2.75
          Mean value_function loss: 77.7390
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.4247
                       Mean reward: 687.85
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.2502
    Episode_Reward/rotating_object: 136.1044
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.43s
                      Time elapsed: 00:31:20
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 42174 steps/s (collection: 2.213s, learning 0.118s)
             Mean action noise std: 2.76
          Mean value_function loss: 92.1564
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.4505
                       Mean reward: 675.77
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 132.7823
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.33s
                      Time elapsed: 00:31:23
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 41900 steps/s (collection: 2.228s, learning 0.118s)
             Mean action noise std: 2.76
          Mean value_function loss: 87.5074
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 62.4791
                       Mean reward: 671.54
               Mean episode length: 234.90
    Episode_Reward/reaching_object: 1.2375
    Episode_Reward/rotating_object: 135.0864
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.35s
                      Time elapsed: 00:31:25
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 42388 steps/s (collection: 2.201s, learning 0.119s)
             Mean action noise std: 2.76
          Mean value_function loss: 80.8453
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.5087
                       Mean reward: 666.88
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.2478
    Episode_Reward/rotating_object: 131.6387
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.32s
                      Time elapsed: 00:31:27
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 42221 steps/s (collection: 2.210s, learning 0.118s)
             Mean action noise std: 2.77
          Mean value_function loss: 80.6947
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 62.5423
                       Mean reward: 671.55
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.2414
    Episode_Reward/rotating_object: 136.0347
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.33s
                      Time elapsed: 00:31:30
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 40943 steps/s (collection: 2.281s, learning 0.120s)
             Mean action noise std: 2.77
          Mean value_function loss: 86.1148
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 62.5716
                       Mean reward: 705.67
               Mean episode length: 240.38
    Episode_Reward/reaching_object: 1.2509
    Episode_Reward/rotating_object: 135.2672
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.40s
                      Time elapsed: 00:31:32
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 41371 steps/s (collection: 2.256s, learning 0.120s)
             Mean action noise std: 2.77
          Mean value_function loss: 73.0288
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 62.5891
                       Mean reward: 706.29
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 133.4955
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.38s
                      Time elapsed: 00:31:34
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 41262 steps/s (collection: 2.262s, learning 0.120s)
             Mean action noise std: 2.77
          Mean value_function loss: 98.0651
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.6092
                       Mean reward: 680.58
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.2187
    Episode_Reward/rotating_object: 130.5281
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.38s
                      Time elapsed: 00:31:37
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 41210 steps/s (collection: 2.265s, learning 0.121s)
             Mean action noise std: 2.78
          Mean value_function loss: 79.7020
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 62.6383
                       Mean reward: 663.30
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.2441
    Episode_Reward/rotating_object: 132.5135
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.39s
                      Time elapsed: 00:31:39
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 41671 steps/s (collection: 2.239s, learning 0.120s)
             Mean action noise std: 2.78
          Mean value_function loss: 74.6913
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.6623
                       Mean reward: 672.58
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 1.2419
    Episode_Reward/rotating_object: 131.8643
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.36s
                      Time elapsed: 00:31:41
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 41701 steps/s (collection: 2.236s, learning 0.122s)
             Mean action noise std: 2.78
          Mean value_function loss: 85.6008
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 62.6872
                       Mean reward: 665.12
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 132.4091
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.36s
                      Time elapsed: 00:31:44
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 41829 steps/s (collection: 2.231s, learning 0.119s)
             Mean action noise std: 2.79
          Mean value_function loss: 82.3019
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.7167
                       Mean reward: 679.34
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 1.2561
    Episode_Reward/rotating_object: 135.5255
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.35s
                      Time elapsed: 00:31:46
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 41740 steps/s (collection: 2.235s, learning 0.120s)
             Mean action noise std: 2.79
          Mean value_function loss: 90.2298
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.7474
                       Mean reward: 614.73
               Mean episode length: 222.41
    Episode_Reward/reaching_object: 1.2171
    Episode_Reward/rotating_object: 129.5929
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.36s
                      Time elapsed: 00:31:49
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 41705 steps/s (collection: 2.237s, learning 0.120s)
             Mean action noise std: 2.79
          Mean value_function loss: 66.3539
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 62.7842
                       Mean reward: 653.48
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 1.2307
    Episode_Reward/rotating_object: 129.9932
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.36s
                      Time elapsed: 00:31:51
                               ETA: 00:27:45

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 41363 steps/s (collection: 2.256s, learning 0.120s)
             Mean action noise std: 2.80
          Mean value_function loss: 71.1088
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.8072
                       Mean reward: 651.11
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 1.2522
    Episode_Reward/rotating_object: 135.7479
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.38s
                      Time elapsed: 00:31:53
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 41347 steps/s (collection: 2.254s, learning 0.124s)
             Mean action noise std: 2.80
          Mean value_function loss: 84.9597
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 62.8328
                       Mean reward: 689.55
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 1.2224
    Episode_Reward/rotating_object: 132.1300
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.38s
                      Time elapsed: 00:31:56
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 41921 steps/s (collection: 2.225s, learning 0.120s)
             Mean action noise std: 2.80
          Mean value_function loss: 60.0543
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.8722
                       Mean reward: 732.42
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 1.2697
    Episode_Reward/rotating_object: 140.4791
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.34s
                      Time elapsed: 00:31:58
                               ETA: 00:27:38

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 41689 steps/s (collection: 2.237s, learning 0.121s)
             Mean action noise std: 2.81
          Mean value_function loss: 68.8618
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 62.9040
                       Mean reward: 664.73
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 1.2513
    Episode_Reward/rotating_object: 136.5623
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.36s
                      Time elapsed: 00:32:00
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 41886 steps/s (collection: 2.228s, learning 0.119s)
             Mean action noise std: 2.81
          Mean value_function loss: 83.4712
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 62.9390
                       Mean reward: 648.39
               Mean episode length: 227.36
    Episode_Reward/reaching_object: 1.2167
    Episode_Reward/rotating_object: 132.8657
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.35s
                      Time elapsed: 00:32:03
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 40623 steps/s (collection: 2.294s, learning 0.126s)
             Mean action noise std: 2.82
          Mean value_function loss: 89.0581
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.9762
                       Mean reward: 709.03
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.2168
    Episode_Reward/rotating_object: 129.8157
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.42s
                      Time elapsed: 00:32:05
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 40763 steps/s (collection: 2.286s, learning 0.125s)
             Mean action noise std: 2.82
          Mean value_function loss: 78.5177
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 63.0057
                       Mean reward: 673.80
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 133.8178
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.41s
                      Time elapsed: 00:32:08
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 40593 steps/s (collection: 2.306s, learning 0.116s)
             Mean action noise std: 2.82
          Mean value_function loss: 71.1843
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.0434
                       Mean reward: 691.82
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.2520
    Episode_Reward/rotating_object: 138.0278
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.42s
                      Time elapsed: 00:32:10
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 43443 steps/s (collection: 2.151s, learning 0.111s)
             Mean action noise std: 2.83
          Mean value_function loss: 95.7110
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 63.0760
                       Mean reward: 654.99
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 1.2391
    Episode_Reward/rotating_object: 134.9595
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.26s
                      Time elapsed: 00:32:12
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 42977 steps/s (collection: 2.176s, learning 0.111s)
             Mean action noise std: 2.83
          Mean value_function loss: 86.0502
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.1038
                       Mean reward: 679.27
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.2351
    Episode_Reward/rotating_object: 132.7036
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.29s
                      Time elapsed: 00:32:14
                               ETA: 00:27:21

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 43319 steps/s (collection: 2.158s, learning 0.111s)
             Mean action noise std: 2.83
          Mean value_function loss: 85.7022
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 63.1360
                       Mean reward: 655.94
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 1.2223
    Episode_Reward/rotating_object: 132.9249
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.27s
                      Time elapsed: 00:32:17
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 42056 steps/s (collection: 2.223s, learning 0.114s)
             Mean action noise std: 2.84
          Mean value_function loss: 79.6155
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 63.1601
                       Mean reward: 720.34
               Mean episode length: 240.83
    Episode_Reward/reaching_object: 1.2314
    Episode_Reward/rotating_object: 135.3997
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.34s
                      Time elapsed: 00:32:19
                               ETA: 00:27:16

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 42637 steps/s (collection: 2.192s, learning 0.113s)
             Mean action noise std: 2.84
          Mean value_function loss: 82.1149
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.1786
                       Mean reward: 690.86
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.2428
    Episode_Reward/rotating_object: 135.3845
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.31s
                      Time elapsed: 00:32:21
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 42567 steps/s (collection: 2.195s, learning 0.114s)
             Mean action noise std: 2.84
          Mean value_function loss: 74.3551
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 63.1953
                       Mean reward: 674.43
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 1.2579
    Episode_Reward/rotating_object: 138.7850
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.31s
                      Time elapsed: 00:32:24
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 43032 steps/s (collection: 2.171s, learning 0.114s)
             Mean action noise std: 2.84
          Mean value_function loss: 101.3093
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.2161
                       Mean reward: 650.18
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 133.3916
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.28s
                      Time elapsed: 00:32:26
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 42443 steps/s (collection: 2.194s, learning 0.122s)
             Mean action noise std: 2.85
          Mean value_function loss: 81.3191
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 63.2417
                       Mean reward: 696.25
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 1.2678
    Episode_Reward/rotating_object: 138.5771
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.32s
                      Time elapsed: 00:32:28
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 42261 steps/s (collection: 2.206s, learning 0.120s)
             Mean action noise std: 2.85
          Mean value_function loss: 90.9907
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 63.2697
                       Mean reward: 693.23
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.2280
    Episode_Reward/rotating_object: 133.5446
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.33s
                      Time elapsed: 00:32:31
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 41682 steps/s (collection: 2.239s, learning 0.119s)
             Mean action noise std: 2.85
          Mean value_function loss: 75.1909
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 63.2997
                       Mean reward: 684.84
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 133.2255
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.36s
                      Time elapsed: 00:32:33
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 41281 steps/s (collection: 2.262s, learning 0.119s)
             Mean action noise std: 2.86
          Mean value_function loss: 90.6936
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 63.3371
                       Mean reward: 674.68
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.2104
    Episode_Reward/rotating_object: 131.0012
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.38s
                      Time elapsed: 00:32:35
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 41490 steps/s (collection: 2.249s, learning 0.120s)
             Mean action noise std: 2.86
          Mean value_function loss: 79.4934
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 63.3676
                       Mean reward: 679.72
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.2214
    Episode_Reward/rotating_object: 133.2785
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.37s
                      Time elapsed: 00:32:38
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 41548 steps/s (collection: 2.247s, learning 0.119s)
             Mean action noise std: 2.86
          Mean value_function loss: 75.4021
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.3940
                       Mean reward: 687.28
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.2505
    Episode_Reward/rotating_object: 134.9980
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.37s
                      Time elapsed: 00:32:40
                               ETA: 00:26:55

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 41653 steps/s (collection: 2.234s, learning 0.126s)
             Mean action noise std: 2.87
          Mean value_function loss: 83.6756
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 63.4216
                       Mean reward: 676.04
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 1.2294
    Episode_Reward/rotating_object: 134.4023
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.36s
                      Time elapsed: 00:32:42
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 41194 steps/s (collection: 2.266s, learning 0.121s)
             Mean action noise std: 2.87
          Mean value_function loss: 77.7516
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.4439
                       Mean reward: 699.02
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 1.2369
    Episode_Reward/rotating_object: 138.8330
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.39s
                      Time elapsed: 00:32:45
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 41420 steps/s (collection: 2.249s, learning 0.125s)
             Mean action noise std: 2.87
          Mean value_function loss: 72.5652
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.4722
                       Mean reward: 719.29
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 1.2641
    Episode_Reward/rotating_object: 137.7991
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.37s
                      Time elapsed: 00:32:47
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 41807 steps/s (collection: 2.228s, learning 0.123s)
             Mean action noise std: 2.88
          Mean value_function loss: 83.0587
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 63.5015
                       Mean reward: 694.40
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.2442
    Episode_Reward/rotating_object: 135.3765
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.35s
                      Time elapsed: 00:32:50
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 40577 steps/s (collection: 2.296s, learning 0.127s)
             Mean action noise std: 2.88
          Mean value_function loss: 91.0157
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.5317
                       Mean reward: 657.90
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.2423
    Episode_Reward/rotating_object: 133.8389
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.42s
                      Time elapsed: 00:32:52
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 40311 steps/s (collection: 2.313s, learning 0.126s)
             Mean action noise std: 2.88
          Mean value_function loss: 96.6598
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 63.5596
                       Mean reward: 720.11
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 133.2939
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.44s
                      Time elapsed: 00:32:54
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 40222 steps/s (collection: 2.317s, learning 0.127s)
             Mean action noise std: 2.88
          Mean value_function loss: 85.3854
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 63.5799
                       Mean reward: 673.65
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.2277
    Episode_Reward/rotating_object: 131.6565
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.44s
                      Time elapsed: 00:32:57
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 39154 steps/s (collection: 2.381s, learning 0.129s)
             Mean action noise std: 2.89
          Mean value_function loss: 86.9773
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.6007
                       Mean reward: 650.48
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 1.2257
    Episode_Reward/rotating_object: 133.4633
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.51s
                      Time elapsed: 00:32:59
                               ETA: 00:26:36

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 42208 steps/s (collection: 2.217s, learning 0.112s)
             Mean action noise std: 2.89
          Mean value_function loss: 91.3730
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 63.6326
                       Mean reward: 698.96
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.2370
    Episode_Reward/rotating_object: 136.9351
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.33s
                      Time elapsed: 00:33:02
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 43170 steps/s (collection: 2.165s, learning 0.112s)
             Mean action noise std: 2.90
          Mean value_function loss: 97.7358
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 63.6666
                       Mean reward: 647.89
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 132.8576
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.28s
                      Time elapsed: 00:33:04
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 42922 steps/s (collection: 2.177s, learning 0.113s)
             Mean action noise std: 2.90
          Mean value_function loss: 84.2402
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 63.7021
                       Mean reward: 681.00
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.2303
    Episode_Reward/rotating_object: 135.4926
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.29s
                      Time elapsed: 00:33:06
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 42693 steps/s (collection: 2.187s, learning 0.115s)
             Mean action noise std: 2.91
          Mean value_function loss: 90.5316
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 63.7416
                       Mean reward: 676.41
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 135.4976
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.30s
                      Time elapsed: 00:33:09
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 41998 steps/s (collection: 2.215s, learning 0.126s)
             Mean action noise std: 2.91
          Mean value_function loss: 73.0757
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 63.7736
                       Mean reward: 654.45
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 130.8618
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.34s
                      Time elapsed: 00:33:11
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 41458 steps/s (collection: 2.252s, learning 0.120s)
             Mean action noise std: 2.91
          Mean value_function loss: 75.8539
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 63.8039
                       Mean reward: 612.04
               Mean episode length: 225.13
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 132.9785
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.37s
                      Time elapsed: 00:33:13
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 41554 steps/s (collection: 2.246s, learning 0.119s)
             Mean action noise std: 2.92
          Mean value_function loss: 73.9101
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 63.8386
                       Mean reward: 676.86
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 138.3275
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.37s
                      Time elapsed: 00:33:16
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 41569 steps/s (collection: 2.242s, learning 0.122s)
             Mean action noise std: 2.92
          Mean value_function loss: 81.9437
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 63.8669
                       Mean reward: 643.24
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 131.0800
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.36s
                      Time elapsed: 00:33:18
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 41702 steps/s (collection: 2.235s, learning 0.123s)
             Mean action noise std: 2.92
          Mean value_function loss: 77.5880
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.9029
                       Mean reward: 679.39
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 134.4715
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.36s
                      Time elapsed: 00:33:20
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 41633 steps/s (collection: 2.239s, learning 0.122s)
             Mean action noise std: 2.93
          Mean value_function loss: 75.8237
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 63.9436
                       Mean reward: 605.54
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 129.6993
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.36s
                      Time elapsed: 00:33:23
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 41566 steps/s (collection: 2.244s, learning 0.121s)
             Mean action noise std: 2.93
          Mean value_function loss: 82.4431
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 63.9709
                       Mean reward: 670.74
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 133.4339
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.36s
                      Time elapsed: 00:33:25
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 40960 steps/s (collection: 2.277s, learning 0.123s)
             Mean action noise std: 2.93
          Mean value_function loss: 102.6409
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 63.9898
                       Mean reward: 674.48
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 132.1370
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.40s
                      Time elapsed: 00:33:28
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 41247 steps/s (collection: 2.262s, learning 0.122s)
             Mean action noise std: 2.94
          Mean value_function loss: 82.1320
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.0205
                       Mean reward: 662.10
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.2338
    Episode_Reward/rotating_object: 136.7026
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.38s
                      Time elapsed: 00:33:30
                               ETA: 00:26:04

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 40604 steps/s (collection: 2.297s, learning 0.124s)
             Mean action noise std: 2.94
          Mean value_function loss: 84.1066
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 64.0454
                       Mean reward: 676.68
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.2190
    Episode_Reward/rotating_object: 133.6438
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.42s
                      Time elapsed: 00:33:32
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 40405 steps/s (collection: 2.311s, learning 0.122s)
             Mean action noise std: 2.94
          Mean value_function loss: 83.7044
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.0684
                       Mean reward: 605.83
               Mean episode length: 218.93
    Episode_Reward/reaching_object: 1.1930
    Episode_Reward/rotating_object: 132.3042
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.43s
                      Time elapsed: 00:33:35
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 41863 steps/s (collection: 2.226s, learning 0.122s)
             Mean action noise std: 2.94
          Mean value_function loss: 81.9924
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.0898
                       Mean reward: 716.05
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 137.9883
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.35s
                      Time elapsed: 00:33:37
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 42031 steps/s (collection: 2.219s, learning 0.119s)
             Mean action noise std: 2.95
          Mean value_function loss: 86.3676
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 64.1099
                       Mean reward: 673.99
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 133.4302
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.34s
                      Time elapsed: 00:33:39
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 39751 steps/s (collection: 2.346s, learning 0.127s)
             Mean action noise std: 2.95
          Mean value_function loss: 70.4306
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.1459
                       Mean reward: 718.34
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 1.2324
    Episode_Reward/rotating_object: 136.9718
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.47s
                      Time elapsed: 00:33:42
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 42162 steps/s (collection: 2.209s, learning 0.123s)
             Mean action noise std: 2.96
          Mean value_function loss: 74.4151
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.1817
                       Mean reward: 682.14
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 1.2261
    Episode_Reward/rotating_object: 136.5005
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.33s
                      Time elapsed: 00:33:44
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 41730 steps/s (collection: 2.224s, learning 0.131s)
             Mean action noise std: 2.96
          Mean value_function loss: 88.0393
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 64.2036
                       Mean reward: 648.48
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 136.2218
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.36s
                      Time elapsed: 00:33:47
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 41749 steps/s (collection: 2.223s, learning 0.132s)
             Mean action noise std: 2.96
          Mean value_function loss: 76.3637
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.2277
                       Mean reward: 654.27
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.2314
    Episode_Reward/rotating_object: 134.9528
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.35s
                      Time elapsed: 00:33:49
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 43122 steps/s (collection: 2.145s, learning 0.134s)
             Mean action noise std: 2.96
          Mean value_function loss: 71.4987
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 64.2536
                       Mean reward: 609.17
               Mean episode length: 224.85
    Episode_Reward/reaching_object: 1.2215
    Episode_Reward/rotating_object: 130.4428
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.28s
                      Time elapsed: 00:33:51
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 43186 steps/s (collection: 2.163s, learning 0.113s)
             Mean action noise std: 2.97
          Mean value_function loss: 84.1738
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.2726
                       Mean reward: 696.90
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.2350
    Episode_Reward/rotating_object: 137.7537
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.28s
                      Time elapsed: 00:33:54
                               ETA: 00:25:40

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 41964 steps/s (collection: 2.207s, learning 0.136s)
             Mean action noise std: 2.97
          Mean value_function loss: 88.0565
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.2897
                       Mean reward: 724.32
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.2484
    Episode_Reward/rotating_object: 140.2708
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.34s
                      Time elapsed: 00:33:56
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 40695 steps/s (collection: 2.292s, learning 0.123s)
             Mean action noise std: 2.97
          Mean value_function loss: 90.8130
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 64.3018
                       Mean reward: 668.10
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.1916
    Episode_Reward/rotating_object: 131.0992
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.42s
                      Time elapsed: 00:33:58
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 41182 steps/s (collection: 2.262s, learning 0.125s)
             Mean action noise std: 2.97
          Mean value_function loss: 71.1798
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.3214
                       Mean reward: 650.05
               Mean episode length: 232.51
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 132.5237
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.39s
                      Time elapsed: 00:34:01
                               ETA: 00:25:33

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 40769 steps/s (collection: 2.288s, learning 0.124s)
             Mean action noise std: 2.98
          Mean value_function loss: 95.3406
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.3484
                       Mean reward: 680.51
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 1.2025
    Episode_Reward/rotating_object: 129.9568
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.41s
                      Time elapsed: 00:34:03
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 40014 steps/s (collection: 2.320s, learning 0.137s)
             Mean action noise std: 2.98
          Mean value_function loss: 79.5658
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.3670
                       Mean reward: 659.51
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 1.2335
    Episode_Reward/rotating_object: 134.1567
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.46s
                      Time elapsed: 00:34:06
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 40369 steps/s (collection: 2.307s, learning 0.128s)
             Mean action noise std: 2.98
          Mean value_function loss: 87.1858
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.3846
                       Mean reward: 691.19
               Mean episode length: 234.17
    Episode_Reward/reaching_object: 1.2295
    Episode_Reward/rotating_object: 135.7742
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.44s
                      Time elapsed: 00:34:08
                               ETA: 00:25:26

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 41243 steps/s (collection: 2.266s, learning 0.118s)
             Mean action noise std: 2.98
          Mean value_function loss: 76.6443
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 64.4108
                       Mean reward: 676.96
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 1.2432
    Episode_Reward/rotating_object: 139.4088
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.38s
                      Time elapsed: 00:34:10
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 42269 steps/s (collection: 2.209s, learning 0.117s)
             Mean action noise std: 2.99
          Mean value_function loss: 85.6596
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.4367
                       Mean reward: 701.01
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.2465
    Episode_Reward/rotating_object: 138.8486
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.33s
                      Time elapsed: 00:34:13
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 41178 steps/s (collection: 2.263s, learning 0.124s)
             Mean action noise std: 2.99
          Mean value_function loss: 67.2414
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.4597
                       Mean reward: 671.27
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 1.2394
    Episode_Reward/rotating_object: 135.2276
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.39s
                      Time elapsed: 00:34:15
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 42131 steps/s (collection: 2.213s, learning 0.121s)
             Mean action noise std: 2.99
          Mean value_function loss: 75.5146
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 64.4764
                       Mean reward: 649.97
               Mean episode length: 225.22
    Episode_Reward/reaching_object: 1.2267
    Episode_Reward/rotating_object: 134.3568
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.33s
                      Time elapsed: 00:34:17
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 42167 steps/s (collection: 2.207s, learning 0.125s)
             Mean action noise std: 3.00
          Mean value_function loss: 88.7530
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 64.4971
                       Mean reward: 715.92
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 137.1687
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.33s
                      Time elapsed: 00:34:20
                               ETA: 00:25:14

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 42318 steps/s (collection: 2.202s, learning 0.121s)
             Mean action noise std: 3.00
          Mean value_function loss: 75.9663
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 64.5300
                       Mean reward: 703.21
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 138.4277
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.32s
                      Time elapsed: 00:34:22
                               ETA: 00:25:12

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 42475 steps/s (collection: 2.196s, learning 0.119s)
             Mean action noise std: 3.00
          Mean value_function loss: 81.1123
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.5596
                       Mean reward: 665.74
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.2077
    Episode_Reward/rotating_object: 132.4062
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.31s
                      Time elapsed: 00:34:24
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 41092 steps/s (collection: 2.266s, learning 0.126s)
             Mean action noise std: 3.01
          Mean value_function loss: 86.5551
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 64.5949
                       Mean reward: 686.89
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.2374
    Episode_Reward/rotating_object: 137.4729
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.39s
                      Time elapsed: 00:34:27
                               ETA: 00:25:07

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 40861 steps/s (collection: 2.280s, learning 0.126s)
             Mean action noise std: 3.01
          Mean value_function loss: 85.7693
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 64.6325
                       Mean reward: 675.17
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 135.3333
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.41s
                      Time elapsed: 00:34:29
                               ETA: 00:25:05

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 40883 steps/s (collection: 2.278s, learning 0.126s)
             Mean action noise std: 3.02
          Mean value_function loss: 75.3377
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 64.6668
                       Mean reward: 674.59
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.2278
    Episode_Reward/rotating_object: 135.0468
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.40s
                      Time elapsed: 00:34:32
                               ETA: 00:25:02

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 39986 steps/s (collection: 2.331s, learning 0.127s)
             Mean action noise std: 3.02
          Mean value_function loss: 82.0328
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 64.6964
                       Mean reward: 698.92
               Mean episode length: 236.28
    Episode_Reward/reaching_object: 1.2355
    Episode_Reward/rotating_object: 138.7184
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.46s
                      Time elapsed: 00:34:34
                               ETA: 00:25:00

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 39780 steps/s (collection: 2.353s, learning 0.118s)
             Mean action noise std: 3.03
          Mean value_function loss: 80.5407
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 64.7370
                       Mean reward: 654.46
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 135.7546
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.47s
                      Time elapsed: 00:34:36
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 42814 steps/s (collection: 2.184s, learning 0.112s)
             Mean action noise std: 3.03
          Mean value_function loss: 66.4035
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 64.7796
                       Mean reward: 677.25
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 136.2173
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.30s
                      Time elapsed: 00:34:39
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 42709 steps/s (collection: 2.180s, learning 0.121s)
             Mean action noise std: 3.03
          Mean value_function loss: 77.6586
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.8074
                       Mean reward: 727.58
               Mean episode length: 246.92
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 139.2272
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.30s
                      Time elapsed: 00:34:41
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 42112 steps/s (collection: 2.207s, learning 0.128s)
             Mean action noise std: 3.03
          Mean value_function loss: 81.0247
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 64.8242
                       Mean reward: 696.63
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2384
    Episode_Reward/rotating_object: 137.8286
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.33s
                      Time elapsed: 00:34:43
                               ETA: 00:24:50

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 42072 steps/s (collection: 2.218s, learning 0.118s)
             Mean action noise std: 3.04
          Mean value_function loss: 79.2545
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.8509
                       Mean reward: 651.28
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.2121
    Episode_Reward/rotating_object: 133.5955
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.34s
                      Time elapsed: 00:34:46
                               ETA: 00:24:48

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 42019 steps/s (collection: 2.218s, learning 0.121s)
             Mean action noise std: 3.04
          Mean value_function loss: 85.1948
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.8839
                       Mean reward: 580.33
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 129.1613
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.34s
                      Time elapsed: 00:34:48
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 42258 steps/s (collection: 2.206s, learning 0.121s)
             Mean action noise std: 3.05
          Mean value_function loss: 74.3024
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.9119
                       Mean reward: 697.93
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 138.8115
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.33s
                      Time elapsed: 00:34:50
                               ETA: 00:24:43

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 42403 steps/s (collection: 2.197s, learning 0.122s)
             Mean action noise std: 3.05
          Mean value_function loss: 69.9060
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 64.9354
                       Mean reward: 661.82
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.2189
    Episode_Reward/rotating_object: 136.0123
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.32s
                      Time elapsed: 00:34:53
                               ETA: 00:24:41

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 41636 steps/s (collection: 2.233s, learning 0.128s)
             Mean action noise std: 3.05
          Mean value_function loss: 93.7748
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.9532
                       Mean reward: 671.23
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 1.2093
    Episode_Reward/rotating_object: 129.9562
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.36s
                      Time elapsed: 00:34:55
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 41657 steps/s (collection: 2.240s, learning 0.120s)
             Mean action noise std: 3.05
          Mean value_function loss: 86.7817
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 64.9727
                       Mean reward: 698.84
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 139.4152
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.36s
                      Time elapsed: 00:34:57
                               ETA: 00:24:36

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 40043 steps/s (collection: 2.326s, learning 0.129s)
             Mean action noise std: 3.06
          Mean value_function loss: 90.1541
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.0099
                       Mean reward: 706.80
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 132.5597
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.45s
                      Time elapsed: 00:35:00
                               ETA: 00:24:34

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 42471 steps/s (collection: 2.201s, learning 0.114s)
             Mean action noise std: 3.06
          Mean value_function loss: 63.1616
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 65.0395
                       Mean reward: 698.35
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.2309
    Episode_Reward/rotating_object: 136.2599
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.31s
                      Time elapsed: 00:35:02
                               ETA: 00:24:31

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 42255 steps/s (collection: 2.206s, learning 0.120s)
             Mean action noise std: 3.07
          Mean value_function loss: 69.3400
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.0661
                       Mean reward: 669.14
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 134.7025
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.33s
                      Time elapsed: 00:35:05
                               ETA: 00:24:29

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 42491 steps/s (collection: 2.195s, learning 0.119s)
             Mean action noise std: 3.07
          Mean value_function loss: 84.6728
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.0917
                       Mean reward: 720.58
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.2352
    Episode_Reward/rotating_object: 137.8227
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.31s
                      Time elapsed: 00:35:07
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 42346 steps/s (collection: 2.201s, learning 0.121s)
             Mean action noise std: 3.07
          Mean value_function loss: 87.9497
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 65.1251
                       Mean reward: 702.20
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 1.2390
    Episode_Reward/rotating_object: 137.2025
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.32s
                      Time elapsed: 00:35:09
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 43098 steps/s (collection: 2.162s, learning 0.119s)
             Mean action noise std: 3.08
          Mean value_function loss: 80.9149
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.1543
                       Mean reward: 668.50
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 134.5207
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.28s
                      Time elapsed: 00:35:11
                               ETA: 00:24:21

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 43384 steps/s (collection: 2.144s, learning 0.122s)
             Mean action noise std: 3.08
          Mean value_function loss: 82.4743
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 65.1756
                       Mean reward: 723.33
               Mean episode length: 239.93
    Episode_Reward/reaching_object: 1.2244
    Episode_Reward/rotating_object: 136.8613
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.27s
                      Time elapsed: 00:35:14
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 42566 steps/s (collection: 2.198s, learning 0.111s)
             Mean action noise std: 3.08
          Mean value_function loss: 75.2088
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.1988
                       Mean reward: 639.82
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 1.2634
    Episode_Reward/rotating_object: 138.2999
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.31s
                      Time elapsed: 00:35:16
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 43510 steps/s (collection: 2.148s, learning 0.111s)
             Mean action noise std: 3.08
          Mean value_function loss: 79.9531
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 65.2188
                       Mean reward: 645.12
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 1.2276
    Episode_Reward/rotating_object: 131.6705
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.26s
                      Time elapsed: 00:35:18
                               ETA: 00:24:14

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 43799 steps/s (collection: 2.133s, learning 0.111s)
             Mean action noise std: 3.09
          Mean value_function loss: 86.0641
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.2452
                       Mean reward: 623.32
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.2040
    Episode_Reward/rotating_object: 129.8051
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.24s
                      Time elapsed: 00:35:21
                               ETA: 00:24:12

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 42643 steps/s (collection: 2.186s, learning 0.119s)
             Mean action noise std: 3.09
          Mean value_function loss: 72.6669
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.2797
                       Mean reward: 670.79
               Mean episode length: 229.76
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 141.5534
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.31s
                      Time elapsed: 00:35:23
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 41555 steps/s (collection: 2.244s, learning 0.121s)
             Mean action noise std: 3.10
          Mean value_function loss: 66.5125
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 65.3033
                       Mean reward: 723.62
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 1.2507
    Episode_Reward/rotating_object: 140.7034
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.37s
                      Time elapsed: 00:35:25
                               ETA: 00:24:07

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 41599 steps/s (collection: 2.244s, learning 0.119s)
             Mean action noise std: 3.10
          Mean value_function loss: 90.6657
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.3325
                       Mean reward: 650.56
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.2161
    Episode_Reward/rotating_object: 131.4218
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.36s
                      Time elapsed: 00:35:28
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 41295 steps/s (collection: 2.259s, learning 0.121s)
             Mean action noise std: 3.10
          Mean value_function loss: 86.7979
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.3584
                       Mean reward: 671.76
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.2166
    Episode_Reward/rotating_object: 133.2080
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.38s
                      Time elapsed: 00:35:30
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 42242 steps/s (collection: 2.205s, learning 0.122s)
             Mean action noise std: 3.11
          Mean value_function loss: 75.4043
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 65.3842
                       Mean reward: 679.95
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 1.2324
    Episode_Reward/rotating_object: 136.8452
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.33s
                      Time elapsed: 00:35:32
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 41693 steps/s (collection: 2.229s, learning 0.129s)
             Mean action noise std: 3.11
          Mean value_function loss: 69.0672
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.4100
                       Mean reward: 655.63
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.2471
    Episode_Reward/rotating_object: 137.1460
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.36s
                      Time elapsed: 00:35:35
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 41840 steps/s (collection: 2.228s, learning 0.121s)
             Mean action noise std: 3.11
          Mean value_function loss: 73.4442
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 65.4251
                       Mean reward: 683.49
               Mean episode length: 236.09
    Episode_Reward/reaching_object: 1.2541
    Episode_Reward/rotating_object: 135.9292
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.35s
                      Time elapsed: 00:35:37
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 41241 steps/s (collection: 2.260s, learning 0.123s)
             Mean action noise std: 3.11
          Mean value_function loss: 78.8085
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.4453
                       Mean reward: 701.40
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 1.2535
    Episode_Reward/rotating_object: 139.3093
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.38s
                      Time elapsed: 00:35:39
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 42011 steps/s (collection: 2.218s, learning 0.122s)
             Mean action noise std: 3.12
          Mean value_function loss: 82.4371
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 65.4727
                       Mean reward: 696.74
               Mean episode length: 230.07
    Episode_Reward/reaching_object: 1.2499
    Episode_Reward/rotating_object: 140.3265
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.34s
                      Time elapsed: 00:35:42
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 41961 steps/s (collection: 2.223s, learning 0.120s)
             Mean action noise std: 3.12
          Mean value_function loss: 74.8716
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 65.5096
                       Mean reward: 696.10
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 137.6963
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.34s
                      Time elapsed: 00:35:44
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 42010 steps/s (collection: 2.218s, learning 0.122s)
             Mean action noise std: 3.13
          Mean value_function loss: 65.8436
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.5429
                       Mean reward: 687.80
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 138.6330
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.34s
                      Time elapsed: 00:35:46
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 41785 steps/s (collection: 2.231s, learning 0.121s)
             Mean action noise std: 3.13
          Mean value_function loss: 90.5168
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.5603
                       Mean reward: 693.45
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 139.9511
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.35s
                      Time elapsed: 00:35:49
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 41336 steps/s (collection: 2.246s, learning 0.132s)
             Mean action noise std: 3.13
          Mean value_function loss: 77.4867
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.5831
                       Mean reward: 681.21
               Mean episode length: 236.92
    Episode_Reward/reaching_object: 1.2247
    Episode_Reward/rotating_object: 131.7717
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.38s
                      Time elapsed: 00:35:51
                               ETA: 00:23:40

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 41614 steps/s (collection: 2.238s, learning 0.125s)
             Mean action noise std: 3.13
          Mean value_function loss: 64.7759
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.6080
                       Mean reward: 705.84
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.2508
    Episode_Reward/rotating_object: 138.3222
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.36s
                      Time elapsed: 00:35:54
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 42088 steps/s (collection: 2.218s, learning 0.118s)
             Mean action noise std: 3.14
          Mean value_function loss: 90.7226
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 65.6317
                       Mean reward: 695.43
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.2259
    Episode_Reward/rotating_object: 135.2344
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.34s
                      Time elapsed: 00:35:56
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 42540 steps/s (collection: 2.193s, learning 0.118s)
             Mean action noise std: 3.14
          Mean value_function loss: 77.8634
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 65.6590
                       Mean reward: 669.82
               Mean episode length: 233.10
    Episode_Reward/reaching_object: 1.2298
    Episode_Reward/rotating_object: 135.0389
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.31s
                      Time elapsed: 00:35:58
                               ETA: 00:23:33

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 41541 steps/s (collection: 2.236s, learning 0.130s)
             Mean action noise std: 3.14
          Mean value_function loss: 83.8754
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 65.6853
                       Mean reward: 687.00
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 136.8931
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.37s
                      Time elapsed: 00:36:01
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 40570 steps/s (collection: 2.289s, learning 0.134s)
             Mean action noise std: 3.15
          Mean value_function loss: 70.4189
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.7035
                       Mean reward: 678.52
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.2586
    Episode_Reward/rotating_object: 138.8116
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.42s
                      Time elapsed: 00:36:03
                               ETA: 00:23:28

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 39049 steps/s (collection: 2.382s, learning 0.135s)
             Mean action noise std: 3.15
          Mean value_function loss: 87.0679
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 65.7239
                       Mean reward: 690.33
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 137.7225
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.52s
                      Time elapsed: 00:36:05
                               ETA: 00:23:26

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 39910 steps/s (collection: 2.336s, learning 0.127s)
             Mean action noise std: 3.15
          Mean value_function loss: 78.0896
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 65.7599
                       Mean reward: 711.24
               Mean episode length: 234.23
    Episode_Reward/reaching_object: 1.2568
    Episode_Reward/rotating_object: 144.0955
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.46s
                      Time elapsed: 00:36:08
                               ETA: 00:23:24

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 40041 steps/s (collection: 2.313s, learning 0.142s)
             Mean action noise std: 3.16
          Mean value_function loss: 64.9702
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.7971
                       Mean reward: 702.71
               Mean episode length: 242.77
    Episode_Reward/reaching_object: 1.2497
    Episode_Reward/rotating_object: 141.0202
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.46s
                      Time elapsed: 00:36:10
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 40402 steps/s (collection: 2.322s, learning 0.111s)
             Mean action noise std: 3.16
          Mean value_function loss: 73.3646
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 65.8195
                       Mean reward: 725.50
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.2542
    Episode_Reward/rotating_object: 141.7544
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.43s
                      Time elapsed: 00:36:13
                               ETA: 00:23:19

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 42222 steps/s (collection: 2.208s, learning 0.120s)
             Mean action noise std: 3.16
          Mean value_function loss: 87.1355
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.8356
                       Mean reward: 720.32
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 139.2043
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.33s
                      Time elapsed: 00:36:15
                               ETA: 00:23:17

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 41830 steps/s (collection: 2.229s, learning 0.121s)
             Mean action noise std: 3.17
          Mean value_function loss: 73.8857
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.8591
                       Mean reward: 698.56
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 1.2540
    Episode_Reward/rotating_object: 137.4054
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.35s
                      Time elapsed: 00:36:17
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 41925 steps/s (collection: 2.224s, learning 0.120s)
             Mean action noise std: 3.17
          Mean value_function loss: 92.2236
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.8897
                       Mean reward: 742.83
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 135.6241
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.34s
                      Time elapsed: 00:36:20
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 42176 steps/s (collection: 2.210s, learning 0.121s)
             Mean action noise std: 3.18
          Mean value_function loss: 87.9894
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 65.9234
                       Mean reward: 676.71
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 135.0639
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.33s
                      Time elapsed: 00:36:22
                               ETA: 00:23:10

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 42530 steps/s (collection: 2.192s, learning 0.119s)
             Mean action noise std: 3.18
          Mean value_function loss: 92.5826
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.9603
                       Mean reward: 714.26
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 1.2299
    Episode_Reward/rotating_object: 137.2000
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.31s
                      Time elapsed: 00:36:24
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 42236 steps/s (collection: 2.206s, learning 0.122s)
             Mean action noise std: 3.18
          Mean value_function loss: 83.0066
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.9839
                       Mean reward: 701.96
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.2330
    Episode_Reward/rotating_object: 132.8321
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.33s
                      Time elapsed: 00:36:27
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 42240 steps/s (collection: 2.200s, learning 0.127s)
             Mean action noise std: 3.18
          Mean value_function loss: 69.1702
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.0021
                       Mean reward: 748.65
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 1.2437
    Episode_Reward/rotating_object: 138.0275
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.33s
                      Time elapsed: 00:36:29
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 42643 steps/s (collection: 2.181s, learning 0.124s)
             Mean action noise std: 3.19
          Mean value_function loss: 86.9795
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.0223
                       Mean reward: 693.85
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.2438
    Episode_Reward/rotating_object: 136.8815
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.31s
                      Time elapsed: 00:36:31
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 42006 steps/s (collection: 2.217s, learning 0.123s)
             Mean action noise std: 3.19
          Mean value_function loss: 87.2328
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 66.0445
                       Mean reward: 682.79
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.2409
    Episode_Reward/rotating_object: 141.1566
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.34s
                      Time elapsed: 00:36:34
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 41246 steps/s (collection: 2.261s, learning 0.123s)
             Mean action noise std: 3.19
          Mean value_function loss: 79.5680
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.0769
                       Mean reward: 687.16
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 1.2328
    Episode_Reward/rotating_object: 138.3036
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.38s
                      Time elapsed: 00:36:36
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 42008 steps/s (collection: 2.216s, learning 0.124s)
             Mean action noise std: 3.20
          Mean value_function loss: 87.2143
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.1081
                       Mean reward: 673.69
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 135.7101
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.34s
                      Time elapsed: 00:36:38
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 41913 steps/s (collection: 2.225s, learning 0.120s)
             Mean action noise std: 3.20
          Mean value_function loss: 91.1424
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 66.1322
                       Mean reward: 671.18
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.2137
    Episode_Reward/rotating_object: 135.6386
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.35s
                      Time elapsed: 00:36:41
                               ETA: 00:22:50

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 42245 steps/s (collection: 2.207s, learning 0.120s)
             Mean action noise std: 3.20
          Mean value_function loss: 80.8805
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 66.1521
                       Mean reward: 654.14
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 1.2114
    Episode_Reward/rotating_object: 134.4851
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.33s
                      Time elapsed: 00:36:43
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 42672 steps/s (collection: 2.183s, learning 0.120s)
             Mean action noise std: 3.21
          Mean value_function loss: 90.2695
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.1850
                       Mean reward: 721.61
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.2240
    Episode_Reward/rotating_object: 138.5345
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.30s
                      Time elapsed: 00:36:45
                               ETA: 00:22:45

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 42755 steps/s (collection: 2.179s, learning 0.120s)
             Mean action noise std: 3.21
          Mean value_function loss: 94.2392
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.2142
                       Mean reward: 659.15
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.2191
    Episode_Reward/rotating_object: 131.9369
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.30s
                      Time elapsed: 00:36:48
                               ETA: 00:22:43

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 42052 steps/s (collection: 2.226s, learning 0.112s)
             Mean action noise std: 3.21
          Mean value_function loss: 99.9085
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.2400
                       Mean reward: 684.36
               Mean episode length: 228.24
    Episode_Reward/reaching_object: 1.2284
    Episode_Reward/rotating_object: 138.7802
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.34s
                      Time elapsed: 00:36:50
                               ETA: 00:22:41

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 43753 steps/s (collection: 2.136s, learning 0.111s)
             Mean action noise std: 3.22
          Mean value_function loss: 90.8427
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.2652
                       Mean reward: 625.61
               Mean episode length: 227.47
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 129.7581
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.25s
                      Time elapsed: 00:36:52
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 44009 steps/s (collection: 2.111s, learning 0.123s)
             Mean action noise std: 3.22
          Mean value_function loss: 97.6118
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.2973
                       Mean reward: 668.48
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 1.1877
    Episode_Reward/rotating_object: 128.8800
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.23s
                      Time elapsed: 00:36:55
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 43720 steps/s (collection: 2.135s, learning 0.114s)
             Mean action noise std: 3.23
          Mean value_function loss: 91.1379
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.3333
                       Mean reward: 711.02
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 1.2455
    Episode_Reward/rotating_object: 139.6660
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.25s
                      Time elapsed: 00:36:57
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 43873 steps/s (collection: 2.127s, learning 0.113s)
             Mean action noise std: 3.23
          Mean value_function loss: 89.6548
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 66.3529
                       Mean reward: 668.60
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 130.0605
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.24s
                      Time elapsed: 00:36:59
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 42844 steps/s (collection: 2.171s, learning 0.123s)
             Mean action noise std: 3.23
          Mean value_function loss: 76.3810
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.3793
                       Mean reward: 689.71
               Mean episode length: 234.10
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 132.8746
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.29s
                      Time elapsed: 00:37:01
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 41430 steps/s (collection: 2.254s, learning 0.119s)
             Mean action noise std: 3.23
          Mean value_function loss: 81.7945
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 66.4015
                       Mean reward: 727.12
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 1.2169
    Episode_Reward/rotating_object: 135.0267
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.37s
                      Time elapsed: 00:37:04
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 41568 steps/s (collection: 2.243s, learning 0.122s)
             Mean action noise std: 3.24
          Mean value_function loss: 93.1609
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.4214
                       Mean reward: 716.20
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.2163
    Episode_Reward/rotating_object: 134.4452
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.36s
                      Time elapsed: 00:37:06
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 41781 steps/s (collection: 2.230s, learning 0.123s)
             Mean action noise std: 3.24
          Mean value_function loss: 85.8921
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.4529
                       Mean reward: 678.67
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 133.6449
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.35s
                      Time elapsed: 00:37:08
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 41605 steps/s (collection: 2.241s, learning 0.122s)
             Mean action noise std: 3.24
          Mean value_function loss: 83.9413
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.4786
                       Mean reward: 671.78
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.2192
    Episode_Reward/rotating_object: 135.9369
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.36s
                      Time elapsed: 00:37:11
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 41458 steps/s (collection: 2.241s, learning 0.130s)
             Mean action noise std: 3.25
          Mean value_function loss: 99.7991
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.5044
                       Mean reward: 686.17
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 133.0687
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.37s
                      Time elapsed: 00:37:13
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 41647 steps/s (collection: 2.238s, learning 0.122s)
             Mean action noise std: 3.25
          Mean value_function loss: 95.3536
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 66.5370
                       Mean reward: 621.01
               Mean episode length: 220.80
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 130.2971
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.36s
                      Time elapsed: 00:37:16
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 41947 steps/s (collection: 2.221s, learning 0.122s)
             Mean action noise std: 3.25
          Mean value_function loss: 85.5506
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.5585
                       Mean reward: 680.46
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 131.8676
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.34s
                      Time elapsed: 00:37:18
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 41821 steps/s (collection: 2.228s, learning 0.122s)
             Mean action noise std: 3.26
          Mean value_function loss: 92.2383
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 66.5810
                       Mean reward: 689.26
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 133.7972
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.35s
                      Time elapsed: 00:37:20
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 41425 steps/s (collection: 2.255s, learning 0.118s)
             Mean action noise std: 3.26
          Mean value_function loss: 103.2507
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 66.6086
                       Mean reward: 673.69
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 1.2091
    Episode_Reward/rotating_object: 134.6940
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.37s
                      Time elapsed: 00:37:23
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 41675 steps/s (collection: 2.240s, learning 0.118s)
             Mean action noise std: 3.26
          Mean value_function loss: 94.3133
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 66.6239
                       Mean reward: 631.20
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 1.2072
    Episode_Reward/rotating_object: 134.8926
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.36s
                      Time elapsed: 00:37:25
                               ETA: 00:22:04

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 41698 steps/s (collection: 2.239s, learning 0.119s)
             Mean action noise std: 3.27
          Mean value_function loss: 72.2824
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.6425
                       Mean reward: 702.52
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 132.2323
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.36s
                      Time elapsed: 00:37:27
                               ETA: 00:22:02

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 41982 steps/s (collection: 2.223s, learning 0.119s)
             Mean action noise std: 3.27
          Mean value_function loss: 94.0977
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 66.6755
                       Mean reward: 702.90
               Mean episode length: 240.76
    Episode_Reward/reaching_object: 1.2424
    Episode_Reward/rotating_object: 138.2077
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.34s
                      Time elapsed: 00:37:30
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 41801 steps/s (collection: 2.232s, learning 0.119s)
             Mean action noise std: 3.27
          Mean value_function loss: 91.1090
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.6946
                       Mean reward: 694.15
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 131.6471
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.35s
                      Time elapsed: 00:37:32
                               ETA: 00:21:57

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 41157 steps/s (collection: 2.267s, learning 0.122s)
             Mean action noise std: 3.27
          Mean value_function loss: 82.4467
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 66.7050
                       Mean reward: 717.50
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 134.3337
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.39s
                      Time elapsed: 00:37:34
                               ETA: 00:21:55

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 40442 steps/s (collection: 2.304s, learning 0.127s)
             Mean action noise std: 3.28
          Mean value_function loss: 85.0253
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 66.7272
                       Mean reward: 675.36
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 138.0816
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.43s
                      Time elapsed: 00:37:37
                               ETA: 00:21:53

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 40666 steps/s (collection: 2.291s, learning 0.126s)
             Mean action noise std: 3.28
          Mean value_function loss: 89.1697
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 66.7545
                       Mean reward: 712.33
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 138.6070
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.42s
                      Time elapsed: 00:37:39
                               ETA: 00:21:50

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 40595 steps/s (collection: 2.292s, learning 0.130s)
             Mean action noise std: 3.29
          Mean value_function loss: 92.8527
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 66.7800
                       Mean reward: 664.34
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.2339
    Episode_Reward/rotating_object: 137.3466
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.42s
                      Time elapsed: 00:37:42
                               ETA: 00:21:48

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 40735 steps/s (collection: 2.287s, learning 0.126s)
             Mean action noise std: 3.29
          Mean value_function loss: 87.6302
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 66.8049
                       Mean reward: 685.31
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 1.2176
    Episode_Reward/rotating_object: 133.6339
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.41s
                      Time elapsed: 00:37:44
                               ETA: 00:21:45

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 41319 steps/s (collection: 2.256s, learning 0.123s)
             Mean action noise std: 3.29
          Mean value_function loss: 89.5133
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.8312
                       Mean reward: 632.19
               Mean episode length: 229.55
    Episode_Reward/reaching_object: 1.2045
    Episode_Reward/rotating_object: 129.5640
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.38s
                      Time elapsed: 00:37:46
                               ETA: 00:21:43

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 41344 steps/s (collection: 2.259s, learning 0.119s)
             Mean action noise std: 3.30
          Mean value_function loss: 82.6046
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.8544
                       Mean reward: 698.59
               Mean episode length: 238.03
    Episode_Reward/reaching_object: 1.2159
    Episode_Reward/rotating_object: 139.0613
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.38s
                      Time elapsed: 00:37:49
                               ETA: 00:21:41

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 42040 steps/s (collection: 2.218s, learning 0.120s)
             Mean action noise std: 3.30
          Mean value_function loss: 82.8807
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.8730
                       Mean reward: 644.29
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.2157
    Episode_Reward/rotating_object: 134.2225
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.34s
                      Time elapsed: 00:37:51
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 41823 steps/s (collection: 2.228s, learning 0.122s)
             Mean action noise std: 3.30
          Mean value_function loss: 80.7507
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 66.8915
                       Mean reward: 698.77
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 132.1686
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.35s
                      Time elapsed: 00:37:54
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 42176 steps/s (collection: 2.211s, learning 0.120s)
             Mean action noise std: 3.30
          Mean value_function loss: 75.9191
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.9123
                       Mean reward: 684.59
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 1.2147
    Episode_Reward/rotating_object: 133.3112
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.33s
                      Time elapsed: 00:37:56
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 41905 steps/s (collection: 2.223s, learning 0.123s)
             Mean action noise std: 3.31
          Mean value_function loss: 89.7442
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.9306
                       Mean reward: 683.67
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 1.2241
    Episode_Reward/rotating_object: 135.0118
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.35s
                      Time elapsed: 00:37:58
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 41383 steps/s (collection: 2.242s, learning 0.133s)
             Mean action noise std: 3.31
          Mean value_function loss: 96.3204
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 66.9434
                       Mean reward: 665.80
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.2336
    Episode_Reward/rotating_object: 134.1058
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.38s
                      Time elapsed: 00:38:01
                               ETA: 00:21:29

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 41281 steps/s (collection: 2.264s, learning 0.118s)
             Mean action noise std: 3.31
          Mean value_function loss: 83.5521
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 66.9663
                       Mean reward: 654.51
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.2102
    Episode_Reward/rotating_object: 130.8795
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.38s
                      Time elapsed: 00:38:03
                               ETA: 00:21:26

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 40734 steps/s (collection: 2.286s, learning 0.127s)
             Mean action noise std: 3.32
          Mean value_function loss: 83.0452
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.9911
                       Mean reward: 627.26
               Mean episode length: 227.78
    Episode_Reward/reaching_object: 1.2192
    Episode_Reward/rotating_object: 132.5057
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.41s
                      Time elapsed: 00:38:05
                               ETA: 00:21:24

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 41432 steps/s (collection: 2.254s, learning 0.119s)
             Mean action noise std: 3.32
          Mean value_function loss: 101.0763
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.0213
                       Mean reward: 643.89
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 134.7661
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.37s
                      Time elapsed: 00:38:08
                               ETA: 00:21:22

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 41946 steps/s (collection: 2.224s, learning 0.120s)
             Mean action noise std: 3.32
          Mean value_function loss: 90.4818
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.0459
                       Mean reward: 668.46
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 1.2091
    Episode_Reward/rotating_object: 135.3229
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.34s
                      Time elapsed: 00:38:10
                               ETA: 00:21:19

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 42032 steps/s (collection: 2.218s, learning 0.121s)
             Mean action noise std: 3.32
          Mean value_function loss: 88.5720
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 67.0642
                       Mean reward: 684.44
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.2229
    Episode_Reward/rotating_object: 137.0262
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.34s
                      Time elapsed: 00:38:12
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 41924 steps/s (collection: 2.221s, learning 0.124s)
             Mean action noise std: 3.33
          Mean value_function loss: 83.2339
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.0919
                       Mean reward: 655.92
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 133.1866
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.34s
                      Time elapsed: 00:38:15
                               ETA: 00:21:14

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 41749 steps/s (collection: 2.236s, learning 0.119s)
             Mean action noise std: 3.33
          Mean value_function loss: 90.2142
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.1168
                       Mean reward: 659.26
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 134.9928
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.35s
                      Time elapsed: 00:38:17
                               ETA: 00:21:12

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 40819 steps/s (collection: 2.281s, learning 0.127s)
             Mean action noise std: 3.33
          Mean value_function loss: 100.4544
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 67.1469
                       Mean reward: 607.07
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 1.1615
    Episode_Reward/rotating_object: 127.8952
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.41s
                      Time elapsed: 00:38:20
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 40172 steps/s (collection: 2.321s, learning 0.126s)
             Mean action noise std: 3.34
          Mean value_function loss: 93.3489
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 67.1712
                       Mean reward: 651.21
               Mean episode length: 224.91
    Episode_Reward/reaching_object: 1.2118
    Episode_Reward/rotating_object: 132.8064
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.45s
                      Time elapsed: 00:38:22
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 41958 steps/s (collection: 2.224s, learning 0.119s)
             Mean action noise std: 3.34
          Mean value_function loss: 78.5911
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 67.1972
                       Mean reward: 745.56
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.2084
    Episode_Reward/rotating_object: 134.1264
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.34s
                      Time elapsed: 00:38:24
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 42452 steps/s (collection: 2.196s, learning 0.119s)
             Mean action noise std: 3.34
          Mean value_function loss: 85.7811
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.2151
                       Mean reward: 664.73
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 1.1989
    Episode_Reward/rotating_object: 135.0795
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.32s
                      Time elapsed: 00:38:27
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 42307 steps/s (collection: 2.200s, learning 0.123s)
             Mean action noise std: 3.35
          Mean value_function loss: 85.2771
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 67.2305
                       Mean reward: 627.43
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 129.8165
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.32s
                      Time elapsed: 00:38:29
                               ETA: 00:21:00

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 44008 steps/s (collection: 2.122s, learning 0.112s)
             Mean action noise std: 3.35
          Mean value_function loss: 101.3407
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.2546
                       Mean reward: 643.64
               Mean episode length: 226.08
    Episode_Reward/reaching_object: 1.1779
    Episode_Reward/rotating_object: 131.3100
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.23s
                      Time elapsed: 00:38:31
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 42385 steps/s (collection: 2.200s, learning 0.120s)
             Mean action noise std: 3.35
          Mean value_function loss: 93.3269
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 67.2818
                       Mean reward: 734.36
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 1.2226
    Episode_Reward/rotating_object: 137.1068
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.32s
                      Time elapsed: 00:38:34
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 42097 steps/s (collection: 2.214s, learning 0.122s)
             Mean action noise std: 3.35
          Mean value_function loss: 88.3157
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.3047
                       Mean reward: 653.10
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 134.0774
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.34s
                      Time elapsed: 00:38:36
                               ETA: 00:20:53

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 42254 steps/s (collection: 2.205s, learning 0.121s)
             Mean action noise std: 3.36
          Mean value_function loss: 96.3962
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.3263
                       Mean reward: 679.14
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 132.8284
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.33s
                      Time elapsed: 00:38:38
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 41906 steps/s (collection: 2.228s, learning 0.118s)
             Mean action noise std: 3.36
          Mean value_function loss: 82.4771
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.3464
                       Mean reward: 698.15
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 1.2262
    Episode_Reward/rotating_object: 137.1263
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.35s
                      Time elapsed: 00:38:41
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 42115 steps/s (collection: 2.216s, learning 0.118s)
             Mean action noise std: 3.36
          Mean value_function loss: 99.5415
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.3714
                       Mean reward: 671.03
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.1777
    Episode_Reward/rotating_object: 131.7338
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.33s
                      Time elapsed: 00:38:43
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 42180 steps/s (collection: 2.210s, learning 0.121s)
             Mean action noise std: 3.37
          Mean value_function loss: 89.6015
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.3952
                       Mean reward: 708.52
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 135.0352
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.33s
                      Time elapsed: 00:38:45
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 41942 steps/s (collection: 2.226s, learning 0.118s)
             Mean action noise std: 3.37
          Mean value_function loss: 85.6473
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 67.4104
                       Mean reward: 671.41
               Mean episode length: 228.39
    Episode_Reward/reaching_object: 1.2194
    Episode_Reward/rotating_object: 136.3294
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.34s
                      Time elapsed: 00:38:48
                               ETA: 00:20:41

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 42515 steps/s (collection: 2.192s, learning 0.120s)
             Mean action noise std: 3.37
          Mean value_function loss: 103.1336
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 67.4356
                       Mean reward: 692.22
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 134.8621
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.31s
                      Time elapsed: 00:38:50
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 42040 steps/s (collection: 2.215s, learning 0.124s)
             Mean action noise std: 3.38
          Mean value_function loss: 84.1516
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.4645
                       Mean reward: 670.04
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 1.2158
    Episode_Reward/rotating_object: 135.3081
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.34s
                      Time elapsed: 00:38:52
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 42120 steps/s (collection: 2.216s, learning 0.118s)
             Mean action noise std: 3.38
          Mean value_function loss: 91.7212
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.4920
                       Mean reward: 653.03
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.2195
    Episode_Reward/rotating_object: 134.7811
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.33s
                      Time elapsed: 00:38:55
                               ETA: 00:20:34

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 42150 steps/s (collection: 2.210s, learning 0.122s)
             Mean action noise std: 3.38
          Mean value_function loss: 79.4682
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.5137
                       Mean reward: 665.39
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 1.2112
    Episode_Reward/rotating_object: 135.8716
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.33s
                      Time elapsed: 00:38:57
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 42371 steps/s (collection: 2.199s, learning 0.121s)
             Mean action noise std: 3.39
          Mean value_function loss: 95.2306
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 67.5363
                       Mean reward: 659.79
               Mean episode length: 231.21
    Episode_Reward/reaching_object: 1.2048
    Episode_Reward/rotating_object: 134.7173
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.32s
                      Time elapsed: 00:38:59
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 41930 steps/s (collection: 2.224s, learning 0.120s)
             Mean action noise std: 3.39
          Mean value_function loss: 85.5724
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.5593
                       Mean reward: 693.61
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 134.3318
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.34s
                      Time elapsed: 00:39:02
                               ETA: 00:20:26

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 41996 steps/s (collection: 2.212s, learning 0.129s)
             Mean action noise std: 3.39
          Mean value_function loss: 93.8315
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.5754
                       Mean reward: 634.08
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 1.2017
    Episode_Reward/rotating_object: 130.8497
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.34s
                      Time elapsed: 00:39:04
                               ETA: 00:20:24

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 42283 steps/s (collection: 2.207s, learning 0.118s)
             Mean action noise std: 3.40
          Mean value_function loss: 79.3952
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.6024
                       Mean reward: 679.87
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.2243
    Episode_Reward/rotating_object: 137.4000
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.32s
                      Time elapsed: 00:39:06
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 41019 steps/s (collection: 2.270s, learning 0.127s)
             Mean action noise std: 3.40
          Mean value_function loss: 87.4457
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.6310
                       Mean reward: 683.87
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.2277
    Episode_Reward/rotating_object: 133.5809
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.40s
                      Time elapsed: 00:39:09
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 40985 steps/s (collection: 2.271s, learning 0.128s)
             Mean action noise std: 3.40
          Mean value_function loss: 84.5714
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.6560
                       Mean reward: 660.50
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 138.0095
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.40s
                      Time elapsed: 00:39:11
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 40752 steps/s (collection: 2.285s, learning 0.127s)
             Mean action noise std: 3.41
          Mean value_function loss: 94.5507
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 67.6774
                       Mean reward: 666.68
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 134.9895
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.41s
                      Time elapsed: 00:39:13
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 40610 steps/s (collection: 2.294s, learning 0.127s)
             Mean action noise std: 3.41
          Mean value_function loss: 93.1724
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.6934
                       Mean reward: 655.15
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 133.7239
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.42s
                      Time elapsed: 00:39:16
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 40820 steps/s (collection: 2.281s, learning 0.127s)
             Mean action noise std: 3.41
          Mean value_function loss: 80.4391
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.7071
                       Mean reward: 689.89
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.2372
    Episode_Reward/rotating_object: 141.6095
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.41s
                      Time elapsed: 00:39:18
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 40471 steps/s (collection: 2.299s, learning 0.129s)
             Mean action noise std: 3.41
          Mean value_function loss: 86.9623
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 67.7298
                       Mean reward: 715.99
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2246
    Episode_Reward/rotating_object: 135.3480
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.43s
                      Time elapsed: 00:39:21
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 41201 steps/s (collection: 2.265s, learning 0.121s)
             Mean action noise std: 3.42
          Mean value_function loss: 85.5147
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.7665
                       Mean reward: 703.32
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 1.2223
    Episode_Reward/rotating_object: 133.2105
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.39s
                      Time elapsed: 00:39:23
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 42688 steps/s (collection: 2.184s, learning 0.119s)
             Mean action noise std: 3.42
          Mean value_function loss: 83.7851
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.7974
                       Mean reward: 656.02
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 1.2334
    Episode_Reward/rotating_object: 134.0744
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.30s
                      Time elapsed: 00:39:25
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 42572 steps/s (collection: 2.191s, learning 0.118s)
             Mean action noise std: 3.42
          Mean value_function loss: 90.3698
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 67.8201
                       Mean reward: 720.52
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.2519
    Episode_Reward/rotating_object: 138.5562
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.31s
                      Time elapsed: 00:39:28
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 41848 steps/s (collection: 2.228s, learning 0.121s)
             Mean action noise std: 3.43
          Mean value_function loss: 88.5254
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.8407
                       Mean reward: 665.06
               Mean episode length: 238.74
    Episode_Reward/reaching_object: 1.2320
    Episode_Reward/rotating_object: 134.4538
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.35s
                      Time elapsed: 00:39:30
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 42266 steps/s (collection: 2.205s, learning 0.121s)
             Mean action noise std: 3.43
          Mean value_function loss: 80.9243
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.8582
                       Mean reward: 663.18
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.2455
    Episode_Reward/rotating_object: 139.4090
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.33s
                      Time elapsed: 00:39:32
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 42399 steps/s (collection: 2.197s, learning 0.122s)
             Mean action noise std: 3.43
          Mean value_function loss: 87.5546
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.8752
                       Mean reward: 648.01
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 130.6729
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.32s
                      Time elapsed: 00:39:35
                               ETA: 00:19:53

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 42171 steps/s (collection: 2.211s, learning 0.120s)
             Mean action noise std: 3.44
          Mean value_function loss: 87.1573
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 67.8993
                       Mean reward: 673.27
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.2061
    Episode_Reward/rotating_object: 131.5035
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.33s
                      Time elapsed: 00:39:37
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 41674 steps/s (collection: 2.236s, learning 0.123s)
             Mean action noise std: 3.44
          Mean value_function loss: 103.9572
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.9183
                       Mean reward: 665.35
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 1.2260
    Episode_Reward/rotating_object: 134.7084
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 2.36s
                      Time elapsed: 00:39:39
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 42276 steps/s (collection: 2.204s, learning 0.121s)
             Mean action noise std: 3.44
          Mean value_function loss: 93.5245
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.9406
                       Mean reward: 646.01
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 132.5613
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 2.33s
                      Time elapsed: 00:39:42
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 42573 steps/s (collection: 2.187s, learning 0.122s)
             Mean action noise std: 3.45
          Mean value_function loss: 109.7449
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.9758
                       Mean reward: 697.22
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 130.8604
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 2.31s
                      Time elapsed: 00:39:44
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 41422 steps/s (collection: 2.244s, learning 0.129s)
             Mean action noise std: 3.45
          Mean value_function loss: 88.5340
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.0117
                       Mean reward: 671.70
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 132.6605
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 2.37s
                      Time elapsed: 00:39:46
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 42224 steps/s (collection: 2.195s, learning 0.133s)
             Mean action noise std: 3.45
          Mean value_function loss: 94.4211
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.0293
                       Mean reward: 678.90
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.2511
    Episode_Reward/rotating_object: 137.7099
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 2.33s
                      Time elapsed: 00:39:49
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 42381 steps/s (collection: 2.201s, learning 0.118s)
             Mean action noise std: 3.46
          Mean value_function loss: 107.1181
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.0454
                       Mean reward: 713.31
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 134.5476
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 2.32s
                      Time elapsed: 00:39:51
                               ETA: 00:19:36

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 42199 steps/s (collection: 2.212s, learning 0.118s)
             Mean action noise std: 3.46
          Mean value_function loss: 103.3107
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.0630
                       Mean reward: 706.66
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.2171
    Episode_Reward/rotating_object: 133.8105
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 2.33s
                      Time elapsed: 00:39:53
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 41939 steps/s (collection: 2.217s, learning 0.127s)
             Mean action noise std: 3.46
          Mean value_function loss: 104.8693
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.0826
                       Mean reward: 677.01
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 136.4403
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 2.34s
                      Time elapsed: 00:39:56
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 41052 steps/s (collection: 2.277s, learning 0.118s)
             Mean action noise std: 3.46
          Mean value_function loss: 100.1694
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.1055
                       Mean reward: 696.89
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 1.2387
    Episode_Reward/rotating_object: 135.9679
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 2.39s
                      Time elapsed: 00:39:58
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 41313 steps/s (collection: 2.262s, learning 0.117s)
             Mean action noise std: 3.47
          Mean value_function loss: 84.0873
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.1257
                       Mean reward: 660.26
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.2464
    Episode_Reward/rotating_object: 135.1611
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.38s
                      Time elapsed: 00:40:00
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 42588 steps/s (collection: 2.191s, learning 0.117s)
             Mean action noise std: 3.47
          Mean value_function loss: 99.9353
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.1490
                       Mean reward: 662.96
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.2197
    Episode_Reward/rotating_object: 133.2524
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.31s
                      Time elapsed: 00:40:03
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 42711 steps/s (collection: 2.183s, learning 0.118s)
             Mean action noise std: 3.47
          Mean value_function loss: 113.4931
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.1792
                       Mean reward: 674.86
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.2294
    Episode_Reward/rotating_object: 127.9792
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.30s
                      Time elapsed: 00:40:05
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 42146 steps/s (collection: 2.211s, learning 0.122s)
             Mean action noise std: 3.48
          Mean value_function loss: 101.5585
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 68.2012
                       Mean reward: 656.07
               Mean episode length: 225.39
    Episode_Reward/reaching_object: 1.2164
    Episode_Reward/rotating_object: 133.2510
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.33s
                      Time elapsed: 00:40:07
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 41813 steps/s (collection: 2.231s, learning 0.120s)
             Mean action noise std: 3.48
          Mean value_function loss: 99.6526
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 68.2295
                       Mean reward: 670.81
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 134.5729
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.35s
                      Time elapsed: 00:40:10
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 41811 steps/s (collection: 2.230s, learning 0.121s)
             Mean action noise std: 3.48
          Mean value_function loss: 104.2047
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.2573
                       Mean reward: 678.80
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 131.1274
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.35s
                      Time elapsed: 00:40:12
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 41938 steps/s (collection: 2.226s, learning 0.118s)
             Mean action noise std: 3.49
          Mean value_function loss: 106.4665
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.2885
                       Mean reward: 694.49
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 132.8365
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.34s
                      Time elapsed: 00:40:14
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 41771 steps/s (collection: 2.234s, learning 0.120s)
             Mean action noise std: 3.49
          Mean value_function loss: 84.4786
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.3212
                       Mean reward: 638.02
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 1.2382
    Episode_Reward/rotating_object: 134.4752
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0539
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.35s
                      Time elapsed: 00:40:17
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 41996 steps/s (collection: 2.222s, learning 0.119s)
             Mean action noise std: 3.50
          Mean value_function loss: 89.2600
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.3455
                       Mean reward: 654.66
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.2542
    Episode_Reward/rotating_object: 134.9664
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.34s
                      Time elapsed: 00:40:19
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 41313 steps/s (collection: 2.260s, learning 0.119s)
             Mean action noise std: 3.50
          Mean value_function loss: 99.2850
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.3597
                       Mean reward: 651.41
               Mean episode length: 224.83
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 132.2440
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.38s
                      Time elapsed: 00:40:22
                               ETA: 00:19:05

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 41814 steps/s (collection: 2.229s, learning 0.122s)
             Mean action noise std: 3.50
          Mean value_function loss: 106.6732
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 68.3809
                       Mean reward: 665.89
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 1.2238
    Episode_Reward/rotating_object: 132.0791
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.35s
                      Time elapsed: 00:40:24
                               ETA: 00:19:03

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 42012 steps/s (collection: 2.218s, learning 0.121s)
             Mean action noise std: 3.50
          Mean value_function loss: 82.8637
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 68.4045
                       Mean reward: 695.93
               Mean episode length: 236.20
    Episode_Reward/reaching_object: 1.2524
    Episode_Reward/rotating_object: 135.9126
        Episode_Reward/action_rate: -0.0735
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.34s
                      Time elapsed: 00:40:26
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 42147 steps/s (collection: 2.212s, learning 0.120s)
             Mean action noise std: 3.51
          Mean value_function loss: 89.1907
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.4286
                       Mean reward: 684.85
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 132.3163
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.33s
                      Time elapsed: 00:40:29
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 41929 steps/s (collection: 2.222s, learning 0.122s)
             Mean action noise std: 3.51
          Mean value_function loss: 93.3770
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.4482
                       Mean reward: 606.51
               Mean episode length: 230.94
    Episode_Reward/reaching_object: 1.2229
    Episode_Reward/rotating_object: 129.6910
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.34s
                      Time elapsed: 00:40:31
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 42224 steps/s (collection: 2.206s, learning 0.122s)
             Mean action noise std: 3.51
          Mean value_function loss: 101.4720
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.4633
                       Mean reward: 672.87
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.2355
    Episode_Reward/rotating_object: 134.8959
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.33s
                      Time elapsed: 00:40:33
                               ETA: 00:18:53

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 41769 steps/s (collection: 2.233s, learning 0.120s)
             Mean action noise std: 3.52
          Mean value_function loss: 99.7081
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.4900
                       Mean reward: 657.30
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 129.4535
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.35s
                      Time elapsed: 00:40:36
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 41667 steps/s (collection: 2.239s, learning 0.120s)
             Mean action noise std: 3.52
          Mean value_function loss: 97.4993
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 68.5101
                       Mean reward: 711.14
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.2128
    Episode_Reward/rotating_object: 132.4431
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.36s
                      Time elapsed: 00:40:38
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 41808 steps/s (collection: 2.231s, learning 0.121s)
             Mean action noise std: 3.52
          Mean value_function loss: 93.8537
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 68.5313
                       Mean reward: 616.43
               Mean episode length: 221.52
    Episode_Reward/reaching_object: 1.1968
    Episode_Reward/rotating_object: 129.3563
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.35s
                      Time elapsed: 00:40:40
                               ETA: 00:18:46

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 41770 steps/s (collection: 2.235s, learning 0.119s)
             Mean action noise std: 3.53
          Mean value_function loss: 107.8710
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.5508
                       Mean reward: 674.92
               Mean episode length: 233.71
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 133.3785
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.35s
                      Time elapsed: 00:40:43
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 41407 steps/s (collection: 2.247s, learning 0.127s)
             Mean action noise std: 3.53
          Mean value_function loss: 92.9215
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 68.5704
                       Mean reward: 705.95
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 1.2275
    Episode_Reward/rotating_object: 133.9223
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.37s
                      Time elapsed: 00:40:45
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 41963 steps/s (collection: 2.224s, learning 0.119s)
             Mean action noise std: 3.53
          Mean value_function loss: 91.7877
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 68.5951
                       Mean reward: 680.19
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.2108
    Episode_Reward/rotating_object: 131.4236
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.34s
                      Time elapsed: 00:40:47
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 41762 steps/s (collection: 2.236s, learning 0.118s)
             Mean action noise std: 3.54
          Mean value_function loss: 85.7916
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.6198
                       Mean reward: 677.12
               Mean episode length: 229.50
    Episode_Reward/reaching_object: 1.2312
    Episode_Reward/rotating_object: 137.0684
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.35s
                      Time elapsed: 00:40:50
                               ETA: 00:18:36

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 41835 steps/s (collection: 2.224s, learning 0.126s)
             Mean action noise std: 3.54
          Mean value_function loss: 94.3952
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.6368
                       Mean reward: 677.85
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 1.2319
    Episode_Reward/rotating_object: 135.7722
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.35s
                      Time elapsed: 00:40:52
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 39848 steps/s (collection: 2.335s, learning 0.132s)
             Mean action noise std: 3.54
          Mean value_function loss: 73.0787
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 68.6585
                       Mean reward: 699.24
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 135.7142
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0560
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.47s
                      Time elapsed: 00:40:55
                               ETA: 00:18:32

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 39947 steps/s (collection: 2.332s, learning 0.129s)
             Mean action noise std: 3.55
          Mean value_function loss: 82.9662
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.6918
                       Mean reward: 692.87
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 1.2247
    Episode_Reward/rotating_object: 133.6477
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.46s
                      Time elapsed: 00:40:57
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 41539 steps/s (collection: 2.236s, learning 0.131s)
             Mean action noise std: 3.55
          Mean value_function loss: 96.0843
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 68.7211
                       Mean reward: 664.95
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 1.2240
    Episode_Reward/rotating_object: 137.0094
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.37s
                      Time elapsed: 00:40:59
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 42068 steps/s (collection: 2.219s, learning 0.118s)
             Mean action noise std: 3.55
          Mean value_function loss: 95.5028
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.7480
                       Mean reward: 635.13
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 1.1944
    Episode_Reward/rotating_object: 130.5857
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.34s
                      Time elapsed: 00:41:02
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 44518 steps/s (collection: 2.092s, learning 0.116s)
             Mean action noise std: 3.56
          Mean value_function loss: 99.3455
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 68.7739
                       Mean reward: 652.82
               Mean episode length: 234.19
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 136.3156
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.21s
                      Time elapsed: 00:41:04
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 43877 steps/s (collection: 2.119s, learning 0.121s)
             Mean action noise std: 3.56
          Mean value_function loss: 93.1034
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 68.7961
                       Mean reward: 667.86
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.1912
    Episode_Reward/rotating_object: 135.5045
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.24s
                      Time elapsed: 00:41:06
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 44367 steps/s (collection: 2.098s, learning 0.118s)
             Mean action noise std: 3.56
          Mean value_function loss: 93.7864
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.8151
                       Mean reward: 715.09
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.2062
    Episode_Reward/rotating_object: 136.3494
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.22s
                      Time elapsed: 00:41:08
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 42940 steps/s (collection: 2.168s, learning 0.121s)
             Mean action noise std: 3.57
          Mean value_function loss: 101.0534
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 68.8352
                       Mean reward: 691.13
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 135.9192
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.29s
                      Time elapsed: 00:41:11
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 43692 steps/s (collection: 2.130s, learning 0.120s)
             Mean action noise std: 3.57
          Mean value_function loss: 83.8496
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 68.8530
                       Mean reward: 709.75
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 1.2287
    Episode_Reward/rotating_object: 139.0837
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.25s
                      Time elapsed: 00:41:13
                               ETA: 00:18:12

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 42764 steps/s (collection: 2.180s, learning 0.119s)
             Mean action noise std: 3.57
          Mean value_function loss: 98.6340
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.8769
                       Mean reward: 683.14
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 1.1770
    Episode_Reward/rotating_object: 131.0819
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.30s
                      Time elapsed: 00:41:15
                               ETA: 00:18:10

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 41622 steps/s (collection: 2.234s, learning 0.127s)
             Mean action noise std: 3.58
          Mean value_function loss: 91.1903
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.8984
                       Mean reward: 678.61
               Mean episode length: 227.44
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 133.2741
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.36s
                      Time elapsed: 00:41:18
                               ETA: 00:18:08

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 40719 steps/s (collection: 2.292s, learning 0.123s)
             Mean action noise std: 3.58
          Mean value_function loss: 98.4632
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 68.9197
                       Mean reward: 648.45
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.2095
    Episode_Reward/rotating_object: 131.6152
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.41s
                      Time elapsed: 00:41:20
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 41921 steps/s (collection: 2.220s, learning 0.125s)
             Mean action noise std: 3.58
          Mean value_function loss: 109.5563
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.9398
                       Mean reward: 696.39
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 135.6001
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.34s
                      Time elapsed: 00:41:22
                               ETA: 00:18:03

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 41655 steps/s (collection: 2.233s, learning 0.127s)
             Mean action noise std: 3.59
          Mean value_function loss: 95.8320
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.9645
                       Mean reward: 624.63
               Mean episode length: 223.62
    Episode_Reward/reaching_object: 1.1994
    Episode_Reward/rotating_object: 132.4978
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.36s
                      Time elapsed: 00:41:25
                               ETA: 00:18:01

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 41791 steps/s (collection: 2.230s, learning 0.122s)
             Mean action noise std: 3.59
          Mean value_function loss: 96.3005
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 68.9968
                       Mean reward: 718.94
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 133.8184
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.35s
                      Time elapsed: 00:41:27
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 41787 steps/s (collection: 2.234s, learning 0.119s)
             Mean action noise std: 3.59
          Mean value_function loss: 90.8623
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.0147
                       Mean reward: 625.78
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 134.1260
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.35s
                      Time elapsed: 00:41:29
                               ETA: 00:17:56

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 40884 steps/s (collection: 2.279s, learning 0.126s)
             Mean action noise std: 3.59
          Mean value_function loss: 70.4525
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.0328
                       Mean reward: 691.25
               Mean episode length: 241.96
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 134.4662
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.40s
                      Time elapsed: 00:41:32
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 40310 steps/s (collection: 2.312s, learning 0.127s)
             Mean action noise std: 3.60
          Mean value_function loss: 95.5862
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.0524
                       Mean reward: 644.45
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 1.2152
    Episode_Reward/rotating_object: 131.0327
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.44s
                      Time elapsed: 00:41:34
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 40529 steps/s (collection: 2.298s, learning 0.127s)
             Mean action noise std: 3.60
          Mean value_function loss: 70.6171
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.0699
                       Mean reward: 689.28
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 133.9018
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.43s
                      Time elapsed: 00:41:37
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 40149 steps/s (collection: 2.322s, learning 0.126s)
             Mean action noise std: 3.60
          Mean value_function loss: 99.6246
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.0930
                       Mean reward: 707.48
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 1.2025
    Episode_Reward/rotating_object: 132.6840
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.45s
                      Time elapsed: 00:41:39
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 40146 steps/s (collection: 2.322s, learning 0.127s)
             Mean action noise std: 3.61
          Mean value_function loss: 88.1201
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.1059
                       Mean reward: 677.05
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 135.8086
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.45s
                      Time elapsed: 00:41:42
                               ETA: 00:17:44

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 40300 steps/s (collection: 2.313s, learning 0.126s)
             Mean action noise std: 3.61
          Mean value_function loss: 109.0343
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 69.1252
                       Mean reward: 688.75
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 1.2028
    Episode_Reward/rotating_object: 130.5656
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.44s
                      Time elapsed: 00:41:44
                               ETA: 00:17:42

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 39351 steps/s (collection: 2.377s, learning 0.122s)
             Mean action noise std: 3.61
          Mean value_function loss: 103.1696
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.1474
                       Mean reward: 695.21
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.2252
    Episode_Reward/rotating_object: 134.4286
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0569
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.50s
                      Time elapsed: 00:41:46
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 42145 steps/s (collection: 2.214s, learning 0.118s)
             Mean action noise std: 3.62
          Mean value_function loss: 106.2885
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.1708
                       Mean reward: 709.81
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 134.8476
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.33s
                      Time elapsed: 00:41:49
                               ETA: 00:17:37

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 42025 steps/s (collection: 2.217s, learning 0.122s)
             Mean action noise std: 3.62
          Mean value_function loss: 100.6374
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.1975
                       Mean reward: 686.75
               Mean episode length: 225.49
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 133.1995
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.34s
                      Time elapsed: 00:41:51
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 41756 steps/s (collection: 2.236s, learning 0.119s)
             Mean action noise std: 3.62
          Mean value_function loss: 96.6482
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.2233
                       Mean reward: 712.54
               Mean episode length: 233.35
    Episode_Reward/reaching_object: 1.2257
    Episode_Reward/rotating_object: 137.9123
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.35s
                      Time elapsed: 00:41:54
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 41602 steps/s (collection: 2.231s, learning 0.132s)
             Mean action noise std: 3.63
          Mean value_function loss: 99.5903
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 69.2455
                       Mean reward: 696.21
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 132.8864
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.36s
                      Time elapsed: 00:41:56
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 41268 steps/s (collection: 2.255s, learning 0.127s)
             Mean action noise std: 3.63
          Mean value_function loss: 99.0045
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 69.2657
                       Mean reward: 673.15
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 1.2034
    Episode_Reward/rotating_object: 133.1712
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.38s
                      Time elapsed: 00:41:58
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 41104 steps/s (collection: 2.260s, learning 0.132s)
             Mean action noise std: 3.63
          Mean value_function loss: 93.7090
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 69.2907
                       Mean reward: 665.04
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 135.3117
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.39s
                      Time elapsed: 00:42:01
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 41490 steps/s (collection: 2.237s, learning 0.133s)
             Mean action noise std: 3.64
          Mean value_function loss: 102.7483
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 69.3255
                       Mean reward: 668.79
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 131.7990
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.37s
                      Time elapsed: 00:42:03
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 41192 steps/s (collection: 2.257s, learning 0.129s)
             Mean action noise std: 3.64
          Mean value_function loss: 77.4033
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 69.3528
                       Mean reward: 688.69
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 1.2400
    Episode_Reward/rotating_object: 135.8976
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.39s
                      Time elapsed: 00:42:05
                               ETA: 00:17:20

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 40869 steps/s (collection: 2.285s, learning 0.121s)
             Mean action noise std: 3.65
          Mean value_function loss: 83.9237
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 69.3779
                       Mean reward: 702.41
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 136.9546
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.41s
                      Time elapsed: 00:42:08
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 41957 steps/s (collection: 2.225s, learning 0.118s)
             Mean action noise std: 3.65
          Mean value_function loss: 95.9298
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.4082
                       Mean reward: 639.34
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 128.2801
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.34s
                      Time elapsed: 00:42:10
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 40763 steps/s (collection: 2.274s, learning 0.137s)
             Mean action noise std: 3.65
          Mean value_function loss: 85.0268
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 69.4260
                       Mean reward: 700.87
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 134.0584
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.41s
                      Time elapsed: 00:42:13
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 41432 steps/s (collection: 2.252s, learning 0.121s)
             Mean action noise std: 3.65
          Mean value_function loss: 97.7494
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.4448
                       Mean reward: 567.60
               Mean episode length: 216.38
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 125.6742
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.37s
                      Time elapsed: 00:42:15
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 41367 steps/s (collection: 2.257s, learning 0.119s)
             Mean action noise std: 3.66
          Mean value_function loss: 100.0948
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.4627
                       Mean reward: 670.12
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.2207
    Episode_Reward/rotating_object: 134.5391
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.38s
                      Time elapsed: 00:42:17
                               ETA: 00:17:08

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 41108 steps/s (collection: 2.268s, learning 0.123s)
             Mean action noise std: 3.66
          Mean value_function loss: 106.9605
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.4753
                       Mean reward: 673.66
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.1840
    Episode_Reward/rotating_object: 127.1073
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0543
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.39s
                      Time elapsed: 00:42:20
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 43180 steps/s (collection: 2.152s, learning 0.124s)
             Mean action noise std: 3.66
          Mean value_function loss: 96.7915
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.4854
                       Mean reward: 615.45
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.2332
    Episode_Reward/rotating_object: 134.3761
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0560
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.28s
                      Time elapsed: 00:42:22
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 43401 steps/s (collection: 2.141s, learning 0.124s)
             Mean action noise std: 3.66
          Mean value_function loss: 98.3837
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.5004
                       Mean reward: 661.33
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.2214
    Episode_Reward/rotating_object: 134.8698
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.27s
                      Time elapsed: 00:42:24
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 42973 steps/s (collection: 2.163s, learning 0.124s)
             Mean action noise std: 3.67
          Mean value_function loss: 97.5775
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 69.5175
                       Mean reward: 662.13
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 127.7967
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.29s
                      Time elapsed: 00:42:27
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 43082 steps/s (collection: 2.158s, learning 0.124s)
             Mean action noise std: 3.67
          Mean value_function loss: 100.2142
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 69.5385
                       Mean reward: 699.56
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 137.3108
        Episode_Reward/action_rate: -0.0797
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.28s
                      Time elapsed: 00:42:29
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 42767 steps/s (collection: 2.174s, learning 0.124s)
             Mean action noise std: 3.67
          Mean value_function loss: 109.6208
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.5545
                       Mean reward: 697.05
               Mean episode length: 233.04
    Episode_Reward/reaching_object: 1.2151
    Episode_Reward/rotating_object: 134.9193
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.30s
                      Time elapsed: 00:42:31
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 42483 steps/s (collection: 2.189s, learning 0.125s)
             Mean action noise std: 3.67
          Mean value_function loss: 99.2918
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.5710
                       Mean reward: 656.27
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.1815
    Episode_Reward/rotating_object: 129.7609
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.31s
                      Time elapsed: 00:42:33
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 40802 steps/s (collection: 2.278s, learning 0.132s)
             Mean action noise std: 3.68
          Mean value_function loss: 97.3791
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.5909
                       Mean reward: 663.36
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 1.1907
    Episode_Reward/rotating_object: 132.2896
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.41s
                      Time elapsed: 00:42:36
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 41506 steps/s (collection: 2.251s, learning 0.117s)
             Mean action noise std: 3.68
          Mean value_function loss: 89.5846
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 69.6090
                       Mean reward: 649.56
               Mean episode length: 228.06
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 132.6664
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.37s
                      Time elapsed: 00:42:38
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 41212 steps/s (collection: 2.263s, learning 0.122s)
             Mean action noise std: 3.68
          Mean value_function loss: 112.8483
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.6311
                       Mean reward: 708.68
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 135.2517
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.39s
                      Time elapsed: 00:42:41
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 41394 steps/s (collection: 2.253s, learning 0.122s)
             Mean action noise std: 3.69
          Mean value_function loss: 88.9598
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.6521
                       Mean reward: 669.94
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 134.8773
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.37s
                      Time elapsed: 00:42:43
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 41612 steps/s (collection: 2.242s, learning 0.120s)
             Mean action noise std: 3.69
          Mean value_function loss: 92.7459
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.6684
                       Mean reward: 683.94
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 1.2106
    Episode_Reward/rotating_object: 138.3135
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.36s
                      Time elapsed: 00:42:45
                               ETA: 00:16:40

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 41436 steps/s (collection: 2.253s, learning 0.119s)
             Mean action noise std: 3.69
          Mean value_function loss: 96.1315
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.6944
                       Mean reward: 673.32
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.2103
    Episode_Reward/rotating_object: 136.3865
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.37s
                      Time elapsed: 00:42:48
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 41504 steps/s (collection: 2.248s, learning 0.121s)
             Mean action noise std: 3.70
          Mean value_function loss: 97.7185
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.7253
                       Mean reward: 670.82
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.2218
    Episode_Reward/rotating_object: 131.9194
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.37s
                      Time elapsed: 00:42:50
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 41708 steps/s (collection: 2.234s, learning 0.123s)
             Mean action noise std: 3.70
          Mean value_function loss: 103.6036
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.7450
                       Mean reward: 640.24
               Mean episode length: 225.96
    Episode_Reward/reaching_object: 1.2308
    Episode_Reward/rotating_object: 131.6743
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0588
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.36s
                      Time elapsed: 00:42:52
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 41553 steps/s (collection: 2.240s, learning 0.125s)
             Mean action noise std: 3.70
          Mean value_function loss: 126.3539
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.7605
                       Mean reward: 629.41
               Mean episode length: 226.73
    Episode_Reward/reaching_object: 1.1835
    Episode_Reward/rotating_object: 127.9337
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0540
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.37s
                      Time elapsed: 00:42:55
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 40508 steps/s (collection: 2.303s, learning 0.123s)
             Mean action noise std: 3.71
          Mean value_function loss: 95.6994
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 69.7837
                       Mean reward: 632.73
               Mean episode length: 223.67
    Episode_Reward/reaching_object: 1.2183
    Episode_Reward/rotating_object: 136.5796
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.43s
                      Time elapsed: 00:42:57
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 41161 steps/s (collection: 2.258s, learning 0.130s)
             Mean action noise std: 3.71
          Mean value_function loss: 99.5489
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.8077
                       Mean reward: 650.32
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.2202
    Episode_Reward/rotating_object: 135.2569
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.39s
                      Time elapsed: 00:43:00
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 40922 steps/s (collection: 2.269s, learning 0.133s)
             Mean action noise std: 3.71
          Mean value_function loss: 105.8868
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.8346
                       Mean reward: 661.86
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 127.4527
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.40s
                      Time elapsed: 00:43:02
                               ETA: 00:16:23

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 41507 steps/s (collection: 2.237s, learning 0.132s)
             Mean action noise std: 3.72
          Mean value_function loss: 94.7769
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.8661
                       Mean reward: 685.80
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.1995
    Episode_Reward/rotating_object: 132.5151
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.37s
                      Time elapsed: 00:43:04
                               ETA: 00:16:21

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 40954 steps/s (collection: 2.274s, learning 0.127s)
             Mean action noise std: 3.72
          Mean value_function loss: 97.8800
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.8865
                       Mean reward: 685.82
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.1877
    Episode_Reward/rotating_object: 128.1086
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.40s
                      Time elapsed: 00:43:07
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 40281 steps/s (collection: 2.315s, learning 0.126s)
             Mean action noise std: 3.72
          Mean value_function loss: 99.4478
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 69.9056
                       Mean reward: 723.69
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.2217
    Episode_Reward/rotating_object: 133.3229
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.44s
                      Time elapsed: 00:43:09
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 40290 steps/s (collection: 2.313s, learning 0.127s)
             Mean action noise std: 3.73
          Mean value_function loss: 107.6331
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.9283
                       Mean reward: 671.40
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 1.2189
    Episode_Reward/rotating_object: 134.5235
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.44s
                      Time elapsed: 00:43:12
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 40445 steps/s (collection: 2.305s, learning 0.126s)
             Mean action noise std: 3.73
          Mean value_function loss: 105.8879
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.9496
                       Mean reward: 630.51
               Mean episode length: 224.28
    Episode_Reward/reaching_object: 1.1920
    Episode_Reward/rotating_object: 127.3295
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0560
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.43s
                      Time elapsed: 00:43:14
                               ETA: 00:16:11

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 39939 steps/s (collection: 2.335s, learning 0.126s)
             Mean action noise std: 3.73
          Mean value_function loss: 99.2249
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 69.9679
                       Mean reward: 677.55
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 1.2121
    Episode_Reward/rotating_object: 128.5744
        Episode_Reward/action_rate: -0.0811
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.46s
                      Time elapsed: 00:43:17
                               ETA: 00:16:09

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 39960 steps/s (collection: 2.334s, learning 0.126s)
             Mean action noise std: 3.74
          Mean value_function loss: 99.0140
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 69.9922
                       Mean reward: 712.28
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.2431
    Episode_Reward/rotating_object: 137.2813
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.46s
                      Time elapsed: 00:43:19
                               ETA: 00:16:07

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 41487 steps/s (collection: 2.249s, learning 0.120s)
             Mean action noise std: 3.74
          Mean value_function loss: 104.9861
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.0166
                       Mean reward: 647.19
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 130.8750
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.37s
                      Time elapsed: 00:43:21
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 41540 steps/s (collection: 2.243s, learning 0.123s)
             Mean action noise std: 3.74
          Mean value_function loss: 100.2189
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 70.0329
                       Mean reward: 626.05
               Mean episode length: 222.63
    Episode_Reward/reaching_object: 1.1881
    Episode_Reward/rotating_object: 128.0628
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.37s
                      Time elapsed: 00:43:24
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 40676 steps/s (collection: 2.289s, learning 0.127s)
             Mean action noise std: 3.74
          Mean value_function loss: 91.2616
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.0466
                       Mean reward: 710.17
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.2554
    Episode_Reward/rotating_object: 137.7331
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.42s
                      Time elapsed: 00:43:26
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 41026 steps/s (collection: 2.269s, learning 0.127s)
             Mean action noise std: 3.75
          Mean value_function loss: 90.3925
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.0650
                       Mean reward: 688.43
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.2208
    Episode_Reward/rotating_object: 132.2737
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.40s
                      Time elapsed: 00:43:29
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 41570 steps/s (collection: 2.245s, learning 0.119s)
             Mean action noise std: 3.75
          Mean value_function loss: 92.4192
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 70.0801
                       Mean reward: 661.13
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 132.2068
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.36s
                      Time elapsed: 00:43:31
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 41378 steps/s (collection: 2.258s, learning 0.118s)
             Mean action noise std: 3.75
          Mean value_function loss: 92.1923
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 70.0926
                       Mean reward: 629.39
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.2385
    Episode_Reward/rotating_object: 131.6389
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.38s
                      Time elapsed: 00:43:33
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 41703 steps/s (collection: 2.239s, learning 0.118s)
             Mean action noise std: 3.75
          Mean value_function loss: 104.4860
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.1131
                       Mean reward: 648.03
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 1.2234
    Episode_Reward/rotating_object: 131.1221
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.36s
                      Time elapsed: 00:43:36
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 41429 steps/s (collection: 2.237s, learning 0.136s)
             Mean action noise std: 3.76
          Mean value_function loss: 87.4542
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.1363
                       Mean reward: 669.04
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 1.2295
    Episode_Reward/rotating_object: 131.7309
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.37s
                      Time elapsed: 00:43:38
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 41787 steps/s (collection: 2.233s, learning 0.120s)
             Mean action noise std: 3.76
          Mean value_function loss: 107.1717
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.1565
                       Mean reward: 671.43
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 131.4597
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.35s
                      Time elapsed: 00:43:40
                               ETA: 00:15:45

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 41672 steps/s (collection: 2.237s, learning 0.122s)
             Mean action noise std: 3.76
          Mean value_function loss: 81.4669
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.1762
                       Mean reward: 644.78
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 1.2193
    Episode_Reward/rotating_object: 130.9090
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0574
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.36s
                      Time elapsed: 00:43:43
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 41787 steps/s (collection: 2.233s, learning 0.119s)
             Mean action noise std: 3.77
          Mean value_function loss: 92.4123
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.2008
                       Mean reward: 662.11
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 135.1068
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.35s
                      Time elapsed: 00:43:45
                               ETA: 00:15:40

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 41483 steps/s (collection: 2.249s, learning 0.121s)
             Mean action noise std: 3.77
          Mean value_function loss: 104.5608
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.2298
                       Mean reward: 675.34
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 135.3370
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.37s
                      Time elapsed: 00:43:47
                               ETA: 00:15:38

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 41467 steps/s (collection: 2.251s, learning 0.120s)
             Mean action noise std: 3.78
          Mean value_function loss: 100.6112
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.2522
                       Mean reward: 645.14
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 134.4829
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.37s
                      Time elapsed: 00:43:50
                               ETA: 00:15:36

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 41818 steps/s (collection: 2.227s, learning 0.124s)
             Mean action noise std: 3.78
          Mean value_function loss: 115.4728
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.2696
                       Mean reward: 657.61
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.2205
    Episode_Reward/rotating_object: 134.9138
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.35s
                      Time elapsed: 00:43:52
                               ETA: 00:15:33

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 41315 steps/s (collection: 2.251s, learning 0.128s)
             Mean action noise std: 3.78
          Mean value_function loss: 107.6645
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.2898
                       Mean reward: 667.85
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 134.3703
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.38s
                      Time elapsed: 00:43:55
                               ETA: 00:15:31

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 40598 steps/s (collection: 2.304s, learning 0.118s)
             Mean action noise std: 3.78
          Mean value_function loss: 108.7470
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 70.3071
                       Mean reward: 682.94
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 129.9926
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.42s
                      Time elapsed: 00:43:57
                               ETA: 00:15:29

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 41386 steps/s (collection: 2.257s, learning 0.118s)
             Mean action noise std: 3.79
          Mean value_function loss: 103.7305
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.3216
                       Mean reward: 704.49
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 1.2296
    Episode_Reward/rotating_object: 132.8871
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.38s
                      Time elapsed: 00:43:59
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 40818 steps/s (collection: 2.282s, learning 0.127s)
             Mean action noise std: 3.79
          Mean value_function loss: 104.0627
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.3384
                       Mean reward: 637.95
               Mean episode length: 226.67
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 131.6225
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.41s
                      Time elapsed: 00:44:02
                               ETA: 00:15:24

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 39990 steps/s (collection: 2.331s, learning 0.127s)
             Mean action noise std: 3.79
          Mean value_function loss: 97.5458
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.3604
                       Mean reward: 639.03
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 130.7456
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.46s
                      Time elapsed: 00:44:04
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 40574 steps/s (collection: 2.304s, learning 0.119s)
             Mean action noise std: 3.80
          Mean value_function loss: 90.6179
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 70.3830
                       Mean reward: 677.97
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.2267
    Episode_Reward/rotating_object: 134.3999
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.42s
                      Time elapsed: 00:44:07
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 41748 steps/s (collection: 2.236s, learning 0.119s)
             Mean action noise std: 3.80
          Mean value_function loss: 95.9191
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.4033
                       Mean reward: 676.69
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.2276
    Episode_Reward/rotating_object: 131.0091
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.35s
                      Time elapsed: 00:44:09
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 41616 steps/s (collection: 2.243s, learning 0.119s)
             Mean action noise std: 3.80
          Mean value_function loss: 96.8237
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.4163
                       Mean reward: 687.39
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.2402
    Episode_Reward/rotating_object: 138.0673
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.36s
                      Time elapsed: 00:44:11
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 41608 steps/s (collection: 2.242s, learning 0.120s)
             Mean action noise std: 3.80
          Mean value_function loss: 92.7781
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.4334
                       Mean reward: 641.96
               Mean episode length: 225.97
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 132.3534
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.36s
                      Time elapsed: 00:44:14
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 41765 steps/s (collection: 2.234s, learning 0.120s)
             Mean action noise std: 3.81
          Mean value_function loss: 105.8453
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.4528
                       Mean reward: 615.25
               Mean episode length: 223.51
    Episode_Reward/reaching_object: 1.1960
    Episode_Reward/rotating_object: 127.4646
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.35s
                      Time elapsed: 00:44:16
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 41906 steps/s (collection: 2.229s, learning 0.117s)
             Mean action noise std: 3.81
          Mean value_function loss: 88.7312
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 70.4678
                       Mean reward: 678.50
               Mean episode length: 228.72
    Episode_Reward/reaching_object: 1.2143
    Episode_Reward/rotating_object: 134.5253
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.35s
                      Time elapsed: 00:44:18
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 41508 steps/s (collection: 2.247s, learning 0.121s)
             Mean action noise std: 3.81
          Mean value_function loss: 95.7339
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 70.4877
                       Mean reward: 711.87
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 1.2183
    Episode_Reward/rotating_object: 136.4995
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.37s
                      Time elapsed: 00:44:21
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 41755 steps/s (collection: 2.234s, learning 0.120s)
             Mean action noise std: 3.82
          Mean value_function loss: 98.8961
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.5069
                       Mean reward: 658.61
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 132.5617
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.35s
                      Time elapsed: 00:44:23
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 41807 steps/s (collection: 2.227s, learning 0.124s)
             Mean action noise std: 3.82
          Mean value_function loss: 84.8716
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 70.5300
                       Mean reward: 647.23
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.2076
    Episode_Reward/rotating_object: 134.4036
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.35s
                      Time elapsed: 00:44:25
                               ETA: 00:15:00

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 41539 steps/s (collection: 2.246s, learning 0.120s)
             Mean action noise std: 3.82
          Mean value_function loss: 100.8134
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 70.5489
                       Mean reward: 680.99
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 138.0641
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.37s
                      Time elapsed: 00:44:28
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 41589 steps/s (collection: 2.242s, learning 0.121s)
             Mean action noise std: 3.82
          Mean value_function loss: 107.2876
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 70.5657
                       Mean reward: 675.20
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 133.5336
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.36s
                      Time elapsed: 00:44:30
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 41834 steps/s (collection: 2.230s, learning 0.120s)
             Mean action noise std: 3.83
          Mean value_function loss: 111.7228
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.5874
                       Mean reward: 708.04
               Mean episode length: 234.23
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 134.2472
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.35s
                      Time elapsed: 00:44:33
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 41780 steps/s (collection: 2.232s, learning 0.121s)
             Mean action noise std: 3.83
          Mean value_function loss: 109.4836
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.6106
                       Mean reward: 653.09
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 133.8046
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.35s
                      Time elapsed: 00:44:35
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 41880 steps/s (collection: 2.226s, learning 0.121s)
             Mean action noise std: 3.83
          Mean value_function loss: 102.2150
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 70.6286
                       Mean reward: 602.60
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 1.1949
    Episode_Reward/rotating_object: 128.4158
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.35s
                      Time elapsed: 00:44:37
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 41457 steps/s (collection: 2.248s, learning 0.123s)
             Mean action noise std: 3.84
          Mean value_function loss: 89.0878
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 70.6499
                       Mean reward: 664.42
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 133.6391
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.37s
                      Time elapsed: 00:44:40
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 41667 steps/s (collection: 2.224s, learning 0.135s)
             Mean action noise std: 3.84
          Mean value_function loss: 84.1453
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.6700
                       Mean reward: 629.06
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 1.2252
    Episode_Reward/rotating_object: 135.5511
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.36s
                      Time elapsed: 00:44:42
                               ETA: 00:14:43

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 41563 steps/s (collection: 2.247s, learning 0.118s)
             Mean action noise std: 3.84
          Mean value_function loss: 109.9701
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 70.6879
                       Mean reward: 671.85
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 1.1987
    Episode_Reward/rotating_object: 133.5745
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.37s
                      Time elapsed: 00:44:44
                               ETA: 00:14:41

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 40172 steps/s (collection: 2.323s, learning 0.124s)
             Mean action noise std: 3.85
          Mean value_function loss: 98.6507
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.7040
                       Mean reward: 701.70
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 136.4594
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.45s
                      Time elapsed: 00:44:47
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 40855 steps/s (collection: 2.280s, learning 0.126s)
             Mean action noise std: 3.85
          Mean value_function loss: 90.9965
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.7222
                       Mean reward: 719.91
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 1.2115
    Episode_Reward/rotating_object: 131.7720
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.41s
                      Time elapsed: 00:44:49
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 42540 steps/s (collection: 2.198s, learning 0.113s)
             Mean action noise std: 3.85
          Mean value_function loss: 117.0143
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.7419
                       Mean reward: 640.81
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.1820
    Episode_Reward/rotating_object: 128.8067
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.31s
                      Time elapsed: 00:44:52
                               ETA: 00:14:34

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 43693 steps/s (collection: 2.139s, learning 0.111s)
             Mean action noise std: 3.85
          Mean value_function loss: 106.7071
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.7670
                       Mean reward: 643.58
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 127.9246
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.25s
                      Time elapsed: 00:44:54
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 42984 steps/s (collection: 2.168s, learning 0.119s)
             Mean action noise std: 3.86
          Mean value_function loss: 107.9954
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.7884
                       Mean reward: 647.94
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 127.6151
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.29s
                      Time elapsed: 00:44:56
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 41600 steps/s (collection: 2.241s, learning 0.122s)
             Mean action noise std: 3.86
          Mean value_function loss: 93.2007
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 70.8168
                       Mean reward: 671.86
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 133.6894
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.36s
                      Time elapsed: 00:44:58
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 41738 steps/s (collection: 2.234s, learning 0.122s)
             Mean action noise std: 3.87
          Mean value_function loss: 92.4453
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 70.8419
                       Mean reward: 686.55
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.1904
    Episode_Reward/rotating_object: 128.5252
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.36s
                      Time elapsed: 00:45:01
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 41641 steps/s (collection: 2.233s, learning 0.127s)
             Mean action noise std: 3.87
          Mean value_function loss: 113.2693
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 70.8695
                       Mean reward: 631.25
               Mean episode length: 222.39
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 132.1378
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.36s
                      Time elapsed: 00:45:03
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 41740 steps/s (collection: 2.235s, learning 0.120s)
             Mean action noise std: 3.87
          Mean value_function loss: 97.1267
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.8875
                       Mean reward: 666.58
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 1.2194
    Episode_Reward/rotating_object: 134.0350
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.36s
                      Time elapsed: 00:45:06
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 41161 steps/s (collection: 2.268s, learning 0.121s)
             Mean action noise std: 3.88
          Mean value_function loss: 97.5852
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.9049
                       Mean reward: 652.87
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 134.5691
        Episode_Reward/action_rate: -0.0889
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.39s
                      Time elapsed: 00:45:08
                               ETA: 00:14:17

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 41428 steps/s (collection: 2.249s, learning 0.124s)
             Mean action noise std: 3.88
          Mean value_function loss: 98.9070
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.9230
                       Mean reward: 700.00
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.2092
    Episode_Reward/rotating_object: 133.9569
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0569
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.37s
                      Time elapsed: 00:45:10
                               ETA: 00:14:15

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 41643 steps/s (collection: 2.238s, learning 0.122s)
             Mean action noise std: 3.88
          Mean value_function loss: 92.5678
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.9362
                       Mean reward: 707.92
               Mean episode length: 235.94
    Episode_Reward/reaching_object: 1.2168
    Episode_Reward/rotating_object: 133.6247
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.36s
                      Time elapsed: 00:45:13
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 41706 steps/s (collection: 2.234s, learning 0.123s)
             Mean action noise std: 3.88
          Mean value_function loss: 81.3977
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.9514
                       Mean reward: 673.19
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.1931
    Episode_Reward/rotating_object: 128.4780
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.36s
                      Time elapsed: 00:45:15
                               ETA: 00:14:10

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 41708 steps/s (collection: 2.235s, learning 0.122s)
             Mean action noise std: 3.88
          Mean value_function loss: 94.3176
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.9638
                       Mean reward: 668.46
               Mean episode length: 226.33
    Episode_Reward/reaching_object: 1.1943
    Episode_Reward/rotating_object: 134.4247
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0583
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.36s
                      Time elapsed: 00:45:17
                               ETA: 00:14:08

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 42242 steps/s (collection: 2.207s, learning 0.121s)
             Mean action noise std: 3.89
          Mean value_function loss: 95.7879
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.9818
                       Mean reward: 629.51
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.2115
    Episode_Reward/rotating_object: 134.5459
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0582
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.33s
                      Time elapsed: 00:45:20
                               ETA: 00:14:05

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 42342 steps/s (collection: 2.200s, learning 0.122s)
             Mean action noise std: 3.89
          Mean value_function loss: 86.8536
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.0063
                       Mean reward: 691.69
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.2121
    Episode_Reward/rotating_object: 138.3492
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.32s
                      Time elapsed: 00:45:22
                               ETA: 00:14:03

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 42338 steps/s (collection: 2.202s, learning 0.120s)
             Mean action noise std: 3.90
          Mean value_function loss: 91.7088
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.0261
                       Mean reward: 669.47
               Mean episode length: 230.21
    Episode_Reward/reaching_object: 1.1911
    Episode_Reward/rotating_object: 129.7964
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.32s
                      Time elapsed: 00:45:24
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 42607 steps/s (collection: 2.187s, learning 0.121s)
             Mean action noise std: 3.90
          Mean value_function loss: 77.9852
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.0433
                       Mean reward: 705.81
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.1998
    Episode_Reward/rotating_object: 134.1332
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0597
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.31s
                      Time elapsed: 00:45:27
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 42576 steps/s (collection: 2.190s, learning 0.119s)
             Mean action noise std: 3.90
          Mean value_function loss: 103.7899
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.0642
                       Mean reward: 672.00
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 1.2241
    Episode_Reward/rotating_object: 137.1913
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.31s
                      Time elapsed: 00:45:29
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 40907 steps/s (collection: 2.276s, learning 0.127s)
             Mean action noise std: 3.91
          Mean value_function loss: 86.7410
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.0863
                       Mean reward: 722.24
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 136.8640
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.40s
                      Time elapsed: 00:45:31
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 40487 steps/s (collection: 2.296s, learning 0.132s)
             Mean action noise std: 3.91
          Mean value_function loss: 88.1742
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 71.1067
                       Mean reward: 760.93
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 139.1552
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.43s
                      Time elapsed: 00:45:34
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 40322 steps/s (collection: 2.311s, learning 0.127s)
             Mean action noise std: 3.91
          Mean value_function loss: 88.0603
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 71.1142
                       Mean reward: 683.39
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 134.3896
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.44s
                      Time elapsed: 00:45:36
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 40887 steps/s (collection: 2.278s, learning 0.126s)
             Mean action noise std: 3.91
          Mean value_function loss: 97.6502
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.1333
                       Mean reward: 642.62
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 131.1215
        Episode_Reward/action_rate: -0.0893
          Episode_Reward/joint_vel: -0.0588
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.40s
                      Time elapsed: 00:45:39
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 40764 steps/s (collection: 2.296s, learning 0.116s)
             Mean action noise std: 3.92
          Mean value_function loss: 81.8167
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.1638
                       Mean reward: 677.13
               Mean episode length: 228.07
    Episode_Reward/reaching_object: 1.1898
    Episode_Reward/rotating_object: 134.5447
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.41s
                      Time elapsed: 00:45:41
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 43443 steps/s (collection: 2.150s, learning 0.113s)
             Mean action noise std: 3.92
          Mean value_function loss: 105.4020
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 71.1886
                       Mean reward: 676.89
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.1731
    Episode_Reward/rotating_object: 131.4402
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.26s
                      Time elapsed: 00:45:43
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 42076 steps/s (collection: 2.217s, learning 0.120s)
             Mean action noise std: 3.92
          Mean value_function loss: 100.9868
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.2147
                       Mean reward: 690.53
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 1.2035
    Episode_Reward/rotating_object: 137.6524
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.34s
                      Time elapsed: 00:45:46
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 41294 steps/s (collection: 2.247s, learning 0.133s)
             Mean action noise std: 3.93
          Mean value_function loss: 84.0009
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 71.2356
                       Mean reward: 691.22
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.1739
    Episode_Reward/rotating_object: 134.9687
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.38s
                      Time elapsed: 00:45:48
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 42188 steps/s (collection: 2.209s, learning 0.121s)
             Mean action noise std: 3.93
          Mean value_function loss: 91.5560
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.2546
                       Mean reward: 663.72
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.2108
    Episode_Reward/rotating_object: 135.6359
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0582
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.33s
                      Time elapsed: 00:45:50
                               ETA: 00:13:34

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 42172 steps/s (collection: 2.208s, learning 0.123s)
             Mean action noise std: 3.93
          Mean value_function loss: 82.3053
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.2692
                       Mean reward: 710.85
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 1.1967
    Episode_Reward/rotating_object: 134.8462
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.33s
                      Time elapsed: 00:45:53
                               ETA: 00:13:32

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 42015 steps/s (collection: 2.213s, learning 0.126s)
             Mean action noise std: 3.93
          Mean value_function loss: 80.6947
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.2830
                       Mean reward: 685.19
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 1.1941
    Episode_Reward/rotating_object: 133.6239
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.34s
                      Time elapsed: 00:45:55
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 42066 steps/s (collection: 2.216s, learning 0.121s)
             Mean action noise std: 3.94
          Mean value_function loss: 92.2843
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.3001
                       Mean reward: 702.57
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.1963
    Episode_Reward/rotating_object: 135.2629
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.34s
                      Time elapsed: 00:45:57
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 41915 steps/s (collection: 2.224s, learning 0.122s)
             Mean action noise std: 3.94
          Mean value_function loss: 101.1182
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.3199
                       Mean reward: 654.79
               Mean episode length: 222.93
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 137.8967
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.35s
                      Time elapsed: 00:46:00
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 41891 steps/s (collection: 2.226s, learning 0.121s)
             Mean action noise std: 3.95
          Mean value_function loss: 76.4795
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.3489
                       Mean reward: 668.90
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.1891
    Episode_Reward/rotating_object: 134.0147
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0583
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.35s
                      Time elapsed: 00:46:02
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 41776 steps/s (collection: 2.231s, learning 0.122s)
             Mean action noise std: 3.95
          Mean value_function loss: 90.2498
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.3728
                       Mean reward: 663.90
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 1.1792
    Episode_Reward/rotating_object: 132.8550
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.35s
                      Time elapsed: 00:46:04
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 41230 steps/s (collection: 2.249s, learning 0.135s)
             Mean action noise std: 3.95
          Mean value_function loss: 89.1570
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 71.3856
                       Mean reward: 676.02
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.2025
    Episode_Reward/rotating_object: 135.1755
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.38s
                      Time elapsed: 00:46:07
                               ETA: 00:13:18

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 42153 steps/s (collection: 2.212s, learning 0.120s)
             Mean action noise std: 3.95
          Mean value_function loss: 84.9986
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.3937
                       Mean reward: 677.43
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 1.1859
    Episode_Reward/rotating_object: 135.8642
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.33s
                      Time elapsed: 00:46:09
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 42139 steps/s (collection: 2.211s, learning 0.122s)
             Mean action noise std: 3.95
          Mean value_function loss: 96.3333
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.4096
                       Mean reward: 662.63
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.1928
    Episode_Reward/rotating_object: 134.5003
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0584
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.33s
                      Time elapsed: 00:46:11
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 41928 steps/s (collection: 2.223s, learning 0.121s)
             Mean action noise std: 3.96
          Mean value_function loss: 92.1903
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 71.4319
                       Mean reward: 685.93
               Mean episode length: 230.36
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 136.0272
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.34s
                      Time elapsed: 00:46:14
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 42257 steps/s (collection: 2.205s, learning 0.121s)
             Mean action noise std: 3.96
          Mean value_function loss: 86.6113
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.4557
                       Mean reward: 677.87
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 137.5305
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.33s
                      Time elapsed: 00:46:16
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 41843 steps/s (collection: 2.228s, learning 0.121s)
             Mean action noise std: 3.96
          Mean value_function loss: 85.3800
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.4723
                       Mean reward: 678.03
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 1.1941
    Episode_Reward/rotating_object: 139.2966
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.35s
                      Time elapsed: 00:46:18
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 42233 steps/s (collection: 2.204s, learning 0.123s)
             Mean action noise std: 3.97
          Mean value_function loss: 84.7623
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.4889
                       Mean reward: 706.46
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.1976
    Episode_Reward/rotating_object: 135.1201
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.33s
                      Time elapsed: 00:46:21
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 41351 steps/s (collection: 2.251s, learning 0.126s)
             Mean action noise std: 3.97
          Mean value_function loss: 79.6993
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.5041
                       Mean reward: 686.03
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 137.0721
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.38s
                      Time elapsed: 00:46:23
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 40877 steps/s (collection: 2.278s, learning 0.127s)
             Mean action noise std: 3.97
          Mean value_function loss: 90.0688
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.5200
                       Mean reward: 683.25
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 138.5370
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.40s
                      Time elapsed: 00:46:26
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 41016 steps/s (collection: 2.271s, learning 0.126s)
             Mean action noise std: 3.97
          Mean value_function loss: 83.2469
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.5341
                       Mean reward: 691.77
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 1.2160
    Episode_Reward/rotating_object: 138.5343
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.40s
                      Time elapsed: 00:46:28
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 40402 steps/s (collection: 2.305s, learning 0.129s)
             Mean action noise std: 3.98
          Mean value_function loss: 95.4800
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.5542
                       Mean reward: 699.58
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.1738
    Episode_Reward/rotating_object: 134.2482
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.43s
                      Time elapsed: 00:46:30
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 40320 steps/s (collection: 2.308s, learning 0.130s)
             Mean action noise std: 3.98
          Mean value_function loss: 90.5524
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.5789
                       Mean reward: 694.39
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 133.6367
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.44s
                      Time elapsed: 00:46:33
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 41778 steps/s (collection: 2.233s, learning 0.120s)
             Mean action noise std: 3.99
          Mean value_function loss: 96.6028
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.6030
                       Mean reward: 671.60
               Mean episode length: 236.07
    Episode_Reward/reaching_object: 1.1879
    Episode_Reward/rotating_object: 134.9100
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.35s
                      Time elapsed: 00:46:35
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 41787 steps/s (collection: 2.231s, learning 0.122s)
             Mean action noise std: 3.99
          Mean value_function loss: 98.0530
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.6226
                       Mean reward: 662.78
               Mean episode length: 221.36
    Episode_Reward/reaching_object: 1.1561
    Episode_Reward/rotating_object: 132.4243
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.35s
                      Time elapsed: 00:46:38
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 41675 steps/s (collection: 2.238s, learning 0.121s)
             Mean action noise std: 3.99
          Mean value_function loss: 98.8548
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.6409
                       Mean reward: 655.52
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.1699
    Episode_Reward/rotating_object: 132.9957
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.36s
                      Time elapsed: 00:46:40
                               ETA: 00:12:44

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 42157 steps/s (collection: 2.209s, learning 0.122s)
             Mean action noise std: 3.99
          Mean value_function loss: 92.1846
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.6603
                       Mean reward: 657.51
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 133.5773
        Episode_Reward/action_rate: -0.0935
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.33s
                      Time elapsed: 00:46:42
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 41807 steps/s (collection: 2.228s, learning 0.124s)
             Mean action noise std: 4.00
          Mean value_function loss: 103.1571
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.6772
                       Mean reward: 665.61
               Mean episode length: 221.63
    Episode_Reward/reaching_object: 1.1599
    Episode_Reward/rotating_object: 133.1640
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.35s
                      Time elapsed: 00:46:45
                               ETA: 00:12:40

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 41307 steps/s (collection: 2.258s, learning 0.122s)
             Mean action noise std: 4.00
          Mean value_function loss: 106.4205
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.6940
                       Mean reward: 682.67
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.1809
    Episode_Reward/rotating_object: 138.1872
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.38s
                      Time elapsed: 00:46:47
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 41775 steps/s (collection: 2.219s, learning 0.134s)
             Mean action noise std: 4.00
          Mean value_function loss: 95.3942
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.7141
                       Mean reward: 675.37
               Mean episode length: 229.93
    Episode_Reward/reaching_object: 1.1737
    Episode_Reward/rotating_object: 133.5218
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.35s
                      Time elapsed: 00:46:49
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 41908 steps/s (collection: 2.225s, learning 0.121s)
             Mean action noise std: 4.01
          Mean value_function loss: 99.1514
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.7444
                       Mean reward: 627.53
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 1.1757
    Episode_Reward/rotating_object: 132.5214
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.35s
                      Time elapsed: 00:46:52
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 42543 steps/s (collection: 2.196s, learning 0.114s)
             Mean action noise std: 4.01
          Mean value_function loss: 91.3417
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.7793
                       Mean reward: 690.08
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.1752
    Episode_Reward/rotating_object: 138.0295
        Episode_Reward/action_rate: -0.0933
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.31s
                      Time elapsed: 00:46:54
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 41943 steps/s (collection: 2.225s, learning 0.119s)
             Mean action noise std: 4.02
          Mean value_function loss: 100.1984
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.8091
                       Mean reward: 675.48
               Mean episode length: 232.32
    Episode_Reward/reaching_object: 1.1690
    Episode_Reward/rotating_object: 134.7548
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.34s
                      Time elapsed: 00:46:56
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 41896 steps/s (collection: 2.224s, learning 0.123s)
             Mean action noise std: 4.02
          Mean value_function loss: 110.7576
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.8262
                       Mean reward: 673.89
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 1.1517
    Episode_Reward/rotating_object: 129.8694
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.35s
                      Time elapsed: 00:46:59
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 42377 steps/s (collection: 2.191s, learning 0.128s)
             Mean action noise std: 4.02
          Mean value_function loss: 107.1516
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.8420
                       Mean reward: 672.74
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 133.8276
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.32s
                      Time elapsed: 00:47:01
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 42289 steps/s (collection: 2.201s, learning 0.124s)
             Mean action noise std: 4.02
          Mean value_function loss: 108.3885
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.8549
                       Mean reward: 682.56
               Mean episode length: 234.10
    Episode_Reward/reaching_object: 1.1821
    Episode_Reward/rotating_object: 136.0511
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.32s
                      Time elapsed: 00:47:03
                               ETA: 00:12:20

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 41518 steps/s (collection: 2.242s, learning 0.126s)
             Mean action noise std: 4.03
          Mean value_function loss: 125.4459
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 71.8706
                       Mean reward: 639.10
               Mean episode length: 224.99
    Episode_Reward/reaching_object: 1.1598
    Episode_Reward/rotating_object: 130.0946
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.37s
                      Time elapsed: 00:47:06
                               ETA: 00:12:18

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 40803 steps/s (collection: 2.284s, learning 0.126s)
             Mean action noise std: 4.03
          Mean value_function loss: 104.2586
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 71.8892
                       Mean reward: 697.41
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.1633
    Episode_Reward/rotating_object: 130.1817
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.41s
                      Time elapsed: 00:47:08
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 40574 steps/s (collection: 2.289s, learning 0.134s)
             Mean action noise std: 4.03
          Mean value_function loss: 103.9618
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.9032
                       Mean reward: 638.04
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 1.1721
    Episode_Reward/rotating_object: 131.3015
        Episode_Reward/action_rate: -0.0935
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.42s
                      Time elapsed: 00:47:10
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 40844 steps/s (collection: 2.281s, learning 0.126s)
             Mean action noise std: 4.03
          Mean value_function loss: 100.4922
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.9165
                       Mean reward: 645.72
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 1.1513
    Episode_Reward/rotating_object: 128.4528
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.41s
                      Time elapsed: 00:47:13
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 40381 steps/s (collection: 2.309s, learning 0.125s)
             Mean action noise std: 4.04
          Mean value_function loss: 103.1052
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.9364
                       Mean reward: 671.76
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 1.1759
    Episode_Reward/rotating_object: 135.7570
        Episode_Reward/action_rate: -0.0941
          Episode_Reward/joint_vel: -0.0560
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.43s
                      Time elapsed: 00:47:15
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 40490 steps/s (collection: 2.301s, learning 0.127s)
             Mean action noise std: 4.04
          Mean value_function loss: 96.1584
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.9621
                       Mean reward: 658.06
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.1931
    Episode_Reward/rotating_object: 134.6400
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.43s
                      Time elapsed: 00:47:18
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 41739 steps/s (collection: 2.233s, learning 0.122s)
             Mean action noise std: 4.04
          Mean value_function loss: 96.7366
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 71.9789
                       Mean reward: 691.20
               Mean episode length: 230.99
    Episode_Reward/reaching_object: 1.2008
    Episode_Reward/rotating_object: 134.5466
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.36s
                      Time elapsed: 00:47:20
                               ETA: 00:12:04

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 41269 steps/s (collection: 2.248s, learning 0.134s)
             Mean action noise std: 4.05
          Mean value_function loss: 106.0838
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 71.9878
                       Mean reward: 656.55
               Mean episode length: 230.62
    Episode_Reward/reaching_object: 1.1503
    Episode_Reward/rotating_object: 128.5257
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.38s
                      Time elapsed: 00:47:22
                               ETA: 00:12:02

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 41796 steps/s (collection: 2.228s, learning 0.124s)
             Mean action noise std: 4.05
          Mean value_function loss: 107.3406
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.9977
                       Mean reward: 696.26
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 134.2790
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.35s
                      Time elapsed: 00:47:25
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 42207 steps/s (collection: 2.207s, learning 0.123s)
             Mean action noise std: 4.05
          Mean value_function loss: 96.8923
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.0127
                       Mean reward: 653.24
               Mean episode length: 226.07
    Episode_Reward/reaching_object: 1.1633
    Episode_Reward/rotating_object: 129.9983
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.33s
                      Time elapsed: 00:47:27
                               ETA: 00:11:57

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 42408 steps/s (collection: 2.197s, learning 0.121s)
             Mean action noise std: 4.05
          Mean value_function loss: 94.0837
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.0298
                       Mean reward: 704.10
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 1.2076
    Episode_Reward/rotating_object: 135.7061
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.32s
                      Time elapsed: 00:47:29
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 42534 steps/s (collection: 2.190s, learning 0.121s)
             Mean action noise std: 4.06
          Mean value_function loss: 86.3087
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.0433
                       Mean reward: 701.17
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.1812
    Episode_Reward/rotating_object: 135.6973
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.31s
                      Time elapsed: 00:47:32
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 42130 steps/s (collection: 2.209s, learning 0.124s)
             Mean action noise std: 4.06
          Mean value_function loss: 90.0837
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.0660
                       Mean reward: 649.63
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 1.1908
    Episode_Reward/rotating_object: 134.6311
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.33s
                      Time elapsed: 00:47:34
                               ETA: 00:11:50

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 42224 steps/s (collection: 2.210s, learning 0.118s)
             Mean action noise std: 4.06
          Mean value_function loss: 98.0803
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.0857
                       Mean reward: 638.92
               Mean episode length: 231.54
    Episode_Reward/reaching_object: 1.1636
    Episode_Reward/rotating_object: 130.2878
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.33s
                      Time elapsed: 00:47:36
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 42402 steps/s (collection: 2.192s, learning 0.127s)
             Mean action noise std: 4.07
          Mean value_function loss: 97.9354
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 72.1098
                       Mean reward: 635.45
               Mean episode length: 218.84
    Episode_Reward/reaching_object: 1.1501
    Episode_Reward/rotating_object: 127.8835
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.32s
                      Time elapsed: 00:47:39
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 42314 steps/s (collection: 2.205s, learning 0.119s)
             Mean action noise std: 4.07
          Mean value_function loss: 104.5345
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 72.1323
                       Mean reward: 681.08
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.1776
    Episode_Reward/rotating_object: 134.1654
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.32s
                      Time elapsed: 00:47:41
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 42263 steps/s (collection: 2.208s, learning 0.118s)
             Mean action noise std: 4.07
          Mean value_function loss: 102.9306
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.1567
                       Mean reward: 661.39
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.1774
    Episode_Reward/rotating_object: 129.7324
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0584
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.33s
                      Time elapsed: 00:47:43
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 41917 steps/s (collection: 2.225s, learning 0.120s)
             Mean action noise std: 4.08
          Mean value_function loss: 94.6235
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.1788
                       Mean reward: 721.67
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 1.1700
    Episode_Reward/rotating_object: 131.5584
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.35s
                      Time elapsed: 00:47:46
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 42102 steps/s (collection: 2.214s, learning 0.121s)
             Mean action noise std: 4.08
          Mean value_function loss: 114.5873
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.1981
                       Mean reward: 682.85
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 1.1772
    Episode_Reward/rotating_object: 134.8563
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.33s
                      Time elapsed: 00:47:48
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 41985 steps/s (collection: 2.221s, learning 0.120s)
             Mean action noise std: 4.08
          Mean value_function loss: 105.7091
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.2244
                       Mean reward: 670.03
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.1587
    Episode_Reward/rotating_object: 128.7335
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.34s
                      Time elapsed: 00:47:50
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 42520 steps/s (collection: 2.193s, learning 0.119s)
             Mean action noise std: 4.08
          Mean value_function loss: 109.9212
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.2396
                       Mean reward: 698.34
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.1549
    Episode_Reward/rotating_object: 130.1107
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.31s
                      Time elapsed: 00:47:53
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 42063 steps/s (collection: 2.211s, learning 0.126s)
             Mean action noise std: 4.09
          Mean value_function loss: 107.2009
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.2512
                       Mean reward: 696.66
               Mean episode length: 236.83
    Episode_Reward/reaching_object: 1.1632
    Episode_Reward/rotating_object: 132.8044
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0569
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.34s
                      Time elapsed: 00:47:55
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 42606 steps/s (collection: 2.189s, learning 0.119s)
             Mean action noise std: 4.09
          Mean value_function loss: 100.5922
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.2667
                       Mean reward: 650.98
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 1.1649
    Episode_Reward/rotating_object: 131.8262
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0574
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.31s
                      Time elapsed: 00:47:57
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 42479 steps/s (collection: 2.195s, learning 0.119s)
             Mean action noise std: 4.09
          Mean value_function loss: 108.4493
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.2809
                       Mean reward: 633.10
               Mean episode length: 218.64
    Episode_Reward/reaching_object: 1.1531
    Episode_Reward/rotating_object: 131.4017
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.31s
                      Time elapsed: 00:48:00
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 40541 steps/s (collection: 2.294s, learning 0.131s)
             Mean action noise std: 4.09
          Mean value_function loss: 103.8552
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.2944
                       Mean reward: 706.95
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 1.1903
    Episode_Reward/rotating_object: 135.1150
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.42s
                      Time elapsed: 00:48:02
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 40953 steps/s (collection: 2.275s, learning 0.126s)
             Mean action noise std: 4.10
          Mean value_function loss: 127.4738
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 72.3113
                       Mean reward: 625.59
               Mean episode length: 218.83
    Episode_Reward/reaching_object: 1.1490
    Episode_Reward/rotating_object: 128.3598
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.40s
                      Time elapsed: 00:48:05
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 40431 steps/s (collection: 2.303s, learning 0.128s)
             Mean action noise std: 4.10
          Mean value_function loss: 104.7626
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.3345
                       Mean reward: 612.81
               Mean episode length: 220.67
    Episode_Reward/reaching_object: 1.1460
    Episode_Reward/rotating_object: 131.4930
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.43s
                      Time elapsed: 00:48:07
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 41286 steps/s (collection: 2.260s, learning 0.121s)
             Mean action noise std: 4.10
          Mean value_function loss: 106.7983
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.3559
                       Mean reward: 662.14
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.1767
    Episode_Reward/rotating_object: 132.7508
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.38s
                      Time elapsed: 00:48:09
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 41753 steps/s (collection: 2.234s, learning 0.120s)
             Mean action noise std: 4.11
          Mean value_function loss: 95.8915
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.3688
                       Mean reward: 681.19
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.1587
    Episode_Reward/rotating_object: 129.3012
        Episode_Reward/action_rate: -0.0968
          Episode_Reward/joint_vel: -0.0583
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.35s
                      Time elapsed: 00:48:12
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 41870 steps/s (collection: 2.225s, learning 0.122s)
             Mean action noise std: 4.11
          Mean value_function loss: 101.2382
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.3813
                       Mean reward: 660.04
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 1.1665
    Episode_Reward/rotating_object: 128.8524
        Episode_Reward/action_rate: -0.0973
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.35s
                      Time elapsed: 00:48:14
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 41368 steps/s (collection: 2.253s, learning 0.124s)
             Mean action noise std: 4.11
          Mean value_function loss: 116.5841
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 72.3969
                       Mean reward: 642.74
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.1736
    Episode_Reward/rotating_object: 131.3799
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.38s
                      Time elapsed: 00:48:16
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 41506 steps/s (collection: 2.245s, learning 0.123s)
             Mean action noise std: 4.12
          Mean value_function loss: 102.1421
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.4162
                       Mean reward: 679.24
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 1.1593
    Episode_Reward/rotating_object: 131.6171
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.37s
                      Time elapsed: 00:48:19
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 42066 steps/s (collection: 2.217s, learning 0.120s)
             Mean action noise std: 4.12
          Mean value_function loss: 98.2814
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.4307
                       Mean reward: 699.38
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.1884
    Episode_Reward/rotating_object: 135.4694
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.34s
                      Time elapsed: 00:48:21
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 42046 steps/s (collection: 2.218s, learning 0.120s)
             Mean action noise std: 4.12
          Mean value_function loss: 94.2662
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.4481
                       Mean reward: 642.72
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.1565
    Episode_Reward/rotating_object: 130.4400
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.34s
                      Time elapsed: 00:48:23
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 42305 steps/s (collection: 2.204s, learning 0.120s)
             Mean action noise std: 4.12
          Mean value_function loss: 104.8921
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 72.4650
                       Mean reward: 645.99
               Mean episode length: 219.24
    Episode_Reward/reaching_object: 1.1504
    Episode_Reward/rotating_object: 127.9812
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.32s
                      Time elapsed: 00:48:26
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 42301 steps/s (collection: 2.197s, learning 0.127s)
             Mean action noise std: 4.13
          Mean value_function loss: 92.3137
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.4838
                       Mean reward: 675.91
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 1.1775
    Episode_Reward/rotating_object: 133.4297
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.32s
                      Time elapsed: 00:48:28
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 42381 steps/s (collection: 2.196s, learning 0.123s)
             Mean action noise std: 4.13
          Mean value_function loss: 95.7021
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.5046
                       Mean reward: 690.19
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.1600
    Episode_Reward/rotating_object: 132.4135
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.32s
                      Time elapsed: 00:48:30
                               ETA: 00:10:52

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 41384 steps/s (collection: 2.252s, learning 0.123s)
             Mean action noise std: 4.13
          Mean value_function loss: 99.1291
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 72.5211
                       Mean reward: 679.95
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 135.1506
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.38s
                      Time elapsed: 00:48:33
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 42266 steps/s (collection: 2.204s, learning 0.121s)
             Mean action noise std: 4.14
          Mean value_function loss: 96.6047
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 72.5352
                       Mean reward: 686.21
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.1708
    Episode_Reward/rotating_object: 135.2091
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.33s
                      Time elapsed: 00:48:35
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 41789 steps/s (collection: 2.230s, learning 0.123s)
             Mean action noise std: 4.14
          Mean value_function loss: 112.5144
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.5545
                       Mean reward: 648.37
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 1.1641
    Episode_Reward/rotating_object: 130.5540
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.35s
                      Time elapsed: 00:48:38
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 41492 steps/s (collection: 2.248s, learning 0.121s)
             Mean action noise std: 4.14
          Mean value_function loss: 110.7356
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 72.5701
                       Mean reward: 661.47
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.1409
    Episode_Reward/rotating_object: 127.5647
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.37s
                      Time elapsed: 00:48:40
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 41382 steps/s (collection: 2.248s, learning 0.128s)
             Mean action noise std: 4.14
          Mean value_function loss: 98.0765
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.5862
                       Mean reward: 652.68
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.1721
    Episode_Reward/rotating_object: 135.7038
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.38s
                      Time elapsed: 00:48:42
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 40081 steps/s (collection: 2.327s, learning 0.126s)
             Mean action noise std: 4.15
          Mean value_function loss: 108.3769
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 72.5985
                       Mean reward: 674.64
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.1698
    Episode_Reward/rotating_object: 132.1650
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.45s
                      Time elapsed: 00:48:45
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 39677 steps/s (collection: 2.366s, learning 0.111s)
             Mean action noise std: 4.15
          Mean value_function loss: 105.1963
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 72.6163
                       Mean reward: 676.13
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.1456
    Episode_Reward/rotating_object: 132.6893
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0543
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.48s
                      Time elapsed: 00:48:47
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 43754 steps/s (collection: 2.135s, learning 0.111s)
             Mean action noise std: 4.15
          Mean value_function loss: 114.1502
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 72.6313
                       Mean reward: 668.90
               Mean episode length: 225.54
    Episode_Reward/reaching_object: 1.1272
    Episode_Reward/rotating_object: 131.6766
        Episode_Reward/action_rate: -0.0973
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.25s
                      Time elapsed: 00:48:49
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 44087 steps/s (collection: 2.108s, learning 0.121s)
             Mean action noise std: 4.15
          Mean value_function loss: 74.6105
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 72.6456
                       Mean reward: 698.91
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.1417
    Episode_Reward/rotating_object: 131.9593
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.23s
                      Time elapsed: 00:48:52
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 42049 steps/s (collection: 2.217s, learning 0.121s)
             Mean action noise std: 4.16
          Mean value_function loss: 94.5658
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.6641
                       Mean reward: 686.94
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 1.1704
    Episode_Reward/rotating_object: 135.4376
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.34s
                      Time elapsed: 00:48:54
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 42334 steps/s (collection: 2.200s, learning 0.122s)
             Mean action noise std: 4.16
          Mean value_function loss: 110.0673
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.6766
                       Mean reward: 702.88
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.1543
    Episode_Reward/rotating_object: 133.3513
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.32s
                      Time elapsed: 00:48:56
                               ETA: 00:10:26

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 41938 steps/s (collection: 2.216s, learning 0.128s)
             Mean action noise std: 4.16
          Mean value_function loss: 87.7621
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 72.6938
                       Mean reward: 588.16
               Mean episode length: 219.51
    Episode_Reward/reaching_object: 1.1349
    Episode_Reward/rotating_object: 130.0598
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.34s
                      Time elapsed: 00:48:59
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 41331 steps/s (collection: 2.241s, learning 0.137s)
             Mean action noise std: 4.17
          Mean value_function loss: 97.2835
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.7116
                       Mean reward: 700.86
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 1.1398
    Episode_Reward/rotating_object: 130.4629
        Episode_Reward/action_rate: -0.1004
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.38s
                      Time elapsed: 00:49:01
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 41745 steps/s (collection: 2.232s, learning 0.123s)
             Mean action noise std: 4.17
          Mean value_function loss: 122.7387
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.7275
                       Mean reward: 608.49
               Mean episode length: 217.59
    Episode_Reward/reaching_object: 1.1312
    Episode_Reward/rotating_object: 131.2963
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.35s
                      Time elapsed: 00:49:03
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 41737 steps/s (collection: 2.234s, learning 0.121s)
             Mean action noise std: 4.17
          Mean value_function loss: 115.9388
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.7452
                       Mean reward: 658.05
               Mean episode length: 229.70
    Episode_Reward/reaching_object: 1.1562
    Episode_Reward/rotating_object: 135.7585
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.36s
                      Time elapsed: 00:49:06
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 42274 steps/s (collection: 2.207s, learning 0.119s)
             Mean action noise std: 4.17
          Mean value_function loss: 117.0898
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 72.7662
                       Mean reward: 680.70
               Mean episode length: 227.55
    Episode_Reward/reaching_object: 1.1181
    Episode_Reward/rotating_object: 133.7107
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.33s
                      Time elapsed: 00:49:08
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 42221 steps/s (collection: 2.207s, learning 0.121s)
             Mean action noise std: 4.18
          Mean value_function loss: 93.3061
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.7815
                       Mean reward: 713.17
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 135.4012
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.33s
                      Time elapsed: 00:49:10
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 41502 steps/s (collection: 2.247s, learning 0.122s)
             Mean action noise std: 4.18
          Mean value_function loss: 103.3441
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 72.7963
                       Mean reward: 650.69
               Mean episode length: 223.34
    Episode_Reward/reaching_object: 1.1510
    Episode_Reward/rotating_object: 136.2000
        Episode_Reward/action_rate: -0.1011
          Episode_Reward/joint_vel: -0.0548
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.37s
                      Time elapsed: 00:49:13
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 41031 steps/s (collection: 2.270s, learning 0.126s)
             Mean action noise std: 4.18
          Mean value_function loss: 100.3069
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.8153
                       Mean reward: 676.27
               Mean episode length: 231.39
    Episode_Reward/reaching_object: 1.1472
    Episode_Reward/rotating_object: 136.3658
        Episode_Reward/action_rate: -0.1008
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.40s
                      Time elapsed: 00:49:15
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 40817 steps/s (collection: 2.281s, learning 0.127s)
             Mean action noise std: 4.18
          Mean value_function loss: 98.2703
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.8341
                       Mean reward: 649.31
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 1.1246
    Episode_Reward/rotating_object: 128.1697
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0572
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.41s
                      Time elapsed: 00:49:18
                               ETA: 00:10:05

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 42046 steps/s (collection: 2.193s, learning 0.145s)
             Mean action noise std: 4.19
          Mean value_function loss: 89.7499
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.8558
                       Mean reward: 692.06
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.1735
    Episode_Reward/rotating_object: 137.2333
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.34s
                      Time elapsed: 00:49:20
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 42297 steps/s (collection: 2.200s, learning 0.124s)
             Mean action noise std: 4.19
          Mean value_function loss: 105.1853
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.8790
                       Mean reward: 686.13
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.1471
    Episode_Reward/rotating_object: 135.5396
        Episode_Reward/action_rate: -0.1016
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.32s
                      Time elapsed: 00:49:22
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 42104 steps/s (collection: 2.215s, learning 0.120s)
             Mean action noise std: 4.20
          Mean value_function loss: 80.4186
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.9001
                       Mean reward: 655.54
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.1616
    Episode_Reward/rotating_object: 133.7175
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.33s
                      Time elapsed: 00:49:25
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 42526 steps/s (collection: 2.191s, learning 0.120s)
             Mean action noise std: 4.20
          Mean value_function loss: 92.3192
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.9165
                       Mean reward: 651.73
               Mean episode length: 230.04
    Episode_Reward/reaching_object: 1.1713
    Episode_Reward/rotating_object: 138.6050
        Episode_Reward/action_rate: -0.1039
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 18.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.31s
                      Time elapsed: 00:49:27
                               ETA: 00:09:55

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 42079 steps/s (collection: 2.216s, learning 0.120s)
             Mean action noise std: 4.20
          Mean value_function loss: 113.8078
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.9300
                       Mean reward: 628.44
               Mean episode length: 214.74
    Episode_Reward/reaching_object: 1.1285
    Episode_Reward/rotating_object: 131.9267
        Episode_Reward/action_rate: -0.1016
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.34s
                      Time elapsed: 00:49:29
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 41085 steps/s (collection: 2.267s, learning 0.126s)
             Mean action noise std: 4.20
          Mean value_function loss: 91.3944
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.9441
                       Mean reward: 684.94
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 1.1466
    Episode_Reward/rotating_object: 133.4518
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.39s
                      Time elapsed: 00:49:32
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 40822 steps/s (collection: 2.281s, learning 0.127s)
             Mean action noise std: 4.21
          Mean value_function loss: 115.6117
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 72.9667
                       Mean reward: 664.02
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.1346
    Episode_Reward/rotating_object: 129.8267
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.41s
                      Time elapsed: 00:49:34
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 40856 steps/s (collection: 2.286s, learning 0.120s)
             Mean action noise std: 4.21
          Mean value_function loss: 97.4534
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 72.9876
                       Mean reward: 715.96
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.1635
    Episode_Reward/rotating_object: 134.0233
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0573
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.41s
                      Time elapsed: 00:49:36
                               ETA: 00:09:46

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 41077 steps/s (collection: 2.264s, learning 0.129s)
             Mean action noise std: 4.22
          Mean value_function loss: 103.0419
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.0074
                       Mean reward: 687.65
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.1340
    Episode_Reward/rotating_object: 134.5508
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0583
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.39s
                      Time elapsed: 00:49:39
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 41424 steps/s (collection: 2.262s, learning 0.111s)
             Mean action noise std: 4.22
          Mean value_function loss: 107.0413
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 73.0294
                       Mean reward: 653.72
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.1409
    Episode_Reward/rotating_object: 131.1196
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.37s
                      Time elapsed: 00:49:41
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 42414 steps/s (collection: 2.198s, learning 0.120s)
             Mean action noise std: 4.22
          Mean value_function loss: 95.1703
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.0523
                       Mean reward: 669.07
               Mean episode length: 224.86
    Episode_Reward/reaching_object: 1.1294
    Episode_Reward/rotating_object: 132.6990
        Episode_Reward/action_rate: -0.1022
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.32s
                      Time elapsed: 00:49:44
                               ETA: 00:09:39

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 42455 steps/s (collection: 2.197s, learning 0.118s)
             Mean action noise std: 4.22
          Mean value_function loss: 95.3243
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.0668
                       Mean reward: 693.97
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.1349
    Episode_Reward/rotating_object: 133.9206
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.32s
                      Time elapsed: 00:49:46
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 42291 steps/s (collection: 2.203s, learning 0.121s)
             Mean action noise std: 4.23
          Mean value_function loss: 99.9097
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.0795
                       Mean reward: 631.07
               Mean episode length: 228.59
    Episode_Reward/reaching_object: 1.1379
    Episode_Reward/rotating_object: 132.3364
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.32s
                      Time elapsed: 00:49:48
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 42094 steps/s (collection: 2.216s, learning 0.119s)
             Mean action noise std: 4.23
          Mean value_function loss: 99.8307
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.0931
                       Mean reward: 653.11
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.1390
    Episode_Reward/rotating_object: 133.0105
        Episode_Reward/action_rate: -0.1033
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.34s
                      Time elapsed: 00:49:50
                               ETA: 00:09:32

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 42316 steps/s (collection: 2.202s, learning 0.121s)
             Mean action noise std: 4.23
          Mean value_function loss: 106.0211
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 73.1098
                       Mean reward: 732.32
               Mean episode length: 243.22
    Episode_Reward/reaching_object: 1.1549
    Episode_Reward/rotating_object: 138.2007
        Episode_Reward/action_rate: -0.1044
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.32s
                      Time elapsed: 00:49:53
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 42441 steps/s (collection: 2.197s, learning 0.119s)
             Mean action noise std: 4.23
          Mean value_function loss: 108.8179
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 73.1255
                       Mean reward: 703.82
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 1.1340
    Episode_Reward/rotating_object: 133.8631
        Episode_Reward/action_rate: -0.1028
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.32s
                      Time elapsed: 00:49:55
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 41885 steps/s (collection: 2.223s, learning 0.124s)
             Mean action noise std: 4.24
          Mean value_function loss: 109.8687
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.1367
                       Mean reward: 630.47
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.1256
    Episode_Reward/rotating_object: 128.4773
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.35s
                      Time elapsed: 00:49:57
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 42565 steps/s (collection: 2.188s, learning 0.122s)
             Mean action noise std: 4.24
          Mean value_function loss: 91.9383
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.1472
                       Mean reward: 714.76
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 1.1638
    Episode_Reward/rotating_object: 135.0995
        Episode_Reward/action_rate: -0.1052
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.31s
                      Time elapsed: 00:50:00
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 42694 steps/s (collection: 2.176s, learning 0.126s)
             Mean action noise std: 4.24
          Mean value_function loss: 97.8553
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 73.1577
                       Mean reward: 702.25
               Mean episode length: 241.05
    Episode_Reward/reaching_object: 1.1678
    Episode_Reward/rotating_object: 133.4511
        Episode_Reward/action_rate: -0.1059
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.30s
                      Time elapsed: 00:50:02
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 42422 steps/s (collection: 2.184s, learning 0.134s)
             Mean action noise std: 4.24
          Mean value_function loss: 98.5300
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 73.1758
                       Mean reward: 672.45
               Mean episode length: 225.83
    Episode_Reward/reaching_object: 1.1431
    Episode_Reward/rotating_object: 131.2722
        Episode_Reward/action_rate: -0.1038
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.32s
                      Time elapsed: 00:50:04
                               ETA: 00:09:17

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 42776 steps/s (collection: 2.180s, learning 0.118s)
             Mean action noise std: 4.25
          Mean value_function loss: 91.7929
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.1980
                       Mean reward: 611.95
               Mean episode length: 217.63
    Episode_Reward/reaching_object: 1.1201
    Episode_Reward/rotating_object: 130.8136
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.30s
                      Time elapsed: 00:50:07
                               ETA: 00:09:15

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 41821 steps/s (collection: 2.217s, learning 0.133s)
             Mean action noise std: 4.25
          Mean value_function loss: 88.6547
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.2154
                       Mean reward: 662.91
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.1486
    Episode_Reward/rotating_object: 133.2130
        Episode_Reward/action_rate: -0.1053
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.35s
                      Time elapsed: 00:50:09
                               ETA: 00:09:13

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 41660 steps/s (collection: 2.237s, learning 0.123s)
             Mean action noise std: 4.25
          Mean value_function loss: 92.5986
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.2316
                       Mean reward: 620.78
               Mean episode length: 223.15
    Episode_Reward/reaching_object: 1.1467
    Episode_Reward/rotating_object: 134.1909
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.36s
                      Time elapsed: 00:50:11
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 42456 steps/s (collection: 2.193s, learning 0.122s)
             Mean action noise std: 4.26
          Mean value_function loss: 105.2275
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.2452
                       Mean reward: 683.70
               Mean episode length: 226.50
    Episode_Reward/reaching_object: 1.1328
    Episode_Reward/rotating_object: 133.9990
        Episode_Reward/action_rate: -0.1038
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.32s
                      Time elapsed: 00:50:14
                               ETA: 00:09:08

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 42569 steps/s (collection: 2.191s, learning 0.119s)
             Mean action noise std: 4.26
          Mean value_function loss: 81.8135
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.2608
                       Mean reward: 698.49
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 1.1915
    Episode_Reward/rotating_object: 144.7342
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 18.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.31s
                      Time elapsed: 00:50:16
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 40814 steps/s (collection: 2.282s, learning 0.126s)
             Mean action noise std: 4.26
          Mean value_function loss: 110.5023
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.2773
                       Mean reward: 691.31
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.1060
    Episode_Reward/rotating_object: 126.3435
        Episode_Reward/action_rate: -0.1022
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.41s
                      Time elapsed: 00:50:18
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 40690 steps/s (collection: 2.289s, learning 0.127s)
             Mean action noise std: 4.26
          Mean value_function loss: 107.2437
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.2924
                       Mean reward: 696.48
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.1533
    Episode_Reward/rotating_object: 138.2087
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.42s
                      Time elapsed: 00:50:21
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 40915 steps/s (collection: 2.276s, learning 0.126s)
             Mean action noise std: 4.27
          Mean value_function loss: 107.3608
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 73.3153
                       Mean reward: 662.14
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 1.1380
    Episode_Reward/rotating_object: 133.0037
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.40s
                      Time elapsed: 00:50:23
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 41003 steps/s (collection: 2.272s, learning 0.125s)
             Mean action noise std: 4.27
          Mean value_function loss: 108.7688
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.3321
                       Mean reward: 689.90
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.1317
    Episode_Reward/rotating_object: 133.8775
        Episode_Reward/action_rate: -0.1047
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.40s
                      Time elapsed: 00:50:26
                               ETA: 00:08:56

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 40692 steps/s (collection: 2.290s, learning 0.126s)
             Mean action noise std: 4.27
          Mean value_function loss: 93.1315
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.3476
                       Mean reward: 687.47
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.1628
    Episode_Reward/rotating_object: 137.4750
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.42s
                      Time elapsed: 00:50:28
                               ETA: 00:08:54

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 40893 steps/s (collection: 2.277s, learning 0.127s)
             Mean action noise std: 4.28
          Mean value_function loss: 101.5035
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.3623
                       Mean reward: 652.23
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 1.1255
    Episode_Reward/rotating_object: 136.9057
        Episode_Reward/action_rate: -0.1043
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.40s
                      Time elapsed: 00:50:30
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 41712 steps/s (collection: 2.234s, learning 0.122s)
             Mean action noise std: 4.28
          Mean value_function loss: 89.0335
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.3756
                       Mean reward: 684.86
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.1316
    Episode_Reward/rotating_object: 134.7661
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.36s
                      Time elapsed: 00:50:33
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 42524 steps/s (collection: 2.189s, learning 0.123s)
             Mean action noise std: 4.28
          Mean value_function loss: 98.3525
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.3969
                       Mean reward: 631.41
               Mean episode length: 221.09
    Episode_Reward/reaching_object: 1.1476
    Episode_Reward/rotating_object: 132.6243
        Episode_Reward/action_rate: -0.1067
          Episode_Reward/joint_vel: -0.0586
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.31s
                      Time elapsed: 00:50:35
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 41374 steps/s (collection: 2.254s, learning 0.122s)
             Mean action noise std: 4.29
          Mean value_function loss: 111.2172
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.4217
                       Mean reward: 672.02
               Mean episode length: 227.24
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 136.9492
        Episode_Reward/action_rate: -0.1078
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.38s
                      Time elapsed: 00:50:38
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 42086 steps/s (collection: 2.215s, learning 0.121s)
             Mean action noise std: 4.29
          Mean value_function loss: 104.4485
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 73.4443
                       Mean reward: 693.72
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 1.1583
    Episode_Reward/rotating_object: 134.2054
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.34s
                      Time elapsed: 00:50:40
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 42061 steps/s (collection: 2.216s, learning 0.121s)
             Mean action noise std: 4.29
          Mean value_function loss: 99.1944
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.4637
                       Mean reward: 629.72
               Mean episode length: 223.55
    Episode_Reward/reaching_object: 1.1373
    Episode_Reward/rotating_object: 131.3839
        Episode_Reward/action_rate: -0.1063
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.34s
                      Time elapsed: 00:50:42
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 41807 steps/s (collection: 2.229s, learning 0.123s)
             Mean action noise std: 4.30
          Mean value_function loss: 114.9176
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.4855
                       Mean reward: 687.60
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.1397
    Episode_Reward/rotating_object: 133.2931
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.35s
                      Time elapsed: 00:50:45
                               ETA: 00:08:37

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 42265 steps/s (collection: 2.204s, learning 0.122s)
             Mean action noise std: 4.30
          Mean value_function loss: 107.5028
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.5035
                       Mean reward: 656.46
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 1.1436
    Episode_Reward/rotating_object: 131.9176
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.33s
                      Time elapsed: 00:50:47
                               ETA: 00:08:35

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 42143 steps/s (collection: 2.210s, learning 0.123s)
             Mean action noise std: 4.30
          Mean value_function loss: 99.7804
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.5232
                       Mean reward: 594.88
               Mean episode length: 211.75
    Episode_Reward/reaching_object: 1.1437
    Episode_Reward/rotating_object: 133.2567
        Episode_Reward/action_rate: -0.1068
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.33s
                      Time elapsed: 00:50:49
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 42011 steps/s (collection: 2.218s, learning 0.122s)
             Mean action noise std: 4.31
          Mean value_function loss: 104.8833
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.5422
                       Mean reward: 645.65
               Mean episode length: 223.87
    Episode_Reward/reaching_object: 1.1405
    Episode_Reward/rotating_object: 132.6329
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0569
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.34s
                      Time elapsed: 00:50:52
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 42291 steps/s (collection: 2.202s, learning 0.122s)
             Mean action noise std: 4.31
          Mean value_function loss: 110.3021
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.5610
                       Mean reward: 651.44
               Mean episode length: 227.82
    Episode_Reward/reaching_object: 1.1494
    Episode_Reward/rotating_object: 130.2312
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0601
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.32s
                      Time elapsed: 00:50:54
                               ETA: 00:08:27

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 42267 steps/s (collection: 2.205s, learning 0.120s)
             Mean action noise std: 4.31
          Mean value_function loss: 102.5408
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.5789
                       Mean reward: 639.16
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.1385
    Episode_Reward/rotating_object: 135.0539
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.33s
                      Time elapsed: 00:50:56
                               ETA: 00:08:25

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 41717 steps/s (collection: 2.233s, learning 0.123s)
             Mean action noise std: 4.31
          Mean value_function loss: 96.8856
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.5962
                       Mean reward: 638.47
               Mean episode length: 224.36
    Episode_Reward/reaching_object: 1.1288
    Episode_Reward/rotating_object: 124.7638
        Episode_Reward/action_rate: -0.1058
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.36s
                      Time elapsed: 00:50:59
                               ETA: 00:08:23

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 42364 steps/s (collection: 2.200s, learning 0.121s)
             Mean action noise std: 4.32
          Mean value_function loss: 92.3327
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 73.6107
                       Mean reward: 676.57
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 1.1475
    Episode_Reward/rotating_object: 133.0733
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.32s
                      Time elapsed: 00:51:01
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 42052 steps/s (collection: 2.214s, learning 0.124s)
             Mean action noise std: 4.32
          Mean value_function loss: 89.0474
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.6311
                       Mean reward: 647.72
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.1568
    Episode_Reward/rotating_object: 133.7318
        Episode_Reward/action_rate: -0.1097
          Episode_Reward/joint_vel: -0.0595
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.34s
                      Time elapsed: 00:51:03
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 41456 steps/s (collection: 2.245s, learning 0.126s)
             Mean action noise std: 4.32
          Mean value_function loss: 98.0219
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 73.6493
                       Mean reward: 661.06
               Mean episode length: 229.55
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 134.3722
        Episode_Reward/action_rate: -0.1096
          Episode_Reward/joint_vel: -0.0603
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.37s
                      Time elapsed: 00:51:06
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 40967 steps/s (collection: 2.273s, learning 0.126s)
             Mean action noise std: 4.33
          Mean value_function loss: 92.9418
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.6621
                       Mean reward: 672.65
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 1.1665
    Episode_Reward/rotating_object: 137.3601
        Episode_Reward/action_rate: -0.1097
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.40s
                      Time elapsed: 00:51:08
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 40589 steps/s (collection: 2.295s, learning 0.126s)
             Mean action noise std: 4.33
          Mean value_function loss: 99.4884
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.6689
                       Mean reward: 658.59
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.1523
    Episode_Reward/rotating_object: 131.7898
        Episode_Reward/action_rate: -0.1093
          Episode_Reward/joint_vel: -0.0599
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.42s
                      Time elapsed: 00:51:10
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 41033 steps/s (collection: 2.270s, learning 0.126s)
             Mean action noise std: 4.33
          Mean value_function loss: 91.9686
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.6815
                       Mean reward: 711.68
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 1.1488
    Episode_Reward/rotating_object: 131.0395
        Episode_Reward/action_rate: -0.1087
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.40s
                      Time elapsed: 00:51:13
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 40145 steps/s (collection: 2.322s, learning 0.126s)
             Mean action noise std: 4.33
          Mean value_function loss: 89.3126
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.7000
                       Mean reward: 612.37
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1513
    Episode_Reward/rotating_object: 133.5878
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.45s
                      Time elapsed: 00:51:15
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 42496 steps/s (collection: 2.194s, learning 0.119s)
             Mean action noise std: 4.34
          Mean value_function loss: 104.3043
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 73.7230
                       Mean reward: 642.85
               Mean episode length: 225.77
    Episode_Reward/reaching_object: 1.1613
    Episode_Reward/rotating_object: 135.5231
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0607
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.31s
                      Time elapsed: 00:51:18
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 42626 steps/s (collection: 2.186s, learning 0.120s)
             Mean action noise std: 4.34
          Mean value_function loss: 90.5548
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 73.7452
                       Mean reward: 657.44
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1397
    Episode_Reward/rotating_object: 131.1909
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0590
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.31s
                      Time elapsed: 00:51:20
                               ETA: 00:08:01

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 41694 steps/s (collection: 2.205s, learning 0.153s)
             Mean action noise std: 4.34
          Mean value_function loss: 104.7806
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.7607
                       Mean reward: 705.15
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 1.1323
    Episode_Reward/rotating_object: 133.0205
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.36s
                      Time elapsed: 00:51:22
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 41591 steps/s (collection: 2.243s, learning 0.121s)
             Mean action noise std: 4.35
          Mean value_function loss: 102.4571
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.7785
                       Mean reward: 682.04
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 1.1395
    Episode_Reward/rotating_object: 130.5137
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.36s
                      Time elapsed: 00:51:25
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 42348 steps/s (collection: 2.199s, learning 0.123s)
             Mean action noise std: 4.35
          Mean value_function loss: 99.3999
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.7954
                       Mean reward: 689.58
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.1481
    Episode_Reward/rotating_object: 134.3251
        Episode_Reward/action_rate: -0.1094
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.32s
                      Time elapsed: 00:51:27
                               ETA: 00:07:54

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 42517 steps/s (collection: 2.188s, learning 0.124s)
             Mean action noise std: 4.35
          Mean value_function loss: 95.8679
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.8145
                       Mean reward: 716.43
               Mean episode length: 231.74
    Episode_Reward/reaching_object: 1.1388
    Episode_Reward/rotating_object: 135.7098
        Episode_Reward/action_rate: -0.1088
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.31s
                      Time elapsed: 00:51:29
                               ETA: 00:07:52

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 42470 steps/s (collection: 2.189s, learning 0.125s)
             Mean action noise std: 4.36
          Mean value_function loss: 96.3076
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.8350
                       Mean reward: 689.74
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.1521
    Episode_Reward/rotating_object: 136.9546
        Episode_Reward/action_rate: -0.1097
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.31s
                      Time elapsed: 00:51:32
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 41955 steps/s (collection: 2.221s, learning 0.122s)
             Mean action noise std: 4.36
          Mean value_function loss: 90.6589
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 73.8524
                       Mean reward: 665.63
               Mean episode length: 228.26
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 136.0567
        Episode_Reward/action_rate: -0.1102
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.34s
                      Time elapsed: 00:51:34
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 42329 steps/s (collection: 2.201s, learning 0.122s)
             Mean action noise std: 4.36
          Mean value_function loss: 96.8981
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.8774
                       Mean reward: 704.23
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.1565
    Episode_Reward/rotating_object: 137.6952
        Episode_Reward/action_rate: -0.1104
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.32s
                      Time elapsed: 00:51:36
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 42369 steps/s (collection: 2.201s, learning 0.119s)
             Mean action noise std: 4.37
          Mean value_function loss: 106.1280
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 73.9001
                       Mean reward: 702.75
               Mean episode length: 233.03
    Episode_Reward/reaching_object: 1.1210
    Episode_Reward/rotating_object: 128.2375
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0621
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.32s
                      Time elapsed: 00:51:39
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 42398 steps/s (collection: 2.196s, learning 0.122s)
             Mean action noise std: 4.37
          Mean value_function loss: 90.4139
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.9260
                       Mean reward: 707.61
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.1495
    Episode_Reward/rotating_object: 136.0997
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0584
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.32s
                      Time elapsed: 00:51:41
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 42602 steps/s (collection: 2.187s, learning 0.121s)
             Mean action noise std: 4.38
          Mean value_function loss: 101.7605
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 73.9517
                       Mean reward: 682.30
               Mean episode length: 228.52
    Episode_Reward/reaching_object: 1.1292
    Episode_Reward/rotating_object: 133.1864
        Episode_Reward/action_rate: -0.1084
          Episode_Reward/joint_vel: -0.0567
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.31s
                      Time elapsed: 00:51:43
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 42675 steps/s (collection: 2.184s, learning 0.119s)
             Mean action noise std: 4.38
          Mean value_function loss: 96.1994
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.9680
                       Mean reward: 705.09
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 137.7957
        Episode_Reward/action_rate: -0.1117
          Episode_Reward/joint_vel: -0.0583
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.30s
                      Time elapsed: 00:51:45
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 42175 steps/s (collection: 2.196s, learning 0.135s)
             Mean action noise std: 4.38
          Mean value_function loss: 102.6219
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 73.9862
                       Mean reward: 637.08
               Mean episode length: 222.96
    Episode_Reward/reaching_object: 1.1345
    Episode_Reward/rotating_object: 130.7495
        Episode_Reward/action_rate: -0.1097
          Episode_Reward/joint_vel: -0.0577
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.33s
                      Time elapsed: 00:51:48
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 42334 steps/s (collection: 2.189s, learning 0.133s)
             Mean action noise std: 4.38
          Mean value_function loss: 102.7184
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.0043
                       Mean reward: 643.82
               Mean episode length: 217.19
    Episode_Reward/reaching_object: 1.1483
    Episode_Reward/rotating_object: 134.8524
        Episode_Reward/action_rate: -0.1104
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.32s
                      Time elapsed: 00:51:50
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 42034 steps/s (collection: 2.213s, learning 0.126s)
             Mean action noise std: 4.39
          Mean value_function loss: 77.5977
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.0222
                       Mean reward: 661.14
               Mean episode length: 230.76
    Episode_Reward/reaching_object: 1.1525
    Episode_Reward/rotating_object: 135.8331
        Episode_Reward/action_rate: -0.1111
          Episode_Reward/joint_vel: -0.0589
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.34s
                      Time elapsed: 00:51:52
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 41046 steps/s (collection: 2.267s, learning 0.128s)
             Mean action noise std: 4.39
          Mean value_function loss: 88.2862
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.0470
                       Mean reward: 679.23
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 1.1784
    Episode_Reward/rotating_object: 139.8723
        Episode_Reward/action_rate: -0.1136
          Episode_Reward/joint_vel: -0.0590
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.39s
                      Time elapsed: 00:51:55
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 41339 steps/s (collection: 2.249s, learning 0.129s)
             Mean action noise std: 4.40
          Mean value_function loss: 103.7583
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.0695
                       Mean reward: 696.29
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 1.1634
    Episode_Reward/rotating_object: 141.0186
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0591
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.38s
                      Time elapsed: 00:51:57
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 41603 steps/s (collection: 2.232s, learning 0.130s)
             Mean action noise std: 4.40
          Mean value_function loss: 88.3070
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 74.0813
                       Mean reward: 723.16
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.1508
    Episode_Reward/rotating_object: 138.1831
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.36s
                      Time elapsed: 00:52:00
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 41636 steps/s (collection: 2.237s, learning 0.124s)
             Mean action noise std: 4.40
          Mean value_function loss: 82.4158
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.0919
                       Mean reward: 712.88
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.1539
    Episode_Reward/rotating_object: 136.1571
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.36s
                      Time elapsed: 00:52:02
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 44499 steps/s (collection: 2.097s, learning 0.112s)
             Mean action noise std: 4.40
          Mean value_function loss: 89.9795
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.1118
                       Mean reward: 685.45
               Mean episode length: 227.06
    Episode_Reward/reaching_object: 1.1388
    Episode_Reward/rotating_object: 134.5413
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0585
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.21s
                      Time elapsed: 00:52:04
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 43207 steps/s (collection: 2.152s, learning 0.123s)
             Mean action noise std: 4.41
          Mean value_function loss: 70.0378
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 74.1312
                       Mean reward: 698.06
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 1.1807
    Episode_Reward/rotating_object: 141.3337
        Episode_Reward/action_rate: -0.1153
          Episode_Reward/joint_vel: -0.0598
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.28s
                      Time elapsed: 00:52:06
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 42111 steps/s (collection: 2.212s, learning 0.122s)
             Mean action noise std: 4.41
          Mean value_function loss: 111.2832
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.1418
                       Mean reward: 644.40
               Mean episode length: 222.05
    Episode_Reward/reaching_object: 1.1058
    Episode_Reward/rotating_object: 127.4935
        Episode_Reward/action_rate: -0.1085
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.33s
                      Time elapsed: 00:52:09
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 41909 steps/s (collection: 2.226s, learning 0.120s)
             Mean action noise std: 4.41
          Mean value_function loss: 102.0412
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.1572
                       Mean reward: 627.63
               Mean episode length: 217.15
    Episode_Reward/reaching_object: 1.1298
    Episode_Reward/rotating_object: 135.2124
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.35s
                      Time elapsed: 00:52:11
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 42277 steps/s (collection: 2.203s, learning 0.122s)
             Mean action noise std: 4.41
          Mean value_function loss: 89.3605
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.1742
                       Mean reward: 693.06
               Mean episode length: 229.62
    Episode_Reward/reaching_object: 1.1217
    Episode_Reward/rotating_object: 132.9255
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0580
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.33s
                      Time elapsed: 00:52:13
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 41815 steps/s (collection: 2.226s, learning 0.125s)
             Mean action noise std: 4.42
          Mean value_function loss: 97.8885
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.1881
                       Mean reward: 696.69
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 1.1652
    Episode_Reward/rotating_object: 137.8179
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0586
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.35s
                      Time elapsed: 00:52:16
                               ETA: 00:07:04

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 42132 steps/s (collection: 2.206s, learning 0.127s)
             Mean action noise std: 4.42
          Mean value_function loss: 84.6876
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.2040
                       Mean reward: 691.16
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.1585
    Episode_Reward/rotating_object: 139.5181
        Episode_Reward/action_rate: -0.1143
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.33s
                      Time elapsed: 00:52:18
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 42374 steps/s (collection: 2.199s, learning 0.121s)
             Mean action noise std: 4.42
          Mean value_function loss: 107.0062
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.2248
                       Mean reward: 692.01
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 1.1576
    Episode_Reward/rotating_object: 136.0985
        Episode_Reward/action_rate: -0.1146
          Episode_Reward/joint_vel: -0.0588
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.32s
                      Time elapsed: 00:52:20
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 41952 steps/s (collection: 2.221s, learning 0.122s)
             Mean action noise std: 4.43
          Mean value_function loss: 107.2019
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.2472
                       Mean reward: 688.51
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.1328
    Episode_Reward/rotating_object: 136.0660
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.34s
                      Time elapsed: 00:52:23
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 42666 steps/s (collection: 2.181s, learning 0.123s)
             Mean action noise std: 4.43
          Mean value_function loss: 101.1867
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.2699
                       Mean reward: 672.52
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.1113
    Episode_Reward/rotating_object: 131.1295
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.30s
                      Time elapsed: 00:52:25
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 42541 steps/s (collection: 2.190s, learning 0.121s)
             Mean action noise std: 4.43
          Mean value_function loss: 95.9944
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.2882
                       Mean reward: 676.29
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.1334
    Episode_Reward/rotating_object: 133.1577
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0568
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.31s
                      Time elapsed: 00:52:27
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 43087 steps/s (collection: 2.156s, learning 0.126s)
             Mean action noise std: 4.44
          Mean value_function loss: 97.5119
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.3011
                       Mean reward: 681.02
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 1.1508
    Episode_Reward/rotating_object: 137.3157
        Episode_Reward/action_rate: -0.1149
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.28s
                      Time elapsed: 00:52:30
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 42549 steps/s (collection: 2.191s, learning 0.119s)
             Mean action noise std: 4.44
          Mean value_function loss: 94.8703
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.3155
                       Mean reward: 640.01
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 1.1287
    Episode_Reward/rotating_object: 132.1921
        Episode_Reward/action_rate: -0.1133
          Episode_Reward/joint_vel: -0.0597
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.31s
                      Time elapsed: 00:52:32
                               ETA: 00:06:47

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 42296 steps/s (collection: 2.203s, learning 0.121s)
             Mean action noise std: 4.44
          Mean value_function loss: 101.4932
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.3306
                       Mean reward: 701.02
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.1198
    Episode_Reward/rotating_object: 132.1419
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0574
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.32s
                      Time elapsed: 00:52:34
                               ETA: 00:06:45

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 42009 steps/s (collection: 2.212s, learning 0.128s)
             Mean action noise std: 4.44
          Mean value_function loss: 95.0231
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.3477
                       Mean reward: 707.29
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 1.1496
    Episode_Reward/rotating_object: 136.8421
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0560
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.34s
                      Time elapsed: 00:52:37
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 42193 steps/s (collection: 2.211s, learning 0.119s)
             Mean action noise std: 4.45
          Mean value_function loss: 81.6764
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.3647
                       Mean reward: 704.48
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.1662
    Episode_Reward/rotating_object: 138.1522
        Episode_Reward/action_rate: -0.1171
          Episode_Reward/joint_vel: -0.0581
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.33s
                      Time elapsed: 00:52:39
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 43323 steps/s (collection: 2.153s, learning 0.116s)
             Mean action noise std: 4.45
          Mean value_function loss: 97.0672
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.3799
                       Mean reward: 701.74
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 1.1363
    Episode_Reward/rotating_object: 137.4335
        Episode_Reward/action_rate: -0.1144
          Episode_Reward/joint_vel: -0.0579
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.27s
                      Time elapsed: 00:52:41
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 43882 steps/s (collection: 2.129s, learning 0.111s)
             Mean action noise std: 4.45
          Mean value_function loss: 100.8155
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.3937
                       Mean reward: 693.85
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 1.1603
    Episode_Reward/rotating_object: 138.4436
        Episode_Reward/action_rate: -0.1168
          Episode_Reward/joint_vel: -0.0565
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 2.24s
                      Time elapsed: 00:52:43
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 43174 steps/s (collection: 2.142s, learning 0.135s)
             Mean action noise std: 4.46
          Mean value_function loss: 97.1995
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.4066
                       Mean reward: 658.66
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.1487
    Episode_Reward/rotating_object: 132.8148
        Episode_Reward/action_rate: -0.1161
          Episode_Reward/joint_vel: -0.0569
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 2.28s
                      Time elapsed: 00:52:46
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 43611 steps/s (collection: 2.128s, learning 0.126s)
             Mean action noise std: 4.46
          Mean value_function loss: 101.8173
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.4271
                       Mean reward: 702.25
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.1230
    Episode_Reward/rotating_object: 133.9061
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 2.25s
                      Time elapsed: 00:52:48
                               ETA: 00:06:31

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 43413 steps/s (collection: 2.132s, learning 0.133s)
             Mean action noise std: 4.46
          Mean value_function loss: 90.8470
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 74.4462
                       Mean reward: 669.24
               Mean episode length: 234.89
    Episode_Reward/reaching_object: 1.1641
    Episode_Reward/rotating_object: 137.6110
        Episode_Reward/action_rate: -0.1173
          Episode_Reward/joint_vel: -0.0578
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 2.26s
                      Time elapsed: 00:52:50
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 41768 steps/s (collection: 2.231s, learning 0.123s)
             Mean action noise std: 4.46
          Mean value_function loss: 123.8019
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.4623
                       Mean reward: 640.48
               Mean episode length: 219.16
    Episode_Reward/reaching_object: 1.0913
    Episode_Reward/rotating_object: 127.5135
        Episode_Reward/action_rate: -0.1111
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 2.35s
                      Time elapsed: 00:52:53
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 41801 steps/s (collection: 2.232s, learning 0.119s)
             Mean action noise std: 4.47
          Mean value_function loss: 111.6799
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.4878
                       Mean reward: 647.69
               Mean episode length: 223.52
    Episode_Reward/reaching_object: 1.1244
    Episode_Reward/rotating_object: 132.2106
        Episode_Reward/action_rate: -0.1141
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 2.35s
                      Time elapsed: 00:52:55
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 42024 steps/s (collection: 2.218s, learning 0.121s)
             Mean action noise std: 4.47
          Mean value_function loss: 98.4861
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 74.5183
                       Mean reward: 687.83
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.1162
    Episode_Reward/rotating_object: 129.8381
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0576
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 2.34s
                      Time elapsed: 00:52:57
                               ETA: 00:06:21

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 41756 steps/s (collection: 2.232s, learning 0.122s)
             Mean action noise std: 4.48
          Mean value_function loss: 103.4396
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.5378
                       Mean reward: 685.70
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 1.1172
    Episode_Reward/rotating_object: 132.1306
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 2.35s
                      Time elapsed: 00:53:00
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 41671 steps/s (collection: 2.239s, learning 0.120s)
             Mean action noise std: 4.48
          Mean value_function loss: 116.2966
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 74.5539
                       Mean reward: 630.99
               Mean episode length: 218.11
    Episode_Reward/reaching_object: 1.1289
    Episode_Reward/rotating_object: 132.7471
        Episode_Reward/action_rate: -0.1148
          Episode_Reward/joint_vel: -0.0561
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 2.36s
                      Time elapsed: 00:53:02
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 42159 steps/s (collection: 2.212s, learning 0.120s)
             Mean action noise std: 4.48
          Mean value_function loss: 105.9127
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.5687
                       Mean reward: 682.77
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.1327
    Episode_Reward/rotating_object: 133.0907
        Episode_Reward/action_rate: -0.1156
          Episode_Reward/joint_vel: -0.0574
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.33s
                      Time elapsed: 00:53:04
                               ETA: 00:06:14

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 42107 steps/s (collection: 2.219s, learning 0.116s)
             Mean action noise std: 4.49
          Mean value_function loss: 107.5170
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.5903
                       Mean reward: 690.79
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 1.1384
    Episode_Reward/rotating_object: 134.5448
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.33s
                      Time elapsed: 00:53:07
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 41737 steps/s (collection: 2.225s, learning 0.131s)
             Mean action noise std: 4.49
          Mean value_function loss: 122.9553
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 74.6040
                       Mean reward: 699.81
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.1340
    Episode_Reward/rotating_object: 134.1364
        Episode_Reward/action_rate: -0.1158
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.36s
                      Time elapsed: 00:53:09
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 41506 steps/s (collection: 2.246s, learning 0.122s)
             Mean action noise std: 4.49
          Mean value_function loss: 105.3292
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.6119
                       Mean reward: 662.80
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 1.1227
    Episode_Reward/rotating_object: 129.4022
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0575
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.37s
                      Time elapsed: 00:53:11
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 41750 steps/s (collection: 2.234s, learning 0.120s)
             Mean action noise std: 4.49
          Mean value_function loss: 107.1411
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 74.6253
                       Mean reward: 652.33
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.1157
    Episode_Reward/rotating_object: 133.7938
        Episode_Reward/action_rate: -0.1142
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.35s
                      Time elapsed: 00:53:14
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 41867 steps/s (collection: 2.226s, learning 0.122s)
             Mean action noise std: 4.49
          Mean value_function loss: 114.8997
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 74.6339
                       Mean reward: 612.71
               Mean episode length: 220.50
    Episode_Reward/reaching_object: 1.1168
    Episode_Reward/rotating_object: 128.3128
        Episode_Reward/action_rate: -0.1141
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.35s
                      Time elapsed: 00:53:16
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 42283 steps/s (collection: 2.203s, learning 0.122s)
             Mean action noise std: 4.50
          Mean value_function loss: 105.0030
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 74.6442
                       Mean reward: 684.29
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.1139
    Episode_Reward/rotating_object: 131.8963
        Episode_Reward/action_rate: -0.1140
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.32s
                      Time elapsed: 00:53:18
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 41944 steps/s (collection: 2.218s, learning 0.126s)
             Mean action noise std: 4.50
          Mean value_function loss: 108.7523
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.6558
                       Mean reward: 675.32
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.1272
    Episode_Reward/rotating_object: 135.2339
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.34s
                      Time elapsed: 00:53:21
                               ETA: 00:05:58

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 42147 steps/s (collection: 2.212s, learning 0.120s)
             Mean action noise std: 4.50
          Mean value_function loss: 83.6086
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.6674
                       Mean reward: 651.70
               Mean episode length: 227.70
    Episode_Reward/reaching_object: 1.1219
    Episode_Reward/rotating_object: 131.8967
        Episode_Reward/action_rate: -0.1158
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.33s
                      Time elapsed: 00:53:23
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 42316 steps/s (collection: 2.200s, learning 0.123s)
             Mean action noise std: 4.50
          Mean value_function loss: 95.9267
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.6785
                       Mean reward: 664.34
               Mean episode length: 219.48
    Episode_Reward/reaching_object: 1.1141
    Episode_Reward/rotating_object: 135.0847
        Episode_Reward/action_rate: -0.1149
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.32s
                      Time elapsed: 00:53:25
                               ETA: 00:05:53

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 41730 steps/s (collection: 2.227s, learning 0.129s)
             Mean action noise std: 4.50
          Mean value_function loss: 94.5934
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 74.6892
                       Mean reward: 704.19
               Mean episode length: 236.77
    Episode_Reward/reaching_object: 1.1505
    Episode_Reward/rotating_object: 134.6413
        Episode_Reward/action_rate: -0.1185
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.36s
                      Time elapsed: 00:53:28
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 41060 steps/s (collection: 2.268s, learning 0.126s)
             Mean action noise std: 4.51
          Mean value_function loss: 80.7289
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.7053
                       Mean reward: 668.17
               Mean episode length: 230.31
    Episode_Reward/reaching_object: 1.1593
    Episode_Reward/rotating_object: 133.4415
        Episode_Reward/action_rate: -0.1198
          Episode_Reward/joint_vel: -0.0564
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.39s
                      Time elapsed: 00:53:30
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 41080 steps/s (collection: 2.266s, learning 0.127s)
             Mean action noise std: 4.51
          Mean value_function loss: 102.1878
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.7186
                       Mean reward: 684.91
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1360
    Episode_Reward/rotating_object: 135.6357
        Episode_Reward/action_rate: -0.1175
          Episode_Reward/joint_vel: -0.0562
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.39s
                      Time elapsed: 00:53:33
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 43745 steps/s (collection: 2.136s, learning 0.111s)
             Mean action noise std: 4.51
          Mean value_function loss: 105.3456
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.7336
                       Mean reward: 678.60
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.1178
    Episode_Reward/rotating_object: 134.4623
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0571
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.25s
                      Time elapsed: 00:53:35
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 44325 steps/s (collection: 2.102s, learning 0.116s)
             Mean action noise std: 4.52
          Mean value_function loss: 99.4682
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 74.7529
                       Mean reward: 720.29
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.1664
    Episode_Reward/rotating_object: 140.8769
        Episode_Reward/action_rate: -0.1205
          Episode_Reward/joint_vel: -0.0570
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.22s
                      Time elapsed: 00:53:37
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 43702 steps/s (collection: 2.135s, learning 0.114s)
             Mean action noise std: 4.52
          Mean value_function loss: 110.0441
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.7736
                       Mean reward: 678.76
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 1.1465
    Episode_Reward/rotating_object: 133.7958
        Episode_Reward/action_rate: -0.1185
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.25s
                      Time elapsed: 00:53:39
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 42614 steps/s (collection: 2.180s, learning 0.127s)
             Mean action noise std: 4.52
          Mean value_function loss: 105.9302
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.7894
                       Mean reward: 664.27
               Mean episode length: 226.79
    Episode_Reward/reaching_object: 1.1331
    Episode_Reward/rotating_object: 135.2798
        Episode_Reward/action_rate: -0.1171
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.31s
                      Time elapsed: 00:53:42
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 42218 steps/s (collection: 2.209s, learning 0.120s)
             Mean action noise std: 4.53
          Mean value_function loss: 122.3546
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 74.8051
                       Mean reward: 671.15
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 1.1191
    Episode_Reward/rotating_object: 130.8091
        Episode_Reward/action_rate: -0.1161
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.33s
                      Time elapsed: 00:53:44
                               ETA: 00:05:34

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 41979 steps/s (collection: 2.221s, learning 0.120s)
             Mean action noise std: 4.53
          Mean value_function loss: 103.5964
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.8190
                       Mean reward: 654.42
               Mean episode length: 218.30
    Episode_Reward/reaching_object: 1.1313
    Episode_Reward/rotating_object: 134.4557
        Episode_Reward/action_rate: -0.1171
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.34s
                      Time elapsed: 00:53:46
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 42366 steps/s (collection: 2.200s, learning 0.120s)
             Mean action noise std: 4.53
          Mean value_function loss: 97.5903
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 74.8340
                       Mean reward: 705.08
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 1.1428
    Episode_Reward/rotating_object: 136.4085
        Episode_Reward/action_rate: -0.1185
          Episode_Reward/joint_vel: -0.0563
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.32s
                      Time elapsed: 00:53:49
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 44876 steps/s (collection: 2.077s, learning 0.114s)
             Mean action noise std: 4.53
          Mean value_function loss: 96.3138
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.8513
                       Mean reward: 710.53
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.1435
    Episode_Reward/rotating_object: 135.8236
        Episode_Reward/action_rate: -0.1180
          Episode_Reward/joint_vel: -0.0559
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.19s
                      Time elapsed: 00:53:51
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 44497 steps/s (collection: 2.092s, learning 0.117s)
             Mean action noise std: 4.54
          Mean value_function loss: 95.2296
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 74.8650
                       Mean reward: 671.67
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.1486
    Episode_Reward/rotating_object: 133.9290
        Episode_Reward/action_rate: -0.1183
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.21s
                      Time elapsed: 00:53:53
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 43890 steps/s (collection: 2.119s, learning 0.121s)
             Mean action noise std: 4.54
          Mean value_function loss: 92.5504
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.8823
                       Mean reward: 728.92
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.1462
    Episode_Reward/rotating_object: 137.0580
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.24s
                      Time elapsed: 00:53:55
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 43871 steps/s (collection: 2.121s, learning 0.120s)
             Mean action noise std: 4.54
          Mean value_function loss: 96.6242
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.9021
                       Mean reward: 665.45
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.1378
    Episode_Reward/rotating_object: 131.7889
        Episode_Reward/action_rate: -0.1183
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.24s
                      Time elapsed: 00:53:57
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 43437 steps/s (collection: 2.144s, learning 0.119s)
             Mean action noise std: 4.55
          Mean value_function loss: 96.6374
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.9168
                       Mean reward: 697.14
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.1459
    Episode_Reward/rotating_object: 136.2865
        Episode_Reward/action_rate: -0.1188
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.26s
                      Time elapsed: 00:54:00
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 43740 steps/s (collection: 2.120s, learning 0.127s)
             Mean action noise std: 4.55
          Mean value_function loss: 86.9886
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.9268
                       Mean reward: 674.60
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 1.1393
    Episode_Reward/rotating_object: 133.5824
        Episode_Reward/action_rate: -0.1195
          Episode_Reward/joint_vel: -0.0554
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.25s
                      Time elapsed: 00:54:02
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 40697 steps/s (collection: 2.292s, learning 0.123s)
             Mean action noise std: 4.55
          Mean value_function loss: 96.0828
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 74.9388
                       Mean reward: 662.88
               Mean episode length: 234.23
    Episode_Reward/reaching_object: 1.1504
    Episode_Reward/rotating_object: 132.2118
        Episode_Reward/action_rate: -0.1200
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.42s
                      Time elapsed: 00:54:04
                               ETA: 00:05:12

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 41306 steps/s (collection: 2.256s, learning 0.124s)
             Mean action noise std: 4.55
          Mean value_function loss: 99.9207
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.9549
                       Mean reward: 697.16
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.1294
    Episode_Reward/rotating_object: 134.1431
        Episode_Reward/action_rate: -0.1191
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.38s
                      Time elapsed: 00:54:07
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 42123 steps/s (collection: 2.212s, learning 0.122s)
             Mean action noise std: 4.56
          Mean value_function loss: 103.3529
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 74.9731
                       Mean reward: 623.38
               Mean episode length: 228.64
    Episode_Reward/reaching_object: 1.1360
    Episode_Reward/rotating_object: 132.5425
        Episode_Reward/action_rate: -0.1190
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.33s
                      Time elapsed: 00:54:09
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 42032 steps/s (collection: 2.218s, learning 0.121s)
             Mean action noise std: 4.56
          Mean value_function loss: 120.0488
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.9888
                       Mean reward: 680.36
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 1.1299
    Episode_Reward/rotating_object: 136.1290
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.34s
                      Time elapsed: 00:54:11
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 42466 steps/s (collection: 2.195s, learning 0.120s)
             Mean action noise std: 4.56
          Mean value_function loss: 110.5139
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.0006
                       Mean reward: 687.79
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 1.1342
    Episode_Reward/rotating_object: 134.0917
        Episode_Reward/action_rate: -0.1191
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.31s
                      Time elapsed: 00:54:14
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 41270 steps/s (collection: 2.264s, learning 0.118s)
             Mean action noise std: 4.56
          Mean value_function loss: 114.7673
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 75.0161
                       Mean reward: 697.02
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 1.1207
    Episode_Reward/rotating_object: 132.5898
        Episode_Reward/action_rate: -0.1178
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.38s
                      Time elapsed: 00:54:16
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 40857 steps/s (collection: 2.280s, learning 0.126s)
             Mean action noise std: 4.57
          Mean value_function loss: 101.6909
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.0319
                       Mean reward: 651.02
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 1.1324
    Episode_Reward/rotating_object: 132.3858
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.41s
                      Time elapsed: 00:54:19
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 40936 steps/s (collection: 2.276s, learning 0.126s)
             Mean action noise std: 4.57
          Mean value_function loss: 106.3721
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 75.0495
                       Mean reward: 662.55
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.1569
    Episode_Reward/rotating_object: 137.3444
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.40s
                      Time elapsed: 00:54:21
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 40464 steps/s (collection: 2.304s, learning 0.126s)
             Mean action noise std: 4.58
          Mean value_function loss: 116.0628
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 75.0762
                       Mean reward: 665.50
               Mean episode length: 222.26
    Episode_Reward/reaching_object: 1.1425
    Episode_Reward/rotating_object: 134.1747
        Episode_Reward/action_rate: -0.1202
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.43s
                      Time elapsed: 00:54:23
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 40788 steps/s (collection: 2.284s, learning 0.126s)
             Mean action noise std: 4.58
          Mean value_function loss: 90.5870
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.0960
                       Mean reward: 669.67
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 1.1485
    Episode_Reward/rotating_object: 134.0139
        Episode_Reward/action_rate: -0.1209
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.41s
                      Time elapsed: 00:54:26
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 40404 steps/s (collection: 2.289s, learning 0.144s)
             Mean action noise std: 4.58
          Mean value_function loss: 93.1945
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.1160
                       Mean reward: 656.97
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.1350
    Episode_Reward/rotating_object: 129.5025
        Episode_Reward/action_rate: -0.1202
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.43s
                      Time elapsed: 00:54:28
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 41234 steps/s (collection: 2.250s, learning 0.134s)
             Mean action noise std: 4.59
          Mean value_function loss: 108.4470
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.1370
                       Mean reward: 691.31
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 1.1420
    Episode_Reward/rotating_object: 133.0513
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.38s
                      Time elapsed: 00:54:31
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 41910 steps/s (collection: 2.224s, learning 0.121s)
             Mean action noise std: 4.59
          Mean value_function loss: 94.4778
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.1567
                       Mean reward: 658.08
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 1.1486
    Episode_Reward/rotating_object: 133.7072
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.35s
                      Time elapsed: 00:54:33
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 42408 steps/s (collection: 2.198s, learning 0.120s)
             Mean action noise std: 4.59
          Mean value_function loss: 107.8836
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.1745
                       Mean reward: 695.16
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.1170
    Episode_Reward/rotating_object: 131.3892
        Episode_Reward/action_rate: -0.1187
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.32s
                      Time elapsed: 00:54:35
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 41911 steps/s (collection: 2.225s, learning 0.120s)
             Mean action noise std: 4.60
          Mean value_function loss: 79.8715
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 75.1946
                       Mean reward: 681.28
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 1.1471
    Episode_Reward/rotating_object: 135.1182
        Episode_Reward/action_rate: -0.1221
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.35s
                      Time elapsed: 00:54:38
                               ETA: 00:04:39

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 42092 steps/s (collection: 2.209s, learning 0.126s)
             Mean action noise std: 4.60
          Mean value_function loss: 87.3635
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 75.2063
                       Mean reward: 663.68
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.1459
    Episode_Reward/rotating_object: 136.1689
        Episode_Reward/action_rate: -0.1219
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.34s
                      Time elapsed: 00:54:40
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 41970 steps/s (collection: 2.219s, learning 0.123s)
             Mean action noise std: 4.60
          Mean value_function loss: 98.4991
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.2216
                       Mean reward: 715.05
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.1564
    Episode_Reward/rotating_object: 136.2601
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.34s
                      Time elapsed: 00:54:42
                               ETA: 00:04:34

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 41615 steps/s (collection: 2.243s, learning 0.119s)
             Mean action noise std: 4.60
          Mean value_function loss: 114.0895
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.2374
                       Mean reward: 699.87
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.1341
    Episode_Reward/rotating_object: 133.4654
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.36s
                      Time elapsed: 00:54:45
                               ETA: 00:04:32

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 41448 steps/s (collection: 2.248s, learning 0.123s)
             Mean action noise std: 4.61
          Mean value_function loss: 97.0335
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.2471
                       Mean reward: 674.10
               Mean episode length: 227.75
    Episode_Reward/reaching_object: 1.1435
    Episode_Reward/rotating_object: 137.1322
        Episode_Reward/action_rate: -0.1219
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.37s
                      Time elapsed: 00:54:47
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 41766 steps/s (collection: 2.230s, learning 0.123s)
             Mean action noise std: 4.61
          Mean value_function loss: 85.9049
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.2613
                       Mean reward: 659.48
               Mean episode length: 223.93
    Episode_Reward/reaching_object: 1.1041
    Episode_Reward/rotating_object: 131.6360
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.35s
                      Time elapsed: 00:54:49
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 41927 steps/s (collection: 2.224s, learning 0.121s)
             Mean action noise std: 4.61
          Mean value_function loss: 115.2323
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 75.2720
                       Mean reward: 644.80
               Mean episode length: 225.03
    Episode_Reward/reaching_object: 1.1327
    Episode_Reward/rotating_object: 134.3365
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.34s
                      Time elapsed: 00:54:52
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 42063 steps/s (collection: 2.216s, learning 0.121s)
             Mean action noise std: 4.61
          Mean value_function loss: 95.1602
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.2801
                       Mean reward: 684.60
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.1441
    Episode_Reward/rotating_object: 137.0410
        Episode_Reward/action_rate: -0.1222
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.34s
                      Time elapsed: 00:54:54
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 41878 steps/s (collection: 2.223s, learning 0.124s)
             Mean action noise std: 4.61
          Mean value_function loss: 105.1810
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 75.2895
                       Mean reward: 666.24
               Mean episode length: 223.37
    Episode_Reward/reaching_object: 1.1267
    Episode_Reward/rotating_object: 134.0717
        Episode_Reward/action_rate: -0.1212
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.35s
                      Time elapsed: 00:54:56
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 41659 steps/s (collection: 2.240s, learning 0.120s)
             Mean action noise std: 4.62
          Mean value_function loss: 94.5298
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.3020
                       Mean reward: 688.78
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.1320
    Episode_Reward/rotating_object: 134.0107
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.36s
                      Time elapsed: 00:54:59
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 42127 steps/s (collection: 2.208s, learning 0.126s)
             Mean action noise std: 4.62
          Mean value_function loss: 95.1788
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 75.3191
                       Mean reward: 670.85
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 1.1561
    Episode_Reward/rotating_object: 137.4859
        Episode_Reward/action_rate: -0.1245
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.33s
                      Time elapsed: 00:55:01
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 41181 steps/s (collection: 2.261s, learning 0.126s)
             Mean action noise std: 4.62
          Mean value_function loss: 102.0070
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.3293
                       Mean reward: 672.74
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.1388
    Episode_Reward/rotating_object: 134.9713
        Episode_Reward/action_rate: -0.1223
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.39s
                      Time elapsed: 00:55:04
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 41028 steps/s (collection: 2.281s, learning 0.115s)
             Mean action noise std: 4.63
          Mean value_function loss: 93.6456
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.3419
                       Mean reward: 704.93
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.1299
    Episode_Reward/rotating_object: 134.9078
        Episode_Reward/action_rate: -0.1217
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.40s
                      Time elapsed: 00:55:06
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 44569 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 4.63
          Mean value_function loss: 89.1820
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.3637
                       Mean reward: 667.05
               Mean episode length: 222.85
    Episode_Reward/reaching_object: 1.1321
    Episode_Reward/rotating_object: 133.7283
        Episode_Reward/action_rate: -0.1223
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.21s
                      Time elapsed: 00:55:08
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 43995 steps/s (collection: 2.123s, learning 0.111s)
             Mean action noise std: 4.63
          Mean value_function loss: 91.2531
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 75.3805
                       Mean reward: 648.03
               Mean episode length: 219.97
    Episode_Reward/reaching_object: 1.1371
    Episode_Reward/rotating_object: 138.6748
        Episode_Reward/action_rate: -0.1223
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.23s
                      Time elapsed: 00:55:10
                               ETA: 00:04:06

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 43761 steps/s (collection: 2.126s, learning 0.120s)
             Mean action noise std: 4.63
          Mean value_function loss: 97.4643
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.3996
                       Mean reward: 646.51
               Mean episode length: 222.15
    Episode_Reward/reaching_object: 1.1327
    Episode_Reward/rotating_object: 135.7949
        Episode_Reward/action_rate: -0.1219
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.25s
                      Time elapsed: 00:55:13
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 42577 steps/s (collection: 2.188s, learning 0.121s)
             Mean action noise std: 4.64
          Mean value_function loss: 84.8296
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.4161
                       Mean reward: 694.79
               Mean episode length: 228.24
    Episode_Reward/reaching_object: 1.1380
    Episode_Reward/rotating_object: 137.8219
        Episode_Reward/action_rate: -0.1234
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.31s
                      Time elapsed: 00:55:15
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 42201 steps/s (collection: 2.207s, learning 0.123s)
             Mean action noise std: 4.64
          Mean value_function loss: 95.2954
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.4324
                       Mean reward: 692.45
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.1548
    Episode_Reward/rotating_object: 141.3871
        Episode_Reward/action_rate: -0.1250
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.33s
                      Time elapsed: 00:55:17
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 42840 steps/s (collection: 2.175s, learning 0.119s)
             Mean action noise std: 4.64
          Mean value_function loss: 85.7759
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 75.4561
                       Mean reward: 649.89
               Mean episode length: 226.39
    Episode_Reward/reaching_object: 1.1320
    Episode_Reward/rotating_object: 136.3076
        Episode_Reward/action_rate: -0.1232
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.29s
                      Time elapsed: 00:55:20
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 42282 steps/s (collection: 2.207s, learning 0.118s)
             Mean action noise std: 4.65
          Mean value_function loss: 96.6748
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 75.4752
                       Mean reward: 661.48
               Mean episode length: 221.81
    Episode_Reward/reaching_object: 1.1337
    Episode_Reward/rotating_object: 136.7344
        Episode_Reward/action_rate: -0.1239
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.32s
                      Time elapsed: 00:55:22
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 42054 steps/s (collection: 2.209s, learning 0.128s)
             Mean action noise std: 4.65
          Mean value_function loss: 105.3375
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.4890
                       Mean reward: 668.47
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 141.0929
        Episode_Reward/action_rate: -0.1258
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.34s
                      Time elapsed: 00:55:24
                               ETA: 00:03:52

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 42465 steps/s (collection: 2.195s, learning 0.120s)
             Mean action noise std: 4.65
          Mean value_function loss: 86.7677
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 75.5066
                       Mean reward: 702.68
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 1.1420
    Episode_Reward/rotating_object: 139.8912
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.31s
                      Time elapsed: 00:55:27
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 42295 steps/s (collection: 2.203s, learning 0.121s)
             Mean action noise std: 4.66
          Mean value_function loss: 82.3737
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.5247
                       Mean reward: 734.19
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 1.1642
    Episode_Reward/rotating_object: 141.5311
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.32s
                      Time elapsed: 00:55:29
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 42220 steps/s (collection: 2.198s, learning 0.130s)
             Mean action noise std: 4.66
          Mean value_function loss: 79.9234
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.5465
                       Mean reward: 683.91
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.1547
    Episode_Reward/rotating_object: 139.0169
        Episode_Reward/action_rate: -0.1271
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.33s
                      Time elapsed: 00:55:31
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 42071 steps/s (collection: 2.204s, learning 0.132s)
             Mean action noise std: 4.67
          Mean value_function loss: 97.8551
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 75.5721
                       Mean reward: 660.87
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 1.1204
    Episode_Reward/rotating_object: 133.6045
        Episode_Reward/action_rate: -0.1238
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.34s
                      Time elapsed: 00:55:33
                               ETA: 00:03:42

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 42055 steps/s (collection: 2.203s, learning 0.134s)
             Mean action noise std: 4.67
          Mean value_function loss: 113.9564
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 75.5849
                       Mean reward: 683.88
               Mean episode length: 232.04
    Episode_Reward/reaching_object: 1.1342
    Episode_Reward/rotating_object: 135.9748
        Episode_Reward/action_rate: -0.1253
          Episode_Reward/joint_vel: -0.0533
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.34s
                      Time elapsed: 00:55:36
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 41783 steps/s (collection: 2.216s, learning 0.137s)
             Mean action noise std: 4.67
          Mean value_function loss: 100.1717
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 75.5974
                       Mean reward: 671.68
               Mean episode length: 227.69
    Episode_Reward/reaching_object: 1.0961
    Episode_Reward/rotating_object: 130.8215
        Episode_Reward/action_rate: -0.1213
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.35s
                      Time elapsed: 00:55:38
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 41797 steps/s (collection: 2.220s, learning 0.132s)
             Mean action noise std: 4.68
          Mean value_function loss: 86.8791
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 75.6198
                       Mean reward: 696.82
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 1.1294
    Episode_Reward/rotating_object: 134.7071
        Episode_Reward/action_rate: -0.1250
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.35s
                      Time elapsed: 00:55:41
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 41739 steps/s (collection: 2.232s, learning 0.123s)
             Mean action noise std: 4.68
          Mean value_function loss: 110.1590
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.6455
                       Mean reward: 662.71
               Mean episode length: 223.47
    Episode_Reward/reaching_object: 1.1228
    Episode_Reward/rotating_object: 135.0344
        Episode_Reward/action_rate: -0.1237
          Episode_Reward/joint_vel: -0.0525
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.36s
                      Time elapsed: 00:55:43
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 42371 steps/s (collection: 2.198s, learning 0.122s)
             Mean action noise std: 4.68
          Mean value_function loss: 99.7594
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.6670
                       Mean reward: 655.26
               Mean episode length: 226.91
    Episode_Reward/reaching_object: 1.1371
    Episode_Reward/rotating_object: 133.6282
        Episode_Reward/action_rate: -0.1258
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.32s
                      Time elapsed: 00:55:45
                               ETA: 00:03:30

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 40585 steps/s (collection: 2.296s, learning 0.126s)
             Mean action noise std: 4.69
          Mean value_function loss: 109.5145
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.6842
                       Mean reward: 737.65
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 1.1111
    Episode_Reward/rotating_object: 132.3057
        Episode_Reward/action_rate: -0.1231
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.42s
                      Time elapsed: 00:55:48
                               ETA: 00:03:28

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 40908 steps/s (collection: 2.277s, learning 0.126s)
             Mean action noise std: 4.69
          Mean value_function loss: 123.1545
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 75.6992
                       Mean reward: 634.49
               Mean episode length: 223.27
    Episode_Reward/reaching_object: 1.1033
    Episode_Reward/rotating_object: 128.4115
        Episode_Reward/action_rate: -0.1221
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.40s
                      Time elapsed: 00:55:50
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 41109 steps/s (collection: 2.264s, learning 0.127s)
             Mean action noise std: 4.69
          Mean value_function loss: 134.9712
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 75.7071
                       Mean reward: 640.55
               Mean episode length: 211.60
    Episode_Reward/reaching_object: 1.0754
    Episode_Reward/rotating_object: 128.7037
        Episode_Reward/action_rate: -0.1193
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.39s
                      Time elapsed: 00:55:52
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 41241 steps/s (collection: 2.258s, learning 0.126s)
             Mean action noise std: 4.69
          Mean value_function loss: 105.4224
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.7165
                       Mean reward: 693.47
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 1.1216
    Episode_Reward/rotating_object: 133.3302
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.38s
                      Time elapsed: 00:55:55
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 40971 steps/s (collection: 2.273s, learning 0.126s)
             Mean action noise std: 4.70
          Mean value_function loss: 106.5894
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.7303
                       Mean reward: 669.06
               Mean episode length: 226.35
    Episode_Reward/reaching_object: 1.1387
    Episode_Reward/rotating_object: 135.6024
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.40s
                      Time elapsed: 00:55:57
                               ETA: 00:03:19

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 40791 steps/s (collection: 2.280s, learning 0.130s)
             Mean action noise std: 4.70
          Mean value_function loss: 98.7416
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.7454
                       Mean reward: 696.20
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 1.1326
    Episode_Reward/rotating_object: 134.7345
        Episode_Reward/action_rate: -0.1257
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.41s
                      Time elapsed: 00:56:00
                               ETA: 00:03:16

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 40840 steps/s (collection: 2.296s, learning 0.111s)
             Mean action noise std: 4.70
          Mean value_function loss: 120.3676
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 75.7588
                       Mean reward: 675.12
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.1308
    Episode_Reward/rotating_object: 132.7126
        Episode_Reward/action_rate: -0.1255
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.41s
                      Time elapsed: 00:56:02
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 42569 steps/s (collection: 2.188s, learning 0.121s)
             Mean action noise std: 4.70
          Mean value_function loss: 94.7377
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.7729
                       Mean reward: 690.65
               Mean episode length: 230.79
    Episode_Reward/reaching_object: 1.1332
    Episode_Reward/rotating_object: 131.9977
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.31s
                      Time elapsed: 00:56:04
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 41923 steps/s (collection: 2.209s, learning 0.136s)
             Mean action noise std: 4.71
          Mean value_function loss: 110.6775
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.7854
                       Mean reward: 674.74
               Mean episode length: 225.04
    Episode_Reward/reaching_object: 1.1448
    Episode_Reward/rotating_object: 138.8397
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.34s
                      Time elapsed: 00:56:07
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 41924 steps/s (collection: 2.223s, learning 0.121s)
             Mean action noise std: 4.71
          Mean value_function loss: 115.4845
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.7969
                       Mean reward: 634.97
               Mean episode length: 212.36
    Episode_Reward/reaching_object: 1.0891
    Episode_Reward/rotating_object: 126.9177
        Episode_Reward/action_rate: -0.1231
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.34s
                      Time elapsed: 00:56:09
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 42564 steps/s (collection: 2.189s, learning 0.121s)
             Mean action noise std: 4.71
          Mean value_function loss: 108.4646
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 75.8144
                       Mean reward: 648.62
               Mean episode length: 216.73
    Episode_Reward/reaching_object: 1.0937
    Episode_Reward/rotating_object: 129.1829
        Episode_Reward/action_rate: -0.1226
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.31s
                      Time elapsed: 00:56:11
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 42128 steps/s (collection: 2.211s, learning 0.122s)
             Mean action noise std: 4.71
          Mean value_function loss: 105.7320
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 75.8290
                       Mean reward: 619.75
               Mean episode length: 221.07
    Episode_Reward/reaching_object: 1.1364
    Episode_Reward/rotating_object: 133.3258
        Episode_Reward/action_rate: -0.1274
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.33s
                      Time elapsed: 00:56:14
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 42451 steps/s (collection: 2.191s, learning 0.124s)
             Mean action noise std: 4.72
          Mean value_function loss: 109.9631
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 75.8438
                       Mean reward: 728.67
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.1405
    Episode_Reward/rotating_object: 138.3145
        Episode_Reward/action_rate: -0.1273
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.32s
                      Time elapsed: 00:56:16
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 42143 steps/s (collection: 2.210s, learning 0.122s)
             Mean action noise std: 4.72
          Mean value_function loss: 96.2110
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.8587
                       Mean reward: 745.18
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 1.1610
    Episode_Reward/rotating_object: 138.3933
        Episode_Reward/action_rate: -0.1295
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.33s
                      Time elapsed: 00:56:18
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 42239 steps/s (collection: 2.204s, learning 0.123s)
             Mean action noise std: 4.72
          Mean value_function loss: 91.1437
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 75.8778
                       Mean reward: 737.22
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 1.1635
    Episode_Reward/rotating_object: 138.7431
        Episode_Reward/action_rate: -0.1303
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.33s
                      Time elapsed: 00:56:21
                               ETA: 00:02:55

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 42306 steps/s (collection: 2.203s, learning 0.121s)
             Mean action noise std: 4.73
          Mean value_function loss: 101.9441
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 75.8944
                       Mean reward: 662.99
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.1332
    Episode_Reward/rotating_object: 129.9481
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.32s
                      Time elapsed: 00:56:23
                               ETA: 00:02:52

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 42254 steps/s (collection: 2.205s, learning 0.121s)
             Mean action noise std: 4.73
          Mean value_function loss: 113.0472
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 75.9105
                       Mean reward: 693.78
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 1.1417
    Episode_Reward/rotating_object: 134.4152
        Episode_Reward/action_rate: -0.1278
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.33s
                      Time elapsed: 00:56:25
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 42124 steps/s (collection: 2.214s, learning 0.120s)
             Mean action noise std: 4.73
          Mean value_function loss: 99.9783
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 75.9236
                       Mean reward: 609.18
               Mean episode length: 211.87
    Episode_Reward/reaching_object: 1.1268
    Episode_Reward/rotating_object: 131.3491
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.33s
                      Time elapsed: 00:56:28
                               ETA: 00:02:48

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 42221 steps/s (collection: 2.203s, learning 0.125s)
             Mean action noise std: 4.73
          Mean value_function loss: 116.4006
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 75.9388
                       Mean reward: 643.17
               Mean episode length: 222.34
    Episode_Reward/reaching_object: 1.1397
    Episode_Reward/rotating_object: 134.6595
        Episode_Reward/action_rate: -0.1282
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.33s
                      Time elapsed: 00:56:30
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 42208 steps/s (collection: 2.196s, learning 0.133s)
             Mean action noise std: 4.74
          Mean value_function loss: 88.4374
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.9532
                       Mean reward: 631.37
               Mean episode length: 216.76
    Episode_Reward/reaching_object: 1.1399
    Episode_Reward/rotating_object: 134.6768
        Episode_Reward/action_rate: -0.1284
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.33s
                      Time elapsed: 00:56:32
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 41240 steps/s (collection: 2.257s, learning 0.127s)
             Mean action noise std: 4.74
          Mean value_function loss: 104.2501
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.9743
                       Mean reward: 649.00
               Mean episode length: 225.96
    Episode_Reward/reaching_object: 1.1470
    Episode_Reward/rotating_object: 131.7400
        Episode_Reward/action_rate: -0.1296
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.38s
                      Time elapsed: 00:56:35
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 41654 steps/s (collection: 2.240s, learning 0.120s)
             Mean action noise std: 4.74
          Mean value_function loss: 101.8726
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 75.9885
                       Mean reward: 698.12
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.1656
    Episode_Reward/rotating_object: 138.0677
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.36s
                      Time elapsed: 00:56:37
                               ETA: 00:02:38

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 42537 steps/s (collection: 2.188s, learning 0.123s)
             Mean action noise std: 4.75
          Mean value_function loss: 105.1658
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 75.9994
                       Mean reward: 648.95
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.1454
    Episode_Reward/rotating_object: 128.6845
        Episode_Reward/action_rate: -0.1297
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.31s
                      Time elapsed: 00:56:39
                               ETA: 00:02:36

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 42596 steps/s (collection: 2.183s, learning 0.125s)
             Mean action noise std: 4.75
          Mean value_function loss: 109.8535
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.0147
                       Mean reward: 664.42
               Mean episode length: 227.81
    Episode_Reward/reaching_object: 1.1247
    Episode_Reward/rotating_object: 131.5099
        Episode_Reward/action_rate: -0.1278
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.31s
                      Time elapsed: 00:56:42
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 40498 steps/s (collection: 2.317s, learning 0.111s)
             Mean action noise std: 4.75
          Mean value_function loss: 112.1441
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 76.0333
                       Mean reward: 637.48
               Mean episode length: 218.54
    Episode_Reward/reaching_object: 1.1351
    Episode_Reward/rotating_object: 135.0072
        Episode_Reward/action_rate: -0.1286
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.43s
                      Time elapsed: 00:56:44
                               ETA: 00:02:31

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 43574 steps/s (collection: 2.145s, learning 0.111s)
             Mean action noise std: 4.76
          Mean value_function loss: 99.5776
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 76.0547
                       Mean reward: 676.46
               Mean episode length: 226.50
    Episode_Reward/reaching_object: 1.1509
    Episode_Reward/rotating_object: 134.7275
        Episode_Reward/action_rate: -0.1302
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.26s
                      Time elapsed: 00:56:46
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 41063 steps/s (collection: 2.266s, learning 0.128s)
             Mean action noise std: 4.76
          Mean value_function loss: 111.6946
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 76.0703
                       Mean reward: 680.87
               Mean episode length: 226.48
    Episode_Reward/reaching_object: 1.1208
    Episode_Reward/rotating_object: 133.3494
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.39s
                      Time elapsed: 00:56:49
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 40390 steps/s (collection: 2.312s, learning 0.122s)
             Mean action noise std: 4.76
          Mean value_function loss: 114.6000
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.0814
                       Mean reward: 634.04
               Mean episode length: 217.50
    Episode_Reward/reaching_object: 1.1230
    Episode_Reward/rotating_object: 132.7072
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.43s
                      Time elapsed: 00:56:51
                               ETA: 00:02:24

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 42110 steps/s (collection: 2.205s, learning 0.129s)
             Mean action noise std: 4.76
          Mean value_function loss: 100.1943
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 76.0958
                       Mean reward: 664.41
               Mean episode length: 225.76
    Episode_Reward/reaching_object: 1.1150
    Episode_Reward/rotating_object: 131.4036
        Episode_Reward/action_rate: -0.1286
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.33s
                      Time elapsed: 00:56:53
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 42421 steps/s (collection: 2.194s, learning 0.123s)
             Mean action noise std: 4.77
          Mean value_function loss: 102.6343
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 76.1108
                       Mean reward: 675.41
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.1292
    Episode_Reward/rotating_object: 129.0461
        Episode_Reward/action_rate: -0.1295
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.32s
                      Time elapsed: 00:56:56
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 41928 steps/s (collection: 2.223s, learning 0.122s)
             Mean action noise std: 4.77
          Mean value_function loss: 98.4579
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.1294
                       Mean reward: 667.66
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 1.1367
    Episode_Reward/rotating_object: 131.8306
        Episode_Reward/action_rate: -0.1308
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.34s
                      Time elapsed: 00:56:58
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 42144 steps/s (collection: 2.210s, learning 0.122s)
             Mean action noise std: 4.77
          Mean value_function loss: 114.9879
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 76.1507
                       Mean reward: 681.18
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 1.1152
    Episode_Reward/rotating_object: 131.2333
        Episode_Reward/action_rate: -0.1287
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.33s
                      Time elapsed: 00:57:00
                               ETA: 00:02:15

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 42157 steps/s (collection: 2.213s, learning 0.119s)
             Mean action noise std: 4.78
          Mean value_function loss: 98.1020
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 76.1666
                       Mean reward: 697.29
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 1.1227
    Episode_Reward/rotating_object: 135.8795
        Episode_Reward/action_rate: -0.1298
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.33s
                      Time elapsed: 00:57:03
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 42281 steps/s (collection: 2.200s, learning 0.125s)
             Mean action noise std: 4.78
          Mean value_function loss: 105.5034
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 76.1831
                       Mean reward: 671.88
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.1596
    Episode_Reward/rotating_object: 135.8218
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.32s
                      Time elapsed: 00:57:05
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 42194 steps/s (collection: 2.198s, learning 0.132s)
             Mean action noise std: 4.78
          Mean value_function loss: 105.0132
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 76.1996
                       Mean reward: 686.89
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 1.1239
    Episode_Reward/rotating_object: 132.5309
        Episode_Reward/action_rate: -0.1310
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.33s
                      Time elapsed: 00:57:07
                               ETA: 00:02:07

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 42144 steps/s (collection: 2.212s, learning 0.120s)
             Mean action noise std: 4.79
          Mean value_function loss: 109.4546
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.2102
                       Mean reward: 661.96
               Mean episode length: 223.78
    Episode_Reward/reaching_object: 1.1208
    Episode_Reward/rotating_object: 132.1119
        Episode_Reward/action_rate: -0.1304
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.33s
                      Time elapsed: 00:57:10
                               ETA: 00:02:05

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 42322 steps/s (collection: 2.202s, learning 0.121s)
             Mean action noise std: 4.79
          Mean value_function loss: 97.3730
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 76.2252
                       Mean reward: 648.71
               Mean episode length: 222.41
    Episode_Reward/reaching_object: 1.1308
    Episode_Reward/rotating_object: 136.8703
        Episode_Reward/action_rate: -0.1322
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.32s
                      Time elapsed: 00:57:12
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 42319 steps/s (collection: 2.200s, learning 0.123s)
             Mean action noise std: 4.79
          Mean value_function loss: 97.2302
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.2447
                       Mean reward: 669.53
               Mean episode length: 227.16
    Episode_Reward/reaching_object: 1.1534
    Episode_Reward/rotating_object: 135.9683
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.32s
                      Time elapsed: 00:57:14
                               ETA: 00:02:00

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 41985 steps/s (collection: 2.218s, learning 0.123s)
             Mean action noise std: 4.80
          Mean value_function loss: 93.0569
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.2641
                       Mean reward: 635.73
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 1.1332
    Episode_Reward/rotating_object: 131.6955
        Episode_Reward/action_rate: -0.1321
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.34s
                      Time elapsed: 00:57:17
                               ETA: 00:01:58

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 42574 steps/s (collection: 2.188s, learning 0.121s)
             Mean action noise std: 4.80
          Mean value_function loss: 82.2344
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.2786
                       Mean reward: 686.33
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.1366
    Episode_Reward/rotating_object: 136.3621
        Episode_Reward/action_rate: -0.1332
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.31s
                      Time elapsed: 00:57:19
                               ETA: 00:01:56

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 41617 steps/s (collection: 2.236s, learning 0.126s)
             Mean action noise std: 4.80
          Mean value_function loss: 105.3241
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 76.2928
                       Mean reward: 726.65
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.1477
    Episode_Reward/rotating_object: 136.0916
        Episode_Reward/action_rate: -0.1344
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.36s
                      Time elapsed: 00:57:21
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 41177 steps/s (collection: 2.261s, learning 0.126s)
             Mean action noise std: 4.80
          Mean value_function loss: 97.3435
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 76.3080
                       Mean reward: 641.50
               Mean episode length: 225.34
    Episode_Reward/reaching_object: 1.1423
    Episode_Reward/rotating_object: 135.6424
        Episode_Reward/action_rate: -0.1342
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.39s
                      Time elapsed: 00:57:24
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 41079 steps/s (collection: 2.267s, learning 0.126s)
             Mean action noise std: 4.81
          Mean value_function loss: 97.2800
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.3206
                       Mean reward: 673.02
               Mean episode length: 227.76
    Episode_Reward/reaching_object: 1.1567
    Episode_Reward/rotating_object: 138.0452
        Episode_Reward/action_rate: -0.1356
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.39s
                      Time elapsed: 00:57:26
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 40944 steps/s (collection: 2.275s, learning 0.126s)
             Mean action noise std: 4.81
          Mean value_function loss: 100.3165
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 76.3375
                       Mean reward: 733.08
               Mean episode length: 242.82
    Episode_Reward/reaching_object: 1.1321
    Episode_Reward/rotating_object: 137.0112
        Episode_Reward/action_rate: -0.1330
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.40s
                      Time elapsed: 00:57:29
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 41391 steps/s (collection: 2.250s, learning 0.125s)
             Mean action noise std: 4.81
          Mean value_function loss: 82.9761
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 76.3536
                       Mean reward: 707.18
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.1392
    Episode_Reward/rotating_object: 135.1404
        Episode_Reward/action_rate: -0.1342
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.37s
                      Time elapsed: 00:57:31
                               ETA: 00:01:44

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 41159 steps/s (collection: 2.262s, learning 0.126s)
             Mean action noise std: 4.82
          Mean value_function loss: 87.1362
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 76.3695
                       Mean reward: 742.33
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.1510
    Episode_Reward/rotating_object: 135.6414
        Episode_Reward/action_rate: -0.1359
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.39s
                      Time elapsed: 00:57:33
                               ETA: 00:01:41

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 40439 steps/s (collection: 2.300s, learning 0.131s)
             Mean action noise std: 4.82
          Mean value_function loss: 112.0984
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.3859
                       Mean reward: 683.97
               Mean episode length: 229.02
    Episode_Reward/reaching_object: 1.1361
    Episode_Reward/rotating_object: 134.2359
        Episode_Reward/action_rate: -0.1349
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.43s
                      Time elapsed: 00:57:36
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 42109 steps/s (collection: 2.214s, learning 0.120s)
             Mean action noise std: 4.82
          Mean value_function loss: 80.9131
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.3988
                       Mean reward: 667.08
               Mean episode length: 222.69
    Episode_Reward/reaching_object: 1.1620
    Episode_Reward/rotating_object: 138.5674
        Episode_Reward/action_rate: -0.1372
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.33s
                      Time elapsed: 00:57:38
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 42403 steps/s (collection: 2.198s, learning 0.121s)
             Mean action noise std: 4.82
          Mean value_function loss: 79.5981
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.4154
                       Mean reward: 685.53
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 1.1555
    Episode_Reward/rotating_object: 136.0580
        Episode_Reward/action_rate: -0.1372
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.32s
                      Time elapsed: 00:57:40
                               ETA: 00:01:34

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 42259 steps/s (collection: 2.205s, learning 0.121s)
             Mean action noise std: 4.83
          Mean value_function loss: 95.3453
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 76.4333
                       Mean reward: 677.52
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 1.1301
    Episode_Reward/rotating_object: 133.7695
        Episode_Reward/action_rate: -0.1347
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.33s
                      Time elapsed: 00:57:43
                               ETA: 00:01:32

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 42248 steps/s (collection: 2.204s, learning 0.122s)
             Mean action noise std: 4.83
          Mean value_function loss: 88.3520
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 76.4467
                       Mean reward: 667.90
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 1.1670
    Episode_Reward/rotating_object: 142.5897
        Episode_Reward/action_rate: -0.1395
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.33s
                      Time elapsed: 00:57:45
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 42273 steps/s (collection: 2.203s, learning 0.122s)
             Mean action noise std: 4.83
          Mean value_function loss: 86.8962
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 76.4591
                       Mean reward: 705.69
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 1.1146
    Episode_Reward/rotating_object: 131.6241
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.33s
                      Time elapsed: 00:57:47
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 41038 steps/s (collection: 2.273s, learning 0.123s)
             Mean action noise std: 4.84
          Mean value_function loss: 108.9528
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.4732
                       Mean reward: 676.03
               Mean episode length: 223.74
    Episode_Reward/reaching_object: 1.1301
    Episode_Reward/rotating_object: 133.7352
        Episode_Reward/action_rate: -0.1353
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.40s
                      Time elapsed: 00:57:50
                               ETA: 00:01:25

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 42449 steps/s (collection: 2.193s, learning 0.123s)
             Mean action noise std: 4.84
          Mean value_function loss: 95.5918
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 76.4960
                       Mean reward: 683.28
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 1.1250
    Episode_Reward/rotating_object: 133.1912
        Episode_Reward/action_rate: -0.1345
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.32s
                      Time elapsed: 00:57:52
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 42565 steps/s (collection: 2.187s, learning 0.122s)
             Mean action noise std: 4.84
          Mean value_function loss: 98.7527
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 76.5205
                       Mean reward: 722.38
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.1426
    Episode_Reward/rotating_object: 139.0489
        Episode_Reward/action_rate: -0.1369
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.31s
                      Time elapsed: 00:57:54
                               ETA: 00:01:20

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 41463 steps/s (collection: 2.251s, learning 0.120s)
             Mean action noise std: 4.85
          Mean value_function loss: 99.9301
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 76.5421
                       Mean reward: 627.30
               Mean episode length: 228.10
    Episode_Reward/reaching_object: 1.1275
    Episode_Reward/rotating_object: 132.6934
        Episode_Reward/action_rate: -0.1351
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.37s
                      Time elapsed: 00:57:57
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 41768 steps/s (collection: 2.227s, learning 0.127s)
             Mean action noise std: 4.85
          Mean value_function loss: 101.8609
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 76.5579
                       Mean reward: 702.42
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 1.1279
    Episode_Reward/rotating_object: 136.0587
        Episode_Reward/action_rate: -0.1350
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.35s
                      Time elapsed: 00:57:59
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 41564 steps/s (collection: 2.240s, learning 0.125s)
             Mean action noise std: 4.85
          Mean value_function loss: 103.8443
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 76.5737
                       Mean reward: 660.10
               Mean episode length: 226.72
    Episode_Reward/reaching_object: 1.1391
    Episode_Reward/rotating_object: 136.8762
        Episode_Reward/action_rate: -0.1360
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.37s
                      Time elapsed: 00:58:02
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 41908 steps/s (collection: 2.226s, learning 0.120s)
             Mean action noise std: 4.86
          Mean value_function loss: 99.5086
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 76.5897
                       Mean reward: 662.84
               Mean episode length: 226.86
    Episode_Reward/reaching_object: 1.1255
    Episode_Reward/rotating_object: 131.1489
        Episode_Reward/action_rate: -0.1344
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.35s
                      Time elapsed: 00:58:04
                               ETA: 00:01:11

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 41919 steps/s (collection: 2.227s, learning 0.118s)
             Mean action noise std: 4.86
          Mean value_function loss: 99.8345
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 76.6060
                       Mean reward: 626.40
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.1234
    Episode_Reward/rotating_object: 133.9726
        Episode_Reward/action_rate: -0.1356
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.35s
                      Time elapsed: 00:58:06
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 42834 steps/s (collection: 2.176s, learning 0.119s)
             Mean action noise std: 4.86
          Mean value_function loss: 102.7248
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 76.6199
                       Mean reward: 705.93
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 1.1421
    Episode_Reward/rotating_object: 138.7568
        Episode_Reward/action_rate: -0.1369
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.29s
                      Time elapsed: 00:58:09
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 43671 steps/s (collection: 2.140s, learning 0.111s)
             Mean action noise std: 4.87
          Mean value_function loss: 85.2431
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 76.6403
                       Mean reward: 720.56
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.1469
    Episode_Reward/rotating_object: 137.1423
        Episode_Reward/action_rate: -0.1379
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.25s
                      Time elapsed: 00:58:11
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 44491 steps/s (collection: 2.099s, learning 0.110s)
             Mean action noise std: 4.87
          Mean value_function loss: 104.4059
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.6582
                       Mean reward: 643.90
               Mean episode length: 221.43
    Episode_Reward/reaching_object: 1.1367
    Episode_Reward/rotating_object: 133.4883
        Episode_Reward/action_rate: -0.1367
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.21s
                      Time elapsed: 00:58:13
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 43018 steps/s (collection: 2.159s, learning 0.126s)
             Mean action noise std: 4.87
          Mean value_function loss: 91.5792
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 76.6725
                       Mean reward: 638.85
               Mean episode length: 227.49
    Episode_Reward/reaching_object: 1.1466
    Episode_Reward/rotating_object: 134.7145
        Episode_Reward/action_rate: -0.1382
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.29s
                      Time elapsed: 00:58:15
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 41204 steps/s (collection: 2.260s, learning 0.126s)
             Mean action noise std: 4.88
          Mean value_function loss: 97.2837
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.6901
                       Mean reward: 707.00
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 1.1611
    Episode_Reward/rotating_object: 139.6199
        Episode_Reward/action_rate: -0.1397
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.39s
                      Time elapsed: 00:58:18
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 41052 steps/s (collection: 2.269s, learning 0.125s)
             Mean action noise std: 4.88
          Mean value_function loss: 94.9778
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 76.7093
                       Mean reward: 693.78
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 1.1363
    Episode_Reward/rotating_object: 134.8428
        Episode_Reward/action_rate: -0.1372
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.39s
                      Time elapsed: 00:58:20
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 40242 steps/s (collection: 2.314s, learning 0.129s)
             Mean action noise std: 4.88
          Mean value_function loss: 99.8773
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 76.7243
                       Mean reward: 673.90
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 1.1460
    Episode_Reward/rotating_object: 136.9733
        Episode_Reward/action_rate: -0.1380
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.44s
                      Time elapsed: 00:58:23
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 41068 steps/s (collection: 2.273s, learning 0.120s)
             Mean action noise std: 4.88
          Mean value_function loss: 108.0445
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 76.7377
                       Mean reward: 667.29
               Mean episode length: 222.41
    Episode_Reward/reaching_object: 1.1384
    Episode_Reward/rotating_object: 132.3009
        Episode_Reward/action_rate: -0.1368
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.39s
                      Time elapsed: 00:58:25
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 41766 steps/s (collection: 2.221s, learning 0.133s)
             Mean action noise std: 4.89
          Mean value_function loss: 103.2664
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 76.7507
                       Mean reward: 698.58
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 1.1318
    Episode_Reward/rotating_object: 132.6581
        Episode_Reward/action_rate: -0.1371
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.35s
                      Time elapsed: 00:58:27
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 42397 steps/s (collection: 2.196s, learning 0.123s)
             Mean action noise std: 4.89
          Mean value_function loss: 108.2068
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 76.7697
                       Mean reward: 680.27
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 1.1074
    Episode_Reward/rotating_object: 131.4486
        Episode_Reward/action_rate: -0.1345
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.32s
                      Time elapsed: 00:58:30
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 42371 steps/s (collection: 2.199s, learning 0.121s)
             Mean action noise std: 4.89
          Mean value_function loss: 98.2460
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 76.7853
                       Mean reward: 633.01
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 1.1423
    Episode_Reward/rotating_object: 134.7139
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.32s
                      Time elapsed: 00:58:32
                               ETA: 00:00:42

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 41860 steps/s (collection: 2.224s, learning 0.124s)
             Mean action noise std: 4.90
          Mean value_function loss: 97.4200
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 76.7983
                       Mean reward: 621.53
               Mean episode length: 212.54
    Episode_Reward/reaching_object: 1.1386
    Episode_Reward/rotating_object: 134.4157
        Episode_Reward/action_rate: -0.1381
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.35s
                      Time elapsed: 00:58:34
                               ETA: 00:00:40

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 42190 steps/s (collection: 2.203s, learning 0.127s)
             Mean action noise std: 4.90
          Mean value_function loss: 94.5232
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 76.8119
                       Mean reward: 696.62
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 1.1416
    Episode_Reward/rotating_object: 136.2770
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.33s
                      Time elapsed: 00:58:37
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 42394 steps/s (collection: 2.196s, learning 0.123s)
             Mean action noise std: 4.90
          Mean value_function loss: 103.5093
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 76.8249
                       Mean reward: 703.53
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.1526
    Episode_Reward/rotating_object: 137.1886
        Episode_Reward/action_rate: -0.1401
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.32s
                      Time elapsed: 00:58:39
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 42457 steps/s (collection: 2.196s, learning 0.119s)
             Mean action noise std: 4.91
          Mean value_function loss: 113.0479
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 76.8435
                       Mean reward: 683.15
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 1.1110
    Episode_Reward/rotating_object: 131.7375
        Episode_Reward/action_rate: -0.1352
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.32s
                      Time elapsed: 00:58:41
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 42414 steps/s (collection: 2.195s, learning 0.123s)
             Mean action noise std: 4.91
          Mean value_function loss: 94.2953
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 76.8591
                       Mean reward: 647.66
               Mean episode length: 219.00
    Episode_Reward/reaching_object: 1.1250
    Episode_Reward/rotating_object: 133.6317
        Episode_Reward/action_rate: -0.1365
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.32s
                      Time elapsed: 00:58:44
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 42564 steps/s (collection: 2.188s, learning 0.121s)
             Mean action noise std: 4.91
          Mean value_function loss: 103.7258
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 76.8800
                       Mean reward: 680.59
               Mean episode length: 225.00
    Episode_Reward/reaching_object: 1.1321
    Episode_Reward/rotating_object: 134.9492
        Episode_Reward/action_rate: -0.1382
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.31s
                      Time elapsed: 00:58:46
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 42542 steps/s (collection: 2.185s, learning 0.126s)
             Mean action noise std: 4.92
          Mean value_function loss: 97.2291
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 76.8984
                       Mean reward: 715.78
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 1.1596
    Episode_Reward/rotating_object: 139.8957
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.31s
                      Time elapsed: 00:58:48
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 42483 steps/s (collection: 2.194s, learning 0.120s)
             Mean action noise std: 4.92
          Mean value_function loss: 102.1775
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.9184
                       Mean reward: 701.56
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.1223
    Episode_Reward/rotating_object: 132.5000
        Episode_Reward/action_rate: -0.1384
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.31s
                      Time elapsed: 00:58:50
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 42476 steps/s (collection: 2.189s, learning 0.125s)
             Mean action noise std: 4.92
          Mean value_function loss: 111.2700
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 76.9372
                       Mean reward: 642.65
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 1.1179
    Episode_Reward/rotating_object: 131.4952
        Episode_Reward/action_rate: -0.1382
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.31s
                      Time elapsed: 00:58:53
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 42995 steps/s (collection: 2.167s, learning 0.120s)
             Mean action noise std: 4.93
          Mean value_function loss: 84.0566
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 76.9503
                       Mean reward: 702.73
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.1345
    Episode_Reward/rotating_object: 137.6702
        Episode_Reward/action_rate: -0.1403
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.29s
                      Time elapsed: 00:58:55
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 41326 steps/s (collection: 2.253s, learning 0.126s)
             Mean action noise std: 4.93
          Mean value_function loss: 89.1252
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 76.9620
                       Mean reward: 682.13
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.1239
    Episode_Reward/rotating_object: 132.2439
        Episode_Reward/action_rate: -0.1396
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.38s
                      Time elapsed: 00:58:57
                               ETA: 00:00:16

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 41608 steps/s (collection: 2.237s, learning 0.126s)
             Mean action noise std: 4.93
          Mean value_function loss: 101.7377
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 76.9730
                       Mean reward: 708.19
               Mean episode length: 238.31
    Episode_Reward/reaching_object: 1.1300
    Episode_Reward/rotating_object: 133.2143
        Episode_Reward/action_rate: -0.1399
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.36s
                      Time elapsed: 00:59:00
                               ETA: 00:00:14

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 41501 steps/s (collection: 2.243s, learning 0.126s)
             Mean action noise std: 4.93
          Mean value_function loss: 103.3506
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 76.9908
                       Mean reward: 687.20
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 1.1454
    Episode_Reward/rotating_object: 137.0889
        Episode_Reward/action_rate: -0.1430
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.37s
                      Time elapsed: 00:59:02
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 41465 steps/s (collection: 2.245s, learning 0.126s)
             Mean action noise std: 4.94
          Mean value_function loss: 105.0541
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 77.0125
                       Mean reward: 685.36
               Mean episode length: 225.38
    Episode_Reward/reaching_object: 1.1170
    Episode_Reward/rotating_object: 134.2247
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.37s
                      Time elapsed: 00:59:05
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 41164 steps/s (collection: 2.259s, learning 0.129s)
             Mean action noise std: 4.94
          Mean value_function loss: 98.6082
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 77.0272
                       Mean reward: 682.11
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.1424
    Episode_Reward/rotating_object: 134.9061
        Episode_Reward/action_rate: -0.1428
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.39s
                      Time elapsed: 00:59:07
                               ETA: 00:00:07

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 40564 steps/s (collection: 2.295s, learning 0.129s)
             Mean action noise std: 4.94
          Mean value_function loss: 90.5200
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 77.0377
                       Mean reward: 665.62
               Mean episode length: 222.48
    Episode_Reward/reaching_object: 1.1201
    Episode_Reward/rotating_object: 132.9106
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.42s
                      Time elapsed: 00:59:09
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 40426 steps/s (collection: 2.304s, learning 0.128s)
             Mean action noise std: 4.95
          Mean value_function loss: 93.7519
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 77.0513
                       Mean reward: 697.85
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.1653
    Episode_Reward/rotating_object: 139.2769
        Episode_Reward/action_rate: -0.1453
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.43s
                      Time elapsed: 00:59:12
                               ETA: 00:00:02

